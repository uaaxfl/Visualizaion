2020.aacl-main.22,C18-1139,0,0.0459533,"Missing"
2020.aacl-main.22,N19-1423,0,0.110489,"eam tasks, such as entity linking (Luo et al., 2015), relation extraction (Feldman and Rosenfeld, 2006) and question answering (Lee et al., 2006). NER is usually modeled as a sentence-level sequence labeling task in previous work. For example, Lample et al. (2016) used long-short term memory (LSTM) (Gers et al., 2000) for capturing contextual word representations and conditional random ﬁeid (CRF) (Lafferty et al., 2001) for jointly label decoding. In recent years, language models (LMs) were introduced to this task to learn better contextual representations of words (Peters et al., 2017, 2018; Devlin et al., 2019). However, these methods only consider the contexts within a sentence, which is insufﬁcient. Our work is motivated by the observation that the contextual information beyond sentences can mitigate the negative effects of the ambiguous and limited sentence contexts. The sentences within a document are highly related, and the interactions between them can provide document-level contextual information. For example, in Figure 1, sentence 1 is ambiguous because it can be either his mother called Elizabeth Trump or a business called Elizabeth Trump and Son. But another sentence in this document expli"
2020.aacl-main.22,W06-1656,0,0.0506255,"es of document- and word-level contextual evidence. Blue italic and red underlined entities are the names of organizations and persons respectively. Green and orange arrows indicate the document- and word-level contextual evidence respectively. Introduction Named Entity Recognition (NER) is deﬁned as automatically identifying and classifying named entities into speciﬁc categories (e.g., person, location, organization) in text. It is a critical task in Natural Language Processing (NLP) and a prerequisite for many downstream tasks, such as entity linking (Luo et al., 2015), relation extraction (Feldman and Rosenfeld, 2006) and question answering (Lee et al., 2006). NER is usually modeled as a sentence-level sequence labeling task in previous work. For example, Lample et al. (2016) used long-short term memory (LSTM) (Gers et al., 2000) for capturing contextual word representations and conditional random ﬁeid (CRF) (Lafferty et al., 2001) for jointly label decoding. In recent years, language models (LMs) were introduced to this task to learn better contextual representations of words (Peters et al., 2017, 2018; Devlin et al., 2019). However, these methods only consider the contexts within a sentence, which is ins"
2020.aacl-main.22,N16-1030,0,0.493173,"ows indicate the document- and word-level contextual evidence respectively. Introduction Named Entity Recognition (NER) is deﬁned as automatically identifying and classifying named entities into speciﬁc categories (e.g., person, location, organization) in text. It is a critical task in Natural Language Processing (NLP) and a prerequisite for many downstream tasks, such as entity linking (Luo et al., 2015), relation extraction (Feldman and Rosenfeld, 2006) and question answering (Lee et al., 2006). NER is usually modeled as a sentence-level sequence labeling task in previous work. For example, Lample et al. (2016) used long-short term memory (LSTM) (Gers et al., 2000) for capturing contextual word representations and conditional random ﬁeid (CRF) (Lafferty et al., 2001) for jointly label decoding. In recent years, language models (LMs) were introduced to this task to learn better contextual representations of words (Peters et al., 2017, 2018; Devlin et al., 2019). However, these methods only consider the contexts within a sentence, which is insufﬁcient. Our work is motivated by the observation that the contextual information beyond sentences can mitigate the negative effects of the ambiguous and limite"
2020.aacl-main.22,K18-2005,0,0.0239259,"Missing"
2020.aacl-main.22,Q16-1026,0,0.0213156,"example, Passos et al. (2014) trained phrase vectors in their lexicon-infused skip-gram model. Lin and Wu (2009) used a linear chain CRF and added phrase cluster features extracted from the web data. However, these methods require heavy feature engineering, which necessities massive domain knowledge. In addition, these methods cannot make full use of contextual information within texts. In recent years, many neural networks were applied to the NER task. Collobert et al. (2011) ﬁrst adopted CNNs to learn word representations. Recently, BiLSTM was widely used for long distance context modeling (Chiu and Nichols, 2016; Lample et al., 2016; Ma and Hovy, 2016). Additionally, Chiu and Nichols (2016) employed CNNs to capture morphological word representations; Lample et al. (2016) utilized CRF to model the dependencies between adjacent tags; Ma and Hovy (2016) proposed LSTM-CNNs-CRF model to combine the strengths of these components. Besides, Strubell et al. (2017) proposed iterated-dilated CNNs for higher efﬁciency than BiLSTM and better capacity with large context than vanilla CNNs. Recent work proved that the context-sensitive representations captured by language models are useful in NER systems. Peters et"
2020.aacl-main.22,P09-1116,0,0.0109506,"t by capturing the interactions between sentences within a document with the multi-head self attention mechanism. • We propose to mine the word-level context with an auxiliary word classiﬁcation task to learn the words’ preferences of entity type and relative position from the entities. • We conduct experiments on several benchmark datasets, and the results validate the effectiveness of our method. 2 Related Work In traditional NER methods, contexts are usually modeled via hand-crafted features. For example, Passos et al. (2014) trained phrase vectors in their lexicon-infused skip-gram model. Lin and Wu (2009) used a linear chain CRF and added phrase cluster features extracted from the web data. However, these methods require heavy feature engineering, which necessities massive domain knowledge. In addition, these methods cannot make full use of contextual information within texts. In recent years, many neural networks were applied to the NER task. Collobert et al. (2011) ﬁrst adopted CNNs to learn word representations. Recently, BiLSTM was widely used for long distance context modeling (Chiu and Nichols, 2016; Lample et al., 2016; Ma and Hovy, 2016). Additionally, Chiu and Nichols (2016) employed"
2020.aacl-main.22,P19-1524,0,0.0244358,"Missing"
2020.aacl-main.22,D15-1104,0,0.0210484,"g officer. × Sentence 2 Figure 1: Examples of document- and word-level contextual evidence. Blue italic and red underlined entities are the names of organizations and persons respectively. Green and orange arrows indicate the document- and word-level contextual evidence respectively. Introduction Named Entity Recognition (NER) is deﬁned as automatically identifying and classifying named entities into speciﬁc categories (e.g., person, location, organization) in text. It is a critical task in Natural Language Processing (NLP) and a prerequisite for many downstream tasks, such as entity linking (Luo et al., 2015), relation extraction (Feldman and Rosenfeld, 2006) and question answering (Lee et al., 2006). NER is usually modeled as a sentence-level sequence labeling task in previous work. For example, Lample et al. (2016) used long-short term memory (LSTM) (Gers et al., 2000) for capturing contextual word representations and conditional random ﬁeid (CRF) (Lafferty et al., 2001) for jointly label decoding. In recent years, language models (LMs) were introduced to this task to learn better contextual representations of words (Peters et al., 2017, 2018; Devlin et al., 2019). However, these methods only co"
2020.aacl-main.22,W09-1119,0,0.0311585,"f all labels denoted as |C|). During training, we use plabel to compute k the loss function for word classiﬁcation, which is formulated as cross-entropy loss: n  (11) where λ is the weight of word classiﬁcation loss. (8) where pk is obtained by looking up a randomlyinitialized embedding matrix and tuned during training. Then xk is fed into the two-layer classiﬁer to predict label distribution: tanh(Wc1 xk L(θ) = LCRF (θ) + λLW C (θ), 4.2 Experimental Settings In our experiments, we use the BIOES labeling scheme for output tags, which was proven to outperform other options in previous work (Ratinov and Roth, 2009). Under this tagging scheme, the number of labels |C |= 17 ([B,I,E,S]× 1 The CoNLL-2002 dataset contains Dutch and Spanish data. But the Spanish data lacks the marks of doucument boundaries. Thus we only conduct experiments on the Dutch data. (10) k=1 185 Hyper-parameter Word embedding dim. (dwe ) Character embedding dim. (dce ) Position embedding dim. (dpe ) Character hidden state dim. (dch ) Word hidden state dim. (dwh ) Sentence hidden state dim. (dsh ) Sequence hidden state dim. (dsqh ) Neural attention subspace dim. (dna ) Self attention subspace dim. (dsa ) Label classiﬁer hidden dim. (d"
2020.aacl-main.22,P16-1101,0,0.0216239,"vectors in their lexicon-infused skip-gram model. Lin and Wu (2009) used a linear chain CRF and added phrase cluster features extracted from the web data. However, these methods require heavy feature engineering, which necessities massive domain knowledge. In addition, these methods cannot make full use of contextual information within texts. In recent years, many neural networks were applied to the NER task. Collobert et al. (2011) ﬁrst adopted CNNs to learn word representations. Recently, BiLSTM was widely used for long distance context modeling (Chiu and Nichols, 2016; Lample et al., 2016; Ma and Hovy, 2016). Additionally, Chiu and Nichols (2016) employed CNNs to capture morphological word representations; Lample et al. (2016) utilized CRF to model the dependencies between adjacent tags; Ma and Hovy (2016) proposed LSTM-CNNs-CRF model to combine the strengths of these components. Besides, Strubell et al. (2017) proposed iterated-dilated CNNs for higher efﬁciency than BiLSTM and better capacity with large context than vanilla CNNs. Recent work proved that the context-sensitive representations captured by language models are useful in NER systems. Peters et al. (2017) proposed TagLM model and intro"
2020.aacl-main.22,P18-2039,0,0.011775,". . . , win , and feed the sentence into TagLM’s bottom BiGRU to compute [hword , hword , . . . , hword i0 i1 in ]. Next we compute the document representation di and replace hword with i0 it (requires dwh = dsh ). Then we feed them into 184 the top BiGRU. The input of the top BiGRU contains document- and sentence-level contextual representations simultaneously. Thus its output hidden states act as the fusion of the two contexts. 3.3 To incorporate the word-level context, we conwith the original CRF input hseq catenate plabel ik ik to enrich word representations with the label distributions (Seyler et al., 2018). The CRF takes the enhanced word representations as input and decodes the best label sequence. Our framework is jointly trained on the original NER and the auxiliary classiﬁcation task via multi-task learning: Word-level Context In natural language, words themselves have different preferences on different entity types and relative positions from the entities. These preferences provide word-level contextual information for the NER task. For example, in the sentence “With only one match before New Year, Real will spend Christmas ahead of others”, the type of the entity Real is uncertain because"
2020.aacl-main.22,E99-1001,0,0.0674449,"that the context-sensitive representations captured by language models are useful in NER systems. Peters et al. (2017) proposed TagLM model and introduced LM embeddings in this task. Afterwards, ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) were proposed for better contextual representations. However, these methods focused only on the context within a sentence, so their performance is substantially hurt by the ambiguity and limitation of sentence context. To combine contexts beyond sentences, several methods were proposed to mine document-level information, such as logical rules (Mikheev et al., 1999), global attention (Xu et al., 2018; Zhang et al., 2018; Hu et al., 2020) and memory mechanisms (Gui et al., 2020). But these methods ignored the sequential characteristics of the sentences within a document, which may be sub-optimal. We observe that contextual associations between sentences in a document have the potential of improving the NER performance. Moreover, the words’ preferences of entity type and relative position from the entities 182 O O … O O S O O O S O S O O S O tanh 2-layer Neural Network … Character embedding Word embedding Character representation (ு) ு ߙଵଵ … ߙଵ … … … ଵ …"
2020.aacl-main.22,W14-1609,0,0.0177081,"he NER task with a uniﬁed framework. • We propose to exploit the document-level context by capturing the interactions between sentences within a document with the multi-head self attention mechanism. • We propose to mine the word-level context with an auxiliary word classiﬁcation task to learn the words’ preferences of entity type and relative position from the entities. • We conduct experiments on several benchmark datasets, and the results validate the effectiveness of our method. 2 Related Work In traditional NER methods, contexts are usually modeled via hand-crafted features. For example, Passos et al. (2014) trained phrase vectors in their lexicon-infused skip-gram model. Lin and Wu (2009) used a linear chain CRF and added phrase cluster features extracted from the web data. However, these methods require heavy feature engineering, which necessities massive domain knowledge. In addition, these methods cannot make full use of contextual information within texts. In recent years, many neural networks were applied to the NER task. Collobert et al. (2011) ﬁrst adopted CNNs to learn word representations. Recently, BiLSTM was widely used for long distance context modeling (Chiu and Nichols, 2016; Lampl"
2020.aacl-main.22,P17-1161,0,0.35782,"erequisite for many downstream tasks, such as entity linking (Luo et al., 2015), relation extraction (Feldman and Rosenfeld, 2006) and question answering (Lee et al., 2006). NER is usually modeled as a sentence-level sequence labeling task in previous work. For example, Lample et al. (2016) used long-short term memory (LSTM) (Gers et al., 2000) for capturing contextual word representations and conditional random ﬁeid (CRF) (Lafferty et al., 2001) for jointly label decoding. In recent years, language models (LMs) were introduced to this task to learn better contextual representations of words (Peters et al., 2017, 2018; Devlin et al., 2019). However, these methods only consider the contexts within a sentence, which is insufﬁcient. Our work is motivated by the observation that the contextual information beyond sentences can mitigate the negative effects of the ambiguous and limited sentence contexts. The sentences within a document are highly related, and the interactions between them can provide document-level contextual information. For example, in Figure 1, sentence 1 is ambiguous because it can be either his mother called Elizabeth Trump or a business called Elizabeth Trump and Son. But another sen"
2020.aacl-main.22,N18-1202,0,0.0490263,"s to capture morphological word representations; Lample et al. (2016) utilized CRF to model the dependencies between adjacent tags; Ma and Hovy (2016) proposed LSTM-CNNs-CRF model to combine the strengths of these components. Besides, Strubell et al. (2017) proposed iterated-dilated CNNs for higher efﬁciency than BiLSTM and better capacity with large context than vanilla CNNs. Recent work proved that the context-sensitive representations captured by language models are useful in NER systems. Peters et al. (2017) proposed TagLM model and introduced LM embeddings in this task. Afterwards, ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) were proposed for better contextual representations. However, these methods focused only on the context within a sentence, so their performance is substantially hurt by the ambiguity and limitation of sentence context. To combine contexts beyond sentences, several methods were proposed to mine document-level information, such as logical rules (Mikheev et al., 1999), global attention (Xu et al., 2018; Zhang et al., 2018; Hu et al., 2020) and memory mechanisms (Gui et al., 2020). But these methods ignored the sequential characteristics of the sentences within a do"
2020.aacl-main.22,D17-1283,0,0.011877,"of contextual information within texts. In recent years, many neural networks were applied to the NER task. Collobert et al. (2011) ﬁrst adopted CNNs to learn word representations. Recently, BiLSTM was widely used for long distance context modeling (Chiu and Nichols, 2016; Lample et al., 2016; Ma and Hovy, 2016). Additionally, Chiu and Nichols (2016) employed CNNs to capture morphological word representations; Lample et al. (2016) utilized CRF to model the dependencies between adjacent tags; Ma and Hovy (2016) proposed LSTM-CNNs-CRF model to combine the strengths of these components. Besides, Strubell et al. (2017) proposed iterated-dilated CNNs for higher efﬁciency than BiLSTM and better capacity with large context than vanilla CNNs. Recent work proved that the context-sensitive representations captured by language models are useful in NER systems. Peters et al. (2017) proposed TagLM model and introduced LM embeddings in this task. Afterwards, ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) were proposed for better contextual representations. However, these methods focused only on the context within a sentence, so their performance is substantially hurt by the ambiguity and limitation of sent"
2020.aacl-main.22,K18-1009,0,0.0237893,"nguage models are useful in NER systems. Peters et al. (2017) proposed TagLM model and introduced LM embeddings in this task. Afterwards, ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019) were proposed for better contextual representations. However, these methods focused only on the context within a sentence, so their performance is substantially hurt by the ambiguity and limitation of sentence context. To combine contexts beyond sentences, several methods were proposed to mine document-level information, such as logical rules (Mikheev et al., 1999), global attention (Xu et al., 2018; Zhang et al., 2018; Hu et al., 2020) and memory mechanisms (Gui et al., 2020). But these methods ignored the sequential characteristics of the sentences within a document, which may be sub-optimal. We observe that contextual associations between sentences in a document have the potential of improving the NER performance. Moreover, the words’ preferences of entity type and relative position from the entities 182 O O … O O S O O O S O S O O S O tanh 2-layer Neural Network … Character embedding Word embedding Character representation (ு) ு ߙଵଵ … ߙଵ … … … ଵ … … …… ߙଵ … … … ு ଵ ߙ ߙଵ ……  … … ଵ ߙଵ … … ଵ ଵ ߙଵ …"
2020.aacl-main.81,W06-0901,0,0.173113,"ic English MUC-4 dataset and a large-scale Chinese CFEED dataset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised methods rely on intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Tradit"
2020.aacl-main.81,D17-1209,0,0.0554986,"Missing"
2020.aacl-main.81,D14-1199,0,0.038221,"Missing"
2020.aacl-main.81,P17-1038,1,0.848953,"08; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised methods rely on intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Traditionally, pattern-based and classifier-based methods are popular to solve this task. Systems like AutoSlog (Riloff et al., 1993) and AutoSlogTS (Riloff, 1996) directly applied regular patterns to extract role fillers. Many works (Patwardhan and Riloff, 2007, 2009; Huang and Riloff, 2011, 2012; Boros et al., 2014) relied on feature-based classifiers to distinguish can"
2020.aacl-main.81,P15-1017,1,0.877144,"relevant sources. • We propose an edge-enriched graph attention algorithm that can blend both the local clues and global context to enforce semantic representations for each candidate and help to filter noises in the event regions. • Experimental results show that our method outperforms the existing state-of-the-arts on two datasets with different languages, including a public English MUC-4 dataset and a large-scale Chinese CFEED dataset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However,"
2020.aacl-main.81,D18-1158,1,0.821423,"nriched graph attention algorithm that can blend both the local clues and global context to enforce semantic representations for each candidate and help to filter noises in the event regions. • Experimental results show that our method outperforms the existing state-of-the-arts on two datasets with different languages, including a public English MUC-4 dataset and a large-scale Chinese CFEED dataset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised methods rely on intensiv"
2020.aacl-main.81,W04-1000,0,0.595724,"a graph into rich vector representations to facilitate event region identification. The experimental results on two datasets of two languages show that our approach yields new state-of-the-art performance for the challenging event extraction task. 1 Event Template Event Extraction (EE), a challenging task in Natural Language Processing, aims to extract key types of information (aka event roles, e.g., perpetrators and victims of an attack event) that can represent an event in texts and plays a critical role in downstream applications such as Question Answer (Yang et al., 2003) and Summarizing (Filatova and Hatzivassiloglou, 2004). Existing research on EE mostly focused on sentence-level, such as the evaluation in Automatic Content Extraction (ACE) 20051 . However, an event is usually described in Most of the work was done when the first author was a research engineer in the Institute of Automation, CAS. 1 http://projects.ldc.upenn.edu/ace/ Role Fillers PerpInd TERRORISTS, HOODED INDIVIDUALS PerpOrg SHINING PATH Victim DOLORES HINOSTROZA, HINOSTROZA Figure 1: An example of document-level event extraction. We need to extract noun phrases from the document as role fillers for the event roles in the predefined event templ"
2020.aacl-main.81,P11-1114,1,0.959214,"intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Traditionally, pattern-based and classifier-based methods are popular to solve this task. Systems like AutoSlog (Riloff et al., 1993) and AutoSlogTS (Riloff, 1996) directly applied regular patterns to extract role fillers. Many works (Patwardhan and Riloff, 2007, 2009; Huang and Riloff, 2011, 2012; Boros et al., 2014) relied on feature-based classifiers to distinguish candidate role fillers from texts and achieved better performance. Until recent years, researchers (Hsi, 2018; Yang et al., 2018; Zheng et al., 2019) began to utilize multiple neuralbased methods to solve the task. Notably, among the document-level EE research, some works (Patwardhan and Riloff, 2009; Huang and Riloff, 2012; Yang et al., 2018) have noticed the importance of identifying event regions to improve performance. Traditional neural networks such as Convolutional Neural Networks and Recursive Neural Network"
2020.aacl-main.81,P08-1030,0,0.140204,"MUC-4 dataset and a large-scale Chinese CFEED dataset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised methods rely on intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Traditionally, pattern-based"
2020.aacl-main.81,P10-1081,0,0.195906,"ge-scale Chinese CFEED dataset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised methods rely on intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Traditionally, pattern-based and classifier-based meth"
2020.aacl-main.81,D17-1159,0,0.0728135,"Missing"
2020.aacl-main.81,N16-1034,0,0.0729328,"We propose an edge-enriched graph attention algorithm that can blend both the local clues and global context to enforce semantic representations for each candidate and help to filter noises in the event regions. • Experimental results show that our method outperforms the existing state-of-the-arts on two datasets with different languages, including a public English MUC-4 dataset and a large-scale Chinese CFEED dataset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised meth"
2020.aacl-main.81,D07-1075,0,0.0602653,", these supervised methods rely on intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Traditionally, pattern-based and classifier-based methods are popular to solve this task. Systems like AutoSlog (Riloff et al., 1993) and AutoSlogTS (Riloff, 1996) directly applied regular patterns to extract role fillers. Many works (Patwardhan and Riloff, 2007, 2009; Huang and Riloff, 2011, 2012; Boros et al., 2014) relied on feature-based classifiers to distinguish candidate role fillers from texts and achieved better performance. Until recent years, researchers (Hsi, 2018; Yang et al., 2018; Zheng et al., 2019) began to utilize multiple neuralbased methods to solve the task. Notably, among the document-level EE research, some works (Patwardhan and Riloff, 2009; Huang and Riloff, 2012; Yang et al., 2018) have noticed the importance of identifying event regions to improve performance. Traditional neural networks such as Convolutional Neural Network"
2020.aacl-main.81,D09-1016,0,0.768247,"mentions the target event twice in two regions. The correct role fillers are crowding in the first event region S1, S2, S3 and the second one S5, S6 respectively. Nevertheless, the sentence-level extractor will extract noise from both the event regions like HOUSE from S3 and irrelevant sentence like FATHER in S4, destroying the layout of the original regions. Many previous efforts try to avoid aggregating the noisy candidates by detecting such event regions. The popular approach is to apply sentential classification to filter the sentences and recognize role fillers from the chosen sentences (Patwardhan and Riloff, 2009; Huang and Riloff, 2012). However, these approaches only detect regions at single sentence-level and ignore the crowding of relevant sentences. Also, they also suffer from the accumulative error of sentential classification. For example, they may identify S2 as a relevant event region but S3 as irrelevant because they fail to take into account the similarity of S2 and S3. Another solution proposed by Yang et al. (2018) tries to detect the primary event description sentence and supplement the missing event roles with fillers from adjacent sentences. This method considers the multiple sentences"
2020.aacl-main.81,N12-1008,0,0.0667316,"taset. 2 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/documentevent1.html ˜ 812 2 Related Work Sentence-level EE has achieved a lot of advancement in recent work (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018) and can be classified into template-based approaches (Jungermann and Morik, 2008; Bjorne et al., 2010; Hogenboom et al., 2016) and statistical approaches. Templatebased methods require human-crafted templates to match the events. Most of the statistical methods are supervised and either based on feature engineering (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Reichart and Barzilay, 2012) or Neural network algorithm (Chen et al., 2015; Nguyen et al., 2016; Chen et al., 2018; Liu et al., 2018; Sha et al., 2018; Liu et al., 2018). However, these supervised methods rely on intensive manual annotations. To alleviate this problem, many weak supervised methods (Chen et al., 2017; Zeng et al., 2018) have arisen and achieved good performance in ACE 2005 evaluation. However, most of the time, people care about the events discussed across a whole document. So research on document-level EE also prevails. Traditionally, pattern-based and classifier-based methods are popular to solve this"
2020.aacl-main.81,P18-4009,1,0.243235,"detecting such event regions. The popular approach is to apply sentential classification to filter the sentences and recognize role fillers from the chosen sentences (Patwardhan and Riloff, 2009; Huang and Riloff, 2012). However, these approaches only detect regions at single sentence-level and ignore the crowding of relevant sentences. Also, they also suffer from the accumulative error of sentential classification. For example, they may identify S2 as a relevant event region but S3 as irrelevant because they fail to take into account the similarity of S2 and S3. Another solution proposed by Yang et al. (2018) tries to detect the primary event description sentence and supplement the missing event roles with fillers from adjacent sentences. This method considers the multiple sentences in an event region but is limited to one region per document. For instance, it may detect S1 as the primary sentence and supplement it with S2, missing the valid items like SHINING PATH from region 2. Moreover, it also suffers from the errors selecting primary sentence, and the supplementing strategy is coarse-grained and fails to take into account every candidate filler individually. We build a graph for each document"
2020.aacl-main.81,D19-1032,0,0.443645,"Missing"
2020.acl-demos.33,D15-1180,0,0.028667,"d by (Mullenbach et al., 2018), assigning the importance value for each label to the discharge summaries to assists in explaining the model prediction process. 2.2 Dilated Convolution Dilated convolution is designed for image classification to aggregate multi-scale contextual information without losing resolution in computer vision (Yu and Koltun, 2016). It inserts “holes” in the standard convolution map to increase the reception field. The hole-structure brings a breakthrough improvement to the semantic segmentation task. Similarly, several hole-structured convolution neural networks (CNNs) (Lei et al., 2015; Guo et al., 2017) are designed to handle natural language processing tasks. In the text, there exists noncontinuous semantic where useless information may be interspersed among the sentences. Holes in the dilated convolution can ignore the extra word between the non-continuous words and well adapt to match non-continuous semantic. Since the semantic infomation is crutial when understanding natural language(Zuo et al., 2019), we apply the dilated convolution to encode the text, capturing the non-continuous semantic information. 3 3.1 Clinical Coder System Method We propose a Dilated Convoluti"
2020.acl-demos.33,N18-1100,0,0.388356,"bstract is no doubt that the increased granularity increases the difficulty of manual coding. Existing studies came up with several approaches of automatic coding prediction to replace the repetitive manual work, from the traditional machine learning methods (Perotte et al., 2013; Koopman et al., 2015), to neural network methods (Shi et al., 2017; Yu et al., 2019). Although these methods achieve great success, they are still confronted with a critical challenge, which is the interpretability of predicted codes. Explainable model and results are essential for clinical medicine decision making (Mullenbach et al., 2018). Thus, the practical approach is supposed to predict correct codes and simultaneously give the reason why each code is predicted. In this paper, we introduce Clinical-Coder, an online system aiming to assign ICD codes to Chinese clinical notes. ICD coding has been a research hotspot of clinical medicine, but the interpretability of prediction hinders its practical application. We exploit a Dilated Convolutional Attention network with N-gram Matching Mechanism (DCANM) to capture semantic features for non-continuous words and continuous n-gram words, concentrating on explaining the reason why e"
2020.acl-demos.33,D18-1352,0,0.0143544,"Related Work Automatic ICD coding Automatic ICD coding has recently been a research hotspot in the field of clinical medicine, where neural network architecture methods show promising results than traditional machine learning methods. Most studies treat automatic ICD coding as a multi-label classification problem and use only the free-text in summaries to predict codes (Subotin and Davis, 2015; Kavuluru et al., 2015; Yu et al., 2019), while many methods benefit from extra information. Shi et al. (2017) encode label description with character-level and word-level long shortterm memory network. Rios and Kavuluru (2018) encode label description with averaging words embedding. Furthermore, adversarial learning is employed to unify writing styles of diagnosis descriptions and ICD code descriptions (Xie et al., 2018). Besides code descriptions, Wikipedia comes to be regarded as an external knowledge source (Prakash et al., 2017; Bai and Vucetic, 2019). Additionally, inferring interpretability is a crucial challenge and obstacle for practical automatic coding, since professionals are willing to be con295 Figure 3: The whole architecture of the model. The input is the clinical text, and output is the ICD codes. T"
2020.acl-demos.33,P18-1098,0,0.0279916,"nal machine learning methods. Most studies treat automatic ICD coding as a multi-label classification problem and use only the free-text in summaries to predict codes (Subotin and Davis, 2015; Kavuluru et al., 2015; Yu et al., 2019), while many methods benefit from extra information. Shi et al. (2017) encode label description with character-level and word-level long shortterm memory network. Rios and Kavuluru (2018) encode label description with averaging words embedding. Furthermore, adversarial learning is employed to unify writing styles of diagnosis descriptions and ICD code descriptions (Xie et al., 2018). Besides code descriptions, Wikipedia comes to be regarded as an external knowledge source (Prakash et al., 2017; Bai and Vucetic, 2019). Additionally, inferring interpretability is a crucial challenge and obstacle for practical automatic coding, since professionals are willing to be con295 Figure 3: The whole architecture of the model. The input is the clinical text, and output is the ICD codes. The yellow dotted box indicates how to use attention-based dilated convolution to capture the implicit semantic of noncontinuous words. The green dotted box indicates how to use n-gram matching mecha"
2020.acl-main.282,D17-1209,0,0.0178045,"been successfully applied to question answering (Tay et al., 2018), machine translation (Gulcehre et al., 2018) and sentence representation (Dhingra et al., 2018). To our knowledge, this is the first work to apply hyperbolic representation method to the automatic ICD coding task. Graph Convolutional Networks. GCN (Kipf and Welling, 2016) is a powerful neural network, which operates on graph data. It yields substantial improvements over various NLP tasks such as semantic role labeling (Marcheggiani and Titov, 2017), multi-document summarization (Yasunaga et al., 2017) and machine translation (Bastings et al., 2017). Veliˇckovi´c et al. (2017) propose graph attention networks (GAT) to summarize neighborhood features by using masked self-attentional layers. We are the first to capture the code co-occurrence characteristic via the GCN for the automatic ICD coding task. 3 Method We propose a hyperbolic and co-graph representation (HyperCore) model for automatic ICD coding. Firstly, to capture the code hierarchy, we learn the code hyperbolic representations and measure the similarities between document and codes in the hyperbolic space. Secondly, to exploit code cooccurrence, we exploit the GCN to learn code"
2020.acl-main.282,W18-1708,0,0.248355,"rchy and code co-occurrence. Hyperbolic Representation. Hyperbolic space has been applied to modeling complex networks (Krioukov et al., 2010). Recent research on representation learning demonstrates that the hyperbolic space is more suitable for representing symbolic data with hierarchical structures than the Euclidean space (Nickel and Kiela, 2017, 2018; Hamann, 2018). In the field of natural language processing (NLP), the hyperbolic representation has been successfully applied to question answering (Tay et al., 2018), machine translation (Gulcehre et al., 2018) and sentence representation (Dhingra et al., 2018). To our knowledge, this is the first work to apply hyperbolic representation method to the automatic ICD coding task. Graph Convolutional Networks. GCN (Kipf and Welling, 2016) is a powerful neural network, which operates on graph data. It yields substantial improvements over various NLP tasks such as semantic role labeling (Marcheggiani and Titov, 2017), multi-document summarization (Yasunaga et al., 2017) and machine translation (Bastings et al., 2017). Veliˇckovi´c et al. (2017) propose graph attention networks (GAT) to summarize neighborhood features by using masked self-attentional layer"
2020.acl-main.282,W19-4319,0,0.123564,"Missing"
2020.acl-main.282,D17-1159,0,0.028195,"17, 2018; Hamann, 2018). In the field of natural language processing (NLP), the hyperbolic representation has been successfully applied to question answering (Tay et al., 2018), machine translation (Gulcehre et al., 2018) and sentence representation (Dhingra et al., 2018). To our knowledge, this is the first work to apply hyperbolic representation method to the automatic ICD coding task. Graph Convolutional Networks. GCN (Kipf and Welling, 2016) is a powerful neural network, which operates on graph data. It yields substantial improvements over various NLP tasks such as semantic role labeling (Marcheggiani and Titov, 2017), multi-document summarization (Yasunaga et al., 2017) and machine translation (Bastings et al., 2017). Veliˇckovi´c et al. (2017) propose graph attention networks (GAT) to summarize neighborhood features by using masked self-attentional layers. We are the first to capture the code co-occurrence characteristic via the GCN for the automatic ICD coding task. 3 Method We propose a hyperbolic and co-graph representation (HyperCore) model for automatic ICD coding. Firstly, to capture the code hierarchy, we learn the code hyperbolic representations and measure the similarities between document and c"
2020.acl-main.282,P18-1098,0,0.290404,"tical for the automatic ICD coding. Code Hierarchy: Based on ICD taxonomy, ICD codes are organized under a tree-like hierarchical structure as shown in Figure 2, which indicates the parent-child and sibling relations between codes. In the hierarchical structure, the upper level nodes represent more generic disease categories and the lower level nodes represent more specific diseases. The code hierarchy can capture the mutual exclusion of some codes. If code X and Y are both children of Z (i.e., X and Y are the siblings), it is unlikely to simultaneously assign X and Y to a patient in general (Xie and Xing, 2018). For example in Figure 2, if code “464.00 (acute laryngitis without mention of obstruction)” is assigned to a patient, it is unlikely to assign the code “464.01 (acute laryngitis with obstruction)” to the patient at the same time. If automatic ICD coding models ignore such a characteristic, they are prone to giving inconsistent predictions. Thus, a challenging problem is how to model the code hierarchy and use it to capture the mutual exclusion of codes. Code Co-occurrence: Since some diseases are concurrent or have a causal relationship with each other, their codes usually co-occur in the cl"
2020.acl-main.282,K17-1045,0,0.0287217,"cessing (NLP), the hyperbolic representation has been successfully applied to question answering (Tay et al., 2018), machine translation (Gulcehre et al., 2018) and sentence representation (Dhingra et al., 2018). To our knowledge, this is the first work to apply hyperbolic representation method to the automatic ICD coding task. Graph Convolutional Networks. GCN (Kipf and Welling, 2016) is a powerful neural network, which operates on graph data. It yields substantial improvements over various NLP tasks such as semantic role labeling (Marcheggiani and Titov, 2017), multi-document summarization (Yasunaga et al., 2017) and machine translation (Bastings et al., 2017). Veliˇckovi´c et al. (2017) propose graph attention networks (GAT) to summarize neighborhood features by using masked self-attentional layers. We are the first to capture the code co-occurrence characteristic via the GCN for the automatic ICD coding task. 3 Method We propose a hyperbolic and co-graph representation (HyperCore) model for automatic ICD coding. Firstly, to capture the code hierarchy, we learn the code hyperbolic representations and measure the similarities between document and codes in the hyperbolic space. Secondly, to exploit cod"
2020.acl-main.282,N18-1100,0,0.245413,"alized ICD coding skills can handle the task. However, it is hard to train such an eligible ICD coder. Second, it is difficult to correctly assign proper codes to the input document even for professional coders, because one document can be assigned multiple ICD codes and the number of codes in the taxonomy of ICD is large. For example, there are over 15,000 and 60,000 codes respectively in the ninth version (ICD-9) and the tenth version (ICD-10) of ICD taxonomies. To reduce human labor and coding errors, many methods have been carefully designed for automatic ICD coding (Perotte et al., 2013; Mullenbach et al., 2018). For example in Figure 1, given the clinical text of a patient, the ICD coding model needs to automatically predict the corresponding ICD codes. The automatic ICD coding task can be modeled as a multi-label classification task since each clinical text is usually accompanied by mul3105 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3105–3114 c July 5 - 10, 2020. 2020 Association for Computational Linguistics ICD-9 Descriptor Hierarchical Structure 460-519 - DISEASES OF THE RESPIRATORY SYSTEM 460-519 460 - Acute nasopharyngitis 461 - Acute sinusit"
2020.acl-main.282,D18-1352,0,0.0115341,"sopharyngitis 461 - Acute sinusitis 461.0 - Maxillary 460 461 462 463 464 461.1 - Frontal 464 - Acute laryngitis and tracheitis 464.0 - Acute laryngitis 461.0 464.0 461.1 464.1 464.00 - Without mention of obstruction 464.01 - With obstruction 464.00 464.01 464.1 - Acute tracheitis Figure 2: An example of ICD-9 descriptors and the derived hierarchical structure. tiple codes. Most of the previous methods handle each code in isolation and convert the multi-label problem into a set of binary classification problems to predict whether each code of interest presents or not (Mullenbach et al., 2018; Rios and Kavuluru, 2018). Though effective, they ignore two important characteristics: Code Hierarchy and Code Co-occurrence, which can be leveraged to improve coding accuracy. In the following, we will introduce the two characteristics and the reasons why they are critical for the automatic ICD coding. Code Hierarchy: Based on ICD taxonomy, ICD codes are organized under a tree-like hierarchical structure as shown in Figure 2, which indicates the parent-child and sibling relations between codes. In the hierarchical structure, the upper level nodes represent more generic disease categories and the lower level nodes re"
2020.ccl-1.84,D17-1209,0,0.0358136,"Missing"
2020.ccl-1.84,D18-1307,0,0.0127475,"an modify the dominance of discourses via a top attention-based discourse-level salient network to enhance explanatory semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), a"
2020.ccl-1.84,D18-1017,1,0.713794,"dding vector of each word sn (ddm ) as sn (ddm ) from the pre-trained embedding. Finally, we obtain Proceedings of the 19th China National Conference on Computational Linguistics, pages 903-914, Hainan, China, October 30 - Novermber 1, 2020. (c) Technical Committee on Computational Linguistics, Chinese Information Processing Society of China Computational Linguistics the word representation sequence s = {s1 , ..., sn } of message s and d = {dd1 , ..., ddm } of discourse d corresponding to s. 3.1.3 Word Encoding Inspired by the application of self-attention to multiple tasks (Tan et al., 2018; Cao et al., 2018), we exploit multi-head self-attention encoder to encode input words. The scaled dot-product attention can be described as follows:   QK T √ (Q, K, V ) = softmax V (1) d 20 where Q ∈ RN ×2dimh , K ∈ RN ×2dimh and V ∈ RN ×2dimh are query matrices, keys matrices and value matrices, respectively. In our setting, Q = K = V = s for encoding sentence, and Q = K = V = d for encoding discourse. Multi-head attention first projects the queries, keys, and values h times by using different linear projections. The results of attention are concatenated and once again projected to get the final representat"
2020.ccl-1.84,D11-1027,0,0.0194132,"iscourses via a top attention-based discourse-level salient network to enhance explanatory semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interact"
2020.ccl-1.84,Q17-1009,0,0.0191957,"ent network to enhance explanatory semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interactive hierarchical Bi-LSTM framework (Xia and Ding, 2019) to e"
2020.ccl-1.84,W17-0812,0,0.0242857,"ent network to enhance explanatory semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interactive hierarchical Bi-LSTM framework (Xia and Ding, 2019) to e"
2020.ccl-1.84,N19-1179,0,0.173756,"planation detection (CED) which is the fundamental and important subtask of CEA. Syntactic Dependency with Graph Network: Syntactic dependency is a vital linguistic feature for natural language processing (NLP). There are some researches employ syntactic dependency such as retrieving question answering passage assisted with syntactic dependency (Cui et al., 2005), mining opinion with syntactic dependency (Wu et al., 2009) and so on. For tasks related to causal semantics extraction from relevant texts, dependency syntactic information may evoke causal relations between discourse units in text (Gao et al., 2019). And recently, there are some researches (Marcheggiani and Titov, 2017; Zhang et al., 2018) convert the syntactic dependency into a graph with graph convolutional network (GCN) (Kipf and Welling, 2016) to effectively capture the syntactic dependency semantics between words in context, such as a semantic role model with GCN (Marcheggiani and Titov, 2017), a GCN-based model assisted with a syntactic dependency to improving relation extraction (Zhang et al., 2018). In this paper, we capture the salient explanatory semantics based on the syntactic-centric graph. Self-attention Mechanism: Self-att"
2020.ccl-1.84,P16-1135,0,0.0159136,"coherent semantics (Jurafsky, 2010). As shown in Figure 1, M1 can be divided into three discourses, and D2 is the explanation that expresses the reason why it is advantageous for the equipment to operate at these temperatures. CED is important for tasks that require an understanding of textual expression (Son et al., 2018). For example, for question answering, the answers of questions are most likely to be in a group of sentences that contains causal explanations (Oh et al., 2013). Furthermore, the summarization of event descriptions can be improved by selecting causally motivated sentences (Hidey and McKeown, 2016). Therefore, CED is a problem worthy of further study. The existing methods mostly regard this task as a classification problem (Son et al., 2018). At present, there are mainly two kinds of methods, feature-based methods and neural-based methods, for similar semantic understanding tasks in discourse granularity, such as opinion sentiment classification and discourse parsing (Nejat et al., 2017; Jia et al., 2018; Soricut and Marcu, 2003). The feature-based methods can extract the feature of the relation between discourses. However, these methods do not deal well with the implicit instances whic"
2020.ccl-1.84,P18-2070,0,0.0283788,"of sentences that contains causal explanations (Oh et al., 2013). Furthermore, the summarization of event descriptions can be improved by selecting causally motivated sentences (Hidey and McKeown, 2016). Therefore, CED is a problem worthy of further study. The existing methods mostly regard this task as a classification problem (Son et al., 2018). At present, there are mainly two kinds of methods, feature-based methods and neural-based methods, for similar semantic understanding tasks in discourse granularity, such as opinion sentiment classification and discourse parsing (Nejat et al., 2017; Jia et al., 2018; Soricut and Marcu, 2003). The feature-based methods can extract the feature of the relation between discourses. However, these methods do not deal well with the implicit instances which lack explicit features. For CED, as shown in Figure 1, D2 lacks explicit features such as because of, due to, or the features of tenses, which are not friendly for feature-based methods. The methods based on neural network are mainly Tree-LSTM model (Wang et al., 2017) and hierarchical Bi-LSTM model (Son et al., 2018). The Tree-LSTM models learn the relations between words to capture the semantics of discours"
2020.ccl-1.84,D15-1278,0,0.0307231,"Missing"
2020.ccl-1.84,D16-1035,0,0.0279858,"to keywords, the common way is using attention mechanisms to increase the attention weight of them. However, this implicitly learned attention is not very interpretable. Inspired by previous researches (Vashishth et al., 2019; Bastings et al., 2017), we propose a bottom graph-based word-level salient network which merges the syntactic dependency to capture the salient semantics of discourses contained in their keywords. Finally, how to consider the correlation at the discourse level and pay more attention to the discourses that are key to the explanatory semantics? Inspired by previous work (Li et al., 2016), we propose a top attention-based discourse-level salient network to focus on the key discourses in terms of explanatory semantics. In summary, the contributions of this paper are as follows: • We design a Pyramid Salient-Aware Network (PSAN) to detect causal explanations of messages which can effectively learn the pivotal relations between keywords at word level and further filter the key information at discourse level in terms of explanatory semantics. 20 • PSAN can assist in causal explanation detection via capturing the salient semantics of discourses contained in their keywords with a bo"
2020.ccl-1.84,W17-5535,0,0.012278,"ly to be in a group of sentences that contains causal explanations (Oh et al., 2013). Furthermore, the summarization of event descriptions can be improved by selecting causally motivated sentences (Hidey and McKeown, 2016). Therefore, CED is a problem worthy of further study. The existing methods mostly regard this task as a classification problem (Son et al., 2018). At present, there are mainly two kinds of methods, feature-based methods and neural-based methods, for similar semantic understanding tasks in discourse granularity, such as opinion sentiment classification and discourse parsing (Nejat et al., 2017; Jia et al., 2018; Soricut and Marcu, 2003). The feature-based methods can extract the feature of the relation between discourses. However, these methods do not deal well with the implicit instances which lack explicit features. For CED, as shown in Figure 1, D2 lacks explicit features such as because of, due to, or the features of tenses, which are not friendly for feature-based methods. The methods based on neural network are mainly Tree-LSTM model (Wang et al., 2017) and hierarchical Bi-LSTM model (Son et al., 2018). The Tree-LSTM models learn the relations between words to capture the sem"
2020.ccl-1.84,P13-1170,0,0.537816,"Missing"
2020.ccl-1.84,W14-4322,0,0.024862,"ntion-based discourse-level salient network to enhance explanatory semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interactive hierarchical Bi-LSTM fram"
2020.ccl-1.84,D16-1014,0,0.0137524,"semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interactive hierarchical Bi-LSTM framework (Xia and Ding, 2019) to extract emotion-cause pair in mess"
2020.ccl-1.84,P17-2103,0,0.0264943,"the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interactive hierarchical Bi-LSTM framework (Xia and Ding, 2019) to extract emotion-cause pair in messages. Furthermore, Son (2018) defines the causal explanation analysis task (CEA) to extract causal explanatory semantics in messages and annotates a dataset for other downstream tasks. In this paper, we focus on causal explanation detection (CED) which is the fundamental and important subtask of CEA. Syntactic Dependency with"
2020.ccl-1.84,D18-1372,0,0.117529,"relations in messages which explain how the meaning of different textual units can combine to jointly build a discourse meaning for the larger unit. The explanation is an important relation of coherence which refers to the textual unit (e.g. discourse) in a message that expresses explanatory coherent semantics (Jurafsky, 2010). As shown in Figure 1, M1 can be divided into three discourses, and D2 is the explanation that expresses the reason why it is advantageous for the equipment to operate at these temperatures. CED is important for tasks that require an understanding of textual expression (Son et al., 2018). For example, for question answering, the answers of questions are most likely to be in a group of sentences that contains causal explanations (Oh et al., 2013). Furthermore, the summarization of event descriptions can be improved by selecting causally motivated sentences (Hidey and McKeown, 2016). Therefore, CED is a problem worthy of further study. The existing methods mostly regard this task as a classification problem (Son et al., 2018). At present, there are mainly two kinds of methods, feature-based methods and neural-based methods, for similar semantic understanding tasks in discourse"
2020.ccl-1.84,N03-1030,0,0.129378,"contains causal explanations (Oh et al., 2013). Furthermore, the summarization of event descriptions can be improved by selecting causally motivated sentences (Hidey and McKeown, 2016). Therefore, CED is a problem worthy of further study. The existing methods mostly regard this task as a classification problem (Son et al., 2018). At present, there are mainly two kinds of methods, feature-based methods and neural-based methods, for similar semantic understanding tasks in discourse granularity, such as opinion sentiment classification and discourse parsing (Nejat et al., 2017; Jia et al., 2018; Soricut and Marcu, 2003). The feature-based methods can extract the feature of the relation between discourses. However, these methods do not deal well with the implicit instances which lack explicit features. For CED, as shown in Figure 1, D2 lacks explicit features such as because of, due to, or the features of tenses, which are not friendly for feature-based methods. The methods based on neural network are mainly Tree-LSTM model (Wang et al., 2017) and hierarchical Bi-LSTM model (Son et al., 2018). The Tree-LSTM models learn the relations between words to capture the semantics of discourses more accurately but lac"
2020.ccl-1.84,P19-1320,0,0.0132091,"f the 19th China National Conference on Computational Linguistics, pages 903-914, Hainan, China, October 30 - Novermber 1, 2020. (c) Technical Committee on Computational Linguistics, Chinese Information Processing Society of China Computational Linguistics Next, we need to consider how to make better use of the information of keywords contained in the syntactic structure. To pay more attention to keywords, the common way is using attention mechanisms to increase the attention weight of them. However, this implicitly learned attention is not very interpretable. Inspired by previous researches (Vashishth et al., 2019; Bastings et al., 2017), we propose a bottom graph-based word-level salient network which merges the syntactic dependency to capture the salient semantics of discourses contained in their keywords. Finally, how to consider the correlation at the discourse level and pay more attention to the discourses that are key to the explanatory semantics? Inspired by previous work (Li et al., 2016), we propose a top attention-based discourse-level salient network to focus on the key discourses in terms of explanatory semantics. In summary, the contributions of this paper are as follows: • We design a Pyr"
2020.ccl-1.84,I17-1050,0,0.0168256,"milar semantic understanding tasks in discourse granularity, such as opinion sentiment classification and discourse parsing (Nejat et al., 2017; Jia et al., 2018; Soricut and Marcu, 2003). The feature-based methods can extract the feature of the relation between discourses. However, these methods do not deal well with the implicit instances which lack explicit features. For CED, as shown in Figure 1, D2 lacks explicit features such as because of, due to, or the features of tenses, which are not friendly for feature-based methods. The methods based on neural network are mainly Tree-LSTM model (Wang et al., 2017) and hierarchical Bi-LSTM model (Son et al., 2018). The Tree-LSTM models learn the relations between words to capture the semantics of discourses more accurately but lack further understanding of the semantics between discourses. The hierarchical Bi-LSTM models can employ sequence structure to implicitly learn the relations between words and discourses. However, previous work shows that compared with Tree-LSTM, Bi-LSTM lacks a direct understanding of the dependency relations between words. Therefore, the method of implicit learning of inter-word relations is not prominent in the tasks related"
2020.ccl-1.84,D09-1159,0,0.00806823,"defines the causal explanation analysis task (CEA) to extract causal explanatory semantics in messages and annotates a dataset for other downstream tasks. In this paper, we focus on causal explanation detection (CED) which is the fundamental and important subtask of CEA. Syntactic Dependency with Graph Network: Syntactic dependency is a vital linguistic feature for natural language processing (NLP). There are some researches employ syntactic dependency such as retrieving question answering passage assisted with syntactic dependency (Cui et al., 2005), mining opinion with syntactic dependency (Wu et al., 2009) and so on. For tasks related to causal semantics extraction from relevant texts, dependency syntactic information may evoke causal relations between discourse units in text (Gao et al., 2019). And recently, there are some researches (Marcheggiani and Titov, 2017; Zhang et al., 2018) convert the syntactic dependency into a graph with graph convolutional network (GCN) (Kipf and Welling, 2016) to effectively capture the syntactic dependency semantics between words in context, such as a semantic role model with GCN (Marcheggiani and Titov, 2017), a GCN-based model assisted with a syntactic depend"
2020.ccl-1.84,P19-1096,0,0.0195044,"tz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on movie reviews (Ji and Smith, 2017), and a two-step interactive hierarchical Bi-LSTM framework (Xia and Ding, 2019) to extract emotion-cause pair in messages. Furthermore, Son (2018) defines the causal explanation analysis task (CEA) to extract causal explanatory semantics in messages and annotates a dataset for other downstream tasks. In this paper, we focus on causal explanation detection (CED) which is the fundamental and important subtask of CEA. Syntactic Dependency with Graph Network: Syntactic dependency is a vital linguistic feature for natural language processing (NLP). There are some researches employ syntactic dependency such as retrieving question answering passage assisted with syntactic depen"
2020.ccl-1.84,D17-1004,0,0.0245705,"nt network. Furthermore, PSAN can modify the dominance of discourses via a top attention-based discourse-level salient network to enhance explanatory semantics of messages. 2 Related Works 20 • Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. Our experiments also prove the effectiveness of each module. CC L Causal Semantic Detection: Recently, causality detection which detects specific causes and effects and the relations between them has received more attention, such as the researches proposed by Li (Li and Mao, 2019), Zhang (Zhang et al., 2017), Bekoulis (Bekoulis et al., 2018), Do (Do et al., 2011), Riaz (Riaz and Girju, 2014), Dunietz (Dunietz et al., 2017a) and Sharp (Sharp et al., 2016). Specifically, to extract the causal explanation semantics from the messages in a general level, some researches capture the causal semantics in messages from the perspective of discourse structure, such as capturing counterfactual conditionals from a social message with the PDTB discourse relation parsing (Son et al., 2017), a pre-trained model with Rhetorical Structure Theory Discourse Treebank (RSTDT) for exploiting discourse structures on mov"
2020.ccl-1.84,D18-1244,0,0.0936203,"Dependency with Graph Network: Syntactic dependency is a vital linguistic feature for natural language processing (NLP). There are some researches employ syntactic dependency such as retrieving question answering passage assisted with syntactic dependency (Cui et al., 2005), mining opinion with syntactic dependency (Wu et al., 2009) and so on. For tasks related to causal semantics extraction from relevant texts, dependency syntactic information may evoke causal relations between discourse units in text (Gao et al., 2019). And recently, there are some researches (Marcheggiani and Titov, 2017; Zhang et al., 2018) convert the syntactic dependency into a graph with graph convolutional network (GCN) (Kipf and Welling, 2016) to effectively capture the syntactic dependency semantics between words in context, such as a semantic role model with GCN (Marcheggiani and Titov, 2017), a GCN-based model assisted with a syntactic dependency to improving relation extraction (Zhang et al., 2018). In this paper, we capture the salient explanatory semantics based on the syntactic-centric graph. Self-attention Mechanism: Self-attention has been introduced to machine translation by Vaswani (Vaswani et al., 2017) for capt"
2020.ccl-1.86,D18-1017,1,0.770613,"the LSTM. Peters et al. (2017) leverage a character language model to enhance the input of the model. For Chinese NER, character-based methods have been the dominant approaches (Lu et al., 2016; Dong et al., 2016). These methods only focus on character sequence information, ignoring word boundaries information, which can cause errors of predicting entity boundaries. Thus, how to better exploit lexical knowledge has received much research attention. Word segmentation information is used as extra features for Chinese NER task (Peng and Dredze, 2015; He and Sun, 2016). Peng and Dredze (2016) and Cao et al. (2018) propose a joint model for Chinese NER, which is jointly trained with CWS task. Zhang and Yang (2018) investigate a lattice LSTM to encode a sequence of input characters as well as words that match a lexicon. However, the lattice model cannot exploit all matched words and only processes the matched words once. Recently, graph-based models have been proposed for Chinese NER (Gui et al., 2019; Sui et al., 2019). Based on the lattice structure, Sui et al. (2019) propose a graph neural network to encode word information. Tag dependencies is also a challenging problem, but few attention has been pa"
2020.ccl-1.86,N13-1006,0,0.0660884,"Missing"
2020.ccl-1.86,W06-0130,0,0.0670738,"Missing"
2020.ccl-1.86,P15-1017,1,0.880678,"Missing"
2020.ccl-1.86,D19-1096,0,0.0157827,"it lexical knowledge has received much research attention. Word segmentation information is used as extra features for Chinese NER task (Peng and Dredze, 2015; He and Sun, 2016). Peng and Dredze (2016) and Cao et al. (2018) propose a joint model for Chinese NER, which is jointly trained with CWS task. Zhang and Yang (2018) investigate a lattice LSTM to encode a sequence of input characters as well as words that match a lexicon. However, the lattice model cannot exploit all matched words and only processes the matched words once. Recently, graph-based models have been proposed for Chinese NER (Gui et al., 2019; Sui et al., 2019). Based on the lattice structure, Sui et al. (2019) propose a graph neural network to encode word information. Tag dependencies is also a challenging problem, but few attention has been paid to tackling the problem. Zhang et al. (2018) leverages LSTM as decoder for sequence labeling task. However, the unidirectional LSTM decoder only exploits the past predicted tags information, ignoring the future un-predicted tags. Hence, we propose a hierarchical tagging mechanism to capture bidirectional tag dependencies in the whole sentence. To our best knowledge, we are the first to i"
2020.ccl-1.86,C02-1054,0,0.432472,"ethods. CC L The task of named entity recognition (NER) is to recognize the named entities from a plain text and classify them into pre-defined types. NER is a fundamental and preliminary task in natural language processing (NLP) area and is beneficial for many downstream NLP tasks such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015) and question answering (Yahya et al., 2013). In recent years, numerous methods have been carefully studied for NER task, including Conditional Random Fields (CRFs) (Lafferty et al., 2001) and Support Vector Machines (SVMs) (Isozaki and Kazawa, 2002). Currently, with the development of deep learning methods, neural networks have been introduced for the NER task. In particular, sequence labeling neural network models have achieved state-of-the-art performance (Lample et al., 2016; Zhang and Yang, 2018). Though sequence labeling neural network methods have achieved great success for Chinese NER task, some challenging issues still have not been well addressed. One significant drawback is that previous methods usually fail to correctly predict entity boundaries. To conduct a quantitative analysis, we perform a BiLSTM+CRF model proposed by Hua"
2020.ccl-1.86,N16-1030,0,0.147027,"is beneficial for many downstream NLP tasks such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015) and question answering (Yahya et al., 2013). In recent years, numerous methods have been carefully studied for NER task, including Conditional Random Fields (CRFs) (Lafferty et al., 2001) and Support Vector Machines (SVMs) (Isozaki and Kazawa, 2002). Currently, with the development of deep learning methods, neural networks have been introduced for the NER task. In particular, sequence labeling neural network models have achieved state-of-the-art performance (Lample et al., 2016; Zhang and Yang, 2018). Though sequence labeling neural network methods have achieved great success for Chinese NER task, some challenging issues still have not been well addressed. One significant drawback is that previous methods usually fail to correctly predict entity boundaries. To conduct a quantitative analysis, we perform a BiLSTM+CRF model proposed by Huang et al. (2015), which is the most representative Chinese NER sequence labeling system, on WeiboNER dataset (Peng and Dredze, 2015; He and Sun, 2016), OntoNotes 4 dataset (Weischedel et al., 2011) and MSRA dataset (Levow, 2006). The"
2020.ccl-1.86,W06-0115,0,0.105309,"Missing"
2020.ccl-1.86,L16-1138,0,0.0137114,"long short term memory (BiLSTM) for feature extraction and the CRF for decoding. The model is trained via the end-to-end paradigm. After that, the BiLSTM+CRF model is usually exploited as the baseline model for NER task. Ma and Hovy (2016) use a character convolutional neural network (CNN) to represent spelling characteristic. Then the charcter representation vector is concatenated with word embedding as the input of the LSTM. Peters et al. (2017) leverage a character language model to enhance the input of the model. For Chinese NER, character-based methods have been the dominant approaches (Lu et al., 2016; Dong et al., 2016). These methods only focus on character sequence information, ignoring word boundaries information, which can cause errors of predicting entity boundaries. Thus, how to better exploit lexical knowledge has received much research attention. Word segmentation information is used as extra features for Chinese NER task (Peng and Dredze, 2015; He and Sun, 2016). Peng and Dredze (2016) and Cao et al. (2018) propose a joint model for Chinese NER, which is jointly trained with CWS task. Zhang and Yang (2018) investigate a lattice LSTM to encode a sequence of input characters as wel"
2020.ccl-1.86,P18-1230,0,0.153362,"g passes on the matched words to better learn lexical knowledge in complex sentences intuitively. Take the sentence “南京市长江大桥 (Nanjing Yangtze River Bridge)” for example, it is more complicated than the sentence in Figure 1 because it is prone to be misunderstood as “南京市长/江大桥 (The mayor of Nanjing is Jiang Daqiao)”. Thus, it needs more reasoning passes to learn the lexical knowledge for recognizing the entity “长江大桥 (Yangtze River Bridge)” than the entity “北海道 (Hokkaido)” in Figure 1. However, if the reasoning passes are too many, the performance will decrease in word sense disambiguation task (Luo et al., 2018). We argue that the problem also exists in Chinese NER task. Hence, how to exploit all matched words and perform flexible multi-pass reasoning according to the complexity of sentences should be well investigated. Another issue is that most of the existing methods cannot efficiently capture tag dependencies. In sequence labeling neural network models, CRF is usually used as a decoding layer. Although the CRF decoder has achieved improvements, the transition matrix in CRF layer only learns the neighboring tag dependencies, which are typically first order dependencies (Zhang et al., 2018). Thus,"
2020.ccl-1.86,P16-1101,0,0.0346172,") and SVMs (Isozaki and Kazawa, 2002). These methods rely heavily on feature engineering. However, the designed features may be not appropriate for the task, which can lead to error propagation problem. Currently, neural network methods have been introduced into NER task and achieved state-of-the-art performance (Lample et al., 2016). Huang et al. (2015) use the bidirectional long short term memory (BiLSTM) for feature extraction and the CRF for decoding. The model is trained via the end-to-end paradigm. After that, the BiLSTM+CRF model is usually exploited as the baseline model for NER task. Ma and Hovy (2016) use a character convolutional neural network (CNN) to represent spelling characteristic. Then the charcter representation vector is concatenated with word embedding as the input of the LSTM. Peters et al. (2017) leverage a character language model to enhance the input of the model. For Chinese NER, character-based methods have been the dominant approaches (Lu et al., 2016; Dong et al., 2016). These methods only focus on character sequence information, ignoring word boundaries information, which can cause errors of predicting entity boundaries. Thus, how to better exploit lexical knowledge has"
2020.ccl-1.86,D15-1064,0,0.165739,"sentation vector is concatenated with word embedding as the input of the LSTM. Peters et al. (2017) leverage a character language model to enhance the input of the model. For Chinese NER, character-based methods have been the dominant approaches (Lu et al., 2016; Dong et al., 2016). These methods only focus on character sequence information, ignoring word boundaries information, which can cause errors of predicting entity boundaries. Thus, how to better exploit lexical knowledge has received much research attention. Word segmentation information is used as extra features for Chinese NER task (Peng and Dredze, 2015; He and Sun, 2016). Peng and Dredze (2016) and Cao et al. (2018) propose a joint model for Chinese NER, which is jointly trained with CWS task. Zhang and Yang (2018) investigate a lattice LSTM to encode a sequence of input characters as well as words that match a lexicon. However, the lattice model cannot exploit all matched words and only processes the matched words once. Recently, graph-based models have been proposed for Chinese NER (Gui et al., 2019; Sui et al., 2019). Based on the lattice structure, Sui et al. (2019) propose a graph neural network to encode word information. Tag dependen"
2020.ccl-1.86,P16-2025,0,0.0178452,"embedding as the input of the LSTM. Peters et al. (2017) leverage a character language model to enhance the input of the model. For Chinese NER, character-based methods have been the dominant approaches (Lu et al., 2016; Dong et al., 2016). These methods only focus on character sequence information, ignoring word boundaries information, which can cause errors of predicting entity boundaries. Thus, how to better exploit lexical knowledge has received much research attention. Word segmentation information is used as extra features for Chinese NER task (Peng and Dredze, 2015; He and Sun, 2016). Peng and Dredze (2016) and Cao et al. (2018) propose a joint model for Chinese NER, which is jointly trained with CWS task. Zhang and Yang (2018) investigate a lattice LSTM to encode a sequence of input characters as well as words that match a lexicon. However, the lattice model cannot exploit all matched words and only processes the matched words once. Recently, graph-based models have been proposed for Chinese NER (Gui et al., 2019; Sui et al., 2019). Based on the lattice structure, Sui et al. (2019) propose a graph neural network to encode word information. Tag dependencies is also a challenging problem, but few"
2020.ccl-1.86,D19-1396,1,0.790402,"ge has received much research attention. Word segmentation information is used as extra features for Chinese NER task (Peng and Dredze, 2015; He and Sun, 2016). Peng and Dredze (2016) and Cao et al. (2018) propose a joint model for Chinese NER, which is jointly trained with CWS task. Zhang and Yang (2018) investigate a lattice LSTM to encode a sequence of input characters as well as words that match a lexicon. However, the lattice model cannot exploit all matched words and only processes the matched words once. Recently, graph-based models have been proposed for Chinese NER (Gui et al., 2019; Sui et al., 2019). Based on the lattice structure, Sui et al. (2019) propose a graph neural network to encode word information. Tag dependencies is also a challenging problem, but few attention has been paid to tackling the problem. Zhang et al. (2018) leverages LSTM as decoder for sequence labeling task. However, the unidirectional LSTM decoder only exploits the past predicted tags information, ignoring the future un-predicted tags. Hence, we propose a hierarchical tagging mechanism to capture bidirectional tag dependencies in the whole sentence. To our best knowledge, we are the first to introduce the hierar"
2020.ccl-1.86,N16-1174,0,0.0318534,"ed tagging vector. 20 Tagging Attention Module: T-Attention Tagging attention aims to dynamically leverage the hidden ˆ 1, h ˆ 2, . . . , h ˆ n } and Traw = {Tb1 , Tb2 , . . . , Tbn } b = {h states and preliminary predictions of the TLSTM. H denote the hidden states and preliminary predictions of the TLSTM, respectively. The attention is expressed as follows: ˆ di = [h ˆ i : Tbi ] h ˆ di + bda ) mi = uT tanh(Wda h d exp(mi ) αi = Pn j=1 exp(mj ) Xn ˆ dj ) ri = tanh( αj h (10) CC L j=1 Rdda where ud ∈ is the context vector, which is randomly initialized and learned during the training process (Yang et al., 2016b). ri denotes the representation of the hidden states and preliminary predictions of the TLSTM. The Second Tagging Module: CRF H = {h1 , h2 , . . . , hn } and R = {r1 , r2 , . . . , rn } denote the outputs of BiLSTM encoding layer and tagging attention module, respectively, which are concatenated as the input of the CRF module, denoted as Hc = {hc1 , hc2 , . . . , hcn }. Given a sentence s = {x1 , x2 , . . . , xn } with a final predicted tag sequence y = {y1 , y2 , . . . , yn }, the CRF tagging process is formalized as follows: oi = Wo hci + bo Xn s(s, y) = (oi,yi + Tyi−1 ,yi ) i=1 (11) y ∗ ="
2020.ccl-1.86,P18-1144,0,0.19628,"” in Figure 1. To reduce the errors of predicting entity boundaries, some works (Peng and Dredze, 2016; Cao et al., 2018) try to jointly perform Chinese NER with Chinese word segmentation (CWS) for using word boundaries information. However, the joint model requires additional annotated training data for CWS task. Fortunately, existing lexicons can provide information on word boundaries and we refer to the information as lexical knowledge. In addition, the cost of obtaining lexicon is low and almost all fields have their lexicons, such as biomedical, social science fields and so on. Recently, Zhang and Yang (2018) propose a lattice LSTM model capable of leveraging lexicon for Chinese NER. Though effective, the lattice LSTM Proceedings of the 19th China National Conference on Computational Linguistics, pages 927-938, Hainan, China, October 30 - Novermber 1, 2020. (c) Technical Committee on Computational Linguistics, Chinese Information Processing Society of China Computational Linguistics English Translation: Chinese Sentence: Matched Words: Gold Label: Hokkaido has a variable climate 北 海 道 气 候 多 北海 北海道 海道 气候 多变 North Sea Hokkaido Seaway Climate Change B-LOC I-LOC I-LOC BiLSTM+CRF: B-LOC I-LOC O 变 O O O"
2020.ccl-1.86,W06-0126,0,0.0696592,"Missing"
2020.ccl-1.86,W06-0140,0,0.102478,"Missing"
2020.coling-main.135,2020.acl-main.499,0,0.0216175,"tation ei and ej encoded by BERT. Then, we take the stitching of manual designed feature vector (same lexical, causal potential, and syntactic features representation as Gao et al. (Gao et al., 2019)) f , ei and ej as the input of top MLP classifier. Finally, the output is a binary vector to indicate the causality of the input event pair eij . We employ relabeling and annealing strategies to make better use of distantly labeled data for training. (1) Relabeling: We pre-train a detector on annotated data and employ it to relabel the refined distantly labeled training data Dr via self-training (Asai and Hajishirzi, 2020). Then, we collect the sentences that are relabeled as causal sentences to obtain the distantly relabeled training data Drr which are more casual and informative for the training of ECD task. (2) Annealing: Distantly labeled training data may not be appropriate at the beginning of training for building an effective detector due to noises. Therefore, we employ the annealing training strategy (Kirkpatrick et al., 1983) to maximize the effectiveness of distantly labeled training data. In the beginning, we only employ annotated data for training, and with the increase of epochs, we added Drr for t"
2020.coling-main.135,P98-1013,0,0.388273,"Missing"
2020.coling-main.135,W17-2711,0,0.297622,"hortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label training data for some tasks, such as relation extraction (Mintz et al., 2009), event detection (Chen et al., 2017), and so on. Therefore, we investigate a distant data augmentation framework for solving the data lacking problem on the ECD task, dubbed as Knowledge Enhanced Distant Data Augmentation (KnowDis), to au"
2020.coling-main.135,P17-1038,1,0.831098,"hieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label training data for some tasks, such as relation extraction (Mintz et al., 2009), event detection (Chen et al., 2017), and so on. Therefore, we investigate a distant data augmentation framework for solving the data lacking problem on the ECD task, dubbed as Knowledge Enhanced Distant Data Augmentation (KnowDis), to automatically label available data. We argue that a sentence contains an event pair with a high probability of causality and expresses its causal semantic can be labeled as training data for the ECD task. To automatically label a large number of training data, we need to solve the following three challenges. (1) How to collect a large number of event pairs with a high probability of causality and"
2020.coling-main.135,P17-2001,0,0.232749,"Missing"
2020.coling-main.135,D17-1190,0,0.14897,"Missing"
2020.coling-main.135,P89-1010,0,0.359682,"Missing"
2020.coling-main.135,N19-1423,0,0.0707252,"Missing"
2020.coling-main.135,N19-1179,0,0.674643,"ju, 2003; Oh et al., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label training data for some tasks, such as relation"
2020.coling-main.135,W03-1210,0,0.525738,"s). Experimental results on two benchmark datasets EventStoryLine corpus and CausalTimeBank show that 1) KnowDis can augment available training data assisted with the lexical and causal commonsense knowledge for ECD via distant supervision, and 2) our method outperforms previous methods by a large margin assisted with automatically labeled training data. 1 Introduction Event causality detection (ECD) aims to identify causal relations between events from texts, which may provide crucial clues for many NLP tasks, such as information extraction, logical reasoning, question answering, and others (Girju, 2003; Oh et al., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et a"
2020.coling-main.135,P14-1093,0,0.43486,"easoning, question answering, and others (Girju, 2003; Oh et al., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label trainin"
2020.coling-main.135,W17-5540,0,0.109412,"ring, and others (Girju, 2003; Oh et al., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label training data for some tasks"
2020.coling-main.135,P09-1113,0,0.127371,"2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label training data for some tasks, such as relation extraction (Mintz et al., 2009), event detection (Chen et al., 2017), and so on. Therefore, we investigate a distant data augmentation framework for solving the data lacking problem on the ECD task, dubbed as Knowledge Enhanced Distant Data Augmentation (KnowDis), to automatically label available data. We argue that a sentence contains an event pair with a high probability of causality and expresses its causal semantic can be labeled as training data for the ECD task. To automatically label a large number of training data, we need to solve the following three challenges. (1) How to collect a large number of event pairs with"
2020.coling-main.135,C14-1198,0,0.332249,"training data. In the beginning, we only employ annotated data for training, and with the increase of epochs, we added Drr for training incrementally in a proportion of β. 3 Experiments Datasets. (1) ESC: We use the same way to partition dataset as the SOTA method on ESC (Gao et al., 2019). Same as it, we use the last two topics as a development set. (2) Causal-TB: This dataset only contains 318 causal links which can further prove effectiveness of the proposed framework for solving the problem of data lacking. We use the same development set as ESC because of the SOTA method on this dataset (Mirza and Tonelli, 2014) does not partition the development set. Specifically, we conduct 5-fold cross-validation on the two datasets3 . We tune the augmented proportion, α, and β on the development set. All the results are the average of three independent experiments. 3 For each fold, we add extra distantly labeled data based on the annotated event pairs corresponding to this fold for training. 1546 Parameters Setting. We apply the base-uncase-bert as the pre-trained BERT model. We set the learning rate of detector as 1e-5. Specifically, the dimension of the causal semantic space is 100. We set the α and β as 0.5 an"
2020.coling-main.135,C16-1007,0,0.0730174,"asks, such as information extraction, logical reasoning, question answering, and others (Girju, 2003; Oh et al., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision hav"
2020.coling-main.135,P13-1170,0,0.356303,"Missing"
2020.coling-main.135,W14-0707,0,0.474301,"extraction, logical reasoning, question answering, and others (Girju, 2003; Oh et al., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be ef"
2020.coling-main.135,D19-1670,0,0.063133,"Missing"
2020.coling-main.135,2020.ccl-1.84,1,0.747803,"., 2013; Oh et al., 2017). For example, the causal relation that Kimani Gray was killed because of a police attack is needed to be detected in the following sentence: ”Kimani Gray, a young man who likes football, was killed in a police attack shortly after a tight match.” This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. To this end, most existing methods adopt a supervised learning paradigm (Mirza and Tonelli, 2016; Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019; Zuo et al., 2020). Although these methods have achieved good performance, they usually need large-scale annotated training data. However, existing event causality detection datasets are relatively small. For example, the EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. These small datasets are in low coverage of causal expressions and obstacle NLP applications deployed on large-scale data. Recent improvements of distant supervision have been proven to be effective to label training data for some tasks, such as relation extraction (Mintz"
2020.emnlp-main.128,W06-0901,0,0.357252,"emplates to generate questions, our method can generate questions that are both topic-relevant and context-dependent, which can better instruct an MRC model for question-answering. • We report on state-of-the-art performance on the benchmark EE dataset. Our method also demonstrate promising results in addressing data-low and zero-shot scenarios. 2 Related Work Event Extraction. EE is a crucial IE task that aims to extract event information in texts, which has attracted extensive attention among researchers. Traditional EE methods employ manual-designed features, such as the syntactic feature (Ahn, 2006), document-level feature (Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Rec"
2020.emnlp-main.128,W14-3001,0,0.0410834,"Missing"
2020.emnlp-main.128,D14-1159,0,0.0822613,"Missing"
2020.emnlp-main.128,P16-1223,0,0.08691,"Missing"
2020.emnlp-main.128,N19-1423,0,0.0466044,"extraction of role-filler of Instrument is semantically equivalent to the following questionanswering process (as shown in Figure 1 (b)): Q1: What Instrument did the protester use According to the ACE event ontology. 1641 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 1641–1651, c November 16–20, 2020. 2020 Association for Computational Linguistics to stab the officer? A1: a paper cutter. 2 This implies new ways to tackle EE, which come with two major advantages: First, by framing EE as MRC, we can leverage the recent advances in MRC (e.g., BERT (Devlin et al., 2019)) to boost EE task, which may greatly strengthen the reasoning process in the model. Second, we may directly leverage the abundant MRC datasets to boost EE, which may relieve the data scarcity problem (This is referred to as cross-domain data augmentation). The second advantage also opens a door for zero-shot EE: for unseen event types, we can list questions defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme"
2020.emnlp-main.128,2020.emnlp-main.49,0,0.114784,"guyen, 2019; Zhang et al., 2019). Despite many advances, as mentioned in Introduction, most previous approaches formulate EE as a classification problem, which usually suffer from the data scarcity problem, and they generally cannot deal with new event types never seen at the training time. MRC for Other Tasks. Our work also relates to works connecting MRC and other tasks, such as relation extraction (Levy et al., 2017; Li et al., 2019b), semantic role labeling (FitzGerald et al., 2018), named entity recognition (Li et al., 2019a), and others (Wu et al., 2019; Gao et al., 2019). Particularly, Du and Cardie (2020) adopt a similar idea to frames EE as MRC. But different from our work, most of the above methods (Levy et al., 2017; Li et al., 2019b; FitzGerald et al., 2018; Du and Cardie, 2020) adopt human-designed, context-independent questions, which may not provide enough contextual evidence for question-answering. Some works indeed do not adopt question-style queries (Li et al., 2019a; Gao et al., 2019). For example, Li et al. (2019a) use “Find organizations in the text” as a query command to find ORGANIZATION entity. The discrepancy between such non-natural “queries” and natural questions in MRC data"
2020.emnlp-main.128,D17-1090,0,0.029054,"directly leverage the abundant MRC datasets to boost EE, which may relieve the data scarcity problem (This is referred to as cross-domain data augmentation). The second advantage also opens a door for zero-shot EE: for unseen event types, we can list questions defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme (e.g., generating Q1 for Instrument). Note we cannot adopt supervised question generation methods (Duan et al., 2017; Yuan et al., 2017; Elsahar et al., 2018), owing to the lack of aligned question-event pairs. Previous works connecting MRC and other tasks usually adopt humandesigned templates (Levy et al., 2017; FitzGerald et al., 2018; Li et al., 2019b,a; Gao et al., 2019; Wu et al., 2019). For example, in QA-SRL (FitzGerald et al., 2018), the question for a predicate publish is always “Who published something?”, regardless of the contexts. Such questions may not expressive enough to instruct an MRC model to find answers. We overcome the above challenge by proposing an unsupervised question generation pro"
2020.emnlp-main.128,N18-1020,0,0.0245017,"tasets to boost EE, which may relieve the data scarcity problem (This is referred to as cross-domain data augmentation). The second advantage also opens a door for zero-shot EE: for unseen event types, we can list questions defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme (e.g., generating Q1 for Instrument). Note we cannot adopt supervised question generation methods (Duan et al., 2017; Yuan et al., 2017; Elsahar et al., 2018), owing to the lack of aligned question-event pairs. Previous works connecting MRC and other tasks usually adopt humandesigned templates (Levy et al., 2017; FitzGerald et al., 2018; Li et al., 2019b,a; Gao et al., 2019; Wu et al., 2019). For example, in QA-SRL (FitzGerald et al., 2018), the question for a predicate publish is always “Who published something?”, regardless of the contexts. Such questions may not expressive enough to instruct an MRC model to find answers. We overcome the above challenge by proposing an unsupervised question generation process, which can generate questions that ar"
2020.emnlp-main.128,P18-1191,0,0.212484,"for unseen event types, we can list questions defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme (e.g., generating Q1 for Instrument). Note we cannot adopt supervised question generation methods (Duan et al., 2017; Yuan et al., 2017; Elsahar et al., 2018), owing to the lack of aligned question-event pairs. Previous works connecting MRC and other tasks usually adopt humandesigned templates (Levy et al., 2017; FitzGerald et al., 2018; Li et al., 2019b,a; Gao et al., 2019; Wu et al., 2019). For example, in QA-SRL (FitzGerald et al., 2018), the question for a predicate publish is always “Who published something?”, regardless of the contexts. Such questions may not expressive enough to instruct an MRC model to find answers. We overcome the above challenge by proposing an unsupervised question generation process, which can generate questions that are both relevant and context-dependent. Specifically, in our approach, we assume that each question can be decomposed as two parts, reflecting query topic and context-related inform"
2020.emnlp-main.128,W19-5932,0,0.14612,"defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme (e.g., generating Q1 for Instrument). Note we cannot adopt supervised question generation methods (Duan et al., 2017; Yuan et al., 2017; Elsahar et al., 2018), owing to the lack of aligned question-event pairs. Previous works connecting MRC and other tasks usually adopt humandesigned templates (Levy et al., 2017; FitzGerald et al., 2018; Li et al., 2019b,a; Gao et al., 2019; Wu et al., 2019). For example, in QA-SRL (FitzGerald et al., 2018), the question for a predicate publish is always “Who published something?”, regardless of the contexts. Such questions may not expressive enough to instruct an MRC model to find answers. We overcome the above challenge by proposing an unsupervised question generation process, which can generate questions that are both relevant and context-dependent. Specifically, in our approach, we assume that each question can be decomposed as two parts, reflecting query topic and context-related information respectively. For example, Q1 ca"
2020.emnlp-main.128,P17-1038,1,0.900128,"sets without using any EE training data. 1 Figure 1: Comparison of the event extraction task and machine reading comprehension task. base augmentation (Ji and Grishman, 2011), document summarization, question answering (Berant et al., 2014), and others. In the current study, EE is mostly formulated as a classification problem, aiming to locate and categorize each event trigger/argument (Ahn, 2006; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016). Despite many advances, classification based methods are data-hungry, which require a great deal of training data to ensure good performance (Chen et al., 2017; Li et al., 2013; Liu et al., 2018a). Moreover, such methods generally cannot deal with new event types never encountered during training time (Huang et al., 2018). Introduction Event extraction (EE), a crucial information extraction (IE) task, aims to extract event information in texts. For example, in a sentence S1 (shown in Figure 1 (a)), an EE system should recognize an Attack event1 , expressed by an event trigger stabbed with four event arguments — Sunday (Role=Time), a protester (Role=Attacker), an officer (Role=Target), and a paper cutter (Role=Instrument). EE is shown to benefit a wi"
2020.emnlp-main.128,P11-1113,0,0.191705,"pic-relevant and context-dependent, which can better instruct an MRC model for question-answering. • We report on state-of-the-art performance on the benchmark EE dataset. Our method also demonstrate promising results in addressing data-low and zero-shot scenarios. 2 Related Work Event Extraction. EE is a crucial IE task that aims to extract event information in texts, which has attracted extensive attention among researchers. Traditional EE methods employ manual-designed features, such as the syntactic feature (Ahn, 2006), document-level feature (Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Recurrent Neural Networks (Nguyen et al., 2016; Sha et al., 2018), Graph Convolutional Neural"
2020.emnlp-main.128,P15-1017,1,0.961366,"tic feature (Ahn, 2006), document-level feature (Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Recurrent Neural Networks (Nguyen et al., 2016; Sha et al., 2018), Graph Convolutional Neural Networks (Liu et al., 2018b, 2019b), and other advanced architectures (Yang and Mitchell, 2016; Liu et al., 2018a, 2019a; Nguyen and Nguyen, 2019; Zhang et al., 2019). Despite many advances, as mentioned in Introduction, most previous approaches formulate EE as a classification problem, which usually suffer from the data scarcity problem, and they generally cannot deal with new event types never seen at the training time. MRC for Other Tasks. Our work also relates to works connecting MRC and other t"
2020.emnlp-main.128,P08-1030,0,0.199329,"method can generate questions that are both topic-relevant and context-dependent, which can better instruct an MRC model for question-answering. • We report on state-of-the-art performance on the benchmark EE dataset. Our method also demonstrate promising results in addressing data-low and zero-shot scenarios. 2 Related Work Event Extraction. EE is a crucial IE task that aims to extract event information in texts, which has attracted extensive attention among researchers. Traditional EE methods employ manual-designed features, such as the syntactic feature (Ahn, 2006), document-level feature (Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Recurrent Neural Networks (Nguyen et al., 2016; Sha"
2020.emnlp-main.128,P11-1115,0,0.118647,"Missing"
2020.emnlp-main.128,J82-2005,0,0.680084,"Missing"
2020.emnlp-main.128,K17-1034,0,0.267082,"for zero-shot EE: for unseen event types, we can list questions defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme (e.g., generating Q1 for Instrument). Note we cannot adopt supervised question generation methods (Duan et al., 2017; Yuan et al., 2017; Elsahar et al., 2018), owing to the lack of aligned question-event pairs. Previous works connecting MRC and other tasks usually adopt humandesigned templates (Levy et al., 2017; FitzGerald et al., 2018; Li et al., 2019b,a; Gao et al., 2019; Wu et al., 2019). For example, in QA-SRL (FitzGerald et al., 2018), the question for a predicate publish is always “Who published something?”, regardless of the contexts. Such questions may not expressive enough to instruct an MRC model to find answers. We overcome the above challenge by proposing an unsupervised question generation process, which can generate questions that are both relevant and context-dependent. Specifically, in our approach, we assume that each question can be decomposed as two parts, reflecting query topic a"
2020.emnlp-main.128,P13-1008,0,0.422567,"MRC model for question-answering. • We report on state-of-the-art performance on the benchmark EE dataset. Our method also demonstrate promising results in addressing data-low and zero-shot scenarios. 2 Related Work Event Extraction. EE is a crucial IE task that aims to extract event information in texts, which has attracted extensive attention among researchers. Traditional EE methods employ manual-designed features, such as the syntactic feature (Ahn, 2006), document-level feature (Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Recurrent Neural Networks (Nguyen et al., 2016; Sha et al., 2018), Graph Convolutional Neural Networks (Liu et al., 2018b, 2019b), and other advanced archi"
2020.emnlp-main.128,P19-1129,0,0.0518452,"Missing"
2020.emnlp-main.128,P10-1081,0,0.356045,"ch can better instruct an MRC model for question-answering. • We report on state-of-the-art performance on the benchmark EE dataset. Our method also demonstrate promising results in addressing data-low and zero-shot scenarios. 2 Related Work Event Extraction. EE is a crucial IE task that aims to extract event information in texts, which has attracted extensive attention among researchers. Traditional EE methods employ manual-designed features, such as the syntactic feature (Ahn, 2006), document-level feature (Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Recurrent Neural Networks (Nguyen et al., 2016; Sha et al., 2018), Graph Convolutional Neural Networks (Liu et al., 2018b, 2019b), and ot"
2020.emnlp-main.128,D19-1068,1,0.906963,"Missing"
2020.emnlp-main.128,D18-1156,0,0.306091,"Missing"
2020.emnlp-main.128,N16-1034,0,0.790654,"(Ji and Grishman, 2008), entity-level feature (Hong et al., 2011) and other features (Liao and Grishman, 2010; Li et al., 2013) 1642 Figure 2: The overview of the proposed model RCEE. Given S1, RCEE first uses a special query [EVENT] to locate event trigger and predict the type. Then RCEE generates questions for each semantic role related to the predicted event type. Finally, RCEE answers each question and synthesizes all of the answers as the EE result. for the task. Modern EE methods employ neural models, such as Convolutional Neural Networks (Chen et al., 2015), Recurrent Neural Networks (Nguyen et al., 2016; Sha et al., 2018), Graph Convolutional Neural Networks (Liu et al., 2018b, 2019b), and other advanced architectures (Yang and Mitchell, 2016; Liu et al., 2018a, 2019a; Nguyen and Nguyen, 2019; Zhang et al., 2019). Despite many advances, as mentioned in Introduction, most previous approaches formulate EE as a classification problem, which usually suffer from the data scarcity problem, and they generally cannot deal with new event types never seen at the training time. MRC for Other Tasks. Our work also relates to works connecting MRC and other tasks, such as relation extraction (Levy et al.,"
2020.emnlp-main.128,P18-1080,0,0.0395064,"and context-dependent. Specifically, in our approach, we assume that each question can be decomposed as two parts, reflecting query topic and context-related information respectively. For example, Q1 can be decomposed as “What instrument” and “did the protester use to stab the officer?”. To generate the query topic expression, we design a template-based generation method, combining role categorization and interrogative words realization. To generate the more challenging contextdependent expression, we formulate it as an unsupervised translation task (Lample et al., 2018b) (or style transfer (Prabhumoye et al., 2018)), which transforms a descriptive statement into a questionstyle expression, based on in-domain de-noising auto-encoding (Vincent et al., 2008) and crossdomain back-translation (Sennrich et al., 2016). 2 Figure 1 (b) gives another example. Note the training process only needs large volume of descriptive statements and unaligned questionstyle statements. Finally, after the questions are generated, we build a BERT based MRC model (Devlin et al., 2019) to answer each of question and synthesize all of the answers as the result of EE. To evaluate our approach, we have conducted extensive experiment"
2020.emnlp-main.128,P18-2124,0,0.0754648,"Missing"
2020.emnlp-main.128,P16-1009,0,0.265758,"an be decomposed as “What instrument” and “did the protester use to stab the officer?”. To generate the query topic expression, we design a template-based generation method, combining role categorization and interrogative words realization. To generate the more challenging contextdependent expression, we formulate it as an unsupervised translation task (Lample et al., 2018b) (or style transfer (Prabhumoye et al., 2018)), which transforms a descriptive statement into a questionstyle expression, based on in-domain de-noising auto-encoding (Vincent et al., 2008) and crossdomain back-translation (Sennrich et al., 2016). 2 Figure 1 (b) gives another example. Note the training process only needs large volume of descriptive statements and unaligned questionstyle statements. Finally, after the questions are generated, we build a BERT based MRC model (Devlin et al., 2019) to answer each of question and synthesize all of the answers as the result of EE. To evaluate our approach, we have conducted extensive experiments on the benchmark EE datasets, and the experimental results have justified the effectiveness of our approach. Specifically, 1) in the standard evolution, our method attains state-ofthe-art performanc"
2020.emnlp-main.128,W17-2603,0,0.0232458,"the abundant MRC datasets to boost EE, which may relieve the data scarcity problem (This is referred to as cross-domain data augmentation). The second advantage also opens a door for zero-shot EE: for unseen event types, we can list questions defining their schema and use an MRC model to retrieve answers as EE results, instead of obtaining training data for them in advance. To bridge MRC and EE, the key challenge lies in generating relevant questions describing an event scheme (e.g., generating Q1 for Instrument). Note we cannot adopt supervised question generation methods (Duan et al., 2017; Yuan et al., 2017; Elsahar et al., 2018), owing to the lack of aligned question-event pairs. Previous works connecting MRC and other tasks usually adopt humandesigned templates (Levy et al., 2017; FitzGerald et al., 2018; Li et al., 2019b,a; Gao et al., 2019; Wu et al., 2019). For example, in QA-SRL (FitzGerald et al., 2018), the question for a predicate publish is always “Who published something?”, regardless of the contexts. Such questions may not expressive enough to instruct an MRC model to find answers. We overcome the above challenge by proposing an unsupervised question generation process, which can gen"
2020.emnlp-main.165,W19-1909,0,0.046282,"Missing"
2020.emnlp-main.165,P19-1279,0,0.22243,"d predictions of ensemble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method. 1 Introduction Privacy - like eating and breathing - is one of life’s basic requirements. — Katherine Neville Relation extraction is a task of mining factual knowledge from the free text by labeling relations between entity mentions and has attracted increasing attention in recent years, such as Zeng et al. (2014); Xu et al. (2015a,b); Wang et al. (2016); Baldini Soares et al. (2019); Song et al. (2019). Applying automatic relation extraction to medical texts, such as electronic health records and discharge summaries, can be useful for many applications, including drug repurposing and medical knowledge graph construction. Unlike other domains, medical texts are highly privacy-sensitive, because these texts can include some of the most intimate details about one’s life, which document a patient’s physical and mental health, and can include information on social behaviors, personal relationships and financial status (Gostin and Hodge, 2002). To prevent private information l"
2020.emnlp-main.165,W19-5004,0,0.211871,"recent deep transformers (Vaswani et al., 2017) trained on variants of language modeling, we utilize the BERT model (Devlin et al., 2019) as the backbone encoder. In this section, we explore a simple way of representing relations with the deep transformers model. The model architecture is shown in Figure 1 and the details are as follows: Firstly, we construct the input sequence s = {w0 , w1 , ..., wn }, where w0 = [CLS] and wn = [SEP] are special start and end markers. Next, to ensure generalization of the model, we follow previous studies (He et al., 2013; Kim et al., 2015; Liu et al., 2016; Chauhan et al., 2019) to perform entity blinding on the sequence, where the words in the sequence matching the entity are replaced with the target entity label. Then, in order to highlight entity mentions, we augment the sequence with four reserved word pieces, i.e., he1i,h/e1i,he2i and h/e2i, to mark the begin and end of each entity mention. After that, we get the prepared sequence sˆ. sˆ ={[CLS], w1 , ..., wi−2 , he1i, wi , ..., wj , h/e1i, ..., he2i, wk , ..., wl , h/e2i, ..., wm−2 , [SEP]} Given the prepared sequence sˆ as input, the output of BERT is expressed as H ∈ Rm×d , where m is the prepared sequence le"
2020.emnlp-main.165,N19-1423,0,0.423909,"acy protection compared to centralized training, federated learning algorithms, such as FedAvg (McMahan et al., 2016), require frequent communication between local platforms and the central server to upload and download models’ parameters. Communication is a critical bottleneck of applying federated learning to relation extraction, which is largely due to the following reasons: First, the state-of-the-art relation extraction models (Baldini Soares et al., 2019; Li et al., 2019b; Thillaisundaram and Togia, 2019) usually utilize transformer-based pretrained language models (Raffel et al., 2019; Devlin et al., 2019; Liu et al., 2118 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2118–2128, c November 16–20, 2020. 2020 Association for Computational Linguistics 2019; Yang et al., 2019b) as backbone encoders, which have millions or even billions of parameters. Second, the framework of federated learning includes a massive number of local platforms (Li et al., 2019a), and communication between each platform and the central server is necessary. Third, upload bandwidth is typically limited to 1 MB/s or less in most situations 1 . Considering the cumbersome model,"
2020.emnlp-main.165,P84-1044,0,0.22601,"Missing"
2020.emnlp-main.165,P19-1129,0,0.0509814,"Missing"
2020.emnlp-main.165,2021.ccl-1.108,0,0.0851294,"Missing"
2020.emnlp-main.165,W15-1506,0,0.0145221,"l models’ parameters. • The method yields promising results on three different medical relation extraction datasets, and we perform various experiments to verify the effectiveness of the proposed method. 2 Related Work Our work builds on a rich line of recent efforts on relation extraction models and federated learning. 2.1 Relation Extraction Relation extraction is a long-standing NLP task of mining factual knowledge from free texts by labeling relations between entity mentions. There are a number of recent neural network approaches applied to relation extraction, such as Zeng et al. (2014); Nguyen and Grishman (2015); dos Santos et al. (2015); Zhang and Wang (2015); Zhang et al. (2017). Recently, the NLP community has seen excitement around neural models that make heavy use of pretraining based on language modeling (Radford et al.; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019b). Baldini Soares et al. (2019); Shi and Lin (2019) and Alt et al. (2019) achieved the state-of-the-art performance in relation extraction by fine-tuning the pretrained language models. In this paper, we also adopt a pretrained language model as the backbone encoder. Applying relation extraction models to the medical fiel"
2020.emnlp-main.165,Q17-1008,0,0.0159347,"i Soares et al. (2019); Shi and Lin (2019) and Alt et al. (2019) achieved the state-of-the-art performance in relation extraction by fine-tuning the pretrained language models. In this paper, we also adopt a pretrained language model as the backbone encoder. Applying relation extraction models to the medical field has great practical value, and there is a rich literature on medical relation extraction. Some studies focused on clinical relation extraction (Sahu et al., 2016; Munkhdalai et al., 2018; Ningthoujam et al., 2019) and some studies concentrated on 2119 biomedical relation extraction (Peng et al., 2017; Song et al., 2018, 2019). Compared with previous studies, we develop a federated relation extraction system to protect patients’ privacy in medical relation extraction. 2.2 Federated Learning Recently, McMahan et al. (2016), Koneˇcn`y et al. (2016a) and Koneˇcn`y et al. (2016b) proposed the concept of federated learning. The main idea of federated learning is to build machine learning models based on data sets that are distributed across multiple local platforms while preventing data leakage. Federated learning can be divided into three categories, i.e., horizontal federated learning, vertic"
2020.emnlp-main.165,W19-4302,0,0.0564325,"Missing"
2020.emnlp-main.165,K17-1032,0,0.0293043,"Missing"
2020.emnlp-main.165,W16-2928,0,0.365407,"make heavy use of pretraining based on language modeling (Radford et al.; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019b). Baldini Soares et al. (2019); Shi and Lin (2019) and Alt et al. (2019) achieved the state-of-the-art performance in relation extraction by fine-tuning the pretrained language models. In this paper, we also adopt a pretrained language model as the backbone encoder. Applying relation extraction models to the medical field has great practical value, and there is a rich literature on medical relation extraction. Some studies focused on clinical relation extraction (Sahu et al., 2016; Munkhdalai et al., 2018; Ningthoujam et al., 2019) and some studies concentrated on 2119 biomedical relation extraction (Peng et al., 2017; Song et al., 2018, 2019). Compared with previous studies, we develop a federated relation extraction system to protect patients’ privacy in medical relation extraction. 2.2 Federated Learning Recently, McMahan et al. (2016), Koneˇcn`y et al. (2016a) and Koneˇcn`y et al. (2016b) proposed the concept of federated learning. The main idea of federated learning is to build machine learning models based on data sets that are distributed across multiple local p"
2020.emnlp-main.165,P15-1061,0,0.0165852,"od yields promising results on three different medical relation extraction datasets, and we perform various experiments to verify the effectiveness of the proposed method. 2 Related Work Our work builds on a rich line of recent efforts on relation extraction models and federated learning. 2.1 Relation Extraction Relation extraction is a long-standing NLP task of mining factual knowledge from free texts by labeling relations between entity mentions. There are a number of recent neural network approaches applied to relation extraction, such as Zeng et al. (2014); Nguyen and Grishman (2015); dos Santos et al. (2015); Zhang and Wang (2015); Zhang et al. (2017). Recently, the NLP community has seen excitement around neural models that make heavy use of pretraining based on language modeling (Radford et al.; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019b). Baldini Soares et al. (2019); Shi and Lin (2019) and Alt et al. (2019) achieved the state-of-the-art performance in relation extraction by fine-tuning the pretrained language models. In this paper, we also adopt a pretrained language model as the backbone encoder. Applying relation extraction models to the medical field has great practical valu"
2020.emnlp-main.165,D19-1020,0,0.0157022,"ble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method. 1 Introduction Privacy - like eating and breathing - is one of life’s basic requirements. — Katherine Neville Relation extraction is a task of mining factual knowledge from the free text by labeling relations between entity mentions and has attracted increasing attention in recent years, such as Zeng et al. (2014); Xu et al. (2015a,b); Wang et al. (2016); Baldini Soares et al. (2019); Song et al. (2019). Applying automatic relation extraction to medical texts, such as electronic health records and discharge summaries, can be useful for many applications, including drug repurposing and medical knowledge graph construction. Unlike other domains, medical texts are highly privacy-sensitive, because these texts can include some of the most intimate details about one’s life, which document a patient’s physical and mental health, and can include information on social behaviors, personal relationships and financial status (Gostin and Hodge, 2002). To prevent private information leakage, sharing or c"
2020.emnlp-main.165,D18-1246,0,0.015314,"19); Shi and Lin (2019) and Alt et al. (2019) achieved the state-of-the-art performance in relation extraction by fine-tuning the pretrained language models. In this paper, we also adopt a pretrained language model as the backbone encoder. Applying relation extraction models to the medical field has great practical value, and there is a rich literature on medical relation extraction. Some studies focused on clinical relation extraction (Sahu et al., 2016; Munkhdalai et al., 2018; Ningthoujam et al., 2019) and some studies concentrated on 2119 biomedical relation extraction (Peng et al., 2017; Song et al., 2018, 2019). Compared with previous studies, we develop a federated relation extraction system to protect patients’ privacy in medical relation extraction. 2.2 Federated Learning Recently, McMahan et al. (2016), Koneˇcn`y et al. (2016a) and Koneˇcn`y et al. (2016b) proposed the concept of federated learning. The main idea of federated learning is to build machine learning models based on data sets that are distributed across multiple local platforms while preventing data leakage. Federated learning can be divided into three categories, i.e., horizontal federated learning, vertical federated learni"
2020.emnlp-main.165,D19-5713,0,0.0185413,"ers are sent to the server for updating the central model. Though federated learning has distinct advantages in privacy protection compared to centralized training, federated learning algorithms, such as FedAvg (McMahan et al., 2016), require frequent communication between local platforms and the central server to upload and download models’ parameters. Communication is a critical bottleneck of applying federated learning to relation extraction, which is largely due to the following reasons: First, the state-of-the-art relation extraction models (Baldini Soares et al., 2019; Li et al., 2019b; Thillaisundaram and Togia, 2019) usually utilize transformer-based pretrained language models (Raffel et al., 2019; Devlin et al., 2019; Liu et al., 2118 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2118–2128, c November 16–20, 2020. 2020 Association for Computational Linguistics 2019; Yang et al., 2019b) as backbone encoders, which have millions or even billions of parameters. Second, the framework of federated learning includes a massive number of local platforms (Li et al., 2019a), and communication between each platform and the central server is necessary. Third, upload ba"
2020.emnlp-main.165,P16-1123,0,0.0406523,"Missing"
2020.emnlp-main.165,D15-1062,0,0.0137727,"ge distillation. Such a strategy uses the uploaded predictions of ensemble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method. 1 Introduction Privacy - like eating and breathing - is one of life’s basic requirements. — Katherine Neville Relation extraction is a task of mining factual knowledge from the free text by labeling relations between entity mentions and has attracted increasing attention in recent years, such as Zeng et al. (2014); Xu et al. (2015a,b); Wang et al. (2016); Baldini Soares et al. (2019); Song et al. (2019). Applying automatic relation extraction to medical texts, such as electronic health records and discharge summaries, can be useful for many applications, including drug repurposing and medical knowledge graph construction. Unlike other domains, medical texts are highly privacy-sensitive, because these texts can include some of the most intimate details about one’s life, which document a patient’s physical and mental health, and can include information on social behaviors, personal relationships and financial status (Gos"
2020.emnlp-main.165,D15-1206,0,0.025816,"ge distillation. Such a strategy uses the uploaded predictions of ensemble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method. 1 Introduction Privacy - like eating and breathing - is one of life’s basic requirements. — Katherine Neville Relation extraction is a task of mining factual knowledge from the free text by labeling relations between entity mentions and has attracted increasing attention in recent years, such as Zeng et al. (2014); Xu et al. (2015a,b); Wang et al. (2016); Baldini Soares et al. (2019); Song et al. (2019). Applying automatic relation extraction to medical texts, such as electronic health records and discharge summaries, can be useful for many applications, including drug repurposing and medical knowledge graph construction. Unlike other domains, medical texts are highly privacy-sensitive, because these texts can include some of the most intimate details about one’s life, which document a patient’s physical and mental health, and can include information on social behaviors, personal relationships and financial status (Gos"
2020.emnlp-main.165,C14-1220,1,0.845672,"egy based on knowledge distillation. Such a strategy uses the uploaded predictions of ensemble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method. 1 Introduction Privacy - like eating and breathing - is one of life’s basic requirements. — Katherine Neville Relation extraction is a task of mining factual knowledge from the free text by labeling relations between entity mentions and has attracted increasing attention in recent years, such as Zeng et al. (2014); Xu et al. (2015a,b); Wang et al. (2016); Baldini Soares et al. (2019); Song et al. (2019). Applying automatic relation extraction to medical texts, such as electronic health records and discharge summaries, can be useful for many applications, including drug repurposing and medical knowledge graph construction. Unlike other domains, medical texts are highly privacy-sensitive, because these texts can include some of the most intimate details about one’s life, which document a patient’s physical and mental health, and can include information on social behaviors, personal relationships and fina"
2020.emnlp-main.165,D17-1004,0,0.0168007,"t medical relation extraction datasets, and we perform various experiments to verify the effectiveness of the proposed method. 2 Related Work Our work builds on a rich line of recent efforts on relation extraction models and federated learning. 2.1 Relation Extraction Relation extraction is a long-standing NLP task of mining factual knowledge from free texts by labeling relations between entity mentions. There are a number of recent neural network approaches applied to relation extraction, such as Zeng et al. (2014); Nguyen and Grishman (2015); dos Santos et al. (2015); Zhang and Wang (2015); Zhang et al. (2017). Recently, the NLP community has seen excitement around neural models that make heavy use of pretraining based on language modeling (Radford et al.; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019b). Baldini Soares et al. (2019); Shi and Lin (2019) and Alt et al. (2019) achieved the state-of-the-art performance in relation extraction by fine-tuning the pretrained language models. In this paper, we also adopt a pretrained language model as the backbone encoder. Applying relation extraction models to the medical field has great practical value, and there is a rich literature on medical"
2020.emnlp-main.52,P15-1017,1,0.916809,"nt. Note that there is only one memory. For better understanding, we show the memory states after learning Attack and Meet, respectively. to a word that most clearly expresses the occurrence of an event. Event arguments are participants of the event. Event mention refers to a phrase or sentence within which an event is described. Given a sentence or document, an ED system aims to locate event triggers and categorize their types. For example, in the sentence “A man died in the hospital”, an ED system is expected to detect a Die event along with the trigger word “died”. Following previous work (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018a), we formulate ED as a token-level multi-class classification task. Namely, given a sentence, we treat every token in it as a trigger candidate, and we aim to classify each candidate into pre-defined event classes. In real world, new event classes continually occur. Therefore, a practical ED system should enable to incrementally learn new event classes. We introduce a new problem, incremental event detection. Suppose that there a class-incremental data stream, denoted as {X (1) , X (2) , . . . , X (M ) }. Each X (k)1 contains training/validation/testing"
2020.emnlp-main.52,D18-1158,1,0.779624,"d replay-based methods which reserve a small amount of data from each old class. When new classes arrive, the stored data and new data are combined to re-train the model (Rebuffi et al., 2017; Hou et al., 2018, 2019). Since replay-based methods are very simple and effective, such methods have dominated the research. However, when applying replay-based methods to incremental event detection, we find two challenges: 1) Semantic Ambiguity problem and 2) Class Imbalance problem. Semantic Ambiguity: Compared with simple image classification task, event detection has more serious ambiguity problem (Chen et al., 2018). For example, in the sentence “He left the company”, the word “left” can not only trigger End-Position event, but also trigger Transport event. By contrast, the example “He resigned his position as manager” can more accurately express End-Position event and is more representative for the End-Position class. The ambiguous examples could confuse the classifier, affecting the generalization ability (Liu et al., 2014). It indicates that re-training the model with ambiguous old examples isn’t conducive to retaining previous knowledge. Therefore, to alleviate semantic ambiguity, we need to reserve"
2020.emnlp-main.52,N19-1423,0,0.0269541,"KCN model updates the parameters with the combination of reserved old classes data and training data of new arriving classes. The prototype enhanced retrospection retains previous knowledge via reserving the most representative examples. The hierarchical distillation transfers the previous knowledge from the original model to the current model. We will detail these three components. In general, X (k) can contain one or more new classes. 709 3.1 Trigger Extractor Our trigger extractor is based on the Transformer architecture (Vaswani et al., 2017). We use the stateof-the-art text encoder BERT (Devlin et al., 2019) to encode the input sentence. BERT is a multilayer bidirectional Transformer, pre-trained on a large-scale unlabeled corpus, which has achieved the state-of-the-art performance for event detection (Wang et al., 2019b; Yang et al., 2019). When new classes C (k) arrive, the training (k) data of the new classes is denoted as Xtrain = {(Xi , Yi ), 1 ≤ i ≤ K}, where K is the number of training examples, Xi is the sentence and Yi denotes the label of each token in the sentence Xi . The memory reserves the representative examples S (i) |), denoted for old m classes (i.e., m = |k−1 C i=1 as P = {P (1"
2020.emnlp-main.52,D19-1033,0,0.012646,"es better performance than EMR, which indicates that the prototype enhanced retrospection can select the most representative examples and hierarchical distillation enables to reduce the impact of class imbalance. 4.6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the scalability and robustness. In recent years, neural network-based methods have dominated the research. Chen et al. (2015) exploit the convolutional neural network for event extraction. Nguyen et al. (2016) leverage the recur"
2020.emnlp-main.52,2020.acl-main.573,0,0.203886,"two categories, parameterbased methods (Kirkpatrick et al., 2017; Aljundi et al., 2018) and replay-based methods (Rebuffi et al., 2017; Hou et al., 2019; Wang et al., 2019a). In parameter-based methods, these methods try to identify and preserve significant parameters of the original model (Kirkpatrick et al., 2017; Zenke et al., 2017; Aljundi et al., 2018). However, it is difficult to design a reasonable metric to evaluate all the parameters. In replay-based methods, these methods preserve the previous knowledge via storing a small number of old data (Castro et al., 2018; Wang et al., 2019a; Han et al., 2020). Wang et al. (2019a) propose an episodic memory replay (EMR) method which randomly selects examples to reserve in a memory. Despite the effectiveness of these methods on image classification tasks, these methods cannot handle semantic ambiguity problem and class imbalance problem in incremental event detection. 6 Conclusion In this paper, we introduce incremental learning into event detection and propose a knowledge consolidation network to preserve previously learned knowledge. To alleviate semantic ambiguity, we devise the prototype enhanced retrospection to reserve the most representative"
2020.emnlp-main.52,W06-0901,0,0.0803686,"R and our approach KCN. While in each case, the results of our approach are superior to those of EMR. It demonstrates the effectiveness of our proposed method. (2) Even reserved fewer samples, our method still achieves better performance than EMR, which indicates that the prototype enhanced retrospection can select the most representative examples and hierarchical distillation enables to reduce the impact of class imbalance. 4.6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the"
2020.emnlp-main.52,P84-1044,0,0.523447,"Missing"
2020.emnlp-main.52,P11-1113,0,0.0270441,".6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the scalability and robustness. In recent years, neural network-based methods have dominated the research. Chen et al. (2015) exploit the convolutional neural network for event extraction. Nguyen et al. (2016) leverage the recurrent neural network to model the dependency of triggers and arguments. Wang et al. (2019b) and Yang et al. (2019) exploit the BERT for event detection. Despite the vast progress that event detection has made in rec"
2020.emnlp-main.52,P08-1030,0,0.0635414,"pproach KCN. While in each case, the results of our approach are superior to those of EMR. It demonstrates the effectiveness of our proposed method. (2) Even reserved fewer samples, our method still achieves better performance than EMR, which indicates that the prototype enhanced retrospection can select the most representative examples and hierarchical distillation enables to reduce the impact of class imbalance. 4.6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the scalability and robust"
2020.emnlp-main.52,P14-1038,0,0.0315009,"superior to those of EMR. It demonstrates the effectiveness of our proposed method. (2) Even reserved fewer samples, our method still achieves better performance than EMR, which indicates that the prototype enhanced retrospection can select the most representative examples and hierarchical distillation enables to reduce the impact of class imbalance. 4.6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the scalability and robustness. In recent years, neural network-based methods have dom"
2020.emnlp-main.52,P13-1008,0,0.161458,"is outlined in Algorithm 1. 4.3 4 Experiments 4.1 Incremental Event Detection Benchmarks So far, there is no benchmark for evaluating incremental event detection models. Therefore, we propose the following construction method: for a given event detection dataset, the classes are arranged in a fixed order. Each method is then trained in a class-incremental way on the available training data. Based on two widely used datasets, ACE 20053 and TAC KBP 20174 , we introduce two instantiations of the above construction method. 1) ACE benchmark: We use the dataset split of ACE dataset as suggested in (Li et al., 2013; Chen et al., 2015; Lu et al., 2019; Liu et al., 2019). Since the ACE dataset has long-tail frequency distribution, we exploit the data of the top 10 most frequent classes. 2) TAC KBP benchmark: We exploit the official training and testing data of TAC KBP. Same as the ACE benchmark, we also use the data of the top 10 most frequent classes. For both of two benchmarks, one new class is available for the model at each time. 4.2 Evaluation Metrics and Implementation Details For conventional event detection, Precision (P), Recall (R) and F1 score are used as evaluation metrics. For incremental eve"
2020.emnlp-main.52,P10-1081,0,0.0418646,"ach case, the results of our approach are superior to those of EMR. It demonstrates the effectiveness of our proposed method. (2) Even reserved fewer samples, our method still achieves better performance than EMR, which indicates that the prototype enhanced retrospection can select the most representative examples and hierarchical distillation enables to reduce the impact of class imbalance. 4.6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the scalability and robustness. In recent years, ne"
2020.emnlp-main.52,D19-1068,1,0.835205,"Missing"
2020.emnlp-main.52,D18-1127,0,0.0121469,"For better understanding, we show the memory states after learning Attack and Meet, respectively. to a word that most clearly expresses the occurrence of an event. Event arguments are participants of the event. Event mention refers to a phrase or sentence within which an event is described. Given a sentence or document, an ED system aims to locate event triggers and categorize their types. For example, in the sentence “A man died in the hospital”, an ED system is expected to detect a Die event along with the trigger word “died”. Following previous work (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018a), we formulate ED as a token-level multi-class classification task. Namely, given a sentence, we treat every token in it as a trigger candidate, and we aim to classify each candidate into pre-defined event classes. In real world, new event classes continually occur. Therefore, a practical ED system should enable to incrementally learn new event classes. We introduce a new problem, incremental event detection. Suppose that there a class-incremental data stream, denoted as {X (1) , X (2) , . . . , X (M ) }. Each X (k)1 contains training/validation/testing (k) (k) (k) data (Xtrain , Xvalid , Xt"
2020.emnlp-main.52,P17-1164,1,0.864258,"Missing"
2020.emnlp-main.52,D18-1156,0,0.0223677,"Missing"
2020.emnlp-main.52,P19-1429,0,0.0272989,"Missing"
2020.emnlp-main.52,N16-1034,0,0.0849167,"is only one memory. For better understanding, we show the memory states after learning Attack and Meet, respectively. to a word that most clearly expresses the occurrence of an event. Event arguments are participants of the event. Event mention refers to a phrase or sentence within which an event is described. Given a sentence or document, an ED system aims to locate event triggers and categorize their types. For example, in the sentence “A man died in the hospital”, an ED system is expected to detect a Die event along with the trigger word “died”. Following previous work (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018a), we formulate ED as a token-level multi-class classification task. Namely, given a sentence, we treat every token in it as a trigger candidate, and we aim to classify each candidate into pre-defined event classes. In real world, new event classes continually occur. Therefore, a practical ED system should enable to incrementally learn new event classes. We introduce a new problem, incremental event detection. Suppose that there a class-incremental data stream, denoted as {X (1) , X (2) , . . . , X (M ) }. Each X (k)1 contains training/validation/testing (k) (k) (k) data (Xt"
2020.emnlp-main.52,P15-2060,0,0.0213185,"oposed method. (2) Even reserved fewer samples, our method still achieves better performance than EMR, which indicates that the prototype enhanced retrospection can select the most representative examples and hierarchical distillation enables to reduce the impact of class imbalance. 4.6.2 Related Work Event Detection Event detection (ED) is a very important task in information extraction. The proposed models can be divided into feature-based methods (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Li and Ji, 2014) and neural networkbased methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017, 2018a,b; Lu et al., 2019; Ding et al., 2019). In feature-based methods, a diverse set of features is exploited to predict event. Ahn (2006) leverage lexical features, syntactic features and external knowledge features to extract the event. Hong et al. (2011) propose a cross-event and cross-entity inference method to capture more clues. However, feature-based methods rely heavily on handcrafted features, limiting the scalability and robustness. In recent years, neural network-based methods have dominated the research. Chen et al. (2015) exploit the convolutional neural netwo"
2020.emnlp-main.52,N19-1086,0,0.366822,"entative examples. The hierarchical distillation transfers the previous knowledge from the original model to the current model. We will detail these three components. In general, X (k) can contain one or more new classes. 709 3.1 Trigger Extractor Our trigger extractor is based on the Transformer architecture (Vaswani et al., 2017). We use the stateof-the-art text encoder BERT (Devlin et al., 2019) to encode the input sentence. BERT is a multilayer bidirectional Transformer, pre-trained on a large-scale unlabeled corpus, which has achieved the state-of-the-art performance for event detection (Wang et al., 2019b; Yang et al., 2019). When new classes C (k) arrive, the training (k) data of the new classes is denoted as Xtrain = {(Xi , Yi ), 1 ≤ i ≤ K}, where K is the number of training examples, Xi is the sentence and Yi denotes the label of each token in the sentence Xi . The memory reserves the representative examples S (i) |), denoted for old m classes (i.e., m = |k−1 C i=1 as P = {P (1) , . . . , P (m) }, where P (i) is the set of stored examples for i-th class. We combine the stored old data and training data of new classes data, S (k) denoted as N = P Xtrain , to train the current model. The tar"
2020.emnlp-main.52,N19-1105,0,0.154578,"entative examples. The hierarchical distillation transfers the previous knowledge from the original model to the current model. We will detail these three components. In general, X (k) can contain one or more new classes. 709 3.1 Trigger Extractor Our trigger extractor is based on the Transformer architecture (Vaswani et al., 2017). We use the stateof-the-art text encoder BERT (Devlin et al., 2019) to encode the input sentence. BERT is a multilayer bidirectional Transformer, pre-trained on a large-scale unlabeled corpus, which has achieved the state-of-the-art performance for event detection (Wang et al., 2019b; Yang et al., 2019). When new classes C (k) arrive, the training (k) data of the new classes is denoted as Xtrain = {(Xi , Yi ), 1 ≤ i ≤ K}, where K is the number of training examples, Xi is the sentence and Yi denotes the label of each token in the sentence Xi . The memory reserves the representative examples S (i) |), denoted for old m classes (i.e., m = |k−1 C i=1 as P = {P (1) , . . . , P (m) }, where P (i) is the set of stored examples for i-th class. We combine the stored old data and training data of new classes data, S (k) denoted as N = P Xtrain , to train the current model. The tar"
2020.emnlp-main.52,P19-1522,0,0.0577116,"he hierarchical distillation transfers the previous knowledge from the original model to the current model. We will detail these three components. In general, X (k) can contain one or more new classes. 709 3.1 Trigger Extractor Our trigger extractor is based on the Transformer architecture (Vaswani et al., 2017). We use the stateof-the-art text encoder BERT (Devlin et al., 2019) to encode the input sentence. BERT is a multilayer bidirectional Transformer, pre-trained on a large-scale unlabeled corpus, which has achieved the state-of-the-art performance for event detection (Wang et al., 2019b; Yang et al., 2019). When new classes C (k) arrive, the training (k) data of the new classes is denoted as Xtrain = {(Xi , Yi ), 1 ≤ i ≤ K}, where K is the number of training examples, Xi is the sentence and Yi denotes the label of each token in the sentence Xi . The memory reserves the representative examples S (i) |), denoted for old m classes (i.e., m = |k−1 C i=1 as P = {P (1) , . . . , P (m) }, where P (i) is the set of stored examples for i-th class. We combine the stored old data and training data of new classes data, S (k) denoted as N = P Xtrain , to train the current model. The target label set contain"
2020.findings-emnlp.229,W06-0901,0,0.0753411,"g paradigm, called contextselective mask generalization, which can effective mine context-specific patterns for ED, shedding lights on building ED systems of decent robustness. 3) We report on extensive experiments demonstrating the advantages of our model in defending against adversarial attack, handling unseen predicates, and tackling ambiguous cases. We also give a deeper analysis exploring the predictive bias of our method. 2 2.1 Related Work Event Detection ED is a crucial subtask of EE that aims to find event triggers in texts. Earlier approaches for ED are feature based. To name a few, Ahn (2006) exploited lexical, syntactic, and external knowledge based features for the task; Ji and Grishman (2008) combined global and local decision features for the task. Liao and Grishman (2010) and Hong et al. (2011) investigated cross-event/cross-entity inference for the task; Li et al. (2013) proposed a joint framework for the task. Modern approaches for ED are neural network based. For example, Chen et al. 2524 (2015) leveraged Convolutional Neural Networks (CNNs) for the task; Nguyen et al. (2016) used Recurrent Neural Networks (RNNs) for the task; Feng et al. (2016) combined CNNs with RNNs and"
2020.findings-emnlp.229,D18-1316,0,0.0968754,"onal dimension of our work regarding the generalization of ED models. 2.2 Robustness Probing in Natural Language Processing Applications Enhancing the robustness of a model is a challenging and long-standing goal of AI research community. In computer vision, Szegedy et al. (2014) first pointed out that a crafted input with small perturbations could easily fool a neural model, referring to it as adversarial example. Papernot et al. (2016) first studied adversarial example in texts, and they proposed to producing adversarial input sequences on Recurrent Neural Network (RNN). Following the work, Alzantot et al. (2018) proposed a populationbased optimization method to generate more semantically similar adversarial examples. Many researchers have investigated robustness modeling in specific NLP problems. To name a few, Jia and Liang (2017) inserted adversarial perturbations into paragraphs for machine reading comprehension (MRC). The work was further extended by Mudrakarta et al. (2018), which cast the generation of adversarial examples as an optimization problem for the task of natural language inference (NLI); Belinkov and Bisk (2017); Ebrahimi et al. (2018) investigated how to tackle adversarial examples"
2020.findings-emnlp.229,C18-1055,0,0.0207553,"urrent Neural Network (RNN). Following the work, Alzantot et al. (2018) proposed a populationbased optimization method to generate more semantically similar adversarial examples. Many researchers have investigated robustness modeling in specific NLP problems. To name a few, Jia and Liang (2017) inserted adversarial perturbations into paragraphs for machine reading comprehension (MRC). The work was further extended by Mudrakarta et al. (2018), which cast the generation of adversarial examples as an optimization problem for the task of natural language inference (NLI); Belinkov and Bisk (2017); Ebrahimi et al. (2018) investigated how to tackle adversarial examples in neural machine translation (NMT). A very recent work of Hsieh et al. (2019) investigated the robustness of self-attentive architectures (Vaswani et al., 2017) in sentiment analysis, entailment and machine translation under adversarial attacks. But to our best knowledge, there is no work systematically studying the robustness of ED. 3 Approach Figure 2 visualizes the overview of our approach, by taking S1 as an example. Let a sentence of N words be S = [w1 , w2 , ..., wN ]. Following previous works (Li et al., 2013; Chen et al., 2015; Nguyen e"
2020.findings-emnlp.229,P16-2011,0,0.0904582,"d context-selective mask generalization for ED, which can effectively mine contextspecific patterns for learning and robustify an ED model. The experimental results have confirmed the effectiveness of our model regarding defending against adversarial attacks, exploring unseen predicates, and tackling ambiguity cases. Moreover, a deeper analysis suggests that our approach can learn a complementary predictive bias with most ED models that use full context for feature learning. 1 Replace With S2: During a war, invaders annihilated the whole town. Event Detector et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Liu et al., 2018b,a, 2019b). However, the vast majority of existing studies focus on improving the overall performance of an ED model (usually on a fixed test set), which rarely consider the robustness (and generalization capability) of an ED model. For example, most of existing methods do not answer questions such as when/why an ED system would fail, how to handle new, previously unseen data, despite these considerations are especially crucial for designing real-world ED systems. Event detection (ED), a crucial subtask of event extraction (EE), aims to identify and categorize event triggers"
2020.findings-emnlp.229,W04-1017,0,0.157653,"swer questions such as when/why an ED system would fail, how to handle new, previously unseen data, despite these considerations are especially crucial for designing real-world ED systems. Event detection (ED), a crucial subtask of event extraction (EE), aims to identify and categorize event triggers in texts. For example, in a sentence S1: “During a war, invaders destroyed the whole town”, ED requires a system to detect an event trigger destroyed, along with its event type ATTACK1 . Building a robust ED system is shown to benefit a wide range of applications including document summarization (Filatova and Hatzivassiloglou, 2004), knowledge base population (Ji and Grishman, 2011; Mitamura et al., 2017), question answering (Berant et al., 2014), and others. In recent years, great advances have been made in ED (Ji and Grishman, 2008; Li et al., 2013; Chen According to ACE event ontology. NIL Figure 1: Example of adversarial attack in ED. Introduction 1 Attack This paper focuses on the robustness aspect of ED models. We first emphasize the necessity of this research by pinpointing three stark cases demonstrating the vulnerability of existing ED models. These cases are: 1) adversarial attack, which refers to adding small"
2020.findings-emnlp.229,P11-1113,0,0.0322351,"experiments demonstrating the advantages of our model in defending against adversarial attack, handling unseen predicates, and tackling ambiguous cases. We also give a deeper analysis exploring the predictive bias of our method. 2 2.1 Related Work Event Detection ED is a crucial subtask of EE that aims to find event triggers in texts. Earlier approaches for ED are feature based. To name a few, Ahn (2006) exploited lexical, syntactic, and external knowledge based features for the task; Ji and Grishman (2008) combined global and local decision features for the task. Liao and Grishman (2010) and Hong et al. (2011) investigated cross-event/cross-entity inference for the task; Li et al. (2013) proposed a joint framework for the task. Modern approaches for ED are neural network based. For example, Chen et al. 2524 (2015) leveraged Convolutional Neural Networks (CNNs) for the task; Nguyen et al. (2016) used Recurrent Neural Networks (RNNs) for the task; Feng et al. (2016) combined CNNs with RNNs and Liu et al. (2018b) explored Graph Convolutional Networks (GCNs) for the task. More recent works have designed advanced architectures for the task (Liu et al., 2017, 2018a; Lu et al., 2019; Liu et al., 2019a). D"
2020.findings-emnlp.229,P19-1147,0,0.0183299,"more semantically similar adversarial examples. Many researchers have investigated robustness modeling in specific NLP problems. To name a few, Jia and Liang (2017) inserted adversarial perturbations into paragraphs for machine reading comprehension (MRC). The work was further extended by Mudrakarta et al. (2018), which cast the generation of adversarial examples as an optimization problem for the task of natural language inference (NLI); Belinkov and Bisk (2017); Ebrahimi et al. (2018) investigated how to tackle adversarial examples in neural machine translation (NMT). A very recent work of Hsieh et al. (2019) investigated the robustness of self-attentive architectures (Vaswani et al., 2017) in sentiment analysis, entailment and machine translation under adversarial attacks. But to our best knowledge, there is no work systematically studying the robustness of ED. 3 Approach Figure 2 visualizes the overview of our approach, by taking S1 as an example. Let a sentence of N words be S = [w1 , w2 , ..., wN ]. Following previous works (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Lu et al., 2019), we formulate the ED task as a token-level classification problem. That is, for each word in S, w"
2020.findings-emnlp.229,P18-1201,0,0.0113385,"e work has studied the robustness (and generalization capability) of an ED model. The work of Lu et al. (2019) is related to ours, which improved the generalization of an ED model by decoupling lexicalspecific and lexical-free representations via adversarial training. Compared to their work, the introduction of placeholders in our work can naturally decouple lexical-specific and lexical-free representations, which avoids the unstable adversarial learning process. Moreover, our work evaluates three aspects of robustness, rather than only unseen predicates. Our work also relates to the study of Huang et al. (2018), which aims to recognize events of never-seen event types, i.e. zero-shot EE. Their work lies in an orthogonal dimension of our work regarding the generalization of ED models. 2.2 Robustness Probing in Natural Language Processing Applications Enhancing the robustness of a model is a challenging and long-standing goal of AI research community. In computer vision, Szegedy et al. (2014) first pointed out that a crafted input with small perturbations could easily fool a neural model, referring to it as adversarial example. Papernot et al. (2016) first studied adversarial example in texts, and the"
2020.findings-emnlp.229,P08-1030,0,0.709562,"subtask of event extraction (EE), aims to identify and categorize event triggers in texts. For example, in a sentence S1: “During a war, invaders destroyed the whole town”, ED requires a system to detect an event trigger destroyed, along with its event type ATTACK1 . Building a robust ED system is shown to benefit a wide range of applications including document summarization (Filatova and Hatzivassiloglou, 2004), knowledge base population (Ji and Grishman, 2011; Mitamura et al., 2017), question answering (Berant et al., 2014), and others. In recent years, great advances have been made in ED (Ji and Grishman, 2008; Li et al., 2013; Chen According to ACE event ontology. NIL Figure 1: Example of adversarial attack in ED. Introduction 1 Attack This paper focuses on the robustness aspect of ED models. We first emphasize the necessity of this research by pinpointing three stark cases demonstrating the vulnerability of existing ED models. These cases are: 1) adversarial attack, which refers to adding small perturbations in the original sentences (Papernot et al., 2016; Alzantot et al., 2018). As shown in Figure 1, a well-trained event detector can correctly recognize the event trigger destroyed at first. But"
2020.findings-emnlp.229,P11-1115,0,0.0445066,"andle new, previously unseen data, despite these considerations are especially crucial for designing real-world ED systems. Event detection (ED), a crucial subtask of event extraction (EE), aims to identify and categorize event triggers in texts. For example, in a sentence S1: “During a war, invaders destroyed the whole town”, ED requires a system to detect an event trigger destroyed, along with its event type ATTACK1 . Building a robust ED system is shown to benefit a wide range of applications including document summarization (Filatova and Hatzivassiloglou, 2004), knowledge base population (Ji and Grishman, 2011; Mitamura et al., 2017), question answering (Berant et al., 2014), and others. In recent years, great advances have been made in ED (Ji and Grishman, 2008; Li et al., 2013; Chen According to ACE event ontology. NIL Figure 1: Example of adversarial attack in ED. Introduction 1 Attack This paper focuses on the robustness aspect of ED models. We first emphasize the necessity of this research by pinpointing three stark cases demonstrating the vulnerability of existing ED models. These cases are: 1) adversarial attack, which refers to adding small perturbations in the original sentences (Papernot"
2020.findings-emnlp.229,D14-1159,0,0.0225971,"especially crucial for designing real-world ED systems. Event detection (ED), a crucial subtask of event extraction (EE), aims to identify and categorize event triggers in texts. For example, in a sentence S1: “During a war, invaders destroyed the whole town”, ED requires a system to detect an event trigger destroyed, along with its event type ATTACK1 . Building a robust ED system is shown to benefit a wide range of applications including document summarization (Filatova and Hatzivassiloglou, 2004), knowledge base population (Ji and Grishman, 2011; Mitamura et al., 2017), question answering (Berant et al., 2014), and others. In recent years, great advances have been made in ED (Ji and Grishman, 2008; Li et al., 2013; Chen According to ACE event ontology. NIL Figure 1: Example of adversarial attack in ED. Introduction 1 Attack This paper focuses on the robustness aspect of ED models. We first emphasize the necessity of this research by pinpointing three stark cases demonstrating the vulnerability of existing ED models. These cases are: 1) adversarial attack, which refers to adding small perturbations in the original sentences (Papernot et al., 2016; Alzantot et al., 2018). As shown in Figure 1, a well"
2020.findings-emnlp.229,D17-1215,0,0.0264339,"h community. In computer vision, Szegedy et al. (2014) first pointed out that a crafted input with small perturbations could easily fool a neural model, referring to it as adversarial example. Papernot et al. (2016) first studied adversarial example in texts, and they proposed to producing adversarial input sequences on Recurrent Neural Network (RNN). Following the work, Alzantot et al. (2018) proposed a populationbased optimization method to generate more semantically similar adversarial examples. Many researchers have investigated robustness modeling in specific NLP problems. To name a few, Jia and Liang (2017) inserted adversarial perturbations into paragraphs for machine reading comprehension (MRC). The work was further extended by Mudrakarta et al. (2018), which cast the generation of adversarial examples as an optimization problem for the task of natural language inference (NLI); Belinkov and Bisk (2017); Ebrahimi et al. (2018) investigated how to tackle adversarial examples in neural machine translation (NMT). A very recent work of Hsieh et al. (2019) investigated the robustness of self-attentive architectures (Vaswani et al., 2017) in sentiment analysis, entailment and machine translation unde"
2020.findings-emnlp.229,P15-1017,1,0.947044,"17); Ebrahimi et al. (2018) investigated how to tackle adversarial examples in neural machine translation (NMT). A very recent work of Hsieh et al. (2019) investigated the robustness of self-attentive architectures (Vaswani et al., 2017) in sentiment analysis, entailment and machine translation under adversarial attacks. But to our best knowledge, there is no work systematically studying the robustness of ED. 3 Approach Figure 2 visualizes the overview of our approach, by taking S1 as an example. Let a sentence of N words be S = [w1 , w2 , ..., wN ]. Following previous works (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Lu et al., 2019), we formulate the ED task as a token-level classification problem. That is, for each word in S, we consider it as a candidate trigger, and our goal is to assign a correct event label to it (A type of NIL is used to indicate a non-trigger word). The technical details of our approach are presented in the following, including: trigger delexicalization (§ 3.1), context-selective discriminative learning (§ 3.2), contextualized similarity learning (§ 3.3), attentive representation fusion (§ 3.4), and the training strategy (§ 3.5). 3.1 Trigger Delexicalization"
2020.findings-emnlp.229,N19-1423,0,0.0216916,"l classification problem. That is, for each word in S, we consider it as a candidate trigger, and our goal is to assign a correct event label to it (A type of NIL is used to indicate a non-trigger word). The technical details of our approach are presented in the following, including: trigger delexicalization (§ 3.1), context-selective discriminative learning (§ 3.2), contextualized similarity learning (§ 3.3), attentive representation fusion (§ 3.4), and the training strategy (§ 3.5). 3.1 Trigger Delexicalization Following recent advances in ED (Yang et al., 2019), we adopt BERT architecture (Devlin et al., 2019) to learn the input representations, by first adding special tokens at the both ends of S to construct an extended sequence “[CLS] S [SEP]”. Note we do not allow our model to leverage lexical clues, we explicitly delexicalize the candidate trigger, by replacing it with a placeholder [MASK]. Consider S1 and S2 in Figure 1. If we take destroyed or annihilated as the candidate trigger, the mask-containing sequence is “[CLS] During a war, invaders [MASK] the whole town [SEP]”. Next. we use BERT for sequence encoding and take the final hidden layer2 of BERT as the input representations, denoted as"
2020.findings-emnlp.229,P19-1262,0,0.041953,"Missing"
2020.findings-emnlp.229,D17-1018,0,0.0249684,"a placeholder [MASK]. Consider S1 and S2 in Figure 1. If we take destroyed or annihilated as the candidate trigger, the mask-containing sequence is “[CLS] During a war, invaders [MASK] the whole town [SEP]”. Next. we use BERT for sequence encoding and take the final hidden layer2 of BERT as the input representations, denoted as HS ∈ R(N +2)×d . We use hwi ∈ Rd to denote the representation of a specific token wi . 2 In case a word may be split into many sub-word pieces, we conduct a self-attentive computation over sub-word pieces to compute the representation of original word, as suggested by Lee et al. (2017). 2525 During a war, invaders destroyed the whole town. Context-selective Discrimination Learning Contextualized Similarity Learning [CLS] During a war, invaders [MASK] the whole town [SEP] S1: During [Ă] invaders [MASK] the whole town. Attack S2: An American tank [MASK] the hotel. Attack BERT H[CLS] H1 H2 H3  H[M] 1 0 1 Uncertainty modeling And select the better one  random mask attention  1 high value S1: During [Ă] invaders [MASK] the whole town. Attack S2: Government [MASK] 5000 dollars. Transfer-Money  0 S1: H[M] , S2: H[M] BERT HN H[SEP] selective attention  0  S1: H[M]"
2020.findings-emnlp.229,P13-1008,0,0.618556,"ction (EE), aims to identify and categorize event triggers in texts. For example, in a sentence S1: “During a war, invaders destroyed the whole town”, ED requires a system to detect an event trigger destroyed, along with its event type ATTACK1 . Building a robust ED system is shown to benefit a wide range of applications including document summarization (Filatova and Hatzivassiloglou, 2004), knowledge base population (Ji and Grishman, 2011; Mitamura et al., 2017), question answering (Berant et al., 2014), and others. In recent years, great advances have been made in ED (Ji and Grishman, 2008; Li et al., 2013; Chen According to ACE event ontology. NIL Figure 1: Example of adversarial attack in ED. Introduction 1 Attack This paper focuses on the robustness aspect of ED models. We first emphasize the necessity of this research by pinpointing three stark cases demonstrating the vulnerability of existing ED models. These cases are: 1) adversarial attack, which refers to adding small perturbations in the original sentences (Papernot et al., 2016; Alzantot et al., 2018). As shown in Figure 1, a well-trained event detector can correctly recognize the event trigger destroyed at first. But when we replace"
2020.findings-emnlp.229,N16-1034,0,0.236098,"ning mechanism, called context-selective mask generalization for ED, which can effectively mine contextspecific patterns for learning and robustify an ED model. The experimental results have confirmed the effectiveness of our model regarding defending against adversarial attacks, exploring unseen predicates, and tackling ambiguity cases. Moreover, a deeper analysis suggests that our approach can learn a complementary predictive bias with most ED models that use full context for feature learning. 1 Replace With S2: During a war, invaders annihilated the whole town. Event Detector et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Liu et al., 2018b,a, 2019b). However, the vast majority of existing studies focus on improving the overall performance of an ED model (usually on a fixed test set), which rarely consider the robustness (and generalization capability) of an ED model. For example, most of existing methods do not answer questions such as when/why an ED system would fail, how to handle new, previously unseen data, despite these considerations are especially crucial for designing real-world ED systems. Event detection (ED), a crucial subtask of event extraction (EE), aims to identify and catego"
2020.findings-emnlp.229,P10-1081,0,0.213772,"s. 3) We report on extensive experiments demonstrating the advantages of our model in defending against adversarial attack, handling unseen predicates, and tackling ambiguous cases. We also give a deeper analysis exploring the predictive bias of our method. 2 2.1 Related Work Event Detection ED is a crucial subtask of EE that aims to find event triggers in texts. Earlier approaches for ED are feature based. To name a few, Ahn (2006) exploited lexical, syntactic, and external knowledge based features for the task; Ji and Grishman (2008) combined global and local decision features for the task. Liao and Grishman (2010) and Hong et al. (2011) investigated cross-event/cross-entity inference for the task; Li et al. (2013) proposed a joint framework for the task. Modern approaches for ED are neural network based. For example, Chen et al. 2524 (2015) leveraged Convolutional Neural Networks (CNNs) for the task; Nguyen et al. (2016) used Recurrent Neural Networks (RNNs) for the task; Feng et al. (2016) combined CNNs with RNNs and Liu et al. (2018b) explored Graph Convolutional Networks (GCNs) for the task. More recent works have designed advanced architectures for the task (Liu et al., 2017, 2018a; Lu et al., 2019"
2020.findings-emnlp.229,P16-1200,0,0.0673205,"Missing"
2020.findings-emnlp.229,D19-1068,1,0.875764,"Missing"
2020.findings-emnlp.229,P17-1164,1,0.848366,"s for the task. Liao and Grishman (2010) and Hong et al. (2011) investigated cross-event/cross-entity inference for the task; Li et al. (2013) proposed a joint framework for the task. Modern approaches for ED are neural network based. For example, Chen et al. 2524 (2015) leveraged Convolutional Neural Networks (CNNs) for the task; Nguyen et al. (2016) used Recurrent Neural Networks (RNNs) for the task; Feng et al. (2016) combined CNNs with RNNs and Liu et al. (2018b) explored Graph Convolutional Networks (GCNs) for the task. More recent works have designed advanced architectures for the task (Liu et al., 2017, 2018a; Lu et al., 2019; Liu et al., 2019a). Despite many advances in ED, to date rare work has studied the robustness (and generalization capability) of an ED model. The work of Lu et al. (2019) is related to ours, which improved the generalization of an ED model by decoupling lexicalspecific and lexical-free representations via adversarial training. Compared to their work, the introduction of placeholders in our work can naturally decouple lexical-specific and lexical-free representations, which avoids the unstable adversarial learning process. Moreover, our work evaluates three aspects of"
2020.findings-emnlp.229,D14-1162,0,0.0841568,"adversarial attacks, unseen predicates, and tackling ambiguity cases. To maintain tractability, in the following experiments, we take model achieving best performance on the development set for testing, instead of adopting 5-run average as in previous evaluation. Moreover, to simplicity analysis, our experiments are mostly conducted on ACE 2005. 5.2.1 Defending Against Adversarial Attacks In adversarial attacks, we adopt list-based method (Alzantot et al., 2018) to generate adversarial examples. Specifically, for a word, we first find its semantically similar words based on GloVe embeddings (Pennington et al., 2014), and then we replace the original word with each word and evaluate the new sentence with a GPT language model (Radford et al., 2019). We take the new sentence with the largest score as adversarial example. Some cases in 2528 M ODEL O RG ADT ADC ∆F1 M ODEL LA HA ∆F1 DNNED DMCNN JRNN Delta-Adv MBERT 66.7 69.0 69.5 71.8 74.2 18.8 20.1 19.3 20.4 36.1 16.6 19.2 18.9 19.6 33.2 -47.1/50.1 -48.9/49.8 -50.2/50.6 -51.4/52.2 -38.1/41.0 DNNED DMCNN (2015) JRNN (2016) Delta-Adv (2019) MBERT 70.6 72.7 71.0 72.2 73.5 50.4 55.2 49.5 52.1 60.3 -20.2 -17.5 -21.5 -20.1 -13.2 MFULL MMASK 76.0 45.0 47.9 45.0 43.3"
2020.findings-emnlp.229,D19-1002,0,0.0254995,"ry vector (Bahdanau et al., 2014). Wa ∈ Rd×d is an attention matrix. Then we conduct a weighted summation computation over HS using αu as the weight vector and compute a feature vector for the masked candidate trigger, denoted by F[MS] . Finally, F[MS] is used for event label prediction by computing an output vector containing the probability of different event labels: o[MS] = Wm F[MS] + bm (1) where Wm and bm are model parameters. The predicted event label corresponds to the index having the highest value in o[MS] . Considering that unsupervised attention may not always learn a good pattern (Wiegreffe and Pinter, 2019), we devise a “trial-and-error” approach to guide the learning. Specifically, at the training time, we also generate random context mask3 and normalize it as a weight vector αr . Our intuition is, if αr leads to a better result than using αu , it might be a better selective pattern for our model to learn. Note there are cases where the predicted event labels are the same for αr and αu , and here we introduce model uncertainty (Gal and Ghahramani, 2016) to evaluate whether the result is improved. Specifically, we compute the model uncertainty by making predictions many times but with dropout la"
2020.findings-emnlp.229,P19-1522,0,0.116406,"2019), we formulate the ED task as a token-level classification problem. That is, for each word in S, we consider it as a candidate trigger, and our goal is to assign a correct event label to it (A type of NIL is used to indicate a non-trigger word). The technical details of our approach are presented in the following, including: trigger delexicalization (§ 3.1), context-selective discriminative learning (§ 3.2), contextualized similarity learning (§ 3.3), attentive representation fusion (§ 3.4), and the training strategy (§ 3.5). 3.1 Trigger Delexicalization Following recent advances in ED (Yang et al., 2019), we adopt BERT architecture (Devlin et al., 2019) to learn the input representations, by first adding special tokens at the both ends of S to construct an extended sequence “[CLS] S [SEP]”. Note we do not allow our model to leverage lexical clues, we explicitly delexicalize the candidate trigger, by replacing it with a placeholder [MASK]. Consider S1 and S2 in Figure 1. If we take destroyed or annihilated as the candidate trigger, the mask-containing sequence is “[CLS] During a war, invaders [MASK] the whole town [SEP]”. Next. we use BERT for sequence encoding and take the final hidden layer2"
2020.findings-emnlp.229,D18-1156,0,0.0503645,"mask generalization for ED, which can effectively mine contextspecific patterns for learning and robustify an ED model. The experimental results have confirmed the effectiveness of our model regarding defending against adversarial attacks, exploring unseen predicates, and tackling ambiguity cases. Moreover, a deeper analysis suggests that our approach can learn a complementary predictive bias with most ED models that use full context for feature learning. 1 Replace With S2: During a war, invaders annihilated the whole town. Event Detector et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Liu et al., 2018b,a, 2019b). However, the vast majority of existing studies focus on improving the overall performance of an ED model (usually on a fixed test set), which rarely consider the robustness (and generalization capability) of an ED model. For example, most of existing methods do not answer questions such as when/why an ED system would fail, how to handle new, previously unseen data, despite these considerations are especially crucial for designing real-world ED systems. Event detection (ED), a crucial subtask of event extraction (EE), aims to identify and categorize event triggers in texts. For exa"
2020.findings-emnlp.229,P19-1429,0,0.0291083,"Missing"
2021.acl-demo.11,N19-4010,0,0.0214883,"ply CogNet to downstream tasks, it is challenging to expand CogNet and ground raw texts to CogNet automatically. For this target, information extraction (IE) is an effective method, which aims to extract entity, relation, event, and other factual information from raw texts and link them to KBs. With the rapid development of IE area, a few remarkable open-source toolkits have been developed in recent years. The mainstream toolkits can be classified into two categories: task-specific toolkits and task-agnostic toolkits. Task-specific toolkits focus on one or a few specific tasks, such as FLAIR (Akbik et al., 2019) for named entity recognition (NER), BLINK (Ledell Wu, 2020) for entity linking (EL), OpenNRE (Han et al., 2019) for relation extraction (RE) and Open-SESAME (Swayamdipta et al., 2017) for frame-semantic parsing. On the other end of the spectrum, AllenNLP (Gardner et al., 2017), OpenNMT (Klein et al., 2017) and other task-agnostic toolkits are designed to provide programming framework without the implementation of specific tasks. As mentioned above, various toolkits have been widely used, but they also suffer from several limitations. First, most of the existing NLP toolkits only support one o"
2021.acl-demo.11,D19-1641,0,0.0182068,"with the frame. Frame-semantic parsing is usually performed as a pipeline of tasks: target identification, frame identification and argument identification. To achieve the function of argument identification, we add tarFine-grained entity typing aims to assign one or more types to each entity mention given a certain context and can provide valuable prior knowledge for a wide range of NLP tasks, such as relation extraction and question answering. To achieve the function of entity typing, we adopt a two-step mention-aware attention mechanism to enable the model to focus on important words like Lin and Ji (2019). Compared with NER, ET has finer and richer entity labels with internal correlations (e.g., /person, /person/artist, /person/artist/actor), there are 87 fine-grained entity lables in CogIE. 95 Loader Loader Datable Datable Processor Processor DatableSet DatableSet Dataset Vocabulary Config ...Dataset Input Input Model Vocabulary Config ... Trainer Model Metrics Trainer Metrics Tester Loss Tester Checkpoint Output Log Visualization ... Checkpoint Output Log Visualization ... Loss Optimizer Optimizer Transformer RNN CNN ...Transformer RNN CNN MultiLabelMetirc ... ClassifyMetric SpanMetric ... M"
2021.acl-demo.11,P98-1013,0,0.648345,"s a knowledgegrounded toolkit, CogIE can ground the extracted facts to CogNet and leverage different types of knowledge to enrich extracted results. Third, for extensibility, owing to the design of three-tier architecture, CogIE is not only a plug-and-play toolkit for developers but also an extensible programming framework for researchers. We release an open-access online system 1 to visually extract information from texts. Source code, datasets and pre-trained models are publicly available at GitHub 2 , with a short instruction video 3 . 1 Introduction Knowledge bases (KBs) such as FrameNet (Baker et al., 1998), DBpedia (Lehmann et al., 2015), Wikidata (Vrandeˇci´c and Kr¨otzsch, 2014), and ConceptNet (Liu and Singh, 2004) are becoming popular for a variety of downstream tasks including information retrieval, recommender system and dialog system. Wang et al. (2021) divide KBs into three categories according to the type of knowledge, respectively linguistic KBs (e.g., FrameNet), world KBs (e.g., DBpedia, Wikidata) and commonsense KBs (e.g., ConceptNet). Unlike most of the 1 http://cognet.top/cogie https://github.com/jinzhuoran/CogIE 3 https://youtu.be/csgnjU_F3Qs 2 92 Proceedings of the Joint Confere"
2021.acl-demo.11,P15-1017,1,0.78689,"relation extraction, event extraction, and frame-semantic parsing, etc. CogIE can also align the extracted facts to CogNet via entity linking, relation matching and frame matching. As shown in Figure 2, we give some examples to illustrate these functions. 3.1 Entity Linking Event Extraction Events are classified as things that happen or occur, and usually involve entities as their properties. Event extraction need to identify events that are composed of an event trigger, an event type, and a set of arguments with different roles. To achieve the function of event extraction, we realize DMCNN (Chen et al., 2015) and a joint model based on BERT. 3.6 Entity Typing Frame-Semantic Parsing Frame semantic parsing is the task of automatically extracting semantic structures in plain texts according the framework of FrameNet. Each frame represents a kind of event, situation, or relationship, and consists of a frame name, a list of lexical units (LUs), and a set of frame elements (FEs). LU is a word that plays the role of evoking the corresponding frame. FE indicates different semantic roles associated with the frame. Frame-semantic parsing is usually performed as a pipeline of tasks: target identification, fr"
2021.acl-demo.11,W03-0419,0,0.651429,"Missing"
2021.acl-demo.11,L18-1544,0,0.0230851,"ganizations, and miscellaneous entities, but also support the recognition of 54 entity types. 3.2 Relation Extraction Relation extraction aims at predicting semantic relations between pairs of entities. More specifically, after identifying entity mentions in texts, the main goal of RE is to classify relations. To achieve the function of relation extraction, we adopt BERT as the textual encoder and use FFN as the decoder. As CogIE implements relation extraction simultaneously, it also matches extracted relations to Wikidata in the form as shown in Figure 2. We train relation matching on T-REx (Elsahar et al., 2018), which is a large-scale alignment dataset between free text documents and KB triples, there are currently 500 relation classes in CogIE. CogIE is designed for a series of IE functions, including named entity recognition, entity typing, entity linking, relation extraction, event extraction, and frame-semantic parsing, etc. CogIE can also align the extracted facts to CogNet via entity linking, relation matching and frame matching. As shown in Figure 2, we give some examples to illustrate these functions. 3.1 Entity Linking Event Extraction Events are classified as things that happen or occur, a"
2021.acl-demo.11,P19-1279,0,0.0179109,"t tasks, and the evaluation results demonstrate the models implemented by CogIE are efficient. Experiment and Evaluation In this section, we train and evaluate CogIE on several datasets in different tasks. Each task’s performance is shown in Table 1, all pre-trained models are publicly downloadable. For the NER component, we compare CogIE against Stanza (v1.0), FLAIR (v0.4.5) and spaCy (v2.2), we find that CogIE can achieve either higher or close F1 scores when compared against other toolkits. For the RE component, we compare CogIE with two baselines: RNN+PI (Zhang and Wang, 2015) and BERTEM (Soares et al., 2019), we observe that CogIE can achieve comparable or even better performance than them. For the framesemantic parsing component, we compare CogIE against SimpleFrameId (Hartmann et al., 2017), we find that CogIE can have better performance than SimpleFrameId. For the other components, 5 Conclusion and Future Work In the future, we consider the following points during improvement: (1) To use CogIE on any device, we will further optimize model sizes and speed up computation in CogIE while striking a balance between accuracy and efficiency; (2) For making models robust to the texts of different doma"
2021.acl-demo.11,I05-3017,0,0.263132,"Missing"
2021.acl-demo.11,D19-3029,0,0.0212227,"or this target, information extraction (IE) is an effective method, which aims to extract entity, relation, event, and other factual information from raw texts and link them to KBs. With the rapid development of IE area, a few remarkable open-source toolkits have been developed in recent years. The mainstream toolkits can be classified into two categories: task-specific toolkits and task-agnostic toolkits. Task-specific toolkits focus on one or a few specific tasks, such as FLAIR (Akbik et al., 2019) for named entity recognition (NER), BLINK (Ledell Wu, 2020) for entity linking (EL), OpenNRE (Han et al., 2019) for relation extraction (RE) and Open-SESAME (Swayamdipta et al., 2017) for frame-semantic parsing. On the other end of the spectrum, AllenNLP (Gardner et al., 2017), OpenNMT (Klein et al., 2017) and other task-agnostic toolkits are designed to provide programming framework without the implementation of specific tasks. As mentioned above, various toolkits have been widely used, but they also suffer from several limitations. First, most of the existing NLP toolkits only support one or a few IE functions, and there is a lack of an integrated and efficient IE toolkit. Second, very few IE toolkit"
2021.acl-demo.11,E17-1045,0,0.0311233,"Missing"
2021.acl-demo.11,C18-1267,0,0.0169747,"749 816 F1 F1 F1 F1 F1 F1 F1 F1 F1 F1 F1 Acc F1 91.2 91.4 85.6 80.0 75.5 69.9 93.0 68.9 46.4 58.8 52.8 91.0 56.4 Named Entity Recognition Entity Typing Relation Extraction Event Extraction Frame-Semantic Parsing Trigger Argument Trigger Argument Frame Element Table 1: Performance of each task. The datasets references are: MSRA (Emerson, 2005), CoNLL2003 (Sang and De Meulder, 2003), OntoNotes5.0 (Pradhan et al., 2013), OntoNotes4.0 (Weischedel et al., 2011), BBN (Weischedel and Brunstein, 2005), KBP37 (Zhang and Wang, 2015), DuIE (Li et al., 2019), ACE2005 (Walker et al., 2006), and Frame 1.5 (Kabbach et al., 2018). We train models for different tasks and deploy pretrained models for online access. The online system can be directly used for extracting entities, relations, events and frames from plain texts. Besides, the extracted results can be linked to CogNet, so users can further acquire external knowledge through CogNet. We also visualize the extracted results in the form of knowledge graphs to improve the availability of the online system. Meanwhile, open online APIs 5 can be called directly . 5 we also compare CogIE with a series of baselines and toolkits, and the evaluation results show that CogI"
2021.acl-demo.11,P17-4012,0,0.0374796,"id development of IE area, a few remarkable open-source toolkits have been developed in recent years. The mainstream toolkits can be classified into two categories: task-specific toolkits and task-agnostic toolkits. Task-specific toolkits focus on one or a few specific tasks, such as FLAIR (Akbik et al., 2019) for named entity recognition (NER), BLINK (Ledell Wu, 2020) for entity linking (EL), OpenNRE (Han et al., 2019) for relation extraction (RE) and Open-SESAME (Swayamdipta et al., 2017) for frame-semantic parsing. On the other end of the spectrum, AllenNLP (Gardner et al., 2017), OpenNMT (Klein et al., 2017) and other task-agnostic toolkits are designed to provide programming framework without the implementation of specific tasks. As mentioned above, various toolkits have been widely used, but they also suffer from several limitations. First, most of the existing NLP toolkits only support one or a few IE functions, and there is a lack of an integrated and efficient IE toolkit. Second, very few IE toolkits can align the extracted facts to KBs, which may cause the extracted facts not to be applied directly to downstream tasks. Third, for an efficient and effective toolkit, providing application pro"
2021.acl-long.218,C18-1139,0,0.0141834,"tch a lexicon. (2) ZEN (Diao et al., 2020) is a pretrained Chinese text encoder enhanced by an n-gram lexicon. In ZEN, n-gram contexts are extracted, encoded and integrated with the character encoder. For more details about Lattice-LSTM and ZEN, we refer readers to Zhang and Yang (2018) and Diao et al. (2020). 5.1 5.3 5 Baselines Text-Only Model Open-Source NLP Toolkit: Many open-source NLP toolkits, such as spaCy (Honnibal et al., 2020) and Stanza (Qi et al., 2020), support Chinese NER. In spaCy, a multitask CNN is employed. In Stanza, a contextualized string representation based tagger from Akbik et al. (2018) is adopted. In both spaCy and Stanza, the tagger is trained on OntoNote (Weischedel et al., 2011). To map the output of taggers to CNERTA’s label space, expert-designed rules are used, such as PERSON → PER. Since these toolkits are only designed for flat structure, we do not evaluate these toolkits in nested settings. Multimodal Model To leverage the acoustic modality, several multimodal models are introduced. In these models, fusion modules are built on the top of the acoustic encoder and the textual encoder, which are designed for capturing the interaction between the textual hidden represe"
2021.acl-long.218,W15-4319,0,0.0733109,"Missing"
2021.acl-long.218,D18-1017,1,0.851384,"imodal NER with both textual and acoustic contents. The motivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computational Linguistics First, despite much recent success in multimodal NER, current studies on this topic are limited in English, and totally skirt other languages. Meanwhile, previous work on Chinese NER, such as Xu et al. (2013); Peng and Dredze (2016a); Zhang and Yang (2018); Cao et al. (2018); Sui et al. (2019); Gui et al. (2019); Ma et al. (2020); Li et al. (2020), totally ignores valuable multimodal information. With around 1.3 billion native speakers and the wide spread of short-form video apps in China, it is necessary and urgent to carry out research on Chinese multimodal NER. Second, unlike the static visual modality, the time-varying acoustic modality plays a unique role in Chinese NER, especially in providing precise word segmentation information. In detail, different from English, Chinese is an ideographic language featured by no word delimiter between words in written. T"
2021.acl-long.218,Q16-1026,0,0.0397644,"on “Speech is a part of thought.” — Oliver Sacks, Seeing Voices As a fundamental subtask of information extraction, named entity recognition (NER) aims to locate and classify named entities mentioned in unstructured texts into predefined semantic categories, such as person names, locations and organizations. NER plays a crucial role in many natural language processing (NLP) tasks, including relation extraction (Zelenko et al., 2003), question answering (Moll´a et al., 2006) and summarization (Aramaki et al., 2009). Most of the research on NER, such as Lample et al. (2016); Ma and Hovy (2016); Chiu and Nichols (2016), only relies on the textual modality to infer tags. However, when texts are noisy or short, and it is not sufficient to locate and classify named entities accurately only based on textual information (Baldwin et al., 2015; Lu et al., 2018). One promising solution is to introduce other modalities as the supplement of the textual modality. So far, some studies on multimodal NER, such as Moon et al. (2018); Zhang et al. (2018); Lu et al. (2018); Arshad et al. (2019); Asgari-Chenaghlu et al. (2020); Yu et al. (2020); Chen et al. (2020); Sun et al. (2020), have attempted to couple the textual moda"
2021.acl-long.218,W04-1213,0,0.126643,"nese character and sj denotes the j-th waveform frame, the goal of the task is to leverage textual and speech clues to identify and classify all named entities contained in the text. 3.2 4.2 Dataset Comparison We compare CNERTA with several widely used NER datasets in Table 2. Specifically, we first compare our corpus with some Chinese NER datasets, such as MSRA (Levow, 2006), OntoNotes (Weischedel et al., 2011), Weibo NER (Peng and Dredze, 2016a) and Resume (Zhang and Yang, 2018). Then, we compare our corpus with several widely used nested NER datasets, like GENIA (Kim et al., 2003), JNLPBA (Collier and Kim, 2004), ACE-2004 (Doddington et al., 2004) and ACE-2005 (Walker et al., 2004). Finally, multimodal NER datasets, including Twitter-2015 (Zhang et al., 2018) and Twitter-2017 (Lu et al., 2018), are compared with our corpus. From Table 2, we observe that our corpus has unique value compared with the existing datasets. The value is reflected in the following aspects: (1) CNERTA is a large-scale dataset; (2) CNERTA is the first Chinese multimodal dataset; (3) Not only the topmost entities but also nested entities are annotated; (4) Among these datasets, the acoustic modality is only introduced in CNERTA"
2021.acl-long.218,2020.findings-emnlp.58,0,0.103877,"ual encoder and conditional random fields (CRF) (Lafferty et al., 2001) as the decoder, the widely used BiLSTM-CRF (Lample et al., 2016) is adopted as an important baseline. PLM-CRF: Instead of training a model from scratch, we also adopt the framework of fine-tuning a pretrained language model (PLM) on a downstream task (Radford et al., 2018). In this framework, we adopt BERT (Devlin et al., 2019) as the textual encoder and use CRF as the decoder. In addition to initializing the textual encoder with the original pretrained BERT model, a SoTA Chinese pretrained language model, called MacBERT (Cui et al., 2020), is used. Compared with BERT, MacBERT is built upon RoBERTa (Liu et al., 2019b) and the original MLM task in BERT is replaced with the MLM as correction task. For more details, we refer readers to Cui et al. (2020). 5.2 Lexicon-Enhanced Model: Based on the annotated dataset, a family of strong and representative baselines is established, including (1) text-only models presented in Section 5.1, (2) lexicon-enhanced models shown in Section 5.2 and (3) multimodal models introduced in Section 5.3. A drawback of the text-only methods mentioned above is that explicit word and word sequence informat"
2021.acl-long.218,N19-1423,0,0.611401,"hinese NER, since named entity boundaries are usually word boundaries (Zhang and Yang, 2018). Fortunately, cues contained in the fluent acoustic modality, especially pauses between adjacent words, are able to aid the NER model in discovering word boundaries. A classic example shown in Figure 1 can perfectly illustrate this point. In this example, the sentence with ambiguous word segmentation would be disambiguated with the aid of the acoustic modality, which would absolutely assist the model to infer correct NER tags. In this work, we make the following efforts to advance multimodal NER: CRF (Devlin et al., 2019). Then, since introducing a lexicon has been proven as an effective way to incorporate word information in Chinese NER (Zhang and Yang, 2018), we implement several lexicon-enhanced models, such as Lattice-LSTM (Zhang and Yang, 2018) and ZEN (Diao et al., 2020), to explore whether the acoustic modality can provide word information beyond the lexicon. Finally, to verify the effectiveness of introducing the acoustic modality, we test some widely used multimodal models, such as CMA (Tsai et al., 2019) and MMI (Yu et al., 2020), on our dataset. Third, upon these strong baselines, we further propose"
2021.acl-long.218,2020.findings-emnlp.425,0,0.32266,"lassic example shown in Figure 1 can perfectly illustrate this point. In this example, the sentence with ambiguous word segmentation would be disambiguated with the aid of the acoustic modality, which would absolutely assist the model to infer correct NER tags. In this work, we make the following efforts to advance multimodal NER: CRF (Devlin et al., 2019). Then, since introducing a lexicon has been proven as an effective way to incorporate word information in Chinese NER (Zhang and Yang, 2018), we implement several lexicon-enhanced models, such as Lattice-LSTM (Zhang and Yang, 2018) and ZEN (Diao et al., 2020), to explore whether the acoustic modality can provide word information beyond the lexicon. Finally, to verify the effectiveness of introducing the acoustic modality, we test some widely used multimodal models, such as CMA (Tsai et al., 2019) and MMI (Yu et al., 2020), on our dataset. Third, upon these strong baselines, we further propose a simple Multi-Modal Multi-Task model (short for M3T) to make better use of the pause information in the acoustic modality. Specifically, different from coupling the visual modality with the textual modality, there is a monotonic alignment between the acousti"
2021.acl-long.218,P19-1141,0,0.0306561,"Missing"
2021.acl-long.218,doddington-etal-2004-automatic,0,0.0362605,"j-th waveform frame, the goal of the task is to leverage textual and speech clues to identify and classify all named entities contained in the text. 3.2 4.2 Dataset Comparison We compare CNERTA with several widely used NER datasets in Table 2. Specifically, we first compare our corpus with some Chinese NER datasets, such as MSRA (Levow, 2006), OntoNotes (Weischedel et al., 2011), Weibo NER (Peng and Dredze, 2016a) and Resume (Zhang and Yang, 2018). Then, we compare our corpus with several widely used nested NER datasets, like GENIA (Kim et al., 2003), JNLPBA (Collier and Kim, 2004), ACE-2004 (Doddington et al., 2004) and ACE-2005 (Walker et al., 2004). Finally, multimodal NER datasets, including Twitter-2015 (Zhang et al., 2018) and Twitter-2017 (Lu et al., 2018), are compared with our corpus. From Table 2, we observe that our corpus has unique value compared with the existing datasets. The value is reflected in the following aspects: (1) CNERTA is a large-scale dataset; (2) CNERTA is the first Chinese multimodal dataset; (3) Not only the topmost entities but also nested entities are annotated; (4) Among these datasets, the acoustic modality is only introduced in CNERTA. 4 4.1 Preliminaries Task Descripti"
2021.acl-long.218,D19-1096,0,0.0413513,"Missing"
2021.acl-long.218,W06-0115,0,0.0429611,"three parts: training, development, and test set. Table 1 shows the high level statistics of data splits for CNERTA. Given a text X = x1 , x2 , ..., xn and its corresponding speech S = s1 , s2 , ..., st , where xi denotes the i-th Chinese character and sj denotes the j-th waveform frame, the goal of the task is to leverage textual and speech clues to identify and classify all named entities contained in the text. 3.2 4.2 Dataset Comparison We compare CNERTA with several widely used NER datasets in Table 2. Specifically, we first compare our corpus with some Chinese NER datasets, such as MSRA (Levow, 2006), OntoNotes (Weischedel et al., 2011), Weibo NER (Peng and Dredze, 2016a) and Resume (Zhang and Yang, 2018). Then, we compare our corpus with several widely used nested NER datasets, like GENIA (Kim et al., 2003), JNLPBA (Collier and Kim, 2004), ACE-2004 (Doddington et al., 2004) and ACE-2005 (Walker et al., 2004). Finally, multimodal NER datasets, including Twitter-2015 (Zhang et al., 2018) and Twitter-2017 (Lu et al., 2018), are compared with our corpus. From Table 2, we observe that our corpus has unique value compared with the existing datasets. The value is reflected in the following aspe"
2021.acl-long.218,2020.acl-main.611,0,0.012065,"om two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computational Linguistics First, despite much recent success in multimodal NER, current studies on this topic are limited in English, and totally skirt other languages. Meanwhile, previous work on Chinese NER, such as Xu et al. (2013); Peng and Dredze (2016a); Zhang and Yang (2018); Cao et al. (2018); Sui et al. (2019); Gui et al. (2019); Ma et al. (2020); Li et al. (2020), totally ignores valuable multimodal information. With around 1.3 billion native speakers and the wide spread of short-form video apps in China, it is necessary and urgent to carry out research on Chinese multimodal NER. Second, unlike the static visual modality, the time-varying acoustic modality plays a unique role in Chinese NER, especially in providing precise word segmentation information. In detail, different from English, Chinese is an ideographic language featured by no word delimiter between words in written. This language characteristic is one of the major roadblocks in Chinese NER,"
2021.acl-long.218,N19-1247,0,0.0122547,"decoder, the widely used BiLSTM-CRF (Lample et al., 2016) is adopted as an important baseline. PLM-CRF: Instead of training a model from scratch, we also adopt the framework of fine-tuning a pretrained language model (PLM) on a downstream task (Radford et al., 2018). In this framework, we adopt BERT (Devlin et al., 2019) as the textual encoder and use CRF as the decoder. In addition to initializing the textual encoder with the original pretrained BERT model, a SoTA Chinese pretrained language model, called MacBERT (Cui et al., 2020), is used. Compared with BERT, MacBERT is built upon RoBERTa (Liu et al., 2019b) and the original MLM task in BERT is replaced with the MLM as correction task. For more details, we refer readers to Cui et al. (2020). 5.2 Lexicon-Enhanced Model: Based on the annotated dataset, a family of strong and representative baselines is established, including (1) text-only models presented in Section 5.1, (2) lexicon-enhanced models shown in Section 5.2 and (3) multimodal models introduced in Section 5.3. A drawback of the text-only methods mentioned above is that explicit word and word sequence information is not fully exploited, which can be potentially useful. With this conside"
2021.acl-long.218,P18-1185,0,0.0281341,"Missing"
2021.acl-long.218,2020.acl-main.528,0,0.0202317,"otivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computational Linguistics First, despite much recent success in multimodal NER, current studies on this topic are limited in English, and totally skirt other languages. Meanwhile, previous work on Chinese NER, such as Xu et al. (2013); Peng and Dredze (2016a); Zhang and Yang (2018); Cao et al. (2018); Sui et al. (2019); Gui et al. (2019); Ma et al. (2020); Li et al. (2020), totally ignores valuable multimodal information. With around 1.3 billion native speakers and the wide spread of short-form video apps in China, it is necessary and urgent to carry out research on Chinese multimodal NER. Second, unlike the static visual modality, the time-varying acoustic modality plays a unique role in Chinese NER, especially in providing precise word segmentation information. In detail, different from English, Chinese is an ideographic language featured by no word delimiter between words in written. This language characteristic is one of the major roadbloc"
2021.acl-long.218,P16-1101,0,0.0333306,"ifferent. Introduction “Speech is a part of thought.” — Oliver Sacks, Seeing Voices As a fundamental subtask of information extraction, named entity recognition (NER) aims to locate and classify named entities mentioned in unstructured texts into predefined semantic categories, such as person names, locations and organizations. NER plays a crucial role in many natural language processing (NLP) tasks, including relation extraction (Zelenko et al., 2003), question answering (Moll´a et al., 2006) and summarization (Aramaki et al., 2009). Most of the research on NER, such as Lample et al. (2016); Ma and Hovy (2016); Chiu and Nichols (2016), only relies on the textual modality to infer tags. However, when texts are noisy or short, and it is not sufficient to locate and classify named entities accurately only based on textual information (Baldwin et al., 2015; Lu et al., 2018). One promising solution is to introduce other modalities as the supplement of the textual modality. So far, some studies on multimodal NER, such as Moon et al. (2018); Zhang et al. (2018); Lu et al. (2018); Arshad et al. (2019); Asgari-Chenaghlu et al. (2020); Yu et al. (2020); Chen et al. (2020); Sun et al. (2020), have attempted t"
2021.acl-long.218,U06-1009,0,0.178673,"Missing"
2021.acl-long.218,N16-1030,0,0.477357,"ations are radically different. Introduction “Speech is a part of thought.” — Oliver Sacks, Seeing Voices As a fundamental subtask of information extraction, named entity recognition (NER) aims to locate and classify named entities mentioned in unstructured texts into predefined semantic categories, such as person names, locations and organizations. NER plays a crucial role in many natural language processing (NLP) tasks, including relation extraction (Zelenko et al., 2003), question answering (Moll´a et al., 2006) and summarization (Aramaki et al., 2009). Most of the research on NER, such as Lample et al. (2016); Ma and Hovy (2016); Chiu and Nichols (2016), only relies on the textual modality to infer tags. However, when texts are noisy or short, and it is not sufficient to locate and classify named entities accurately only based on textual information (Baldwin et al., 2015; Lu et al., 2018). One promising solution is to introduce other modalities as the supplement of the textual modality. So far, some studies on multimodal NER, such as Moon et al. (2018); Zhang et al. (2018); Lu et al. (2018); Arshad et al. (2019); Asgari-Chenaghlu et al. (2020); Yu et al. (2020); Chen et al. (2020); Sun et al. (202"
2021.acl-long.218,N18-1078,0,0.164262,"n (Zelenko et al., 2003), question answering (Moll´a et al., 2006) and summarization (Aramaki et al., 2009). Most of the research on NER, such as Lample et al. (2016); Ma and Hovy (2016); Chiu and Nichols (2016), only relies on the textual modality to infer tags. However, when texts are noisy or short, and it is not sufficient to locate and classify named entities accurately only based on textual information (Baldwin et al., 2015; Lu et al., 2018). One promising solution is to introduce other modalities as the supplement of the textual modality. So far, some studies on multimodal NER, such as Moon et al. (2018); Zhang et al. (2018); Lu et al. (2018); Arshad et al. (2019); Asgari-Chenaghlu et al. (2020); Yu et al. (2020); Chen et al. (2020); Sun et al. (2020), have attempted to couple the textual modality with the visual modality and witnessed a stable improvement. In this work, we also focus on multimodal NER. But differently from previous studies, we pay special attention to Chinese multimodal NER with both textual and acoustic contents. The motivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Join"
2021.acl-long.218,P16-2025,0,0.345455,"tudies, we pay special attention to Chinese multimodal NER with both textual and acoustic contents. The motivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computational Linguistics First, despite much recent success in multimodal NER, current studies on this topic are limited in English, and totally skirt other languages. Meanwhile, previous work on Chinese NER, such as Xu et al. (2013); Peng and Dredze (2016a); Zhang and Yang (2018); Cao et al. (2018); Sui et al. (2019); Gui et al. (2019); Ma et al. (2020); Li et al. (2020), totally ignores valuable multimodal information. With around 1.3 billion native speakers and the wide spread of short-form video apps in China, it is necessary and urgent to carry out research on Chinese multimodal NER. Second, unlike the static visual modality, the time-varying acoustic modality plays a unique role in Chinese NER, especially in providing precise word segmentation information. In detail, different from English, Chinese is an ideographic language featured by n"
2021.acl-long.218,2020.acl-demos.14,0,0.0168824,"(1) Lattice-LSTM (Zhang and Yang, 2018) is a classic method that can encode a sequence of input characters as well as all potential words that match a lexicon. (2) ZEN (Diao et al., 2020) is a pretrained Chinese text encoder enhanced by an n-gram lexicon. In ZEN, n-gram contexts are extracted, encoded and integrated with the character encoder. For more details about Lattice-LSTM and ZEN, we refer readers to Zhang and Yang (2018) and Diao et al. (2020). 5.1 5.3 5 Baselines Text-Only Model Open-Source NLP Toolkit: Many open-source NLP toolkits, such as spaCy (Honnibal et al., 2020) and Stanza (Qi et al., 2020), support Chinese NER. In spaCy, a multitask CNN is employed. In Stanza, a contextualized string representation based tagger from Akbik et al. (2018) is adopted. In both spaCy and Stanza, the tagger is trained on OntoNote (Weischedel et al., 2011). To map the output of taggers to CNERTA’s label space, expert-designed rules are used, such as PERSON → PER. Since these toolkits are only designed for flat structure, we do not evaluate these toolkits in nested settings. Multimodal Model To leverage the acoustic modality, several multimodal models are introduced. In these models, fusion modules are"
2021.acl-long.218,2020.coling-main.168,0,0.0327781,"e et al. (2016); Ma and Hovy (2016); Chiu and Nichols (2016), only relies on the textual modality to infer tags. However, when texts are noisy or short, and it is not sufficient to locate and classify named entities accurately only based on textual information (Baldwin et al., 2015; Lu et al., 2018). One promising solution is to introduce other modalities as the supplement of the textual modality. So far, some studies on multimodal NER, such as Moon et al. (2018); Zhang et al. (2018); Lu et al. (2018); Arshad et al. (2019); Asgari-Chenaghlu et al. (2020); Yu et al. (2020); Chen et al. (2020); Sun et al. (2020), have attempted to couple the textual modality with the visual modality and witnessed a stable improvement. In this work, we also focus on multimodal NER. But differently from previous studies, we pay special attention to Chinese multimodal NER with both textual and acoustic contents. The motivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computational Linguistics First, despite much rec"
2021.acl-long.218,P19-1656,0,0.0596754,"r correct NER tags. In this work, we make the following efforts to advance multimodal NER: CRF (Devlin et al., 2019). Then, since introducing a lexicon has been proven as an effective way to incorporate word information in Chinese NER (Zhang and Yang, 2018), we implement several lexicon-enhanced models, such as Lattice-LSTM (Zhang and Yang, 2018) and ZEN (Diao et al., 2020), to explore whether the acoustic modality can provide word information beyond the lexicon. Finally, to verify the effectiveness of introducing the acoustic modality, we test some widely used multimodal models, such as CMA (Tsai et al., 2019) and MMI (Yu et al., 2020), on our dataset. Third, upon these strong baselines, we further propose a simple Multi-Modal Multi-Task model (short for M3T) to make better use of the pause information in the acoustic modality. Specifically, different from coupling the visual modality with the textual modality, there is a monotonic alignment between the acoustic modality and the textual modality. Armed with such an alignment, the position of each Chinese character in the continuous speech would be determined, which would make it easy to discover pauses between adjacent words. Therefore, to automati"
2021.acl-long.218,W95-0107,0,0.123723,"e value is reflected in the following aspects: (1) CNERTA is a large-scale dataset; (2) CNERTA is the first Chinese multimodal dataset; (3) Not only the topmost entities but also nested entities are annotated; (4) Among these datasets, the acoustic modality is only introduced in CNERTA. 4 4.1 Preliminaries Task Description Nested Structure Linearization Unlike flat NER, named entities may overlap and also be labeled with more than one label in nested NER. To solve nested NER, we follow Strakov´a et al. (2019) to encode the nested entity structure into a CoNLL-like, per-character BIO encoding (Ramshaw and Marcus, 1995). There are two rules to guide the linearization: (1) entity mentions starting earlier have priority over entities starting later, and (2) for mentions with the same beginning, longer entity mentions have priority over shorter ones. A multilabel for a given Chinese character is a concatenation of all intersecting entity mentions, from the highest priority to the lowest. For more details, we refer readers to Strakov´a et al. (2019). 2810 4.3 Acoustic Encoder The acoustic encoder is used to map raw speech signals into continuous space. There are three parts in the proposed acoustic encoder: a sp"
2021.acl-long.218,E12-2021,0,0.0773052,"Missing"
2021.acl-long.218,P19-1527,0,0.0432651,"Missing"
2021.acl-long.218,2020.coling-main.340,0,0.0476125,"Missing"
2021.acl-long.218,2020.acl-main.306,0,0.445007,"of the research on NER, such as Lample et al. (2016); Ma and Hovy (2016); Chiu and Nichols (2016), only relies on the textual modality to infer tags. However, when texts are noisy or short, and it is not sufficient to locate and classify named entities accurately only based on textual information (Baldwin et al., 2015; Lu et al., 2018). One promising solution is to introduce other modalities as the supplement of the textual modality. So far, some studies on multimodal NER, such as Moon et al. (2018); Zhang et al. (2018); Lu et al. (2018); Arshad et al. (2019); Asgari-Chenaghlu et al. (2020); Yu et al. (2020); Chen et al. (2020); Sun et al. (2020), have attempted to couple the textual modality with the visual modality and witnessed a stable improvement. In this work, we also focus on multimodal NER. But differently from previous studies, we pay special attention to Chinese multimodal NER with both textual and acoustic contents. The motivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computatio"
2021.acl-long.218,P18-1144,0,0.237485,"tention to Chinese multimodal NER with both textual and acoustic contents. The motivation comes from two aspects: 2807 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2807–2818 August 1–6, 2021. ©2021 Association for Computational Linguistics First, despite much recent success in multimodal NER, current studies on this topic are limited in English, and totally skirt other languages. Meanwhile, previous work on Chinese NER, such as Xu et al. (2013); Peng and Dredze (2016a); Zhang and Yang (2018); Cao et al. (2018); Sui et al. (2019); Gui et al. (2019); Ma et al. (2020); Li et al. (2020), totally ignores valuable multimodal information. With around 1.3 billion native speakers and the wide spread of short-form video apps in China, it is necessary and urgent to carry out research on Chinese multimodal NER. Second, unlike the static visual modality, the time-varying acoustic modality plays a unique role in Chinese NER, especially in providing precise word segmentation information. In detail, different from English, Chinese is an ideographic language featured by no word delimiter between"
2021.acl-long.276,P98-1013,0,0.194369,"e take causal sentence generation via lexical knowledge expanding as an example. erative architecture to generate new well-formed causal/non-causal sentences that contain them. Knowledge Guiding KSG introduces event pairs that are probabilistic causal or non-causal from multiple knowledge bases in two ways. (1) Lexical knowledge expanding: expanding annotated event pairs via external dictionaries, such as WordNet (Miller, 1995) and VerbNet (Schuler, 2005). (2) Connective knowledge introducing: introducing event pairs from external event-annotated documents (KBP corpus) assisted with FrameNet (Baker et al., 1998) and Penn Discourse Treebank (PDTB2) (Group et al., 2008). As shown in Table 1, we illustrate how to extract event pairs from multiple knowledge bases. Then, inspired by Bordes et al. (2013), we filter the extracted event pairs by converting them into triples &lt;ei , causal/noncausal, ej &gt; and calculating the causal-distance by maximizing L in a causal representation space: L= X X [λ + d(e0i , e0j ) − d(ei , ej )]+ , (3) (ei ,ej )∈T (e0i ,e0j )∈T 0 (2) where θG is the parameter of G, c is the input relation, t is one of the generated tokens Ts of the generated sentence s0 , and p(t|c; θG ) is th"
2021.acl-long.276,P19-1007,0,0.0585267,"Missing"
2021.acl-long.276,2020.acl-main.608,0,0.0678662,"Missing"
2021.acl-long.276,W17-2711,0,0.235676,"between two events in a sentence. For example in Figure 1, an ECI system should identify two causal relations in cause two sentences: (1) attack −→ killed in S1; (2) cause statement −→ protests in S2. Most existing methods for ECI heavily rely on annotated training data (Mirza and Tonelli, 2016; Riaz and Girju, 2014b; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019). However, existing datasets are relatively small, which impede the training of the high-performance event causality reasoning model. According to our statistics, the largest widely used dataset EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. Therefore, data lacking is an essential problem that urgently needs to be addressed for ECI. Up to now, data augmentation is one of the most effective methods to solve the data lacking problem. However, most of the NLP-related augmentation methods are a task-independent framework that produces new data at one time (Zhang et al., 2015; Guo et al., 2019; Xie et al., 2019b). In these frameworks, data augmentation and target task are modeled independently. This often leads to a lack of task-related characteristics in the ge"
2021.acl-long.276,P16-1135,0,0.0207477,"generated causal sentences via iteratively learning in the dual interaction. • Experimental results on two benchmarks show that our model achieves the best performance on ECI. Moreover, it also shows definite advantages over previous data augmentation methods. 2 Related Work To date, many researches attempt to identify the causality with linguistic patterns or statistical features. For example, some methods rely on syntactic and lexical features (Riaz and Girju, 2013, 2014b). Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016). And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017). Recently, more attention is paid to the causality between events. Mirza and Tonelli (2014) annotated Causal-TimeBank of event-causal relations based on the TempEval-3 corpus. Mirza et al. (2014), Mirza and Tonelli (2016) extracted eventcausal relation with a rule-based multi-sieve approach and improved the performance incorporating with event temporal relation. Mostafazadeh et al. (2016) annotated both temporal and causal relations in 320 short stories. Cas"
2021.acl-long.276,W17-2708,0,0.0239346,"that our model achieves the best performance on ECI. Moreover, it also shows definite advantages over previous data augmentation methods. 2 Related Work To date, many researches attempt to identify the causality with linguistic patterns or statistical features. For example, some methods rely on syntactic and lexical features (Riaz and Girju, 2013, 2014b). Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016). And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017). Recently, more attention is paid to the causality between events. Mirza and Tonelli (2014) annotated Causal-TimeBank of event-causal relations based on the TempEval-3 corpus. Mirza et al. (2014), Mirza and Tonelli (2016) extracted eventcausal relation with a rule-based multi-sieve approach and improved the performance incorporating with event temporal relation. Mostafazadeh et al. (2016) annotated both temporal and causal relations in 320 short stories. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for 3559 Knowledge relation-&gt;sentence-&gt;relation Annotate"
2021.acl-long.276,W17-5540,0,0.136483,"s in texts, which can provide crucial clues for NLP tasks, such as logical reasoning and question answering (Girju, 2003; Oh et al., 2013, 2017). This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. For example in Figure 1, an ECI system should identify two causal relations in cause two sentences: (1) attack −→ killed in S1; (2) cause statement −→ protests in S2. Most existing methods for ECI heavily rely on annotated training data (Mirza and Tonelli, 2016; Riaz and Girju, 2014b; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019). However, existing datasets are relatively small, which impede the training of the high-performance event causality reasoning model. According to our statistics, the largest widely used dataset EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. Therefore, data lacking is an essential problem that urgently needs to be addressed for ECI. Up to now, data augmentation is one of the most effective methods to solve the data lacking problem. However, most of the NLP-related augmentation methods are a task-inde"
2021.acl-long.276,P14-3002,0,0.0281709,"017), a dependency path based 4 https://github.com/google-research/ bert 3563 sequential model that models the context between events to identify causality; 2) Seq (Choubey and Huang, 2017), a sequence model explores complex human designed features for ECI; 3) LR+ and ILP (Gao et al., 2019), document-level models adopt document structures for ECI. For Causal-TB, we prefer 1) RB, a rule-based system; 2) DD, a data driven machine learning based system; 3) VR-C, a verb rule based model with data filtering and gold causal signals enhancement. These models are designed by Mirza and Tonelli (2014); Mirza (2014) for ECI. Owing to our methods are constructed on BERT, we build BERT-based methods: 1) BERT, a BERTbased baseline, our basic proposed event causality identifier. 2) MM (Liu et al., 2020), the BERTbased SOTA method with mention masking generalization. 3) MM+Aug, the further re-trained MM with our dual augmented data. 4) KnowDis (Zuo et al., 2020) improved the performance of ECI with the distantly labeled training data. We compare with it to illustrate the quality of our generated ECI-related training data. 5) MM+ConceptAug, to make a fair comparison, we introduce causalrelated events from Conc"
2021.acl-long.276,W14-0702,0,0.0314991,"th linguistic patterns or statistical features. For example, some methods rely on syntactic and lexical features (Riaz and Girju, 2013, 2014b). Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016). And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017). Recently, more attention is paid to the causality between events. Mirza and Tonelli (2014) annotated Causal-TimeBank of event-causal relations based on the TempEval-3 corpus. Mirza et al. (2014), Mirza and Tonelli (2016) extracted eventcausal relation with a rule-based multi-sieve approach and improved the performance incorporating with event temporal relation. Mostafazadeh et al. (2016) annotated both temporal and causal relations in 320 short stories. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for 3559 Knowledge relation-&gt;sentence-&gt;relation Annotated Data Pre-training event pair (ep) R causal/non-causal relation (c) Primal Cycle sentence-&gt;relation-&gt;sentence G Dual Cycle Pre-trained Generator causal/ non-causal relaiton event pair Pre-trained Identifier Learnable"
2021.acl-long.276,C14-1198,0,0.104622,"vious data augmentation methods. 2 Related Work To date, many researches attempt to identify the causality with linguistic patterns or statistical features. For example, some methods rely on syntactic and lexical features (Riaz and Girju, 2013, 2014b). Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016). And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017). Recently, more attention is paid to the causality between events. Mirza and Tonelli (2014) annotated Causal-TimeBank of event-causal relations based on the TempEval-3 corpus. Mirza et al. (2014), Mirza and Tonelli (2016) extracted eventcausal relation with a rule-based multi-sieve approach and improved the performance incorporating with event temporal relation. Mostafazadeh et al. (2016) annotated both temporal and causal relations in 320 short stories. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for 3559 Knowledge relation-&gt;sentence-&gt;relation Annotated Data Pre-training event pair (ep) R causal/non-causal relation (c) Primal Cycle sentence-&gt;relation-&gt;sentence G D"
2021.acl-long.276,W14-4322,0,0.148529,"aims to identify causal relations between events in texts, which can provide crucial clues for NLP tasks, such as logical reasoning and question answering (Girju, 2003; Oh et al., 2013, 2017). This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. For example in Figure 1, an ECI system should identify two causal relations in cause two sentences: (1) attack −→ killed in S1; (2) cause statement −→ protests in S2. Most existing methods for ECI heavily rely on annotated training data (Mirza and Tonelli, 2016; Riaz and Girju, 2014b; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019). However, existing datasets are relatively small, which impede the training of the high-performance event causality reasoning model. According to our statistics, the largest widely used dataset EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. Therefore, data lacking is an essential problem that urgently needs to be addressed for ECI. Up to now, data augmentation is one of the most effective methods to solve the data lacking problem. However, most of the NL"
2021.acl-long.276,C16-1007,0,0.131821,"ity identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for NLP tasks, such as logical reasoning and question answering (Girju, 2003; Oh et al., 2013, 2017). This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. For example in Figure 1, an ECI system should identify two causal relations in cause two sentences: (1) attack −→ killed in S1; (2) cause statement −→ protests in S2. Most existing methods for ECI heavily rely on annotated training data (Mirza and Tonelli, 2016; Riaz and Girju, 2014b; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019). However, existing datasets are relatively small, which impede the training of the high-performance event causality reasoning model. According to our statistics, the largest widely used dataset EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. Therefore, data lacking is an essential problem that urgently needs to be addressed for ECI. Up to now, data augmentation is one of the most effective methods to solve the data lacking problem. H"
2021.acl-long.276,W14-0707,0,0.126083,"aims to identify causal relations between events in texts, which can provide crucial clues for NLP tasks, such as logical reasoning and question answering (Girju, 2003; Oh et al., 2013, 2017). This task is usually modeled as a classification problem, i.e. determining whether there is a causal relation between two events in a sentence. For example in Figure 1, an ECI system should identify two causal relations in cause two sentences: (1) attack −→ killed in S1; (2) cause statement −→ protests in S2. Most existing methods for ECI heavily rely on annotated training data (Mirza and Tonelli, 2016; Riaz and Girju, 2014b; Hashimoto et al., 2014; Hu and Walker, 2017; Gao et al., 2019). However, existing datasets are relatively small, which impede the training of the high-performance event causality reasoning model. According to our statistics, the largest widely used dataset EventStoryLine Corpus (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. Therefore, data lacking is an essential problem that urgently needs to be addressed for ECI. Up to now, data augmentation is one of the most effective methods to solve the data lacking problem. However, most of the NL"
2021.acl-long.276,W16-1007,0,0.0177884,"s (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016). And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017). Recently, more attention is paid to the causality between events. Mirza and Tonelli (2014) annotated Causal-TimeBank of event-causal relations based on the TempEval-3 corpus. Mirza et al. (2014), Mirza and Tonelli (2016) extracted eventcausal relation with a rule-based multi-sieve approach and improved the performance incorporating with event temporal relation. Mostafazadeh et al. (2016) annotated both temporal and causal relations in 320 short stories. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for 3559 Knowledge relation-&gt;sentence-&gt;relation Annotated Data Pre-training event pair (ep) R causal/non-causal relation (c) Primal Cycle sentence-&gt;relation-&gt;sentence G Dual Cycle Pre-trained Generator causal/ non-causal relaiton event pair Pre-trained Identifier Learnable Dual Augmentation Architecture Causal-Generator Rs NCausal-Generator Rc Dual-trained Identifier Rc Further training Sentence→Relation I Full-trained Identifier ep, c&apos; Primal Cycle Figure 2: Overvi"
2021.acl-long.276,P13-1170,0,0.0385941,"Missing"
2021.acl-long.276,P02-1040,0,0.109347,"impact on ECI; 2) Back translation introduces limited new causal expressions by translation, thus it slightly increases the recall value on ECI; 3) EDA can introduce new expressions via substitution, but the augmented data is not canonical and cannot accurately express the causality, therefore, its impact on ECI is also limited. Quantitative Evaluation of Task-relevance We select five Ph.D. students majoring in NLP to manual score the 100 randomly selected augmented sentences given their corresponding original sentences as reference (Cohen’s kappa = 0.85). Furthermore, we calculate the BLEU (Papineni et al., 2002) value to further evaluate the 3565 Generator Dual reward feedback A was crash by B because C targeted ... A was crash by B as C targeted ... Identifier non-causal relation a) ate task-related sentences for ECI. Moreover, our framework is knowledge guided and learnable. Our method achieves state-of-the-art performance on EventStoryLine and Causal-TimeBank datasets. ... A order when B attack ... &lt;crash, target&gt; causal relation Generator non-causal relation causal relation Dual reward feedback Acknowledgments Identifier &lt;order, attack&gt; ... A ordered B to attack ... b) Figure 6: The modification"
2021.acl-long.276,W13-4004,0,0.0265743,"generated causal sentences. We also employ a constrained generative architecture to gradually generate well-formed causal linguistic expressions of generated causal sentences via iteratively learning in the dual interaction. • Experimental results on two benchmarks show that our model achieves the best performance on ECI. Moreover, it also shows definite advantages over previous data augmentation methods. 2 Related Work To date, many researches attempt to identify the causality with linguistic patterns or statistical features. For example, some methods rely on syntactic and lexical features (Riaz and Girju, 2013, 2014b). Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016). And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017). Recently, more attention is paid to the causality between events. Mirza and Tonelli (2014) annotated Causal-TimeBank of event-causal relations based on the TempEval-3 corpus. Mirza et al. (2014), Mirza and Tonelli (2016) extracted eventcausal relation with a rule-based multi-sieve approach and improved the p"
2021.acl-long.276,P19-1178,0,0.0633589,"Missing"
2021.acl-long.276,2020.acl-main.52,0,0.024628,"ard R consists of a causality reward Rc from itself and a semantic alignment reward Rs from G (dual cycle). I and G are optimized interactively with dual reinforcement learning. Specifically, for G, an action is the generation from relation to sentence, a state is denoted by the representation of input event pair and its relation, a policy is defined by the parameters of generator. For I, an action is the identification from sentence to relation, a state is denoted by the representation of input event pair and its 3560 sentence, a policy is defined by the parameters of identifier. Inspired by Shen and Feng (2020), we utilize a probability distribution over actions given states to represent the policys, i.e., the probability distribution of the generation of G and identification of I. As aforementioned, we introduce two rewards, causality (Rc ) and semantic alignment (Rs ) rewards, which encourage G to generate taskrelated sentences with the feedback from identifier, while further optimize I with the feedback from generator. Definitions are as following: Causality Reward (Rc ) If the relation of input event pair can be clearly expressed by the generated sentence, it will be easier to be understood by i"
2021.acl-long.276,P19-1545,0,0.0548547,"Missing"
2021.acl-long.276,2020.acl-main.63,0,0.0488736,"Missing"
2021.acl-long.276,D18-1236,0,0.0620774,"Missing"
2021.acl-long.276,D15-1306,0,0.053515,"Missing"
2021.acl-long.276,D19-1670,0,0.0193009,"problem that urgently needs to be addressed for ECI. Up to now, data augmentation is one of the most effective methods to solve the data lacking problem. However, most of the NLP-related augmentation methods are a task-independent framework that produces new data at one time (Zhang et al., 2015; Guo et al., 2019; Xie et al., 2019b). In these frameworks, data augmentation and target task are modeled independently. This often leads to a lack of task-related characteristics in the generated data, such as taskrelated linguistic expression and knowledge. For example, easy data augmentation (EDA) (Wei and Zou, 2019) is the most representative method that relies on lexical substitution, deletion, swapping, and insertion to produce new data. However, solely relying on such word operations often generates new data that dissatisfies task-related qualities. As shown in Figure 1, S3 is produced by EDA, it lacks a linguistic expression that expresses the causal semantics between kill and attack. Therefore, how to 3558 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3558–3571 August 1–6, 2021"
2021.acl-long.276,P19-1522,0,0.117495,"e mention masking generalization. Unlike computer vision, the augmentation of text data in NLP is pretty rare (Chaudhary, 2020). Zuo et al. (2020) solved the data lacking problem of ECI with the distantly supervised labeled training data. However, including the distant supervision, most of the existing data augmentation methods for NLP tasks are task-independent frameworks (Related work of data augmentation and dual learning are detailed in Appendix B). Inspired by some generative methods which try to generate additional training data while preserving the class label (AnabyTavor et al., 2019; Yang et al., 2019; Papanikolaou and Pierleoni, 2020), we introduce a new learnable framework for augmenting task-related training data for ECI via dual learning enhanced with external knowledge. 3 ep, s&apos; Rs Dual Augmented Data causal/ non-causal sentence Relation→Sentence Methodology As shown in Figure 2, LearnDA jointly models a knowledge guided sentence generator (input: event pair and its causal/non-causal relation, output: causal/non-causal sentence) and an event causality identifier (input: event pair and its sentence, output: causal/non-causal relation) with dual learning. LearnDA iteratively optimizes i"
2021.acl-long.376,D14-1159,0,0.0805137,"Missing"
2021.acl-long.376,P19-1470,0,0.0232665,"unds e1 to a concept via matching the event mention with the tokens of concepts in C ONCEPT N ET. We enhance the matching approach with some rules, such as soft matching with lemmatization and filtering of stop words. The grounded concept is called zero-hop concept. Then, our method grows zero-hop concept with one-hop concepts. The zero-hop concept, one-hop concepts and all relations between them form the descriptive graph for e1 (denoted as Gd1 ). (2) If the descriptive knowledge cannot be retrieved from the KB, we adopt the generation method. Our method employs the pre-trained model, COMET (Bosselut et al., 2019), which is originally proposed for the knowledge base completion. Specifically, COMET is obtained by finetuning GPT (Radford et al., 2018) on C ONCEPTN ET. The input of COMET is the head event and candidate relation, and the output is the tail event. The relation types are the same as the ones used in Bosselut et al. (2019). By leveraging COMET, we can generate the descriptive graph Gd1 for e1 . In the same way, we can also construct the descriptive graph Gd2 for e2 . 3.2.2 Knowledge Encoding Graph neural networks have been widely used to encode graph-structured data (Lin et al., 2019; Yang et"
2021.acl-long.376,W17-2711,0,0.254172,"l., 2013) and future event prediction (Radinsky et al., 2012; Hashimoto et al., 2014). Identifying event causal relation is inherently challenging, because event causality is usually expressed in diverse forms that often lack explicit clues indicating its existence. For example in Figure 1, the sentence has no explicit clue indicating the causal relation between “global warming” and “tsunami”. In this scenario, models can resort to a large amount of labeled data to learn diverse causal expressions. However, existing ECI datasets are very small. For example, the largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, which is not sufficient to train neural network models (Liu et al., 2020). Consequently, models cannot thoroughly understand the text and possibly make a wrong prediction. Nonetheless, humans could make a correct judgement, because humans have the background knowledge about the two events. To be more specific, humans not only know what the two events are, but also know the connection between them. Fortunately, existing knowledge bases (KBs) usually contain the Descriptive Knowledge of events and Relational Knowledge between events, which can be regarded as the bac"
2021.acl-long.376,P17-2001,0,0.0542099,"Missing"
2021.acl-long.376,D17-1190,0,0.123547,"evaluate our proposed method on two widely used datasets, including EventStoryLine (Caselli and Vossen, 2017) and Causal-TimeBank (Mirza et al., 2014). For EventStoryLine, the dataset contains 258 documents, 5,334 events in total, and 1,770 of 7,805 event pairs are causally related. For Causal-TimeBank, the dataset contains 184 documents, 6,813 events, and 318 of 7,608 event pairs are causally related. We conduct the 5-fold and 10fold cross-validation on the EventStoryLine dataset and Causal-TimeBank dataset respectively, same as previous methods to ensure fairness. Following previous works (Choubey and Huang, 2017; Gao et al., 2019), we adopt Precision (P), Recall (R) and F1-score (F1) as evaluation metrics. 4.2 Parameter Settings In our implementations, our method uses the HuggingFace’s Transformers library4 to implement the uncased BERT base model, which has 12-layers, 768-hidden, and 12-heads. The learning rate is initialized as 2e-5 with a linear decay. We use the Adam algorithm (Kingma and Ba, 2015) to optimize model parameters. The batch size is set to 20. The number of induction blocks (i.e., N ) is set to 2. The dropout of GCN is set to 0.3. Due to the sparseness of positive examples, we adopt"
2021.acl-long.376,N19-1423,0,0.00505751,"ptive knowledge for each event, and then encodes the graph-structured knowledge; (3) Relational Graph Induction (§3.3), which automatically induces a reasoning structure and performs causality reasoning on the induced structure. We will illustrate each component in detail. 3.1 Context Encoding Given a sentence with a pair of events (denoted as e1 and e2 ), the context encoding module aims to extract context features, which takes the sentence as input and outputs the context representations. Our context encoder is based on the Transformer architecture (Vaswani et al., 2017). We adopt the BERT (Devlin et al., 2019) to encode the input sentence,2 which has achieved the state-of-the-art performance for ECI task (Liu et al., 2020; Zuo et al., 2020). After using BERT encoder to compute the contextual representations of the entire sentence, we concatenate representations of [CLS], e1 and e2 as the context representation regarding to the event pair (e1 , e2 ), namely (e ,e2 ) FC 1 Methodology 2 Following previous works (Ning et al., 2018; Liu et al., 2020), we formulate ECI as a binary clas= h[CLS] ⊕ he1 ⊕ he2 , (1) Note that the encoder is not our focus in this paper. In fact, other models like convolutional"
2021.acl-long.376,D11-1027,0,0.0214556,"ted in the KB; (2) Not all the knowledge on the path is related to causality, such as (sea-level rising, AtLocation, ocean). Therefore, directly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house CapableOf tsunami Causes Knowledge Encoding death ocean Descriptive Knowledge Representat"
2021.acl-long.376,N19-1179,0,0.0565021,"in the wikipedia page of “sea-level rising”1 , while it is not annotated in the KB; (2) Not all the knowledge on the path is related to causality, such as (sea-level rising, AtLocation, ocean). Therefore, directly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house CapableOf tsunami Caus"
2021.acl-long.376,Q19-1019,0,0.0218713,"∈ Rd . We first calculate the pair-wise unnormalized attention score sij between the i-th node and the j-th node: where δ is the Kronecker delta (Koo et al., 2007) and ·−1 denotes matrix inversion. Ar can be regarded as a weighted adjacency matrix of the graph Gr . Finally, Ar is fed into the iterative refinement for event causality reasoning. 3.3.3 Iterative Refinement After obtaining the relational graph structure, we perform event causality reasoning on the induced structure. To better capture potential reasoning clues, we adopt the densely connected graph convolutional networks (DCGCNs) (Guo et al., 2019), which allows training a deeper reasoning model. The convolution computation of each layer is: (l) vi nr X (l) = ρ( Arij Wv(l) gj + b(l) v ), T (10) j=1 sij = (tanh(Wp mi )) Wb (tanh(Wc mj )), (4) (l) where Wp and Wc are weights matrixes. Wb are the weights for the bilinear transformation. Next, we compute the root score sri which represents the unnormalized probability of the i-th node to be selected as the root node of the structure: sri = Wr mi , (5) where Wr ∈ R1×d is the weight for linear transformation. Suppose the graph Gr has nr nodes, we first assign non-negative weights P ∈ Rnr ×nr"
2021.acl-long.376,D19-1296,0,0.0119862,"ectly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house CapableOf tsunami Causes Knowledge Encoding death ocean Descriptive Knowledge Representation Descriptive Graph Relational Knowledge Representation Relational Graph Induction global warming Causes sea-level rising CapableOf tsunam"
2021.acl-long.376,P14-1093,0,0.169075,"ledge base. Introduction Event causality identification (ECI) aims to identify causal relation of events in texts. For example, in the sentence “The earthquake generated a tsunami.”, an ECI model should be able to identify a causal relationship that holds between the two cause mentioned events, i.e., earthquake −−−→ tsunami. ECI is an important task in natural language processing (NLP) area and can support many NLP applications, such as machine reading comprehension (Berant et al., 2014), process extraction (Thalappillil Scaria et al., 2013) and future event prediction (Radinsky et al., 2012; Hashimoto et al., 2014). Identifying event causal relation is inherently challenging, because event causality is usually expressed in diverse forms that often lack explicit clues indicating its existence. For example in Figure 1, the sentence has no explicit clue indicating the causal relation between “global warming” and “tsunami”. In this scenario, models can resort to a large amount of labeled data to learn diverse causal expressions. However, existing ECI datasets are very small. For example, the largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, which is not sufficient to tra"
2021.acl-long.376,W17-2708,0,0.0207882,") Not all the knowledge on the path is related to causality, such as (sea-level rising, AtLocation, ocean). Therefore, directly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house CapableOf tsunami Causes Knowledge Encoding death ocean Descriptive Knowledge Representation Descriptive Gr"
2021.acl-long.376,W17-5540,0,0.0235892,"cean). Therefore, directly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house CapableOf tsunami Causes Knowledge Encoding death ocean Descriptive Knowledge Representation Descriptive Graph Relational Knowledge Representation Relational Graph Induction global warming Causes sea-level risin"
2021.acl-long.376,D19-1590,0,0.0116605,"auses Knowledge Encoding death ocean Descriptive Knowledge Representation Descriptive Graph Relational Knowledge Representation Relational Graph Induction global warming Causes sea-level rising CapableOf tsunami AtLocation glacier melting ocean AtLocation Iterative Refinement Structure Induction Relational Graph Relational Path global Causes tsunami warming Figure 2: The architecture of our proposed latent structure induction network for event causality identification. network-based methods have been proposed for the task and achieved the state-of-the-art performance (Kruengkrai et al., 2017; Kadowaki et al., 2019; Liu et al., 2020; Zuo et al., 2020). Liu et al. (2020) propose a mention masking generalization method and also consider the external structural knowledge. The very recent work (Zuo et al., 2020) propose a data augmentation method to alleviate the data lacking problem for the task. Regarding datasets construction, Mirza (2014) annotates the CausalTimeBank dataset about event causal relations in the TempEval-3 corpus. Caselli and Vossen (2017) construct a dataset called EventStoryLine for event causality identification. Despite many efforts for this task, most existing methods typically train"
2021.acl-long.376,D07-1015,0,0.351579,"andomly select one path for avoiding information redundancy. 3.3.2 Structure Induction To capture potentially useful information and reduce the impact of irrelevant knowledge on the relational path, our model treats the reasoning structure as a latent variable and induces it with the 4865 3 https://networkx.org input of the relational path, which can be shown in Figure 2. We call the induced reasoning structure as Relational Graph (denoted as Gr ). The structure induction module is built based on the structured attention (Kim et al., 2017). We use a variant of Kirchhoff’s Matrix-Tree Theorem (Koo et al., 2007; Nan et al., 2020) to learn the graph structure. Formally, the nodes of relational graph are the concepts on the relational path. The initialized representation of each node is obtained via the pretrained model (i.e., BERT). The representation of the i-th node is denoted as mi ∈ Rd . We first calculate the pair-wise unnormalized attention score sij between the i-th node and the j-th node: where δ is the Kronecker delta (Koo et al., 2007) and ·−1 denotes matrix inversion. Ar can be regarded as a weighted adjacency matrix of the graph Gr . Finally, Ar is fed into the iterative refinement for ev"
2021.acl-long.376,P14-3002,0,0.018477,"uses tsunami warming Figure 2: The architecture of our proposed latent structure induction network for event causality identification. network-based methods have been proposed for the task and achieved the state-of-the-art performance (Kruengkrai et al., 2017; Kadowaki et al., 2019; Liu et al., 2020; Zuo et al., 2020). Liu et al. (2020) propose a mention masking generalization method and also consider the external structural knowledge. The very recent work (Zuo et al., 2020) propose a data augmentation method to alleviate the data lacking problem for the task. Regarding datasets construction, Mirza (2014) annotates the CausalTimeBank dataset about event causal relations in the TempEval-3 corpus. Caselli and Vossen (2017) construct a dataset called EventStoryLine for event causality identification. Despite many efforts for this task, most existing methods typically train the models on manually labeled data solely, rarely considering the external structural knowledge. As a result, these methods cannot handle well the cases where there is no explicit causal clue. Although Liu et al. (2020) leverage the descriptive knowledge to enrich event representations, they directly retrieve the descriptive k"
2021.acl-long.376,W14-0702,0,0.0310344,"inary classification by taking Fe1 ,e2 as input: pe1 ,e2 = softmax(Ws Fe1 ,e2 + bs ). (13) For training, we adopt cross entropy as the loss function: X X J(Θ) = − yei ,ej log(pei ,ej ), (14) s∈D ei ,ej ∈Es ei 6=ej 4866 where Θ denotes the model parameters. s denotes a sentence in the training set D. Es is the set of events in sentence s. yei ,ej is a one-hot vector representing the gold label between ei and ej . 4 4.1 Experiments Datasets and Evaluation Metrics We evaluate our proposed method on two widely used datasets, including EventStoryLine (Caselli and Vossen, 2017) and Causal-TimeBank (Mirza et al., 2014). For EventStoryLine, the dataset contains 258 documents, 5,334 events in total, and 1,770 of 7,805 event pairs are causally related. For Causal-TimeBank, the dataset contains 184 documents, 6,813 events, and 318 of 7,608 event pairs are causally related. We conduct the 5-fold and 10fold cross-validation on the EventStoryLine dataset and Causal-TimeBank dataset respectively, same as previous methods to ensure fairness. Following previous works (Choubey and Huang, 2017; Gao et al., 2019), we adopt Precision (P), Recall (R) and F1-score (F1) as evaluation metrics. 4.2 Parameter Settings In our i"
2021.acl-long.376,C14-1198,0,0.0547001,"Missing"
2021.acl-long.376,2020.acl-main.141,0,0.0775993,"path for avoiding information redundancy. 3.3.2 Structure Induction To capture potentially useful information and reduce the impact of irrelevant knowledge on the relational path, our model treats the reasoning structure as a latent variable and induces it with the 4865 3 https://networkx.org input of the relational path, which can be shown in Figure 2. We call the induced reasoning structure as Relational Graph (denoted as Gr ). The structure induction module is built based on the structured attention (Kim et al., 2017). We use a variant of Kirchhoff’s Matrix-Tree Theorem (Koo et al., 2007; Nan et al., 2020) to learn the graph structure. Formally, the nodes of relational graph are the concepts on the relational path. The initialized representation of each node is obtained via the pretrained model (i.e., BERT). The representation of the i-th node is denoted as mi ∈ Rd . We first calculate the pair-wise unnormalized attention score sij between the i-th node and the j-th node: where δ is the Kronecker delta (Koo et al., 2007) and ·−1 denotes matrix inversion. Ar can be regarded as a weighted adjacency matrix of the graph Gr . Finally, Ar is fed into the iterative refinement for event causality reaso"
2021.acl-long.376,P18-1212,0,0.0495353,"Missing"
2021.acl-long.376,D19-1282,0,0.102953,"T (Bosselut et al., 2019), which is originally proposed for the knowledge base completion. Specifically, COMET is obtained by finetuning GPT (Radford et al., 2018) on C ONCEPTN ET. The input of COMET is the head event and candidate relation, and the output is the tail event. The relation types are the same as the ones used in Bosselut et al. (2019). By leveraging COMET, we can generate the descriptive graph Gd1 for e1 . In the same way, we can also construct the descriptive graph Gd2 for e2 . 3.2.2 Knowledge Encoding Graph neural networks have been widely used to encode graph-structured data (Lin et al., 2019; Yang et al., 2019), as they are able to effectively collect relevant evidence based on an information aggregation scheme. In addition, many works show that relational graph convolutional networks (RGCNs) (Schlichtkrull et al., 2018) usually overparameterize the model and cannot effectively utilize multi-hop relational information (Zhang et al., 2018; Lin et al., 2019). We thus apply GCNs (Kipf and Welling, 2017) to encode the related descriptive knowledge of e1 and e2 . Formally, given a descriptive graph Gd (i.e., Gd1 or Gd2 ) with nd nodes (i.e., concepts), which can be represented with an"
2021.acl-long.376,W13-4004,0,0.0293358,"tsunami) is described in the wikipedia page of “sea-level rising”1 , while it is not annotated in the KB; (2) Not all the knowledge on the path is related to causality, such as (sea-level rising, AtLocation, ocean). Therefore, directly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house Cap"
2021.acl-long.376,W14-4322,0,0.0261063,"lity, such as (sea-level rising, AtLocation, ocean). Therefore, directly reasoning along the multi-hop path struc1 https://en.wikipedia.org/wiki/Sea_ level_rise 2 Related Work Event causality identification (ECI) is a very important task in natural language processing area, which has attracted extensive attention in the past few years. Early studies for the task are feature-based methods which utilize lexical and syntactic features (Riaz and Girju, 2013; Gao et al., 2019), explicit causal patterns (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), and statistical causal associations (Riaz and Girju, 2014; Hashimoto et al., 2014; Hu and Walker, 2017; Hashimoto, 2019) for the task. With the development of deep learning, neural 4863 Context Encoding Deep Transformer Global warming worsened, and tsunami strengthened. Context Representation greenhouse gas Descriptive Graph Induction glacier melting CreatedBy Knowledge Obtaining global warming IsA heating ConceptNet tidal wave Causes IsA AtLocation IsA temperature change destroy house CapableOf tsunami Causes Knowledge Encoding death ocean Descriptive Knowledge Representation Descriptive Graph Relational Knowledge Representation Relational Graph In"
2021.acl-long.376,N19-1173,0,0.0241258,"ights P ∈ Rnr ×nr to the edges of the induced relational graph: ( 0, if i = j Pij = (6) exp(sij ), otherwise, where Pij is the weight of the edge between the i-th and the j-th node. Then, following Koo et al. (2007), we define the Laplacian matrix ˆ ∈ Rnr ×nr , L ∈ Rnr ×nr of Gr , and its variant L respectively: (P nr k=1 Pkj , if i = j Lij = (7) −Pij , otherwise, where gj is the concatenation of the initial node representation and the node representations pro(l) duced in layers 1, . . . , l − 1, namely gj = mj ⊕ (1) (l−1) . vj ⊕ · · · ⊕ vj The induced structure at once is relatively shallow (Liu et al., 2019; Nan et al., 2020) and may not be optimal for causality reasoning. Therefore, we iteratively refine the induced structure to learn a more informative structure. We stack N blocks (each block is structure induction and DCGCNs reasoning) of this module to induce the structure N times. Intuitively, as the structure gets more refined, the structure is more reasonable. After the iterative refinement, the representations of e1 and e2 are denoted as ve1 and ve2 , respectively. We concatenate them as the relational knowledge representation: (e ,e2 ) FR 1 3.4 ˆ ij = L exp(sri ), Lij , if i = 1 otherwi"
2021.acl-long.376,D13-1177,0,0.0252817,"ledge for ECI task. The dashed arrow indicates a missing link in the knowledge base. Introduction Event causality identification (ECI) aims to identify causal relation of events in texts. For example, in the sentence “The earthquake generated a tsunami.”, an ECI model should be able to identify a causal relationship that holds between the two cause mentioned events, i.e., earthquake −−−→ tsunami. ECI is an important task in natural language processing (NLP) area and can support many NLP applications, such as machine reading comprehension (Berant et al., 2014), process extraction (Thalappillil Scaria et al., 2013) and future event prediction (Radinsky et al., 2012; Hashimoto et al., 2014). Identifying event causal relation is inherently challenging, because event causality is usually expressed in diverse forms that often lack explicit clues indicating its existence. For example in Figure 1, the sentence has no explicit clue indicating the causal relation between “global warming” and “tsunami”. In this scenario, models can resort to a large amount of labeled data to learn diverse causal expressions. However, existing ECI datasets are very small. For example, the largest dataset EventStoryLine (Caselli a"
2021.acl-long.376,2020.findings-emnlp.369,0,0.0241244,"A, temperature change), (global warming, CreatedBy, greenhouse gas) and so on. If the model can make use of such knowledge, it is obvious that the model can better understand the meaning of the event itself than using only the given text. Therefore, incorporating the descriptive knowledge is very helpful for this task. However, when leveraging this kind of knowledge, we find two critical challenges: (1) As shown in Figure 1, the descriptive knowledge forms a sub-graph. How to effectively encode the graph-structured knowledge is a very challenging problem; (2) The knowledge base is incomplete (Wang et al., 2020), which will inevitably cause the descriptive knowledge of some events cannot be obtained from the KB. Thus, the model should have the ability to obtain and encode such knowledge, even if it does not exist in the KB. Relational Knowledge: The external knowledge base contains connections between events, which can be referred as the relational knowledge between events. It is usually defined by the multi-hop path between two events. This kind of knowledge can provide useful information for event causality reasoning, especially when the text lacks causal clues. For example in Figure 1, the relatio"
2021.acl-long.376,D19-1451,0,0.0115509,", 2019), which is originally proposed for the knowledge base completion. Specifically, COMET is obtained by finetuning GPT (Radford et al., 2018) on C ONCEPTN ET. The input of COMET is the head event and candidate relation, and the output is the tail event. The relation types are the same as the ones used in Bosselut et al. (2019). By leveraging COMET, we can generate the descriptive graph Gd1 for e1 . In the same way, we can also construct the descriptive graph Gd2 for e2 . 3.2.2 Knowledge Encoding Graph neural networks have been widely used to encode graph-structured data (Lin et al., 2019; Yang et al., 2019), as they are able to effectively collect relevant evidence based on an information aggregation scheme. In addition, many works show that relational graph convolutional networks (RGCNs) (Schlichtkrull et al., 2018) usually overparameterize the model and cannot effectively utilize multi-hop relational information (Zhang et al., 2018; Lin et al., 2019). We thus apply GCNs (Kipf and Welling, 2017) to encode the related descriptive knowledge of e1 and e2 . Formally, given a descriptive graph Gd (i.e., Gd1 or Gd2 ) with nd nodes (i.e., concepts), which can be represented with an nd × nd adjacency m"
2021.acl-long.376,D18-1244,0,0.0258851,"By leveraging COMET, we can generate the descriptive graph Gd1 for e1 . In the same way, we can also construct the descriptive graph Gd2 for e2 . 3.2.2 Knowledge Encoding Graph neural networks have been widely used to encode graph-structured data (Lin et al., 2019; Yang et al., 2019), as they are able to effectively collect relevant evidence based on an information aggregation scheme. In addition, many works show that relational graph convolutional networks (RGCNs) (Schlichtkrull et al., 2018) usually overparameterize the model and cannot effectively utilize multi-hop relational information (Zhang et al., 2018; Lin et al., 2019). We thus apply GCNs (Kipf and Welling, 2017) to encode the related descriptive knowledge of e1 and e2 . Formally, given a descriptive graph Gd (i.e., Gd1 or Gd2 ) with nd nodes (i.e., concepts), which can be represented with an nd × nd adjacency matrix Ad . If there is a connection between node i and node j, the Adij is set to 1. For the node i at the l-th layer, the convolution computation can be defined as follows: (l) ui nd X (l−1) = ρ( Adij Wu(l) uj + b(l) u ), (2) j=1 (l) (l) where Wu and bu are the weight matrix and bias vector for the l-th layer, respectively. ρ is a"
2021.acl-long.376,2020.coling-main.135,1,0.882817,"riptive Knowledge Representation Descriptive Graph Relational Knowledge Representation Relational Graph Induction global warming Causes sea-level rising CapableOf tsunami AtLocation glacier melting ocean AtLocation Iterative Refinement Structure Induction Relational Graph Relational Path global Causes tsunami warming Figure 2: The architecture of our proposed latent structure induction network for event causality identification. network-based methods have been proposed for the task and achieved the state-of-the-art performance (Kruengkrai et al., 2017; Kadowaki et al., 2019; Liu et al., 2020; Zuo et al., 2020). Liu et al. (2020) propose a mention masking generalization method and also consider the external structural knowledge. The very recent work (Zuo et al., 2020) propose a data augmentation method to alleviate the data lacking problem for the task. Regarding datasets construction, Mirza (2014) annotates the CausalTimeBank dataset about event causal relations in the TempEval-3 corpus. Caselli and Vossen (2017) construct a dataset called EventStoryLine for event causality identification. Despite many efforts for this task, most existing methods typically train the models on manually labeled data"
2021.acl-long.463,2020.acl-main.282,1,0.889912,"e code set and tedious clinical notes. As statistics, the cost incurred by coding errors and the financial investment spent on improving coding quality are estimated to be $25 billion per year in the US (Lang, 2007). Automatic ICD coding methods (Stanfill et al., 2010) have been proposed to resolve the deficiency of manual annotation, regarding it as a multi-label text classification task. As shown in Figure 1, given a plain clinical text, the model tries to predict all the standardized codes from ICD-9. Recently, neural networks were introduced (Mullenbach et al., 2018) (Falis et al., 2019) (Cao et al., 2020) to alleviate the deficiency of manual feature engineering process of traditional machine learning method (Larkey and Croft, 1996) (Perotte et al., 2014) in ICD coding task, and great progresses have been made. Although effective, those methods either ignore the 5948 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5948–5957 August 1–6, 2021. ©2021 Association for Computational Linguistics long-tail distribution of the code frequency or not target the noisy text in clinical"
2021.acl-long.463,D19-6220,0,0.0506867,"Missing"
2021.acl-long.463,N18-1100,0,0.399657,"professional coders, due to the large candidate code set and tedious clinical notes. As statistics, the cost incurred by coding errors and the financial investment spent on improving coding quality are estimated to be $25 billion per year in the US (Lang, 2007). Automatic ICD coding methods (Stanfill et al., 2010) have been proposed to resolve the deficiency of manual annotation, regarding it as a multi-label text classification task. As shown in Figure 1, given a plain clinical text, the model tries to predict all the standardized codes from ICD-9. Recently, neural networks were introduced (Mullenbach et al., 2018) (Falis et al., 2019) (Cao et al., 2020) to alleviate the deficiency of manual feature engineering process of traditional machine learning method (Larkey and Croft, 1996) (Perotte et al., 2014) in ICD coding task, and great progresses have been made. Although effective, those methods either ignore the 5948 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5948–5957 August 1–6, 2021. ©2021 Association for Computational Linguistics long-tail distribution of the code frequency o"
2021.acl-long.463,P18-1098,0,0.0191667,"based methods firstly brought to solve this task. (Larkey and Croft, 1996) explored traditional machine learning algorithms, including KNN, relevance feedback, and Bayesian applying to ICD coding. (Perotte et al., 2014) utilized SVM for classification in consideration of the hierarchy of ICD codes. With the popularity of neural networks, researchers have proven the effectiveness of CNN and LSTM in ICD coding task. (Mullenbach et al., 2018) propose a convolutional neural network with an attention mechanism to capture each code’s desire information in source text also exhibit interpretability. (Xie and Xing, 2018) develop tree LSTM to utilize code descriptions. To further improve the performance, customized structures were introduced to utilize the code cooccurrence and code hierarchy of ICD taxonomies. (Cao et al., 2020) embedded the ICD codes into hyperbolic space to explore their hierarchical nature and constructed a co-graph to import code co-occurrence prior. We argue that they capture code co-occurrence in a static manner rather than dynamic multi-hop relations. (Vu et al., 2020) consider learning attention distribution for each code and introduce hierarchical joint learning architecture to handl"
2021.acl-long.463,2020.coling-main.311,0,0.0255211,"shared multi-attention for multi-label image labeling. Our work further constructs a label interaction module for label relevant shared representation to utilize dynamic label co-occurrence. Lots of effects tried to normalize noisy texts before inputting to downstream tasks. (Vateekul and Koomsubha, 2016) (Joshi and Deshpande, 2018) apply pre-processing techniques on twitter data for sentiment classification. (Lourentzou et al., 2019) utilized seq2seq model for text normalization. Others targeted at noisy input in an end2end manner by designing customized architecture. (Sergio and Lee, 2020) (Sergio et al., 2020). Different from previous works on noisy text, our method neither need extra text processing nor bring in specific parameters. 3 Method This section describes our interactive shared representation learning mechanism and self-distillation learning paradigm for ICD coding. Figure 2 shows the architecture of interactive shared representation networks and manifest the inference workflow of our method. We first encode the source clinical note to the hidden state with a multi-scale convolution neural network. Then a shared attention module further extracts code relevant information shared among all"
2021.acl-long.492,W06-0901,0,0.127515,"0000 shares of the company. The 20000 shares were frozen by the Shenzhen Inter mediate People's Court on November 1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed w"
2021.acl-long.492,W18-2311,0,0.0617749,"Missing"
2021.acl-long.492,P19-3006,0,0.0180635,"ing the relationship between event roles and more inter-attention modules allow for integrating information of candidate arguments into roles. 2 61.6 71.3 65.4 62.9 50.8 42.1 35.7 62.1 59.6 53.2 38.3 26.4 3 4 Number of Annotated Events >=5 Figure 4: F1-score for performance differences of generated events. have been proposed to improve performance on this task. These studies are mainly based on handdesigned features (Li et al., 2013; Kai and Grishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020). A few methods make extraction decisions beyond individual sentences. Ji and Grishman (2008) and Liao and Grishman (2010) used event type co-occurrence patterns for event detection. Yang and Mitchell (2016) introduced event structure to jointly extract events and entities within a document. Although these approaches make decisions beyond sentence boundary, their extractions are still done at the sentence level. 4.2 Document-level Event Extraction Many real-world applications need DEE, in which the event information scatters across the whole document. MUC-"
2021.acl-long.492,2020.aacl-main.81,1,0.801741,"decisions beyond sentence boundary, their extractions are still done at the sentence level. 4.2 Document-level Event Extraction Many real-world applications need DEE, in which the event information scatters across the whole document. MUC-4 (1992) proposed the MUC-4 template-filling task that aims to identify event role fillers with associated role types from a document. Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020). Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking. A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences. Li et al. (2021) extend this task and compile a new benchmark dataset 6305 WIKIEVENTS for exploring document-level argument extraction task. Then, Li et al. (2021) propose an end-to-end neural event argument extraction model by conditional text generation. However, the"
2021.acl-long.492,P15-1017,1,0.914082,"Court on November 1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specifi"
2021.acl-long.492,doddington-etal-2004-automatic,0,0.163991,"d Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and multievents. Specifically, arguments-scattering indicates that arguments of an event may scatter across multiple sentences. For example, As shown in Figure 1, the arguments of Event-1 are distributed"
2021.acl-long.492,2020.acl-main.714,0,0.0114849,"their extractions are still done at the sentence level. 4.2 Document-level Event Extraction Many real-world applications need DEE, in which the event information scatters across the whole document. MUC-4 (1992) proposed the MUC-4 template-filling task that aims to identify event role fillers with associated role types from a document. Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020). Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking. A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences. Li et al. (2021) extend this task and compile a new benchmark dataset 6305 WIKIEVENTS for exploring document-level argument extraction task. Then, Li et al. (2021) propose an end-to-end neural event argument extraction model by conditional text generation. However, these works focused on the sub-task of DEE"
2021.acl-long.492,2020.acl-main.718,0,0.098399,"Missing"
2021.acl-long.492,P11-1113,0,0.0317212,"the Shenzhen Inter mediate People's Court on November 1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In co"
2021.acl-long.492,P11-2000,0,0.241582,"Missing"
2021.acl-long.492,P18-1201,0,0.0136029,"People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and multievents. Specifically, arguments-sc"
2021.acl-long.492,P11-1114,0,0.0334207,"act events and entities within a document. Although these approaches make decisions beyond sentence boundary, their extractions are still done at the sentence level. 4.2 Document-level Event Extraction Many real-world applications need DEE, in which the event information scatters across the whole document. MUC-4 (1992) proposed the MUC-4 template-filling task that aims to identify event role fillers with associated role types from a document. Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020). Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking. A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences. Li et al. (2021) extend this task and compile a new benchmark dataset 6305 WIKIEVENTS for exploring document-level argument extraction task. Then, Li et al. (2021) propose an end-to-end neural event ar"
2021.acl-long.492,E12-1029,0,0.047866,"Missing"
2021.acl-long.492,P08-1030,0,0.107392,"of the company. The 20000 shares were frozen by the Shenzhen Inter mediate People's Court on November 1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event informati"
2021.acl-long.492,W15-4502,0,0.0187149,"e decoder layers, the better performance on the results. We conjecture that more layers of the decoder with the more self-attention modules allow for better modeling the relationship between event roles and more inter-attention modules allow for integrating information of candidate arguments into roles. 2 61.6 71.3 65.4 62.9 50.8 42.1 35.7 62.1 59.6 53.2 38.3 26.4 3 4 Number of Annotated Events >=5 Figure 4: F1-score for performance differences of generated events. have been proposed to improve performance on this task. These studies are mainly based on handdesigned features (Li et al., 2013; Kai and Grishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020). A few methods make extraction decisions beyond individual sentences. Ji and Grishman (2008) and Liao and Grishman (2010) used event type co-occurrence patterns for event detection. Yang and Mitchell (2016) introduced event structure to jointly extract events and entities within a document. Although these approaches make decisions beyond sentence boundary, their extractions are still done at the senten"
2021.acl-long.492,P13-1008,0,0.075044,"mediate People's Court on November 1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, th"
2021.acl-long.492,2021.naacl-main.69,0,0.0398292,"le types from a document. Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020). Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking. A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences. Li et al. (2021) extend this task and compile a new benchmark dataset 6305 WIKIEVENTS for exploring document-level argument extraction task. Then, Li et al. (2021) propose an end-to-end neural event argument extraction model by conditional text generation. However, these works focused on the sub-task of DEE (i.e., role filler extraction or argument extraction) and ignored the challenge of multi-events. To simultaneously address both challenges for DEE (i.e., arguments-scattering and multi-events), previous works focus on the ChFinAnn (Zheng et al., 2019) dataset and model DEE as an event table filling task, i"
2021.acl-long.492,P10-1081,0,0.124062,"000 shares were frozen by the Shenzhen Inter mediate People's Court on November 1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the wh"
2021.acl-long.492,2020.emnlp-main.128,1,0.899655,"r 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and multievents. Specifically, arguments-scattering indicates that arguments of a"
2021.acl-long.492,N16-1034,0,0.0991911,"1, 2018. Jing Yan 10000 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE:"
2021.acl-long.492,D09-1016,0,0.0464206,"ent structure to jointly extract events and entities within a document. Although these approaches make decisions beyond sentence boundary, their extractions are still done at the sentence level. 4.2 Document-level Event Extraction Many real-world applications need DEE, in which the event information scatters across the whole document. MUC-4 (1992) proposed the MUC-4 template-filling task that aims to identify event role fillers with associated role types from a document. Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020). Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking. A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences. Li et al. (2021) extend this task and compile a new benchmark dataset 6305 WIKIEVENTS for exploring document-level argument extraction task. Then, Li et al. (2021) propose an en"
2021.acl-long.492,N16-1033,0,0.0718802,"00 shares 20000 shares Shenzhen Intermediate People's Court October 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and"
2021.acl-long.492,P18-4009,1,0.902203,"ent with the same event type and there is no obvious textual boundary between the two events. The multi-events problem requires the DEE method to recognize how many events are contained in a document and achieve accurate arguments assembling (i.e., assign arguments to the corresponding event). As a result of these two complications, SEE methods are ill-suited for the DEE task, which calls for a model that can integrate document-level information, assemble relevant arguments across multiple sentences and capture multiple events simultaneously. To handle these challenges in DEE, previous works (Yang et al., 2018; Zheng et al., 2019) formulate DEE as an event table filling task, i.e., filling candidate arguments into a predefined event table. Specifically, they model the DEE as a serial prediction paradigm, in which arguments are predicted in a predefined role order and multiple events are also extracted in predefined event order. Such a manner is restricted to the extraction of individual arguments, and the former extraction will not consider the latter extraction results. As a result, errors will be propagated and the extraction performance is under satisfaction. In this paper, to avoid the shortage"
2021.acl-long.492,P19-1522,0,0.0713168,"ber 30, 2018 October 30, 2019 November 1, 2018  Figure 1: An example of a document contains two Equity Freeze type events: Event-1 and Event-2. Words in bold-faced are arguments that scatter across multiple sentences. Introduction The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within 1 https://www.ldc.upenn.edu/ collaborations/past-projects/ace Shanghai Fukong Co., Ltd a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and multievents. Specifically, arguments-scattering indicates"
2021.acl-long.492,2020.acl-main.667,0,0.0276894,") proposed the MUC-4 template-filling task that aims to identify event role fillers with associated role types from a document. Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020). Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking. A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences. Li et al. (2021) extend this task and compile a new benchmark dataset 6305 WIKIEVENTS for exploring document-level argument extraction task. Then, Li et al. (2021) propose an end-to-end neural event argument extraction model by conditional text generation. However, these works focused on the sub-task of DEE (i.e., role filler extraction or argument extraction) and ignored the challenge of multi-events. To simultaneously address both challenges for DEE (i.e., arguments-scattering and multi-events), previous works"
2021.acl-long.492,D19-1032,0,0.0457033,"Missing"
2021.eacl-main.175,grivaz-2010-human,0,0.0853443,"Missing"
2021.eacl-main.175,W17-5540,0,0.065173,"Missing"
2021.eacl-main.175,W14-2903,0,0.0714461,"Missing"
2021.eacl-main.175,W10-0206,0,0.110895,"Missing"
2021.eacl-main.175,P16-1101,0,0.0386419,"future research. The selected baselines are as followed (see more details in Appendix C): Regular Expressions (RegExp): In this setting, we regard the FinReason task as a causal sentence detection problem and employ some ad-hoc regular expressions to solve it. Specifically, we use five modifiers (因为(because),由于(since),原 因(cause),为(in order to),目的(aims to)) as causal clues to detect the sentence as the reasons for an event. BiLSTM-CRF (BiLSTM): We can take the reasons as one part of the event description and regard the task as an EE task. Similar to Yang et al. (2018), we employ a BiLSTM-CRF (Ma and Hovy, 2016) to predict the start and end positions of each reason. Specifically, We simply get the event participants in the documents via string matching between the documents and the given structural events. Such information is used as features in a BIO tagging format. BERT-QA: We can take this task as an MRC problem if the structural event is regarded as a query and the target reason as the answer. In particular, we use templates to turn each structural event into a why-question and employ BERT-QA (Devlin et al., 2019) model to find the corresponding reasons. Type RegExp BiLSTM BERT-QA Human Pledge O/"
2021.eacl-main.175,C14-1198,0,0.170116,"n 2 for Event 1 and Event 2 respectively. Introduction Why does the event happen? People are always eager to find the reasons for an event. Automatically extracting the causal explanations of the given events from texts is useful and important for common users and downstream applications. For example, in the financial domain, returning the reasons of a concerned financial event in an Information Retrieval system can free analysts from reading the enormous company announcements and help investors make financial decisions. Previous work on event causality (Do et al., 2011; Riaz and Girju, 2013; Mirza and Tonelli, 2014; Caselli and Vossen, 2017) mainly focus on ∗ Most of the work was done when the first author was a research engineer in the Institute of Automation, CAS. the identification of causal relations between two given events that are usually presented as event trigger words. However, in reality, users may only know a particular event happened but without knowing its mention or trigger in the documents, and they just wonder the reasons for it. Therefore, we propose a new task aiming at extracting the causal explanations of the given structurally presented events from document-level texts. Specificall"
2021.eacl-main.175,P18-2124,0,0.077376,"Missing"
2021.eacl-main.175,W13-4004,0,0.0221398,"act Reason 1 and Reason 2 for Event 1 and Event 2 respectively. Introduction Why does the event happen? People are always eager to find the reasons for an event. Automatically extracting the causal explanations of the given events from texts is useful and important for common users and downstream applications. For example, in the financial domain, returning the reasons of a concerned financial event in an Information Retrieval system can free analysts from reading the enormous company announcements and help investors make financial decisions. Previous work on event causality (Do et al., 2011; Riaz and Girju, 2013; Mirza and Tonelli, 2014; Caselli and Vossen, 2017) mainly focus on ∗ Most of the work was done when the first author was a research engineer in the Institute of Automation, CAS. the identification of causal relations between two given events that are usually presented as event trigger words. However, in reality, users may only know a particular event happened but without knowing its mention or trigger in the documents, and they just wonder the reasons for it. Therefore, we propose a new task aiming at extracting the causal explanations of the given structurally presented events from document"
2021.eacl-main.175,P18-4009,1,0.929031,"different aspects. However, they have found it is difficult to agree on if a causal relationship exists in reality due to the ambiguity of causality definition. Our dataset mitigates this problem by only identifying contextual causality and do not check with reality. In addition, plenty of work also only identify context-level causal relationships, such as general causality detection tasks PDTB (Prasad et al., 1 http://www.nlpr.ia.ac.cn/cip/ liukang/dataset/finreason1.html ˜ To construct this dataset, we first collect a corpus of structural events with their corresponding documents following Yang et al. (2018). The collected documents are constrained to company financial announcements, which are relatively formal documents. Such a setting could improve annotation IAA because of the logical consistency and clarity. In specific, we crawl the public company financial announcements as documents from sohu.com3 and the structural events from eastmoney.com4 . Since the documents are not in line with their corresponding structural events, we leverage key event items (see more details in Appendix B) matching to align them. Same as Yang et al. (2018), we assume that if the key event items of a structural eve"
2021.emnlp-demo.32,W16-5808,0,0.0427636,"Missing"
2021.emnlp-demo.32,E12-2021,0,0.126546,"Missing"
2021.emnlp-demo.32,P18-4006,0,0.125221,"se disagreement. ∗ co-first authors, they contributed equally to this work. We call this phenomenon instance-level label incon275 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 275–282 August 1–6, 2021. ©2021 Association for Computational Linguistics Figure 2: The screenshot of Annotator Interface. Figure 3: The screenshot of Disagreement Adjudicator. sistency, because this inconsistency occurs in the same instance. Instance-level label inconsistency is easy to locate but difficult to display and correct. as follows: YEDDA (Yang et al., 2018) employs a comparison report to show these inconsistencies to annotation • We propose a crowd annotation platform, experts. But it failed to display detailed informawhich can promote label consistency of tion of inconsistent entities, and annotation experts the Chinese NER dataset. The site can cannot directly correct these entities through the be accessed by http://116.62.20.198:3000, comparison report. To solve these display and corand instruction video is provided at rection issues, CroAno uses a multi-dimensional https://www.youtube.com/watch?v=wt2ma9F display mode to show inconsistent ins"
2021.emnlp-demo.32,P18-1144,0,0.0550584,"Missing"
2021.emnlp-main.760,D17-1277,0,0.013745,"en output embedding hd ∈ Rd , we first compute the predicted logit values of the entities: logith = Ve relu(W1 hd ) (6) logitt = Ve relu(W2 hd ) where W1 , W2 ∈ Rd×d are learnable parameters, and Ve is entity embedding matrix mentioned in Section 2.1. Then, we conduct masked softmax1 to compute the distribution of the entities: ph = masked_softmax(logith , C(X)) pt = masked_softmax(logitt , C(X)) (7) where C(X) is the entity candidates of the given sentence X and is obtained through the process mention in the following paragraph. Candidate Selection. Inspired by the studies in entity linking (Ganea and Hofmann, 2017; Kolitsas et al., 2018), we conduct the candidate selection to avoid involving an extremely large number of entities. For each span s in the given sentence X, we select up to 10 entity candidates that might be referred by this span. These top entities are based on an empirical probabilistic entity-map p(e|s) built from hyperlinks and disambiguation pages in Wikipedia. We denote this candidate set as C(X) and use it at both training and test time. For more details about the candidate selection, we refer readers to Kolitsas et al. (2018). 2.4 Bipartite Matching Loss The main difficulty of train"
2021.emnlp-main.760,N13-1092,0,0.0281207,"Missing"
2021.emnlp-main.760,D17-1278,0,0.0346279,"Missing"
2021.emnlp-main.760,L18-1245,0,0.0282996,"previous step. We define the loss as: ˆ Y) = L(Y, m X {− log prπ? (i) (ri ) + 1{ri 6=∅} [ i=1 • RQ1: How well do our proposed set generation networks (SGN) perform, in comparison with the competitive baselines? • RQ2: How efficient is the training and inference of the model? • RQ3: How does each design of the proposed networks matter? • RQ4: What is the performance of the proposed networks in sentences that mention different numbers of facts? In the remainder of this section, we describe the datasets, experimental settings (in the Appendix), and all baselines. 3.1 The Cold Start track in TAC (Getman et al., 2018) provides a testbed for KBP systems. However, the dataset is not publicly available and manual evaluation is used to examine a system’s “justification” (Mesquita et al., 2019), which make it difficult to reproduce TAC’s evaluation for new systems. Instead, we validate the proposed method on two publicly available datasets: WIKI and GEO4 (Trisedya et al., 2019). The statistics of these datasets are shown in Table 2. The training set, validation set and WIKI are constructed from Wikipedia articles. To evaluate methods on a different style of text than the training data, GEO is used as a testbed,"
2021.emnlp-main.760,D17-1109,0,0.0116875,"avoiding while the fact <h, r, t> does not exist in the KB, considering the order of multiple facts. To since KBs typically have much better coverage on solve the set generation problem, we propose entities than on relationships. networks featured by transformers with nonautoregressive parallel decoding. Unlike previConventionally, KBP is solved by several inous approaches that use an autoregressive dedividual components in a pipeline manner (Shin coder to generate facts one by one, the proet al., 2015; Angeli et al., 2015; Zhang et al., 2017; posed networks can directly output the final set Chaganty et al., 2017; Mesquita et al., 2019), typof facts in one shot. Furthermore, to train the ically including (1) entity discovery or named ennetworks, we also design a set-based loss that tity recognition (Tjong Kim Sang and De Meulder, forces unique predictions via bipartite matching. Compared with cross-entropy loss that 2003), (2) entity linking (Milne and Witten, 2008) highly penalizes small shifts in fact order, the and (3) relation extraction (Zelenko et al., 2003). proposed bipartite matching loss is invariant Entity discovery seeks to locate and classify named to any permutation of predictions. Benef"
2021.emnlp-main.760,D16-1236,0,0.0321919,"Missing"
2021.emnlp-main.760,D11-1072,0,0.0138019,"ram combination of attention weight to capture the verbal or noun phrase context. Note that all of these end-to-end models are based on the encoder-decoder framework and are required to sort the ground truth facts. Following previous work (Trisedya et al., 2019), we build the ground truth sequence according to the inherent order in these datasets. We compare the proposed model with the following systems that report SoTA results on these datasets. Firstly, we compare our proposed model with pipeline models. In these pipeline models, we use two entity discovery and entity linking systems, AIDA (Hoffart et al., 2011; Yosef et al., 2011) and NeuralEL (Kolitsas et al., 2018). In AIDA, entity mentions are automatically detected by using the Stanford NER Tagger (Manning et al., 2014), and then are mapped to entities by using a probabilistic 3.4 Main Results graphical model. In NeuralEL, all possible spans To start, we address the research question RQ1. that have at least one possible entity candidate are Table 3 shows the results of our proposed model generated, and are linked to entities by using a against baselines on two benchmark datasets. context-aware compatibility score. To label the relationship betw"
2021.emnlp-main.760,P11-1115,0,0.0410348,". However, high-quality KBs still rely almost all based on the sequence-to-sequence (seq2seq) exclusively on human-curated structured or semi- framework (Sutskever et al., 2014; Cho et al., 2014). structured data (Mesquita et al., 2019). Such a Under this framework, end-to-end KBP is treated reliance on human curation is a major barrier to as a translation of a sentence into a sequence of fact creating always-up-to-date KBs. elements (entity or predicate). Considering the runTo overcome this barrier, knowledge base popu- ning example in Table 1, a seq2seq model would lation (KBP) is proposed (Ji and Grishman, 2011; translate the sentence “President Obama 9650 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9650–9660 c November 7–11, 2021. 2021 Association for Computational Linguistics Input Sentence: President Obama welcomed President Xi Jinping of China to visit the United States. Output Facts: <Q76, P39, Q11696>; <Q15031, P39, Q655407> Table 1: An example of KBP. In this example, “Obama”, “President of United States”, “Xi Jinping”, and “President of People’s Republic of China” are mapped to their unique Wikidata identifiers “Q76”, “Q11696”, “Q15031” and “"
2021.emnlp-main.760,K18-1050,0,0.0412472,"Rd , we first compute the predicted logit values of the entities: logith = Ve relu(W1 hd ) (6) logitt = Ve relu(W2 hd ) where W1 , W2 ∈ Rd×d are learnable parameters, and Ve is entity embedding matrix mentioned in Section 2.1. Then, we conduct masked softmax1 to compute the distribution of the entities: ph = masked_softmax(logith , C(X)) pt = masked_softmax(logitt , C(X)) (7) where C(X) is the entity candidates of the given sentence X and is obtained through the process mention in the following paragraph. Candidate Selection. Inspired by the studies in entity linking (Ganea and Hofmann, 2017; Kolitsas et al., 2018), we conduct the candidate selection to avoid involving an extremely large number of entities. For each span s in the given sentence X, we select up to 10 entity candidates that might be referred by this span. These top entities are based on an empirical probabilistic entity-map p(e|s) built from hyperlinks and disambiguation pages in Wikipedia. We denote this candidate set as C(X) and use it at both training and test time. For more details about the candidate selection, we refer readers to Kolitsas et al. (2018). 2.4 Bipartite Matching Loss The main difficulty of training is to score the pred"
2021.emnlp-main.760,2020.emnlp-main.79,0,0.0360792,"when the number of facts increases, the performance of models decreases significantly. the advancement of this line of research is that an inexistent order of facts must be introduced to train the seq2seq model. In this paper, we introduce set generation networks to overcome this roadblock. Non-Autoregressive Model for Generation. Gu et al. (2018) began to explore non-autoregressive model, the aim of which is to generate sequences in a parallel manner. Since then, there is rich literature devoted to this topic, such as Lee et al. (2018); Ma et al. (2019); Ren et al. (2020); Ran et al. (2020); Kong et al. (2020). Nowadays, non-autoregressive models are widely explored in natural language and speech processing tasks such as neural machine translation (Lee et al., 2018; Ma et al., 2019) and automatic speech recognition (Chen et al., 2019; Tian et al., 2020; Bai et al., 2020). To the best of our knowledge, this is the first work to apply the non-autoregressive model to knowledge base population. In this work, we resort to the nonautoregressive model to generate the set of relational facts in one shot. Set Prediction. The problem with predicting sets is that the output order of the elements is arbitrary,"
2021.emnlp-main.760,D18-1149,0,0.022059,"1 fact or 2 facts, most models can achieve the best performance. However, when the number of facts increases, the performance of models decreases significantly. the advancement of this line of research is that an inexistent order of facts must be introduced to train the seq2seq model. In this paper, we introduce set generation networks to overcome this roadblock. Non-Autoregressive Model for Generation. Gu et al. (2018) began to explore non-autoregressive model, the aim of which is to generate sequences in a parallel manner. Since then, there is rich literature devoted to this topic, such as Lee et al. (2018); Ma et al. (2019); Ren et al. (2020); Ran et al. (2020); Kong et al. (2020). Nowadays, non-autoregressive models are widely explored in natural language and speech processing tasks such as neural machine translation (Lee et al., 2018; Ma et al., 2019) and automatic speech recognition (Chen et al., 2019; Tian et al., 2020; Bai et al., 2020). To the best of our knowledge, this is the first work to apply the non-autoregressive model to knowledge base population. In this work, we resort to the nonautoregressive model to generate the set of relational facts in one shot. Set Prediction. The problem"
2021.emnlp-main.760,P16-1200,0,0.0172154,"Missing"
2021.emnlp-main.760,D19-1437,0,0.0129576,"most models can achieve the best performance. However, when the number of facts increases, the performance of models decreases significantly. the advancement of this line of research is that an inexistent order of facts must be introduced to train the seq2seq model. In this paper, we introduce set generation networks to overcome this roadblock. Non-Autoregressive Model for Generation. Gu et al. (2018) began to explore non-autoregressive model, the aim of which is to generate sequences in a parallel manner. Since then, there is rich literature devoted to this topic, such as Lee et al. (2018); Ma et al. (2019); Ren et al. (2020); Ran et al. (2020); Kong et al. (2020). Nowadays, non-autoregressive models are widely explored in natural language and speech processing tasks such as neural machine translation (Lee et al., 2018; Ma et al., 2019) and automatic speech recognition (Chen et al., 2019; Tian et al., 2020; Bai et al., 2020). To the best of our knowledge, this is the first work to apply the non-autoregressive model to knowledge base population. In this work, we resort to the nonautoregressive model to generate the set of relational facts in one shot. Set Prediction. The problem with predicting s"
2021.emnlp-main.760,P18-1136,0,0.0488494,"Missing"
2021.emnlp-main.760,P14-5010,0,0.00251492,"and are required to sort the ground truth facts. Following previous work (Trisedya et al., 2019), we build the ground truth sequence according to the inherent order in these datasets. We compare the proposed model with the following systems that report SoTA results on these datasets. Firstly, we compare our proposed model with pipeline models. In these pipeline models, we use two entity discovery and entity linking systems, AIDA (Hoffart et al., 2011; Yosef et al., 2011) and NeuralEL (Kolitsas et al., 2018). In AIDA, entity mentions are automatically detected by using the Stanford NER Tagger (Manning et al., 2014), and then are mapped to entities by using a probabilistic 3.4 Main Results graphical model. In NeuralEL, all possible spans To start, we address the research question RQ1. that have at least one possible entity candidate are Table 3 shows the results of our proposed model generated, and are linked to entities by using a against baselines on two benchmark datasets. context-aware compatibility score. To label the relationship between two entities, we adopt superTaken overall, our proposed model substantially vised approaches like CNN (Lin et al., 2016) and outperforms baselines on these dataset"
2021.emnlp-main.760,D19-1069,0,0.147557,"t <h, r, t> does not exist in the KB, considering the order of multiple facts. To since KBs typically have much better coverage on solve the set generation problem, we propose entities than on relationships. networks featured by transformers with nonautoregressive parallel decoding. Unlike previConventionally, KBP is solved by several inous approaches that use an autoregressive dedividual components in a pipeline manner (Shin coder to generate facts one by one, the proet al., 2015; Angeli et al., 2015; Zhang et al., 2017; posed networks can directly output the final set Chaganty et al., 2017; Mesquita et al., 2019), typof facts in one shot. Furthermore, to train the ically including (1) entity discovery or named ennetworks, we also design a set-based loss that tity recognition (Tjong Kim Sang and De Meulder, forces unique predictions via bipartite matching. Compared with cross-entropy loss that 2003), (2) entity linking (Milne and Witten, 2008) highly penalizes small shifts in fact order, the and (3) relation extraction (Zelenko et al., 2003). proposed bipartite matching loss is invariant Entity discovery seeks to locate and classify named to any permutation of predictions. Benefiting entities mentioned"
2021.emnlp-main.760,2020.acl-main.277,0,0.0113114,"formance. However, when the number of facts increases, the performance of models decreases significantly. the advancement of this line of research is that an inexistent order of facts must be introduced to train the seq2seq model. In this paper, we introduce set generation networks to overcome this roadblock. Non-Autoregressive Model for Generation. Gu et al. (2018) began to explore non-autoregressive model, the aim of which is to generate sequences in a parallel manner. Since then, there is rich literature devoted to this topic, such as Lee et al. (2018); Ma et al. (2019); Ren et al. (2020); Ran et al. (2020); Kong et al. (2020). Nowadays, non-autoregressive models are widely explored in natural language and speech processing tasks such as neural machine translation (Lee et al., 2018; Ma et al., 2019) and automatic speech recognition (Chen et al., 2019; Tian et al., 2020; Bai et al., 2020). To the best of our knowledge, this is the first work to apply the non-autoregressive model to knowledge base population. In this work, we resort to the nonautoregressive model to generate the set of relational facts in one shot. Set Prediction. The problem with predicting sets is that the output order of the el"
2021.emnlp-main.760,2020.acl-main.15,0,0.0140361,"chieve the best performance. However, when the number of facts increases, the performance of models decreases significantly. the advancement of this line of research is that an inexistent order of facts must be introduced to train the seq2seq model. In this paper, we introduce set generation networks to overcome this roadblock. Non-Autoregressive Model for Generation. Gu et al. (2018) began to explore non-autoregressive model, the aim of which is to generate sequences in a parallel manner. Since then, there is rich literature devoted to this topic, such as Lee et al. (2018); Ma et al. (2019); Ren et al. (2020); Ran et al. (2020); Kong et al. (2020). Nowadays, non-autoregressive models are widely explored in natural language and speech processing tasks such as neural machine translation (Lee et al., 2018; Ma et al., 2019) and automatic speech recognition (Chen et al., 2019; Tian et al., 2020; Bai et al., 2020). To the best of our knowledge, this is the first work to apply the non-autoregressive model to knowledge base population. In this work, we resort to the nonautoregressive model to generate the set of relational facts in one shot. Set Prediction. The problem with predicting sets is that the out"
2021.emnlp-main.760,P19-1023,0,0.0759135,"s to discover facts about entities from texts As shown in Table 1, a KBP system is required to and expand a knowledge base with these facts. take a given sentence as input and transform it into Previous studies shape end-to-end KBP as a machine translation task, which is required to a set of facts. A fact is in the form of <h, r, t>, convert unordered fact into a sequence accordwhere h is a head entity, t is a tail entity, and r is a ing to a pre-specified order. However, the facts predicate that falls in a predefined set of predicates. stated in a sentence are unordered in essence. Following Trisedya et al. (2019), we also assume In this paper, we formulate end-to-end KBP that h and t are existing entities in the given KB as a direct set generation problem, avoiding while the fact <h, r, t> does not exist in the KB, considering the order of multiple facts. To since KBs typically have much better coverage on solve the set generation problem, we propose entities than on relationships. networks featured by transformers with nonautoregressive parallel decoding. Unlike previConventionally, KBP is solved by several inous approaches that use an autoregressive dedividual components in a pipeline manner (Shin c"
2021.emnlp-main.760,K16-1025,0,0.0214373,"chitecture of set generation networks. The set generation networks predict the final set of facts in parallel by combining a transformer-based encoder with a non-autoregressive decoder. In the training phrase, bipartite matching uniquely assigns predictions with ground truths to provide accurate training signals. 2.1 Joint Learning of Word and Entity Embeddings set are not included in the KB). The loss function of the TransE model is defined as : In the first step, we jointly embed words, entities and predicates into the same vector space. To achieve this, we combine the anchor context model (Yamada et al., 2016) to compute the word embeddings with TransE (Bordes et al., 2013) to compute the entity and predicate embeddings. Specifically, we first utilize the anchor context model to establish the interaction between the entity and word embeddings. In this model, a modified Wikipedia corpus is generated by replacing the hyperlinks with the related entity identifiers, and a skip-gram model (Mikolov et al., 2013) is trained on this corpus to compute the word and entity embeddings. Formally, given a sequence [w1 , w2 , ..., wT ], the loss function of the anchor context model is: JW = − T X X log P (wt+j |w"
2021.findings-acl.190,W17-2711,0,0.171512,"clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality inference, where those KBs store inherent causal relations between some given events. For those unseen events and unlabeled causalities in KBs, Liu et al. (2020) proposed a mention-mask based reasoner to enhance the caus"
2021.findings-acl.190,P17-2001,0,0.171009,"ng: EventStoryLine v0.9 (ESC) (Caselli and Vossen, 2017) described above; and (2) Causal-TimeBank (CTB) (Mirza and Tonelli, 2014) which contains 184 documents, 6813 events, and 318 causal event pairs. Same as previous methods, we use the last two topics of ESC as the development set for two datasets. For evaluation, we adopt Precision (P), Recall (R), and F1-score (F1) as evaluation metrics. We conduct 5-fold and 10fold cross-validation on ESC and CTB respectively, same as previous methods. All the results are the average of three independent experiments. 2166 Methods P EventStoryLine S-Path (Cheng and Miyao, 2017) 34.0 S-Fea (Choubey and Huang, 2017) 32.7 LR+ (Gao et al., 2019) 37.0 ILP (Gao et al., 2019) 37.4 BERT 36.0 KnowDis (Zuo et al., 2020) 39.7 MasG (Liu et al., 2020) 41.9 KnowDis+CauSeRL (Ours) 40.1 MasG+CauSeRL (Ours) 40.8 CauSeRLDIST AN T (Ours) 39.9 CauSeRLAT OM IC (Ours) 41.0 CauSeRLGLU -GEN (Ours) 41.4 CauSeRLGLU -SP E (Ours) 41.9 Causal-TimeBank Rule-B (Mirza and Tonelli, 2014) 36.8 Data-D (Mirza and Tonelli, 2014) 67.3 VerR-C (Mirza, 2014) 69.0 BERT 39.5 MasG (Liu et al., 2020) 36.6 KnowDis (Zuo et al., 2020) 42.3 MasG+CauSeRL (Ours) 42.6 KnowDis+CauSeRL (Ours) 42.5 CauSeRLDIST AN T (Our"
2021.findings-acl.190,D17-1190,0,0.116152,"lli and Vossen, 2017) described above; and (2) Causal-TimeBank (CTB) (Mirza and Tonelli, 2014) which contains 184 documents, 6813 events, and 318 causal event pairs. Same as previous methods, we use the last two topics of ESC as the development set for two datasets. For evaluation, we adopt Precision (P), Recall (R), and F1-score (F1) as evaluation metrics. We conduct 5-fold and 10fold cross-validation on ESC and CTB respectively, same as previous methods. All the results are the average of three independent experiments. 2166 Methods P EventStoryLine S-Path (Cheng and Miyao, 2017) 34.0 S-Fea (Choubey and Huang, 2017) 32.7 LR+ (Gao et al., 2019) 37.0 ILP (Gao et al., 2019) 37.4 BERT 36.0 KnowDis (Zuo et al., 2020) 39.7 MasG (Liu et al., 2020) 41.9 KnowDis+CauSeRL (Ours) 40.1 MasG+CauSeRL (Ours) 40.8 CauSeRLDIST AN T (Ours) 39.9 CauSeRLAT OM IC (Ours) 41.0 CauSeRLGLU -GEN (Ours) 41.4 CauSeRLGLU -SP E (Ours) 41.9 Causal-TimeBank Rule-B (Mirza and Tonelli, 2014) 36.8 Data-D (Mirza and Tonelli, 2014) 67.3 VerR-C (Mirza, 2014) 69.0 BERT 39.5 MasG (Liu et al., 2020) 36.6 KnowDis (Zuo et al., 2020) 42.3 MasG+CauSeRL (Ours) 42.6 KnowDis+CauSeRL (Ours) 42.5 CauSeRLDIST AN T (Ours) 41.6 CauSeRLAT OM IC (Ours) 42.8 C"
2021.findings-acl.190,N19-1423,0,0.152696,"sion targets to train the online network which makes it learn the commonalities among two input causal statements, that is, the causal representations reflecting different context-specific causal patterns. Structurally, the online network is defined as a set of weights θ which is comprised of three submodules: an encoder Encθ , a projector P rojθ and a predictor P redθ . And the target network has the same architecture as the online network, but no predictor and uses a different set of weights δ. In specific, we iteratively sample two external causal statements, initially encode them by BERT (Devlin et al., 2019), and input them into two net2164 works respectively. After encoding and projection, the online network and target network respectively output a projection zθ and zδ0 . Then the online network outputs a prediction yθ , and takes the following mean square error between `2 -normalized y ¯θ and z¯δ0 as the training objective to learn the commonalities of two causal statements, that are regarded as the context-specific causal patterns. hyθ , zδ0 i , kyθ k2 · zδ0 2 (1) y ¯θ , yθ / kyθ k2 , z¯δ0 , zδ0 / zδ0 2 . (2) 2 Lθ,δ , y ¯θ − z¯δ0 2 =2 − 2 · To reduce the bias, we symmetrize the Lθ,δ by swappin"
2021.findings-acl.190,D11-1027,0,0.0320078,"all, we design a self-supervised framework to learn context-specific causal patterns from external causal statements. Then, we adopt a contrastive transfer strategy to incorporate the learned context-specific causal patterns into target ECI model for identification. • Experimental results on two benchmarks show that our model achieves the best performance. 2 Related Work Event Causality Identification Up to now, identifying the causality implied in the text has attracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh"
2021.findings-acl.190,W15-1622,0,0.018033,"Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BECauSE (Dunietz et al., 2015) of causal relation and other seven relations. Based on the above benchmarks, Gao et al. (2019) modeled document-level structures to identify the causalities of events. Liu et al. (2020) identified event causalities with the mention masking generalization and external KBs. Zuo et al. (2020) improved the performance of ECI with the distantly automatically labeled training data. However, these methods only rely on a small scale of labeled data. In this paper, we introduce external causal statements to help identify event causalities. Self-Supervised Representation Learning Self-supervised repres"
2021.findings-acl.190,W17-0812,0,0.0155953,"eown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BECauSE (Dunietz et al., 2015) of causal relation and other seven relations. Based on the above benchmarks, Gao et al. (2019) modeled document-level structures to identify the causalities of events. Liu et al. (2020) identified event causalities with the mention masking generalization and external KBs. Zuo et al. (2020) improved the performance of ECI with the distantly automatically labeled training data. However, these methods only rely on a small scale of labeled data. In this paper, we introduce external causal statements to help identify event"
2021.findings-acl.190,N19-1179,0,0.207505,"n S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality inference, where those KBs store inherent causal relations between some"
2021.findings-acl.190,W03-1210,0,0.28597,"een Case [Entity] find/notice/feel/... [Entity] >Causes/Enables> [Entity] call/give/alert/... [Entity] noticedE1 Context-specific Causal Pattern alertedE3 Prediction Figure 1: S1 is a labeled data that contains unseen causal events and their statement when training; S2 is an external causal statement; The bottom illustrates the context-specific causal pattern in S2 could help identify the causality of unseen events in S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 docume"
2021.findings-acl.190,P14-1093,0,0.086047,"the context-specific causal pattern in S2 could help identify the causality of unseen events in S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enha"
2021.findings-acl.190,P16-1135,0,0.0211599,"self-supervised framework to learn context-specific causal patterns from external causal statements. Then, we adopt a contrastive transfer strategy to incorporate the learned context-specific causal patterns into target ECI model for identification. • Experimental results on two benchmarks show that our model achieves the best performance. 2 Related Work Event Causality Identification Up to now, identifying the causality implied in the text has attracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et"
2021.findings-acl.190,W17-2708,0,0.0237781,"fic causal patterns from external causal statements. Then, we adopt a contrastive transfer strategy to incorporate the learned context-specific causal patterns into target ECI model for identification. • Experimental results on two benchmarks show that our model achieves the best performance. 2 Related Work Event Causality Identification Up to now, identifying the causality implied in the text has attracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et al. (2017) presented BECauSE 2.0, a new"
2021.findings-acl.190,W17-5540,0,0.391188,"ity of unseen events in S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality inference, where those KBs store inherent causal re"
2021.findings-acl.190,P14-3002,0,0.0680568,"Missing"
2021.findings-acl.190,W14-0702,0,0.0303958,"orate the learned context-specific causal patterns into target ECI model for identification. • Experimental results on two benchmarks show that our model achieves the best performance. 2 Related Work Event Causality Identification Up to now, identifying the causality implied in the text has attracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BECauSE (Dunietz et al., 2015) of causal relation and other seven relations. Based on the above be"
2021.findings-acl.190,C14-1198,0,0.38248,"e best performance. 2 Related Work Event Causality Identification Up to now, identifying the causality implied in the text has attracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BECauSE (Dunietz et al., 2015) of causal relation and other seven relations. Based on the above benchmarks, Gao et al. (2019) modeled document-level structures to identify the causalities of events. Liu et al. (2020) identified event causalities with the mention maski"
2021.findings-acl.190,C16-1007,0,0.124547,"help identify the causality of unseen events in S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality inference, where those KBs sto"
2021.findings-acl.190,W16-1007,0,0.0254408,"et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b). Recently, some benchmarks on the event causality have been released. Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation. Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations. Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identification in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016). Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BECauSE (Dunietz et al., 2015) of causal relation and other seven relations. Based on the above benchmarks, Gao et al. (2019) modeled document-level structures to identify the causalities of events. Liu et al. (2020) identified event causalities with the mention masking generalization and external KBs. Zuo et al. (2020) improved the performance of ECI with the distantly automatically labeled training data. However, these methods only rely on a small scale of labeled data. In this paper, we introduce external causal statements"
2021.findings-acl.190,2020.emnlp-main.370,0,0.245465,"ed reasoner to enhance the causal statement representation. However, such mention-mask based reasoner is still trained on the human-annotated examples solely. It will still suffer from data limitations and have no capacity to handling unseen contexts. Moreover, Zuo et al. (2020) improved the performance of ECI with the distantly supervised labeled training data. However, their models are still limited to the unsatisfied qualities of the automatically generated data. To address the insufficient annotated example problem, we employ a large number of external causal statements (Sap et al., 2018; Mostafazadeh et al., 2020) that can support adequate evidence of context-specific causal patterns (Liu et al., 2020) 2162 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 2162–2172 August 1–6, 2021. ©2021 Association for Computational Linguistics for understanding event causalities. For example in Figure 1, the context-specific causal pattern support by an external causal statement S2 is helpful for identifying the causality of event noticedE1 and event alertedE3 in S1 , which is unseen when only training with labeled data. However, different from annotated examples for the ECI task, th"
2021.findings-acl.190,P13-1170,0,0.0638961,"Missing"
2021.findings-acl.190,W14-4322,0,0.0938932,"sal pattern in S2 could help identify the causality of unseen events in S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality infe"
2021.findings-acl.190,W14-0707,0,0.161159,"sal pattern in S2 could help identify the causality of unseen events in S1 . Introduction Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017). For example in Figure 1, an ECI system should identify two causal relations in S1 with mentioned events: noticedE1 cause cause −→ alertedE3 and alertedE3 −→ ranE2 . To date, most existing methods regard this task as a classification problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019). However, the scale of current annotated datasets are relatively limited, where the so far largest dataset EventStoryLine (Caselli and Vossen, 2017) only contains 258 documents, 4316 sentences, and 1770 causal event pairs. As a result, on the limited annotated examples, existing ECI models could not easily capture useful indicators from causal statements, especially for handing those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality infe"
2021.findings-acl.190,2020.coling-main.135,1,0.562556,"g those new, unseen cases. To address this problem, Liu et al. (2020) employed external event-related knowledge bases (KBs) to enhance the causality inference, where those KBs store inherent causal relations between some given events. For those unseen events and unlabeled causalities in KBs, Liu et al. (2020) proposed a mention-mask based reasoner to enhance the causal statement representation. However, such mention-mask based reasoner is still trained on the human-annotated examples solely. It will still suffer from data limitations and have no capacity to handling unseen contexts. Moreover, Zuo et al. (2020) improved the performance of ECI with the distantly supervised labeled training data. However, their models are still limited to the unsatisfied qualities of the automatically generated data. To address the insufficient annotated example problem, we employ a large number of external causal statements (Sap et al., 2018; Mostafazadeh et al., 2020) that can support adequate evidence of context-specific causal patterns (Liu et al., 2020) 2162 Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 2162–2172 August 1–6, 2021. ©2021 Association for Computational Linguistics"
2021.findings-acl.423,W17-4418,0,0.0219582,"Missing"
2021.findings-emnlp.52,P17-1040,0,0.0188525,"proposed distant supervision by using a knowledge base to ated settings. Due to the lack of comparison with annotate a large-scale dataset automatically. HowS1 , previous denoising methods would mistakenly regard S2 as a true positive instance. As a result, ever, automatic labeling inevitably accompanies with label noise. To deal with label noise, most disS2 is retained and then poisons the local model in tantly supervised approaches (Riedel et al., 2010; platform 2, which would affect the global model in Hoffmann et al., 2011; Surdeanu et al., 2012; Zeng turn. et al., 2015; Lin et al., 2016; Luo et al., 2017; Ye To suppress label noise in federated settings, we and Ling, 2019; Yuan et al., 2019; Yu et al., 2020a) propose a federated denoising framework in this focus on reducing label noise at bag 2 level prepaper. The core of this framework is a multiple instance learning (MIL) (Dietterich et al., 1997; diction. These studies fall under multiple instance learning framework, which assumes that at least Maron and Lozano-Pérez, 1998) based denoising algorithm, called Lazy MIL, which is only ex- one sentence expresses the relation in a bag. Another line of work aims to reduce label noise at senecuted"
2021.findings-emnlp.52,P09-1113,0,0.0728067,"r- ies in federated learning and federated learning in rier between Platform 1 and Platform 2; therefore, natural language processing (NLP). Distant Supervision. Relation extraction is a simultaneously considering S1 and S2 can easily task of mining factual knowledge from free text filter out noise via only selecting S1 (Zeng et al., 2015) or placing a small weight on S2 (Lin et al., by labeling relations between entity mentions. To 2016; Ye and Ling, 2019). However, raw data ex- alleviate the dependence of supervised methods change between platforms is prohibited in feder- on annotated data, Mintz et al. (2009) proposed distant supervision by using a knowledge base to ated settings. Due to the lack of comparison with annotate a large-scale dataset automatically. HowS1 , previous denoising methods would mistakenly regard S2 as a true positive instance. As a result, ever, automatic labeling inevitably accompanies with label noise. To deal with label noise, most disS2 is retained and then poisons the local model in tantly supervised approaches (Riedel et al., 2010; platform 2, which would affect the global model in Hoffmann et al., 2011; Surdeanu et al., 2012; Zeng turn. et al., 2015; Lin et al., 2016;"
2021.findings-emnlp.52,P18-1046,0,0.0214348,"reducing label noise at bag 2 level prepaper. The core of this framework is a multiple instance learning (MIL) (Dietterich et al., 1997; diction. These studies fall under multiple instance learning framework, which assumes that at least Maron and Lozano-Pérez, 1998) based denoising algorithm, called Lazy MIL, which is only ex- one sentence expresses the relation in a bag. Another line of work aims to reduce label noise at senecuted at the beginning of each communication round and then would rest until the next round. tence level prediction. These studies (Zeng et al., 2018; Feng et al., 2018; Qin et al., 2018a,b) use Since the sentences containing the same entity pair scatter around different platforms, Lazy MIL al- reinforcement learning or adversarial training to 2 gorithm coordinates multiple platforms to jointly A set of sentences containing the same entity pair is called select reliable sentences. Once sentences have been a “bag&quot; 570 select trustable relation labels by matching the predicted labels with distantly supervised labels. In this paper, we follows the line of bag level prediction. Different from previous studies, our work extends distant supervision to federated settings. Federated"
2021.findings-emnlp.52,P18-1199,0,0.0210876,"reducing label noise at bag 2 level prepaper. The core of this framework is a multiple instance learning (MIL) (Dietterich et al., 1997; diction. These studies fall under multiple instance learning framework, which assumes that at least Maron and Lozano-Pérez, 1998) based denoising algorithm, called Lazy MIL, which is only ex- one sentence expresses the relation in a bag. Another line of work aims to reduce label noise at senecuted at the beginning of each communication round and then would rest until the next round. tence level prediction. These studies (Zeng et al., 2018; Feng et al., 2018; Qin et al., 2018a,b) use Since the sentences containing the same entity pair scatter around different platforms, Lazy MIL al- reinforcement learning or adversarial training to 2 gorithm coordinates multiple platforms to jointly A set of sentences containing the same entity pair is called select reliable sentences. Once sentences have been a “bag&quot; 570 select trustable relation labels by matching the predicted labels with distantly supervised labels. In this paper, we follows the line of bag level prediction. Different from previous studies, our work extends distant supervision to federated settings. Federated"
2021.findings-emnlp.52,P16-1162,0,0.0481373,"Missing"
2021.findings-emnlp.52,2020.emnlp-main.300,0,0.0337082,", then all sentences a great deal of centralized unstructured text. However, in practice, texts are usually disthat mention these two entities will express this tributed on different platforms and cannot be relation. Since then, there has been a rich litercentralized due to privacy restrictions. Thereature devoted to this topic, such as Riedel et al. fore, it is worthwhile to investigate distant su(2010); Hoffmann et al. (2011); Zeng et al. (2015); pervision in the federated learning paradigm, Lin et al. (2016); Ye and Ling (2019); Yuan et al. which decouples the training of the model (2019); Xiao et al. (2020). from the need for direct access to raw texts. However, overcoming label noise of distant suThough the progress is exciting, distant superpervision becomes more difficult in federated vision approaches have so far been limited to the settings, because texts containing the same encentralized learning paradigm, which assumes that tity pair scatter around different platforms. In a great deal of text is easily accessible. However, this paper, we propose a federated denoising in practice, texts are usually distributed on differframework to suppress label noise in federated ent platforms and are ma"
2021.findings-emnlp.52,N19-1288,0,0.136527,"ening studies in this field have assumed there is tities have a relation in the KB, then all sentences a great deal of centralized unstructured text. However, in practice, texts are usually disthat mention these two entities will express this tributed on different platforms and cannot be relation. Since then, there has been a rich litercentralized due to privacy restrictions. Thereature devoted to this topic, such as Riedel et al. fore, it is worthwhile to investigate distant su(2010); Hoffmann et al. (2011); Zeng et al. (2015); pervision in the federated learning paradigm, Lin et al. (2016); Ye and Ling (2019); Yuan et al. which decouples the training of the model (2019); Xiao et al. (2020). from the need for direct access to raw texts. However, overcoming label noise of distant suThough the progress is exciting, distant superpervision becomes more difficult in federated vision approaches have so far been limited to the settings, because texts containing the same encentralized learning paradigm, which assumes that tity pair scatter around different platforms. In a great deal of text is easily accessible. However, this paper, we propose a federated denoising in practice, texts are usually distribute"
2021.findings-emnlp.52,2020.coling-main.146,0,0.0674843,"h annotate a large-scale dataset automatically. HowS1 , previous denoising methods would mistakenly regard S2 as a true positive instance. As a result, ever, automatic labeling inevitably accompanies with label noise. To deal with label noise, most disS2 is retained and then poisons the local model in tantly supervised approaches (Riedel et al., 2010; platform 2, which would affect the global model in Hoffmann et al., 2011; Surdeanu et al., 2012; Zeng turn. et al., 2015; Lin et al., 2016; Luo et al., 2017; Ye To suppress label noise in federated settings, we and Ling, 2019; Yuan et al., 2019; Yu et al., 2020a) propose a federated denoising framework in this focus on reducing label noise at bag 2 level prepaper. The core of this framework is a multiple instance learning (MIL) (Dietterich et al., 1997; diction. These studies fall under multiple instance learning framework, which assumes that at least Maron and Lozano-Pérez, 1998) based denoising algorithm, called Lazy MIL, which is only ex- one sentence expresses the relation in a bag. Another line of work aims to reduce label noise at senecuted at the beginning of each communication round and then would rest until the next round. tence level predi"
2021.naacl-main.261,P07-1056,0,0.082676,"re constructed by corrupting either subjects or objects. Knowledge Retrieval Inspired by the previous studies (Yang and Mitchell, 2017; Yang et al., 2019), exact string matching (Charras and Lecroq, 2004) is used to recognize entity mentions from a given passage and link recognized entity mentions to subjects in KB. Then, we collect the corresponding objects (concepts) as candidates. After this retrieval process, we obtain a set of potentially relevant KB concepts, where each KB concept is associated with a KB embedding. 4 4.1 Experiment Dataset Our model is evaluated on the widely used ARSC (Blitzer et al., 2007) dataset, which comprises reviews for 23 types of products on Amazon. For each product domain, there are three different binary classification tasks. These buckets form 69 tasks in total. Following Yu et al. (2018), we select 12 tasks from four domains (Books, DVDs, Electronics, and Kitchen) as testing set, with only (8) 5 examples as support set for each class. 3268 4.2 Implementation Details In our experiments, we use hugginface’s implementation1 of BERT (base version) and initialize parameters of the BERT encoding layer with pre-trained models officially released by Google2 . To represent k"
2021.naacl-main.261,N19-1423,0,0.0321339,"hown in Equation 2) and the knowledge of the support set as input, and produces a scalar in range of 0 to 1 representing the similarity between the query sentence and the class representation, which is called relation score. Compared with the original relation network (Sung et al., 2018), we decompose the relation network into two parts, task-agnostic relation network and task-relevant relation network, in order to serve two purposes. Task agnostic relation network models a basic metric function, while taskrelevant relation network adapts to diverse tasks. In this network, a pre-trained BERT (Devlin et al., 2019) encoder is used to model sentences. Given Task-Agnostic Relation Network The taskan input text xi = ([CLS], w1 , w2 , ..., wT , [SEP]) agnostic relation network uses a learned unified as input, the output of BERT encoder is denoted metric for all tasks, which is the same with the orig(T +2)×d 1 as H(xi ) ∈ R , where d1 is the output inal relation network (Sung et al., 2018). With this agn dimension of the BERT encoder. We use the first unified metric, C task-agnostic relation scores rz,j 3267 are generated for modeling the relation between one query input xj and the class representation cz ,"
2021.naacl-main.261,2020.acl-main.102,0,0.0329205,"Missing"
2021.naacl-main.261,D19-1403,0,0.0709613,"e different metrics. Through experiments, we demonstrate that our method outperforms the SoTA few-shot text classification models. 1 Introduction To adapt metric learning to significantly diverse tasks, we propose a knowledge guided metric learning method. This method is inspired by the fact that human beings approach diverse tasks armed with knowledge obtained from relevant tasks (Lake et al., 2017). We use external knowledge from the knowledge base (KB) to imitate human knowledge, whereas the role of external knowledge has been ignored in previous methods (Yu et al., 2018; Bao et al., 2019; Geng et al., 2019, 2020). In detail, we resort to distributed representations of the KB instead of symbolic facts, since symbolic facts face the issues of poor generalization and data sparsity. Based on such KB embeddings, we investigate a novel parameter generator network (Ha et al., 2016; Jia et al., 2016) to generate task-relevant relation network parameters. With these generated parameters, the task-relevant relation network is able to apply diverse metrics to diverse tasks and ensure that similar tasks use similar metrics while different tasks use different metrics. In summary, the major contributions of"
2021.naacl-main.261,D18-2024,0,0.0294656,"assification tasks. These buckets form 69 tasks in total. Following Yu et al. (2018), we select 12 tasks from four domains (Books, DVDs, Electronics, and Kitchen) as testing set, with only (8) 5 examples as support set for each class. 3268 4.2 Implementation Details In our experiments, we use hugginface’s implementation1 of BERT (base version) and initialize parameters of the BERT encoding layer with pre-trained models officially released by Google2 . To represent knowledge in NELL (Carlson et al., 2010), BILINEAR model (Yang et al., 2015) is implemented with the open-source framework OpenKE (Han et al., 2018) to obtain the embedding of entities and relations. The size of embeddings of entities and relations is set to 100. To train our model, We use Adam optimizer (Kingma and Ba, 2014) with a learning rate of 0.00001. All experiments are run with an NVIDIA GeForce RTX 2080 Ti. 4.3 Experiment Results Baseline. We compare our method to the following baselines: (1) Match Network is a metricbased attention method for few-shot learning; (2) Prototypical Network is a metric-based method that uses sample averages as class prototypes; (3) MAML is an optimization-based method through learning to learn with"
2021.naacl-main.261,P19-1226,0,0.0175714,"ed in the real number space. We adopt the BILINEAR model (Yang et al., 2015) to measure the validity of triples: f (s, r, o) = sT diag(r)o ∈ R (9) where s, r, o ∈ Rd2 are the embeddings associated with s, r, o, respectively, and diag(r) is a diagonal matrix with the main diagonal given by the relation embedding r. To learn these vector embeddings, a margin-based ranking loss is designed, where triples in the KB are adopted to be positive and negative triples are constructed by corrupting either subjects or objects. Knowledge Retrieval Inspired by the previous studies (Yang and Mitchell, 2017; Yang et al., 2019), exact string matching (Charras and Lecroq, 2004) is used to recognize entity mentions from a given passage and link recognized entity mentions to subjects in KB. Then, we collect the corresponding objects (concepts) as candidates. After this retrieval process, we obtain a set of potentially relevant KB concepts, where each KB concept is associated with a KB embedding. 4 4.1 Experiment Dataset Our model is evaluated on the widely used ARSC (Blitzer et al., 2007) dataset, which comprises reviews for 23 types of products on Amazon. For each product domain, there are three different binary class"
2021.naacl-main.261,P17-1132,0,0.0266367,"the triple can be measured in the real number space. We adopt the BILINEAR model (Yang et al., 2015) to measure the validity of triples: f (s, r, o) = sT diag(r)o ∈ R (9) where s, r, o ∈ Rd2 are the embeddings associated with s, r, o, respectively, and diag(r) is a diagonal matrix with the main diagonal given by the relation embedding r. To learn these vector embeddings, a margin-based ranking loss is designed, where triples in the KB are adopted to be positive and negative triples are constructed by corrupting either subjects or objects. Knowledge Retrieval Inspired by the previous studies (Yang and Mitchell, 2017; Yang et al., 2019), exact string matching (Charras and Lecroq, 2004) is used to recognize entity mentions from a given passage and link recognized entity mentions to subjects in KB. Then, we collect the corresponding objects (concepts) as candidates. After this retrieval process, we obtain a set of potentially relevant KB concepts, where each KB concept is associated with a KB embedding. 4 4.1 Experiment Dataset Our model is evaluated on the widely used ARSC (Blitzer et al., 2007) dataset, which comprises reviews for 23 types of products on Amazon. For each product domain, there are three di"
2021.naacl-main.261,N18-1109,0,0.318992,"ar metrics while different tasks use different metrics. Through experiments, we demonstrate that our method outperforms the SoTA few-shot text classification models. 1 Introduction To adapt metric learning to significantly diverse tasks, we propose a knowledge guided metric learning method. This method is inspired by the fact that human beings approach diverse tasks armed with knowledge obtained from relevant tasks (Lake et al., 2017). We use external knowledge from the knowledge base (KB) to imitate human knowledge, whereas the role of external knowledge has been ignored in previous methods (Yu et al., 2018; Bao et al., 2019; Geng et al., 2019, 2020). In detail, we resort to distributed representations of the KB instead of symbolic facts, since symbolic facts face the issues of poor generalization and data sparsity. Based on such KB embeddings, we investigate a novel parameter generator network (Ha et al., 2016; Jia et al., 2016) to generate task-relevant relation network parameters. With these generated parameters, the task-relevant relation network is able to apply diverse metrics to diverse tasks and ensure that similar tasks use similar metrics while different tasks use different metrics. In"
2021.naacl-main.453,W13-3515,0,0.206677,"many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by the key relational phrases, but the implicit relation “Live in” 1 Introduction is not expressed explicitly. Unfortunately, existing Relational triple extraction is defined as automat- methods usually ignored implicit triples (Zhu et al., 2019), which will cause serious incompleteness of ically recognizing semantic relations with triple structures (subject, relation, object) among multi- the constructed KGs and performance degradation of downstream tasks (Angeli and Manning, 2013; ple entities in a sentence. It is a critical task for constructing Knowledge Graphs (KGs) from unla- Jia et al., 2020; Jun et al., 2020). beled corpus (Dong et al., 2014). Our work is motivated by several observations. Early work of relational triple extraction ap- First, other relational triples within a sentence proplied pipeline methods (Zelenko et al., 2003; Chan vide supplementary information for discovering and Roth, 2011), which ran entity recognition and entity pairs that may have implicit relational conrelation classification separately. However, such nections. For example, in Figur"
2021.naacl-main.453,P11-1056,0,0.0284052,"lementary evidence for discovering entity pairs with implicit relational connections. Second, the relation types of the implicit connections need to be identified through real-world reasoning patterns. In this paper, we propose a unified framework for the joint extraction of explicit and implicit rela2 Related Work tional triples. We propose a binary pointer network Early work of relational triple extraction addressed to sequentially extract overlapping relational triples this task in a pipelined manner (Zelenko et al., and externally keep the information of predicted 2003; Zhou et al., 2005; Chan and Roth, 2011; triples for exploring implicitly connected entity Gormley et al., 2015). They first ran named entity pairs. We also propose to introduce real-world rearecognition to identify all entities and then classi- soning patterns in our model to help derive the relafied relations between all entity pairs. However, tion type of implicit triples with a relation network. these pipelined methods usually suffered from er- Experimental results on several benchmark datasets ror propagation problem and failed to capture the demonstrate the effectiveness of our method. 5695 Extracted Triples (i=n) Linear Gate"
2021.naacl-main.453,N19-1423,0,0.0197871,"0 for others. We also train the entity tagger with a cross-entrory loss: 1 4 Table 1: Statistics of evaluation datasets. 4.2 Experimental Settings We determine the hyper-parameters on the validation sets. We use the pre-trained GloVe (Pennington et al., 2014) embeddings as w. We adopt a one-layer CNN with dc = 30 channels to learn c from 30-dimensional randomly-initialized character embeddings. We choose the state-of-the-art RoBERTaLARGE (Liu et al., 2019) model3 as the pre-tained LM. For a fair comparison with previous methods, we also conduct experiments and report the scores with BERTBASE (Devlin et al., 2019). We set din (Equation 1) as 300. The hidden dimensions of the encoder dE and the entity tagger dT are both 200. The dimensions of entity tag embeddings de and relation type embeddings dR are set as 50 and 200, respectively. The projection dimension dP of the RN is set as 500. 2 As mentioned in (Wang et al., 2020), this number is miswritten as 246 in (Wei et al., 2020) and (Yu et al., 2019). Here we quote the correct number from (Wang et al., 2020). 3 https://github.com/huggingface/transformers 5698 NYT Method WebNLG Prec. Rec. F1 Prec. Rec. F1 NovelTagging (Zheng et al., 2017) CopyRE (Zeng et"
2021.naacl-main.453,P19-1136,0,0.0492987,"Missing"
2021.naacl-main.453,P17-1017,0,0.0299237,"the binary scores of candidate triples. We denote our Reasoning pattern enhanced BPtrNet model as R-BPtrNet. Note that we use quite simple formulas for fφ and gθ because our contribution focuses on the effectiveness of introducing relational reasoning patterns for this task rather than the model structure. Exploration for more complex structures will be left for future work. 3.3 4.1 Experiments Datasets and Evaluation Metrics We evaluate our method on two benchmark datasets. NYT (Riedel et al., 2010) consists of sentences from the New York Times corpus and contains 24 relation types. WebNLG (Gardent et al., 2017) was created for natural language generation task. It contains 171 relation types2 and was adopted for relational triple extraction by (Zeng et al., 2018). We split the sentences into three categories: Normal, SingleEntityOverlap (SPO) and EntityPairOverlap (EPO) following Zeng et al. (2018). The statistics of the two datasets are shown in Table 1. Following previous work (Zeng et al., 2018; Wei et al., 2020; Wang et al., 2020), an extracted relational triple is regarded as correct only if the relation and the heads of both subject and object are all correct. We report the standard micro preci"
2021.naacl-main.453,D15-1205,0,0.0627378,"Missing"
2021.naacl-main.453,C16-1239,0,0.100715,"on network. We conduct experiments on several benchmark datasets, and the results prove the validity of our method. Locate in Work for … Mark Spencer, a designer of Digium, a company in Huntsville … Live in Person Organization Location Explict Triple Implicit Triple Figure 1: An example of explicit and implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by t"
2021.naacl-main.453,P14-1038,0,0.211649,"iples, we propose to introduce real-world relational reasoning patterns in our model and capture these patterns with a relation network. We conduct experiments on several benchmark datasets, and the results prove the validity of our method. Locate in Work for … Mark Spencer, a designer of Digium, a company in Huntsville … Live in Person Organization Location Explict Triple Implicit Triple Figure 1: An example of explicit and implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit"
2021.naacl-main.453,2021.ccl-1.108,0,0.0301336,"Missing"
2021.naacl-main.453,P16-1105,0,0.0215395,"xtracted triples. • To enhance the relation type inference of implicitly connected entity pairs, we propose to introduce relational reasoning patterns, captured with a RN, to augment our model. • We conduct experiments on several benchmark datasets and the experimental results demonstrate the validity of our method. interactions between entities and relations. To overcome these drawbacks, recent research focused on jointly extracting entities and relations, including feature-based models (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017) and neural network-based models (Gupta et al., 2016; Miwa and Bansal, 2016; Zheng et al., 2017). For example, Ren et al. (2017) proposed to jointly embed entities, relations, text features and type labels into two low-dimensional spaces. Miwa and Bansal (2016) proposed a joint model containing two long-short term memories (LSTMs) (Gers et al., 2000) with shared parameters. Zheng et al. (2017) proposed to extract relational triples directly by transforming this task into a sequence tagging problem, whose tags contain the information of entities and the relations they hold. However, they only assigned one label for each word, which means that this method failed to ext"
2021.naacl-main.453,D14-1162,0,0.0887317,"000 5019 703 Training and Inference We calculate the triple loss of a sentence as a binary cross entropy over valid candidate triples Tv , whose subject and object are different entities (or the end words of different entities):  X 1 yt log st +(1−yt ) log(1−st ) Lt = − |Tv | t∈Tv (9) where st is the score of the candidate triple t, yt = 1 for gold triples and 0 for others. We also train the entity tagger with a cross-entrory loss: 1 4 Table 1: Statistics of evaluation datasets. 4.2 Experimental Settings We determine the hyper-parameters on the validation sets. We use the pre-trained GloVe (Pennington et al., 2014) embeddings as w. We adopt a one-layer CNN with dc = 30 channels to learn c from 30-dimensional randomly-initialized character embeddings. We choose the state-of-the-art RoBERTaLARGE (Liu et al., 2019) model3 as the pre-tained LM. For a fair comparison with previous methods, we also conduct experiments and report the scores with BERTBASE (Devlin et al., 2019). We set din (Equation 1) as 300. The hidden dimensions of the encoder dE and the entity tagger dT are both 200. The dimensions of entity tag embeddings de and relation type embeddings dR are set as 50 and 200, respectively. The projection"
2021.naacl-main.453,C10-2160,0,0.0656999,"icit relational triples, we propose to introduce real-world relational reasoning patterns in our model and capture these patterns with a relation network. We conduct experiments on several benchmark datasets, and the results prove the validity of our method. Locate in Work for … Mark Spencer, a designer of Digium, a company in Huntsville … Live in Person Organization Location Explict Triple Implicit Triple Figure 1: An example of explicit and implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there a"
2021.naacl-main.453,D19-1035,0,0.0600746,"1) as 300. The hidden dimensions of the encoder dE and the entity tagger dT are both 200. The dimensions of entity tag embeddings de and relation type embeddings dR are set as 50 and 200, respectively. The projection dimension dP of the RN is set as 500. 2 As mentioned in (Wang et al., 2020), this number is miswritten as 246 in (Wei et al., 2020) and (Yu et al., 2019). Here we quote the correct number from (Wang et al., 2020). 3 https://github.com/huggingface/transformers 5698 NYT Method WebNLG Prec. Rec. F1 Prec. Rec. F1 NovelTagging (Zheng et al., 2017) CopyRE (Zeng et al., 2018) CopyRERL (Zeng et al., 2019) GraphRel (Fu et al., 2019) ETL-Span (Yu et al., 2019) CopyMTL (Zeng et al., 2020) WDec (Nayak and Ng, 2020) CGTUniLM (Ye et al., 2020) C AS R ELLSTM (Wei et al., 2020) C AS R ELBERT (Wei et al., 2020) TPLinkerLSTM (Wang et al., 2020) TPLinkerBERT (Wang et al., 2020) 62.4 72.8 77.9 63.9 84.9 75.7 94.5 94.7 84.2 89.7 83.8 91.3 31.7 69.4 67.2 60.0 72.3 68.7 76.2 84.2 83.0 89.5 83.4 92.5 42.0 71.1 72.1 61.9 78.1 72.0 84.4 89.1 83.6 89.6 83.6 91.9 52.5 60.9 63.3 44.7 84.0 58.0 92.9 86.9 93.4 90.8 91.8 19.3 61.1 59.9 41.1 91.5 54.9 75.6 80.6 90.1 90.3 92.0 28.3 61.0 61.6 42.9 87.6 56.4 83.4 83.7 91"
2021.naacl-main.453,P18-1047,0,0.228397,"ict Triple Implicit Triple Figure 1: An example of explicit and implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by the key relational phrases, but the implicit relation “Live in” 1 Introduction is not expressed explicitly. Unfortunately, existing Relational triple extraction is defined as automat- methods usually ignored implicit triples (Zhu et al., 20"
2021.naacl-main.453,2020.coling-main.138,0,0.230316,"d implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by the key relational phrases, but the implicit relation “Live in” 1 Introduction is not expressed explicitly. Unfortunately, existing Relational triple extraction is defined as automat- methods usually ignored implicit triples (Zhu et al., 2019), which will cause serious incompleteness of ically recogniz"
2021.naacl-main.453,P17-1113,0,0.348376,"ct experiments on several benchmark datasets, and the results prove the validity of our method. Locate in Work for … Mark Spencer, a designer of Digium, a company in Huntsville … Live in Person Organization Location Explict Triple Implicit Triple Figure 1: An example of explicit and implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by the key relational phr"
2021.naacl-main.453,2020.acl-main.136,0,0.463045,"er of Digium, a company in Huntsville … Live in Person Organization Location Explict Triple Implicit Triple Figure 1: An example of explicit and implicit relational triples. Italic phrases are key relational expressions corresponding to the explicit relational triples. with feature-based methods (Yu and Lam, 2010; Li and Ji, 2014; Ren et al., 2017). Afterward, neural network-based models were proposed to eliminate hand-crafted features (Gupta et al., 2016; Zheng et al., 2017). More recently, several methods were proposed to extract overlapping triples, such as tagging-based (Dai et al., 2019; Wei et al., 2020), graph-based (Wang et al., 2018; Fu et al., 2019), copy-based (Zeng et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by the key relational phrases, but the implicit relation “Live in” 1 Introduction is not expressed explicitly. Unfortunately, existing Relational triple extractio"
2021.naacl-main.453,P19-1128,0,0.230987,"g et al., 2018, 2019, 2020) and token pair linking models (Wang et al., 2020). Existing models achieved considerable success on extracting explicit triples which have direct relational expressions in the sentence. However, there are many implicit relational triples that are not explicitly expressed. For example, in Figure 1, the explicit triples are strongly indicated by the key relational phrases, but the implicit relation “Live in” 1 Introduction is not expressed explicitly. Unfortunately, existing Relational triple extraction is defined as automat- methods usually ignored implicit triples (Zhu et al., 2019), which will cause serious incompleteness of ically recognizing semantic relations with triple structures (subject, relation, object) among multi- the constructed KGs and performance degradation of downstream tasks (Angeli and Manning, 2013; ple entities in a sentence. It is a critical task for constructing Knowledge Graphs (KGs) from unla- Jia et al., 2020; Jun et al., 2020). beled corpus (Dong et al., 2014). Our work is motivated by several observations. Early work of relational triple extraction ap- First, other relational triples within a sentence proplied pipeline methods (Zelenko et al.,"
2021.smm4h-1.13,2021.ccl-1.108,0,0.0491427,"Missing"
2021.smm4h-1.13,P16-1101,0,0.0906702,"Missing"
2021.smm4h-1.13,2021.smm4h-1.3,0,0.0283476,"tional Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences 2 School of Artificial Intelligence University of Chinese Academy of Sciences 3 Beijing University of Posts and Telecommunications 4 Beijing University of Chemical Technology 5 Beijing Unisound Information Technology Co., Ltd {tongzhou21, niukun}@bupt.edu.cn {zhucong.li,baoli.zhang,yubo.chen,kliu,jzhao}@nlpr.ia.ac.cn {ganzhen, wanj}@mail.buct.edu.cn {shiyafei,chongweifeng,liushengping}@unisound.com that mentions ADE in the tweet; (3) normalization ADE mentions to standard terms. Subtask b of task 7 (Miranda-Escalada et al., 2021) is designed to identify professions and occupations (ProfNER) in Spanish tweets during the COVID-19 outbreak. Task 8 is targeting the classification of self-reported breast cancer posts on Twitter. The ubiquitous two challenges of all the SMM4H shared tasks are (1) how to properly model the colloquial text in tweets; (2) avoid prediction bias caused by learning from unbalanced annotated data. The tweet’s text, mixing with informal spelling, various emojis, usernames mentioned, and hyperlinks, will hinder the real semantic comprehension by a common pre-trained language model. Meanwhile, medica"
2021.smm4h-1.13,2020.emnlp-demos.2,0,0.0332969,"Missing"
C14-1010,P09-1082,0,0.0142399,"stions and the historical questions in the archives. For example, if a queried question contains the word “company” but a relevant historical question instead contains the word “firm”, then there is a mismatch and the historical question may not be easily distinguished from an irrelevant one. To solve the lexical gap problem, most researchers focused on translation-based approaches since the relationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases) translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012). However, these existing methods model the relevance ranking without considering the category-specific and shared topics with natural categories, it is not clear whether this information is useful for question retrieval. A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questions into a hierarchy of natural categories. For example, Yahoo! Answers contains a hierarchy of 26 categories at the first level and more than 1262 subcategories at the leaf level. When a user asks a question, the user is typically required to cho"
C14-1010,I11-1031,1,0.958854,"o matrices: one matrix represents the category-specific topics as well as the shared topics, and the other matrix denotes the question representation based on topics. An objective function is defined to measure the goodness of prediction of the data with the model. Optimization of the objective function leads to the automatic discovery of topics as well as the topic representation of questions. Finally, we calculate the relevance ranking between the queried questions and the historical questions in the latent topic space. Past studies by (Cao et al., 2009; Cao et al., 2010; Ming et al., 2010; Cai et al., 2011; Ji et al., 2012; Zhou et al., 2013) confirmed a significant retrieval improvement by adding the natural categories into various existing retrieval models. However, all these previous work regarded natural categories individually without considering the relationships among them. On the contrary, this paper can effectively capture the relationships between the shared aspects and the category-specific individual aspects with natural categories via a group non-negative matrix factorization framework. Also, our work models the relevance ranking in the latent topic space rather than using the exis"
C14-1010,D08-1043,0,0.583662,"en the queried questions and the historical questions in the archives. For example, if a queried question contains the word “company” but a relevant historical question instead contains the word “firm”, then there is a mismatch and the historical question may not be easily distinguished from an irrelevant one. To solve the lexical gap problem, most researchers focused on translation-based approaches since the relationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases) translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012). However, these existing methods model the relevance ranking without considering the category-specific and shared topics with natural categories, it is not clear whether this information is useful for question retrieval. A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questions into a hierarchy of natural categories. For example, Yahoo! Answers contains a hierarchy of 26 categories at the first level and more than 1262 subcategories at the leaf level. When a user asks a question, the user"
C14-1010,P07-1059,0,0.0172911,"etrieval tasks, is the lexical gap between the queried questions and the historical questions in the archives. For example, if a queried question contains the word “company” but a relevant historical question instead contains the word “firm”, then there is a mismatch and the historical question may not be easily distinguished from an irrelevant one. To solve the lexical gap problem, most researchers focused on translation-based approaches since the relationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases) translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012). However, these existing methods model the relevance ranking without considering the category-specific and shared topics with natural categories, it is not clear whether this information is useful for question retrieval. A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questions into a hierarchy of natural categories. For example, Yahoo! Answers contains a hierarchy of 26 categories at the first level and more than 1262 subcategories at the leaf level. W"
C14-1010,D12-1116,0,0.896946,"ves. For example, if a queried question contains the word “company” but a relevant historical question instead contains the word “firm”, then there is a mismatch and the historical question may not be easily distinguished from an irrelevant one. To solve the lexical gap problem, most researchers focused on translation-based approaches since the relationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases) translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012). However, these existing methods model the relevance ranking without considering the category-specific and shared topics with natural categories, it is not clear whether this information is useful for question retrieval. A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questions into a hierarchy of natural categories. For example, Yahoo! Answers contains a hierarchy of 26 categories at the first level and more than 1262 subcategories at the leaf level. When a user asks a question, the user is typically required to choose a category label for the ques"
C14-1010,P11-1066,1,0.957131,"stions in the archives. For example, if a queried question contains the word “company” but a relevant historical question instead contains the word “firm”, then there is a mismatch and the historical question may not be easily distinguished from an irrelevant one. To solve the lexical gap problem, most researchers focused on translation-based approaches since the relationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases) translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012). However, these existing methods model the relevance ranking without considering the category-specific and shared topics with natural categories, it is not clear whether this information is useful for question retrieval. A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questions into a hierarchy of natural categories. For example, Yahoo! Answers contains a hierarchy of 26 categories at the first level and more than 1262 subcategories at the leaf level. When a user asks a question, the user is typically required to choose a category labe"
C14-1010,P13-1084,1,0.757024,"he category-specific topics as well as the shared topics, and the other matrix denotes the question representation based on topics. An objective function is defined to measure the goodness of prediction of the data with the model. Optimization of the objective function leads to the automatic discovery of topics as well as the topic representation of questions. Finally, we calculate the relevance ranking between the queried questions and the historical questions in the latent topic space. Past studies by (Cao et al., 2009; Cao et al., 2010; Ming et al., 2010; Cai et al., 2011; Ji et al., 2012; Zhou et al., 2013) confirmed a significant retrieval improvement by adding the natural categories into various existing retrieval models. However, all these previous work regarded natural categories individually without considering the relationships among them. On the contrary, this paper can effectively capture the relationships between the shared aspects and the category-specific individual aspects with natural categories via a group non-negative matrix factorization framework. Also, our work models the relevance ranking in the latent topic space rather than using the existing retrieval models. To date, no at"
D15-1203,H05-1091,0,0.0182546,"Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a part"
D15-1203,P11-1055,0,0.847103,"the distant supervision assumption is too strong and causes the wrong label problem. A sentence that mentions two entities does not necessarily express their relation in a knowledge base. It is possible that these two entities may simply share the same topic. For instance, the upper sentence indeed expresses the “company/founders” relation in Figure 1. The lower sentence, however, does not express this relation but is still selected as a training instance. This will hinder the performance of a model trained on such noisy data. Second, previous methods (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision. These features are often derived from preexisting Natural Language Processing (NLP) tools. Since errors inevitably exist in NLP tools, the use of traditional features leads to error propagation or accumulation. Distant supervised relation extraction generally ad1 http://www.freebase.com/ 1753 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Com"
D15-1203,J14-1004,0,0.00734325,"larity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 ... hired , the son of ma x(c 1 ... ma x(c 1 2 , in 1 ) ) ... max(c13) word position Vector representation Convolution Piecewise max pooling Softmax classifier Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013). In this paper, we use"
D15-1203,P09-1113,0,0.971786,"reated as a multi-instance problem in which the uncertainty of instance labels is taken into account. To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features. Experiments show that our method is effective and outperforms several competitive baseline methods. 1 Introduction In relation extraction, one challenge that is faced when building a machine learning system is the generation of training examples. One common technique for coping with this difficulty is distant supervision (Mintz et al., 2009) which assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way. Figure 1 shows an example of the automatic labeling of data through distant supervision. In this example, Apple and Steve Jobs are two related entities in Freebase1 . All sentences that contain these two entities are selected as training instances. The distant supervision strategy is an effective method of automatically labeling training data. However, it has two major shortcomings when used for relation extraction. Fi"
D15-1203,P14-1100,0,0.00732672,"in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 ... hired , the son of ma x(c 1 ... ma x(c 1 2 , in 1 ) ) ... max(c13) word position Vector representation Convolution Piecewise max pooling Softmax classifier Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013). I"
D15-1203,D14-1162,0,0.125053,"onal vectors. In our method, each input word token is transformed into a vector by looking up pre-trained word embeddings. Moreover, we use position features (PFs) to specify entity pairs, which are also transformed into vectors by looking up position embeddings. 3.1.1 Word Embeddings Word embeddings are distributed representations of words that map each word in a text to a ‘k’dimensional real-valued vector. They have recently been shown to capture both semantic and syntactic information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 ... hired , the son of ma x(c 1 ... ma x(c 1 2 , in 1 ) ) ... max(c13) word position Vector representation Convolution Piecewise max pooling Softmax classifier Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural ne"
D15-1203,C08-1088,0,0.0992936,"to convert classification clues (e.g., sequences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Die"
D15-1203,D12-1110,0,0.0128094,"arse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a particularly interesting topic. Zhang and Zhou (2006) successfully incorporated multiinstance learning into traditional Backpropagation (BP) and Radial Basis Function (RBF) networks and optimized these networks by minimizing a sum-of-squares error function. In contrast to their method, we define the obje"
D15-1203,D12-1042,0,0.923468,"2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem, the training set consists of many bags, and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. ("
D15-1203,D14-1181,0,0.0100498,"ive function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features. Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information. These approaches usually consider both internal and external contexts. A sentence is inherently divided into three segments according to the two given entities. The internal context includes"
D15-1203,C14-1220,1,0.777227,"iedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem, the training set consists of many bags, and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features. Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have e"
D15-1203,D07-1013,0,0.00778306,"m/ 1753 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. 8000 Number of sentence 6000 4000 2000 0 0 20 40 60 Sentence Length 80 100 Figure 2: The sentence length distribution of Riedel’s dataset. dresses corpora from the Web, including many informal texts. Figure 2 shows the sentence length distribution of a benchmark distant supervision dataset that was developed by Riedel et al. (2010). Approximately half of the sentences are longer than 40 words. McDonald and Nivre (2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surde"
D15-1203,P06-1104,0,0.0256735,"tities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information. These approaches usually consider both internal and external contexts. A sentence is inherently divided into three segments according to the two given entities. The internal context includes the characters inside the two entities, and the external context involves the characters around the two entities (Zhang et al., 2006). Clearly, single max pooling is not sufficient to capture such structural information. To capture structural and other latent information, we divide the convolution results into three segments based on the positions of the two given entities and devise a piecewise max pooling layer instead of the single max pooling layer. The piecewise max pooling procedure returns the maximum value in each segment instead of a single maximum value over the entire sentence. Thus, it is expected to exhibit superior performance compared with traditional methods. The contributions of this paper can be summarized"
D15-1203,P05-1053,0,0.547616,"earning into the PCNNS for distant supervised relation extraction. • In the proposed network, we devise a piecewise max pooling layer, which aims to capture structural information between two entities. 2 Related Work Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance learning was coined"
D18-1017,A97-1029,0,0.532514,"for some words such as “ • (Hilton)” and “» (leaves)”, while Chinese NER has more coarse-grained boundaries Introduction The task of named entity recognition (NER) is to recognize the named entities in given text. NER is a preliminary and important task in natural language processing (NLP) area and can be used in many downstream NLP tasks, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015) and question answering (Yao and Van Durme, 2014). In recent years, numerous methods have been carefully studied for NER task, including Hidden Markov Models (HMMs) (Bikel et al., 1997), Support Vector Machines (SVMs) (Isozaki and Kazawa, 2002) and Conditional Random Fields (CRFs) (Lafferty et al., 2001). Currently, with the development 182 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 182–192 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics than CWS task for certain word such as “ ¯• :: (Houston Airport)” in the example of Figure 1, which we call task-specific information. In order to incorporate word boundary information from CWS task into NER task, Peng and Dredze (2016) prop"
D18-1017,W06-0130,0,0.756932,"different domains. The WeiboNER dataset is social media domain, while the MSR dataset can be regard as news domain. The improvement of performance indicates that our proposed adversarial transfer learning framework may not only learn task-shared word boundary information from CWS task but also tackle the domain adaptation problem. 4.3.2 Evaluation on SighanNER Table 4 lists the comparisons on SighanNER dataset. We observe that our proposed model achieves new state-of-the-art performance. In the first block, we give the performance of previous methods for Chinese NER task on SighanNER dataset. Chen et al. (2006) propose a character-based CRF model for Chinese NER task. Zhou et al. (2006) introduce a pipeline model, which first segments the text with characterlevel CRF model and then applies word-level CRF to tag. Luo and Yang (2016) first train a word segmenter and then use word segmentation as addiWe also conduct an experiment on the updated WeiboNER dataset. Table 3 lists the performance of the latest models and our proposed model on the updated dataset. In the first block of Table 3, 188 Models BiLSTM+CRF BiLSTM+CRF+transfer BiLSTM+CRF+adversarial BiLSTM+CRF+self-attention BiLSTM+CRF+adversarial+s"
D18-1017,P17-1110,0,0.0288707,"and task discriminator. introduce self-attention mechanism to Chinese NER task. NER, which are jointly trained with CWS task. However, the specific features brought by CWS task can lower the performance of the Chinese NER task. Adversarial Training Adversarial networks have achieved great success in computer vision (Goodfellow et al., 2014; Denton et al., 2015). In NLP area, adversarial training has been introduced for domain adaptation (Ganin and Lempitsky, 2014; Zhang et al., 2017; Gui et al., 2017), cross-lingual transfer learning (Chen et al., 2016; Kim et al., 2017), multi-task learning (Chen et al., 2017; Liu et al., 2017) and crowdsourcing learning (Yang et al., 2018). Bousmalis et al. (2016) propose shared-private model in domain separation network. Different from these works, we exploit adversarial network to jointly train Chinese NER task and CWS task, aiming to extract task-shared word boundary information from CWS task. To our knowledge, it is the first work to apply adversarial transfer learning framework to Chinese NER task. Self-Attention Self-attention has been introduced to machine translation by Vaswani et al. (2017) for capturing global dependencies between input and output and a"
D18-1017,P15-1017,1,0.833514,"ER task and CWS task, which we call task-shared information. As shown in Figure 1, given a sentence “ •» ¯•: : (Hilton leaves Houston Airport)”, the two tasks have the same boundaries for some words such as “ • (Hilton)” and “» (leaves)”, while Chinese NER has more coarse-grained boundaries Introduction The task of named entity recognition (NER) is to recognize the named entities in given text. NER is a preliminary and important task in natural language processing (NLP) area and can be used in many downstream NLP tasks, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015) and question answering (Yao and Van Durme, 2014). In recent years, numerous methods have been carefully studied for NER task, including Hidden Markov Models (HMMs) (Bikel et al., 1997), Support Vector Machines (SVMs) (Isozaki and Kazawa, 2002) and Conditional Random Fields (CRFs) (Lafferty et al., 2001). Currently, with the development 182 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 182–192 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics than CWS task for certain word such as “ ¯• :: (Houston"
D18-1017,D17-1302,0,0.0478753,"tractor (Shared BiLSTM), self-attention and task discriminator. introduce self-attention mechanism to Chinese NER task. NER, which are jointly trained with CWS task. However, the specific features brought by CWS task can lower the performance of the Chinese NER task. Adversarial Training Adversarial networks have achieved great success in computer vision (Goodfellow et al., 2014; Denton et al., 2015). In NLP area, adversarial training has been introduced for domain adaptation (Ganin and Lempitsky, 2014; Zhang et al., 2017; Gui et al., 2017), cross-lingual transfer learning (Chen et al., 2016; Kim et al., 2017), multi-task learning (Chen et al., 2017; Liu et al., 2017) and crowdsourcing learning (Yang et al., 2018). Bousmalis et al. (2016) propose shared-private model in domain separation network. Different from these works, we exploit adversarial network to jointly train Chinese NER task and CWS task, aiming to extract task-shared word boundary information from CWS task. To our knowledge, it is the first work to apply adversarial transfer learning framework to Chinese NER task. Self-Attention Self-attention has been introduced to machine translation by Vaswani et al. (2017) for capturing global dep"
D18-1017,N16-1030,0,0.117738,"methods have been proposed for NER task. Early studies on NER often exploit SVMs (Isozaki and Kazawa, 2002), HMMs (Bikel et al., 1997) and CRFs (Lafferty et al., 2001), heavily relying on feature engineering. Zhou et al. (2013) formulate Chinese NER as a joint identification and categorization task. In recent years, neural network models have been introduced to NER task (Collobert et al., 2011; Huang et al., 2015; Peng and Dredze, 2016). Huang et al. (2015) exploit BiLSTM to extract features and feed them into CRF decoder. After that, the BiLSTM-CRF model is usually exploited as the baseline. Lample et al. (2016) use a character LSTM to represent spelling characteristics. In addition, Wang et al. (2017) propose a gated convolutional neural network (GCNN) model for Chinese NER. Peng and Dredze (2016) propose a joint model for Chinese To address the above problems, we propose an adversarial transfer learning framework to integrate the task-shared word boundary information into Chinese NER task in this paper. The adversarial transfer learning is incorporating adversarial training into transfer learning. To better capture long range dependencies and synthesize the information of the sentence, we extend se"
D18-1017,W06-0115,0,0.849277,"Missing"
D18-1017,P17-1001,0,0.073611,"Missing"
D18-1017,N16-1028,0,0.261227,"Missing"
D18-1017,D17-1256,0,0.0414657,"and CRF layer. The middle part is shared space consisting of feature extractor (Shared BiLSTM), self-attention and task discriminator. introduce self-attention mechanism to Chinese NER task. NER, which are jointly trained with CWS task. However, the specific features brought by CWS task can lower the performance of the Chinese NER task. Adversarial Training Adversarial networks have achieved great success in computer vision (Goodfellow et al., 2014; Denton et al., 2015). In NLP area, adversarial training has been introduced for domain adaptation (Ganin and Lempitsky, 2014; Zhang et al., 2017; Gui et al., 2017), cross-lingual transfer learning (Chen et al., 2016; Kim et al., 2017), multi-task learning (Chen et al., 2017; Liu et al., 2017) and crowdsourcing learning (Yang et al., 2018). Bousmalis et al. (2016) propose shared-private model in domain separation network. Different from these works, we exploit adversarial network to jointly train Chinese NER task and CWS task, aiming to extract task-shared word boundary information from CWS task. To our knowledge, it is the first work to apply adversarial transfer learning framework to Chinese NER task. Self-Attention Self-attention has been introduced t"
D18-1017,E17-2113,0,0.25823,"Missing"
D18-1017,D15-1064,0,0.0916977,"tasks. Besides the task loss LT ask , we introduce an adversarial loss LAdv to prevent specific features of CWS task from creeping into shared space. The adversarial loss trains the shared model to produce shared features such that the task discriminator cannot reliably recognize which task the sentence comes from. The adversarial loss can be computed as follows: LAdv = min(max θs θd Tk K X X Training 4 Experiments (i) logD(Es (xk ))) 4.1 k=1 i=1 Datasets To evaluate our proposed model on Chinese NER, we experiment on two different widely used datasets, including Weibo NER dataset (WeiboNER) (Peng and Dredze, 2015; He and Sun, (17) where θs denotes the trainable parameters of shared BiLSTM. Es denotes the shared feature extractor. Tk is the number of training examples of 186 Dataset WeiboNER SighanNER MSR Task Chinese NER Chinese NER CWS # Train sent 1350 41728 86924 # Dev sent 270 4636 — # Test sent 270 4365 3985 Table 1: Statistics of the datasets. Models CRF (Peng and Dredze, 2015) CRF+word (Peng and Dredze, 2015) CRF+character (Peng and Dredze, 2015) CRF+character+position (Peng and Dredze, 2015) Joint(cp) (main) (Peng and Dredze, 2015) Pipeline Seg.Repr.+NER (Peng and Dredze, 2016) Jointly Train C"
D18-1017,P16-2025,0,0.262044,"ake full use of task-shared boundaries information and prevent the taskspecific features of CWS. Besides, since arbitrary character can provide important cues when predicting entity type, we exploit selfattention to explicitly capture long range dependencies between two tokens. Experimental results on two different widely used datasets show that our proposed model significantly and consistently outperforms other state-ofthe-art methods. 1 Figure 1: An example of illustrating the similarities and specificities between Chinese NER and CWS. of deep learning, neural networks (Lample et al., 2016; Peng and Dredze, 2016; Luo and Yang, 2016) have been introduced to NER task. All these methods need to determine entities boundaries and classify them into pre-defined categories. Although great improvements have been achieved by these methods on Chinese NER task, some issues still have not been well addressed. One significant drawback is that there is only a very small amount of annotated data available. Weibo NER dataset (Peng and Dredze, 2015; He and Sun, 2017a) and Sighan2006 NER dataset (Levow, 2006) are two widely used datasets for Chinese NER task, containing 1.3k and 45k training examples, respectively. On"
D18-1017,C02-1054,0,0.887775,", while Chinese NER has more coarse-grained boundaries Introduction The task of named entity recognition (NER) is to recognize the named entities in given text. NER is a preliminary and important task in natural language processing (NLP) area and can be used in many downstream NLP tasks, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015) and question answering (Yao and Van Durme, 2014). In recent years, numerous methods have been carefully studied for NER task, including Hidden Markov Models (HMMs) (Bikel et al., 1997), Support Vector Machines (SVMs) (Isozaki and Kazawa, 2002) and Conditional Random Fields (CRFs) (Lafferty et al., 2001). Currently, with the development 182 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 182–192 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics than CWS task for certain word such as “ ¯• :: (Houston Airport)” in the example of Figure 1, which we call task-specific information. In order to incorporate word boundary information from CWS task into NER task, Peng and Dredze (2016) propose a joint model that performs Chinese NER with CWS task."
D18-1017,P14-1090,0,0.0207541,"Missing"
D18-1017,Q17-1036,0,0.0277527,"TM), self-attention and CRF layer. The middle part is shared space consisting of feature extractor (Shared BiLSTM), self-attention and task discriminator. introduce self-attention mechanism to Chinese NER task. NER, which are jointly trained with CWS task. However, the specific features brought by CWS task can lower the performance of the Chinese NER task. Adversarial Training Adversarial networks have achieved great success in computer vision (Goodfellow et al., 2014; Denton et al., 2015). In NLP area, adversarial training has been introduced for domain adaptation (Ganin and Lempitsky, 2014; Zhang et al., 2017; Gui et al., 2017), cross-lingual transfer learning (Chen et al., 2016; Kim et al., 2017), multi-task learning (Chen et al., 2017; Liu et al., 2017) and crowdsourcing learning (Yang et al., 2018). Bousmalis et al. (2016) propose shared-private model in domain separation network. Different from these works, we exploit adversarial network to jointly train Chinese NER task and CWS task, aiming to extract task-shared word boundary information from CWS task. To our knowledge, it is the first work to apply adversarial transfer learning framework to Chinese NER task. Self-Attention Self-attention ha"
D18-1017,W06-0140,0,0.328467,"Missing"
D18-1158,P11-1113,0,0.865199,"specifically. S2: The project leader was fired for the bankruptcy of the subsidiary company. Event detection (ED) is a crucial subtask of event extraction, which aims to identify event triggers and classify them into specific types from texts. According to the task defined in Automatic Context Extraction1 (ACE), given the following sentence S1, a robust ED system should be able to recognize two events: a Die event triggered by died and an Attack event triggered by fired. S1: In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel. To this end, most methods (Ahn, 2006; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2016; Liu et al., 2017) model ED as a multiclassification task and predict every word in the http://projects.ldc.upenn.edu/ace/ Transport Figure 1: Top 5 event types that co-occur with Attack event in the same sentence in ACE 2005. Introduction 1 Die Event interdependency: In S1, fired triggers an Attack event, while it triggers an End-Position event in S2. Because of the ambiguity, a traditional approach may mislabel fired in S1 as a trigger of End-Position event. However, if we know died triggers a Die event in S1, which is easier to disambiguate, we"
D18-1158,W06-0901,0,0.9252,"wo problems specifically. S2: The project leader was fired for the bankruptcy of the subsidiary company. Event detection (ED) is a crucial subtask of event extraction, which aims to identify event triggers and classify them into specific types from texts. According to the task defined in Automatic Context Extraction1 (ACE), given the following sentence S1, a robust ED system should be able to recognize two events: a Die event triggered by died and an Attack event triggered by fired. S1: In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel. To this end, most methods (Ahn, 2006; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2016; Liu et al., 2017) model ED as a multiclassification task and predict every word in the http://projects.ldc.upenn.edu/ace/ Transport Figure 1: Top 5 event types that co-occur with Attack event in the same sentence in ACE 2005. Introduction 1 Die Event interdependency: In S1, fired triggers an Attack event, while it triggers an End-Position event in S2. Because of the ambiguity, a traditional approach may mislabel fired in S1 as a trigger of End-Position event. However, if we know died triggers a Die event in S1, which is easier"
D18-1158,P17-1038,1,0.923322,"hods for comparison, which can be classified as two types: separate and collective methods: Separate methods: 1) Li’s MaxEnt: the method that detects events in one sentence separately by using human-designed features (Li et al., 2013). 2) Liao’s CrossEvent : the method that uses cross event information (Liao and Grishman, 2010). 3) Hong’s CrossEntity: the method that uses cross entity information (Hong et al., 2011). 4) Chen’s DMCNN: the dynamic multipooling convolutional neural networks method (Chen et al., 2015). 5) Chen’s DMCNN+: the DMCNN method argumented with automatically labeled data (Chen et al., 2017). 6) Liu’s FrameNet : the method that leverages FrameNet as extended training data to improve ED (Liu et al., 2016a). 7) Liu’s ANN-Aug: the method that use the annotated argument information via a supervised attention to improve ED (Liu et al., 2017). Collective methods: 1) Li’s Structure: the method that collectively detects events by using human-designed features (Li et al., 2013). 2) Yang’s JointEE: the method that detects events and entities in one sentence jointly based on human-designed features (Yang and Mitchell, 2016). 3) Nguyen’s JRNN: the method that exploits a RNN model to collecti"
D18-1158,P15-1017,1,0.818833,"The project leader was fired for the bankruptcy of the subsidiary company. Event detection (ED) is a crucial subtask of event extraction, which aims to identify event triggers and classify them into specific types from texts. According to the task defined in Automatic Context Extraction1 (ACE), given the following sentence S1, a robust ED system should be able to recognize two events: a Die event triggered by died and an Attack event triggered by fired. S1: In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel. To this end, most methods (Ahn, 2006; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2016; Liu et al., 2017) model ED as a multiclassification task and predict every word in the http://projects.ldc.upenn.edu/ace/ Transport Figure 1: Top 5 event types that co-occur with Attack event in the same sentence in ACE 2005. Introduction 1 Die Event interdependency: In S1, fired triggers an Attack event, while it triggers an End-Position event in S2. Because of the ambiguity, a traditional approach may mislabel fired in S1 as a trigger of End-Position event. However, if we know died triggers a Die event in S1, which is easier to disambiguate, we tend to predict th"
D18-1158,I17-1036,0,0.227844,"and collective methods. Separate methods: These methods regard multiple events in one sentence as independent ones and recognize them separately. These methods include feature-based methods which exploit a diverse set of strategies to convert classification clues into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al., 2015; Nguyen and Grishman, 2015; Feng et al., 2016; Nguyen and Grishman, 2016; Chen et al., 2017; Duan et al., 2017; Liu et al., 2017). Though effective these methods, they neglect event interdependency by separately predicting each event. Collective methods: These methods try to model the event interdependency and detect multiple events in one sentence collectively. However, nearly all of these methods are feature-based methods (McClosky et al., 2011; Li et al., 2013; Yang and Mitchell, 2016; Liu et al., 2016b), which rely on elaborately designed features and suffer error propagation from existing NLP tools. Nguyen et al. (2016) exploits a neural-based method to detect multiple events collectively. Howeve"
D18-1158,P08-1030,0,0.876093,"eft triggers a Transport event, while a clue like “They held a party for his retirement.” would indicate the aforementioned event is an End-Position event. We call such clues as document-level information. Moreover, the confidence of sentence-level and document-level information should be taken into consideration when using them together to construct a broader range of contextual information. For example in S3, document-level information will give us more evidence, while in S1 sentence-level information is enough to disambiguate the types of events. There have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED. However, they suffer from two problems: (1) The features they used often need to be manually designed and may involve error propagation from existing NLP tools; (2) Sentence-level and document-level information are integrated by a large number of fixed rules, which is complicated to construct and it will be far from complete. Thus, how to use a neural-based model to automatically extract sentence-level and document-level information and dynamically inte"
D18-1158,N16-1030,0,0.0106837,"7 S-Attention S-Attention S-Attention S-Attention S-Attention S-Attention S-Attention ℎ1 ℎ2 ℎ3 ℎ4 ℎ5 ℎ6 ℎ7 BiLSTM BiLSTM BiLSTM BiLSTM BiLSTM BiLSTM BiLSTM ?1 ?2 ?3 ?4 ?5 ?6 died when an Document ?ℎ? D-Attention … (Sentence i) BiLSTM Layer Embedding Layer Input … cameraman American ?7 tank fired Figure 2: The architecture of our proposed hierarchical and bias tagging networks with gated multi-level attention. 3.2 BiLSTM Layer semantic information sht is calculated as follows: In sequence labelling problems, the BiLSTM has been proven effective to capture the semantic information of each word (Lample et al., 2016). In this paper, we use the LSTM unit as described in (Zaremba and Sutskever, 2014). For each word wt , the forward LSTM encodes wt by considering the contextual information from word w1 to ! wt , which is marked as h t . Similarly, the backward LSTM encodes wt based on the contextual information from wNw to wt , which is marked as ! h t . Finally, we concatenate h t and h t to represent the information of the word wt , denoted as ! ! ht = [ h t , h t ], and we concatenate h Nw and h 1 to represent the encoding information of the whole ! sentence si , denoted as hsi = [ h Nw , h 1 ]. 3.3 Gated"
D18-1158,P13-1008,0,0.794389,"es the occurrence of an event. Event arguments: the mentions that are involved in an event (viz., participants). Event mention: a phrase or sentence within which an event is described, including a trigger and arguments. Given an English text document, an ED system should identify event triggers and categorize their event types for each sentence. For instance, in the sentence “He died in the hospital”, an ED system is expected to detect a Die event along with the trigger word “died”. The ACE 2005 evaluation defines 8 event types and 33 subtypes, such as Attack or Die. Following previous works (Li et al., 2013; Chen et al., 2015; Liu et al., 2017; Nguyen and Grishman, 2016), we categorize triggers into these 33 subtypes. 3 Methodology In this paper, we formulate event detection as a sequence labelling task. As shown in Figure 2, 3 Our source code, including all hyper-parameter settings and pre-trained word embeddings, is openly available at https://github.com/yubochen/NBTNGMA4ED we label all words in one sentence collectively via a Hierarchical and Bias Tagging Networks with Gated Multi-level Attention Mechanisms (HBTNGMA). We assign a tag for each word to indicate whether it triggers a specific ty"
D18-1158,P10-1081,0,0.911701,"t event, while a clue like “They held a party for his retirement.” would indicate the aforementioned event is an End-Position event. We call such clues as document-level information. Moreover, the confidence of sentence-level and document-level information should be taken into consideration when using them together to construct a broader range of contextual information. For example in S3, document-level information will give us more evidence, while in S1 sentence-level information is enough to disambiguate the types of events. There have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED. However, they suffer from two problems: (1) The features they used often need to be manually designed and may involve error propagation from existing NLP tools; (2) Sentence-level and document-level information are integrated by a large number of fixed rules, which is complicated to construct and it will be far from complete. Thus, how to use a neural-based model to automatically extract sentence-level and document-level information and dynamically integrate them is another cha"
D18-1158,P16-1201,1,0.943202,"s MaxEnt: the method that detects events in one sentence separately by using human-designed features (Li et al., 2013). 2) Liao’s CrossEvent : the method that uses cross event information (Liao and Grishman, 2010). 3) Hong’s CrossEntity: the method that uses cross entity information (Hong et al., 2011). 4) Chen’s DMCNN: the dynamic multipooling convolutional neural networks method (Chen et al., 2015). 5) Chen’s DMCNN+: the DMCNN method argumented with automatically labeled data (Chen et al., 2017). 6) Liu’s FrameNet : the method that leverages FrameNet as extended training data to improve ED (Liu et al., 2016a). 7) Liu’s ANN-Aug: the method that use the annotated argument information via a supervised attention to improve ED (Liu et al., 2017). Collective methods: 1) Li’s Structure: the method that collectively detects events by using human-designed features (Li et al., 2013). 2) Yang’s JointEE: the method that detects events and entities in one sentence jointly based on human-designed features (Yang and Mitchell, 2016). 3) Nguyen’s JRNN: the method that exploits a RNN model to collectively detects events by only using sentence-level information (Nguyen et al., 2016). 4) Liu’s PSL : the method that"
D18-1158,P17-1164,1,0.892173,"Missing"
D18-1158,P11-1163,0,0.0427987,"n, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al., 2015; Nguyen and Grishman, 2015; Feng et al., 2016; Nguyen and Grishman, 2016; Chen et al., 2017; Duan et al., 2017; Liu et al., 2017). Though effective these methods, they neglect event interdependency by separately predicting each event. Collective methods: These methods try to model the event interdependency and detect multiple events in one sentence collectively. However, nearly all of these methods are feature-based methods (McClosky et al., 2011; Li et al., 2013; Yang and Mitchell, 2016; Liu et al., 2016b), which rely on elaborately designed features and suffer error propagation from existing NLP tools. Nguyen et al. (2016) exploits a neural-based method to detect multiple events collectively. However, they only use the sentence-level information and ne1274 glect document-level clues, and can only capture the interdependencies between the current event candidate and its former predicted events. Moreover, there method can not handle the multiple words trigger problem. Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji, Bing Qin, and Ting"
D18-1158,P15-2060,0,0.367125,"c in NLP. Generally, existing approaches could roughly be divided into two groups: separate and collective methods. Separate methods: These methods regard multiple events in one sentence as independent ones and recognize them separately. These methods include feature-based methods which exploit a diverse set of strategies to convert classification clues into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al., 2015; Nguyen and Grishman, 2015; Feng et al., 2016; Nguyen and Grishman, 2016; Chen et al., 2017; Duan et al., 2017; Liu et al., 2017). Though effective these methods, they neglect event interdependency by separately predicting each event. Collective methods: These methods try to model the event interdependency and detect multiple events in one sentence collectively. However, nearly all of these methods are feature-based methods (McClosky et al., 2011; Li et al., 2013; Yang and Mitchell, 2016; Liu et al., 2016b), which rely on elaborately designed features and suffer error propagation from existing NLP tools. Nguyen et al."
D18-1158,N16-1034,0,0.791988,"re 1. We call such clues as event 1267 Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1267–1276 c Brussels, Belgium, October 31 - November 4, 2018. 2018 Association for Computational Linguistics interdependency. Some works (Li et al., 2013; Yang and Mitchell, 2016; Liu et al., 2016b) rely on a set of elaborately designed features and complicated natural language processing (NLP) tools to capture event interdependency. However, these methods lack generalization, take a large amount of human effort and are prone to error propagation problem. Though Nguyen et al. (2016) use a Recurrent Neural Networks (RNN) based classification model to capture the event interdependency between current event candidate and the former (left) predicted events, they miss the event interdependency between current event candidate and the later (right) predicted events, and the later events can not change the type of current event. The reason is that they classify the words of the sentence from left to right one by one and only use the former events to predict the later event types. We claim that both of the former and later predicted events are important to predict the event type"
D18-1158,D16-1085,0,0.792479,"was fired for the bankruptcy of the subsidiary company. Event detection (ED) is a crucial subtask of event extraction, which aims to identify event triggers and classify them into specific types from texts. According to the task defined in Automatic Context Extraction1 (ACE), given the following sentence S1, a robust ED system should be able to recognize two events: a Die event triggered by died and an Attack event triggered by fired. S1: In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel. To this end, most methods (Ahn, 2006; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2016; Liu et al., 2017) model ED as a multiclassification task and predict every word in the http://projects.ldc.upenn.edu/ace/ Transport Figure 1: Top 5 event types that co-occur with Attack event in the same sentence in ACE 2005. Introduction 1 Die Event interdependency: In S1, fired triggers an Attack event, while it triggers an End-Position event in S2. Because of the ambiguity, a traditional approach may mislabel fired in S1 as a trigger of End-Position event. However, if we know died triggers a Die event in S1, which is easier to disambiguate, we tend to predict that fired triggers an Attack"
D18-1158,N16-1033,0,0.300227,"en’s DMCNN+: the DMCNN method argumented with automatically labeled data (Chen et al., 2017). 6) Liu’s FrameNet : the method that leverages FrameNet as extended training data to improve ED (Liu et al., 2016a). 7) Liu’s ANN-Aug: the method that use the annotated argument information via a supervised attention to improve ED (Liu et al., 2017). Collective methods: 1) Li’s Structure: the method that collectively detects events by using human-designed features (Li et al., 2013). 2) Yang’s JointEE: the method that detects events and entities in one sentence jointly based on human-designed features (Yang and Mitchell, 2016). 3) Nguyen’s JRNN: the method that exploits a RNN model to collectively detects events by only using sentence-level information (Nguyen et al., 2016). 4) Liu’s PSL : the method that uses a probabilistic soft logic to detect events by using human-designed features (Liu et al., 2016b). Experimental results are shown in Table 1. From the table, we have the following observations: (1) Among all the methods, our HBTNGMA achieves the best performance. It can improve the best collective method’s F1 by 1272 4 5 https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2008T19 Methods Li’s"
D19-1068,W06-0901,0,0.822084,"nt languages, we devise a context-dependent translation method; to treat the word order difference problem, we propose a shared syntactic order event detector for multilingual cotraining. The efficiency of our method is studied through extensive experiments on two standard datasets. Empirical results indicate that our method is effective in 1) performing cross-lingual transfer concerning different directions and 2) tackling the extremely annotation-poor scenario. 1 Introduction Event detection (ED) is a crucial natural language processing problem that aims to identify event triggers in texts (Ahn, 2006; Nguyen and Grishman, 2015). For example, in the sentence: “A man died when a tank fired on the hotel”, ED requires a system to identify two event triggers, died and fired, along with their types Die and Attack. Generally, training an ED system requires to obtain a considerably large amount of labeled data. However, owing to the complexity and high costs of annotation, existing event resources are scarce and unbalanced across languages (Hsi et al., 2016), which prevents us from building an ED system in languages with insufficient training data. Cross-lingual ED (Ji, 2009; Chen and ∗ Equal con"
D19-1068,P15-1017,1,0.904732,"dent patterns in crosslingual transfer to circumvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2018a) used machine translation to obtain additional labeled data for training; (Hsi et al., 2016) combined the embedding-proje"
D19-1068,W09-2209,0,0.0339393,"ure-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2018a) used machine translation to obtain additional labeled data for training; (Hsi et al., 2016) combined the embedding-projection method with multilingual feature extraction for bilingual ED. Nevertheless, the heavily dependency on parallel resources often limits the applicability of these methods. Our study also relates to cross-lingual studies in other applications (Guo et al., 2015; Ni et al., 2017; Mayhew et al., 2017; Xie et al., 2018; Lample"
D19-1068,P07-2045,0,0.0062674,"Missing"
D19-1068,P16-2011,0,0.0380258,"GCNs with a self-attention network (by comparing CL Trans GCN with CL Trans GCN Self). tent. 2) Retrieving more translation candidates could consistently improve Recall. But when too many candidates (e.g., 5) are added, the Precision drops, which harms the overall F1 measure. Exploring the Syntactic Order Event Detector. We compare our syntactic order event detector (CL Trans GCN) with several event detectors, including 1) CL Trans MLP, which employs a feed-forward network as event detector; 2) CL Trans CNN, which uses CNNs as the event detector; 3) CL Trans Hbrid, which use a hybrid network (Feng et al., 2016) for event detection. We also compared our model with several variants including 4) CL Trans Self., which replaces the GCNs with a self-attention network, and 5) CL Trans GCN Self, which combines GCNs with a self-attention network. We train these models on the same translated English data. Table 3 shows the results. From the results, 1) CL Trans MLP, CL Trans CNN, and CL Trans Hbrid behave poorly, as expected. The reason might be that these models usually employ order-sensitive structures (e.g., CNNs) for ED, which would suffer the word order inconsistency problem when trained on the translate"
D19-1068,P15-1119,0,0.0335088,"we propose a new simple but effective method for cross-lingual ED, which can overcome the data scarcity problem in annotationpoor languages by jointly training with resources in other languages. Compared with previous methods, our approach demonstrates a minimal dependency on parallel resources, which may fit with language pairs that do not have large bitexts. To achieve cross-lingual transfer, two challenges exist: 1) how to build lexical mappings between different languages, and 2) how to handle the word order difference problem (Xie et al., 2018). For the first challenge, previous studies (Guo et al., 2015; Ni et al., 2017; Mayhew et al., 2017; Xie et al., 2018; Lample et al., 2018) have investigated embedding projection-based method in cross-lingual applications and achieved promising results. For example, (Xie et al., 2018) proposed a novel “cheap translation” based method which has greatly advanced the performance in zero-shot named entity recognition (NER). However, these methods may not directly fit with crosslingual ED, as the lexical mapping in ED is usually context-dependent but not deterministic as in other tasks. Consider the following English-to-Chinese lexical mapping examples. To p"
D19-1068,P14-1038,0,0.0385122,"es, it might not fit with languages which lack syntactic parsers. In the future, we plan to investigate more language-independent patterns in crosslingual transfer to circumvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2"
D19-1068,P11-1113,0,0.230944,"y of syntax trees of training examples, it might not fit with languages which lack syntactic parsers. In the future, we plan to investigate more language-independent patterns in crosslingual transfer to circumvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese E"
D19-1068,P13-1008,0,0.236192,"f training examples, it might not fit with languages which lack syntactic parsers. In the future, we plan to investigate more language-independent patterns in crosslingual transfer to circumvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2"
D19-1068,P10-1081,0,0.222557,"icated on the availability of syntax trees of training examples, it might not fit with languages which lack syntactic parsers. In the future, we plan to investigate more language-independent patterns in crosslingual transfer to circumvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for"
D19-1068,C16-1114,0,0.0894339,"n-poor scenario. 1 Introduction Event detection (ED) is a crucial natural language processing problem that aims to identify event triggers in texts (Ahn, 2006; Nguyen and Grishman, 2015). For example, in the sentence: “A man died when a tank fired on the hotel”, ED requires a system to identify two event triggers, died and fired, along with their types Die and Attack. Generally, training an ED system requires to obtain a considerably large amount of labeled data. However, owing to the complexity and high costs of annotation, existing event resources are scarce and unbalanced across languages (Hsi et al., 2016), which prevents us from building an ED system in languages with insufficient training data. Cross-lingual ED (Ji, 2009; Chen and ∗ Equal contribution. 738 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 738–748, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics E1: A man died when a tank fired on the hotel event), and “the house caught fire” (which evokes an NA event) should be translated as different Chinese words “开 火(open fire)” and “着"
D19-1068,P18-1145,0,0.0219583,"Missing"
D19-1068,W09-1704,0,0.170583,"t triggers in texts (Ahn, 2006; Nguyen and Grishman, 2015). For example, in the sentence: “A man died when a tank fired on the hotel”, ED requires a system to identify two event triggers, died and fired, along with their types Die and Attack. Generally, training an ED system requires to obtain a considerably large amount of labeled data. However, owing to the complexity and high costs of annotation, existing event resources are scarce and unbalanced across languages (Hsi et al., 2016), which prevents us from building an ED system in languages with insufficient training data. Cross-lingual ED (Ji, 2009; Chen and ∗ Equal contribution. 738 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 738–748, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics E1: A man died when a tank fired on the hotel event), and “the house caught fire” (which evokes an NA event) should be translated as different Chinese words “开 火(open fire)” and “着 火(be on fire)” respectively. But in previous lexical mapping methods, the “fired” is always having the same transferre"
D19-1068,L16-1147,0,0.0587121,"Missing"
D19-1068,P08-1030,0,0.397709,"as our approach is predicated on the availability of syntax trees of training examples, it might not fit with languages which lack syntactic parsers. In the future, we plan to investigate more language-independent patterns in crosslingual transfer to circumvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to o"
D19-1068,D18-1127,0,0.114004,"y. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2018a) used machine translation to obtain additional labeled data for training; (Hsi et al., 2016) combined the embedding-projection method with multilingual feature extraction for bilingual ED"
D19-1068,P17-4012,0,0.0303764,"Missing"
D19-1068,P14-5010,0,0.0057334,"Missing"
D19-1068,D17-1269,0,0.0497465,"Missing"
D19-1068,D18-1034,0,0.191686,"tly limits the applicability of these methods. In this paper, we propose a new simple but effective method for cross-lingual ED, which can overcome the data scarcity problem in annotationpoor languages by jointly training with resources in other languages. Compared with previous methods, our approach demonstrates a minimal dependency on parallel resources, which may fit with language pairs that do not have large bitexts. To achieve cross-lingual transfer, two challenges exist: 1) how to build lexical mappings between different languages, and 2) how to handle the word order difference problem (Xie et al., 2018). For the first challenge, previous studies (Guo et al., 2015; Ni et al., 2017; Mayhew et al., 2017; Xie et al., 2018; Lample et al., 2018) have investigated embedding projection-based method in cross-lingual applications and achieved promising results. For example, (Xie et al., 2018) proposed a novel “cheap translation” based method which has greatly advanced the performance in zero-shot named entity recognition (NER). However, these methods may not directly fit with crosslingual ED, as the lexical mapping in ED is usually context-dependent but not deterministic as in other tasks. Consider th"
D19-1068,N15-1104,0,0.0617684,"Missing"
D19-1068,C00-2137,0,0.0627521,"Missing"
D19-1068,P14-2136,0,0.0173877,"et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2018a) used machine translation to obtain additional labeled data for training; (Hsi et al., 2016) combined the embedding-projection method with multilingual feature extraction for bilingual ED. Nevertheless, the heavily dependency on parallel resources often limits the applicability of these methods. Our study also relates to cross-lingual studies in other applications (Guo et al., 2015; Ni et al., 2017; Mayhew et al., 2017; Xie et al., 2018; Lample et al., 2018). These approaches adopted embedding projection based method to achieve cross-lingual transfer and achieved prosing re"
D19-1068,N16-1034,0,0.209121,"umvent this dependency. Related Work Event detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2018a) used machine translation to obtain additional labeled data for training; (Hsi et al., 2016) combined the embedding-projection method with multilingual feature extractio"
D19-1068,P15-2060,0,0.494094,"s, we devise a context-dependent translation method; to treat the word order difference problem, we propose a shared syntactic order event detector for multilingual cotraining. The efficiency of our method is studied through extensive experiments on two standard datasets. Empirical results indicate that our method is effective in 1) performing cross-lingual transfer concerning different directions and 2) tackling the extremely annotation-poor scenario. 1 Introduction Event detection (ED) is a crucial natural language processing problem that aims to identify event triggers in texts (Ahn, 2006; Nguyen and Grishman, 2015). For example, in the sentence: “A man died when a tank fired on the hotel”, ED requires a system to identify two event triggers, died and fired, along with their types Die and Attack. Generally, training an ED system requires to obtain a considerably large amount of labeled data. However, owing to the complexity and high costs of annotation, existing event resources are scarce and unbalanced across languages (Hsi et al., 2016), which prevents us from building an ED system in languages with insufficient training data. Cross-lingual ED (Ji, 2009; Chen and ∗ Equal contribution. 738 Proceedings o"
D19-1068,P17-1135,0,0.0415959,"Missing"
D19-1068,D18-1122,0,0.0240603,"nt detection (ED) is a hot topic in natural language processing, which has attracted extensive attention in the past few years. Traditionally, the study of ED has focused on monolingual training. The proposed models can be divided into feature-based methods which employ fine-grained features (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Li and Ji, 2014), and deep learning-based methods which employ neural networks to automatically learn features for the task (Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016; Liu et al., 2018b; Orr et al., 2018; Liu et al., 2019). Usually, their performance is limited by the amount of labeled data in a specific language. Cross-lingual ED attempts transfer knowledge between different languages to boost performance. To name a few, (Chen and Ji, 2009) used an English detector to label events on parallel documents to obtain additional data for boosting Chinese ED; (Zhu et al., 2014; Liu et al., 2018a) used machine translation to obtain additional labeled data for training; (Hsi et al., 2016) combined the embedding-projection method with multilingual feature extraction for bilingual ED. Nevertheless, the"
D19-1396,N19-1078,0,0.0251829,"f-the-art results in various popular Chinese NER datasets, and our model achieves a 6-15x speedup over the existing SOTA model. 2 3 Related Work NER. There is rich literature on NER. This includes statistic methods, such as SVM (Isozaki and Kazawa, 2002), HMMs (Bikel et al., 1997) and CRF (Lafferty et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for Chinese NER, such as (Peng and Dredze, 2015; He and Sun, 2017a; Zhu and Wang, 2019). Peng and Dredze (2016), Cao et al. (2018) and Wu et al. (2019) propose joint models to train NER together with CWS. Our work is inspired by lattice LSTM (Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks. There are a number of recent graph co"
D19-1396,C18-1139,0,0.029162,"al NLP tools. • We achieve the state-of-the-art results in various popular Chinese NER datasets, and our model achieves a 6-15x speedup over the existing SOTA model. 2 3 Related Work NER. There is rich literature on NER. This includes statistic methods, such as SVM (Isozaki and Kazawa, 2002), HMMs (Bikel et al., 1997) and CRF (Lafferty et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for Chinese NER, such as (Peng and Dredze, 2015; He and Sun, 2017a; Zhu and Wang, 2019). Peng and Dredze (2016), Cao et al. (2018) and Wu et al. (2019) propose joint models to train NER together with CWS. Our work is inspired by lattice LSTM (Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks"
D19-1396,D17-1209,0,0.0238957,"nspired by lattice LSTM (Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of t"
D19-1396,A97-1029,0,0.0963717,"edge directly and efficiently for Chinese NER. • To solve the challenges of integrating selfmatched lexical words and the nearest contextual lexical words, we propose three wordcharacter interactive graphs. These interactive graphs can capture different lexical knowledge and are built without external NLP tools. • We achieve the state-of-the-art results in various popular Chinese NER datasets, and our model achieves a 6-15x speedup over the existing SOTA model. 2 3 Related Work NER. There is rich literature on NER. This includes statistic methods, such as SVM (Isozaki and Kazawa, 2002), HMMs (Bikel et al., 1997) and CRF (Lafferty et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for Chinese NER, such as (Peng"
D19-1396,H05-1091,0,0.0950913,"Beijing airport.) Matched Lexical Words: 希尔(Hill), 希尔顿(Hilton), 离开(leave), 北京(Beijing), 北京机场(Beijing Airport) Figure 1: An example sentence integrating the nearest contextual lexical words (red line) and self-matched lexical words (green line) Introduction Named entity recognition (NER) aims to locate and classify certain occurrences of words or expressions in unstructured text into predefined semantic categories such as the person names, locations, organizations, etc. NER is an essential pre-processing step for many natural language processing (NLP) applications, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015), question answering (Moll´a et al., 2006) etc. In English NER, LSTM-CRF models (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) leveraging word-level representations and character-level representations achieve the stateof-the-art results. In this paper, we focus on Chinese NER. Compared with English, Chinese has no obvious word boundaries. Since without word boundaries information, it is intuitive to use character information 1 The code is available at https://github.com/ DianboWork/Graph4CNER only for Chinese NER (He and"
D19-1396,D18-1017,1,0.929315,"me as the boundaries of the named entity “ ¬::” (Beijing airport). Therefore, making full use of word information would help to improve the Chinese NER performance. There are three main ways to incorporate word information in NER. The first one is the pipeline method. The way of pipeline method is to apply Chinese Word Segmentation (CWS) first, and then to use a word-based NER model. However, the pipeline method suffers from error propagation, since the error of CWS may affect the performance of NER. The second one is to learn CWS and NER tasks jointly (Xu et al., 2013; Peng and Dredze, 2016; Cao et al., 2018; Wu et al., 2019). However, the joint models must rely on CWS annotation datasets, which are costly and are annotated under many diverse segmentation criteria (Chen 3830 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3830–3840, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics et al., 2017). The third one is to leverage an automatically constructed lexicon, which is pre-trained on large automatically segmented texts. Lexical knowledge in"
D19-1396,N19-1032,0,0.0310958,"r of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of three automatically constructed graphs, which can avoid error propagation problem naturally. To our best knowledge, we are the"
D19-1396,W17-7607,0,0.0685853,"Missing"
D19-1396,N13-1006,0,0.429616,"Missing"
D19-1396,W06-0130,0,0.18067,"Missing"
D19-1396,P17-1110,0,0.0610368,"Missing"
D19-1396,P15-1017,1,0.867339,"ill), 希尔顿(Hilton), 离开(leave), 北京(Beijing), 北京机场(Beijing Airport) Figure 1: An example sentence integrating the nearest contextual lexical words (red line) and self-matched lexical words (green line) Introduction Named entity recognition (NER) aims to locate and classify certain occurrences of words or expressions in unstructured text into predefined semantic categories such as the person names, locations, organizations, etc. NER is an essential pre-processing step for many natural language processing (NLP) applications, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015), question answering (Moll´a et al., 2006) etc. In English NER, LSTM-CRF models (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) leveraging word-level representations and character-level representations achieve the stateof-the-art results. In this paper, we focus on Chinese NER. Compared with English, Chinese has no obvious word boundaries. Since without word boundaries information, it is intuitive to use character information 1 The code is available at https://github.com/ DianboWork/Graph4CNER only for Chinese NER (He and Wang, 2008; Liu et al., 2010; Li et a"
D19-1396,Q16-1026,0,0.528087,"ords (red line) and self-matched lexical words (green line) Introduction Named entity recognition (NER) aims to locate and classify certain occurrences of words or expressions in unstructured text into predefined semantic categories such as the person names, locations, organizations, etc. NER is an essential pre-processing step for many natural language processing (NLP) applications, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015), question answering (Moll´a et al., 2006) etc. In English NER, LSTM-CRF models (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) leveraging word-level representations and character-level representations achieve the stateof-the-art results. In this paper, we focus on Chinese NER. Compared with English, Chinese has no obvious word boundaries. Since without word boundaries information, it is intuitive to use character information 1 The code is available at https://github.com/ DianboWork/Graph4CNER only for Chinese NER (He and Wang, 2008; Liu et al., 2010; Li et al., 2014), although such methods could result in the disregard of word information. However, word information is very useful in Chinese NER, be"
D19-1396,E17-2113,0,0.170397,"et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for Chinese NER, such as (Peng and Dredze, 2015; He and Sun, 2017a; Zhu and Wang, 2019). Peng and Dredze (2016), Cao et al. (2018) and Wu et al. (2019) propose joint models to train NER together with CWS. Our work is inspired by lattice LSTM (Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attent"
D19-1396,I08-4022,0,0.272635,"2005), event extraction (Chen et al., 2015), question answering (Moll´a et al., 2006) etc. In English NER, LSTM-CRF models (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) leveraging word-level representations and character-level representations achieve the stateof-the-art results. In this paper, we focus on Chinese NER. Compared with English, Chinese has no obvious word boundaries. Since without word boundaries information, it is intuitive to use character information 1 The code is available at https://github.com/ DianboWork/Graph4CNER only for Chinese NER (He and Wang, 2008; Liu et al., 2010; Li et al., 2014), although such methods could result in the disregard of word information. However, word information is very useful in Chinese NER, because word boundaries are usually the same as named entity boundaries. For example, as shown in Figure 1, the boundaries of the word “ ¬::” (Beijing airport) are the same as the boundaries of the named entity “ ¬::” (Beijing airport). Therefore, making full use of word information would help to improve the Chinese NER performance. There are three main ways to incorporate word information in NER. The first one is the pipeline m"
D19-1396,C02-1054,0,0.102519,"etwork to integrate lexical knowledge directly and efficiently for Chinese NER. • To solve the challenges of integrating selfmatched lexical words and the nearest contextual lexical words, we propose three wordcharacter interactive graphs. These interactive graphs can capture different lexical knowledge and are built without external NLP tools. • We achieve the state-of-the-art results in various popular Chinese NER datasets, and our model achieves a 6-15x speedup over the existing SOTA model. 2 3 Related Work NER. There is rich literature on NER. This includes statistic methods, such as SVM (Isozaki and Kazawa, 2002), HMMs (Bikel et al., 1997) and CRF (Lafferty et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for"
D19-1396,N19-1079,0,0.0360056,"chieve the state-of-the-art results in various popular Chinese NER datasets, and our model achieves a 6-15x speedup over the existing SOTA model. 2 3 Related Work NER. There is rich literature on NER. This includes statistic methods, such as SVM (Isozaki and Kazawa, 2002), HMMs (Bikel et al., 1997) and CRF (Lafferty et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for Chinese NER, such as (Peng and Dredze, 2015; He and Sun, 2017a; Zhu and Wang, 2019). Peng and Dredze (2016), Cao et al. (2018) and Wu et al. (2019) propose joint models to train NER together with CWS. Our work is inspired by lattice LSTM (Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks. There are a numb"
D19-1396,W06-0115,0,0.782574,"Missing"
D19-1396,li-etal-2014-comparison,0,0.426311,"Missing"
D19-1396,P18-2023,0,0.0763397,"Missing"
D19-1396,L16-1138,0,0.253291,"Missing"
D19-1396,P16-1101,0,0.501674,"ontextual lexical words (red line) and self-matched lexical words (green line) Introduction Named entity recognition (NER) aims to locate and classify certain occurrences of words or expressions in unstructured text into predefined semantic categories such as the person names, locations, organizations, etc. NER is an essential pre-processing step for many natural language processing (NLP) applications, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015), question answering (Moll´a et al., 2006) etc. In English NER, LSTM-CRF models (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) leveraging word-level representations and character-level representations achieve the stateof-the-art results. In this paper, we focus on Chinese NER. Compared with English, Chinese has no obvious word boundaries. Since without word boundaries information, it is intuitive to use character information 1 The code is available at https://github.com/ DianboWork/Graph4CNER only for Chinese NER (He and Wang, 2008; Liu et al., 2010; Li et al., 2014), although such methods could result in the disregard of word information. However, word information is very u"
D19-1396,D17-1159,0,0.0247942,"(Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of three automatically constructed"
D19-1396,N16-1030,0,0.443467,"grating the nearest contextual lexical words (red line) and self-matched lexical words (green line) Introduction Named entity recognition (NER) aims to locate and classify certain occurrences of words or expressions in unstructured text into predefined semantic categories such as the person names, locations, organizations, etc. NER is an essential pre-processing step for many natural language processing (NLP) applications, such as relation extraction (Bunescu and Mooney, 2005), event extraction (Chen et al., 2015), question answering (Moll´a et al., 2006) etc. In English NER, LSTM-CRF models (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) leveraging word-level representations and character-level representations achieve the stateof-the-art results. In this paper, we focus on Chinese NER. Compared with English, Chinese has no obvious word boundaries. Since without word boundaries information, it is intuitive to use character information 1 The code is available at https://github.com/ DianboWork/Graph4CNER only for Chinese NER (He and Wang, 2008; Liu et al., 2010; Li et al., 2014), although such methods could result in the disregard of word information. However, word in"
D19-1396,N19-1221,0,0.0315652,"ks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of three automatically constructed graphs, which can avoid error propagation problem naturally. To our best know"
D19-1396,U06-1009,0,0.112953,"Missing"
D19-1396,D15-1064,0,0.325118,"1997) and CRF (Lafferty et al., 2001), suffering from feature engineering. There are also a number of recent neural network approaches applied to NER, such as (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018; Akbik et al., 2018; Jie et al., 2019; Akbik et al., 2019). Compared with English, Chinese is not featured with obvious word boundaries, but it is important to leverage word boundaries and semantic information in Chinese NER. Many works use word segmentation information as extra features for Chinese NER, such as (Peng and Dredze, 2015; He and Sun, 2017a; Zhu and Wang, 2019). Peng and Dredze (2016), Cao et al. (2018) and Wu et al. (2019) propose joint models to train NER together with CWS. Our work is inspired by lattice LSTM (Zhang and Yang, 2018), which can integrate lexicon in NER. Graph convolutional networks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging"
D19-1396,P16-2025,0,0.4347,"ing airport) are the same as the boundaries of the named entity “ ¬::” (Beijing airport). Therefore, making full use of word information would help to improve the Chinese NER performance. There are three main ways to incorporate word information in NER. The first one is the pipeline method. The way of pipeline method is to apply Chinese Word Segmentation (CWS) first, and then to use a word-based NER model. However, the pipeline method suffers from error propagation, since the error of CWS may affect the performance of NER. The second one is to learn CWS and NER tasks jointly (Xu et al., 2013; Peng and Dredze, 2016; Cao et al., 2018; Wu et al., 2019). However, the joint models must rely on CWS annotation datasets, which are costly and are annotated under many diverse segmentation criteria (Chen 3830 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3830–3840, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics et al., 2017). The third one is to leverage an automatically constructed lexicon, which is pre-trained on large automatically segmented texts. Le"
D19-1396,D18-1032,0,0.0307567,"onvolutional networks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of three automatically constructed graphs, which can avoid error propagation problem natura"
D19-1396,N19-1306,0,0.0171484,"convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of three automatically constructed graphs, which can avoid error propagation problem naturally. To our best knowledge, we are the first to introduce GA"
D19-1396,W06-0126,0,0.583093,"Missing"
D19-1396,P18-1144,0,0.402665,"3840, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics et al., 2017). The third one is to leverage an automatically constructed lexicon, which is pre-trained on large automatically segmented texts. Lexical knowledge includes boundaries and semantic information. Boundaries information is provided by the lexicon word itself, and semantic information is provided by pre-trained word embeddings (Bengio et al., 2003; Mikolov et al., 2013). Compared with joint methods, a lexicon is easy to obtain and additional annotation CWS datasets are not required. Recently, Zhang and Yang (2018) propose a lattice LSTM to integrate lexical knowledge in NER. However, integrating lexical knowledge into sentences still faces two challenges. The first challenge is to integrate self-matched lexical words. A self-matched lexical word of a character is the lexical word that contains this character. For instance, “ ¬: ::” (Beijing Airport) and “: : :” (Airport) are the self-matched words of the character “: :” (airplane). “» ” (leave) is not the self-matched word of the character “:” (airplane), since “ :” (airplane) is not contained in the word “ » ” (leave). The lexical knowledge of self-ma"
D19-1396,D18-1244,0,0.0217361,"can integrate lexicon in NER. Graph convolutional networks. There are a number of recent graph convolutional network (GCN) architectures (Kipf and Welling, 2017; Hamilton et al., 2017; Veliˇckovi´c et al., 2018; Qu et al., 2019) for learning over graphs. Our work is closely related to the graph attention networks (GAT), introduced by Veliˇckovi´c et al. (2018), leveraging masked self-attention layers to assign different importance to neighbouring nodes. In recent years, there is more and more literature about the application of GCN in NLP (Bastings et al., 2017; Marcheggiani and Titov, 2017; Zhang et al., 2018; Yao et al., 2019; Wang et al., 2018; Mishra et al., 2019; Cao et al., 2019; Zhang et al., 2019). Cetoli et al. (2017) use GCN to investigate the role of the dependency tree in English named entity recognition. However, most of the works (Bastings et al., 2017; Marcheggiani and Titov, 2017; Cetoli et al., 2017; Zhang et al., 2018) heavily rely on the dependency tree to construct a single graph, which suffer from error propagation. To capture different semantic and boundaries information, we propose a Collaborative Graph Network consisting of three automatically constructed graphs, which can a"
D19-1396,N19-1342,0,0.805485,"Missing"
P13-1173,P10-1041,0,0.0104156,"erns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. terns are generated, we drop those patterns with frequency lower than"
P13-1173,P10-1060,0,0.0614549,"Missing"
P13-1173,W09-2307,0,0.0304995,"Missing"
P13-1173,D07-1114,0,0.19021,"alled Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also"
P13-1173,P09-1079,0,0.0125535,"gh frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequent or long-tail opinion targets. 1764 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1764–1773, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics To address the problems stated above, this paper proposes a two-stage framework for mining opinion words and opinion targets. The underlying motivation is analogous to the novel idea “Mine the Easy, Classify the Hard” (Dasgupta and Ng, 2009). In our first stage, we propose a Sentiment Graph Walking algorithm to cope with the false opinion relation problem, which mines easy cases of opinion words/targets. We speculate that it may be helpful to introduce a confidence score for each pattern. Concretely, we create a Sentiment Graph to model opinion relations among opinion word/target/pattern candidates and apply random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confiden"
P13-1173,C10-1074,0,0.1338,"random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confidence patterns will also have low confidence accordingly. This could potentially improve the extraction accuracy. In the second stage, we identify the hard cases, which aims to filter out false opinion targets and extract long-tail opinion targets. Previous supervised methods have been shown to achieve stateof-the-art results for this task (Wu et al., 2009; Jin and Ho, 2009; Li et al., 2010). However, the big challenge for fully supervised method is the lack of annotated training data. Therefore, we adopt a self-learning strategy. Specifically, we employ a semi-supervised classifier to refine the target results from the first stage, which uses some highly confident target candidates as the initial labeled examples. Then opinion words are also refined. Our main contributions are as follows: • We propose a Sentiment Graph Walking algorithm to mine opinion words and opinion targets from reviews, which naturally incorporates confidence of syntactic pattern in a graph to improve extra"
P13-1173,W00-1213,0,0.0355731,"els of hyponyms in four WordNet (Miller, 1995) synsets “object”, “person”, “group” and “measure” into the GN corpus. Our idea was based on the fact that a term is more general when it sits in higher level in the WordNet hierarchy. Then inapplicable candidates were discarded and a 3071-word English 2 Note that the “positive” and “negative” here denote opinion targets and non-target terms respectively and they do not indicate sentiment polarities. 3 http://books.google.com/ngrams. 1767 GN corpus was created. Another Chinese GN corpus with 3493 words was generated in the similar way from HowNet (Gan and Wong, 2000). Generation of Labeled Examples. Let T = {Y+1 , Y−1 } denotes the initial labeled set, where N most highly confident target candidates but not in our GN corpora are regarded as the positive example set Y+1 , other N terms from GN corpora which are also top ranked in the target list are selected as the negative example set Y−1 . The reminder unlabeled candidates are denoted by T ∗ . Feature Representation for Classifier. Given T and T ∗ in the form of {(xi , yi )}. For a target candidate ti , xi = (o1 , . . . , on , p1 , . . . , pm )T represents its feature vector, where oj is the opinion word"
P13-1173,D12-1123,1,0.827279,". Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. terns are generated, we drop those patterns with frequency lower than a threshold F . 3 T"
P13-1173,H05-1043,0,0.974257,"j-{mod}-(Prep)-{pcomp-n}-Noun”, but it doesn’t bear any sentiment orientation. We call such relations that match opinion patterns but express no opinion false opinion relations. Previous pattern learning algorithms (Zhuang et al., 2006; Kessler and Nicolov, 2009; Jijkoun et al., 2010) often extract opinion patterns by frequency. However, some high-frequency syntactic patterns can have very poor precision (Kessler and Nicolov, 2009). False Opinion Targets: In another case, the phrase “wonderful time” can be matched by an opinion pattern “Adj-{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. Due to the lack of ground-truth knowledge for opinion targets, non-target terms introduced in this way can be hardly filtered out. Long-tail Opinion Targets: We further notice that previous works prone to extract opinion targets with high frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequen"
P13-1173,W03-1014,0,0.190424,"nion relations more precisely, subsequent research work exploited syntax information. Popescu and Etzioni (2005) used manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. Qiu et al. (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify"
P13-1173,D09-1159,0,0.157668,"arget/pattern candidates and apply random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confidence patterns will also have low confidence accordingly. This could potentially improve the extraction accuracy. In the second stage, we identify the hard cases, which aims to filter out false opinion targets and extract long-tail opinion targets. Previous supervised methods have been shown to achieve stateof-the-art results for this task (Wu et al., 2009; Jin and Ho, 2009; Li et al., 2010). However, the big challenge for fully supervised method is the lack of annotated training data. Therefore, we adopt a self-learning strategy. Specifically, we employ a semi-supervised classifier to refine the target results from the first stage, which uses some highly confident target candidates as the initial labeled examples. Then opinion words are also refined. Our main contributions are as follows: • We propose a Sentiment Graph Walking algorithm to mine opinion words and opinion targets from reviews, which naturally incorporates confidence of syntactic"
P13-1173,C10-2167,0,0.181247,"Missing"
P13-1173,H05-2017,0,\N,Missing
P13-1173,P12-1043,0,\N,Missing
P15-1017,C12-1033,0,0.0799281,"Missing"
P15-1017,P09-2093,0,0.0476394,"s and structure-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues (such as sequences and parse trees) into feature vectors. Ahn (2006) uses the lexical features(e.g., full word, pos tag), syntactic features (e.g., dependency features) and externalknowledge features(WordNet) to extract the event. Inspired by the hypothesis of “One Sense Per Dis174 course”(Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the cross-event and cross-entity inference for the ACE event task. Although these approaches achieve high performance, featurebased methods suffer from the problem of selecting a suitable feature set when converting the classification clues into feature vectors. In structure-based methods, researchers treat event extraction as the task of predicting the structure of the event in a sentence. McClosky et al. (2011) casted the problem of biomedical event extraction as a dependency parsing problem. Li et al. (2013) presented a joint framew"
P15-1017,P11-1113,0,0.19037,"der the following sentence with an ambiguous word beats: S1: Obama beats McCain. S2: Tyson beats his opponent . In S1, beats is a trigger of type Elect. However, in S2, beats is a trigger of type Attack, which is more common than type Elect. Because of the ambiguity, a traditional approach may mislabel beats in S1 as a trigger of Attack. However, if we have the priori knowledge that Obama and McCain are presidential contenders, we have ample evidence to predict that beats is a trigger of type Elect. We call these knowledge lexical-level clues. To represent such features, the existing methods (Hong et al., 2011) often rely on human ingenuity, which is a time-consuming process and lacks generalization. Furthermore, traditional lexical features in previous methods are a one-hot representation, which may suffer from the data sparsity problem and may not be able to adequately capture the semantics of the words (Turian et al., 2010). To identify events and arguments more precisely, previous methods often captured contextual features, such as syntactic features, which aim to understand how facts are tied together from a larger field of view. For example, in S3, there are two events that share three argumen"
P15-1017,P14-1062,0,0.0101148,"tence-level features. The semantic interactions between the predicted trigger words and argument candidates are crucial for argument classification. Therefore, we propose three types of input that the DMCNN uses to capture these important clues: Figure 2 assumes that word embedding has size dw = 4, position embedding has size dp = 1 and event-type embedding has size de = 1. Let xi ∈ Rd be the d-dimensional vector representation corresponding to the i-th word in the sentence, where d = dw + dp ∗ 2 + de . A sentence of length n is represented as follows: • Context-word feature (CWF): Similar to Kalchbrenner et al. (2014) and Collobert et al. (2011), we take all the words of the whole sentence as the context. CWF is the vector of each word token transformed by looking up word embeddings. x1:n = x1 ⊕ x2 ⊕ ... ⊕ xn (3) where ⊕ is the concatenation operator. Thus, combined word embedding, position embedding and event-type embedding transform an instance as a matrix X ∈ Rn×d . Then, X is fed into the convolution part. • Position feature (PF): It is necessary to spec170 3.2.2 reserve more valuable information without missing the max-pooling value. As shown in Figure 2, the feature map output cj is divided into thre"
P15-1017,P08-1030,0,0.286991,"tences. We propose a dynamic multi-pooling convolutional neural network (DMCNN), which uses a dynamic multi-pooling layer according to event triggers and arguments, to reserve more crucial information. The experimental results show that our approach significantly outperforms other state-of-the-art methods. 1 Introduction Event extraction is an important and challenging task in Information Extraction (IE), which aims to discover event triggers with specific types and their arguments. Current state-of-the-art methods (Li et al., 2014; Li et al., 2013; Hong et al., 2011; Liao and Grishman, 2010; Ji and Grishman, 2008) often use a set of elaborately designed features that are extracted by textual analysis and linguistic 167 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 167–176, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics In Baghdad , a cameraman died when an American tank fired on the Palestine Hotel. det nsubj amod det prep_in advmod nsubj nn det prep_on advcl Figure 1: Event mentions and syntactic parser results of S3. The upper side shows two ev"
P15-1017,W13-3214,0,0.0425143,"Missing"
P15-1017,D14-1181,0,0.00995286,"Missing"
P15-1017,W06-0901,0,0.657785,"sentence may contain more than one event, using only the most important information to represent a sentence, as in the traditional CNN, will miss valuable clues. To resolve this problem, we propose a DMCNN to extract the sentence-level features. The DMCNN uses a dynamic multi-pooling layer to obtain a maximum value for each part of a sentence, which is split by event triggers and event arguments. Thus, the DMCNN is expected to capture more valuable clues compared to traditional CNN methods. • Event-type feature (EF): The event type of a current trigger is valuable for argument classification (Ahn, 2006; Hong et al., 2011; Liao and Grishman, 2010; Li et al., 2013), so we encode event type predicted in the trigger classification stage as an important clue for the DMCNN, as in the PF. 3.2.1 Input This subsection illustrates the input needed for a DMCNN to extract sentence-level features. The semantic interactions between the predicted trigger words and argument candidates are crucial for argument classification. Therefore, we propose three types of input that the DMCNN uses to capture these important clues: Figure 2 assumes that word embedding has size dw = 4, position embedding has size dp ="
P15-1017,P13-1008,0,0.523129,"d may miss valuable facts when considering multiple-event sentences. We propose a dynamic multi-pooling convolutional neural network (DMCNN), which uses a dynamic multi-pooling layer according to event triggers and arguments, to reserve more crucial information. The experimental results show that our approach significantly outperforms other state-of-the-art methods. 1 Introduction Event extraction is an important and challenging task in Information Extraction (IE), which aims to discover event triggers with specific types and their arguments. Current state-of-the-art methods (Li et al., 2014; Li et al., 2013; Hong et al., 2011; Liao and Grishman, 2010; Ji and Grishman, 2008) often use a set of elaborately designed features that are extracted by textual analysis and linguistic 167 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 167–176, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics In Baghdad , a cameraman died when an American tank fired on the Palestine Hotel. det nsubj amod det prep_in advmod nsubj nn det prep_on advcl Figure 1: Event ment"
P15-1017,D14-1198,0,0.213835,"Missing"
P15-1017,P10-1081,0,0.448939,"dering multiple-event sentences. We propose a dynamic multi-pooling convolutional neural network (DMCNN), which uses a dynamic multi-pooling layer according to event triggers and arguments, to reserve more crucial information. The experimental results show that our approach significantly outperforms other state-of-the-art methods. 1 Introduction Event extraction is an important and challenging task in Information Extraction (IE), which aims to discover event triggers with specific types and their arguments. Current state-of-the-art methods (Li et al., 2014; Li et al., 2013; Hong et al., 2011; Liao and Grishman, 2010; Ji and Grishman, 2008) often use a set of elaborately designed features that are extracted by textual analysis and linguistic 167 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 167–176, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics In Baghdad , a cameraman died when an American tank fired on the Palestine Hotel. det nsubj amod det prep_in advmod nsubj nn det prep_on advcl Figure 1: Event mentions and syntactic parser results of S3. The"
P15-1017,P11-1163,0,0.0826368,"Missing"
P15-1017,P10-1040,0,0.015305,"trigger of Attack. However, if we have the priori knowledge that Obama and McCain are presidential contenders, we have ample evidence to predict that beats is a trigger of type Elect. We call these knowledge lexical-level clues. To represent such features, the existing methods (Hong et al., 2011) often rely on human ingenuity, which is a time-consuming process and lacks generalization. Furthermore, traditional lexical features in previous methods are a one-hot representation, which may suffer from the data sparsity problem and may not be able to adequately capture the semantics of the words (Turian et al., 2010). To identify events and arguments more precisely, previous methods often captured contextual features, such as syntactic features, which aim to understand how facts are tied together from a larger field of view. For example, in S3, there are two events that share three arguments as shown in Figure 1. From the dependency relation of nsubj between the argument cameraman and trigger died, we can induce a Victim role to cameraman in the Die event. We call such information sentence-level clues. However, the argument word cameraman and its trigger word fired are in different clauses, and there is n"
P15-1017,P95-1026,0,0.543966,"es have been explored for event extraction. Nearly all of the ACE event extraction use supervised paradigm. We further divide supervised approaches into feature-based methods and structure-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues (such as sequences and parse trees) into feature vectors. Ahn (2006) uses the lexical features(e.g., full word, pos tag), syntactic features (e.g., dependency features) and externalknowledge features(WordNet) to extract the event. Inspired by the hypothesis of “One Sense Per Dis174 course”(Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the cross-event and cross-entity inference for the ACE event task. Although these approaches achieve high performance, featurebased methods suffer from the problem of selecting a suitable feature set when converting the classification clues into feature vectors. In structure-based methods, researchers treat event extraction as the task of predicting the structur"
P15-1017,C14-1220,1,0.29368,"ing such features depends heavily on the performance of pre-existing NLP systems, which could suffer from error propagation. S3: In Baghdad, a cameraman died when an American tank fired on the Palestine Hotel. To correctly attach cameraman to fired as a Target argument, we must exploit internal semantics over the entire sentence such that the Attack event results in Die event. Recent improvements of convolutional neural networks (CNNs) have been proven to be efficient for capturing syntactic and semantics between words within a sentence (Collobert et al., 2011; Kalchbrenner and Blunsom, 2013; Zeng et al., 2014) for NLP tasks. CNNs typically use a max-pooling layer, which applies a max operation over the representation of an entire sentence to capture the most useful information. However, in event extraction, one sentence may contain two or more events, and these events may share the argument with different roles. For example, there are two events in S3, namely, the Die event and Attack event. If we use a traditional max-pooling layer and only keep the most important information to represent the sentence, we may obtain the information that depicts “a cameraman died” but miss the information about “Am"
P15-1017,P14-1023,0,\N,Missing
P16-1201,W06-0901,0,0.0223113,"ackle with it, our basic ED approach follows representation-based paradigm, which has been demonstrated effective in the cross-domain situation (Nguyen and Grishman, 2015). Related Work Event extraction is an increasingly hot and challenging research topic in NLP. Many approaches have been proposed for this task. Nearly all the existing methods on ACE event task use supervised paradigm. We further divide them into featurebased methods and representation-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues into feature vectors. Ahn (2006) uses the lexical features(e.g., full word), syntactic features (e.g., dependency features) and externalknowledge features(WordNet (Miller, 1995)) to extract the event. Inspired by the hypothesis of One Sense Per Discourse (Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the crossevent and cross-entity inference for the ACE event task. Li et al. (2013) proposed a joint model to capture the comb"
P16-1201,P98-1013,0,0.1115,"rom frames to event-types. Finally, we improve the performance of event detection and achieve a new state-of-the-art result by using the events automatically detected from FN. 1 Introduction In the ACE (Automatic Context Extraction) event extraction program, an event is represented as a structure consisting of an event trigger and a set of arguments. This paper tackles with the event detection (ED) task, which is a crucial component in the overall task of event extraction. The goal of ED is to identify event triggers and their corresponding event types from the given documents. FrameNet (FN) (Baker et al., 1998; Fillmore et al., 2003) is a linguistic resource storing considerable information about lexical and predicateargument semantics. In FN, a frame is defined as a composition of a Lexical Unit (LU) and a set of Frame Elements (FE). Most frames contain a set of exemplars with annotated LUs and FEs (see Figure 2 and Section 2.2 for details). From the above definitions of events and frames, it is not hard to find that the frames defined in FN share highly similar structures as the events defined in ACE. Firstly, the LU of a Frame plays a similar role as the trigger of an event. ACE defines the trig"
P16-1201,P15-1017,1,0.792201,"with 150,000 annotated exemplars. Eight relations are defined between frames in FN, but in this paper we only use the following three of them because the others do not satisfy our hypotheses (see section 4.2): Inheritance: A inherited from B indicates that A must correspond to an equally or more specific fact about B. It is a directional relation. See also: A and B connected by this relation indicates that they are similar frames. Perspective on: A and B connected by this relation means that they are different points-of-view about the same fact (i.e. Receiving vs. Transfer). event detection (Chen et al., 2015; Nguyen and Grishman, 2015). Nguyen and Grishman (2015) employed Convolutional Neural Networks (CNNs) to automatically extract sentence-level features for event detection. Chen et al. (2015) proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features. FrameNet is a typical resource for framesemantic parsing, which consists of the resolution of predicate sense into a frame, and the analysis of the frame’s participants (Thompson et al., 2003; Giuglea and Moschitti, 2006; Hermann et al., 2014; Das et al., 2014). Other tasks which have been studied based on FN inclu"
P16-1201,J14-1002,0,0.0257536,"e fact (i.e. Receiving vs. Transfer). event detection (Chen et al., 2015; Nguyen and Grishman, 2015). Nguyen and Grishman (2015) employed Convolutional Neural Networks (CNNs) to automatically extract sentence-level features for event detection. Chen et al. (2015) proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features. FrameNet is a typical resource for framesemantic parsing, which consists of the resolution of predicate sense into a frame, and the analysis of the frame’s participants (Thompson et al., 2003; Giuglea and Moschitti, 2006; Hermann et al., 2014; Das et al., 2014). Other tasks which have been studied based on FN include question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), textual entailment (Burchardt et al., 2009) and paraphrase recognition (Pad´o and Lapata, 2005). This is the first work to explore the application of FN to event detection. 2.3 Alike to existing work, we model event detection (ED) as a word classification task. In the ED task, each word in the given sentence is treated as a candidate trigger and the goal is to classify each of these candidates into one of 34 classes (33 event types plus a NA class). However, in t"
P16-1201,C04-1100,0,0.0228391,"2015). Nguyen and Grishman (2015) employed Convolutional Neural Networks (CNNs) to automatically extract sentence-level features for event detection. Chen et al. (2015) proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features. FrameNet is a typical resource for framesemantic parsing, which consists of the resolution of predicate sense into a frame, and the analysis of the frame’s participants (Thompson et al., 2003; Giuglea and Moschitti, 2006; Hermann et al., 2014; Das et al., 2014). Other tasks which have been studied based on FN include question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), textual entailment (Burchardt et al., 2009) and paraphrase recognition (Pad´o and Lapata, 2005). This is the first work to explore the application of FN to event detection. 2.3 Alike to existing work, we model event detection (ED) as a word classification task. In the ED task, each word in the given sentence is treated as a candidate trigger and the goal is to classify each of these candidates into one of 34 classes (33 event types plus a NA class). However, in this work, as we assumed that the LU of a frame is analogical to the trigger of an event, we only treat the"
P16-1201,P14-1136,0,0.0125522,"-of-view about the same fact (i.e. Receiving vs. Transfer). event detection (Chen et al., 2015; Nguyen and Grishman, 2015). Nguyen and Grishman (2015) employed Convolutional Neural Networks (CNNs) to automatically extract sentence-level features for event detection. Chen et al. (2015) proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features. FrameNet is a typical resource for framesemantic parsing, which consists of the resolution of predicate sense into a frame, and the analysis of the frame’s participants (Thompson et al., 2003; Giuglea and Moschitti, 2006; Hermann et al., 2014; Das et al., 2014). Other tasks which have been studied based on FN include question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), textual entailment (Burchardt et al., 2009) and paraphrase recognition (Pad´o and Lapata, 2005). This is the first work to explore the application of FN to event detection. 2.3 Alike to existing work, we model event detection (ED) as a word classification task. In the ED task, each word in the given sentence is treated as a candidate trigger and the goal is to classify each of these candidates into one of 34 classes (33 event types plus a NA cl"
P16-1201,P15-2060,0,0.619422,"ated exemplars. Eight relations are defined between frames in FN, but in this paper we only use the following three of them because the others do not satisfy our hypotheses (see section 4.2): Inheritance: A inherited from B indicates that A must correspond to an equally or more specific fact about B. It is a directional relation. See also: A and B connected by this relation indicates that they are similar frames. Perspective on: A and B connected by this relation means that they are different points-of-view about the same fact (i.e. Receiving vs. Transfer). event detection (Chen et al., 2015; Nguyen and Grishman, 2015). Nguyen and Grishman (2015) employed Convolutional Neural Networks (CNNs) to automatically extract sentence-level features for event detection. Chen et al. (2015) proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features. FrameNet is a typical resource for framesemantic parsing, which consists of the resolution of predicate sense into a frame, and the analysis of the frame’s participants (Thompson et al., 2003; Giuglea and Moschitti, 2006; Hermann et al., 2014; Das et al., 2014). Other tasks which have been studied based on FN include question answering (Naray"
P16-1201,P11-1113,0,0.149267,"-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues into feature vectors. Ahn (2006) uses the lexical features(e.g., full word), syntactic features (e.g., dependency features) and externalknowledge features(WordNet (Miller, 1995)) to extract the event. Inspired by the hypothesis of One Sense Per Discourse (Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the crossevent and cross-entity inference for the ACE event task. Li et al. (2013) proposed a joint model to capture the combinational features of triggers and arguments. Liu et al. (2016) proposed a global inference approach to employ both latent local and global information for event detection. In representation-based methods, candidate event mentions are represented by embedding, which typically are fed into neural networks. Two similarly related work has been proposed on 3 3.1 Basic Event Detection Model Model We employ a simple three-layer (a input layer, a hidden layer and a so"
P16-1201,P08-1030,0,0.227743,"topic in NLP. Many approaches have been proposed for this task. Nearly all the existing methods on ACE event task use supervised paradigm. We further divide them into featurebased methods and representation-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues into feature vectors. Ahn (2006) uses the lexical features(e.g., full word), syntactic features (e.g., dependency features) and externalknowledge features(WordNet (Miller, 1995)) to extract the event. Inspired by the hypothesis of One Sense Per Discourse (Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the crossevent and cross-entity inference for the ACE event task. Li et al. (2013) proposed a joint model to capture the combinational features of triggers and arguments. Liu et al. (2016) proposed a global inference approach to employ both latent local and global information for event detection. In representation-based methods, candidate event mentions are represented by embedding, wh"
P16-1201,D14-1181,0,0.00150818,"o et al., 2003; Erhan et al., 2010). This paper uses unsupervised learned word embeddings as the source of base features. We use the Skipgram model (Mikolov et al., 2013) to learn word embeddings on the NYT corpus5 . Given a sentence, we concatenate the embedding vector of the candidate trigger and the average embedding vector of the words in the sentence as the input to our model. We train the model using a simple optimization technique called stochastic gradient descent (SGD) over shuffled mini-batches with the Adadelta update rule (Zeiler, 2012). Regularization is implemented by a dropout (Kim, 2014; Hinton et al., 2012). The experiments show that this simple model is surprisingly effective for event detection. 4 Event Detection in FrameNet To detect events in FN, we first learned the basic ED model based on ACE labeled corpus and then employ it to generate initial judgements (possible event types with confidence values) for each sentence in FN. Then, we apply a set of constraints for global inference based on the PSL model. 4.1 Probabilistic Soft Logic PSL is a framework for collective, probabilistic reasoning in relational domains (Kimmig et al., 2012; Bach et al., 2013). Similar to Ma"
P16-1201,P13-1008,0,0.227668,"nvert classification clues into feature vectors. Ahn (2006) uses the lexical features(e.g., full word), syntactic features (e.g., dependency features) and externalknowledge features(WordNet (Miller, 1995)) to extract the event. Inspired by the hypothesis of One Sense Per Discourse (Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the crossevent and cross-entity inference for the ACE event task. Li et al. (2013) proposed a joint model to capture the combinational features of triggers and arguments. Liu et al. (2016) proposed a global inference approach to employ both latent local and global information for event detection. In representation-based methods, candidate event mentions are represented by embedding, which typically are fed into neural networks. Two similarly related work has been proposed on 3 3.1 Basic Event Detection Model Model We employ a simple three-layer (a input layer, a hidden layer and a soft-max output layer) Artificial Neural Networks (ANNs) (Hagan et al., 1996) to model the ED"
P16-1201,H05-1108,0,0.0491284,"Missing"
P16-1201,D07-1002,0,0.0161106,"5) employed Convolutional Neural Networks (CNNs) to automatically extract sentence-level features for event detection. Chen et al. (2015) proposed dynamic multi-pooling operation on CNNs to capture better sentence-level features. FrameNet is a typical resource for framesemantic parsing, which consists of the resolution of predicate sense into a frame, and the analysis of the frame’s participants (Thompson et al., 2003; Giuglea and Moschitti, 2006; Hermann et al., 2014; Das et al., 2014). Other tasks which have been studied based on FN include question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), textual entailment (Burchardt et al., 2009) and paraphrase recognition (Pad´o and Lapata, 2005). This is the first work to explore the application of FN to event detection. 2.3 Alike to existing work, we model event detection (ED) as a word classification task. In the ED task, each word in the given sentence is treated as a candidate trigger and the goal is to classify each of these candidates into one of 34 classes (33 event types plus a NA class). However, in this work, as we assumed that the LU of a frame is analogical to the trigger of an event, we only treat the LU annotated in the give"
P16-1201,P95-1026,0,0.19917,"lenging research topic in NLP. Many approaches have been proposed for this task. Nearly all the existing methods on ACE event task use supervised paradigm. We further divide them into featurebased methods and representation-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues into feature vectors. Ahn (2006) uses the lexical features(e.g., full word), syntactic features (e.g., dependency features) and externalknowledge features(WordNet (Miller, 1995)) to extract the event. Inspired by the hypothesis of One Sense Per Discourse (Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the crossevent and cross-entity inference for the ACE event task. Li et al. (2013) proposed a joint model to capture the combinational features of triggers and arguments. Liu et al. (2016) proposed a global inference approach to employ both latent local and global information for event detection. In representation-based methods, candidate event mentions are repr"
P16-1201,P10-1081,0,0.118674,"ed methods and representation-based methods. In feature-based methods, a diverse set of strategies has been exploited to convert classification clues into feature vectors. Ahn (2006) uses the lexical features(e.g., full word), syntactic features (e.g., dependency features) and externalknowledge features(WordNet (Miller, 1995)) to extract the event. Inspired by the hypothesis of One Sense Per Discourse (Yarowsky, 1995), Ji and Grishman (2008) combined global evidence from related documents with local decisions for the event extraction. To capture more clues from the texts, Gupta and Ji (2009), Liao and Grishman (2010) and Hong et al. (2011) proposed the crossevent and cross-entity inference for the ACE event task. Li et al. (2013) proposed a joint model to capture the combinational features of triggers and arguments. Liu et al. (2016) proposed a global inference approach to employ both latent local and global information for event detection. In representation-based methods, candidate event mentions are represented by embedding, which typically are fed into neural networks. Two similarly related work has been proposed on 3 3.1 Basic Event Detection Model Model We employ a simple three-layer (a input layer,"
P16-1201,C98-1013,0,\N,Missing
P16-1201,P09-2093,0,\N,Missing
P17-1038,W06-0901,0,0.877637,"Missing"
P17-1038,P98-1013,0,0.155226,"arguments in events and roles of CVTs as the roles of arguments play in the event, respectively. According to the statistics of the Freebase released on 23th April, 2015, there are around 1885 CVTs and around 14 million CVTs instances. After filtering out useless and meaningless CVTs, such as CVTs about user profiles and website information, we select 21 types of CVTs with around 3.8 million instances for experiments, which mainly involves events about education, military, sports and so on. FrameNet3 is a linguistic resource storing information about lexical and predicate argument semantics (Baker et al., 1998). FrameNet contains more than 1, 000 frames and 10, 000 Lexical Units (LUs). Each frame of FrameNet can be taken as a semantic frame of a type of events (Liu et al., 2016). Each frame has a set of lemmas with part of speech tags that can evoke the frame, which are called LUs. For example, appoint.v is a LU of Appointing frame in FrameNet, which can be mapped to people.appointment events in Freebase. And a LUs of the frame plays a similar role as the trigger of an event. Thus we use FrameNet to detect triggers in our automatically data labeling process. Wikipedia4 that we used was released on J"
P17-1038,D13-1160,0,0.107616,"Missing"
P17-1038,P11-1098,0,0.0152802,"Missing"
P17-1038,P15-1017,1,0.753394,"Missing"
P17-1038,D14-1198,0,0.197879,"Missing"
P17-1038,N13-1104,0,0.0476628,"Missing"
P17-1038,P13-1008,0,0.741449,"mapped these types of events manually and we add them into ACE training corpus in two ways. (1) we delete the human annotated ACE data for these mapped event types in ACE dataset and add our automatically labeled data to remainder ACE training data. We call this Expanded Data (ED) as ED Only. (2) We directly add our automatically labeled data of mapped event types to ACE training data and we call this training data as ACE+ED. Then we use such data to train the same event extraction model (DMCNN) and evaluate them on the ACE testing data set. Following (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2013), we used the same test set with 40 newswire articles and the same development set with 30 documents and the rest 529 documents are used for ACE training set. And we use the same evaluation metric P, R, F as ACE task defined. We select three baselines trained with ACE data. (1) Li’s structure, which is the best reported structured-based system (Li et al., 2013). (2) Chen’s DMCNN, which is the best reported CNN-based system (Chen et al., 2015). (3) Nguyen’s JRNN, which is the state-ofthe-arts system (Nguyen et al., 2016). The results are shown in Table 4. Compared with all models, DMCNN trained"
P17-1038,P16-1201,1,0.82113,"here are around 1885 CVTs and around 14 million CVTs instances. After filtering out useless and meaningless CVTs, such as CVTs about user profiles and website information, we select 21 types of CVTs with around 3.8 million instances for experiments, which mainly involves events about education, military, sports and so on. FrameNet3 is a linguistic resource storing information about lexical and predicate argument semantics (Baker et al., 1998). FrameNet contains more than 1, 000 frames and 10, 000 Lexical Units (LUs). Each frame of FrameNet can be taken as a semantic frame of a type of events (Liu et al., 2016). Each frame has a set of lemmas with part of speech tags that can evoke the frame, which are called LUs. For example, appoint.v is a LU of Appointing frame in FrameNet, which can be mapped to people.appointment events in Freebase. And a LUs of the frame plays a similar role as the trigger of an event. Thus we use FrameNet to detect triggers in our automatically data labeling process. Wikipedia4 that we used was released on January, 2016. All 6.3 million articles in it are used in our experiments. We use Wikipedia because it is relatively up-to-date, and much of the information in Freebase is"
P17-1038,P11-1055,0,0.0212291,"ge is conducted, which aims to assign arguments to the event and identify their corresponding roles. We call this stage as argument classification. We employ two similar Dynamic Multi-pooling Convolutional Neural Networks with Multi-instance Learning (DMCNNs-MIL) for above two stages. The Dynamic Multi-pooling Convolutional Neural Networks (DMCNNs) is the best reported CNN-based model for event extraction (Chen et al., 2015) by using human-annotated training data. However, our automatically labeled data face a noise problem, which is a intrinsic problem of using DS to construct training data (Hoffmann et al., 2011; Surdeanu et al., 2012). In order to alleviate the wrong label problem, we use Multi-instance Learning (MIL) for two DMCNNs. Because the second stage is more complicated and limited in space, we take the MIL used in arguments classification as an example and describes as follows: We define all of the parameters for the stage of argument classification to be trained in DMCNNs as θ. Suppose that there are T bags {M1 , M2 , ..., MT } and that the  i-th bag contains qi instances (sentences) Mi = m1i , m2i , ..., mqi i , the objective of multi-instance learning is to predict the labels of the uns"
P17-1038,P11-1163,0,0.061963,"Missing"
P17-1038,P11-1113,0,0.811392,"Missing"
P17-1038,P09-1113,0,0.257676,"Missing"
P17-1038,P16-1025,0,0.0529364,"Missing"
P17-1038,P15-2060,0,0.418243,"Missing"
P17-1038,P08-1030,0,0.70382,"Missing"
P17-1038,N16-1034,0,0.537655,"life.marry events in ACE2005 dataset. We mapped these types of events manually and we add them into ACE training corpus in two ways. (1) we delete the human annotated ACE data for these mapped event types in ACE dataset and add our automatically labeled data to remainder ACE training data. We call this Expanded Data (ED) as ED Only. (2) We directly add our automatically labeled data of mapped event types to ACE training data and we call this training data as ACE+ED. Then we use such data to train the same event extraction model (DMCNN) and evaluate them on the ACE testing data set. Following (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2013), we used the same test set with 40 newswire articles and the same development set with 30 documents and the rest 529 documents are used for ACE training set. And we use the same evaluation metric P, R, F as ACE task defined. We select three baselines trained with ACE data. (1) Li’s structure, which is the best reported structured-based system (Li et al., 2013). (2) Chen’s DMCNN, which is the best reported CNN-based system (Chen et al., 2015). (3) Nguyen’s JRNN, which is the state-ofthe-arts system (Nguyen et al., 2016). The results are shown in Table 4. Co"
P17-1038,D12-1069,0,0.0144758,"Missing"
P17-1038,D12-1042,0,0.00878712,"aims to assign arguments to the event and identify their corresponding roles. We call this stage as argument classification. We employ two similar Dynamic Multi-pooling Convolutional Neural Networks with Multi-instance Learning (DMCNNs-MIL) for above two stages. The Dynamic Multi-pooling Convolutional Neural Networks (DMCNNs) is the best reported CNN-based model for event extraction (Chen et al., 2015) by using human-annotated training data. However, our automatically labeled data face a noise problem, which is a intrinsic problem of using DS to construct training data (Hoffmann et al., 2011; Surdeanu et al., 2012). In order to alleviate the wrong label problem, we use Multi-instance Learning (MIL) for two DMCNNs. Because the second stage is more complicated and limited in space, we take the MIL used in arguments classification as an example and describes as follows: We define all of the parameters for the stage of argument classification to be trained in DMCNNs as θ. Suppose that there are T bags {M1 , M2 , ..., MT } and that the  i-th bag contains qi instances (sentences) Mi = m1i , m2i , ..., mqi i , the objective of multi-instance learning is to predict the labels of the unseen bags. In stage of ar"
P17-1038,P10-1040,0,0.0166672,"e trigger words for each event type. 3.3 Trigger Word Filtering and Expansion We can obtain an initial verbal trigger lexicon by above trigger word detection. However, this initial trigger lexicon is noisy and merely contains verbal triggers. The nominal triggers like marriage are missing. Because the number of nouns in one sentence is usually larger than that of verbs, it is hard to use TR to find nominal triggers. Thus, we propose to use linguistic resource FrameNet to filter noisy verbal triggers and expand nominal triggers. As the success of word embedding in capturing semantics of words (Turian et al., 2010), we employ word embedding to map the events in Freebase to frames in FrameNet. Specifically, we use the average word embedding of all words in i-th Freebase event type name ei and word embedding of k-th lexical units of j-th frame ej,k to compute the semantic similarity. Finally, we select the frame contains max similarity of ei and ej,k as the mapped frame, which can be formulated as follows: f rame(i) = arg max(similarity(ei , ej,k )) (7) j Then, we filter the verb, which is in initial verbal trigger word lexicon and not in the mapping frame. And we use nouns with high confidence in the map"
P17-1038,P16-1123,0,0.0109397,"Missing"
P17-1038,D15-1203,1,0.290413,"Missing"
P17-1164,W06-0900,0,0.0583782,"du/software/ 5 Related Work Event detection is an increasingly hot and challenging research topic in NLP. Generally, existing approaches could roughly be divided into two groups. The first kind of approach tackled this task under the supervision of annotated triggers and entities, but totally ignored annotated arguments. The majority of existing work followed this paradigm, which includes feature-based methods and representationbased methods. Feature-based methods exploited a diverse set of strategies to convert classification clues (i.e., POS tags, dependency relations) into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Gupta and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Liu et al., 2016b). Representation-based methods typically represent candidate event mentions by embeddings and feed them into neural networks (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a; Nguyen and Grishman, 2016). The second kind of approach, on the contrast, tackled event detection and argument extraction simultaneously, which is called joint approach (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013, 2014; Venugopal et al., 2014; Nguyen"
P17-1164,P15-1017,1,0.88051,"are event arguments. The correct type of the event triggered by “fired ” in this case is End-Position. However, it might be easily misidentified as Attack because “fired ” is a multivocal word. In this case, if we consider the phrase “former protege”, which serves as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respectively. Compared with state-of-the-art"
P17-1164,P98-1013,0,0.348285,"Specifically, in training procedure, we first construct gold attentions for each trigger candidate based on annotated arguments. Then, treating gold attentions as the supervision to train the attention mechanism, we learn attention and event detector jointly both in supervised manner. In testing procedure, we use the ED model with learned attention mechanisms to detect events. In the experiment section, we systematically conduct comparisons on a widely used benchmark dataset ACE20051 . In order to further demonstrate the effectiveness of our approach, we also use events from FrameNet (FN) (F. Baker et al., 1998) as extra training data, as the same as Liu et al. (2016a) to alleviate the data-sparseness problem for ED to augment the performance of the proposed approach. The experimental results demonstrate that the proposed approach is effective for ED task, and it outperforms state-of-the-art approaches with remarkable gains. To sum up, our main contributions are: (1) we analyze the problem of joint models on the task of ED, and propose to use the annotated argument information explicitly for this task. (2) to achieve this goal, we introduce a supervised attention based ED model. Furthermore, we syste"
P17-1164,P09-2093,0,0.0325485,"e trigger word and the other bold words are event arguments. The correct type of the event triggered by “fired ” in this case is End-Position. However, it might be easily misidentified as Attack because “fired ” is a multivocal word. In this case, if we consider the phrase “former protege”, which serves as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respec"
P17-1164,P11-1113,0,0.921572,"he other bold words are event arguments. The correct type of the event triggered by “fired ” in this case is End-Position. However, it might be easily misidentified as Attack because “fired ” is a multivocal word. In this case, if we consider the phrase “former protege”, which serves as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respectively. Compared wi"
P17-1164,P08-1030,0,0.690342,"entence, “fired ” is the trigger word and the other bold words are event arguments. The correct type of the event triggered by “fired ” in this case is End-Position. However, it might be easily misidentified as Attack because “fired ” is a multivocal word. In this case, if we consider the phrase “former protege”, which serves as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for even"
P17-1164,D14-1181,0,0.00357226,"Missing"
P17-1164,P14-1038,0,0.0166946,"iu et al. (2016a) detected events from FrameNet based on the observation that frames in FN are analogous to events in ACE 1795 5 https://github.com/subacl/acl16 (lexical unit of a frame ↔ trigger of an event, frame elements of a frame ↔ arguments of an event). All events they published are also frames in FN. Thus, we treat frame elements annotated in FN corpus as event arguments. Since frames generally contain more frame elements than events, we only use core6 elements in this work. Moreover, to obtain entity information, we use RPI Joint Information Extraction System7 (Li et al., 2013, 2014; Li and Ji, 2014) to label ACE entity mentions. Experimental Results We use the events from FN as extra training data and keep the development and test datasets unchanged.Table 4 presents the experimental results. Methods ANN ANN-S1 ANN-S2 ANN +FrameNet ANN-S1 +FrameNet ANN-S2 +FrameNet P 69.9 81.4 78.0 72.5 80.1 76.8 R 60.8 62.4 66.3 61.7 63.6 67.5 F1 65.0 70.8 71.7 66.7 70.9 71.9 Table 4: Experimental results on ACE 2005 corpus. “+FrameNet” designates the systems that are augmented by events from FrameNet. From the results, we observe that: 1). With extra training data, ANN achieves significant improvements"
P17-1164,D14-1198,0,0.181628,"Missing"
P17-1164,P13-1008,0,0.608567,"e”, which serves as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respectively. Compared with state-of-the-art pipeline systems, both join1789 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1789–1798 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org"
P17-1164,P10-1081,0,0.822659,"research topic in NLP. Generally, existing approaches could roughly be divided into two groups. The first kind of approach tackled this task under the supervision of annotated triggers and entities, but totally ignored annotated arguments. The majority of existing work followed this paradigm, which includes feature-based methods and representationbased methods. Feature-based methods exploited a diverse set of strategies to convert classification clues (i.e., POS tags, dependency relations) into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Gupta and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Liu et al., 2016b). Representation-based methods typically represent candidate event mentions by embeddings and feed them into neural networks (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a; Nguyen and Grishman, 2016). The second kind of approach, on the contrast, tackled event detection and argument extraction simultaneously, which is called joint approach (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013, 2014; Venugopal et al., 2014; Nguyen et al., 2016). Joint approach is proposed to capture internal and external dependencies of events"
P17-1164,P16-1201,1,0.801923,"event triggered by “fired ” in this case is End-Position. However, it might be easily misidentified as Attack because “fired ” is a multivocal word. In this case, if we consider the phrase “former protege”, which serves as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respectively. Compared with state-of-the-art pipeline systems, both join1789 Proceedings"
P17-1164,D16-1249,0,0.0383889,"rds. To achieve this goal, we propose two strategies to construct gold attention vectors: S1: only pay attention to argument words. That is, all argument words in the given context obtain the same attention, whereas other words get no attention. For candidates without any annotated arguments in context (such as negative samples), we force all entities to average the whole attention. Figure 2 illustrates the details, where α∗ is the final gold attention vector. to ED, the words around them are also helpful. And the nearer a word is to arguments, the more attention it should obtain. Inspired by Mi et al. (2016), we use a gaussian distribution g(·) to model the attention distribution of words around arguments. In detail, given an instance, we first obtain the raw attention vector α in the same manner as S1 (see figure 2). ′ Then, we create a new vector α with all points initialized with zero, and for each αi = 1, we ′ update α by the following algorithm: Algorithm 1: Updating α ′ for k ∈ {−w, ..., 0, ..., w} do ′ ′ αi+k = αi+k + g(|k|, µ, σ) end where w is the window size of the attention mechanism and µ, σ are hyper-parameters of the gaussian distribution. Finally, we normal′ ize α to obtain the tar"
P17-1164,N16-1034,0,0.651498,"osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respectively. Compared with state-of-the-art pipeline systems, both join1789 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1789–1798 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1164 ED AE Symbolic Methods H"
P17-1164,D14-1090,0,0.517295,"as an argument (Role = P osition) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most existing methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detection and argument extraction simultaneously (Riedel et al., 2009; Li et al., 2013; Venugopal et al., 2014; Nguyen et al., 2016), these approaches usually only make remarkable improvements to AE, but insignificant to ED. Table 1 illustrates our observations. Li et al. (2013) and Nguyen et al. (2016) are state-of-the-art joint models in symbolic and embedding methods for event extraction, respectively. Compared with state-of-the-art pipeline systems, both join1789 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1789–1798 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1164 ED"
P17-1164,P14-2136,0,0.0363178,"introduces the non-consecutive convolution to capture non-consecutive k-grams for event detection. It is the best reported representation-based approach on this task. Table 3 presents the experimental results on ACE 2005 corpus. From the table, we make the following observations: 1). ANN performs unexpectedly poorly, which indicates that unsupervised-attention mechanisms do not work well for ED. We believe the reason is that the training data of ACE 2005 corpus is insufficient to train a precise attention in an unsupervised manner, considering that data sparseness is an important issue of ED (Zhu et al., 2014; Liu et al., 2016a). 2). With argument information employed via supervised attention mechanisms, both ANN-S1 and ANN-S2 outperform ANN with remarkable gains, which illustrates the effectiveness of the proposed approach. 3). ANN-S2 outperforms ANN-S1, but the latter achieves higher precision. It is not difficult to understand. On the one hand, strategy S1 only focuses on argument words, which provides accurate information to identify event type, thus ANN-S1 could achieve higher precision. On the other hand, S2 focuses on both arguments and words around them, which provides more general but noi"
P17-1164,P15-2060,0,0.740377,"Missing"
P17-1164,D16-1085,0,0.519844,"Missing"
P17-1164,D09-1016,0,0.152513,"detection is an increasingly hot and challenging research topic in NLP. Generally, existing approaches could roughly be divided into two groups. The first kind of approach tackled this task under the supervision of annotated triggers and entities, but totally ignored annotated arguments. The majority of existing work followed this paradigm, which includes feature-based methods and representationbased methods. Feature-based methods exploited a diverse set of strategies to convert classification clues (i.e., POS tags, dependency relations) into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Gupta and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Liu et al., 2016b). Representation-based methods typically represent candidate event mentions by embeddings and feed them into neural networks (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a; Nguyen and Grishman, 2016). The second kind of approach, on the contrast, tackled event detection and argument extraction simultaneously, which is called joint approach (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013, 2014; Venugopal et al., 2014; Nguyen et al., 2016). Joint approach is proposed to capture"
P17-1164,N10-1123,0,0.0626273,"ation clues (i.e., POS tags, dependency relations) into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Gupta and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Liu et al., 2016b). Representation-based methods typically represent candidate event mentions by embeddings and feed them into neural networks (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a; Nguyen and Grishman, 2016). The second kind of approach, on the contrast, tackled event detection and argument extraction simultaneously, which is called joint approach (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013, 2014; Venugopal et al., 2014; Nguyen et al., 2016). Joint approach is proposed to capture internal and external dependencies of events, including trigger-trigger, argument-argument and trigger-argument dependencies. Theoretically, both ED and AE are expected to benefit from joint methods because triggers and arguments are jointly considered. However, in practice, existing joint methods usually only make remarkable improvements to AE, but insignificant to ED. Different from them, this work investigates the exploitation of argument information to improve the performance of ED."
P17-1164,C98-1013,0,\N,Missing
P18-4009,P15-1017,1,0.900406,"line DCFEE system9 . 5 Related Work The current EE approaches can be mainly classified into statistical methods, pattern-based method and hybrid method (Hogenboom et al., 2016). 12 Example of a pattern for a freeze event: (Frozen institution(ORG)+, Trigger word(TRI)+, Shareholder names(NAME)+,time) 54 Statistical method can be divided into two categories: traditional machine learning algorithm based on feature extraction engineering (Ahn, 2006), (Ji and Grishman, 2008), (Liao and Grishman, 2010), (Reichart and Barzilay, 2012) and neural network algorithm based on automatic feature extraction (Chen et al., 2015), (Nguyen et al., 2016), (Liu et al., 2017). The pattern method is usually used in industry because it can achieve higher accuracy, but meanwhile a lower recall. In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al., 2016). Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010). To our best knowledge, there is no system that automatically generates labeled d"
P18-4009,P10-1081,0,0.248432,"experimental results show that the effectiveness of SEE and DEE, the acceptable precision Figure 5: A screen shot of the online DCFEE system9 . 5 Related Work The current EE approaches can be mainly classified into statistical methods, pattern-based method and hybrid method (Hogenboom et al., 2016). 12 Example of a pattern for a freeze event: (Frozen institution(ORG)+, Trigger word(TRI)+, Shareholder names(NAME)+,time) 54 Statistical method can be divided into two categories: traditional machine learning algorithm based on feature extraction engineering (Ahn, 2006), (Ji and Grishman, 2008), (Liao and Grishman, 2010), (Reichart and Barzilay, 2012) and neural network algorithm based on automatic feature extraction (Chen et al., 2015), (Nguyen et al., 2016), (Liu et al., 2017). The pattern method is usually used in industry because it can achieve higher accuracy, but meanwhile a lower recall. In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al., 2016). Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and"
P18-4009,P16-1154,0,0.0524912,"Missing"
P18-4009,P08-1030,0,0.184611,"event knowledge base. The experimental results show that the effectiveness of SEE and DEE, the acceptable precision Figure 5: A screen shot of the online DCFEE system9 . 5 Related Work The current EE approaches can be mainly classified into statistical methods, pattern-based method and hybrid method (Hogenboom et al., 2016). 12 Example of a pattern for a freeze event: (Frozen institution(ORG)+, Trigger word(TRI)+, Shareholder names(NAME)+,time) 54 Statistical method can be divided into two categories: traditional machine learning algorithm based on feature extraction engineering (Ahn, 2006), (Ji and Grishman, 2008), (Liao and Grishman, 2010), (Reichart and Barzilay, 2012) and neural network algorithm based on automatic feature extraction (Chen et al., 2015), (Nguyen et al., 2016), (Liu et al., 2017). The pattern method is usually used in industry because it can achieve higher accuracy, but meanwhile a lower recall. In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al., 2016). Hybrid event-extraction methods combine statistical methods and pattern-based metho"
P18-4009,P17-1164,1,0.900331,"Missing"
P18-4009,D15-1203,1,0.805938,"obtain these textual data from Sohu securities net10 . Method of data generation: annotation data consists of two parts: sentence-level data generated by labeling the event trigger and event arguments in the event mention; document-level data generated by labeling the event mention from the document-level announcement. Now the question is, how to find the event triggers. Event arguments and event mention that correspond to the structured event knowledge database are summarized from a mass of announcements. DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al., 2017). Inspired by DS, we assume that one sentence contains the most event arguments and driven by a specific trigger is likely to be an event mention in an announcement. And arguments occurring in the event mention are 10 2.2 Event Extraction (EE) Figure 4 depicts the overall architecture of the EE system proposed in this paper which primarily involves the following two components: The sentence-level Event Extraction (SEE) purposes to http://q.stock.sohu.com/cn/000001/gsgg.shtml 52 S1 :… .… Sn :… pledge to CITIC... Sn+1:The pledge period is 12 months. … ext"
P18-4009,W06-0901,0,0.80415,"g.xiao, jzhao,}@nlpr.ia.ac.cn Abstract in Figure 1, an EE system is expected to discover an Equity Freeze event mention (E1 itself) triggered by frozen and extract the corresponding five arguments with different roles: Nagafu Ruihua (Role=Shareholder Name), 520,000 shares (Role=Num of Frozen Stock), People’s Court of Dalian city (Role=Frozen Institution), May 5,2017 (Role=Freezing Start Date) and 3 years (Role=Freezing End Date). Extracting event instances from texts plays a critical role in building NLP applications such as Information Extraction (IE), Question Answer (QA) and Summarization (Ahn, 2006). Recently, researchers have built some English EE systems, such as EventRegistry7 and Stela8 . However, in financial domain, there is no such effective EE system, especially in Chinese. Financial events are able to help users obtain competitors’ strategies, predict the stock market and make correct investment decisions. For example, the occurrence of an Equity Freeze event will have a bad effect on the company and the shareholders should make correct decisions quickly to avoid the losses. In business domain, official announcements released by companies represent the occurrence of major events"
P18-4009,P17-1038,1,0.731308,"ities net10 . Method of data generation: annotation data consists of two parts: sentence-level data generated by labeling the event trigger and event arguments in the event mention; document-level data generated by labeling the event mention from the document-level announcement. Now the question is, how to find the event triggers. Event arguments and event mention that correspond to the structured event knowledge database are summarized from a mass of announcements. DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al., 2017). Inspired by DS, we assume that one sentence contains the most event arguments and driven by a specific trigger is likely to be an event mention in an announcement. And arguments occurring in the event mention are 10 2.2 Event Extraction (EE) Figure 4 depicts the overall architecture of the EE system proposed in this paper which primarily involves the following two components: The sentence-level Event Extraction (SEE) purposes to http://q.stock.sohu.com/cn/000001/gsgg.shtml 52 S1 :… .… Sn :… pledge to CITIC... Sn+1:The pledge period is 12 months. … extract event arguments and event triggers f"
S19-2229,Q17-1010,0,0.0215224,"Missing"
S19-2229,S19-2155,0,0.0632924,"Missing"
S19-2229,P18-2012,0,0.0275008,"toponym detection. Usually the performance of these methods heavily relies on the quality of hand-crafted features. However, manually selected features may be sub-optimal. Also, these methods cannot effectively exploit contextual information due to the dependency on bag-of-word features. In recent years, many neural network based methods have been proposed for NER. For example, Ma and Hovy (2016) proposed a CNN-LSTM-CRF model for NER. They use CNN layer to learn character features of each word, LSTM layer to learn the contextual word representations and CRF layer to predict the label jointly. Gregoric et al. (2018) proposed Parallel RNN architecture. They split a single LSTM into multiple equally-size ones with a penalty to promote diversity. However, these methods cannot utilize external knowledge to recognize entities, which is usually important to toponym detection. Usually, linguistic knowledge such as part-of-speech and dictionary knowledge may be useful for toponym detection, and they are easy to obtain. Therefore, in this paper, we aim to incorporate these external knowledge sources to enhance our neural model for toponym detection. Similarly, there are many works on toponym disambiguation. Most"
S19-2229,P16-1101,0,0.0175191,"ER is a widely explored task and most NER methods can be applied to toponym detection. For example, Ratinov and Roth (2009) used n-grams, history predictions as the input features of conditional random fields (CRF) for toponym detection. Usually the performance of these methods heavily relies on the quality of hand-crafted features. However, manually selected features may be sub-optimal. Also, these methods cannot effectively exploit contextual information due to the dependency on bag-of-word features. In recent years, many neural network based methods have been proposed for NER. For example, Ma and Hovy (2016) proposed a CNN-LSTM-CRF model for NER. They use CNN layer to learn character features of each word, LSTM layer to learn the contextual word representations and CRF layer to predict the label jointly. Gregoric et al. (2018) proposed Parallel RNN architecture. They split a single LSTM into multiple equally-size ones with a penalty to promote diversity. However, these methods cannot utilize external knowledge to recognize entities, which is usually important to toponym detection. Usually, linguistic knowledge such as part-of-speech and dictionary knowledge may be useful for toponym detection, an"
S19-2229,D14-1162,0,0.0808159,"Missing"
S19-2229,P17-1161,0,0.0127184,"larly, there are many works on toponym disambiguation. Most of them are rule-based methods. They use some heuristics to rank the candidates and choose the highest one(Gritta et al., 2018). For example, Karimzadeh et al. (2013) used the geographical level(e.g. country, province and city), the Levenshtein Distance and the population of potential candidates to rank the candidate toponym and choose the highest one. However, the result of toponym disambiguation relied on corpus domain and the rule should be reconsidered when applied to different corpus. For the toponym detection task, we use TagLM(Peters et al., 2017) as the basic model. 1302 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 1302–1307 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics In our model, we first learn word representations from original characters, then learn contextual word representations by a stacked Bi-LSTM network, and finally use a CRF layer to jointly decode the label sequence. To enrich the representations of words, we incorporate various features such as pre-trained word embeddings, POS tags and lexicon features. For the toponym disambig"
S19-2229,W09-1119,0,0.0319894,"ym detection subtask. 1 Introduction Toponym resolution is an important task in the natural language processing field and has many applications such as emergency response and social media geographical event analysis(Gritta et al., 2018). Toponym resolution is usually modelled as a two-step task. The first step is toponym detection, which is a typical named entity recognition (NER) task. The second step is toponym disambiguation, which aims to map locations to its coordinates in the real world. NER is a widely explored task and most NER methods can be applied to toponym detection. For example, Ratinov and Roth (2009) used n-grams, history predictions as the input features of conditional random fields (CRF) for toponym detection. Usually the performance of these methods heavily relies on the quality of hand-crafted features. However, manually selected features may be sub-optimal. Also, these methods cannot effectively exploit contextual information due to the dependency on bag-of-word features. In recent years, many neural network based methods have been proposed for NER. For example, Ma and Hovy (2016) proposed a CNN-LSTM-CRF model for NER. They use CNN layer to learn character features of each word, LSTM"
S19-2229,D17-1035,0,0.0125367,"set, we will select the highest frequency id as the output. Otherwise, we will select the toponym with the most population as output. 3 Experiment 3.1 3.2 Experimental Settings We conduct experiments on science reports provided the SemEval-2019 task 12. The data set is composed of 72 full-text journal articles in open access. There are four different metrics to evaluate the prediction performance, i.e., strict macro F1, strict micro F1, overlap macro F1 and overlap micro F1. In the toponym detection task, we used NLTK1 for sentence segmentation, word tokenization and POS tagging. We used ELMo(Reimers and Gurevych, 2017) and BERT(Devlin et al., 2018) model to generate 1024-dimensional contextualized word embeddings. We used GeoNames2 1 2 https://www.nltk.org http://www.geonames.org to construct lexical feature. The BIO tagging scheme(Sang and Veenstra, 1999) was used in the toponym detection task. In the toponym disambiguation task, we use GeoNames database to retrieve candidate toponyms. In our approach, the three word embedding vectors we used (Glove(Pennington et al., 2014), word2vec(Mikolov et al., 2013), fasttext(Bojanowski et al., 2017)) were all 300dimensional. The dimension of the character embedding"
S19-2229,E99-1023,0,0.0721783,"Missing"
S19-2229,I17-4007,1,0.891925,"Missing"
W18-0913,P16-2017,0,0.745683,"805 110 Proceedings of the Workshop on Figurative Language Processing, pages 110–114 c New Orleans, Louisiana, June 6, 2018. 2018 Association for Computational Linguistics M M - - - CRF or softmax Inference Bi-LSTM CNN zeros POS tag Word Cluster zeros Word embedding Embedding That take him by surprise Lemmatizing That takes him by surprise Figure 1: The architecture of our method. The final metaphor labels will be predicted by a CRF or softmax inference layer. is presented in Figure 1. We will introduce the details of modules in our model from bottom to top. We follow the approach proposed by Klebanov et al. (2016) to use the lemmatizing strategy. The first module in our model is a lemmatizer. This module is used to lemmatize the verbs in texts via a dictionary. The input is a text with a sequence of word, and output is the text with lemmatized words. Since verbs with different forms can share the same lemmas, using the lemmatized verbs in texts can simplify the semantic information and reduce the number of out-of-vocabulary words. We use the NLTK package (Bird et al., 2009) to transform the verbs into their lemmas. nated them with the word embeddings. We use the Stanford parser2 tool to obtain the POS"
W18-0913,W13-0904,0,0.0693244,"Missing"
W18-0913,P14-1045,0,0.015891,"nd they will be fine-tuned during model training. POS tags are useful in metaphor detecting task (Klebanov et al., 2014). Therefore, we also incorporate the one-hot encoded POS tags as additional features into our neural model, and concates∈S where S is the training set, and hs and ys are the hidden states and label sequence of sentence s. 2 111 https://nlp.stanford.edu/software/lex-parser.shtml Softmax: We use a dense layer with softmax activation function to predict the metaphor label sequences. Motivated by the cost-sensitive crossentropy (Santos-Rodr´ıguez et al., 2009; Yang et al., 2014; Muller et al., 2014), the loss function of our model is formulated as follows: LSof tmax = − N XX wyi yi log(yˆi ), 2.0 and 1.0 respectively. The class number of word cluster is set 50. The batch size is 50, and the max training epoch is set to 15. The optimizer we use is RMSProp in our experiment. The performance of both all POS testing and verbs testing subtasks is evaluated by precision, recall and F-score as a standard binary classification task. 3.2 (4) s∈S i=1 We compare the performance of the variants of our model and several baseline methods. The methods to be compared include: 1) CNN+CRF, using CNN to ex"
W18-0913,P14-1024,0,0.386334,"Missing"
W18-0913,W15-1405,0,0.373885,"Missing"
W18-0913,D11-1063,0,0.66098,"Missing"
W18-0913,W13-0908,0,0.0756097,"Missing"
W18-0913,I17-4007,1,0.880841,"Missing"
W18-0913,W14-2302,0,0.674251,"gineering, Tsinghua University, Beijing 100084 2 Microsoft Research Asia {wuch15,ybch14,wu-sx15,yuanzg14,yfhuang}@mails.tsinghua.edu.cn wufangzhao@gmail.com Abstract Existing computational approaches to detect metaphors are mainly based on lexicons (Mohler et al., 2013; Dodge et al., 2015) and supervised methods (Turney et al., 2011; Heintz et al., 2013; Klebanov et al., 2014, 2015, 2016). Lexiconbased methods are free from data annotation, but they are unable to detect novel metaphorical usages and capture the contextual information. Supervised methods such as logistic regression classifier (Klebanov et al., 2014) can capture richer metaphor information. However, they need sophisticated hand-crafted features. To improve the collective techniques on detecting metaphors, the metaphor shared task1 aims to detect both metaphorical verbs and metaphors with other POS. Given a sentence and their words with specific POS tags, systems are required to determine whether each word is a metaphor. We propose a CNN-LSTM model with CRF or weighted softmax classifier to address this task. Our model can take advantage of both long-range and local information by utilizing both LSTM and CNN layers. We propose to use a wei"
W18-0913,W15-1402,0,0.144713,"Missing"
