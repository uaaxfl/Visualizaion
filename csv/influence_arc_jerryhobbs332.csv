A88-1032,C82-1015,1,0.913748,"Missing"
A88-1032,P85-1008,1,0.885125,"Missing"
A88-1032,H86-1003,1,0.646627,"Missing"
A88-1032,J82-3004,0,\N,Missing
A88-1032,P83-1009,1,\N,Missing
A92-1026,H89-2011,0,0.063241,"Missing"
A92-1026,C90-3029,1,0.796987,"Missing"
A92-1026,H91-1034,1,0.903685,"Missing"
A92-1026,H91-1066,0,0.0575465,"Missing"
A92-1026,P90-1031,0,0.0694495,"Missing"
A92-1026,H91-1036,0,0.224707,"Missing"
A92-1026,J83-1005,0,0.199487,"Missing"
A92-1026,H91-1037,0,\N,Missing
A92-1026,M91-1001,0,\N,Missing
C12-1079,W08-2222,0,0.0123274,"h that x = introduced: s x, y = 0. 3 Coreference Resolution in ILP-based Abductive Framework 3.1 Abduction for Discourse Processing Abductive reasoning can be used to recover implicit information from natural language texts. The implicit information includes semantic relations between discourse entities, anaphoric relations, character’s intentions, etc; see (Hobbs et al., 1993) for detailed examples. A logical form (LF) of a text represents observations, which need to be explained by background knowledge. In our discourse processing pipeline, a text is first input to the English parser Boxer (Bos, 2008). For each segment, the parse produced by Boxer is a first-order fragment of the DRS language used in Discourse Representation Theory (Kamp and Reyle, 1993). An add-on to Boxer converts the DRS into a logical form in the style of (Hobbs, 1985). The LF is a conjunction of propositions, which have generalized eventuality arguments that can be used for showing relationships among the propositions. According to (Hobbs, 1985), any predication in the logical notation has an extra argument, which refers to the “condition” of that predication being true. Thus, in the logical form J ohn(e1 , j) ∧ run(e"
C12-1079,W08-2208,0,0.0222857,"Missing"
C12-1079,P09-1068,0,0.0170892,"taset. In addition, we used a resource assigning possible lexical fillers disambiguated into WordNet synsets to FrameNet roles (Bryl et al., 2012). For example, the role THEME of the GIVING frame is mapped to synsets object#n#1 and thing#n#1. Given this information, the following axiom is generated. thing#n#1(s, x) → GIVING(e1 ) ∧ 3 THEME (e1 , x) http://www.wordfrequency.info/ 1300 Weights of these axioms are based on the scores provided by Bryl et al. (2012). We generated 24,571 axioms from the dataset. Narrative chains Similar to (Rahman and Ng, 2012), we employ narrative chains learned by Chambers and Jurafsky (2009), which were shown to have impact on resolving complex coreference; see (Rahman and Ng, 2012) for details. Narrative chains are partially ordered sets of events centered around a common protagonist that are likely to happen in a sequence. Knowledge about such sequences can facilitate coreference resolution. For example, given Max fell, because John pushed him we know that Max and him are coreferential, because we know that an object of the pushing event can be a subject of the falling event. For example, we generate the following axioms. Script#1(s, e1 , x 1 , u) → arrest(e1 , x 1 , x 2 , x 3"
C12-1079,W12-4502,0,0.0233481,"ally motivated constraints in order to prohibit incorrect unification in an abductive framework (Ovchinnikova et al., 2011; Ovchinnikova, 2012). However, the issue of overmerging was never systematically studied and the proposed solutions were never evaluated. In this paper, we investigate whether adding linguistically motivated features can help to block incorrect links in an inference-based framework. A lot of effort in NLP was put into coreference resolution systems ranging from rule-based (Lee et al., 2011, etc.) to machine learning-based resolvers (Soon et al., 2001; Ng and Cardie, 2002; Fernandes et al., 2012, etc.); see (Ng, 2010) for a detailed survey. Coreference resolution may require deep understanding of text, access to world knowledge, and inference ability. For example, (Levesque, 2011) considers twin sentences such as Ed shouted at Tim because he crashed the car and Ed shouted at Tim because he was angry. In order to resolve coreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference resolution systems including the winners of th"
C12-1079,P08-2012,0,0.0200756,"cate that proposition P has cost c and cost(P) to represent the cost of P. w The background knowledge B is a set of first-order logic formulas of the form P1 1 ∧ ... ∧ Pnw n → Q 1 ∧ ... ∧ Q m . All variables occurring in the antecedent of such axioms are universally quantified with the widest possible scope. Other variables are existentially quantified within the scope of the universal quantifiers. Propositions in the antecedents are assigned positive real-valued weights. We use the notation P w to indicate that proposition P has weight w. 1 There has been work on applying ILP to coreference (Finkel and Manning, 2008; Denis and Baldridge, 2009), but with no relationship with logical inference. 1293 The two main inference operations in weighted abduction are backward chaining and unification. Backward chaining is the introduction of new assumptions given an observation and background knowledge. For example, given O = ∃x(q(x)$10 ) and B = {∀x(p(x)1.2 → q(x))}, there are two candidate hypotheses: H1 = ∃x(q(x)$10 ) and H2 = ∃x(p(x)$12 ). In weighted abduction, a cost function f is used to calculate assumption costs. The function takes two arguments: costs of the propositions backchained on and weight of the a"
C12-1079,P85-1008,1,0.646074,"ormation includes semantic relations between discourse entities, anaphoric relations, character’s intentions, etc; see (Hobbs et al., 1993) for detailed examples. A logical form (LF) of a text represents observations, which need to be explained by background knowledge. In our discourse processing pipeline, a text is first input to the English parser Boxer (Bos, 2008). For each segment, the parse produced by Boxer is a first-order fragment of the DRS language used in Discourse Representation Theory (Kamp and Reyle, 1993). An add-on to Boxer converts the DRS into a logical form in the style of (Hobbs, 1985). The LF is a conjunction of propositions, which have generalized eventuality arguments that can be used for showing relationships among the propositions. According to (Hobbs, 1985), any predication in the logical notation has an extra argument, which refers to the “condition” of that predication being true. Thus, in the logical form J ohn(e1 , j) ∧ run(e2 , j) for the sentence John runs, e2 is a running event by John and e1 is a condition of j being named “John”. In the context of discourse processing, we call a hypothesis explaining a logical form an interpretation of this LF. The interpreta"
C12-1079,N06-2015,0,0.0321093,"canonical entities like people or places, registered in a knowledge base like DBpedia (Bizer et al., 2009) or YAGO (Suchanek et al., 2008). For example, mentions A. Einstein and Einstein will be both mapped to the YAGO node Albert_Einstein. An add-on to our pipeline assigns the same variables to each two named entities disambiguated by AIDA into the same YAGO node. 4 Evaluation We evaluate coreference resolution in our weighted abduction framework using the CoNLL2011 shared task dataset (Pradhan et al., 2011). The CoNLL-2011 dataset was based on the English portion of the OntoNotes 4.0 data (Hovy et al., 2006). OntoNotes is a corpus of large scale annotation of multiple levels of the shallow semantic structure in text. The OntoNotes coreference annotation captures general anaphoric coreference. Note that OntoNotes captures explicit coreference links only, while our procedure also discovers implicit semantic overlap. The CoNLL-2011 shared task was to automatically identify mentions of entities and events in text and to link the corefering mentions together to form entity/event chains. In our experiment, we do not identify mentions, but only compute precision and recall of the inferred coreference li"
C12-1079,N12-1015,0,0.0717548,"Missing"
C12-1079,W11-1913,0,0.0113036,"n order to resolve coreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference resolution systems including the winners of the CoNLL-2011 and CoNLL-2012 shared tasks (Lee et al., 2011; Fernandes et al., 2012) do not exploit any world knowledge. There exist attempts to resolve coreference based on world knowledge resources such as WordNet hierarchy, Wikipedia, semantic similarity, narravite chains (Ponzetto and Strube, 2006; Ng, 2007; Irwin et al., 2011; Rahman and Ng, 2012). Unfortunately, the corresponding resolvers were either not evaluated in large-scale challenges or did not show convincing performance in the challenges. Thus, the question remains open whether employing world knowledge can improve coreference resolution in large unfiltered corpora. In this paper, we investigate whether adding world knowledge for establishing more coreference links can 1292 improve coreference resolution. In the world knowledge employed, our work is most similar to the study on twin sentences presented in (Rahman and Ng, 2012). However, instead of using"
C12-1079,J94-4002,0,0.113926,"Missing"
C12-1079,W11-1902,0,0.0315203,"Missing"
C12-1079,D10-1123,0,0.0150906,"ually collected a set of 33 predicates indicating explicit nonidentity, e.g., similar to, different from. Presence of these predicates in a logical form indicates that their second and third arguments are unlikely to refer to the same entity. We create binary feature N I and compute its value as follows: If there is p(e, v1 , v2 ) and p is a predicate indicating explicit non-identity then N I(v1 , v2 ) = 1; otherwise N I(v1 , v2 ) = 0. Functional relations A binary relation r is functional if ∀x, y1 , y2 : r(x, y1 )∧ r(x, y2 ) → y1 = y2 . For example, a person can be a son of exactly one man. Lin et al. (2010) automatically learn functional relations from a corpus and assign a confidence score to each extracted relation. We use the set of functional relations generated by Lin et al. (2010) in order to generate feature F R. We extract 1,661 functional relations from the dataset. We create a binary feature F R and compute its value as follows: if (i) there are two predicates p(e1 , v1 , x 1 ), p(e2 , v2 , x 2 ), where p indicates a functional relation, (ii) x 1 6= x 2 , and (iii) v1 = v2 then F R(v1 , v2 ) = 1; otherwise F R(v1 , v2 ) = 0. Modality We assume that two predications having different mod"
C12-1079,H05-1004,0,0.0221705,"the CoNLL-2011 shared task, four metrics were used for evaluating coreference performance: MUC, B3 , CEAF, and BLANC. The evaluation metrics are described in (Pradhan et al., 2011). Each of the metric tries to address the shortcomings of the earlier metrics. MUC is the oldest metric; it has been criticized for not penalizing overmerging (Recasens and Hovy, 2010). Since one of the goals of this study is to reduce overmerging in our inference-based framework, this metric does not seem to be representative for us. The B3 and CEAF metrics were also considered to produce counterintuitive results (Luo, 2005; Recasens and Hovy, 2010). BLANC, as the most recent evaluation metric, overcomes the drawbacks of MUC, B3 , and CEAF. The definition formula of BLANC given in (Recasens and Hovy, 2010) is replicated in Table 2, where 1301 r c, wc, r n, wn indicate the number of right coreference links, wrong coreference links, right non-coreference links, and wrong non-coreference links correspondingly. Score Coreference rc P Pc = R Rc = F Fc = r c + wc rc r c + wn 2Pc R c Pc + R c Non-coreference rn Pn = r n + wn rn Rn = r n + wc 2Pn R n Fn = Pn + R n Metric Pc + Pn BLANC-P = BLANC-R = BLANC = 2 Rc + Rn 2 F"
C12-1079,N10-1069,0,0.0322037,"φ(H) are the sums of feature vectors for variable unification assumptions updates. φ(H) ˆ and H respectively. ∆(H, ˆ H) is a loss function that measures how different H ˆ and H are. in H ˆ and H are the larger an ensured margin is. In our experiments, we use The more different H ˆ H) = WO /TO , where TO is the total number of pairs of logical atomic the loss function ∆ P (H, terms in the observation and WO is the total number of variable unification assumptions for ˆ that disagrees with H. We implemented this training algorithm in a observed logical terms in H distributed learning framework (McDonald et al., 2010). 3.3 Features Each feature we use is defined for pairs of unifiable variables (v1 , v2 ). The features are summarized in Table 1. Incompatible properties If two entities have incompatible properties, they are unlikely to be identical. We use WordNet antonymy (black – white) and sibling relation (cat – dog) to derive incompatible properties. Moreover, we assume that two proper names not belonging to the same WordNet synset are unlikely to refer to the same entity. Correspondingly, we generate three binary features A, S, and P (see Table 1). 1297 Algorithm 1 Passive-Aggressive algorithm for par"
C12-1079,P10-1142,0,0.013933,"to prohibit incorrect unification in an abductive framework (Ovchinnikova et al., 2011; Ovchinnikova, 2012). However, the issue of overmerging was never systematically studied and the proposed solutions were never evaluated. In this paper, we investigate whether adding linguistically motivated features can help to block incorrect links in an inference-based framework. A lot of effort in NLP was put into coreference resolution systems ranging from rule-based (Lee et al., 2011, etc.) to machine learning-based resolvers (Soon et al., 2001; Ng and Cardie, 2002; Fernandes et al., 2012, etc.); see (Ng, 2010) for a detailed survey. Coreference resolution may require deep understanding of text, access to world knowledge, and inference ability. For example, (Levesque, 2011) considers twin sentences such as Ed shouted at Tim because he crashed the car and Ed shouted at Tim because he was angry. In order to resolve coreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference resolution systems including the winners of the CoNLL-2011 and CoNLL-"
C12-1079,P02-1014,0,0.0772542,"pts to use linguistically motivated constraints in order to prohibit incorrect unification in an abductive framework (Ovchinnikova et al., 2011; Ovchinnikova, 2012). However, the issue of overmerging was never systematically studied and the proposed solutions were never evaluated. In this paper, we investigate whether adding linguistically motivated features can help to block incorrect links in an inference-based framework. A lot of effort in NLP was put into coreference resolution systems ranging from rule-based (Lee et al., 2011, etc.) to machine learning-based resolvers (Soon et al., 2001; Ng and Cardie, 2002; Fernandes et al., 2012, etc.); see (Ng, 2010) for a detailed survey. Coreference resolution may require deep understanding of text, access to world knowledge, and inference ability. For example, (Levesque, 2011) considers twin sentences such as Ed shouted at Tim because he crashed the car and Ed shouted at Tim because he was angry. In order to resolve coreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference resolution systems inc"
C12-1079,W11-0124,1,0.904163,"age understanding the more general principle that we understand our environment by coming up with the best explanation for the observables in the environment. Hobbs et al. (1993) show that the lowest-cost abductive proof provides the solution to a whole range of natural language pragmatics problems, such as word sense disambiguation, anaphora and metonymy resolution, interpretation of noun compounds and prepositional phrases and detection of discourse relations. For examples of the application of weighted abduction to discourse processing see (Charniak and Goldman, 1991; Inoue and Inui, 2011; Ovchinnikova et al., 2011; Ovchinnikova, 2012). If weighted abduction is applied to discourse processing, coreference links naturally follow as a by-product of constructing best explanations. In weighted abduction, coreference resolution is equal to unification of predications; see Sec. 3.1. Similarly, if deductive model building is applied to discourse interpretation, coreference links result from the model minimality. Both inference approaches are based on the idea that predications having the same predicates describe the same situation and therefore their arguments can be assumed to be equal if no logical contradic"
C12-1079,N06-1025,0,0.0322134,"houted at Tim because he was angry. In order to resolve coreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference resolution systems including the winners of the CoNLL-2011 and CoNLL-2012 shared tasks (Lee et al., 2011; Fernandes et al., 2012) do not exploit any world knowledge. There exist attempts to resolve coreference based on world knowledge resources such as WordNet hierarchy, Wikipedia, semantic similarity, narravite chains (Ponzetto and Strube, 2006; Ng, 2007; Irwin et al., 2011; Rahman and Ng, 2012). Unfortunately, the corresponding resolvers were either not evaluated in large-scale challenges or did not show convincing performance in the challenges. Thus, the question remains open whether employing world knowledge can improve coreference resolution in large unfiltered corpora. In this paper, we investigate whether adding world knowledge for establishing more coreference links can 1292 improve coreference resolution. In the world knowledge employed, our work is most similar to the study on twin sentences presented in (Rahman and Ng, 201"
C12-1079,D08-1068,0,0.0285617,"prove coreference resolution in large unfiltered corpora. In this paper, we investigate whether adding world knowledge for establishing more coreference links can 1292 improve coreference resolution. In the world knowledge employed, our work is most similar to the study on twin sentences presented in (Rahman and Ng, 2012). However, instead of using world knowledge for generating features in a machine learning framework, we explore inference-based discourse processing. Regarding inference, our method may seem related to the coreference resolution research based on Markov Logic Networks (MLNs) (Poon and Domingos, 2008; Song et al., 2012). However, previous MLN-based work on coreference resolution does not incorporate inference rules based on world knowledge. The key contributions of our work are the following. First, we propose a novel solution to the overmerging problem in an inference-based framework. We extend (Hobbs et al., 1993)’s weighted abduction in order to accommodate unification weights and show how to learn the weights by applying machine learning techniques. For making large-scale processing and parameter learning in an abductive logic framework feasible, we employ a new efficient implementati"
C12-1079,W11-1901,0,0.0304668,"Missing"
C12-1079,D12-1071,0,0.0772712,"oreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference resolution systems including the winners of the CoNLL-2011 and CoNLL-2012 shared tasks (Lee et al., 2011; Fernandes et al., 2012) do not exploit any world knowledge. There exist attempts to resolve coreference based on world knowledge resources such as WordNet hierarchy, Wikipedia, semantic similarity, narravite chains (Ponzetto and Strube, 2006; Ng, 2007; Irwin et al., 2011; Rahman and Ng, 2012). Unfortunately, the corresponding resolvers were either not evaluated in large-scale challenges or did not show convincing performance in the challenges. Thus, the question remains open whether employing world knowledge can improve coreference resolution in large unfiltered corpora. In this paper, we investigate whether adding world knowledge for establishing more coreference links can 1292 improve coreference resolution. In the world knowledge employed, our work is most similar to the study on twin sentences presented in (Rahman and Ng, 2012). However, instead of using world knowledge for ge"
C12-1079,D07-1002,0,0.141474,"Missing"
C12-1079,D12-1114,0,0.0143829,"ion in large unfiltered corpora. In this paper, we investigate whether adding world knowledge for establishing more coreference links can 1292 improve coreference resolution. In the world knowledge employed, our work is most similar to the study on twin sentences presented in (Rahman and Ng, 2012). However, instead of using world knowledge for generating features in a machine learning framework, we explore inference-based discourse processing. Regarding inference, our method may seem related to the coreference resolution research based on Markov Logic Networks (MLNs) (Poon and Domingos, 2008; Song et al., 2012). However, previous MLN-based work on coreference resolution does not incorporate inference rules based on world knowledge. The key contributions of our work are the following. First, we propose a novel solution to the overmerging problem in an inference-based framework. We extend (Hobbs et al., 1993)’s weighted abduction in order to accommodate unification weights and show how to learn the weights by applying machine learning techniques. For making large-scale processing and parameter learning in an abductive logic framework feasible, we employ a new efficient implementation of weighted abduc"
C12-1079,J01-4004,0,0.0947431,"rt, 2011) and attempts to use linguistically motivated constraints in order to prohibit incorrect unification in an abductive framework (Ovchinnikova et al., 2011; Ovchinnikova, 2012). However, the issue of overmerging was never systematically studied and the proposed solutions were never evaluated. In this paper, we investigate whether adding linguistically motivated features can help to block incorrect links in an inference-based framework. A lot of effort in NLP was put into coreference resolution systems ranging from rule-based (Lee et al., 2011, etc.) to machine learning-based resolvers (Soon et al., 2001; Ng and Cardie, 2002; Fernandes et al., 2012, etc.); see (Ng, 2010) for a detailed survey. Coreference resolution may require deep understanding of text, access to world knowledge, and inference ability. For example, (Levesque, 2011) considers twin sentences such as Ed shouted at Tim because he crashed the car and Ed shouted at Tim because he was angry. In order to resolve coreference in these sentences one requires world knowledge about people shouting when being angry and people shouting at someone who made a mistake, e.g., crashed a car. Surprisingly, most of the contemporary coreference r"
C82-1015,P81-1028,1,0.764824,"Missing"
C82-1015,P82-1001,1,0.832758,"Missing"
C82-1020,C82-1015,1,0.805012,"Missing"
C82-1020,C82-1065,1,0.817714,"r i a l , The s y s t e m i s t o p r o v i d e a c c e s s t o a t e x t b o o k o r o t h e r document of some i m p o r t a n c e , by r e t u r n i n g r e l e v a n t p a s s a g e s i n r e s p o n s e t o a u s e r &apos; s natural language request. C u r r e n t l y we a r e u s i n g t h e H e p a t i t i s Knowledge Base, a compendium of c u r r e n t knowledge about h e p a t i t i s c ompi l e d by t h e N a t i o n a l L i b r a r y o f M e d i c i n e , a l t h o u g h t h e t e c h n i q u e s we a r e d e v i s i n g a r e i n no way p a r t i c u l a r t o t h i s document [ c f . Walker, 1982]. The p r o j e c t ha s two p h a s e s . In t he f i r s t , we are developing text access procedures for translating a user&apos;s r e q u e s t i n t o an u n d e r l y i n g l o g i c a l form and, i n o r d e r t o l o c a t e t h e a p p r o p r i a t e p a s s a g e s , m a t c h i n g the logical form w i t h a Text S t r u c t u r e which e x p r e s s e s t h e s t r u c t u r e of t h e document as a whole and summarizes t h e c o n t e n t of i n d i v i d u a l p a s s a g e s i n t e rms of c a n o n i c a l p r e d i c a t e s (Walker and Hobbs, 1981]. In t h e s e c o n d , l o n"
C82-1020,J80-1002,0,\N,Missing
C90-3028,E89-1037,0,0.11543,"Missing"
C90-3028,P83-1021,0,0.0503361,"Missing"
C90-3028,C88-2128,0,0.0360088,"Missing"
C90-3028,P88-1011,0,0.060991,"Missing"
C90-3028,P88-1012,1,0.886945,"Missing"
C90-3029,A88-1032,1,0.893808,"Missing"
C90-3029,P90-1003,1,0.861395,"Missing"
C90-3029,P88-1012,1,0.840066,"Missing"
C90-3029,P84-1054,0,0.469566,"Missing"
C90-3029,P83-1017,0,0.120404,"Missing"
C90-3029,C82-1015,1,\N,Missing
C90-3029,P90-1004,0,\N,Missing
C90-3029,A88-1000,0,\N,Missing
H86-1003,P86-1035,1,0.800345,"well as the domains of scalar notions, time, measure, orientation, shape, and functionality. Then to test the adequacy of these theories, we began working from the outside in again, spending some time defining, or characterizing, the words related to these domains that occurred in our target set of casreps. We are now working from the inside out again, going over the core theories and the definitions with a fine-tooth comb, checking manually for consistency and adequacy and proving simple consequences of the axioms on the KADS theorem-prover. This work is described in an enclosed publication [1]. 20 4 Domain Knowledge In all of our work we are seeking general solutions that can be used in a wide variety of applications. This may seem impossible for domain knowledge. In our particular case, we must express facts about the starting air compressor of a ship. It would appear difficult to employ this knowledge in any other application. However, our approach makes most of our work even in this area relevant to many other domains. We are specifying a number of ""abstract machines"" or ""abstract systems"", in levels, of which the particular device we must model is an instantiation. We define, f"
H86-1003,H86-1013,1,\N,Missing
H86-1013,P85-1008,1,\N,Missing
H90-1012,P88-1012,1,0.876613,"Missing"
H91-1024,P88-1011,0,0.0688054,"Missing"
H91-1024,P88-1012,1,0.896734,"Missing"
H91-1024,C88-2128,0,0.0525989,"Missing"
H91-1100,P88-1012,1,0.755996,"Missing"
H93-1026,M92-1001,0,\N,Missing
H94-1032,M92-1001,0,\N,Missing
J11-4005,P10-1143,0,0.0553601,"r conditions fairly reliably persist between three hours and one day. We are often able to decide whether two events overlap or are in sequence by accessing this information. We know that if a war started yesterday, we can be pretty sure it is still going on today. If a hurricane started last year, we can be sure it is over by now. This article describes an exploration into how this information can be captured automatically. Our results can have a signiﬁcant impact on computational linguistics applications like event anchoring and ordering in text (Mani and Schiffman 2007), event coreference (Bejan and Harabagiu 2010), question answering (Tao et al. 2010; Harabagiu and Bejan 2005), and other intelligent systems that would beneﬁt from such temporal commonsense knowledge, for example, temporal reasoning (Zhou and Hripcsak 2007). Our goal is to be able to extract this implicit event duration information from text automatically, and to that end we ﬁrst annotated the events in news articles with bounds on their durations. The corpus that we have annotated currently contains all 48 non-Wall-Street-Journal (non-WSJ) news articles (2,132 event instances), as well as 10 WSJ articles (156 event instances), from the"
J11-4005,H92-1022,0,0.040481,"Missing"
J11-4005,J96-2004,0,0.0452596,"ce to make the conjecture until the time the conjecture is refuted or conﬁrmed. Positive Inﬁnite Durations: These are states which continue essentially forever once they begin, for example, He is dead. Here the state continues for an inﬁnite amount of time, and we allow this as a possible annotation. 3. Inter-Annotator Agreement Although the graphical output of the annotations enables us to visualize quickly the level of agreement among different annotators for each event, a quantitative measurement of the agreement is needed. The kappa statistic (Krippendorff 1980; Siegel and Castellan 1988; Carletta 1996; Di Eugenio and Glass 2004), which factors out the agreement that is expected by chance, has become the de facto standard to assess inter-annotator agreement. It is computed as follows: κ= P(A) − P(E) 1 − P(E) (1) 733 Computational Linguistics Volume 37, Number 4 P(A) is the observed agreement among the annotators, and P(E) is the expected agreement, which is the probability that the annotators agree by chance. In order to compute the kappa statistic for our task, we have to compute P(A) and P(E) ﬁrst. But those computations are not straightforward. P(A): What should count as agreement among"
J11-4005,W01-1313,0,0.0340522,"mputational Linguistics Computational Linguistics Volume 37, Number 4 Sometimes we are explicitly told the duration of events, as in “a ﬁve-day meeting” and “I have lived here for three years.” But more often, such phrases are missing, and present-day natural language applications simply have to proceed without them. There has been a great deal of work on formalizing temporal information (Allen 1984; Moens and Steedman 1988; Zhou and Fikes 2002; Han and Lavie 2004; Hobbs and Pan 2004) and on temporal anchoring and event ordering in text (Hitzeman, Moens, and Grover 1995; Mani and Wilson 2000; Filatova and Hovy 2001; Boguraev and Ando 2005; Mani et al. 2006; Lapata and Lascarides 2006). The uncertainty of temporal durations has been recognized as one of the most signiﬁcant issues for temporal reasoning (Allen and Ferguson 1994). Chittaro and Montanari (2000) point out by way of example that we have to know how long a battery remains charged to decide when to replace it or to predict the effects of actions which refer to the battery charge as a precondition. Yet to our knowledge, there has been no serious published empirical effort to model and learn the vague and implicit duration information in natural"
J11-4005,J02-3001,0,0.0536476,"Missing"
J11-4005,P97-1062,0,0.13909,"Missing"
J11-4005,P06-1095,0,0.200529,"r 4 Sometimes we are explicitly told the duration of events, as in “a ﬁve-day meeting” and “I have lived here for three years.” But more often, such phrases are missing, and present-day natural language applications simply have to proceed without them. There has been a great deal of work on formalizing temporal information (Allen 1984; Moens and Steedman 1988; Zhou and Fikes 2002; Han and Lavie 2004; Hobbs and Pan 2004) and on temporal anchoring and event ordering in text (Hitzeman, Moens, and Grover 1995; Mani and Wilson 2000; Filatova and Hovy 2001; Boguraev and Ando 2005; Mani et al. 2006; Lapata and Lascarides 2006). The uncertainty of temporal durations has been recognized as one of the most signiﬁcant issues for temporal reasoning (Allen and Ferguson 1994). Chittaro and Montanari (2000) point out by way of example that we have to know how long a battery remains charged to decide when to replace it or to predict the effects of actions which refer to the battery charge as a precondition. Yet to our knowledge, there has been no serious published empirical effort to model and learn the vague and implicit duration information in natural language, and to perform reasoning over this information. Cyc has some"
J11-4005,P00-1010,0,0.0599605,"011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 4 Sometimes we are explicitly told the duration of events, as in “a ﬁve-day meeting” and “I have lived here for three years.” But more often, such phrases are missing, and present-day natural language applications simply have to proceed without them. There has been a great deal of work on formalizing temporal information (Allen 1984; Moens and Steedman 1988; Zhou and Fikes 2002; Han and Lavie 2004; Hobbs and Pan 2004) and on temporal anchoring and event ordering in text (Hitzeman, Moens, and Grover 1995; Mani and Wilson 2000; Filatova and Hovy 2001; Boguraev and Ando 2005; Mani et al. 2006; Lapata and Lascarides 2006). The uncertainty of temporal durations has been recognized as one of the most signiﬁcant issues for temporal reasoning (Allen and Ferguson 1994). Chittaro and Montanari (2000) point out by way of example that we have to know how long a battery remains charged to decide when to replace it or to predict the effects of actions which refer to the battery charge as a precondition. Yet to our knowledge, there has been no serious published empirical effort to model and learn the vague and implicit duration"
J11-4005,J88-2003,0,0.958221,"Missing"
J11-4005,J88-2005,0,0.455562,"ve the same durations for the “demonstration” and “chanted” events. 2.2 Analysis When the articles were completely annotated by the three annotators, the results were analyzed and the differences were reconciled. Differences in annotation could be due to the differences in interpretations of the event; we found that the vast majority of radically different judgments could be categorized into a relatively small number of classes, however. Some of these correspond to aspectual features of events, which have been investigated intensively (e.g., Vendler 1967; Dowty, 1979; Moens and Steedman 1988; Passonneau 1988; Giorgi and Pianesi 1997; Madden and Zwaan 2003; Smith 2005). We then developed guidelines to make annotators aware of these cases and to guide them in making the judgments (see the next section). There is a residual of gross discrepancies in annotators’ judgments that result from differences of opinion, for example, about how long a government policy is typically in effect. But the number of these discrepancies was surprisingly small. These guidelines were then used in the annotation of a test set. It was shown that the agreement in the test set was greater than the agreement obtained when a"
J11-4005,E95-1035,0,\N,Missing
J13-4001,W08-2222,0,0.0364343,"l plays a role; the predicate computer-terminal doesn’t. All of this raises a question. If the framework is so elegant and so all-encompassing, why isn’t it more widely adopted? I think there are three reasons for this, historically. 1. Parsers were not accurate enough to produce good logical forms from which inference could start. 2. Algorithms for abduction were too inefficient. 3. There was a lack of an adequate knowledge base. Each of these problems has been alleviated somewhat in the past few years. There are now highly accurate statistical parsers, and for several of these (e.g., Boxer; Bos 2008) a component for translating into a flat logical form has been implemented. Recent work by Naoya Inoue and Kentaro Inui (2011) implements weighted abduction as a problem in integer linear programming, building on earlier work by Charniak and Santos (Santos 1996). Our experience with this is that when we switched from a naive backchaining implementation to the ILP implementation, we got a speed-up of two orders of magnitude. Finally, there have been ongoing efforts to build large knowledge bases, manually and automatically, from a number of different perspectives. Efforts to use Cyc for natural"
J13-4001,P88-1011,0,0.551011,"ary problems like pronoun coreference, one had to make assumptions to get a good interpretation of the text, where the only justification for the assumptions was that they led to a good interpretation. In the fall of 1987 at SRI we organized a discussion group on abduction, reading the classic papers by Peirce, recent attempts in AI to use abduction in, for example, medical diagnosis (Pople 1973; Cox and Pietrzykowski 1986), and contemporary philosophers like Paul Thagard (1978), as well as work by Wilensky and Norvig at Berkeley (Wilensky 1983; Norvig 1987) and Charniak and Goldman at Brown (Charniak and Goldman 1988) that seemed to be taking an approach similar to ours. Among the people in our group were Mark Stickel, Doug Edwards, and the pragmatics scholar Steve Levinson, who was visiting Stanford at the time. We argued about what we were calling identity implicatures and referential implicatures, and about how to distinguish new from given information in discourse, and how to choose the best interpretation of a text. Then late one afternoon in October 1987 Mark Stickel came into my office to say that he thought he had the answer to all our problems. He described his algorithm for weighted abduction. It"
J13-4001,W11-0121,1,0.925574,"-sponsored MOVER project provided the opportunity to develop an ontology of event structure called VERL (Video Event Representation Language, Alexandre et al. 2005), and this led to work with Chris Welty, Mike Gruninger, and people at Cycorp on the ARDAsponsored IKRIS project for developing an interlingua among several event and process ontologies. DARPA’s Machine Reading Program supported my student Rutu MulkarMehta’s work on granular or “how-to” causality (Mulkar-Mehta, Hobbs, and Hovy 2011) and Niloofar Montazeri’s work defining or characterizing several hundred common event-related words (Montazeri and Hobbs 2011). My work with Andrew Gordon on encoding common-sense psychology (Gordon and Hobbs 2004) has been funded by various agencies over the years, most recently by ONR. But some of the research has been “stealth” research—work you don’t tell anyone about until it’s finished for fear your boss will find out and make you work on other stuff. My papers on causality and modality (Hobbs 2005) and on scales and half orders of magnitude (Hobbs 2000) were like this. The goal is to develop what I have come to call “Deep Lexical Semantics” (Hobbs 2008). It is not enough to decompose “move” into “cause - chang"
J13-4001,J11-4005,1,0.891327,"Missing"
J86-3006,P86-1035,1,0.827048,"Missing"
J87-1005,P81-1028,0,\N,Missing
J87-1005,P83-1009,1,\N,Missing
J87-3004,P85-1008,1,\N,Missing
M92-1019,M91-1030,1,0.796674,"Missing"
M92-1036,M91-1033,0,0.0582728,"Missing"
M92-1036,H90-1005,0,\N,Missing
M95-1019,M93-1019,1,0.808663,"s are in som e sense prerequisites to the fourth, we will focus our attention in this paper on the scenario templat e task . BASIC FASTUS The SRI FASTUS system is based on a series of finite-state transducers that compute the transfor mation of text from sequences of characters to domain templates . This architecture has proven t o be very flexible, and has been applied with success to a number of different information extractio n tasks in widely varying domains . We have applied FASTUS to extraction of information about ter rorist incidents [3], extraction of information about joint ventures [2], indexing of legal document s for hypertext, extracting extensive information from military texts (Warbreaker Message Handler) , extraction of information from spoken dialogues [4], and a number of other smaller systems an d pilot applications . We have applied FASTUS to Japanese texts [2, 4] as well as English . Each transducer (or ""phase"") in the series takes the output of the previous phase and map s it into structures that comprise the input to the next phase, or that contain the domain templat e 237 information that is the output of the extraction process . It is possible to vary the num"
P06-1050,H92-1022,0,0.0086467,"y lasts for seconds or minutes, depending on the length of the quoted content. However, there are also cases where quotation marks are used for other purposes, such as emphasis of quoted words and titles of artistic works. For each token in the local context, including the event itself, three features are included: the original form of the token, its lemma (or root form), and its part-of-speech (POS) tag. The lemma of the token is extracted from parse trees generated by the CONTEX parser (Hermjakob and Mooney, 1997) which includes rich context information in parse trees, and the Brill tagger (Brill, 1992) is used for POS tagging. The context window doesn’t cross the boundaries of sentences. When there are not enough tokens on either side of the event within the window, “NULL” is used for the feature values. The local context features extracted for the “signed” event in sentence (1) is shown in Table 1 (with a window size n = 2). The feature vector is [signed, sign, VBD, the, the, DT, plan, plan, NN, Friday, Friday, NNP, on, on, IN]. (1) The two presidents on Friday signed the plan. 3.2 Syntactic Relations The information in the event’s syntactic environment is very important in deciding the du"
P06-1050,J96-2004,0,0.0128864,"generally available; Rieger (1974) discusses the issue for less than a page; there has been work in fuzzy logic on representing and reasoning with imprecise durations (Godo and Vila, 1995; Fortemps, 1997), but these make no attempt to collect human judgments on such durations or learn to extract them automatically from texts.) 2 Inter-Annotator Agreement Although the graphical output of the annotations enables us to visualize quickly the level of agreement among different annotators for each event, a quantitative measurement of the agreement is needed. The kappa statistic (Krippendorff, 1980; Carletta, 1996) has become the de facto standard to assess inter-annotator agreement. It is computed as: κ= P( A) − P( E ) 1 − P( E ) P(A) is the observed agreement among the annotators, and P(E) is the expected agreement, which is the probability that the annotators agree by chance. In order to compute the kappa statistic for our task, we have to compute P(A) and P(E), but those computations are not straightforward. P(A): What should count as agreement among annotators for our task? P(E): What is the probability that the annotators agree by chance for our task? 2.1 What Should Count as Agreement? Determinin"
P06-1050,W01-1313,0,0.563531,"Missing"
P06-1050,J02-3001,0,0.0208118,"). The direct hypernyms of nouns are always not general enough for such purpose, but a hypernym at too high a level can be too general to be useful. For our learning experiments, we extract the first 3 levels of hypernyms from WordNet. Hypernyms are only extracted for the events and their subjects and objects, not for the local context words. For each level of hypernyms in the hierarchy, it’s possible to have more than one hypernym, for example, “see” has two direct hypernyms, “perceive” and “comprehend”. For a given word, it may also have more than one sense in WordNet. In such cases, as in (Gildea and Jurafsky, 2002), we only take the first sense of the word and the first hypernym listed for each level of the hierarchy. A word disambiguation module might improve the learning performance. But since the features we need are the hypernyms, not the word sense itself, even if the first word sense is not the correct one, its hypernyms can still be good enough in many cases. For example, in one news article, the word “controller” refers to an air traffic controller, which corresponds to the second sense in WordNet, but its first sense (business controller) has the same hypernym of “person” (3 levels up) as the s"
P06-1050,P97-1062,0,0.0914719,"quotation mark is a good indication of quoted reporting events, and the duration of such events most likely lasts for seconds or minutes, depending on the length of the quoted content. However, there are also cases where quotation marks are used for other purposes, such as emphasis of quoted words and titles of artistic works. For each token in the local context, including the event itself, three features are included: the original form of the token, its lemma (or root form), and its part-of-speech (POS) tag. The lemma of the token is extracted from parse trees generated by the CONTEX parser (Hermjakob and Mooney, 1997) which includes rich context information in parse trees, and the Brill tagger (Brill, 1992) is used for POS tagging. The context window doesn’t cross the boundaries of sentences. When there are not enough tokens on either side of the event within the window, “NULL” is used for the feature values. The local context features extracted for the “signed” event in sentence (1) is shown in Table 1 (with a window size n = 2). The feature vector is [signed, sign, VBD, the, the, DT, plan, plan, NN, Friday, Friday, NNP, on, on, IN]. (1) The two presidents on Friday signed the plan. 3.2 Syntactic Relation"
P06-1050,P00-1010,0,0.453688,"Missing"
P06-1050,pan-etal-2006-annotated,1,0.916951,"the natural logarithmic scale and the vertical axis represents the number of annotated durations with that width. Note that it peaks at about a half order of magnitude (Hobbs and Kreinovich, 2001). Since the global distribution is determined by the above mean and width distributions, we can then compute the expected agreement, i.e., the probability that the annotators agree by chance, where the chance is actually based on this global distribution. Two different methods were used to compute the expected agreement (baseline), both yielding nearly equal results. These are described in detail in (Pan et al., 2006). For both, P(E) is about 0.15. 395 400 Features Original Lemma POS Event signed sign VBD 1token-after the the DT 2token-after plan plan NN 1token-before Friday Friday NNP 2token-before on on IN Table 1: Local context features for the “signed” event in sentence (1) with n = 2. 350 Number of Annotated Durations 300 250 200 150 100 50 0 -5 0 5 10 15 20 25 Widths of Annotated Durations Figure 3: Distribution of Widths of Annotated Durations. 3 Features In this section, we describe the lexical, syntactic, and semantic features that we considered in learning event durations. 3.1 Local Context For a"
P06-1050,E95-1035,0,\N,Missing
P84-1059,C82-1015,1,\N,Missing
P84-1059,P85-1008,1,\N,Missing
P85-1008,P83-1009,1,\N,Missing
P86-1035,P85-1008,1,0.883489,"Missing"
P88-1012,T75-2034,0,0.228354,"Missing"
P88-1012,P88-1010,0,0.0238839,"Missing"
P88-1012,P83-1021,0,0.130337,"Missing"
P88-1012,P83-1009,1,0.659674,"Missing"
P88-1012,P85-1008,1,0.302169,"Missing"
P88-1012,H86-1003,1,0.746614,"Missing"
P88-1012,P86-1035,1,0.725102,"Missing"
P88-1012,J80-1002,0,\N,Missing
P88-1012,A88-1032,1,\N,Missing
P88-1012,H86-1013,1,\N,Missing
P88-1012,P88-1011,0,\N,Missing
P88-1012,J87-3004,1,\N,Missing
P97-1051,E93-1025,1,0.923385,"w seyeral problematic examples are accounted for in a natural and straightforward fashion. The generality of the approach makes it directly applicable to a variety of other types of ellipsis and reference. 1 The Problem of VP (3) John revised John&apos;s paper before the teacher revised John&apos;s paper, and Bill revised John&apos;s paper before the teacher revised Bill&apos;s paper. Ellipsis VP ellipsis has received a great deal of attention in theoretical and computational linguistics (Asher, 1993; Crouch, 1995; Dalrymple, Shieber, and Pereira, 1991; Fiengo and May, 1994; Gawron and Peters, 1990; Hardt, 1992; Kehler, 1993; Lappin and McCord, 1990; Priist, 1992; Sag, 1976; Webbet, 1978; Williams, 1977, inter alia). The area is a tangled thicket of examples in which readings are mysteriously missing and small changes reverse judgments. It is a prime example of a phenomenon at the boundary between syntax and pragmatics. VP ellipsis is exemplified in sentence (1). (1) John revised his paper before the teacher did. This sentence has two readings, one in which the teacher revised John&apos;s paper (the strict reading), and one in which the teacher revised his own paper (the sloppy reading). Obtaining an adequate account"
P97-1051,E95-1032,0,0.48457,"scourse, and apply it to the special case of resolving possible readings for instances of VP ellipsis. We show how seyeral problematic examples are accounted for in a natural and straightforward fashion. The generality of the approach makes it directly applicable to a variety of other types of ellipsis and reference. 1 The Problem of VP (3) John revised John&apos;s paper before the teacher revised John&apos;s paper, and Bill revised John&apos;s paper before the teacher revised Bill&apos;s paper. Ellipsis VP ellipsis has received a great deal of attention in theoretical and computational linguistics (Asher, 1993; Crouch, 1995; Dalrymple, Shieber, and Pereira, 1991; Fiengo and May, 1994; Gawron and Peters, 1990; Hardt, 1992; Kehler, 1993; Lappin and McCord, 1990; Priist, 1992; Sag, 1976; Webbet, 1978; Williams, 1977, inter alia). The area is a tangled thicket of examples in which readings are mysteriously missing and small changes reverse judgments. It is a prime example of a phenomenon at the boundary between syntax and pragmatics. VP ellipsis is exemplified in sentence (1). (1) John revised his paper before the teacher did. This sentence has two readings, one in which the teacher revised John&apos;s paper (the strict"
P97-1051,J90-4001,0,0.048944,"lematic examples are accounted for in a natural and straightforward fashion. The generality of the approach makes it directly applicable to a variety of other types of ellipsis and reference. 1 The Problem of VP (3) John revised John&apos;s paper before the teacher revised John&apos;s paper, and Bill revised John&apos;s paper before the teacher revised Bill&apos;s paper. Ellipsis VP ellipsis has received a great deal of attention in theoretical and computational linguistics (Asher, 1993; Crouch, 1995; Dalrymple, Shieber, and Pereira, 1991; Fiengo and May, 1994; Gawron and Peters, 1990; Hardt, 1992; Kehler, 1993; Lappin and McCord, 1990; Priist, 1992; Sag, 1976; Webbet, 1978; Williams, 1977, inter alia). The area is a tangled thicket of examples in which readings are mysteriously missing and small changes reverse judgments. It is a prime example of a phenomenon at the boundary between syntax and pragmatics. VP ellipsis is exemplified in sentence (1). (1) John revised his paper before the teacher did. This sentence has two readings, one in which the teacher revised John&apos;s paper (the strict reading), and one in which the teacher revised his own paper (the sloppy reading). Obtaining an adequate account of strict/sloppy ambiguit"
P97-1051,C88-2120,0,0.0960283,"Missing"
P97-1051,C92-1048,0,\N,Missing
pan-etal-2006-annotated,J88-2003,0,\N,Missing
pan-etal-2006-annotated,P00-1010,0,\N,Missing
pan-etal-2006-annotated,W01-1313,0,\N,Missing
pan-etal-2006-annotated,J88-2005,0,\N,Missing
pan-etal-2006-annotated,J96-2004,0,\N,Missing
T87-1006,P85-1037,0,0.110264,"Missing"
T87-1006,P86-1035,1,0.886289,"Missing"
T87-1006,H86-1013,1,\N,Missing
W06-0906,J88-2003,0,0.414382,"ea. But in fact we do have an idea. We know the meeting was longer than 10 seconds and less than a year. How much tighter can we get the 38 Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 38–45, c Sydney, July 2006. 2006 Association for Computational Linguistics interpretations of the event; however, we found that the vast majority of radically different judgments can be categorized into a relatively small number of classes. Some of these correspond to aspectual features of events, which have been intensively investigated (e.g., Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Passonneau, 1988). We then developed guidelines to cover those cases (see the next section). study, and the machine learning results. TimeML and its event classes will be described in Section 3, and we will discuss how to integrate event duration annotations into TimeML in Section 4. 2 Annotating and Learning Typical Duration of Events In the corpus of typical durations of events, every event to be annotated was already identified in the TimeBank corpus. Annotators are asked to provide lower and upper bounds on the duration of the event, and a judgment of level of confidence in those estimat"
W06-0906,pan-etal-2006-annotated,1,0.710007,"ptions of events and relying on our knowledge of the range of usual durations of types of events, which can be very important in applications in which the time course of events is to be extracted from news. For example, whether two events overlap or are in sequence often depends very much on their durations. If a war started yesterday, we can be pretty sure it is still going on today. If a hurricane started last year, we can be sure it is over by now. To extract such implicit event duration information from texts automatically, we developed a corpus annotated with typical durations of events (Pan et al., 2006a) which currently contains all the 48 non-Wall-Street-Journal (non-WSJ) news articles (a total of 2132 event instances), as well as 10 WSJ articles (156 event instances), from the TimeBank corpus annotated in TimeML (Pustejovky et al., 2003). Because the annotated corpus is still fairly small, we cannot hope to learn to make finegrained judgments of event durations that are currently annotated in the corpus, but as we show in greater detail in (Pan et al., 2006b), it is possible to learn useful coarse-grained judgments that considerably outperform a baseline and approach human performance. Th"
W06-0906,J96-2004,0,0.0388096,"“said” event should be short. In the second sentence everything that the spokesperson (here the police) has said is compiled into a single sentence by the reporter, and it is unlikely that the spokesperson said only a single sentence with all this information. Thus, it is reasonable to give longer duration to this “said” event. Inter-Annotator Agreement Although the graphical output of the annotations enables us to visualize quickly the level of agreement among different annotators for each event, a quantitative measurement of the agreement is needed. The kappa statistic (Krippendorff, 1980; Carletta, 1996) has become the de facto standard to assess inter-annotator agreement. It is computed as: κ= Multiple Events: Many occurrences of verbs and other event descriptors refer to multiple events, especially, but not exclusively, if the subject or object of the verb is plural. For example, P ( A) − P( E ) 1 − P( E ) P(A) is the observed agreement among the annotators, and P(E) is the expected agreement, 40 180 160 Number of Annotated Durations 140 120 100 80 60 40 20 Figure 1: Overlap of Judgments of [10 minutes, 30 minutes] and [10 minutes, 2 hours]. 0 -5 5 10 15 20 25 30 Means of Annotated Duration"
W06-0906,P06-1050,1,0.722451,"ptions of events and relying on our knowledge of the range of usual durations of types of events, which can be very important in applications in which the time course of events is to be extracted from news. For example, whether two events overlap or are in sequence often depends very much on their durations. If a war started yesterday, we can be pretty sure it is still going on today. If a hurricane started last year, we can be sure it is over by now. To extract such implicit event duration information from texts automatically, we developed a corpus annotated with typical durations of events (Pan et al., 2006a) which currently contains all the 48 non-Wall-Street-Journal (non-WSJ) news articles (a total of 2132 event instances), as well as 10 WSJ articles (156 event instances), from the TimeBank corpus annotated in TimeML (Pustejovky et al., 2003). Because the annotated corpus is still fairly small, we cannot hope to learn to make finegrained judgments of event durations that are currently annotated in the corpus, but as we show in greater detail in (Pan et al., 2006b), it is possible to learn useful coarse-grained judgments that considerably outperform a baseline and approach human performance. Th"
W06-0906,W01-1313,0,0.0211969,"s. 1 Introduction Temporal information processing has become more and more important in many natural language processing (NLP) applications, such as question answering (Harabagiu and Bejan, 2005; Moldovan et. al., 2005; Saurí et. al., 2005), summarization (Mani and Schiffman, 2005), and information extraction (Surdeanu et. al., 2003). Temporal anchoring and event ordering are among the most important kinds of temporal information needed for NLP applications. Although there has been much work on extracting and inferring such information from texts (Hitzeman et al., 1995; Mani and Wilson, 2000; Filatova and Hovy, 2001; Boguraev and Ando, 2005), none of this work has exploited the implicit event duration information from the text. Consider the sentence from a news article: George W. Bush met with Vladimir Putin in Moscow. How long was the meeting? Our first reaction to this question might be that we have no idea. But in fact we do have an idea. We know the meeting was longer than 10 seconds and less than a year. How much tighter can we get the 38 Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 38–45, c Sydney, July 2006. 2006 Association for Computational Linguistics int"
W06-0906,P97-1062,0,0.0556382,"Missing"
W06-0906,H05-1088,0,0.0586406,"Missing"
W06-0906,P03-1002,0,0.0921095,"Missing"
W06-0906,P00-1010,0,0.0316381,"much on their durations. 1 Introduction Temporal information processing has become more and more important in many natural language processing (NLP) applications, such as question answering (Harabagiu and Bejan, 2005; Moldovan et. al., 2005; Saurí et. al., 2005), summarization (Mani and Schiffman, 2005), and information extraction (Surdeanu et. al., 2003). Temporal anchoring and event ordering are among the most important kinds of temporal information needed for NLP applications. Although there has been much work on extracting and inferring such information from texts (Hitzeman et al., 1995; Mani and Wilson, 2000; Filatova and Hovy, 2001; Boguraev and Ando, 2005), none of this work has exploited the implicit event duration information from the text. Consider the sentence from a news article: George W. Bush met with Vladimir Putin in Moscow. How long was the meeting? Our first reaction to this question might be that we have no idea. But in fact we do have an idea. We know the meeting was longer than 10 seconds and less than a year. How much tighter can we get the 38 Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 38–45, c Sydney, July 2006. 2006 Association for Comp"
W06-0906,J88-2005,0,\N,Missing
W06-0906,E95-1035,0,\N,Missing
W07-1409,P98-1013,0,0.0581043,"rders Y 1 This seems to be an accidental gap; WordNet contains many interlinked disease-patient noun pairs, incl. ""diabetes-diabetic,"" ""epilepsy-eplileptic,"" etc. 58 721: X works on Y → X discusses Y And one that could be is not, namely: 705: X is under a contract with Y → X cooperates with Y (not in the database) Other examples are outside the scope of DIRT&apos;s approach (i.e., “X pattern1 Y” → “X pattern2 Y”), but nonetheless the coverage is encouraging. 3.3 FrameNet In our earlier analysis, we identified knowledge about stereotypical situations and their events as important for RTE. FrameNet (Baker et al, 1998) attempts to encode this knowledge. FrameNet was used with some success in RTE2 by Burchardt and Frank (2005). FrameNet&apos;s basic unit - a Frame - is a script-like conceptual schema that refers to a situation, object, or event along with its participants (Frame Elements), identified independent of their syntactic configuration. We earlier discussed how 538.T ""...the O. J. Simpson murder trial..."" might entail 538.H ""O. J. Simpson was accused of murder."" This case applies to FrameNet’s Trial frame, which includes the Frame Elements Defendant and Charges, with Charges being defined as ""The legal l"
W07-1409,J91-1003,0,0.100568,"Missing"
W07-1409,W06-3907,0,0.0744538,"mbing, which includes sending the bomb in the mail. Thus a person could also recognize alternative verbs in 358.H as valid (e.g., ""mailed"", ""delivered"") or invalid (e.g., ""thrown at"", ""dropped on""), even 56 Some RTE3 examples contain complement-taking verbs that make an implication (either positive or negative) about the complement. For example: 668 ""A survey shows that X..."" → ""X..."" 657 ""...X was seen..."" → ""...X..."" 725 “...decided to X..."" → ""...X..."" 716 ""...have been unable to X..."" → ""...do not X"" In the first 3 the implication is positive, but in the last the implication is negative. (Nairn et al, 2006) provide a detailed analysis of this type of behavior. In fact, this notion of implicature (one part of a sentence making an implication about another part) extends beyond single verbs, and there are some more complex examples in RTE3, e.g.: 453 ""...won the battle to X..."" → ""...X..."" 784.T ""X reassures Russia it has nothing to fear..."" 784.H ""Russia fears..."" In this last example the implication behavior is quite complex: (loosely) If X reassures Y of Z, then Y is concerned about not-Z. 2.12 Metonymy/Transfer In some cases, language allows us to replace a word (sense) with a closely related w"
W07-1409,C98-1013,0,\N,Missing
W08-2205,W07-1420,0,0.0110908,"Missing"
W08-2205,P98-1013,0,0.0707153,"n exactly the right way to fire a script). Second, two new approches for amassing knowledge are available today that were not available previously, namely automated learning from corpora, and use of Web volunteers (e.g., (Chklovski, 2005)), and may be applicable to script acquisition (Script work in the ’70s typically worked with tiny databases of scripts). Finally, techniques for language processing have substantially improved, making core tasks (e.g., parsing) less problematic, and opening the possibility to easy authoring of scripts in English, followed by machine interpretation. FrameNet (Baker et al., 1998) already provides a few small scripts, but does not currently encode the complex scenarios that we would like; a vastly expanded resource would be highly useful. We are in the early stages of exploring this avenue, encoding scripts as a list of simple English sentences, which are then automatically translated to WordNet-sense tagged logic using our software. For example, a “bombing” script looks: A building is bombed by an attacker. The attacker plants the bomb in the building. 54 Clark, Fellbaum, Hobbs, Harrison, Murray, and Thompson The bomb explodes. The explosion damages or destroys the bu"
W08-2205,W07-1427,0,0.0257037,"Missing"
W08-2205,W08-2221,1,0.9137,"ng’s Language Understanding Engine, which we first describe. We then present the WordNet augmentations that we are developing, and our experience with these as well as with the DIRT paraphrase database. Augmenting WordNet for Deep Understanding of Text 47 The contribution of this paper is some preliminary insight into avenues and challenges for creating and leveraging more world knowledge, in the context of WordNet, for deeper language understanding. 2 Text Interpretation and Subsumption 2.1 Text Interpretation For text interpretation we are using BLUE, Boeing’s Language Understanding Engine (Clark and Harrison, 2008), comprising a parser, logical form (LF) generator, and final logic generator. Parsing is performed using SAPIR, a mature, bottom-up, broad coverage chart parser (Harrison and Maxwell, 1986). The parser’s cost function is biased by a database of manually and corpus-derived “tuples” (good parse fragments), as well as hand-coded preference rules. During parsing, the system also generates a logical form (LF), a semi-formal structure between a parse and full logic, loosely based on Schubert and Hwang (1993). The LF is a simplified and normalized tree structure with logic-type elements, generated b"
W08-2205,C98-1013,0,\N,Missing
W08-2205,W07-1401,0,\N,Missing
W08-2217,P83-1009,1,0.443826,"of eventualities, like Dogs bark. We do not want to treat these as radically different kinds of entities. We would like both, at some level, to 3 In order to increase readability, we will often make use of the symbol ∧ in place of the unprimed predicate and. 4 The formula expresses the de-re reading of the sentence, where e , e , e , John, Jack, Ic are first order 1 2 3 constants. Refining the Meaning of Sense Labels in PDTB: “Concession” 213 be treated simply as eventualities that can be the content of thoughts. To this end, the logical framework includes the notion of typical element (from Hobbs (1983, 1995, 1998)). The typical element of a set is the reification of the universally quantified variable ranging over the elements of the set (cf. McCarthy (1977)). Typical elements are first-order individuals. The introduction of typical elements arises from the need to move from the standard set-theoretic notation s = {x |p(x) } or its logical equivalent, (forall (x) (iff (member x s) (p x))) to a simple statement that p is true of a “typical element” of s by reifying typical elements. The principal property of typical elements is that all properties of typical elements are inherited by the re"
W08-2217,prasad-etal-2008-penn,1,0.838203,"rawn by the reader, utilizing basic notions from Hobbs’s logic, including the distinction between causes and causal complexes (Hobbs, 2005). This work is part of a larger project on the semantics of connectives which aims at developing formal descriptions of discourse relations, useful for processing real data. 207 208 Robaldo, Miltsakaki, and Hobbs 1 Introduction As the demand for more powerful NLP applications increases, there is also an increasing need to develop algorithms for automated processing of discourse relations and models for deriving the inferences drawn by the reader. PDTB 2.0 (Prasad et al., 2008), released in January 2008, contains annotations of discourse connectives and their arguments, attribution, and sense labels giving rough semantic descriptions of the connectives. The availability of such a richly annotated corpus promises to boost our understanding of the structure and meaning of discourse and will facilitate the development of efficient algorithms for identifying discourse connectives and their arguments. However, in order to be able to derive appropriate inferences associated with discourse relations, we need to develop useful semantic analyses of the meaning of connectives"
W08-2217,J03-4002,0,0.0300124,"to the semantics of concession. Section 4 presents the semantic analysis of “concession”. In Section 5, we report briefly on the distribution of concessive labels in PDTB 2.0 and conclude in Section 6. 2 Sense labels in PDTB The Penn Discourse Treebank provides annotations of the argument structure of discourse connectives, attribution (e.g., ‘ownership’ of the relation by the writer or other individual), and semantic labels for all the annotated connectives (Prasad et al., 2008). This annotation of discourse connectives and their arguments draws on a lexical approach to discourse structure (Webber et al., 2003; Webber and Joshi, 2003), viewing discourse connectives as discourse-level predicates that take two abstract objects such as events, states, and propositions (Asher, 1993) as their arguments. Two major types of discourse connectives are annotated in PDTB: a) explicit connectives including subordinate conjunctions, coordinate conjunctions and adverbials, and b) implicit connectives that are inserted between two adjacent sentences to capture the meaning of the inferred relation when no explicit connective is present. The PDTB 2.0 is, to date, the largest annotation effort at the discourse level"
W08-2217,W98-0315,0,\N,Missing
W11-0107,W11-0124,1,0.646467,"s done. 4. The lowest-cost proof is the best interpretation, or the best abductive proof of the goal expression. However, there are two significant problems with weighted abduction as it was originally presented. First, it required a large knowledge base of commonsense knowledge. This was not available when weighted abduction was first described, but since that time there have been substantial efforts to build up knowledge bases for various purposes, and at least two of these have been used with promising results in an abductive setting—Extended WordNet [6] for question-answering and FrameNet [11] for textual inference. The second problem with weighted abduction was that the weights and costs did not have a probabilistic semantics. This, for example, hampers automatic learning of weights from data or existing resources. That is the issue we address in the present paper. In the last decade and a half, a number of formalisms for adding uncertain reasoning to predicate logic have been developed that are well-founded in probability theory. Among the most widely investigated is Markov logic [14, 4]. In this paper we show how weighted abduction can be implemented in Markov logic. This demons"
W11-0121,W11-0124,1,0.879821,"Missing"
W11-0121,P85-1008,1,\N,Missing
W11-0124,burchardt-pennacchiotti-2008-fate,0,0.0838728,"eral and not tuned for a particular application. We decided to test our approach on RTE because this is a well-defined task that captures major semantic inference needs across many natural language 1 http://www.rutumulkar.com/download/TACITUS/tacitus.php 225 processing applications, such as question answering, information retrieval, information extraction, and document summarization. For evaluation, we have chosen the RTE-2 data set (Bar-Haim et al., 2006), because besides providing text-hypothesis pairs and a gold standard this data set has been annotated with FrameNet frame and role labels (Burchardt and Pennacchiotti, 2008) which gives us the possibility of evaluating our frame and role labeling based on the axioms extracted from FrameNet. 2 NL Pipeline and Abductive Reasoning Our natural language pipeline produces interpretations of texts given the appropriate knowledge base. A text is first input to the English Slot Grammar (ESG) parser (McCord, 1990, 2010). For each segment, the parse produced by ESG is a dependency tree that shows both surface and deep structure. The deep structure is exhibited via a word sense predication for each node, with logical arguments. These logical predications form a good start on"
W11-0124,P85-1008,1,0.500584,"ameNet. 2 NL Pipeline and Abductive Reasoning Our natural language pipeline produces interpretations of texts given the appropriate knowledge base. A text is first input to the English Slot Grammar (ESG) parser (McCord, 1990, 2010). For each segment, the parse produced by ESG is a dependency tree that shows both surface and deep structure. The deep structure is exhibited via a word sense predication for each node, with logical arguments. These logical predications form a good start on a logical form (LF) for the whole segment. An add-on to ESG converts the parse tree into a LF in the style of Hobbs (1985). The LF is a conjunction of predications, which have generalized entity arguments that can be used for showing relationships among the predications. These LFs are used by the downstream components. The interpretation of the text is carried out by an inference system called Mini-TACITUS using weighted abduction as described in detail in Hobbs et al. (1993). Mini-TACITUS tries to prove the logical form of the text, allowing assumptions where necessary. Where the system is able to prove parts of the LF, it is anchoring it in what is already known from the overall discourse or from a knowledge ba"
W11-0124,N10-1146,0,0.0223305,"Missing"
W11-0124,ovchinnikova-etal-2010-data,1,0.909436,"s” of abductive proofs and hence of interpretations of texts and other situations. The success of a discourse processing system based on inferences heavily depends on a knowledge base. The main contribution of this paper is in showing how a large and reliable knowledge base can be obtained by exploiting existing lexical semantic resources and can be successfully applied to reasoning tasks on a large scale. In particular, we experiment with axioms extracted from WordNet, see Fellbaum (1998), and FrameNet, see Ruppenhofer et al. (2006). In axiomatizing FrameNet we rely on the study described in Ovchinnikova et al. (2010). We evaluate our inference system and the obtained knowledge base in recognizing textual entailment (RTE). As the reader will see in the following sections, inferences carried out by Mini-TACITUS are fairly general and not tuned for a particular application. We decided to test our approach on RTE because this is a well-defined task that captures major semantic inference needs across many natural language 1 http://www.rutumulkar.com/download/TACITUS/tacitus.php 225 processing applications, such as question answering, information retrieval, information extraction, and document summarization. Fo"
W11-0124,D07-1002,0,0.0262472,"228 representation format and converted them into axioms; for example the following axiom represents the meaning of the synset containing such lexemes as horseback. These axioms have the total weight of 100. on(e2,e1,x2):25 & back(e3,x2):25 & of (e4,x2,x1):25 & horse(e5,x1):25 → synset-X(e0,x0) The second resource which we have used as a source of axioms is FrameNet, release 1.5, see Ruppenhofer et al. (2006). FrameNet has a shorter history in NLP applications than WordNet, but lately more and more researchers have been demonstrating its potential to improve the quality of question answering (Shen and Lapata, 2007) and recognizing textual entailment (Burchardt et al., 2009). The lexical meaning of predicates in FrameNet is represented in terms of frames which describe prototypical situations spoken about in natural language. Every frame contains a set of roles corresponding to the participants of the described situation. Predicates with similar semantics are assigned to the same frame; e.g. both give and hand over refer to the G IVING frame. For most of the lexical elements FrameNet provides syntactic patterns showing the surface realization of these lexical elements and their arguments. Syntactic patte"
W11-0124,W07-1409,1,\N,Missing
W11-0124,C12-1079,1,\N,Missing
W11-0143,pan-etal-2006-annotated,1,0.781094,"and are very complex structures in language. 3 Evaluation of the Granularity Model in Natural Language We conducted an evaluation study to judge the “goodness” of the granularity model proposed. In this study the annotators were asked to annotate granularity relations between two given paragraphs. Paragraph-based analysis was preferred to event-word-based analysis because people reason much more easily with paragraph descriptions than with individual event mentions 2 . The annotation set consisted of paragraph pairs from three domains: travel articles (confluence.org), Timebank annotated data Pan et al. (2006), and Wikipedia articles on games. We selected a total of 37 articles: 10 articles about travel, 10 about games, and 17 from Timebank. Both paragraphs of a given question were selected from the same article and referred to the same overall concept. 3.1 Annotation Task The articles were uploaded to Mechanical Turk and were annotated by non-expert annotators (regular Turkers). The entire set of 37 articles was annotated by 5 people. The annotators were given a pair of paragraphs and were asked four questions about the relations between them: (i) Is one paragraph a subevent of the other paragraph"
W13-3817,N06-1020,0,0.0155944,"input formula was proven and which of its parts could not be proven. In the early 90s, research on abduction-based discourse processing resulted in good theoretical work and in interesting small-scale systems, but it faced three difficulties: 1) parsers were slow and not accurate enough, so that inference had no place to start, 2) inference processes were neither efficient nor accurate enough, 3) there was no large knowledge base designed for discourse processing applications. In the last two decades, the first of these difficulties has been addressed by progress in statistical parsing, e.g. (McClosky et al., 2006; Huang, 2008; Bos, 2011). Recently, efficient reasoning techniques were developed that overcome the second difficulty (Inoue and Inui, 2011; Inoue et al., 2012b). Finally, it has been shown that there exists sufficient knowledge about the world – at a level of precision that enables its translation into formal logic – available in a variety of resources (Ovchinnikova et al., 2011; Ovchinnikova, 2012). These advances have recently been capitalized upon in several large-scale applications of abduction to discourse processing tasks (Inoue and Inui, 2011; Ovchinnikova et al., 2011; Ovchinnikova,"
W13-3817,W11-0107,1,0.719601,"redundancy and supports linking the meanings of compose and sonata. As mentioned above, weighted abduction implies unconditional unification. In the discourse interpretation context, unification is one of the Observations costs The second feature concerns the unequal treatment of atomic observations depending on their initial cost. Hobbs et al. (1993) mention that costs reflect the demand for propositions to be proved. Those propositions that are most likely to be linked referentially to other parts of the discourse are expensive to assume. This idea is illustrated by an example provided in (Blythe et al., 2011). Suppose there are two sentences. The smart man is tall. The tall man is smart. The logical representation for each of them is ∃x(smart(x) ∧ tall(x) ∧ man(x)). But certain syntactic features attached to propositions (e.g., definite article) influence the probability of the propositions to be explained or assumed. In the first sentence we want to prove smart(x) to anchor the sentence referentially. Then tall(x) is new information to be assumed. Blythe et al. (2011) suggest having a high cost on smart(x) to force the proof procedure to find this referential anchor. The cost on tall(x) will be l"
W13-3817,W11-0124,1,0.928796,"accurate enough, 3) there was no large knowledge base designed for discourse processing applications. In the last two decades, the first of these difficulties has been addressed by progress in statistical parsing, e.g. (McClosky et al., 2006; Huang, 2008; Bos, 2011). Recently, efficient reasoning techniques were developed that overcome the second difficulty (Inoue and Inui, 2011; Inoue et al., 2012b). Finally, it has been shown that there exists sufficient knowledge about the world – at a level of precision that enables its translation into formal logic – available in a variety of resources (Ovchinnikova et al., 2011; Ovchinnikova, 2012). These advances have recently been capitalized upon in several large-scale applications of abduction to discourse processing tasks (Inoue and Inui, 2011; Ovchinnikova et al., 2011; Ovchinnikova, 2012; Inoue et al., 2012a). In an abductive framework, often many explanations can be provided for the same observation. In order to find the best solution for our pragmatic problem, we need to be able to choose the best, i.e. the most probable, explanation. Several apAbduction allows us to model interpretation of discourse as the explanation of observables, given additional knowl"
W13-3817,P08-1067,0,0.0235296,"n and which of its parts could not be proven. In the early 90s, research on abduction-based discourse processing resulted in good theoretical work and in interesting small-scale systems, but it faced three difficulties: 1) parsers were slow and not accurate enough, so that inference had no place to start, 2) inference processes were neither efficient nor accurate enough, 3) there was no large knowledge base designed for discourse processing applications. In the last two decades, the first of these difficulties has been addressed by progress in statistical parsing, e.g. (McClosky et al., 2006; Huang, 2008; Bos, 2011). Recently, efficient reasoning techniques were developed that overcome the second difficulty (Inoue and Inui, 2011; Inoue et al., 2012b). Finally, it has been shown that there exists sufficient knowledge about the world – at a level of precision that enables its translation into formal logic – available in a variety of resources (Ovchinnikova et al., 2011; Ovchinnikova, 2012). These advances have recently been capitalized upon in several large-scale applications of abduction to discourse processing tasks (Inoue and Inui, 2011; Ovchinnikova et al., 2011; Ovchinnikova, 2012; Inoue e"
W13-3817,C12-1079,1,0.918595,"l work and in interesting small-scale systems, but it faced three difficulties: 1) parsers were slow and not accurate enough, so that inference had no place to start, 2) inference processes were neither efficient nor accurate enough, 3) there was no large knowledge base designed for discourse processing applications. In the last two decades, the first of these difficulties has been addressed by progress in statistical parsing, e.g. (McClosky et al., 2006; Huang, 2008; Bos, 2011). Recently, efficient reasoning techniques were developed that overcome the second difficulty (Inoue and Inui, 2011; Inoue et al., 2012b). Finally, it has been shown that there exists sufficient knowledge about the world – at a level of precision that enables its translation into formal logic – available in a variety of resources (Ovchinnikova et al., 2011; Ovchinnikova, 2012). These advances have recently been capitalized upon in several large-scale applications of abduction to discourse processing tasks (Inoue and Inui, 2011; Ovchinnikova et al., 2011; Ovchinnikova, 2012; Inoue et al., 2012a). In an abductive framework, often many explanations can be provided for the same observation. In order to find the best solution for"
W14-2305,C10-2113,0,0.0126834,"words and phrases. There is a long-standing tradition for considering computational models derived from word co-occurrence statistics as being capable of producing reasonable property-based descriptions of concepts (Baroni and Lenci, 2008). We use proposition stores to derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: Linguistic Metaphors Extraction and Validation For each potential CM, we look for supporting LMs in corpora. A a large number of LMs supporting a particular CM suggests that this CM might be cognitively plausible. We use a simple method for finding LMs. If a target lexeme and a source lexeme are connected by a dependency relation in a sentence, then we assume that this dependency structure contains a LM. For example, in the phrases medicine against poverty and chron"
W14-2305,C12-2109,0,0.101564,"Missing"
W14-2305,C04-1180,0,0.122716,"we generate unlinked predicates for this structure: John(e1 , x1 )∧decide(e2 , x2 , x3 )∧leave(e3 , x4 ). Then, based on the dependency labels, we link argument x1 with x2 , x3 with e3 , and x1 with x4 to obtain the following LF: John(e1 , x1 ) ∧ decide(e2 , x1 , e3 ) ∧ leave(e3 , x1 ). LFs are preferable to dependency structures in this case because they generalize over syntax and link arguments using long-distance dependencies. Furthermore, we need logical representations in order to apply abductive inference. In order to produce logical forms for English, we use the Boxer semantic parser (Bos et al., 2004). As one of the possible formats, Boxer outputs logical forms of sentences in the style of (Hobbs, 1985). For Russian, we use the Malt dependency parser (Nivre et al., 2006). We developed a converter turning Malt dependencies into logical forms in the style of (Hobbs, 1985).1 3.2 Abductive Inference In order to detect conceptual metaphors and infer explicit mappings between target and source domains, we employ a mode of inference called weighted abduction (Hobbs et al., 1993). This framework is appealing because it is a realization of the observation that we understand new material by linking"
W14-2305,N10-1147,0,0.135178,"he understanding of one concept or conceptual domain in terms of the properties of another (Lakoff and Johnson, 1980; Lakoff, 1987). For example, development can be understood as movement (e.g., the economy moves forward, the engine of the economy). In other words, a conceptual metaphor consists in mapping a target conceptual domain (e.g., economy) to a source domain (e.g., vehicle) by comparing their properties 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, c Baltimore, MD, USA, 26 June 2014. 2014 Association for Computational Linguistics 3.1 port&quot; is paraphrased as &quot;a carelessly disclosed report&quot;. This approach currently focuses on"
W14-2305,W13-3818,0,0.0143187,"ere is a long-standing tradition for considering computational models derived from word co-occurrence statistics as being capable of producing reasonable property-based descriptions of concepts (Baroni and Lenci, 2008). We use proposition stores to derive salient properties of concepts that can be potentially compared in a metaphor. A proposition store is a collection of propositions such that each proposition is assigned its frequency in a corpus. Propositions are tuples of words that have a determined pattern of syntactic relations among them (Clark and Harrison, 2009; Peñas and Hovy, 2010; Tsao and Wible, 2013). For example, the following propositions can be extracted from the sentence John decided to go to school: Linguistic Metaphors Extraction and Validation For each potential CM, we look for supporting LMs in corpora. A a large number of LMs supporting a particular CM suggests that this CM might be cognitively plausible. We use a simple method for finding LMs. If a target lexeme and a source lexeme are connected by a dependency relation in a sentence, then we assume that this dependency structure contains a LM. For example, in the phrases medicine against poverty and chronic poverty, the target"
W14-2305,C08-1119,0,0.0317325,"an be understood as movement (e.g., the economy moves forward, the engine of the economy). In other words, a conceptual metaphor consists in mapping a target conceptual domain (e.g., economy) to a source domain (e.g., vehicle) by comparing their properties 2 Related Work Automatic interpretation of linguistic metaphors is performed using two principal approaches: 1) deriving literal paraphrases for metaphorical expressions from corpora (Shutova, 2010; Shutova et al., 2012) and 2) reasoning with manually coded knowledge (Hobbs, 1992; Narayanan, 1999; Barnden and Lee, 2002; Agerri et al., 2007; Veale and Hao, 2008). (Shutova, 2010; Shutova et al., 2012) present methods for deriving paraphrases for linguistic metaphors from corpora. For example, the metaphorical expression &quot;a carelessly leaked re33 Proceedings of the Second Workshop on Metaphor in NLP, pages 33–41, c Baltimore, MD, USA, 26 June 2014. 2014 Association for Computational Linguistics 3.1 port&quot; is paraphrased as &quot;a carelessly disclosed report&quot;. This approach currently focuses on singleword metaphors expressed by verbs only and does not explain the target–source mapping. The KARMA (Narayanan, 1999) and the ATTMeta (Barnden and Lee, 2002; Agerr"
W14-2305,P85-1008,1,0.636456,"ccording to Hobbs, a metaphorical expression should be interpreted in context. For example, John is an elephant can be best interpreted as &quot;John is clumsy&quot; in the context Mary is graceful, but John is an elephant. In order to obtain context-dependent interpretations, (Hobbs, 1992) uses abductive inference linking parts of the discourse and ensuring discourse coherence. 3 Logical Form Generation A logical form (LF) is a conjunction of propositions which have argument links showing relationships among phrase constituents. We use logical representations of natural language texts as described in (Hobbs, 1985). In order to obtain LFs we convert dependency parses into logical representations in two steps: 1) assign arguments to each lemma, 2) apply rules to dependencies in order to link arguments. Consider the dependency structure for the sentence, John decided to leave: [PRED decide [SUBJ John] [OBJ leave]]. First, we generate unlinked predicates for this structure: John(e1 , x1 )∧decide(e2 , x2 , x3 )∧leave(e3 , x4 ). Then, based on the dependency labels, we link argument x1 with x2 , x3 with e3 , and x1 with x4 to obtain the following LF: John(e1 , x1 ) ∧ decide(e2 , x1 , e3 ) ∧ leave(e3 , x1 )."
W14-2305,nivre-etal-2006-maltparser,0,0.0969155,"2 , x3 with e3 , and x1 with x4 to obtain the following LF: John(e1 , x1 ) ∧ decide(e2 , x1 , e3 ) ∧ leave(e3 , x1 ). LFs are preferable to dependency structures in this case because they generalize over syntax and link arguments using long-distance dependencies. Furthermore, we need logical representations in order to apply abductive inference. In order to produce logical forms for English, we use the Boxer semantic parser (Bos et al., 2004). As one of the possible formats, Boxer outputs logical forms of sentences in the style of (Hobbs, 1985). For Russian, we use the Malt dependency parser (Nivre et al., 2006). We developed a converter turning Malt dependencies into logical forms in the style of (Hobbs, 1985).1 3.2 Abductive Inference In order to detect conceptual metaphors and infer explicit mappings between target and source domains, we employ a mode of inference called weighted abduction (Hobbs et al., 1993). This framework is appealing because it is a realization of the observation that we understand new material by linking it with what we already know. Abduction is inference to the best explanation. Formally, logical abduction is defined as follows: Metaphor Interpretation System Our abduction"
W14-3003,W11-0124,1,\N,Missing
W15-1406,C04-1180,0,0.0555953,"edge base Parse Logical form converter LF Abductive reasoner Interpretation Conceptual metaphor domains CM extractor & scorer Figure 1: Abduction-based metaphor processing pipeline. basic natural language explanation of the conceptual metaphor identified by abduction. The effectiveness of this approach was validated by expert linguists for English and Russian metaphors. A diagram of the interpretation pipeline is shown in Figure 1. To process a text fragment containing a metaphor, this system generates logical forms (LFs) in the style of Hobbs (1985) by postprocessing the output of the Boxer (Bos et al., 2004) and Malt (Nivre et al., 2006) dependency parsers. A logical form is a conjunction of propositions, where argument links show the relationships among the constituents. An advantage of LFs over the direct use of dependency structures is that they generalize over syntax and they link arguments using long-distance dependencies. While this process is generally reliable, it can result in incorrect part-of-speech suffixes on predicates or inaccurate linking of arguments. Along with appropriate knowledge bases, the sentential logical forms are input to an engine for weighted abduction based on intege"
W15-1406,J91-1003,0,0.835879,"give deeper analysis, as discussed in section 5. This paper’s main contribution is the use of annotated collections of metaphors, describing seven target concepts in terms of 67 source concepts in four languages, to learn the lexical axioms needed for high-precision abductive metaphor mapping. 2 Related Work Metaphor has been studied extensively in the fields of linguistics, philosophy, and cognitive science (e.g., Lakoff and Johnson, 1980; Lakoff, 1992; Gentner et al., 2002). Computational research on metaphor has focused on the problems of (1) identifying linguistic metaphors in text (e.g., Fass, 1991; Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010; Tsvetkov et al., 2014) and (2) identifying the source and target concepts invoked by each linguistic metaphor. 50 Proceedings of the Third Workshop on Metaphor in NLP, pages 50–55, c Denver, Colorado, June 5, 2015. 2015 Association for Computational Linguistics Knowledge-based approaches to identifying conceptual metaphors include that of Hobbs (1992), described in the following section, KARMA (Narayanan, 1997, 1999), and ATT-Meta (Barnden and Lee, 2002; Agerri et al., 2007). These have relied on the use of manually coded"
W15-1406,P85-1008,1,0.618125,"good memory, etc. 51 Text (LMs) Parser Boxer/Malt Knowledge base Parse Logical form converter LF Abductive reasoner Interpretation Conceptual metaphor domains CM extractor & scorer Figure 1: Abduction-based metaphor processing pipeline. basic natural language explanation of the conceptual metaphor identified by abduction. The effectiveness of this approach was validated by expert linguists for English and Russian metaphors. A diagram of the interpretation pipeline is shown in Figure 1. To process a text fragment containing a metaphor, this system generates logical forms (LFs) in the style of Hobbs (1985) by postprocessing the output of the Boxer (Bos et al., 2004) and Malt (Nivre et al., 2006) dependency parsers. A logical form is a conjunction of propositions, where argument links show the relationships among the constituents. An advantage of LFs over the direct use of dependency structures is that they generalize over syntax and they link arguments using long-distance dependencies. While this process is generally reliable, it can result in incorrect part-of-speech suffixes on predicates or inaccurate linking of arguments. Along with appropriate knowledge bases, the sentential logical forms"
W15-1406,W14-2305,1,0.602889,"ingual Metaphors Jonathan Gordon, Jerry R. Hobbs, and Jonathan May Information Sciences Institute University of Southern California Marina del Rey, CA {jgordon,hobbs,jonmay}@isi.edu Abstract Metaphor is a cognitive phenomenon exhibited in language, where one conceptual domain (the target) is thought of in terms of another (the source). The first level of metaphor interpretation is the mapping of linguistic metaphors to pairs of source and target concepts. Based on the abductive approach to metaphor interpretation proposed by Hobbs (1992) and implemented in the open-source Metaphor-ADP system (Ovchinnikova et al., 2014), we present work to automatically learn knowledge bases to support high-precision conceptual metaphor mapping in English, Spanish, Farsi, and Russian. 1 Introduction In everyday speech and text, people talk about one conceptual domain (the target) in terms of another (the source). According to Lakoff and Johnson (1980) and others, these linguistic metaphors (LMs) are an observable manifestation of our mental, conceptual metaphors (CMs). Computational research on metaphor is important: If natural-language systems treat metaphors at face value, meaning can be missed, resulting in absurd or triv"
W15-1406,N10-1039,0,0.0856645,"r’s main contribution is the use of annotated collections of metaphors, describing seven target concepts in terms of 67 source concepts in four languages, to learn the lexical axioms needed for high-precision abductive metaphor mapping. 2 Related Work Metaphor has been studied extensively in the fields of linguistics, philosophy, and cognitive science (e.g., Lakoff and Johnson, 1980; Lakoff, 1992; Gentner et al., 2002). Computational research on metaphor has focused on the problems of (1) identifying linguistic metaphors in text (e.g., Fass, 1991; Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010; Tsvetkov et al., 2014) and (2) identifying the source and target concepts invoked by each linguistic metaphor. 50 Proceedings of the Third Workshop on Metaphor in NLP, pages 50–55, c Denver, Colorado, June 5, 2015. 2015 Association for Computational Linguistics Knowledge-based approaches to identifying conceptual metaphors include that of Hobbs (1992), described in the following section, KARMA (Narayanan, 1997, 1999), and ATT-Meta (Barnden and Lee, 2002; Agerri et al., 2007). These have relied on the use of manually coded knowledge, limiting their ability to scale across domains and language"
W15-1406,nivre-etal-2006-maltparser,0,0.0151617,"converter LF Abductive reasoner Interpretation Conceptual metaphor domains CM extractor & scorer Figure 1: Abduction-based metaphor processing pipeline. basic natural language explanation of the conceptual metaphor identified by abduction. The effectiveness of this approach was validated by expert linguists for English and Russian metaphors. A diagram of the interpretation pipeline is shown in Figure 1. To process a text fragment containing a metaphor, this system generates logical forms (LFs) in the style of Hobbs (1985) by postprocessing the output of the Boxer (Bos et al., 2004) and Malt (Nivre et al., 2006) dependency parsers. A logical form is a conjunction of propositions, where argument links show the relationships among the constituents. An advantage of LFs over the direct use of dependency structures is that they generalize over syntax and they link arguments using long-distance dependencies. While this process is generally reliable, it can result in incorrect part-of-speech suffixes on predicates or inaccurate linking of arguments. Along with appropriate knowledge bases, the sentential logical forms are input to an engine for weighted abduction based on integer linear programming (Inoue an"
W15-1406,C10-1113,0,0.0489568,"n section 5. This paper’s main contribution is the use of annotated collections of metaphors, describing seven target concepts in terms of 67 source concepts in four languages, to learn the lexical axioms needed for high-precision abductive metaphor mapping. 2 Related Work Metaphor has been studied extensively in the fields of linguistics, philosophy, and cognitive science (e.g., Lakoff and Johnson, 1980; Lakoff, 1992; Gentner et al., 2002). Computational research on metaphor has focused on the problems of (1) identifying linguistic metaphors in text (e.g., Fass, 1991; Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010; Tsvetkov et al., 2014) and (2) identifying the source and target concepts invoked by each linguistic metaphor. 50 Proceedings of the Third Workshop on Metaphor in NLP, pages 50–55, c Denver, Colorado, June 5, 2015. 2015 Association for Computational Linguistics Knowledge-based approaches to identifying conceptual metaphors include that of Hobbs (1992), described in the following section, KARMA (Narayanan, 1997, 1999), and ATT-Meta (Barnden and Lee, 2002; Agerri et al., 2007). These have relied on the use of manually coded knowledge, limiting their ability to scale acr"
W15-1406,C12-2109,0,0.0376563,"Missing"
W15-1406,P14-1024,0,0.0466056,"the use of annotated collections of metaphors, describing seven target concepts in terms of 67 source concepts in four languages, to learn the lexical axioms needed for high-precision abductive metaphor mapping. 2 Related Work Metaphor has been studied extensively in the fields of linguistics, philosophy, and cognitive science (e.g., Lakoff and Johnson, 1980; Lakoff, 1992; Gentner et al., 2002). Computational research on metaphor has focused on the problems of (1) identifying linguistic metaphors in text (e.g., Fass, 1991; Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010; Tsvetkov et al., 2014) and (2) identifying the source and target concepts invoked by each linguistic metaphor. 50 Proceedings of the Third Workshop on Metaphor in NLP, pages 50–55, c Denver, Colorado, June 5, 2015. 2015 Association for Computational Linguistics Knowledge-based approaches to identifying conceptual metaphors include that of Hobbs (1992), described in the following section, KARMA (Narayanan, 1997, 1999), and ATT-Meta (Barnden and Lee, 2002; Agerri et al., 2007). These have relied on the use of manually coded knowledge, limiting their ability to scale across domains and languages. As an alternative to"
W15-1406,W11-0124,1,\N,Missing
W15-1406,N10-1147,0,\N,Missing
W15-1406,E06-1042,0,\N,Missing
W15-1407,nivre-etal-2006-maltparser,0,\N,Missing
W15-1407,C10-1113,0,\N,Missing
W15-1407,N10-1147,0,\N,Missing
W15-1407,J91-1003,0,\N,Missing
W15-1407,E06-1042,0,\N,Missing
W15-1407,N10-1039,0,\N,Missing
W15-1407,shaikh-etal-2014-multi,0,\N,Missing
W15-1407,C14-1165,1,\N,Missing
W15-1407,W15-1406,1,\N,Missing
W15-1407,W13-2322,0,\N,Missing
W15-1407,W14-2305,1,\N,Missing
W15-1407,alonge-2006-italian,0,\N,Missing
W19-2403,P85-1008,1,0.5561,"ed entities and relations that connect the words to our commonsense understanding of the world (a person in the office located in Boston made the call). Given sufficiently rich knowledge bases, logical abduction produces many candidate solutions, necessitating a means of favoring Parsing the Logical Form of the Text Hobbs et al.’s (1993) proposal viewed the problem of syntax as the conversion of a sequence of words into the logical form of the text, where individual morphemes in the text were reified as literals whose arguments encoded their syntactic relationship to other elements, following Hobbs (1985). In their original proposal, this form was abductively derived via a knowledge base of syntactic axioms. However, the emergence of high-accuracy statistical parsers makes this a less than optimal approach to syntactic analysis. Beginning first with systems that generated the logical form of the text from constituency parsers (Rathod, 2005), recent interpretation pipelines have opted to generate these forms using the output of English Slot Grammar parsers, Combinatory Categorical Grammar parsers, or syntactic 20 et al. (2013) showed that the weights used in weighted abduction cannot be interpr"
W19-2403,N03-1022,0,0.235088,"Missing"
W19-2403,W11-0107,1,0.730434,"Missing"
W19-2403,W13-3817,1,0.883836,"Missing"
W19-2403,W08-2222,0,0.0340046,"nly those needed as part of the abductive proof structure. While required for this particular text, these axioms were written in a general style so as to better assess the feasibility of the approach on general textual input. Each axiom was assigned an arbitrary probability, reified as an etcetera literal as required by Etcetera Abduction, which will become more relevant as the size of the knowledge base increases. The following are two examples of 80 axioms authored during the course of this exploration. Logical Form of the Text We began our exploration by applying a contemporary CCG parser (Bos, 2008) to generate the logical form of the text. After some preliminary work with the resulting output, we judged that the automatically-generated logical form of the text 2 https://github.com/asgordon/EtcAbductionPy https://www.nytimes.com/interactive/2017/04/02/ technology/uber-drivers-psychological-tricks.html ;; failure of u to control is bad for u 3 (if (and (cannot’ e35 e37) 22 (control’ e37 u d) Meaning of “This. . . means” (etc1 badFor 0.9 e35 u)) The coherence relation between sentence 2 and sentence 3 is the predicate-argument relation where “means” is the predicate and the argument is the"
X96-1037,P86-1031,1,0.509598,"Missing"
X98-1013,J96-1002,0,0.00464313,"created are less than 700 characters a p a r t in the text. After the feature signatures were written, we examined the texts and manually encoded a key for each. We a t t e m p t e d two approaches to classifying merges using this corpus as training data. The first was to grow a classification tree in the style of Breiman et al. (1984). At each node, the algorithm asks each question and selects the one resulting in the purest split of the data. Entropy was used as the measure of node purity. In the second set of experiments, we used the approach to m a x i m u m entropy modeling described by Berger et al. (1996). The two possible values for each of the same 50 questions (i.e., yes or no) were paired with each of the two possible outcomes for merging (i.e., correct merge or not) to create a set of feature functions, or features for short, which were used in turn to define constraints on a probabilistic model. We used the learned maxi m u m entropy model as a classifier by considering any merge with a probability strictly greater than 0.5 to be correct, and otherwise incorrect. report on learned merging strategies achieving good performance on the less complex template entity and template relation task"
X98-1013,H92-1022,0,0.0234991,"strictly greater than the 68 C o n c l u s i o n s and F u t u r e D i r e c t i o n s In sum, the learned mechanisms were neither significantly better nor worse than a hand-coded merging strategy. The inability to outperform the existing strategy could be attributed to several facts. We suspect that a major problem is the lack of accessible, reliable, and informative indicators for merging decisions. Unlike lower-level problems in natural language processing (NLP) in which local information appears to bear highly on the outcome, including, for instance, part-of-speech tagging (Church, 1988; Brill, 1992, inter alia) and sense disambiguation (Yarowsky, 1994; Yarowsky, 1995, inter alia), none of the questions we have formulated appear to be particularly indicative of what effect a potential merge will have on system performance. This suggests that more research is needed to identify ways 64 62 60 58 56 i 50 i 1oo i 15o i 200 i 250 300 Figure 4: Results of a Learning Experiment to access the necessary knowledge from independent sources such as existing knowledge bases, or by mining it from online text corpora using unsupervised or indirectly supervised learning techniques. Furthermore, these ex"
X98-1013,A88-1019,0,0.0146621,"-score that is strictly greater than the 68 C o n c l u s i o n s and F u t u r e D i r e c t i o n s In sum, the learned mechanisms were neither significantly better nor worse than a hand-coded merging strategy. The inability to outperform the existing strategy could be attributed to several facts. We suspect that a major problem is the lack of accessible, reliable, and informative indicators for merging decisions. Unlike lower-level problems in natural language processing (NLP) in which local information appears to bear highly on the outcome, including, for instance, part-of-speech tagging (Church, 1988; Brill, 1992, inter alia) and sense disambiguation (Yarowsky, 1994; Yarowsky, 1995, inter alia), none of the questions we have formulated appear to be particularly indicative of what effect a potential merge will have on system performance. This suggests that more research is needed to identify ways 64 62 60 58 56 i 50 i 1oo i 15o i 200 i 250 300 Figure 4: Results of a Learning Experiment to access the necessary knowledge from independent sources such as existing knowledge bases, or by mining it from online text corpora using unsupervised or indirectly supervised learning techniques. Furtherm"
X98-1013,W97-0319,1,0.846195,"e if merging strategies can be learned automatically. There are several different types of learning, including supervised, unsupervised, and an area in between which one might call indirectly supervised. We have performed experiments using all three types of technique, which we describe below. 1 xThe work reported on here, also discussed in Kehler (1998), concerns learning merging strategies in support of the scenario template task of MUC-6 as described in Section 2. While we are unaware of any other reported research on this task, other work has addressed other MUC-style tasks. For instance, Kehler (1997) describes a probabilistic approach to entity-level merging that outperforms several baseline metrics. Also, researchers at BBN (Ralph Weischedel, TIPSTER 18-month meeting) Supervised Methods In our first set of experiments, we took the approach most commonly pursued in the computational linguistics literature, namely supervised learning. Supervised methods require a set of training d a t a t h a t the learning algor i t h m can consult in constructing its model. For our initial experiments, we ran the 100 MUC-6 training messages through FASTUS and wrote out feature signatures for the 534 merg"
X98-1013,P94-1013,0,0.0220279,"and F u t u r e D i r e c t i o n s In sum, the learned mechanisms were neither significantly better nor worse than a hand-coded merging strategy. The inability to outperform the existing strategy could be attributed to several facts. We suspect that a major problem is the lack of accessible, reliable, and informative indicators for merging decisions. Unlike lower-level problems in natural language processing (NLP) in which local information appears to bear highly on the outcome, including, for instance, part-of-speech tagging (Church, 1988; Brill, 1992, inter alia) and sense disambiguation (Yarowsky, 1994; Yarowsky, 1995, inter alia), none of the questions we have formulated appear to be particularly indicative of what effect a potential merge will have on system performance. This suggests that more research is needed to identify ways 64 62 60 58 56 i 50 i 1oo i 15o i 200 i 250 300 Figure 4: Results of a Learning Experiment to access the necessary knowledge from independent sources such as existing knowledge bases, or by mining it from online text corpora using unsupervised or indirectly supervised learning techniques. Furthermore, these experiments may be cause for concern about the nature of"
X98-1013,P95-1026,0,0.0134199,"D i r e c t i o n s In sum, the learned mechanisms were neither significantly better nor worse than a hand-coded merging strategy. The inability to outperform the existing strategy could be attributed to several facts. We suspect that a major problem is the lack of accessible, reliable, and informative indicators for merging decisions. Unlike lower-level problems in natural language processing (NLP) in which local information appears to bear highly on the outcome, including, for instance, part-of-speech tagging (Church, 1988; Brill, 1992, inter alia) and sense disambiguation (Yarowsky, 1994; Yarowsky, 1995, inter alia), none of the questions we have formulated appear to be particularly indicative of what effect a potential merge will have on system performance. This suggests that more research is needed to identify ways 64 62 60 58 56 i 50 i 1oo i 15o i 200 i 250 300 Figure 4: Results of a Learning Experiment to access the necessary knowledge from independent sources such as existing knowledge bases, or by mining it from online text corpora using unsupervised or indirectly supervised learning techniques. Furthermore, these experiments may be cause for concern about the nature of the scoring met"
X98-1013,M92-1019,1,\N,Missing
Y07-1003,P85-1008,1,0.723528,"oherence relations that obtain between successive segments of discourse. These coherence relations can be broadly classified into four principal groups. There are relations, such as parallelism, based on similarity, the sort of similarity that is the basis for forming sets of entities, the simplest sort of system. There are figure-ground relations, such as cases where the first segment provides a backdrop and the second segment describes the action that plays out against that backdrop. There are relations based on change of state, such as the relation that I have called the Occasion relation (Hobbs, 1985a). And there are relations based on causality, such as explanation. All of this strongly suggests that theories of these concepts must be at the very foundation of any knowledge base adequate for natural language understanding. In this paper, I outline the structure of such theories. 3. Granularity A road can be viewed as a line, a surface, or a volume. When we are planning a trip, we view it as a line. When we are driving on it, we have to worry about our placement on it to the right or left, so we think of it as a surface. When we hit a pothole, it becomes a volume to us. This shifting of g"
Y07-1003,J87-3004,1,0.253819,"Missing"
