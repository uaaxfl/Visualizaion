2005.sigdial-1.4,P00-1013,0,0.58697,"h of these techniques have been applied to dialog management. The application of MDPs was first explored by Levin and Pieraccini (1997). Levin et al. (2000) provide a formal treatment of how a MDP may be applied to dialogue management, and Singh et al. (2002) show application to real systems. However, MDPs assume the current state of the environment (i.e., the conversation) is known exactly, and thus they do not naturally capture the uncertainty introduced by the speech recognition channel. Partially observable MDPs (POMDPs) extend MDPs by providing a principled account of noisy observations. Roy et al. (2000) compare an MDP and a POMDP version of the same spoken dialogue system, and find that the POMDP version gains more reward per unit time than the MDP version. Further, the authors show a trend that as speech recognition accuracy degrades, the margin by which the POMDP outperforms the MDP increases. Zhang et al. (2001) extend this work in several ways. First, the authors add “hidden” system states to account for various types of dialogue trouble, such as different sources of speech recognition errors. Second, the authors use Bayesian networks to combine observations from a variety of sources (in"
2007.sigdial-1.48,N07-2038,1,\N,Missing
2007.sigdial-1.48,W07-0302,1,\N,Missing
C16-1025,J81-4005,0,0.682625,"Missing"
C16-1025,W14-4340,1,0.913591,"et al., 2011; Deoras and Sarikaya, 2013; Sarikaya et al., 2014). Spoken language understanding from unaligned data, in which utterances are annotated with an abstract semantics, faces the additional challenge of not knowing which specific words are relevant for extracting the semantics. This problem was tackled in (Zhou and He, 2011), by using conditional random fields (CRFs) driven by finely-tuned hand-crafted features. Other discriminative approaches that deal with unaligned data use some form of delexicalisation or mapping of the input to known ontological concepts (Henderson et al., 2012; Henderson et al., 2014a). The main disadvantage of delexicalisation is the difficulty in scaling it, not only to larger and more complex dialogue domains but also to handle the many forms of language variation. We propose in this paper a semantic decoder that learns from unaligned data (Figure 1) and that exploits rich semantic distributed word representations instead of delexicalisation. The semantic decoder predicts the dialogue act and the set of slot-value pairs from a set of n-best hypotheses returned by an automatic speech recognition (ASR). The prediction is made in two steps. First, a deep learning architec"
C16-1025,W14-4337,0,0.278647,"et al., 2011; Deoras and Sarikaya, 2013; Sarikaya et al., 2014). Spoken language understanding from unaligned data, in which utterances are annotated with an abstract semantics, faces the additional challenge of not knowing which specific words are relevant for extracting the semantics. This problem was tackled in (Zhou and He, 2011), by using conditional random fields (CRFs) driven by finely-tuned hand-crafted features. Other discriminative approaches that deal with unaligned data use some form of delexicalisation or mapping of the input to known ontological concepts (Henderson et al., 2012; Henderson et al., 2014a). The main disadvantage of delexicalisation is the difficulty in scaling it, not only to larger and more complex dialogue domains but also to handle the many forms of language variation. We propose in this paper a semantic decoder that learns from unaligned data (Figure 1) and that exploits rich semantic distributed word representations instead of delexicalisation. The semantic decoder predicts the dialogue act and the set of slot-value pairs from a set of n-best hypotheses returned by an automatic speech recognition (ASR). The prediction is made in two steps. First, a deep learning architec"
C16-1025,P14-1062,0,0.0187706,"rder to perform joint intent detection and slot filling. All these models use word-level semantic annotations. However, providing these word-level semantic annotations is costly since it requires specialised annotators. (Zhou and He, 2011) has proposed learning CRFs from unaligned data, however they use manually tuned lexical or syntactic features. In this work we avoid the need for word-level annotation by exploiting distributed word embeddings and using deep learning for feature representation. Convolutional Neural Networks (CNNs) have been used previously for sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014) and in this work we explore a similar CNN to the one presented by Kim (2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-letter input vectors. Instea"
C16-1025,D14-1181,0,0.0306459,"ar CRF in order to perform joint intent detection and slot filling. All these models use word-level semantic annotations. However, providing these word-level semantic annotations is costly since it requires specialised annotators. (Zhou and He, 2011) has proposed learning CRFs from unaligned data, however they use manually tuned lexical or syntactic features. In this work we avoid the need for word-level annotation by exploiting distributed word embeddings and using deep learning for feature representation. Convolutional Neural Networks (CNNs) have been used previously for sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014) and in this work we explore a similar CNN to the one presented by Kim (2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-"
C16-1025,P15-2130,1,0.879225,"Missing"
C16-1025,D14-1162,0,0.0801578,"2014) for generating a sentence representation. However unlike Kim (2014), the input in not a single well formed sentence but a set of ill-formed ASR hypotheses. Additionally, the softmax layer used for binary classification (i.e., positive or negative sentiment) is replaced by a softmax layer for multiclass dialogue act prediction and a further softmax layer is added for each distinct slot in the domain. (Chen and He, 2015) proposed a CNN for generating intent embeddings in SLU, which uses tri-letter input vectors. Instead, in this paper the models are initialised with GloVe word embeddings (Pennington et al., 2014). These GloVe embeddings were trained in an unsupervised fashion on a large amount of data to model the contextual similarity and correlation between words. Chen and He’s model aims to learn the embeddings for utterances and intents such that utterances with similar intents are close to each other in the continuous space. Although we share the same spirit, we use sentence embeddings not only for intent creativecommons.org/licenses/by/4.0/ 259 (or dialogue act) recognition but also for slot-filling within a dialogue system and we combine them with embeddings for dialogue context. Approaches for"
C16-1025,W14-4339,0,0.187447,"Missing"
D15-1199,D10-1049,0,0.00888891,"00). Ratnaparkhi (2002) later addressed some of the limitations of class-based LMs in the over-generation phase by using a modified generator based on a syntactic dependency tree. Mairesse and Young (2014) proposed a phrase-based NLG system based on factored LMs that can learn from a semantically aligned corpus. Although active learning (Mairesse et al., 2010) was also proposed to allow learning online directly from users, the requirement for human annotated alignments limits the scalability of the system. Another similar approach casts NLG as a template extraction and matching problem, e.g., Angeli et al. (2010) train a set of log-linear models to make a series of generation decisions to choose the most suitable template for realisation. Kondadadi et al. (2013) later show that the outputs can be further improved by an SVM reranker making them comparable to human-authored texts. However, template matching approaches do not generalise well to unseen combinations of semantic elements. The use of neural network-based (NN) approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is perhaps the first NN-based generator, although generation was only done at the phrase level"
D15-1199,P13-1138,0,0.0106159,"n a syntactic dependency tree. Mairesse and Young (2014) proposed a phrase-based NLG system based on factored LMs that can learn from a semantically aligned corpus. Although active learning (Mairesse et al., 2010) was also proposed to allow learning online directly from users, the requirement for human annotated alignments limits the scalability of the system. Another similar approach casts NLG as a template extraction and matching problem, e.g., Angeli et al. (2010) train a set of log-linear models to make a series of generation decisions to choose the most suitable template for realisation. Kondadadi et al. (2013) later show that the outputs can be further improved by an SVM reranker making them comparable to human-authored texts. However, template matching approaches do not generalise well to unseen combinations of semantic elements. The use of neural network-based (NN) approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is perhaps the first NN-based generator, although generation was only done at the phrase level. Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of"
D15-1199,P98-1116,0,0.0372841,"mmon and widely adopted today is the rule-based (or template-based) approach (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011). Despite its robustness and adequacy, the frequent repetition of identical, rather stilted, output forms make talking to a rule-based generator rather tedious. Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 2014). Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements. The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-base"
D15-1199,J11-3002,0,0.00986564,"r tedious. Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 2014). Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements. The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-based methods (Oh and Rudnicky, 2000; Mairesse and Young, 2014; Wen et al., 2015) have received attention as access to data becomes increasingly available. By defining a flexible learning structure, corpus-based methods aim to learn generation directly from data by adopting an over-g"
D15-1199,J14-4003,1,0.768759,"2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-based methods (Oh and Rudnicky, 2000; Mairesse and Young, 2014; Wen et al., 2015) have received attention as access to data becomes increasingly available. By defining a flexible learning structure, corpus-based methods aim to learn generation directly from data by adopting an over-generation and reranking paradigm (Oh and Rudnicky, 2000), in which final responses are obtained by reranking a set of candidates generated from a stochastic generator. Learning from data directly enables the system to mimic human responses more naturally, removes the dependency on predefined rules, and makes the system easier to build and extend to other domains. As detailed"
D15-1199,P10-1157,1,0.933767,"Missing"
D15-1199,W00-0306,0,0.402023,"Missing"
D15-1199,P02-1040,0,0.123792,"ning each of the collected corpus into a training, validation, and testing set in the ratio 3:1:1. The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform. Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below3 were averaged over 5 randomly initialised networks. For each DA, we overgenerated 20 utterances and selected the top 5 realisations after reranking. The BLEU-4 metric was used for the objective evaluation (Papineni et al., 2002). Multiple references for each test DA were obtained by mapping them back to the distinct set of DAs, grouping those delexicalised surface forms that have the same DA specification, and then lexicalising those surface forms back to utterances. In addition, the slot error rate (ERR) as described in Section 3.5 was computed as an auxiliary metric alongside the BLEU score. However, for the experiments it is computed at the corpus level, by averaging slot errors over each of the top 5 realisations in the entire corpus. The trade-off weights α between keyword and key phrase detectors as mentioned i"
D15-1199,D14-1162,0,0.117677,"Missing"
D15-1199,W09-3941,0,0.020353,"planning maps input semantic symbols into an intermediary form representing the utterance, e.g. a tree-like or template structure, then surface realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004). Although statistical sentence planning has been explored previously, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010), these methods still rely on a pre-existing, handcrafted generator. To minimise handcrafting, Stent and Molina (2009) proposed learning sentence planning rules directly from a corpus of utterances labelled with Rhetorical Structure Theory (RST) discourse relations (Mann and Thompson, 1988). However, the required corpus labelling is expensive and additional handcrafting is still needed to map the sentence plan to a valid syntactic form. As noted above, corpus-based NLG aims at learning generation decisions from data with minimal dependence on rules and heuristics. A pioneer in this direction is the class-based n-gram language model (LM) approach proposed by Oh and Rudnicky (2000). Ratnaparkhi (2002) later add"
D15-1199,D14-1074,0,0.0628496,"level. Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies. Sutskever et al. (2011) describes a simple variant of the RNN that can generate meaningful sentences by learning from a character-level corpus. More recently, Karpathy and Fei-Fei (2014) have demonstrated that an RNNLM is capable of generating image descriptions by conditioning the network model on a pre-trained convolutional image feature representation. Zhang and Lapata (2014) also describes interesting work using RNNs to generate 1712 Chinese poetry. A forerunner of the system presented here is described in Wen et al. (2015), in which a forward RNN generator, a CNN reranker, and a backward RNN reranker are trained jointly to generate utterances. Although the system was easy to train and extend to other domains, a heuristic gate control was needed to ensure that all of the attribute-value information in the system’s response was accurately captured by the generated utterance. Furthermore, the handling of unusual slot-value pairs by the CNN reranker was rather arbit"
D15-1199,P04-1011,0,0.63393,"(or template-based) approach (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011). Despite its robustness and adequacy, the frequent repetition of identical, rather stilted, output forms make talking to a rule-based generator rather tedious. Furthermore, the approach does not easily scale to large open domain systems(Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 2014). Hence approaches to NLG are required that can be readily scaled whilst meeting the above requirements. The trainable generator approach exemplified by the HALOGEN (Langkilde and Knight, 1998) and SPaRKy system (Stent et al., 2004) provides a possible way forward. These systems include specific trainable modules within the generation framework to allow the model to adapt to different domains (Walker et al., 2007), or reproduce certain style (Mairesse and Walker, 2011). However, these approaches still require a handcrafted generator to define the decision space within which statistics can be used for optimisation. The resulting utterances are therefore constrained by the predefined syntax and any domain-specific colloquial responses must be added manually. More recently, corpus-based methods (Oh and Rudnicky, 2000; Maire"
D15-1199,D14-1003,0,0.0241886,"remaining problem in the structure described so far is that the LSTM generator selects words based only on the preceding history, whereas some sentence forms depend on the backward context. Previously, bidirectional networks (Schuster and 1714 Figure 2: The Deep LSTM generator structure by stacking multiple LSTM layers on top of the DA cell. The skip connection was adopted to mitigate the vanishing gradient, while the dropout was applied on dashed connections to prevent co-adaptation and overfitting. Paliwal, 1997) have been shown to be effective for sequential problems (Graves et al., 2013a; Sundermeyer et al., 2014). However, applying a bidirectional network directly in the SC-LSTM generator is not straightforward since the generation process is sequential in time. Hence instead of integrating the bidirectional information into one network, we trained another SC-LSTM from backward context to choose best candidates from the forward generator outputs. In our experiments, we also found that by tying the keyword detector weights Wwr (see Equations 7 and 12) of both the forward and backward networks together makes the generator less sensitive to random initialisation. 3.4 Training The forward generator and th"
D15-1199,W15-4639,1,0.451846,"Missing"
D15-1199,E09-1078,0,\N,Missing
D15-1199,C98-1112,0,\N,Missing
D16-1233,D14-1179,0,0.0476362,"Missing"
D16-1233,W14-4340,1,0.927408,"ns and alleviates the vanishing gradient problem; (3) it appears to learn transparent and interpretable subspaces of the conditioning vector. 2 Related Work Machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gaˇsi´c et al., 2013). In order to make RL tractable, the state and action space must be carefully designed (Young et al., 2010) and the understanding (Henderson et al., 2014; Mrkˇsi´c et al., 2015) and generation (Wen et al., 2015b; Wen et al., 2016b) modules were assumed available or trained standalone on supervised corpora. Due to the underlying hand-coded semantic representation (Traum, 1999), the conversation is far from natural and the comprehension capability is limited. This motivates the use of neural networks to model dialogues from end to end as a conditional generation problem. Interest in generating natural language using NNs can be attributed to the success of RNN LMs for large vocabulary speech recognition (Mikolov et al., 2010; Mikolov et al., 2011"
D16-1233,P11-1055,0,0.0137807,"collected using Amazon Mechanical Turk. An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks. Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database. It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers. Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention. Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009). Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example. In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which companion objectives are generated from intermediary layer"
D16-1233,N16-1014,0,0.0318639,"t al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy. To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by We"
D16-1233,P16-1094,0,0.0186793,"t al., 2015; Hermann et al., 2015; Ling et al., 2016) have been shown to be very effective improving performance using a dynamic source aggregation strategy. To model dialogue as conditional generation, a sequence-to-sequence learning (Sutskever et al., 2014) framework has been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by We"
D16-1233,P16-1057,0,0.0393118,"Missing"
D16-1233,W15-4640,0,0.0167479,"been adopted. Vinyals and Le (2015) trained the same model on several conversation datasets and showed that the model can generate plausible conversations. However, Serban et al. (2015b) discovered that the majority of the generated responses are generic due to the maximum likelihood criterion, which was latter addressed by Li et al. (2016a) using a maximum mutual information decoding strategy. Furthermore, the lack of a consistent system persona was also studied in Li et al. (2016b). Despite its demonstrated potential, a major barrier for this line of research is data collection. Many works (Lowe et al., 2015; Serban et al., 2015a; Dodge et al., 2016) have investigated conversation datasets for developing chat bot or QA-like general purpose conversation agents. However, collecting data to develop goal oriented dialogue systems that can help users to complete a task in a specific domain remains difficult. In a recent work by Wen et al. (2016a), this problem was addressed by designing an online, parallel version of Wizard-of-Oz data collection (Kelley, 1984) which allows large scale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk. An NNbased dialogue model was also"
D16-1233,N16-1086,0,0.0998745,"oviding both model interpretability and better performance. Thirdly, snapshot learning leads to consistent performance improvements independent of which architecture is used. 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015). Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a)"
D16-1233,P09-1113,0,0.0102347,"ale and cheap in-domain conversation data to be collected using Amazon Mechanical Turk. An NNbased dialogue model was also proposed to learn from the collected dataset and was shown to be able to assist human subjects to complete specific tasks. Snapshot learning can be viewed as a special form of weak supervision (also known as distant- or self supervision) (Craven and Kumlien, 1999; Snow et al., 2004), in which supervision signals are heuristically labelled by matching unlabelled corpora with entities or attributes in a structured database. It has been widely applied to relation extraction (Mintz et al., 2009) and information extraction (Hoffmann et al., 2011) in which facts from a knowledge base (e.g. Freebase) were used as objectives to train classifiers. Recently, self supervision was also used in memory networks (Hill et al., 2016) to improve the discriminative power of memory attention. Conceptually, snapshot learning is related to curriculum learning (Bengio et al., 2009). Instead of learning easier examples before difficult ones, snapshot learning creates an easier target for each example. In practice, snapshot learning is similar to deeply supervised nets (Lee et al., 2015) in which compani"
D16-1233,P15-2130,1,0.896091,"Missing"
D16-1233,P02-1040,0,0.0983833,"ies, we decode all the trained models with the average log probability of tokens in the sentence. We applied beam search with a beamwidth equal to 10, the search stops when an end-of-sentence token is generated. In order to consider language variability, we ran decoding until 5 candidates were obtained and performed evaluation on them. Metrics We compared models trained with different recipes by performing a corpus-based evaluation in which the model is used to predict each system response in the held-out test set. Three evaluation metrics were used: BLEU score (on top-1 and top5 candidates) (Papineni et al., 2002), slot matching rate and objective task success rate (Su et al., 2015). The dialogue is marked as successful if both: (1) the offered entity matches the task that was specified to the user, and (2) the system answered all the associated information requests (e.g. what is the address?) from the user. The slot matching rate is the percentage of delexicalised tokens (e.g. [s.food] and [v.area]1 ) appear in the candidate also appear in the (a) Hybrid LSTM w/o snapshot learning (b) Hybrid LSTM w/ snapshot learning Figure 3: Learned attention heat maps over trackers. The first three columns in each"
D16-1233,P15-1152,0,0.033149,"provements independent of which architecture is used. 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to be very effective in tackling a number of real world problems, such as machine translation (MT) (Cho et al., 2014) and image caption generation (Karpathy and Fei-Fei, 2015). Recently, RNNs were applied to task of generating sentences from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks. Their"
D16-1233,W15-4639,1,0.905933,"Missing"
D16-1233,D15-1199,1,0.906064,"Missing"
D16-1233,N16-1015,1,0.901342,"Missing"
D16-1233,W16-0105,0,0.0581401,"s from an explicit semantic representation (Wen et al., 2015a). Attention-based methods (Mei et al., 2016) and Long Short-term Memory (LSTM)-like (Hochreiter Neural conversational agents (Vinyals and Le, 2015; Shang et al., 2015) are direct extensions of the sequence-to-sequence model (Sutskever et al., 2014) in which a conversation is cast as a source to target transduction problem. However, these models are still far from real world applications because they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2016) and aggregate useful information into their responses. Recent work by Wen et al. (2016a), however, proposed an end-to-end trainable neural dialogue system that can assist users to complete specific tasks. Their system used both distributed and symbolic representations to capture user intents, and these collectively condition a NN language generator to generate system responses. Due to the diversity of the conditioning information sources, the best way to represent and combine them is non-trivial. 2153 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, page"
E17-1042,W14-4340,1,0.407798,"Introduction Building a task-oriented dialogue system such as a hotel booking or a technical support service is difficult because it is application-specific and there is usually limited availability of training data. To mitigate this problem, recent machine learning approaches to task-oriented dialogue system design have cast the problem as a partially observable Markov Decision Process (POMDP) (Young et al., 2013) with the aim of using reinforcement learning (RL) to train dialogue policies online through interactions with real users (Gaši´c et al., 2013). However, the language understanding (Henderson et al., 2014; Yao et al., 2014) and language generation (Wen et al., 2015b; Wen et al., 2016) modules still rely on supervised learning and therefore need corpora to train on. Furthermore, to make RL tractable, the state and action space must be carefully designed (Young et al., 2013; Young et al., 2010), which may restrict the expressive power and learnability of the model. Also, the reward functions needed to train such models are difficult to design and hard to measure at run-time (Su et al., 2015; Su et al., 2016). At the other end of the spectrum, sequence to sequence learning (Sutskever et al., 2014"
E17-1042,P82-1020,0,0.852845,"Missing"
E17-1042,P15-1152,0,0.0310789,"d therefore need corpora to train on. Furthermore, to make RL tractable, the state and action space must be carefully designed (Young et al., 2013; Young et al., 2010), which may restrict the expressive power and learnability of the model. Also, the reward functions needed to train such models are difficult to design and hard to measure at run-time (Su et al., 2015; Su et al., 2016). At the other end of the spectrum, sequence to sequence learning (Sutskever et al., 2014) has inspired several efforts to build end-to-end trainable, non-task-oriented conversational systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015b). This family of approaches treats dialogue as a source to target sequence transduction problem, applying an encoder network (Cho et al., 2014) to encode a user query into a distributed vector representing its semantics, which then conditions a decoder network to generate each system response. These models typically require a large amount of data to train. They allow the creation of effective chatbot type systems but they lack any capability for supporting domain specific tasks, for example, being able to interact with databases (Sukhbaatar et al., 2015; Yin et al., 2015"
E17-1042,P16-1230,1,0.812856,"Missing"
E17-1042,W15-4639,1,0.762536,"Missing"
E17-1042,D15-1199,1,0.0638233,"Missing"
E17-1042,N16-1015,1,0.0427593,"Missing"
J14-4003,D10-1049,0,0.303619,"Missing"
J14-4003,C00-1007,0,0.0174548,"nt, and it was successfully ported to a specific dialogue system domain (Chambers and Allen 2004). However, its performance depends largely on the granularity of the underlying meaning representation, which typically includes syntactic and lexical information. A major issue with data-driven NLG systems is that collecting fine-grained semantic annotations requires a large amount of time and expertise. For most domains, handcrafting templates remains a more cost-effective solution. More recent work has investigated other types of reranking models, such as hierarchical syntactic language models (Bangalore and Rambow 2000), discriminative models trained to replicate user ratings of utterance quality (Walker, Rambow, and Rogati 2002), or language models trained on speaker-specific corpora to model linguistic alignment (Isard, Brockmann, and Oberlander 2006). However, a major drawback of the utterancelevel overgenerate and rank approach is its inherent computational cost. In contrast, this article proposes a method in which local overgeneration can be made tractable through beam pruning. A second line of research has focused on introducing statistics at the generationdecision level by training models that find th"
J14-4003,P05-1074,0,0.0185038,"ue systems in which repetitions are signaled (e.g., as I said before), even though that preference was not significant (Foster and White 2005). However, we do not know of any research applying statistical paraphrasing techniques to dialogue. Most research on paraphrasing has focused on unsupervised techniques for extracting paraphrases from a corpus of written text. Proposed techniques learn to identify phrase templates, which tend to have the same arguments in a monolingual corpus (Lin and Pantel 2001), or to detect variations between translations of the same text (Barzilay and McKeown 2001; Bannard and Callison-Burch 2005). Although these methods could be used to enrich an existing generator, they do not model semantics; hence they cannot be applied directly to NLG. Statistical reranking models have been used for over a decade for language generation (Langkilde and Knight 1998); however, we do not know of any evaluation of their paraphrasing power. Whereas linguistic variation is typically ignored in NLG systems, a recent line of research has started investigating how to control a generator to convey a specific style—for example, to generate language with a target linguistic genre (Paiva and Evans 2005), to con"
J14-4003,P01-1008,0,0.0181017,"ed that users prefer dialogue systems in which repetitions are signaled (e.g., as I said before), even though that preference was not significant (Foster and White 2005). However, we do not know of any research applying statistical paraphrasing techniques to dialogue. Most research on paraphrasing has focused on unsupervised techniques for extracting paraphrases from a corpus of written text. Proposed techniques learn to identify phrase templates, which tend to have the same arguments in a monolingual corpus (Lin and Pantel 2001), or to detect variations between translations of the same text (Barzilay and McKeown 2001; Bannard and Callison-Burch 2005). Although these methods could be used to enrich an existing generator, they do not model semantics; hence they cannot be applied directly to NLG. Statistical reranking models have been used for over a decade for language generation (Langkilde and Knight 1998); however, we do not know of any evaluation of their paraphrasing power. Whereas linguistic variation is typically ignored in NLG systems, a recent line of research has started investigating how to control a generator to convey a specific style—for example, to generate language with a target linguistic ge"
J14-4003,N03-2002,0,0.313754,"owledge about what constitutes a unit of meaning; namely, contiguous words belonging to the same semantic stack are modeled as an atomic observation unit or phrase.2 In contrast with word-level language models, a major advantage of phrase-based generation models is that they can model long-range dependencies and domain-specific idiomatic phrases with fewer parameters. 4. FLM-Based Statistical NLG In order to find the optimal stack and realization phrase sequences given an input dialogue act, we cast the generation task as a search over Factored Language Models (FLMs), which were introduced by Bilmes and Kirchhoff (2003). FLMs extend traditional language models by allowing predicted variables to be conditioned on different utterance contexts, depending on whether they were sufficiently observed in the training data. This approach is equivalent to a dynamic Bayesian network in which the probability of child nodes are estimated by interpolating over different parent nodes. Dynamic Bayesian networks have been used successfully for speech recognition, natural language understanding, dialogue management, and text-to-speech synthesis (Rabiner 1989; Tokuda et al. 2000; He and Young 2005; Lef`evre 2006; Thomson and Y"
J14-4003,P06-1130,0,0.0649984,"Missing"
J14-4003,W04-2302,0,0.0269382,"ne of the last areas of computational linguistics to embrace statistical methods, perhaps because of the difficulty of collecting semantically annotated corpora. Over the past decade, statistical NLG has followed two lines of research. The first, pioneered by Langkilde and Knight (1998), introduces statistics in the generation process by training a model that reranks candidate outputs of a handcrafted generator. Their HAL OGEN system uses an n-gram language model trained on news articles. HAL OGEN is thus domain-independent, and it was successfully ported to a specific dialogue system domain (Chambers and Allen 2004). However, its performance depends largely on the granularity of the underlying meaning representation, which typically includes syntactic and lexical information. A major issue with data-driven NLG systems is that collecting fine-grained semantic annotations requires a large amount of time and expertise. For most domains, handcrafting templates remains a more cost-effective solution. More recent work has investigated other types of reranking models, such as hierarchical syntactic language models (Bangalore and Rambow 2000), discriminative models trained to replicate user ratings of utterance"
J14-4003,W02-1001,0,0.126189,"once and for all regardless of the input. This section therefore investigates whether performance can be improved through discriminative training, by rescoring the list of candidate semantic stack and realization sequences produced by the FLMs based on binary classification models predicting whether each candidate sequence is a valid paraphrase. We propose a training method inspired by Collins’ work on discriminative reranking for part-of-speech tagging and syntactic parsing, which uses the structured perceptron on-line algorithm to learn to rerank the output of a generatively trained model (Collins 2002a, 2002b; Collins and Roark 2004). The structured perceptron algorithm learns a linear discriminant function of the features Φ(x, y) of both the input structure x and the output structure y (e.g., semantic stack and realization phrase sequences, respectively) by iteratively updating its feature weights α each time it wrongly predicts a training example. Each update makes the weight vector closer to the features of the training example, and further away from the incorrect prediction. A crucial point is that each prediction requires finding the output z that maximizes the discriminant function g"
J14-4003,P04-1015,0,0.0361564,"rdless of the input. This section therefore investigates whether performance can be improved through discriminative training, by rescoring the list of candidate semantic stack and realization sequences produced by the FLMs based on binary classification models predicting whether each candidate sequence is a valid paraphrase. We propose a training method inspired by Collins’ work on discriminative reranking for part-of-speech tagging and syntactic parsing, which uses the structured perceptron on-line algorithm to learn to rerank the output of a generatively trained model (Collins 2002a, 2002b; Collins and Roark 2004). The structured perceptron algorithm learns a linear discriminant function of the features Φ(x, y) of both the input structure x and the output structure y (e.g., semantic stack and realization phrase sequences, respectively) by iteratively updating its feature weights α each time it wrongly predicts a training example. Each update makes the weight vector closer to the features of the training example, and further away from the incorrect prediction. A crucial point is that each prediction requires finding the output z that maximizes the discriminant function given the input x. As a Viterbi se"
J14-4003,P08-1022,0,0.0616781,"Missing"
J14-4003,W06-1405,0,0.068263,"Missing"
J14-4003,P13-1138,0,0.138554,"Missing"
J14-4003,P12-1039,0,0.00999464,"ation. This approach offers the benefit of allowing predictions to be made given generation decisions that are arbitrarily far in the past. However, long-range feature dependencies make a Viterbi search intractable, hence the authors use a greedy search, which produces state-ofthe-art results on the R OBOCUP data set and two weather domains. More recently, Kondadadi, Howald, and Schilder (2013) also decouple the NLG task as a template extraction and ranking problem, and show that an SVM reranker can produce outputs comparable to human-authored texts for weather reports and short biographies.1 Konstas and Lapata (2012) jointly model content selection and surface realization by training a forest of PCFGs expressing the relation between records, fields, and words. A Viterbi search is used to find the optimal derivations at generation time; however, the PCFG weights are rescored using an averaged structured perceptron using both content selection and lexical features. The authors show that their approach outperforms Angeli, Liang, & Klein’s (2010) method on the air transport query domain (ATIS data set). This article evaluates the same averaged structured perceptron algorithm within the B AGEL framework (see S"
J14-4003,P98-1116,0,0.896886,". E-mail: sjy@eng.cam.ac.uk. Submission received: 12 June 2011; revised version received: 12 November 2013; accepted for publication: 21 December 2013. doi:10.1162/COLI a 00199 © 2014 Association for Computational Linguistics Computational Linguistics Volume 40, Number 4 1. Introduction The field of natural language generation (NLG) was one of the last areas of computational linguistics to embrace statistical methods, perhaps because of the difficulty of collecting semantically annotated corpora. Over the past decade, statistical NLG has followed two lines of research. The first, pioneered by Langkilde and Knight (1998), introduces statistics in the generation process by training a model that reranks candidate outputs of a handcrafted generator. Their HAL OGEN system uses an n-gram language model trained on news articles. HAL OGEN is thus domain-independent, and it was successfully ported to a specific dialogue system domain (Chambers and Allen 2004). However, its performance depends largely on the granularity of the underlying meaning representation, which typically includes syntactic and lexical information. A major issue with data-driven NLG systems is that collecting fine-grained semantic annotations req"
J14-4003,W02-2103,0,0.041252,"ts in the training data, p(rt |lt−1 , rt−2 ) is likely to be preferred over p(lt−1 , rt−1 ) during reranking, for example, giving a large probability of rt =‘food’ if rt−2 =‘serves’ and lt−1 =inform(food(SOMETHING)). 5. Stochastic Paraphrase Generation Because a dialogue act can typically be conveyed in a large number of ways, it seems natural to model the NLG task as a one-to-many mapping. However, previous work on statistical NLG has typically focused on evaluating the top ranked utterance, without evaluating whether the generator can produce paraphrases matching a reference paraphrase set (Langkilde-Geary 2002; Reiter and Belz 2009). Although single-output NLG is acceptable for one-off text generation, NLG systems used within long-term human– computer interaction are likely to benefit from modeling the paraphrasal variation found in human language (e.g., by reducing the repetitiveness of dialogue system utterances or by improving the chances of successful dialogue clarifications). However, learning to map a single input to a set of surface realizations is a nontrivial machine learning problem. One advantage of casting the NLG task as search over FLMs is that the final n-best list of surface realiza"
J14-4003,A97-1039,0,0.0822388,"Missing"
J14-4003,D09-1042,0,0.0331658,"Missing"
J14-4003,P10-1157,1,0.798272,"Missing"
J14-4003,P08-1020,1,0.62977,"ned on speaker-specific corpora to model linguistic alignment (Isard, Brockmann, and Oberlander 2006). However, a major drawback of the utterancelevel overgenerate and rank approach is its inherent computational cost. In contrast, this article proposes a method in which local overgeneration can be made tractable through beam pruning. A second line of research has focused on introducing statistics at the generationdecision level by training models that find the set of generation parameters maximizing an objective function, for example, producing a target linguistic style (Paiva and Evans 2005; Mairesse and Walker 2008), generating the most likely context-free derivations given a corpus (Belz 2008), or maximizing the expected reward using reinforcement learning (Rieser and Lemon 2010). Although such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. Recently, research has therefore focused on reducing the amount of handcrafting required by learning to infer generation rules from data (see Section 2). This article presents B AGEL, an NLG"
J14-4003,J11-3002,1,0.572161,"Missing"
J14-4003,W05-1510,0,0.060478,"Missing"
J14-4003,P06-1140,0,0.0265877,"s presented here can also be used for stylistic control by including stylistic elements in our stack-based semantic representation; however, we leave this to future work. Another line of work has used NLG paraphrase mechanisms to show that jointly optimizing NLG and speech synthesis can improve human perceptions of voice quality. This was achieved by finding the candidate paraphrase yielding the lowest speech unit concatenation cost using weighted finite state transducers (Bulyko and Ostendorf 2002) or by using a discriminative reranker trained to predict human judgments of synthesis quality (Nakatsu and White 2006). Similarly, Stone et al. (2004) propose a method using dynamic programming for simultaneously optimizing NLG, speech synthesis, and gesture in animated characters. Although all three approaches learn the paraphrase selection step from data, they rely on handcrafted NLG for producing candidates. Hence future work should investigate whether voice quality could also be improved by composing the n-best paraphrases generated by B AGEL with a prosodic reranker. 3. Phrase-Based Generation from Semantic Stacks B AGEL uses a stack-based semantic representation to constrain the sequence of semantic con"
J14-4003,J03-1002,0,0.0170069,"mance with O&R’s utterance class LM approach, and discusses differences between the two techniques. Data-driven NLG research has also been inspired by research on semantic parsing and machine translation. The WASP−1 generator combines a language model with an inverted synchronous context-free grammar parsing model, effectively casting the generation task as a translation problem from a meaning representation to natural language (Wong and Mooney 2007). WASP−1 relies on G IZA ++ to align utterances with 765 Computational Linguistics Volume 40, Number 4 derivations of the meaning representation (Och and Ney 2003). Although early experiments showed that G IZA ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalization performance of synchronous context-free grammars in a dialogue system domain. Lu, Ng, and Lee (2009) show that Tree Conditional Random Fields (CRFs) outperform WASP−1 and their own inverted semantic parser, based on automated evaluation metrics, although their system remains to be evaluated by human judges (Lu, Ng, and Lee 2009). Similarly to the perceptron reranking approach presented here, T"
J14-4003,P05-1008,0,0.200979,"r language models trained on speaker-specific corpora to model linguistic alignment (Isard, Brockmann, and Oberlander 2006). However, a major drawback of the utterancelevel overgenerate and rank approach is its inherent computational cost. In contrast, this article proposes a method in which local overgeneration can be made tractable through beam pruning. A second line of research has focused on introducing statistics at the generationdecision level by training models that find the set of generation parameters maximizing an objective function, for example, producing a target linguistic style (Paiva and Evans 2005; Mairesse and Walker 2008), generating the most likely context-free derivations given a corpus (Belz 2008), or maximizing the expected reward using reinforcement learning (Rieser and Lemon 2010). Although such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. Recently, research has therefore focused on reducing the amount of handcrafting required by learning to infer generation rules from data (see Section 2). This arti"
J14-4003,P02-1040,0,0.0925667,"tail of low-probability utterances, we only consider utterances whose probability lies within a selection beam relative to the probability first-best utterance p1 ; that is, only the utterances generated with a probability above pmin = p1 · (1 − selection beam) are kept. The top utterances are typically grammatical and natural; however, determining a cut-off threshold that captures some of the linguistic variation found in the data without introducing disfluencies is a nontrivial problem. Because many system acts are associated with multiple reference paraphrases in our data, the BLEU score (Papineni et al. 2002) can be used to tune the threshold value. BLEU is a corpus-level metric that is typically used to evaluate a test corpus against a set of reference paraphrases. In order to evaluate the worth of the predicted set of utterances, each utterance within the selection beam is considered as part of the test corpus, thus favoring models generating multiple utterances matching any of the reference paraphrases rather than a single utterance. Figure 7(a) shows the BLEU score of paraphrase sets generated using different n-best selection beams, averaged over a 10-fold cross-validation over 1,646 distinct"
J14-4003,J09-4008,0,0.0467113,"a, p(rt |lt−1 , rt−2 ) is likely to be preferred over p(lt−1 , rt−1 ) during reranking, for example, giving a large probability of rt =‘food’ if rt−2 =‘serves’ and lt−1 =inform(food(SOMETHING)). 5. Stochastic Paraphrase Generation Because a dialogue act can typically be conveyed in a large number of ways, it seems natural to model the NLG task as a one-to-many mapping. However, previous work on statistical NLG has typically focused on evaluating the top ranked utterance, without evaluating whether the generator can produce paraphrases matching a reference paraphrase set (Langkilde-Geary 2002; Reiter and Belz 2009). Although single-output NLG is acceptable for one-off text generation, NLG systems used within long-term human– computer interaction are likely to benefit from modeling the paraphrasal variation found in human language (e.g., by reducing the repetitiveness of dialogue system utterances or by improving the chances of successful dialogue clarifications). However, learning to map a single input to a set of surface realizations is a nontrivial machine learning problem. One advantage of casting the NLG task as search over FLMs is that the final n-best list of surface realizations can be used to co"
J14-4003,N07-2038,1,0.653616,"ant), area(riverside), food(Indian), near(The Red Lion)). The order of the constraints in the description was randomized to reduce the effect of priming. The annotators were then asked to align the attributes (e.g., Indicate the region of the utterance related to the concept ‘area’), and the attribute values (e.g., Indicate only the words related to the concept ‘riverside’). The total input semantic space is approximated by the set of system dialogue acts produced during 250,000 simulated dialogues between our statistical dialogue manager (Young et al. 2010) and an agendabased user simulator (Schatzmann et al. 2007). In order to build the training set, we started with a set of utterances collected for a small subset of our domain (Mairesse et al. 2010). We then ordered the dialogue acts based on their frequency of occurrence in the simulated dialogues. In order to ensure that each semantic stack defined by the domain ontology occurs at least once in our data, we expanded our training set by iteratively adding the most frequent unseen act which contains an unseen mandatory semantic stack. The resulting data set consists of 1,646 unique dialogue acts after replacing nonenumerable values by a generic symbol"
J14-4003,W09-3941,0,0.576198,"h, without any handcrafting beyond the definition of the semantic annotations. In order to reduce complexity, previous work has split the NLG task into two phases: (a) sentence planning and (b) surface realization. The sentence planning phase maps input semantic symbols to an intermediary tree-like or template structure representing the utterance; then the surface realization phase converts it into the final text. As developing a sentence planner capable of overgeneration typically requires a substantial amount of handcrafting (Walker, Rambow, and Rogati 2002; Stent, Prasad, and Walker 2004), Stent and Molina (2009) have proposed a method that learns sentence planning rules from a corpus of utterances labeled with Rhetorical Structure Theory (RST) discourse relations (Mann and Thompson 1988). Although additional handcrafting is needed to map the sentence plan to a valid syntactic form by aggregating the syntactic structures of the relations arguments, we believe RST offers a promising framework for improving the expressiveness of statistical generators. Section 8 discusses how B AGEL’s expressiveness could be improved by including RST relations. Language models (LMs) have previously been used for languag"
J14-4003,P04-1011,0,0.730094,"Missing"
J14-4003,N01-1001,0,0.126234,"ve been used for surface realization within the OpenCCG framework (White, Rajkumar, and Martin 2007; Espinosa, White, and Mehay 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (Nakanishi, Miyao, & Tsujii 2005; Cahill and 1 These papers were published after the main B AGEL development and thus no detailed comparisons are offered in this article. 766 Mairesse and Young Stochastic Language Generation in Dialogue Using FLMs van Genabith 2006; White, Rajkumar, and Martin 2007), as well as from semantically annotated treebanks (Varges and Mellish 2001). Because manual syntactic annotation is costly and syntactic parsers do not necessarily perform well at labeling spoken language utterances, the present work focuses on the generation of surface forms directly from semantic concepts. Future work should investigate whether explicit syntactic modeling improves performance (e.g., by conditioning the realization FLMs on part-of-speech information). Previous studies have shown that paraphrasing improves performance in automated tutoring dialogues (Pon-Barry et al. 2006), and suggested that users prefer dialogue systems in which repetitions are sig"
J14-4003,2007.mtsummit-ucnlg.4,0,0.0613581,"Missing"
J14-4003,N07-1022,0,0.060888,"ing to a small set of post-processing rules in order to facilitate the development of a dialogue system’s NLG component. Section 7.1 therefore compares B AGEL’s performance with O&R’s utterance class LM approach, and discusses differences between the two techniques. Data-driven NLG research has also been inspired by research on semantic parsing and machine translation. The WASP−1 generator combines a language model with an inverted synchronous context-free grammar parsing model, effectively casting the generation task as a translation problem from a meaning representation to natural language (Wong and Mooney 2007). WASP−1 relies on G IZA ++ to align utterances with 765 Computational Linguistics Volume 40, Number 4 derivations of the meaning representation (Och and Ney 2003). Although early experiments showed that G IZA ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalization performance of synchronous context-free grammars in a dialogue system domain. Lu, Ng, and Lee (2009) show that Tree Conditional Random Fields (CRFs) outperform WASP−1 and their own inverted semantic parser, based on automated evaluat"
J14-4003,E09-1078,0,\N,Missing
J14-4003,C98-1112,0,\N,Missing
J14-4003,P05-3012,0,\N,Missing
J14-4003,P02-1062,0,\N,Missing
L16-1287,P07-1124,0,0.0380372,"narratives. Section 3. describes the dataset that we have collated for our experiments. We explain our process of manual coding in section 4. and the ML models in section 5. Results and discussion appear in section 6. and we conclude in section 7. 2. Related Work There has been growing interest in recent years in the application of Natural Language Processing (NLP) and text analysis techniques in the financial domain. One of the largest areas of recent research has been the application of sentiment analysis to stock–related tweets with the intention of predicting the stock market performance (Devitt and Ahmad, 2007; Schumaker, 2010; Im et al., 2013; Ferreira et al., 2014; Neuenschwander et al., 2014). Some studies have taken this a step further by trying to explain the impact on investors’ behaviour from negative reports in the financial media of corporate actions (Moniz and de Jong, 2014). The work by Shuyu (2016) describes the use of computer techniques to measure causal reasoning in financial earningsrelated outcomes of a large sample of 10-K (annual reports) filings of US firms. Their work showed positive and sig1820 nificant association between firms’ causal reasoning intensity and other analyst ea"
L16-1287,N09-1031,0,0.121834,"rge sample of 10-K (annual reports) filings of US firms. Their work showed positive and sig1820 nificant association between firms’ causal reasoning intensity and other analyst earning and forecasts. In their work they focused on using non-language dependent approaches by applying simple text analysis techniques and frequency count using PERL. Whitelaw and Patrick (2004) and Goel and Gangolly (2012) have investigated systemic and other predictive features for the task of identifying financial scam documents. NLP researchers have also attempted to develop empirical techniques for ranking risk (Kogan et al., 2009; Tsai and Wang, 2012) particularly in the American context. In the Accounting and Finance literature, there is an increasing body of work using basic word-list and ML approaches to examine the information content of forward-looking statements (e.g., Li (Li, 2010)) and other work has looked at the relationship of optimistic versus mild statements in the context of positive and negative financial performance (Chen et al., 2013). However, there is no large-scale empirical work on detecting and measuring tone and attribution in financial narratives. In terms of novelty in the ML experiments over"
L16-1287,W02-1011,0,0.0159002,"+ + Key + POST + Sem POST SMO 76.3 76.2 76.3 76.3 LR 79.1 79.1 79.7 76.3 RF 76.9 76.1 78.3 75.5 NB 69.9 72.8 79.2 75.9 Table 6: Most Frequent Class Results Table 3: Effect of attribution’s tone on attribution could help in detecting attribution’s tone. In addition, the results show that part of speech tagging helped in slightly enhancing the detection process, this shows that singular and plural pronouns in addition to past and present verbs and the shift between them could help in telling when there exist a positive or negative internal or external attribution. This aligns with Pang et al. (Pang et al., 2002) where using POS tends to improve accuracy for a NB classifier. The use of singular and plural pronouns could be considered as an indicator of attribution’s positivity where a company usually tends to speak positively when discussing attribution by its own management. ML Att + Key + POST SMO 75.7 LR 76.7 RF 74.0 NB 69.1 Att Key + Att + POST 75.7 77.0 73.8 70.4 75.8 77.7 76.6 74.6 Att Sem Accuracy 71.0 56.8 59.9 + We also ran another experiment using Weka’s StringToWordVector unsupervised filter to convert all PEA sentences into vectors of words contained in the sentences. We kept the top 100 w"
L16-1287,W10-0502,0,0.0317338,"escribes the dataset that we have collated for our experiments. We explain our process of manual coding in section 4. and the ML models in section 5. Results and discussion appear in section 6. and we conclude in section 7. 2. Related Work There has been growing interest in recent years in the application of Natural Language Processing (NLP) and text analysis techniques in the financial domain. One of the largest areas of recent research has been the application of sentiment analysis to stock–related tweets with the intention of predicting the stock market performance (Devitt and Ahmad, 2007; Schumaker, 2010; Im et al., 2013; Ferreira et al., 2014; Neuenschwander et al., 2014). Some studies have taken this a step further by trying to explain the impact on investors’ behaviour from negative reports in the financial media of corporate actions (Moniz and de Jong, 2014). The work by Shuyu (2016) describes the use of computer techniques to measure causal reasoning in financial earningsrelated outcomes of a large sample of 10-K (annual reports) filings of US firms. Their work showed positive and sig1820 nificant association between firms’ causal reasoning intensity and other analyst earning and forecas"
L16-1287,C12-3056,0,0.014444,"annual reports) filings of US firms. Their work showed positive and sig1820 nificant association between firms’ causal reasoning intensity and other analyst earning and forecasts. In their work they focused on using non-language dependent approaches by applying simple text analysis techniques and frequency count using PERL. Whitelaw and Patrick (2004) and Goel and Gangolly (2012) have investigated systemic and other predictive features for the task of identifying financial scam documents. NLP researchers have also attempted to develop empirical techniques for ranking risk (Kogan et al., 2009; Tsai and Wang, 2012) particularly in the American context. In the Accounting and Finance literature, there is an increasing body of work using basic word-list and ML approaches to examine the information content of forward-looking statements (e.g., Li (Li, 2010)) and other work has looked at the relationship of optimistic versus mild statements in the context of positive and negative financial performance (Chen et al., 2013). However, there is no large-scale empirical work on detecting and measuring tone and attribution in financial narratives. In terms of novelty in the ML experiments over and above the state of"
L16-1287,U04-1013,0,0.0196724,"investors’ behaviour from negative reports in the financial media of corporate actions (Moniz and de Jong, 2014). The work by Shuyu (2016) describes the use of computer techniques to measure causal reasoning in financial earningsrelated outcomes of a large sample of 10-K (annual reports) filings of US firms. Their work showed positive and sig1820 nificant association between firms’ causal reasoning intensity and other analyst earning and forecasts. In their work they focused on using non-language dependent approaches by applying simple text analysis techniques and frequency count using PERL. Whitelaw and Patrick (2004) and Goel and Gangolly (2012) have investigated systemic and other predictive features for the task of identifying financial scam documents. NLP researchers have also attempted to develop empirical techniques for ranking risk (Kogan et al., 2009; Tsai and Wang, 2012) particularly in the American context. In the Accounting and Finance literature, there is an increasing body of work using basic word-list and ML approaches to examine the information content of forward-looking statements (e.g., Li (Li, 2010)) and other work has looked at the relationship of optimistic versus mild statements in the"
N07-4014,N07-2038,1,0.79795,"27 NAACL HLT Demonstration Program, pages 27–28, c Rochester, New York, USA, April 2007. 2007 Association for Computational Linguistics Figure 1: The HIS Demo System is a Tourist Information application for a fictitious town Figure 2: A system screenshot showing the ranking of competing dialogue state hypotheses state space and online -greedy policy optimisation. While this offers the potential for online adaptation with real users at a later stage, a simulated user is needed to bootstrap the training process. A novel agenda-based simulation technique was used for this step, as described in (Schatzmann et al., 2007). The results demonstrate that POMDPs facilitate design and implementation of spoken dialogue systems, and that the implementation used in the HIS dialogue manager can be scaled to handle real world tasks. The user study results also show that a simulated user can be successfully used to train a POMDP dialogue policy that performs well in experiments with real users. 3 The HIS Demo System The HIS demo system is a prototype application for the Tourist Information domain. Users are assumed to be visiting a fictitious town called “Jasonville” (see Fig. 1) and need to find a suitable hotel, bar or"
N07-4014,W07-0302,1,0.851473,"Missing"
N16-1015,P14-2023,0,0.0784359,"d-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adaptation approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the 120 Proceedings of NAACL-HLT 2016, pages 120–129, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010). Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU score (Auli and Gao, 2014) or Word Error Rate (Kuo et al., 2002), the model can explore its output space and learn to discriminate between good and bad hypotheses. In this paper we show that DT can enable a generator to learn more efficiently when in-domain data is scarce. The paper presents an incremental recipe for training multi-domain language generators based on a purely data-driven, RNN-based generation model. Following a review of related work in section 2, section 3 describes the detailed RNN generator architecture. The data counterfeiting approach for synthesising an in-domain dataset is introduced in section"
N16-1015,D14-1132,0,0.0192427,"et al. (2015) applied curriculum learning to RNNLM adaptation. Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) criterion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed improved performance on an MT task. However, their RNN probabilities only served as input features to a phrase-based MT system. 3 The Neural Language Generator The neural language generation model (Wen et al., 2015a; Wen et al., 2015b) is a RNNLM (Mikolov et al., 2010) augmented with semantic input features such as a dialogue act1 (DA) denoting the required semantics of the generated output. At every time step t, the model consumes the 1-hot representation of both the DA dt and a token wt 2 to update its internal s"
N16-1015,P07-1056,0,0.0619326,", 2007) and mimicking personality traits (Mairesse and Walker, 2011). Lemon (2008) proposed a Reinforcement Learning (RL) framework in which policy and NLG components can be jointly optimised and adapted based on online user feedback. In contrast, Mairesse et al. (2010) has proposed using active learning to mitigate the data sparsity problem when training datadriven NLG systems. Furthermore, Cuayhuitl et al. (2014) trained statistical surface realisers from unlabelled data by an automatic slot labelling technique. In general, feature-based adaptation is perhaps the most widely used technique (Blitzer et al., 2007; Pan and Yang, 2010; Duan et al., 2012). By exploiting correlations and similarities between data points, it has been successfully applied to problems like speaker adaptation (Gauvain and Lee, 1994; Leggetter and Woodland, 1995) and various tasks in natural language processing (Daum´e III, 2009). In contrast, model-based adaptation is particularly useful for language modeling (LM) (Bellegarda, 2004). Mixture-based topic LMs (Gildea and Hofmann, 1999) are widely used in N-gram LMs for domain adaptation. Similar ideas have been applied to applications that require adapting LMs, such as machine"
N16-1015,W02-1001,0,0.0403925,"(Wen et al., 2012). Domain adaptation for Neural Network (NN)based LMs has also been studied in the past. A feature augmented RNNLM was first proposed by Mikolov and Zweig (2012), but later applied to multi-genre broadcast speech recognition (Chen et al., 2015) and personalised language modeling (Wen et al., 2013). These methods are based on finetuning existing network parameters on adaptation data. However, careful regularisation is often necessary (Yu et al., 2013). In a slightly different area, Shi et al. (2015) applied curriculum learning to RNNLM adaptation. Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) criterion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed improved p"
N16-1015,P12-1031,0,0.0504083,"different area, Shi et al. (2015) applied curriculum learning to RNNLM adaptation. Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) criterion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed improved performance on an MT task. However, their RNN probabilities only served as input features to a phrase-based MT system. 3 The Neural Language Generator The neural language generation model (Wen et al., 2015a; Wen et al., 2015b) is a RNNLM (Mikolov et al., 2010) augmented with semantic input features such as a dialogue act1 (DA) denoting the required semantics of the generated output. At every time step t, the model consumes the 1-hot representation of both the DA dt and a token wt 2 to u"
N16-1015,W08-1122,0,0.0473989,"Missing"
N16-1015,W06-1405,0,0.00971362,") are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mair"
N16-1015,W07-0733,0,0.0167372,"10; Duan et al., 2012). By exploiting correlations and similarities between data points, it has been successfully applied to problems like speaker adaptation (Gauvain and Lee, 1994; Leggetter and Woodland, 1995) and various tasks in natural language processing (Daum´e III, 2009). In contrast, model-based adaptation is particularly useful for language modeling (LM) (Bellegarda, 2004). Mixture-based topic LMs (Gildea and Hofmann, 1999) are widely used in N-gram LMs for domain adaptation. Similar ideas have been applied to applications that require adapting LMs, such as machine translation (MT) (Koehn and Schroeder, 2007) and personalised speech recognition (Wen et al., 2012). Domain adaptation for Neural Network (NN)based LMs has also been studied in the past. A feature augmented RNNLM was first proposed by Mikolov and Zweig (2012), but later applied to multi-genre broadcast speech recognition (Chen et al., 2015) and personalised language modeling (Wen et al., 2013). These methods are based on finetuning existing network parameters on adaptation data. However, careful regularisation is often necessary (Yu et al., 2013). In a slightly different area, Shi et al. (2015) applied curriculum learning to RNNLM adapt"
N16-1015,P98-1116,0,0.0477187,"an et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mairesse and Young, 2014) or hand-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adaptation approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the 120 Proceedings of NAACL-HLT 2016, pages 120–129, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010). Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU score (Auli and Gao, 2014) or Word Error Rate (Kuo"
N16-1015,P08-1020,0,0.0479934,"small amount of data is available in the domain. 1 Introduction Modern Spoken Dialogue Systems (SDS) are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation dec"
N16-1015,J11-3002,0,0.0459034,"ilable in the domain. 1 Introduction Modern Spoken Dialogue Systems (SDS) are typically developed according to a well-defined ontology, which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogu"
N16-1015,J14-4003,1,0.577231,"006). Domain adaptation was first addressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) fstructures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phenomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based language generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mairesse and Young, 2014) or hand-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adaptation approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the 120 Proceedings of NAACL-HLT 2016, pages 120–129, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010). Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU"
N16-1015,P10-1157,1,0.916076,"Missing"
N16-1015,P15-2130,1,0.12451,"Missing"
N16-1015,P02-1040,0,0.119975,"the laptop domain and 7K distinct DAs in the TV domain. We then used AMT workers to collect just one realisation for each DA. Since the resulting datasets have a much larger input space but only one training example for each DA, the system must learn partial realisations of concepts and be able to recombine and apply them to unseen DAs. Also note that the number of act types and slots of the new ontology is larger, which makes NLG in both laptop and TV domains much harder. 7 Corpus-based Evaluation We first assess generator performance using two objective evaluation metrics, the BLEU-4 score (Papineni et al., 2002) and slot error rate ERR (Wen et al., 2015b). Slot error rates were calculated by averaging slot errors over each of the top 5 realisations in the entire corpus. We used multiple references to compute the BLEU scores when available (i.e. for the restaurant and hotel domains). In order to better 125 compare results across different methods, we plotted the BLEU and slot error rate curves against different amounts of adaptation data. Note that in the graphs the x-axis is presented on a log-scale. 7.1 Experimental Setup The generators were implemented using the Theano library (Bergstra et al., 201"
N16-1015,P04-1011,0,0.222077,"an thus generate a sequence of tokens by repeatedly sampling the current output distribution to obtain the next input token until an end-ofsentence sign is generated. Finally, the generated sequence is lexicalised3 to form the target utterance. The Semantically Conditioned Long Short-term Memory Network (SC-LSTM) (Wen et al., 2015b) is a specialised extension of the LSTM network (Hochreiter and Schmidhuber, 1997) for language generation which has previously been shown capable of learning generation decisions from paired DA-utterances end-to-end without a modular pipeline (Walker et al., 2002; Stent et al., 2004). Like LSTM, SC-LSTM relies on a vector of memory cells ct ∈ Rn and a set of elementwise multiplication gates to control how information is stored, forgotten, and exploited inside the network. The SCLSTM architecture used in this paper is defined by the following equations,       A combination of an action type and a set of slot-value pairs. e.g. inform(name=”Seven days”,food=”chinese”) 2 We use token instead of word because our model operates on text for which slot values are replaced by their corresponding slot tokens. We call this procedure delexicalisation. 3 The process of replacing"
N16-1015,H94-1039,0,0.081629,"Missing"
N16-1015,W15-4639,1,0.663718,"Missing"
N16-1015,D15-1199,1,0.528094,"Missing"
N16-1015,C98-1112,0,\N,Missing
N16-1015,P07-1033,0,\N,Missing
N16-1018,P14-2131,0,0.0264055,"oVe vectors before and after counter-fitting Introduction Many popular methods that induce representations for words rely on the distributional hypothesis – the assumption that semantically similar or related words appear in similar contexts. This hypothesis supports unsupervised learning of meaningful word rep´ resentations from large corpora (Curran, 2003; O S´eaghdha and Korhonen, 2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as east and west or expensive and inexpensive appear in near-identical contexts, which means that distributional models produce very similar word vectors for such words. Examples of suc"
N16-1018,P08-1118,0,0.0153105,"Missing"
N16-1018,P15-2076,0,0.038284,"Missing"
N16-1018,N15-1184,0,0.19487,"pages 142–148, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics (e.g. cheaper and pricey) is critical for the performance of dialogue systems. In particular, a dialogue system can be led seriously astray by false synonyms. We propose a method that addresses these two drawbacks by using synonymy and antonymy relations drawn from either a general lexical resource or an application-specific ontology to fine-tune distributional word vectors. Our method, which we term counter-fitting, is a lightweight post-processing procedure in the spirit of retrofitting (Faruqui et al., 2015). The second row of Table 1 illustrates the results of counter-fitting: the nearest neighbours capture true similarity much more intuitively than the original GloVe vectors. The procedure improves word vector quality regardless of the initial word vectors provided as input.1 By applying counter-fitting to the Paragram-SL999 word vectors provided by Wieting et al. (2015), we achieve new state-of-the-art performance on SimLex-999, a dataset designed to measure how well different models judge semantic similarity between words (Hill et al., 2014b). We also show that the counter-fitting method can"
N16-1018,N13-1092,0,0.0298598,"Missing"
N16-1018,D12-1057,0,0.0473899,"Missing"
N16-1018,W14-4337,1,0.107819,"ent descent (SGD) for 20 epochs. An end-to-end run of counter-fitting takes less than two minutes on a laptop with four CPUs. 3.1 Injecting Dialogue Domain Ontologies into Vector Space Representations Dialogue state tracking (DST) models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value pairs such as [food: Indian] or [parking: allowed]. The set of slots S and the set of values Vs for each slot make up the ontology of a dialogue domain. In this paper we adopt the recurrent neural network (RNN) framework for tracking suggested in (Henderson et al., 2014d; Henderson et al., 2014c; Mrkˇsi´c et al., 2015). Rather than using a spoken language understanding (SLU) decoder to convert user utterances into meaning representations, this model operates directly on the n-gram features extracted from the automated speech recognition (ASR) hypotheses. A drawback of this approach is that the RNN model can only perform exact string matching to detect the slot names and values mentioned by the user. It cannot recognise synonymous words such as pricey and expensive, or even subtle morphological variations such as moderate and moderately. A simple way to mitig"
N16-1018,W14-4340,1,0.930369,"ent descent (SGD) for 20 epochs. An end-to-end run of counter-fitting takes less than two minutes on a laptop with four CPUs. 3.1 Injecting Dialogue Domain Ontologies into Vector Space Representations Dialogue state tracking (DST) models capture users’ goals given their utterances. Goals are represented as sets of constraints expressed by slot-value pairs such as [food: Indian] or [parking: allowed]. The set of slots S and the set of values Vs for each slot make up the ontology of a dialogue domain. In this paper we adopt the recurrent neural network (RNN) framework for tracking suggested in (Henderson et al., 2014d; Henderson et al., 2014c; Mrkˇsi´c et al., 2015). Rather than using a spoken language understanding (SLU) decoder to convert user utterances into meaning representations, this model operates directly on the n-gram features extracted from the automated speech recognition (ASR) hypotheses. A drawback of this approach is that the RNN model can only perform exact string matching to detect the slot names and values mentioned by the user. It cannot recognise synonymous words such as pricey and expensive, or even subtle morphological variations such as moderate and moderately. A simple way to mitig"
N16-1018,D15-1242,0,0.191706,"f dialogue domain ontologies into word vector space representations to facilitate the construction of semantic dictionaries which improve DST performance across two different dialogue domains. Our tool and word vectors are available at github.com/nmrksic/counter-fitting. 2 Related Work Most work on improving word vector representations using lexical resources has focused on bringing words which are known to be semantically related closer together in the vector space. Some methods modify the prior or the regularization of the original training procedure (Yu and Dredze, 2014; Bian et al., 2014; Kiela et al., 2015). Wieting et al. (2015) use the Paraphrase Database (Ganitkevitch et al., 2013) to train word vectors which emphasise word similarity over word relatedness. These word vectors achieve the current state-of-the-art performance on the SimLex-999 dataset and are used as input for counter-fitting in our experiments. 1 When we write “improve”, we refer to improving the vector space for a specific purpose. We do not expect that a vector space fine-tuned for semantic similarity will give better results on semantic relatedness. As Mohammad et al. (2008) observe, antonymous concepts are related but not"
N16-1018,P15-1145,0,0.0291586,"r distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting p"
N16-1018,P02-1047,0,0.0195161,"yweight” procedures do. Faruqui et al.’s (2015) retrofitting approach uses similarity constraints from WordNet and other resources to pull similar words closer together. The complications caused by antonymy for distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurre"
N16-1018,D08-1103,0,0.0296778,"2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as east and west or expensive and inexpensive appear in near-identical contexts, which means that distributional models produce very similar word vectors for such words. Examples of such anomalies in GloVe vectors can be seen in Table 1, where words such as cheaper and inexpensive are deemed similar to (their antonym) expensive. A second drawback is that similarity and antonymy can be application- or domain-specific. In our case, we are interested in exploiting distributional knowledge for the dialogue state tracking task (DST). The DST component of a dialogue system"
N16-1018,J13-3004,0,0.0178637,"procedures that use lexical knowledge to refine off-the-shelf word vectors without requiring large corpora for (re-)training as the aforementioned “heavyweight” procedures do. Faruqui et al.’s (2015) retrofitting approach uses similarity constraints from WordNet and other resources to pull similar words closer together. The complications caused by antonymy for distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015),"
N16-1018,P15-2130,1,0.312954,"Missing"
N16-1018,N15-1100,0,0.0467596,"ffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting point is an indexed set of word vectors V = {v1 , v2 , . . . , vN } with one vector for each word in the vocabulary. We will inject semantic relations into this vector space to produce new word vectors V 0 = {v0 1 , v0 2 , . . . , v0 N }. For antonymy and synonymy we have a set of constraints A and S, respectively. The elements of each set are pairs of word indices; for example, each pair (i, j) in S is such that the i-th"
N16-1018,P15-2070,0,0.0699134,"Missing"
N16-1018,D14-1162,0,0.123725,"inexpensive costly pricy overpriced pricey afford British American Australian Britain European England Brits London BBC UK Britain Table 1: Nearest neighbours for target words using GloVe vectors before and after counter-fitting Introduction Many popular methods that induce representations for words rely on the distributional hypothesis – the assumption that semantically similar or related words appear in similar contexts. This hypothesis supports unsupervised learning of meaningful word rep´ resentations from large corpora (Curran, 2003; O S´eaghdha and Korhonen, 2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as e"
N16-1018,K15-1026,0,0.0258896,"Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting point is an indexed set of word vectors V = {v1 , v2 , . . . , vN } with one vector for each word in the vocabulary. We will inject semantic relations into this vector space to produce new word vectors V 0 = {v0 1 , v0 2 , . . . , v0 N }. For"
N16-1018,C08-1114,0,0.0231998,"nterest in lightweight post-processing procedures that use lexical knowledge to refine off-the-shelf word vectors without requiring large corpora for (re-)training as the aforementioned “heavyweight” procedures do. Faruqui et al.’s (2015) retrofitting approach uses similarity constraints from WordNet and other resources to pull similar words closer together. The complications caused by antonymy for distributional methods are well-known in the semantics community. Most prior work focuses on extracting antonym pairs from text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Se"
N16-1018,Q15-1025,0,0.312489,"ither a general lexical resource or an application-specific ontology to fine-tune distributional word vectors. Our method, which we term counter-fitting, is a lightweight post-processing procedure in the spirit of retrofitting (Faruqui et al., 2015). The second row of Table 1 illustrates the results of counter-fitting: the nearest neighbours capture true similarity much more intuitively than the original GloVe vectors. The procedure improves word vector quality regardless of the initial word vectors provided as input.1 By applying counter-fitting to the Paragram-SL999 word vectors provided by Wieting et al. (2015), we achieve new state-of-the-art performance on SimLex-999, a dataset designed to measure how well different models judge semantic similarity between words (Hill et al., 2014b). We also show that the counter-fitting method can inject knowledge of dialogue domain ontologies into word vector space representations to facilitate the construction of semantic dictionaries which improve DST performance across two different dialogue domains. Our tool and word vectors are available at github.com/nmrksic/counter-fitting. 2 Related Work Most work on improving word vector representations using lexical re"
N16-1018,D12-1111,0,0.0507046,"text rather than exploiting them (Lin et al., 2003; Mohammad et al., 2008; Turney, 2008; Hashimoto et al., 2012; Mohammad et al., 2013). The most common use of antonymy information is to provide features for systems that detect contradictions or logical entailment (Marcu and Echihabi, 2002; de Marneffe et al., 2008; Zanzotto et al., 2009). As far as we are aware, there is no previous work on exploiting antonymy in dialogue systems. The modelling work closest to ours are Liu et al. (2015), who use antonymy and WordNet hierarchy information to modify the heavyweight Word2Vec training objective; Yih et al. (2012), who use a Siamese neural network to improve the quality of Latent Semantic Analysis vectors; Schwartz et al. (2015), who build a standard distributional model from co-occurrences based on symmetric patterns, with specified antonymy patterns counted as negative co-occurrences; and Ono et al. (2015), who use thesauri and distributional data to train word embeddings specialised for capturing antonymy. 3 Counter-fitting Word Vectors to Linguistic Constraints Our starting point is an indexed set of word vectors V = {v1 , v2 , . . . , vN } with one vector for each word in the vocabulary. We will i"
N16-1018,P14-2089,0,0.0344864,"er-fitting method can inject knowledge of dialogue domain ontologies into word vector space representations to facilitate the construction of semantic dictionaries which improve DST performance across two different dialogue domains. Our tool and word vectors are available at github.com/nmrksic/counter-fitting. 2 Related Work Most work on improving word vector representations using lexical resources has focused on bringing words which are known to be semantically related closer together in the vector space. Some methods modify the prior or the regularization of the original training procedure (Yu and Dredze, 2014; Bian et al., 2014; Kiela et al., 2015). Wieting et al. (2015) use the Paraphrase Database (Ganitkevitch et al., 2013) to train word vectors which emphasise word similarity over word relatedness. These word vectors achieve the current state-of-the-art performance on the SimLex-999 dataset and are used as input for counter-fitting in our experiments. 1 When we write “improve”, we refer to improving the vector space for a specific purpose. We do not expect that a vector space fine-tuned for semantic similarity will give better results on semantic relatedness. As Mohammad et al. (2008) observe,"
N16-1018,D13-1141,0,0.0235628,"arest neighbours for target words using GloVe vectors before and after counter-fitting Introduction Many popular methods that induce representations for words rely on the distributional hypothesis – the assumption that semantically similar or related words appear in similar contexts. This hypothesis supports unsupervised learning of meaningful word rep´ resentations from large corpora (Curran, 2003; O S´eaghdha and Korhonen, 2014; Mikolov et al., 2013; Pennington et al., 2014). Word vectors trained using these methods have proven useful for many downstream tasks including machine translation (Zou et al., 2013) and dependency parsing (Bansal et al., 2014). One drawback of learning word embeddings from co-occurrence information in corpora is that it tends to coalesce the notions of semantic similarity and conceptual association (Hill et al., 2014b). Furthermore, even methods that can distinguish similarity from association (e.g., based on syntactic co-occurrences) will generally fail to tell synonyms from antonyms (Mohammad et al., 2008). For example, words such as east and west or expensive and inexpensive appear in near-identical contexts, which means that distributional models produce very similar"
P10-1157,C00-1007,0,0.0274535,"the human gold standard with a fraction of the data. 1 Introduction The field of natural language generation (NLG) is one of the last areas of computational linguistics to embrace statistical methods. Over the past decade, statistical NLG has followed two lines of research. The first one, pioneered by Langkilde and Knight (1998), introduces statistics in the generation process by training a model which reranks candidate outputs of a handcrafted generator. While their HAL OGEN system uses an n-gram language model trained on news articles, other systems have used hierarchical syntactic models (Bangalore and Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans,"
P10-1157,N03-2002,0,0.00862214,"cross contexts. For example, if reject(area(centre)) was never observed at training time, P (r = centre of town|s = reject(area(centre))) will be estimated by backing off to P (r = centre of town|h = centre). BAGEL can thus generate ‘there are no venues in the centre of town’ if the phrase ‘centre of town’ was associated with the concept centre in a different context, such as inform(area(centre)). The final realisation model is illustrated in Fig. 2: (8) Conditional probability distributions are represented as factored language models smoothed using Witten-Bell interpolated backoff smoothing (Bilmes and Kirchhoff, 2003), according to the backoff graphs in Fig. 3. Variables which are the furthest away in time are dropped first, and partial stack variables are dropped last as they are observed the most. It is important to note that generating unseen semantic stacks requires all possible mandatory semantic stacks in the target domain to be predefined, in order for all stack unigrams to be assigned a smoothed non-zero probability. 3.2 High cardinality concept abstraction While one should expect a trainable generator to learn multiple lexical realisations for lowcardinality semantic concepts, learning lexical rea"
P10-1157,P10-1088,0,0.0145279,"A ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalisation performance of synchronous CFGs in a dialogue system domain. Although we do not know of any work on active learning for NLG, previous work has used active learning for semantic parsing and information extraction (Thompson et al., 1999; Tang et al., 2002), spoken language understanding (Tur et al., 2003), speech recognition (Hakkani-T¨ur et al., 2002), word alignment (Sassano, 2002), and more recently for statistical machine translation (Bloodgood and Callison-Burch, 2010). While certaintybased methods have been widely used, future work should investigate the performance of committeebased active learning for NLG, in which examples are selected based on the level of disagreement between models trained on subsets of the data (Freund et al., 1997). 7 Discussion and conclusion This paper presents and evaluates BAGEL, a statistical language generator that can be trained entirely from data, with no handcrafting required beyond the semantic annotation. All the required subtasks—i.e. content ordering, aggregation, lexical selection and realisation—are learned from data"
P10-1157,P08-1022,0,0.0245612,"ith the mean informativeness score, over all folds of all systems tested (n = 70, p &lt; .01). This is lower than previous correlations reported by Reiter and Belz (2009) in the shipping forecast domain with nonexpert judges (r = .80), possibly because our domain is larger and more open to subjectivity. 6 Related work While most previous work on trainable NLG relies on a handcrafted component (see Section 1), recent research has started exploring fully datadriven NLG models. Factored language models have recently been used for surface realisation within the OpenCCG framework (White et al., 2007; Espinosa et al., 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (White et al., 2007; Nakanishi et al., 2005), as well as from semantically-annotated treebanks (Varges and Mellish, 2001). However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language model with an inverted synch"
P10-1157,W06-1405,0,0.0132302,"in the generation process by training a model which reranks candidate outputs of a handcrafted generator. While their HAL OGEN system uses an n-gram language model trained on news articles, other systems have used hierarchical syntactic models (Bangalore and Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans, 2005; Mairesse and Walker, 2008), generating the most likely context-free derivations given a corpus (Belz, 2008), or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2009). While such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define"
P10-1157,P98-1116,0,0.0278944,"rs. A human evaluation shows that BAGEL can generate natural and informative utterances from unseen inputs in the information presentation domain. Additionally, generation performance on sparse datasets is improved significantly by using certainty-based active learning, yielding ratings close to the human gold standard with a fraction of the data. 1 Introduction The field of natural language generation (NLG) is one of the last areas of computational linguistics to embrace statistical methods. Over the past decade, statistical NLG has followed two lines of research. The first one, pioneered by Langkilde and Knight (1998), introduces statistics in the generation process by training a model which reranks candidate outputs of a handcrafted generator. While their HAL OGEN system uses an n-gram language model trained on news articles, other systems have used hierarchical syntactic models (Bangalore and Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on spe"
P10-1157,N07-2038,1,0.673558,"inform: presenting information about a restaurant (see Table 1), and (b) reject: informing that the user’s constraints cannot be met (e.g., ‘There is no cheap restaurant in the centre’). Our domain contains 8 restaurant attributes: name, food, near, pricerange, postcode, phone, address, and area, out of which food, pricerange, and area are treated as enumerable.3 Our input semantic space is approximated by the set of information presentation dialogue acts produced over 20,000 simulated dialogues between our statistical dialogue manager (Young et al., 2010) and an agenda-based user simulator (Schatzmann et al., 2007), which results in 202 unique dialogue acts after replacing nonenumerable values by a generic symbol. Each dialogue act contains an average of 4.48 mandatory semantic stacks. As one of our objectives is to test whether BAGEL can learn from data provided by a large sample of untrained annotators, we collected a corpus of semantically-aligned utterances using Amazon’s Mechanical Turk data collection service. A crucial aspect of data collection for NLG is to ensure that the annotators understand the meaning of the semantics to be conveyed. Annotators were first asked to provide an utterance match"
P10-1157,P02-1016,0,0.022591,"m a meaning representation to natural language. WASP−1 relies on G IZA ++ to align utterances with derivations of the meaning representation (Och and Ney, 2003). Although early experiments showed that G IZA ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalisation performance of synchronous CFGs in a dialogue system domain. Although we do not know of any work on active learning for NLG, previous work has used active learning for semantic parsing and information extraction (Thompson et al., 1999; Tang et al., 2002), spoken language understanding (Tur et al., 2003), speech recognition (Hakkani-T¨ur et al., 2002), word alignment (Sassano, 2002), and more recently for statistical machine translation (Bloodgood and Callison-Burch, 2010). While certaintybased methods have been widely used, future work should investigate the performance of committeebased active learning for NLG, in which examples are selected based on the level of disagreement between models trained on subsets of the data (Freund et al., 1997). 7 Discussion and conclusion This paper presents and evaluates BAGEL, a statistical language generat"
P10-1157,N01-1001,0,0.0909503,"possibly because our domain is larger and more open to subjectivity. 6 Related work While most previous work on trainable NLG relies on a handcrafted component (see Section 1), recent research has started exploring fully datadriven NLG models. Factored language models have recently been used for surface realisation within the OpenCCG framework (White et al., 2007; Espinosa et al., 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (White et al., 2007; Nakanishi et al., 2005), as well as from semantically-annotated treebanks (Varges and Mellish, 2001). However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language model with an inverted synchronous CFG parsing model, effectively casting the generation task as a translation problem from a meaning representation to natural language. WASP−1 relies on G IZA ++ to align utterances with derivations of the meaning representation ("
P10-1157,P08-1020,1,0.620959,"s trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans, 2005; Mairesse and Walker, 2008), generating the most likely context-free derivations given a corpus (Belz, 2008), or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2009). While such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. This paper presents BAGEL (Bayesian networks for generation using active learning), an NLG system that can be fully trained from aligned data. While the main requirement of the generator is t"
P10-1157,2007.mtsummit-ucnlg.4,0,0.0979539,"ness score and .35 with the mean informativeness score, over all folds of all systems tested (n = 70, p &lt; .01). This is lower than previous correlations reported by Reiter and Belz (2009) in the shipping forecast domain with nonexpert judges (r = .80), possibly because our domain is larger and more open to subjectivity. 6 Related work While most previous work on trainable NLG relies on a handcrafted component (see Section 1), recent research has started exploring fully datadriven NLG models. Factored language models have recently been used for surface realisation within the OpenCCG framework (White et al., 2007; Espinosa et al., 2008). More generally, chart generators for different grammatical formalisms have been trained from syntactic treebanks (White et al., 2007; Nakanishi et al., 2005), as well as from semantically-annotated treebanks (Varges and Mellish, 2001). However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language mode"
P10-1157,W05-1510,0,0.0239054,"Missing"
P10-1157,N07-1022,0,0.190551,"Missing"
P10-1157,J03-1002,0,0.0232322,". However, a major difference with our approach is that BAGEL uses domain-specific data to generate a surface form directly from semantic concepts, without any syntactic annotation (see Section 7 for further discussion). 1559 This work is strongly related to Wong and Mooney’s WASP−1 generation system (2007), which combines a language model with an inverted synchronous CFG parsing model, effectively casting the generation task as a translation problem from a meaning representation to natural language. WASP−1 relies on G IZA ++ to align utterances with derivations of the meaning representation (Och and Ney, 2003). Although early experiments showed that G IZA ++ did not perform well on our data—possibly because of the coarse granularity of our semantic representation—future work should evaluate the generalisation performance of synchronous CFGs in a dialogue system domain. Although we do not know of any work on active learning for NLG, previous work has used active learning for semantic parsing and information extraction (Thompson et al., 1999; Tang et al., 2002), spoken language understanding (Tur et al., 2003), speech recognition (Hakkani-T¨ur et al., 2002), word alignment (Sassano, 2002), and more r"
P10-1157,P05-1008,0,0.0178359,"nd Rambow, 2000), models trained on user ratings of ∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and funded by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). utterance quality (Walker et al., 2002), or alignment models trained on speaker-specific corpora (Isard et al., 2006). A second line of research has focused on introducing statistics at the generation decision level, by training models that find the set of generation parameters maximising an objective function, e.g. producing a target linguistic style (Paiva and Evans, 2005; Mairesse and Walker, 2008), generating the most likely context-free derivations given a corpus (Belz, 2008), or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2009). While such methods do not suffer from the computational cost of an overgeneration phase, they still require a handcrafted generator to define the generation decision space within which statistics can be used to find an optimal solution. This paper presents BAGEL (Bayesian networks for generation using active learning), an NLG system that can be fully trained from aligned data. While the main requi"
P10-1157,P02-1040,0,0.0991268,"m(type(restaurant)) inform(area) inform(area(riverside)) inform(area) inform inform(food) inform(food(French)) inform(food) END ht START X inform restaurant area riverside area inform food French food END lt START inform(name) EMPTY inform(type) inform inform(area) inform EMPTY inform inform(food) inform END Table 2: Example utterance annotation used to estimate the conditional probability distributions of the models in Figs. 1 and 2 ( rt =realisation phrase, st =semantic stack, ht =stack head, lt =stack tail). 5.2 BLEU score evaluation We first evaluate BAGEL using the BLEU automated metric (Papineni et al., 2002), which measures the word n-gram overlap between the generated utterances and the 2 reference paraphrases over a test corpus (with n up to 4). While BLEU suffers from known issues such as a bias towards statistical NLG systems (Reiter and Belz, 2009), it provides useful information when comparing similar systems. We evaluate BAGEL for different training set sizes, model dependencies, and active learning parameters. Our results are averaged over a 10-fold cross-validation over distinct dialogue acts, i.e. dialogue acts used for testing are not seen at training time,5 and all systems are tested"
P10-1157,J09-4008,0,0.0721372,"rm inform(area) inform EMPTY inform inform(food) inform END Table 2: Example utterance annotation used to estimate the conditional probability distributions of the models in Figs. 1 and 2 ( rt =realisation phrase, st =semantic stack, ht =stack head, lt =stack tail). 5.2 BLEU score evaluation We first evaluate BAGEL using the BLEU automated metric (Papineni et al., 2002), which measures the word n-gram overlap between the generated utterances and the 2 reference paraphrases over a test corpus (with n up to 4). While BLEU suffers from known issues such as a bias towards statistical NLG systems (Reiter and Belz, 2009), it provides useful information when comparing similar systems. We evaluate BAGEL for different training set sizes, model dependencies, and active learning parameters. Our results are averaged over a 10-fold cross-validation over distinct dialogue acts, i.e. dialogue acts used for testing are not seen at training time,5 and all systems are tested on the same folds. The training and test sets respectively contain an average of 181 and 21 distinct dialogue acts, and each dialogue act is associated with two paraphrases, resulting in 362 training utterances. 4 The normalisation process took aroun"
P10-1157,E09-1078,0,\N,Missing
P10-1157,P02-1064,0,\N,Missing
P10-1157,C98-1112,0,\N,Missing
P15-2130,P07-1056,0,0.0840533,"ks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, o"
P15-2130,W13-4071,0,0.0605453,"f tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex sem"
P15-2130,W13-4067,0,0.253377,"We believe that this work is the first to address the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speec"
P15-2130,W13-4073,1,0.727859,"2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in pa"
P15-2130,W14-4337,1,0.15618,"Missing"
P15-2130,W13-4065,0,0.0341703,"Missing"
P15-2130,W14-4340,1,0.809231,"state tracking component of a dialog system is responsible for interpreting the users’ utterances and thus updating the system’s belief state: a probability distribution over all possible states of the dialog. This belief state is used by the system to decide what to do next. Recurrent Neural Networks (RNNs) are well suited to dialog state tracking, as their ability to capture contextual information allows them to model and label complex dynamic sequences (Graves, 2012). In recent shared tasks, approaches based on {diarmuid, blaise}@vocaliq.com these models have shown competitive performance (Henderson et al., 2014d; Henderson et al., 2014c). This approach is particularly well suited to our goal of building open-domain dialog systems, as it does not require handcrafted domain-specific resources for semantic interpretation. We propose a method for training multi-domain RNN dialog state tracking models. Our hierarchical training procedure first uses all the data available to train a very general belief tracking model. This model learns the most frequent and general dialog features present across the various domains. The general model is then specialised for each domain, learning domain-specific behaviour"
P15-2130,W13-4066,0,0.0119824,"the question of multi-domain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, a"
P15-2130,W13-4069,0,0.0115194,"omain belief tracking. 2 Related Work Traditional rule-based approaches to understanding in dialog systems (e.g. Goddeau et al. (1996)) have been superseded by data-driven systems that are more robust and can provide the probabilistic dialog state distributions that are needed by POMDPbased dialog managers. The recent Dialog State Tracking Challenge (DSTC) shared tasks (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) saw a variety of novel approaches, including robust sets of hand-crafted rules (Wang and Lemon, 2013), conditional random fields (Lee and Eskenazi, 2013; Lee, 2013; Ren et al., 2013), maximum entropy models (Williams, 2013) and web-style ranking (Williams, 2014). 794 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794–799, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Henderson et al. (2013; 2014d; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the"
P15-2130,W10-2607,0,0.0181402,"ing state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the same topic. To the best of our knowledge, our work is the first attempt to build a belief tracker capable of operating across disjoint dialog domains. 3 Dialog State Tracking using RNNs Belief tracking models capture use"
P15-2130,N06-1020,0,0.0101323,"; 2014c) proposed a belief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output spa"
P15-2130,N10-1004,0,0.00780112,"ief tracker based on recurrent neural networks. This approach maps directly from the ASR (automatic speech recognition) output to the belief state update, avoiding the use of complex semantic decoders while still attaining state-of-the-art performance. We adopt this RNN framework as the starting point for the work described here. It is well-known in machine learning that a system trained on data from one domain may not perform as well when deployed in a different domain. Researchers have investigated methods for mitigating this problem, with NLP applications in parsing (McClosky et al., 2006; McClosky et al., 2010), sentiment analysis (Blitzer et al., 2007; Glorot et al., 2011) and many other tasks. There has been a small amount of previous work on domain adaptation for dialog systems. Tur et al. (2007) and Margolis et al. (2010) investigated domain adaptation for dialog act tagging. Walker et al. (2007) trained a sentence planner/generator that adapts to different individuals and domains. In the third DSTC shared task (Henderson et al., 2014b), participants deployed belief trackers trained on a restaurant domain in an expanded version of the same domain, with a richer output space but essentially the s"
P15-2130,W14-4339,0,\N,Missing
P16-1230,W15-4653,1,0.73836,"Missing"
P16-1230,J11-1006,0,0.094076,"Missing"
P16-1230,P00-1013,0,0.664241,"Missing"
P16-1230,W15-4655,1,0.636188,"Missing"
P16-1230,P10-1040,0,0.0392136,"Missing"
P16-1230,W15-4649,1,0.866139,"Missing"
P16-1230,P97-1035,0,0.904945,"Missing"
P16-1230,W15-4603,0,\N,Missing
P17-1006,W16-1603,0,0.0323402,"ll and Schütze, 2015; Bhatia et al., 2016, i.a.). The key idea is to learn a morphological composition function (Lazaridou et al., 2013; Cotterell and Schütze, 2017) which synthesises the representation of a word given the representations of its constituent morphemes. Contrary to our work, these models typically coalesce all lexical relations. Another class of models, operating at the character level, shares a similar methodology: such models compose token-level representations from subcomponent embeddings (subwords, morphemes, or characters) (dos Santos and Zadrozny, 2014; Ling et al., 2015; Cao and Rei, 2016; Kim et al., 2016; Acknowledgments This work is supported by the ERC Consolidator Grant LEXICAL: Lexical Acquisition Across Languages (no 648909). RR is supported by the IntelICRI grant: Hybrid Models for Minimally Supervised Information Extraction from Conversations. The authors are grateful to the anonymous reviewers for their helpful suggestions. 64 References Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research 12:2493–2537. http://dl.acm.org/citation"
P17-1006,ehrmann-etal-2014-representing,0,0.0133747,"r verb conjugation (aspettare / aspettiamo); (3) regular formation of past participle (aspettare / aspettato); and (4) rules regarding grammatical gender (bianco / bianca). Besides these, another set of rules is used for German and Russian: (5) regular declension (e.g., asiatisch / asiatischem). Table 3: Vocabulary sizes and counts of ATTRACT (A) and R EPEL (R) constraints. constraints. These can be extracted from a variety of semantic databases such as WordNet (Fellbaum, 1998), the Paraphrase Database (Ganitkevitch et al., 2013; Pavlick et al., 2015), or BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014) as done in prior work (Faruqui et al., 2015; Wieting et al., 2015; Mrkši´c et al., 2016, i.a.). In this work, we investigate another option: extracting constraints without curated knowledge bases in a spectrum of languages by exploiting inherent language-specific properties related to linguistic morphology. This relaxation ensures a wider portability of ATTRACTR EPEL to languages and domains without readily available or adequate resources. Extracting R EPEL Pairs As another source of implicit semantic signals, W also contains words which represent derivational antonyms: e.g., two words that d"
P17-1006,D14-1082,0,0.0120453,"roposed method does not require curated knowledge bases or gold lexicons. Instead, it makes use of the observation that morphology implicitly encodes semantic signals pertaining to synonymy (e.g., German word inflections katalanisch, katalanischem, katalanischer denote the same semantic concept in different grammatical roles), and antonymy (e.g., mature vs. immature), capitalising on the Introduction Word representation learning has become a research area of central importance in natural language processing (NLP), with its usefulness demonstrated across many application areas such as parsing (Chen and Manning, 2014; Johannsen et al., 2015), machine translation (Zou et al., 2013), and many others (Turian et al., 2010; Collobert et al., 56 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 56–68 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1006 en_expensive costly costlier cheaper prohibitively pricey expensiveness costly costlier ruinously unaffordable de_teure teuren kostspielige aufwändige kostenintensive aufwendige teures teuren teurem teurer teurerer it_costoso dispendioso remu"
P17-1006,W14-4340,1,0.939514,"impress). In future work, we will study how to fur61 ther refine extracted sets of constraints. We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation. The Neural Belief Tracker (NBT) is a novel DST model which overcomes both issues by reasoning purely over pre-trained word vectors (Mrkši´c"
P17-1006,N15-1184,0,0.635015,"aduale lenti lente lenta veloce rapido en_book books memoir novel storybooks blurb booked rebook booking rebooked books de_buch sachbuch buches romandebüt büchlein pamphlet bücher büch büche büches büchen it_libro romanzo racconto volumetto saggio ecclesiaste libri libra librare libre librano Table 1: The nearest neighbours of three example words (expensive, slow and book) in English, German and Italian before (top) and after (bottom) morph-fitting. proliferation of word forms in morphologically rich languages. Formalised as an instance of the post-processing semantic specialisation paradigm (Faruqui et al., 2015; Mrkši´c et al., 2016), morphfitting is steered by a set of linguistic constraints derived from simple language-specific rules which describe (a subset of) morphological processes in a language. The constraints emphasise similarity on one side (e.g., by extracting morphological synonyms), and antonymy on the other (by extracting morphological antonyms), see Fig. 1 and Tab. 2. The key idea of the fine-tuning process is to pull synonymous examples described by the constraints closer together in the transformed vector space, while at the same time pushing antonymous examples away from each other"
P17-1006,E14-1049,0,0.198571,"contexts), and training data (PW = Polyglot Wikipedia from Al-Rfou et al. (2013); 8B = 8 billion token word2vec corpus), following (Levy and Goldberg, 2014) and (Schwartz et al., 2015). We also test the symmetricpattern based vectors of Schwartz et al. (2016) (SymPat-Emb), count-based PMI-weighted vectors reduced by SVD (Baroni et al., 2014) (Count-SVD), a model which replaces the context modelling function from CBOW with bidirectional LSTMs (Melamud et al., 2016) (Context2Vec), and two sets of EN vectors trained by injecting multilingual information: BiSkip (Luong et al., 2015) and MultiCCA (Faruqui and Dyer, 2014). We also experiment with standard well-known distributional spaces in other languages (IT and DE ), available from prior work (Dinu et al., 2015; Luong et al., 2015; Vuli´c and Korhonen, 2016a). 4 Intrinsic Evaluation: Word Similarity Evaluation Setup and Datasets The first set of experiments intrinsically evaluates morph-fitted vector spaces on word similarity benchmarks, using Spearman’s rank correlation as the evaluation metric. First, we use the SimLex-999 dataset, as well as SimVerb-3500, a recent EN verb pair similarity dataset providing similarity ratings for 3,500 verb pairs.7 SimLex-"
P17-1006,N16-1077,0,0.0279301,"nally generating incorrect linguistic constraints such as (tent, intent), (prove, improve) or (press, impress). In future work, we will study how to fur61 ther refine extracted sets of constraints. We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation. The Neural Belief Tracker (NBT) is a"
P17-1006,N15-1070,0,0.0942068,"approach to incorporating external information into vector spaces is to pull the representations of similar words closer together. Some models integrate such constraints into the training procedure, modifying the prior or the regularisation (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015), or using a variant of the SGNS-style objective (Liu et al., 2015; Osborne et al., 2016). Another class of models, popularly termed retrofitting, injects lexical knowledge from available semantic databases (e.g., WordNet, PPDB) into pre-trained word vectors (Faruqui et al., 2015; Jauhar et al., 2015; Wieting et al., 2015; Nguyen et al., 2016; Mrkši´c et al., 2016). Morph-fitting falls into the latter category. However, instead of resorting to curated knowledge bases, and experimenting solely with English, we show that the morphological richness of any language can be exploited as a source of inexpensive supervision for fine-tuning vector spaces, at the same time specialising them to better reflect true semantic similarity, and learning more accurate representations for low-frequency words. 7 Conclusion and Future Work We have presented a novel morph-fitting method which injects morpholog"
P17-1006,D15-1245,0,0.0180451,"require curated knowledge bases or gold lexicons. Instead, it makes use of the observation that morphology implicitly encodes semantic signals pertaining to synonymy (e.g., German word inflections katalanisch, katalanischem, katalanischer denote the same semantic concept in different grammatical roles), and antonymy (e.g., mature vs. immature), capitalising on the Introduction Word representation learning has become a research area of central importance in natural language processing (NLP), with its usefulness demonstrated across many application areas such as parsing (Chen and Manning, 2014; Johannsen et al., 2015), machine translation (Zou et al., 2013), and many others (Turian et al., 2010; Collobert et al., 56 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 56–68 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1006 en_expensive costly costlier cheaper prohibitively pricey expensiveness costly costlier ruinously unaffordable de_teure teuren kostspielige aufwändige kostenintensive aufwendige teures teuren teurem teurer teurerer it_costoso dispendioso remunerativo redditizio risch"
P17-1006,E17-1049,0,0.024409,"rect linguistic constraints such as (tent, intent), (prove, improve) or (press, impress). In future work, we will study how to fur61 ther refine extracted sets of constraints. We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation. The Neural Belief Tracker (NBT) is a novel DST model whi"
P17-1006,D15-1242,0,0.404513,"Missing"
P17-1006,N13-1092,0,0.182887,"Missing"
P17-1006,D16-1235,1,0.903455,"Missing"
P17-1006,P13-1149,0,0.162129,"ig. 1). The final A and R constraint counts are given in Tab. 3. The full sets of rules are available as supplemental material. Extracting ATTRACT Pairs The core difference between inflectional and derivational morphology can be summarised in a few lines as follows: the former refers to a set of processes through which the word form expresses meaningful syntactic information, e.g., verb tense, without any change to the semantics of the word. On the other hand, the latter refers to the formation of new words with semantic shifts in meaning (Schone and Jurafsky, 2001; Haspelmath and Sims, 2013; Lazaridou et al., 2013; Zeller et al., 2013; Cotterell and Schütze, 2017). For the ATTRACT constraints, we focus on inflectional rather than on derivational morphology rules as the former preserve the full meaning of a word, modifying it only to reflect grammatical roles such as verb tense or case markers (e.g., (en_read, en_reads) or (de_katalanisch, de_katalanischer)). This choice is guided by our intent to fine-tune the original vector space in order to improve the embedded semantic relations. We define two rules for English, widely recognised as morphologically simple (Avramidis and Koehn, 2008; Cotterell et al"
P17-1006,W13-4066,0,0.0234804,", DE and IT are trained using four variants of the SGNS - LARGE vectors: 1) the initial distributional vectors; 2) morph-fixed vectors; 3) and 4) the two variants of morph-fitted vectors (see Sect. 3). As shown by Mrkši´c et al. (2017b), semantic specialisation of the employed word vectors benThe Dialogue State Tracking Challenge (DSTC) shared task series formalised the evaluation and provided labelled DST datasets (Henderson et al., 2014a,b; Williams et al., 2016). While a plethora of DST models are available based on, e.g., handcrafted rules (Wang et al., 2014) or conditional random fields (Lee and Eskenazi, 2013), the recent DST methodology has seen a shift towards neural62 0.45 0.45 0.85 0.85 SimLex 0.75 0.30 0.70 0.25 0.65 0.20 0.15 Distrib MFix MFit-A MFit-AR SimLex (Spearman’s ρ) SimLex (Spearman’s ρ) 0.35 0.40 0.60 0.35 0.75 0.30 0.70 0.25 0.65 0.20 0.15 (a) English 0.80 Distrib MFix MFit-A MFit-AR DST Performance (Joint) 0.80 DST Performance (Joint) 0.40 DST 0.60 (b) German 0.45 0.85 0.45 0.35 0.75 0.30 0.70 0.25 0.65 0.20 0.15 Distrib MFix MFit-A MFit-AR SimLex SimLex (Spearman’s ρ) SimLex (Spearman’s ρ) 0.80 DST Performance (Joint) 0.40 0.40 0.35 0.30 0.25 0.20 0.15 0.60 (c) Italian Distrib MF"
P17-1006,W14-4337,0,0.147086,"Missing"
P17-1006,W13-4065,0,0.0658382,"Missing"
P17-1006,Q17-1022,1,0.883478,"Missing"
P17-1006,E17-1001,0,0.0359627,"We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation. The Neural Belief Tracker (NBT) is a novel DST model which overcomes both issues by reasoning purely over pre-trained word vectors (Mrkši´c et al., 2017a). The NBT learns to compose these vectors into intermediate utterance and conte"
P17-1006,P15-1145,0,0.280709,"Missing"
P17-1006,W15-1521,0,0.150173,"= bag-ofwords; DEPS = dependency contexts), and training data (PW = Polyglot Wikipedia from Al-Rfou et al. (2013); 8B = 8 billion token word2vec corpus), following (Levy and Goldberg, 2014) and (Schwartz et al., 2015). We also test the symmetricpattern based vectors of Schwartz et al. (2016) (SymPat-Emb), count-based PMI-weighted vectors reduced by SVD (Baroni et al., 2014) (Count-SVD), a model which replaces the context modelling function from CBOW with bidirectional LSTMs (Melamud et al., 2016) (Context2Vec), and two sets of EN vectors trained by injecting multilingual information: BiSkip (Luong et al., 2015) and MultiCCA (Faruqui and Dyer, 2014). We also experiment with standard well-known distributional spaces in other languages (IT and DE ), available from prior work (Dinu et al., 2015; Luong et al., 2015; Vuli´c and Korhonen, 2016a). 4 Intrinsic Evaluation: Word Similarity Evaluation Setup and Datasets The first set of experiments intrinsically evaluates morph-fitted vector spaces on word similarity benchmarks, using Spearman’s rank correlation as the evaluation metric. First, we use the SimLex-999 dataset, as well as SimVerb-3500, a recent EN verb pair similarity dataset providing similarity"
P17-1006,P16-2074,0,0.0671559,"ion into vector spaces is to pull the representations of similar words closer together. Some models integrate such constraints into the training procedure, modifying the prior or the regularisation (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015), or using a variant of the SGNS-style objective (Liu et al., 2015; Osborne et al., 2016). Another class of models, popularly termed retrofitting, injects lexical knowledge from available semantic databases (e.g., WordNet, PPDB) into pre-trained word vectors (Faruqui et al., 2015; Jauhar et al., 2015; Wieting et al., 2015; Nguyen et al., 2016; Mrkši´c et al., 2016). Morph-fitting falls into the latter category. However, instead of resorting to curated knowledge bases, and experimenting solely with English, we show that the morphological richness of any language can be exploited as a source of inexpensive supervision for fine-tuning vector spaces, at the same time specialising them to better reflect true semantic similarity, and learning more accurate representations for low-frequency words. 7 Conclusion and Future Work We have presented a novel morph-fitting method which injects morphological knowledge in the form of linguistic co"
P17-1006,W13-3512,0,0.0917221,"ts of the post-processing specialisation algorithm and the constraint selection. Word Vectors and Morphology The use of morphological resources to improve the representations of morphemes and words is an active area of research. The majority of proposed architectures encode morphological information, provided either as gold standard morphological resources (SylakGlassman et al., 2015) such as CELEX (Baayen et al., 1995) or as an external analyser such as Morfessor (Creutz and Lagus, 2007), along with distributional information jointly at training time in the language modelling (LM) objective (Luong et al., 2013; Botha and Blunsom, 2014; Qiu et al., 2014; Cotterell and Schütze, 2015; Bhatia et al., 2016, i.a.). The key idea is to learn a morphological composition function (Lazaridou et al., 2013; Cotterell and Schütze, 2017) which synthesises the representation of a word given the representations of its constituent morphemes. Contrary to our work, these models typically coalesce all lexical relations. Another class of models, operating at the character level, shares a similar methodology: such models compose token-level representations from subcomponent embeddings (subwords, morphemes, or characters)"
P17-1006,Q16-1030,0,0.239528,"ty and evaluate morph-fitting in a well-defined downstream task where the artefacts of the distributional hypothesis are known to prompt statistical system failures. Related Work Semantic Specialisation A standard approach to incorporating external information into vector spaces is to pull the representations of similar words closer together. Some models integrate such constraints into the training procedure, modifying the prior or the regularisation (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015), or using a variant of the SGNS-style objective (Liu et al., 2015; Osborne et al., 2016). Another class of models, popularly termed retrofitting, injects lexical knowledge from available semantic databases (e.g., WordNet, PPDB) into pre-trained word vectors (Faruqui et al., 2015; Jauhar et al., 2015; Wieting et al., 2015; Nguyen et al., 2016; Mrkši´c et al., 2016). Morph-fitting falls into the latter category. However, instead of resorting to curated knowledge bases, and experimenting solely with English, we show that the morphological richness of any language can be exploited as a source of inexpensive supervision for fine-tuning vector spaces, at the same time specialising them"
P17-1006,K16-1006,0,0.171359,"al models: Common-Crawl GloVe (Pennington et al., 2014), SGNS vectors (Mikolov et al., 2013) with various contexts (BOW = bag-ofwords; DEPS = dependency contexts), and training data (PW = Polyglot Wikipedia from Al-Rfou et al. (2013); 8B = 8 billion token word2vec corpus), following (Levy and Goldberg, 2014) and (Schwartz et al., 2015). We also test the symmetricpattern based vectors of Schwartz et al. (2016) (SymPat-Emb), count-based PMI-weighted vectors reduced by SVD (Baroni et al., 2014) (Count-SVD), a model which replaces the context modelling function from CBOW with bidirectional LSTMs (Melamud et al., 2016) (Context2Vec), and two sets of EN vectors trained by injecting multilingual information: BiSkip (Luong et al., 2015) and MultiCCA (Faruqui and Dyer, 2014). We also experiment with standard well-known distributional spaces in other languages (IT and DE ), available from prior work (Dinu et al., 2015; Luong et al., 2015; Vuli´c and Korhonen, 2016a). 4 Intrinsic Evaluation: Word Similarity Evaluation Setup and Datasets The first set of experiments intrinsically evaluates morph-fitted vector spaces on word similarity benchmarks, using Spearman’s rank correlation as the evaluation metric. First, w"
P17-1006,P15-2070,0,0.0998422,"Missing"
P17-1006,D14-1162,0,0.0854243,"each language are provided in Tab. 3.6 We label these collections of vectors SGNS - LARGE. all of our intrinsic and extrinsic experiments. Morph-fitting Variants We analyse two variants of morph-fitting: (1) using ATTRACT constraints only (MF IT-A), and (2) using both ATTRACT and R EPEL constraints (MF IT-AR). Other Starting Distributional Vectors We also analyse the impact of morph-fitting on other collections of well-known EN word vectors. These vectors have varying vocabulary coverage and are trained with different architectures. We test standard distributional models: Common-Crawl GloVe (Pennington et al., 2014), SGNS vectors (Mikolov et al., 2013) with various contexts (BOW = bag-ofwords; DEPS = dependency contexts), and training data (PW = Polyglot Wikipedia from Al-Rfou et al. (2013); 8B = 8 billion token word2vec corpus), following (Levy and Goldberg, 2014) and (Schwartz et al., 2015). We also test the symmetricpattern based vectors of Schwartz et al. (2016) (SymPat-Emb), count-based PMI-weighted vectors reduced by SVD (Baroni et al., 2014) (Count-SVD), a model which replaces the context modelling function from CBOW with bidirectional LSTMs (Melamud et al., 2016) (Context2Vec), and two sets of EN"
P17-1006,E17-1029,0,0.030739,"sets of constraints. We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation. The Neural Belief Tracker (NBT) is a novel DST model which overcomes both issues by reasoning purely over pre-trained word vectors (Mrkši´c et al., 2017a). The NBT learns to compose these vectors into intermediat"
P17-1006,P15-2130,1,0.859159,"Missing"
P17-1006,C14-1015,0,0.0339755,"rithm and the constraint selection. Word Vectors and Morphology The use of morphological resources to improve the representations of morphemes and words is an active area of research. The majority of proposed architectures encode morphological information, provided either as gold standard morphological resources (SylakGlassman et al., 2015) such as CELEX (Baayen et al., 1995) or as an external analyser such as Morfessor (Creutz and Lagus, 2007), along with distributional information jointly at training time in the language modelling (LM) objective (Luong et al., 2013; Botha and Blunsom, 2014; Qiu et al., 2014; Cotterell and Schütze, 2015; Bhatia et al., 2016, i.a.). The key idea is to learn a morphological composition function (Lazaridou et al., 2013; Cotterell and Schütze, 2017) which synthesises the representation of a word given the representations of its constituent morphemes. Contrary to our work, these models typically coalesce all lexical relations. Another class of models, operating at the character level, shares a similar methodology: such models compose token-level representations from subcomponent embeddings (subwords, morphemes, or characters) (dos Santos and Zadrozny, 2014; Ling et al"
P17-1006,N01-1024,0,0.0956175,"constraints such as (rispettosa, irrispettosi) (see Fig. 1). The final A and R constraint counts are given in Tab. 3. The full sets of rules are available as supplemental material. Extracting ATTRACT Pairs The core difference between inflectional and derivational morphology can be summarised in a few lines as follows: the former refers to a set of processes through which the word form expresses meaningful syntactic information, e.g., verb tense, without any change to the semantics of the word. On the other hand, the latter refers to the formation of new words with semantic shifts in meaning (Schone and Jurafsky, 2001; Haspelmath and Sims, 2013; Lazaridou et al., 2013; Zeller et al., 2013; Cotterell and Schütze, 2017). For the ATTRACT constraints, we focus on inflectional rather than on derivational morphology rules as the former preserve the full meaning of a word, modifying it only to reflect grammatical roles such as verb tense or case markers (e.g., (en_read, en_reads) or (de_katalanisch, de_katalanischer)). This choice is guided by our intent to fine-tune the original vector space in order to improve the embedded semantic relations. We define two rules for English, widely recognised as morphologically"
P17-1006,P17-1163,1,0.882418,"Missing"
P17-1006,K15-1026,1,0.916649,"Simple Language-Specific Rules Ivan Vuli´c1 , Nikola Mrkši´c1 , Roi Reichart2 Diarmuid Ó Séaghdha3 , Steve Young1 , Anna Korhonen1 1 2 3 University of Cambridge Technion, Israel Institute of Technology Apple Inc. {iv250,nm480,sjy11,alk23}@cam.ac.uk doseaghdha@apple.com roiri@ie.technion.ac.il Abstract 2011). Most prominent word representation techniques are grounded in the distributional hypothesis (Harris, 1954), relying on word co-occurrence information in large textual corpora (Curran, 2004; Turney and Pantel, 2010; Mikolov et al., 2013; Mnih and Kavukcuoglu, 2013; Levy and Goldberg, 2014; Schwartz et al., 2015, i.a.). Morphologically rich languages, in which “substantial grammatical information. . . is expressed at word level” (Tsarfaty et al., 2010), pose specific challenges for NLP. This is not always considered when techniques are evaluated on languages such as English or Chinese, which do not have rich morphology. In the case of distributional vector space models, morphological complexity brings two challenges to the fore: Morphologically rich languages accentuate two properties of distributional vector space models: 1) the difficulty of inducing accurate representations for lowfrequency word f"
P17-1006,N16-1060,1,0.847607,"analyse the impact of morph-fitting on other collections of well-known EN word vectors. These vectors have varying vocabulary coverage and are trained with different architectures. We test standard distributional models: Common-Crawl GloVe (Pennington et al., 2014), SGNS vectors (Mikolov et al., 2013) with various contexts (BOW = bag-ofwords; DEPS = dependency contexts), and training data (PW = Polyglot Wikipedia from Al-Rfou et al. (2013); 8B = 8 billion token word2vec corpus), following (Levy and Goldberg, 2014) and (Schwartz et al., 2015). We also test the symmetricpattern based vectors of Schwartz et al. (2016) (SymPat-Emb), count-based PMI-weighted vectors reduced by SVD (Baroni et al., 2014) (Count-SVD), a model which replaces the context modelling function from CBOW with bidirectional LSTMs (Melamud et al., 2016) (Context2Vec), and two sets of EN vectors trained by injecting multilingual information: BiSkip (Luong et al., 2015) and MultiCCA (Faruqui and Dyer, 2014). We also experiment with standard well-known distributional spaces in other languages (IT and DE ), available from prior work (Dinu et al., 2015; Luong et al., 2015; Vuli´c and Korhonen, 2016a). 4 Intrinsic Evaluation: Word Similarity"
P17-1006,N15-1186,0,0.023404,"ge-specific rules does come at a cost of occasionally generating incorrect linguistic constraints such as (tent, intent), (prove, improve) or (press, impress). In future work, we will study how to fur61 ther refine extracted sets of constraints. We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological v"
P17-1006,E17-1042,1,0.846566,"Missing"
P17-1006,Q15-1025,0,0.601637,"redite) (dressed, undressed) (similar, dissimilar) (formality, informality) (stabil, unstabil) (geformtes, ungeformt) (relevant, irrelevant) (abitata, inabitato) (realtà, irrealtà) (attuato, inattuato) words from the in-batch ATTRACT constraints to be closer to one another than to any other word in the current mini-batch. The second term pushes antonyms away from each other. If (xl , xr ) ∈ BR is the current minibatch of R EPEL constraints, this term can be expressed as follows: The ATTRACT-R EPEL model, proposed by Mrkši´c et al. (2017b), is an extension of the PARAGRAM procedure proposed by Wieting et al. (2015). It provides a generic framework for incorporating similarity (e.g. successful and accomplished) and antonymy constraints (e.g. nimble and clumsy) into pre-trained word vectors. Given the initial vector space and collections of ATTRACT and R EPEL constraints A and R, the model gradually modifies the space to bring the designated word vectors closer together or further apart. The method’s cost function consists of three terms. The first term pulls the ATTRACT examples (xl , xr ) ∈ A closer together. If BA denotes the current mini-batch of ATTRACT examples, this term can be expressed as: X Germ"
P17-1006,P16-1230,1,0.801978,"Missing"
P17-1006,D16-1157,0,0.0330579,"→ 66.3 (MF IT-AR), setting a new state-of-the-art score for both datasets. The morph-fixed vectors do not enhance DST performance, probably because fixing word vectors to their highest frequency inflectional form eliminates useful semantic content encoded in the original vectors. On the other hand, morph-fitting makes use of this information, supplementing it with semantic relations between different morphological forms. These conclusions are in line with the SimLex gains, where morph-fitting outperforms both distributional and morph-fixed vectors. 63 spaces for extrinsic tasks such as DST. 6 Wieting et al., 2016; Verwimp et al., 2017, i.a.). In contrast to prior work, our model decouples the use of morphological information, now provided in the form of inflectional and derivational rules transformed into constraints, from the actual training. This pipelined approach results in a simpler, more portable model. In spirit, our work is similar to Cotterell et al. (2016b), who formulate the idea of post-training specialisation in a generative Bayesian framework. Their work uses gold morphological lexicons; we show that competitive performance can be achieved using a non-exhaustive set of simple rules. Our"
P17-1006,P15-2111,0,0.0142836,"models from the literature in lieu of ATTRACT-R EPEL using the same set of “morphological” synonymy and antonymy constraints. We compare ATTRACT-R EPEL to the retrofitting model Further Discussion The simplicity of the used language-specific rules does come at a cost of occasionally generating incorrect linguistic constraints such as (tent, intent), (prove, improve) or (press, impress). In future work, we will study how to fur61 ther refine extracted sets of constraints. We also plan to conduct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existi"
P17-1006,W10-1401,0,0.0148159,"rsity of Cambridge Technion, Israel Institute of Technology Apple Inc. {iv250,nm480,sjy11,alk23}@cam.ac.uk doseaghdha@apple.com roiri@ie.technion.ac.il Abstract 2011). Most prominent word representation techniques are grounded in the distributional hypothesis (Harris, 1954), relying on word co-occurrence information in large textual corpora (Curran, 2004; Turney and Pantel, 2010; Mikolov et al., 2013; Mnih and Kavukcuoglu, 2013; Levy and Goldberg, 2014; Schwartz et al., 2015, i.a.). Morphologically rich languages, in which “substantial grammatical information. . . is expressed at word level” (Tsarfaty et al., 2010), pose specific challenges for NLP. This is not always considered when techniques are evaluated on languages such as English or Chinese, which do not have rich morphology. In the case of distributional vector space models, morphological complexity brings two challenges to the fore: Morphologically rich languages accentuate two properties of distributional vector space models: 1) the difficulty of inducing accurate representations for lowfrequency word forms; and 2) insensitivity to distinct lexical relations that have similar distributional signatures. These effects are detrimental for languag"
P17-1006,P10-1040,0,0.0585254,"ervation that morphology implicitly encodes semantic signals pertaining to synonymy (e.g., German word inflections katalanisch, katalanischem, katalanischer denote the same semantic concept in different grammatical roles), and antonymy (e.g., mature vs. immature), capitalising on the Introduction Word representation learning has become a research area of central importance in natural language processing (NLP), with its usefulness demonstrated across many application areas such as parsing (Chen and Manning, 2014; Johannsen et al., 2015), machine translation (Zou et al., 2013), and many others (Turian et al., 2010; Collobert et al., 56 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 56–68 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1006 en_expensive costly costlier cheaper prohibitively pricey expensiveness costly costlier ruinously unaffordable de_teure teuren kostspielige aufwändige kostenintensive aufwendige teures teuren teurem teurer teurerer it_costoso dispendioso remunerativo redditizio rischioso costosa costosa costose costosi dispendioso dispendiose en_slow fast slow"
P17-1006,P14-2089,0,0.265019,"nd naturally extends to constraints from other sources (e.g., WordNet) in future work. Another practical difference is that we focus on similarity and evaluate morph-fitting in a well-defined downstream task where the artefacts of the distributional hypothesis are known to prompt statistical system failures. Related Work Semantic Specialisation A standard approach to incorporating external information into vector spaces is to pull the representations of similar words closer together. Some models integrate such constraints into the training procedure, modifying the prior or the regularisation (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015), or using a variant of the SGNS-style objective (Liu et al., 2015; Osborne et al., 2016). Another class of models, popularly termed retrofitting, injects lexical knowledge from available semantic databases (e.g., WordNet, PPDB) into pre-trained word vectors (Faruqui et al., 2015; Jauhar et al., 2015; Wieting et al., 2015; Nguyen et al., 2016; Mrkši´c et al., 2016). Morph-fitting falls into the latter category. However, instead of resorting to curated knowledge bases, and experimenting solely with English, we show that the morphological"
P17-1006,P13-1118,0,0.0513226,"Missing"
P17-1006,E17-1040,0,0.0904069,"Missing"
P17-1006,E17-2033,0,0.0793456,"uct experiments with gold standard morphological lexicons on languages for which such resources exist (Sylak-Glassman et al., 2015; Cotterell et al., 2016b), and investigate approaches which learn morphological inflections and derivations in different languages automatically as another potential source of morphological constraints (Soricut and Och, 2015; Cotterell et al., 2016a; Faruqui et al., 2016; Kann et al., 2017; Aharoni and Goldberg, 2017, i.a.). 5 network architectures (Henderson et al., 2014c,d; Zilka and Jurcicek, 2015; Mrkši´c et al., 2015; Perez and Liu, 2017; Liu and Perez, 2017; Vodolán et al., 2017; Mrkši´c et al., 2017a, i.a.). Model: Neural Belief Tracker To detect intents in user utterances, most existing models rely on either (or both): 1) Spoken Language Understanding models which require large amounts of annotated training data; or 2) hand-crafted, domain-specific lexicons which try to capture lexical and morphological variation. The Neural Belief Tracker (NBT) is a novel DST model which overcomes both issues by reasoning purely over pre-trained word vectors (Mrkši´c et al., 2017a). The NBT learns to compose these vectors into intermediate utterance and context representations. Th"
P17-1006,D13-1141,0,0.035066,"ns. Instead, it makes use of the observation that morphology implicitly encodes semantic signals pertaining to synonymy (e.g., German word inflections katalanisch, katalanischem, katalanischer denote the same semantic concept in different grammatical roles), and antonymy (e.g., mature vs. immature), capitalising on the Introduction Word representation learning has become a research area of central importance in natural language processing (NLP), with its usefulness demonstrated across many application areas such as parsing (Chen and Manning, 2014; Johannsen et al., 2015), machine translation (Zou et al., 2013), and many others (Turian et al., 2010; Collobert et al., 56 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 56–68 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1006 en_expensive costly costlier cheaper prohibitively pricey expensiveness costly costlier ruinously unaffordable de_teure teuren kostspielige aufwändige kostenintensive aufwendige teures teuren teurem teurer teurerer it_costoso dispendioso remunerativo redditizio rischioso costosa costosa costose costosi dis"
P17-1006,P16-1024,1,0.914352,"Missing"
P17-1006,W13-3520,0,\N,Missing
P17-1006,J15-4004,1,\N,Missing
P17-1006,P08-1087,0,\N,Missing
P17-1006,P14-2050,0,\N,Missing
P17-1006,P14-2131,0,\N,Missing
P17-1006,D16-1047,0,\N,Missing
P17-1006,P16-1156,0,\N,Missing
P17-1006,P16-2084,1,\N,Missing
P17-1006,N15-1140,0,\N,Missing
P17-1163,P15-1044,0,0.0121317,"Missing"
P17-1163,N13-1092,0,0.0185749,"Missing"
P17-1163,W14-4337,1,0.413244,"Missing"
P17-1163,W13-4065,0,0.349868,"Missing"
P17-1163,W14-4340,1,0.365061,"dy, ...] A REA =C ENTRE : [center, downtown, central, city centre, midtown, town centre, ...] Figure 2: An example semantic dictionary with rephrasings for three ontology values in a restaurant search domain. Traditional statistical approaches use separate Spoken Language Understanding (SLU) modules to address lexical variability within a single dialogue turn. However, training such models requires substantial amounts of domain-specific annotation. Alternatively, turn-level SLU and cross-turn DST can be coalesced into a single model to achieve superior belief tracking performance, as shown by Henderson et al. (2014d). Such coupled models typically rely on manually constructed semantic dictionaries to identify alternative mentions of ontology items that vary lexically or morphologically. Figure 2 gives an example of such a dictionary for three slot-value pairs. This approach, which we term delexicalisation, is clearly not scalable to larger, more complex dialogue domains. Importantly, the focus on English in DST research understates the considerable challenges that morphology poses to systems based on exact matching in morphologically richer languages such as Italian or German (see Vuli´c et al. (2017))."
P17-1163,P14-1062,0,0.00539412,"hrough another hidden layer and summed to obtain the utterance representation r. Figure 5: NBT-CNN Model. L convolutional filters of window sizes 1, 2, 3 are applied to word vectors of the given utterance (L = 3 in the diagram, but L = 300 in the system). The convolutions are followed by the ReLU activation function and max-pooling to produce summary n-gram representations. These are summed to obtain the utterance representation r. NBT-CNN Our second model draws inspiration from successful applications of Convolutional Neural Networks (CNNs) for language understanding (Collobert et al., 2011; Kalchbrenner et al., 2014; Kim, 2014). These models typically apply a number of convolutional filters to n-grams in the input sentence, followed by non-linear activation functions and max-pooling. Following this approach, the NBT-CNN model applies L = 300 different filters for n-gram lengths of 1, 2 and 3 (Figure 5). Let Fns ∈ RL×nD denote the collection of filters for each value of n, where D = 300 is the word vector dimensionality. If vin denotes the concatenation of n word vectors starting at index i, let mn = [v1n ; v2n ; . . . ; vknu −n+1 ] be the list of n-grams that convolutional filters of length n run over. T"
P17-1163,D14-1181,0,0.00573762,"and summed to obtain the utterance representation r. Figure 5: NBT-CNN Model. L convolutional filters of window sizes 1, 2, 3 are applied to word vectors of the given utterance (L = 3 in the diagram, but L = 300 in the system). The convolutions are followed by the ReLU activation function and max-pooling to produce summary n-gram representations. These are summed to obtain the utterance representation r. NBT-CNN Our second model draws inspiration from successful applications of Convolutional Neural Networks (CNNs) for language understanding (Collobert et al., 2011; Kalchbrenner et al., 2014; Kim, 2014). These models typically apply a number of convolutional filters to n-grams in the input sentence, followed by non-linear activation functions and max-pooling. Following this approach, the NBT-CNN model applies L = 300 different filters for n-gram lengths of 1, 2 and 3 (Figure 5). Let Fns ∈ RL×nD denote the collection of filters for each value of n, where D = 300 is the word vector dimensionality. If vin denotes the concatenation of n word vectors starting at index i, let mn = [v1n ; v2n ; . . . ; vknu −n+1 ] be the list of n-grams that convolutional filters of length n run over. The three int"
P17-1163,W16-3603,0,0.0396701,"are good indicators for a given value and can capture elements of paraphrasing (Mairesse et al., 2009). This line of work later shifted focus to robust handling of rich ASR output (Henderson et al., 2012; Tur et al., 2013). SLU has also been treated as a sequence labelling problem, where each word in an utterance is labelled according to its role in the user’s intent; standard labelling models such as CRFs or Recurrent Neural Networks can then be used (Raymond and Ricardi, 2007; Yao et al., 2014; Celikyilmaz and Hakkani-Tur, 2015; Mesnil et al., 2015; Peng et al., 2015; Zhang and Wang, 2016; Liu and Lane, 2016b; Vu et al., 2016; Liu and Lane, 2016a, i.a.). Other approaches adopt a more complex modelling structure inspired by semantic parsing (Saleh et al., 2014; Vlachos and Clark, 2014). One drawback shared by these methods is their resource requirements, either because they need to learn independent parameters for each slot and value or because they need fine-grained manual annotation at the word level. This hinders scaling to larger, more realistic application domains. Joint SLU/DST Research on belief tracking has found it advantageous to reason about SLU and DST jointly, taking ASR predictions a"
P17-1163,E17-1001,0,0.0114048,"categorise prior research according to their reliance (or otherwise) on a separate SLU module for interpreting user utterances:1 Separate SLU Traditional SDS pipelines use Spoken Language Understanding (SLU) decoders to detect slot-value pairs expressed in the Automatic Speech Recognition (ASR) output. The downstream DST model then combines this information with the past dialogue context to update the belief state (Thomson and Young, 2010; Wang and Lemon, 2013; Lee and Kim, 2016; Perez, 2016; Perez and Liu, 2017; Sun et al., 2016; Jang et al., 2016; Shi et al., 2016; Dernoncourt et al., 2016; Liu and Perez, 2017; Vodol´an et al., 2017). 1 The best-performing models in DSTC2 all used both raw ASR output and the output of (potentially more than one) SLU decoders (Williams, 2014; Williams et al., 2016). This does not mean that those models are immune to the drawbacks identified here for the two model categories; in fact, they share the drawbacks of both. 1778 Figure 3: Architecture of the NBT Model. The implementation of the three representation learning subcomponents can be modified, as long as these produce adequate vector representations which the downstream model components can use to decide whether"
P17-1163,P15-2130,1,0.647255,"Missing"
P17-1163,D14-1162,0,0.119281,"test; p &lt; 0.05). indicates that future work should focus on better ASR compensation if the model is to be deployed in environments with challenging acoustics. 6.2 The Importance of Word Vector Spaces The NBT models use the semantic relations embedded in the pre-trained word vectors to handle semantic variation and produce high-quality intermediate representations. Table 2 shows the performance of NBT-CNN5 models making use of three different word vector collections: 1) ‘random’ word vectors initialised using the XAVIER initialisation (Glorot and Bengio, 2010); 2) distributional GloVe vectors (Pennington et al., 2014), trained using co-occurrence information in large textual corpora; and 3) semantically specialised ParagramSL999 vectors (Wieting et al., 2015), which are obtained by injecting semantic similarity constraints from the Paraphrase Database (Ganitkevitch et al., 2013) into the distributional GloVe vectors in order to improve their semantic content. The results in Table 2 show that the use of semantically specialised word vectors leads to considerable performance gains: Paragram-SL999 vectors (significantly) outperformed GloVe and XAVIER vectors for goal tracking on both datasets. The gains are p"
P17-1163,Q14-1042,0,0.0115503,"output (Henderson et al., 2012; Tur et al., 2013). SLU has also been treated as a sequence labelling problem, where each word in an utterance is labelled according to its role in the user’s intent; standard labelling models such as CRFs or Recurrent Neural Networks can then be used (Raymond and Ricardi, 2007; Yao et al., 2014; Celikyilmaz and Hakkani-Tur, 2015; Mesnil et al., 2015; Peng et al., 2015; Zhang and Wang, 2016; Liu and Lane, 2016b; Vu et al., 2016; Liu and Lane, 2016a, i.a.). Other approaches adopt a more complex modelling structure inspired by semantic parsing (Saleh et al., 2014; Vlachos and Clark, 2014). One drawback shared by these methods is their resource requirements, either because they need to learn independent parameters for each slot and value or because they need fine-grained manual annotation at the word level. This hinders scaling to larger, more realistic application domains. Joint SLU/DST Research on belief tracking has found it advantageous to reason about SLU and DST jointly, taking ASR predictions as input and generating belief states as output (Henderson et al., 2014d; Sun et al., 2014; Zilka and Jurcicek, 2015; Mrkˇsi´c et al., 2015). In DSTC2, systems which used no externa"
P17-1163,E17-1029,0,0.0805044,"tistical models to rule-based systems (Wang and Lemon, 2013). To motivate the work presented here, we categorise prior research according to their reliance (or otherwise) on a separate SLU module for interpreting user utterances:1 Separate SLU Traditional SDS pipelines use Spoken Language Understanding (SLU) decoders to detect slot-value pairs expressed in the Automatic Speech Recognition (ASR) output. The downstream DST model then combines this information with the past dialogue context to update the belief state (Thomson and Young, 2010; Wang and Lemon, 2013; Lee and Kim, 2016; Perez, 2016; Perez and Liu, 2017; Sun et al., 2016; Jang et al., 2016; Shi et al., 2016; Dernoncourt et al., 2016; Liu and Perez, 2017; Vodol´an et al., 2017). 1 The best-performing models in DSTC2 all used both raw ASR output and the output of (potentially more than one) SLU decoders (Williams, 2014; Williams et al., 2016). This does not mean that those models are immune to the drawbacks identified here for the two model categories; in fact, they share the drawbacks of both. 1778 Figure 3: Architecture of the NBT Model. The implementation of the three representation learning subcomponents can be modified, as long as these p"
P17-1163,E17-2033,0,0.243265,"Missing"
P17-1163,C14-1020,0,0.015327,"Missing"
P17-1163,P16-1230,1,0.620378,"Missing"
P17-1163,W14-4343,0,0.159234,"more complex modelling structure inspired by semantic parsing (Saleh et al., 2014; Vlachos and Clark, 2014). One drawback shared by these methods is their resource requirements, either because they need to learn independent parameters for each slot and value or because they need fine-grained manual annotation at the word level. This hinders scaling to larger, more realistic application domains. Joint SLU/DST Research on belief tracking has found it advantageous to reason about SLU and DST jointly, taking ASR predictions as input and generating belief states as output (Henderson et al., 2014d; Sun et al., 2014; Zilka and Jurcicek, 2015; Mrkˇsi´c et al., 2015). In DSTC2, systems which used no external SLU module outperformed all systems that only used external SLU features. Joint models typically rely on a strategy known as delexicalisation whereby slots and values mentioned in the text are replaced with generic labels. Once the dataset is transformed in this manner, one can extract a collection of template-like n-gram features such as [want tagged-value food]. To perform belief tracking, the shared model iterates over all slot-value pairs, extracting delexicalised feature vectors and making a separ"
P17-1163,P17-1006,1,0.840952,"Missing"
P17-1163,W13-4067,0,0.450217,"on or request clarification from the user. As mentioned above, the DSTC shared tasks have spurred research on this problem and established a standard evaluation paradigm (Williams et al., 2013; Henderson et al., 2014b,a). In this setting, the task is defined by an ontology that enumerates the goals a user can specify and the attributes of entities that the user can request information about. Many different belief tracking models have been proposed in the literature, from generative (Thomson and Young, 2010) and discriminative (Henderson et al., 2014d) statistical models to rule-based systems (Wang and Lemon, 2013). To motivate the work presented here, we categorise prior research according to their reliance (or otherwise) on a separate SLU module for interpreting user utterances:1 Separate SLU Traditional SDS pipelines use Spoken Language Understanding (SLU) decoders to detect slot-value pairs expressed in the Automatic Speech Recognition (ASR) output. The downstream DST model then combines this information with the past dialogue context to update the belief state (Thomson and Young, 2010; Wang and Lemon, 2013; Lee and Kim, 2016; Perez, 2016; Perez and Liu, 2017; Sun et al., 2016; Jang et al., 2016; Sh"
P17-1163,D15-1199,1,0.0806639,"Missing"
P17-1163,E17-1042,1,0.597056,"Missing"
P17-1163,Q15-1025,0,0.272467,"t-value pair. 3.1 Representation Learning For any given user utterance, system act(s) and candidate slot-value pair, the representation learning submodules produce vector representations which act as input for the downstream components of the model. All representation learning subcomponents make use of pre-trained collections of word vectors. As shown by Mrkˇsi´c et al. (2016), specialising word vectors to express semantic similarity rather than relatedness is essential for improving belief tracking performance. For this reason, we use the semantically-specialised Paragram-SL999 word vectors (Wieting et al., 2015) throughout this work. The NBT training procedure keeps these vectors fixed: that way, at test time, unseen words semantically related to familiar slot values (i.e. inexpensive to cheap) will be recognised purely by their position in the original vector space (see also Rockt¨aschel et al. (2016)). This means that the NBT model parameters can be shared across all values of the given slot, or even across all slots. Let u represent a user utterance consisting of ku words u1 , u2 , . . . , uku . Each word has an associated word vector u1 , . . . , uku . We propose two model variants which differ i"
P17-1163,W14-4339,0,0.0417172,"Spoken Language Understanding (SLU) decoders to detect slot-value pairs expressed in the Automatic Speech Recognition (ASR) output. The downstream DST model then combines this information with the past dialogue context to update the belief state (Thomson and Young, 2010; Wang and Lemon, 2013; Lee and Kim, 2016; Perez, 2016; Perez and Liu, 2017; Sun et al., 2016; Jang et al., 2016; Shi et al., 2016; Dernoncourt et al., 2016; Liu and Perez, 2017; Vodol´an et al., 2017). 1 The best-performing models in DSTC2 all used both raw ASR output and the output of (potentially more than one) SLU decoders (Williams, 2014; Williams et al., 2016). This does not mean that those models are immune to the drawbacks identified here for the two model categories; in fact, they share the drawbacks of both. 1778 Figure 3: Architecture of the NBT Model. The implementation of the three representation learning subcomponents can be modified, as long as these produce adequate vector representations which the downstream model components can use to decide whether the current candidate slot-value pair was expressed in the user utterance (taking into account the preceding system act). In the DSTC challenges, some systems used th"
P17-4013,P17-1163,1,0.129908,"Missing"
P17-4013,P16-1230,1,0.713713,"Missing"
P17-4013,W14-4337,0,0.0162902,"odel for the CamRestaurants domain is provided. Evaluation To evaluate the dialogues, there are currently two success-based modules implemented. The objective task success evaluator compares the constraints and requests the system identifies with the true values. The latter may either be derived from the user simulator or, in real dialogues, by specifying a predefined task. For real dialogues, a subjective task success evaluator may also be applied which queries the user about the outcome of the dialogue. Belief Tracker For tracking the belief state, the rule-based focus tracker is available (Henderson et al., 2014). The implementation is domainindependent. All domain-specific information is drawn from the ontology. 4 www.apache.org/licenses/LICENSE-2.0 76 User Simulation The implementation of the simulated user uses the agenda-based user simulator (Schatzmann et al., 2006). The simulator contains the user model and an error model thus creating a n-best-list of user acts to simulate the noisy speech channel. By using a set of generally applicable parameters, the simulator may be applied for all domains. The domain-specific information is taken from the ontology. 4 training dialogues, the policies achieve"
P17-4013,N16-1015,1,0.253976,"Missing"
P17-4013,W16-3602,0,0.0466362,"ting algorithms (e.g., evaluating understanding or generation components in an interaction). Hence, to stimulate research and make it easy for people to get involved in statistical spoken dialogue systems, we present PyDial, a multi-domain statistical spoken dialogue system toolkit. PyDial is implemented in Python and is actively used by the Cambridge Dialogue Systems Group. PyDial supports multi-domain applications in which a conversation may range over a number of different topics. This introduces a variety of new research issues including generalised belief tracking (Mrkˇsi´c et al., 2015; Lee and Stent, 2016) rapid policy adaptation and parallel learning (Gaˇsi´c et al., 2015a,b) and natural language generation (Wen et al., 2016). Designing speech interfaces to machines has been a focus of research for many years. These Spoken Dialogue Systems (SDSs) are typically based on a modular architecture consisting of input processing modules speech recognition and semantic decoding, dialogue management modules belief tracking and policy, and output processing modules language generation and speech synthesis (see Fig. 1). Statistical SDS are speech interfaces where all SDS modules are based on statistical"
P17-4013,D15-1199,1,0.0538685,"Missing"
P17-4013,E17-1042,1,0.160833,"Missing"
P17-4013,P16-4012,0,0.0542417,", easy extensibility, and domain-independent implementations of the respective dialogue system modules. The toolkit is available for download under the Apache 2.0 license. Speech Synthesis Language Generation Belief State Policy et al., 2013; Wen et al., 2015; Su et al., 2016; Wen et al., 2017; Mrkˇsi´c et al., 2017). Despite the rich body of research on statistical SDS, there is still no common platform or open toolkit available. Other toolkit implementations usually focus on single modules (e.g. (Williams et al., 2010; Ultes and Minker, 2014) or are not full-blown statistical systems (e.g. (Lison and Kennington, 2016; Bohus and Rudnicky, 2009)). The availability of a toolkit targetted specifically at statistical dialogue systems would enable people new to the field would be able to get involved more easily, results to be compared more easily, and researchers to focus on their specific research questions instead of re-implementing algorithms (e.g., evaluating understanding or generation components in an interaction). Hence, to stimulate research and make it easy for people to get involved in statistical spoken dialogue systems, we present PyDial, a multi-domain statistical spoken dialogue system toolkit. P"
P17-4013,P15-2130,1,0.581038,"Missing"
Q17-1022,S15-1003,0,0.0166028,"scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and"
Q17-1022,Q16-1031,0,0.0184747,"gual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by co"
Q17-1022,P98-1013,0,0.0636087,"gue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating"
Q17-1022,P14-2131,0,0.0313084,"ract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories:"
Q17-1022,D14-1082,0,0.0239881,"lude: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train dis"
Q17-1022,P06-1038,0,0.011388,"enson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vecto"
Q17-1022,P14-1129,0,0.0264494,"Missing"
Q17-1022,D16-1136,0,0.0135803,"differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mitra et al., 2016), and transfer learning for reso"
Q17-1022,ehrmann-etal-2014-representing,0,0.0525517,"ural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We then deploy the ATTRACT-R EPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations. This allows us to embed vector spaces of multiple languages into a single vector space, exploiting information from high-resource languages to improve the word representations of lower-resource ones. Table 1 illustrates the effects of cross-lingual ATTRACT-R EPEL specialization by showing the nearest neighbors for three English words across three cross-lingual spaces. 309 Transactions of the Association for Computational Linguistics, vol. 5, pp. 309–324, 2017. Action Ed"
Q17-1022,E14-1049,0,0.359731,"al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vu"
Q17-1022,P15-2076,0,0.0360459,"borne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vectors. However, their performance has not surpassed that of fine-tuning methods.3 Fine-Tuning Pre-trained Vectors Rothe and Schütze (2015) fine-tune word vector spaces to improve the representations of synsets/lexemes found in WordNet. F"
Q17-1022,N15-1184,0,0.532158,"s using Monolingual and Cross-Lingual Constraints Nikola Mrkši´c1,2 , Ivan Vuli´c1 , Diarmuid Ó Séaghdha2 , Ira Leviant3 Roi Reichart3 , Milica Gaši´c1 , Anna Korhonen1 , Steve Young1,2 1 University of Cambridge 2 Apple Inc. 3 Technion, IIT Abstract These models typically build on distributional ones by using human- or automatically-constructed knowledge bases to enrich the semantic content of existing word vector collections. Often this is done as a postprocessing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrkši´c et al., 2016). We term this approach semantic specialization. We present ATTRACT-R EPEL, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. ATTRACT-R EPEL facilitates the use of constraints from mono- and crosslingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct highquality vector spaces for a plethora of different languages, facilitating semantic transfer from high-"
Q17-1022,ganitkevitch-callison-burch-2014-multilingual,0,0.0509444,"Missing"
Q17-1022,N13-1092,0,0.0261119,"Missing"
Q17-1022,D16-1235,1,0.905072,"Missing"
Q17-1022,D14-1012,0,0.0360428,"tion datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into"
Q17-1022,P15-1119,0,0.0296068,"Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mitra et al., 2016), and transfer learning for resource-lean languages (Søgaard et al., 2015; Guo et al., 2015). However, prior work on cross-lingual word embedding has tended not to exploit pre-existing linguistic resources such as BabelNet. In this work, we make use of cross-lingual constraints derived from such repositories to induce high-quality cross-lingual vector spaces by facilitating semantic transfer from highto lower-resource languages. In our experiments, we show that cross-lingual vector spaces produced by ATTRACT-R EPEL consistently outperform a representative selection of five strong cross-lingual word embedding models in both intrinsic and extrinsic evaluation across several languages."
Q17-1022,W14-4337,0,0.0396757,"re expressed by slot-value pairs such as [price: cheap] or [food: Thai]. For modular task-based systems, the Dialogue State Tracking (DST) component is in charge of maintaining the belief state, which is the system’s internal distribution over the possible states of the dialogue. Figure 1 shows the correct dialogue state for each turn of an example dialogue. Unseen Data/Labels As dialogue ontologies can be very large, many of the possible class labels (i.e., the various food types or street names) will not occur in the training set. To overcome this problem, delexicalization-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrkši´c et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values. This is done through exact matching supplemented with semantic lexicons which encode rephrasings, morphology and other linguistic variation. For instance, such lexicons would be required to deal with the underlined non-exact matches in Figure 1. Exact Matching as a Bottleneck Semantic lexicons can be hand-crafted for small dialogue domains. Mrkši´c et al. (2016) showed that semantically specialized vect"
Q17-1022,W14-4340,1,0.938481,"re expressed by slot-value pairs such as [price: cheap] or [food: Thai]. For modular task-based systems, the Dialogue State Tracking (DST) component is in charge of maintaining the belief state, which is the system’s internal distribution over the possible states of the dialogue. Figure 1 shows the correct dialogue state for each turn of an example dialogue. Unseen Data/Labels As dialogue ontologies can be very large, many of the possible class labels (i.e., the various food types or street names) will not occur in the training set. To overcome this problem, delexicalization-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrkši´c et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values. This is done through exact matching supplemented with semantic lexicons which encode rephrasings, morphology and other linguistic variation. For instance, such lexicons would be required to deal with the underlined non-exact matches in Figure 1. Exact Matching as a Bottleneck Semantic lexicons can be hand-crafted for small dialogue domains. Mrkši´c et al. (2016) showed that semantically specialized vect"
Q17-1022,P14-1006,0,0.0667397,"ts models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual"
Q17-1022,J15-4004,1,0.925417,"multilingual DST models, which brings further performance improvements. 1 In this paper we advance the semantic specialization paradigm in a number of ways. We introduce a new algorithm, ATTRACT-R EPEL, that uses synonymy and antonymy constraints drawn from lexical resources to tune word vector spaces using linguistic information that is difficult to capture with conventional distributional training. Our evaluation shows that ATTRACT-R EPEL outperforms previous methods which make use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016). Introduction Word representation learning has become a research area of central importance in modern natural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We the"
Q17-1022,D15-1127,0,0.0127607,"our method to use existing cross-lingual resources to tie distributional vector spaces of different languages into a unified vector space which benefits from positive semantic transfer between its constituent languages. 3 The SimLex-999 web page (www.cl.cam.ac.uk/ ~fh295/simlex.html) lists models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; V"
Q17-1022,D14-1070,0,0.0192932,"chart, 2015). To show that our approach yields semantically informative vectors for lower-resource languages, we collect intrinsic evaluation datasets for Hebrew and Croatian and show that cross-lingual specialization significantly improves word vector quality in these two (comparatively) low-resource languages. In the second part of the paper, we explore the use of ATTRACT-R EPEL-specialized vectors in a downstream application. One important motivation for training word vectors is to improve the lexical coverage of supervised models for language understanding tasks, e.g., question answering (Iyyer et al., 2014) or textual entailment (Rocktäschel et al., 2016). In 1 Some (negative) effects of the distributional hypothesis do persist. For example, nl_krieken (Dutch for cherries), is identified as a synonym for en_morning, presumably because the idiom ‘het krieken van de dag’ translates to ‘the crack of dawn’. 2 Our approach is not suited for languages for which no lexical resources exist. However, many languages have some coverage in cross-lingual lexicons. For instance, BabelNet 3.7 automatically aligns WordNet to Wikipedia, providing accurate cross-lingual mappings between 271 languages. In our eval"
Q17-1022,N15-1070,0,0.0340476,"ons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vectors. However, their performance has not surpassed that of fine-tuning methods.3 Fine-Tuning Pre-trained Vectors Rothe and Schütze (2015) fine-tune word vector spaces to improve the representations of synsets/lexemes found in WordNet. Faruqui et al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semantically similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB. Mrkši´c et al. (2016) build on the retrofitting approach by jointly injecting synonymy and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles o"
Q17-1022,D15-1245,0,0.0248451,"EL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations"
Q17-1022,D15-1242,0,0.0418903,"epresentations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use sy"
Q17-1022,W16-1607,0,0.169112,"Missing"
Q17-1022,C12-1089,0,0.0230184,"eover, we show that starting from distributional vectors allows our method to use existing cross-lingual resources to tie distributional vector spaces of different languages into a unified vector space which benefits from positive semantic transfer between its constituent languages. 3 The SimLex-999 web page (www.cl.cam.ac.uk/ ~fh295/simlex.html) lists models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al."
Q17-1022,2005.mtsummit-papers.11,0,0.0253673,"into a shared cross-lingual space. Ideally, sharing information across languages should lead to improved semantic content for each language, especially for those with limited monolingual resources. Antonymy BabelNet is also used to extract both monolingual and cross-lingual antonymy constraints. Following Faruqui et al. (2015), who found PPDB constraints more beneficial than the WordNet ones, we do not use BabelNet for monolingual synonymy. Availability of Resources Both PPDB and BabelNet are created automatically. However, PPDB relies on large, high-quality parallel corpora such as Europarl (Koehn, 2005). In total, Multilingual PPDB provides collections of paraphrases for 22 languages. On the other hand, BabelNet uses Wikipedia’s interlanguage links and statistical machine translation (Google Translate) to provide cross-lingual mappings for 271 languages. In our evaluation, we show that PPDB and BabelNet can be used jointly to improve word representations for lower-resource languages by tying them into bilingual spaces with high-resource ones. We validate this claim on Hebrew and Croatian, which act as ‘lower-resource’ languages because of their lack of any PPDB resource and their relatively"
Q17-1022,P15-1027,0,0.0203234,"2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mi"
Q17-1022,P14-2050,0,0.10357,"use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016). Introduction Word representation learning has become a research area of central importance in modern natural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We then deploy the ATTRACT-R EPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations. This allows us to embed vector spaces of multiple languages into a single vector space, exploiting information from high-resource languages to improve the word representations of lower-resource ones. T"
Q17-1022,P15-1145,0,0.0286255,"Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and d"
Q17-1022,W15-1521,0,0.0244293,". 3 The SimLex-999 web page (www.cl.cam.ac.uk/ ~fh295/simlex.html) lists models with state-of-the-art performance, none of which learn representations jointly. 2.2 Cross-Lingual Word Representations Most existing models which induce cross-lingual word representations rely on cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015, inter alia). These models differ in the cross-lingual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shar"
Q17-1022,P15-2130,1,0.34097,"Missing"
Q17-1022,N16-1018,1,0.276948,"Missing"
Q17-1022,P17-1163,1,0.07397,"Missing"
Q17-1022,P16-2074,0,0.108128,"-trained Vectors Rothe and Schütze (2015) fine-tune word vector spaces to improve the representations of synsets/lexemes found in WordNet. Faruqui et al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semantically similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB. Mrkši´c et al. (2016) build on the retrofitting approach by jointly injecting synonymy and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles of rich concept dictionaries to further improve a combined collection of semantically specialized word vectors. ATTRACT-R EPEL is an instance of the second family of models, providing a portable, light-weight approach for incorporating external knowledge into arbitrary vector spaces. In our experiments, we show that ATTRACT-R EPEL outperforms previously proposed post-processors, setting the new state-of-art performance on the widely"
Q17-1022,N15-1100,0,0.0338437,"ducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than representations produced by fine-tuning distributional vectors. However, their performance has not surpassed that of fine-tuning methods.3 Fine-Tunin"
Q17-1022,Q16-1030,0,0.48294,"de WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2"
Q17-1022,D14-1162,0,0.11428,"t ATTRACT-R EPEL outperforms previous methods which make use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al., 2016). Introduction Word representation learning has become a research area of central importance in modern natural language processing. The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; Ó Séaghdha and Korhonen, 2014; Levy and Goldberg, 2014). Recently, methods that go beyond stand-alone unsupervised learning have gained increased popularity. We then deploy the ATTRACT-R EPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations. This allows us to embed vector spaces of multiple languages into a single vector space, exploiting information from high-resource languages to i"
Q17-1022,N15-1058,0,0.0309108,"Missing"
Q17-1022,W16-1622,0,0.0658587,"al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semantically similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB. Mrkši´c et al. (2016) build on the retrofitting approach by jointly injecting synonymy and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles of rich concept dictionaries to further improve a combined collection of semantically specialized word vectors. ATTRACT-R EPEL is an instance of the second family of models, providing a portable, light-weight approach for incorporating external knowledge into arbitrary vector spaces. In our experiments, we show that ATTRACT-R EPEL outperforms previously proposed post-processors, setting the new state-of-art performance on the widely used SimLex-999 word similarity dataset. Moreover, we show that starting from distributional vectors allows our method to use existing cross-lingual"
Q17-1022,P15-1173,0,0.0714818,"Missing"
Q17-1022,K15-1026,1,0.312629,"al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in 311 their pattern-based vector space. Ono et al. (2015) combines both approaches, using thesauri and distributional data to train embeddings specialized for capturing antonymy. Faruqui and Dyer (2015) use many different lexicons to create interpretable sparse binary vectors which achieve competitive performance across a range of intrinsic evaluation tasks. In theory, word representations produced by models which consider distributional and lexical information jointly could be as good (or better) than represe"
Q17-1022,P13-1045,0,0.0159713,"ithub.com/nmrksic/ attract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly)"
Q17-1022,D13-1170,0,0.0047346,"ithub.com/nmrksic/ attract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly)"
Q17-1022,P15-1165,0,0.0197866,"Missing"
Q17-1022,P10-1040,0,0.0185912,"tian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical entailment (Vuli´c et al., 2016). Semantic specialization methods fall (broadly) into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexica"
Q17-1022,P16-1157,0,0.028014,"ual signal/supervision they use to tie languages into unified bilingual vector spaces: some models learn on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentence-aligned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015). Other models require document-aligned data (Søgaard et al., 2015; Vuli´c and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli´c and Korhonen, 2016b; Duong et al., 2016). See Upadhyay et al. (2016) and Vuli´c and Korhonen (2016b) for an overview of cross-lingual word embedding work. The inclusion of cross-lingual information results in shared cross-lingual vector spaces which can: a) boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al., 2013a; Gouws et al., 2015; Duong et al., 2016), cross-lingual information retrieval (Vuli´c and Moens, 2015; Mitra et al., 2016), and transfer learning for resource-lean languages (Søgaard"
Q17-1022,P16-2084,1,0.84249,"Missing"
Q17-1022,P16-1024,1,0.758571,"Missing"
Q17-1022,E17-1042,1,0.780077,"Missing"
Q17-1022,Q15-1025,0,0.116195,"d Cross-Lingual Constraints Nikola Mrkši´c1,2 , Ivan Vuli´c1 , Diarmuid Ó Séaghdha2 , Ira Leviant3 Roi Reichart3 , Milica Gaši´c1 , Anna Korhonen1 , Steve Young1,2 1 University of Cambridge 2 Apple Inc. 3 Technion, IIT Abstract These models typically build on distributional ones by using human- or automatically-constructed knowledge bases to enrich the semantic content of existing word vector collections. Often this is done as a postprocessing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrkši´c et al., 2016). We term this approach semantic specialization. We present ATTRACT-R EPEL, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. ATTRACT-R EPEL facilitates the use of constraints from mono- and crosslingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct highquality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource one"
Q17-1022,D16-1157,0,0.0166515,"nsfer (+0.19 / +0.11 over monolingual specialization), with Italian vectors’ performance coming close to the top-performing English ones. 316 Comparison to Baselines Table 3 gives an exhaustive comparison of ATTRACT-R EPEL to counterfitting: ATTRACT-R EPEL achieved substantially stronger performance in all experiments. We believe these results conclusively show that the contextsensitive updates and L2 regularization employed by ATTRACT-R EPEL present a better alternative to the context-insensitive attract/repel terms and pair-wise regularization employed by counter-fitting.11 State-of-the-Art Wieting et al. (2016) note that the hyperparameters of the widely used Paragram-SL999 vectors (Wieting et al., 2015) are tuned on SimLex999, and as such are not comparable to methods which hold out the dataset. This implies that further work which uses these vectors (e.g., (Mrkši´c et al., 11 To understand the relative importance of the contextsensitive updates and the change in regularization, we can compare the two methods to the retrofitting procedure (Faruqui et al., 2015). Retrofitting uses L2 regularization (like ATTRACTR EPEL) and a ‘global’ attract term (like counter-fitting). The performance of retrofitti"
Q17-1022,D12-1111,0,0.0614025,"Missing"
Q17-1022,P14-2089,0,0.0246193,") into two categories: a) those which train distributed representations ‘from scratch’ by combining distributional knowledge and lexical information; and b) those which inject lexical information into pretrained collections of word vectors. Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013). Learning from Scratch Some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015). Other methods modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasize word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches s"
Q17-1022,D13-1141,0,0.0291883,"rce-intensive. All resources related to this paper are available at www.github.com/nmrksic/ attract-repel. These include: 1) the ATTRACTR EPEL source code; 2) bilingual word vector collections combining English with 51 other languages; 3) Hebrew and Croatian intrinsic evaluation datasets; and 4) Italian and German Dialogue State Tracking datasets collected for this work. 2 Related Work 2.1 Semantic Specialization The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al., 2013; Devlin et al., 2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrkši´c et al., 2016; Mrkši´c et al., 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and judging lexical enta"
Q17-1022,J14-3005,1,\N,Missing
Q17-1022,C98-1013,0,\N,Missing
W03-2111,P98-2219,0,0.256071,"based dialog manager using a Wizard-ofOz trial. The state space and action set are discovered through the annotation, and an initial policy is generated using a Supervised Learning algorithm. The method is tested and shown to create an initial policy which performs significantly better and with less effort than a handcrafted policy, and can be generated using a small number of dialogs. 1 Introduction and motivation Recent work has successfully applied Reinforcement Learning (RL) to learning dialog strategy from experience, typically formulating the problem as a Markov Decision Process (MDP). (Walker et al., 1998; Singh et al., 2002; Levin et al., 2000). Despite successes, several open questions remain, especially the issue of how to create (or “bootstrap”) the initial system prior to data becoming available from on-line operation. This paper proceeds as follows. Section 2 outlines the core elements of an MDP and issues related to applying an MDP to dialog management. Sections 3 and 4 detail a method for addressing these issues, and the procedure used to test the method, respectively. Sections 5-7 present the results, a discussion, and conclusions, respectively. 2 Background An MDP is composed of a st"
W03-2111,C98-2214,0,\N,Missing
W04-3007,H94-1010,0,0.050291,"of the goal. TAN networks relax this independence assumption by adding dependencies between concepts based on the conditional mutual information (CMI) between concepts given the goal. The goal prior probability P (Gu ) and the conditional probability of each semantic concept Ci given the goal Gu , P (Ci |Gu ) are learned from the training data. Dialogue act detection is done by picking the goal with the highest posterior probability of Gu given the particular instance of concepts C1 · · · Cn , P (Gu |C1 · · · Cn ). 3 Noise Robustness The ATIS corpus which contains air travel information data (Dahl et al., 1994) has been chosen for the SLU system development and evaluation. ATIS was developed in the DARPA sponsored spoken language understanding programme conducted from 1990 to 1995 and it provides a convenient and well-documented standard for measuring the end-to-end performance of an SLU system. However, since the ATIS corpus contains only clean speech, corrupted test data has been generated by adding samples of background noise to the clean test data at the waveform level. 3.1 Experimental Setup The experimental setup used to evaluate the SLU system was similar to that described in (He and Young, 2"
W04-3007,P94-1016,0,0.0359486,"ople use different words and sentence structures to convey the same meaning. Also, many utterances are grammaticallyincorrect or ill-formed. It thus remains an open issue as to how to provide robustness for large populations of nonexpert users in spoken dialogue systems. The key component of a spoken language understanding (SLU) system is the semantic parser, which translates the users’ utterances into semantic representations. Traditionally, most semantic parser systems have been built using hand-crafted semantic grammar rules and so-called robust parsing (Ward and Issar, 1996; Seneff, 1992; Dowding et al., 1994) is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel. The frame with the highest score then yields the selected semantic representation. Formally speaking, the robustness of language (recognition, parsing, etc.) is a measure of the ability of human speakers to communicate despite incomplete information, ambiguity, and the constant element of surprise (Briscoe, 1996). In this paper, two aspects of SLU system performance are investigated: noise robustness and adaptability to different"
W04-3007,N03-1027,0,0.0303745,"iques are widely used to reduce the mismatch between training and test or to adapt a well-trained model to a novel domain. Commonly used techniques can be classified into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear how general they are. Since MAP adaptation is straightforward and has been applied successfully to PCFG parsers, it has been selected for investigation in this paper. Since one of the special forms of MAP adaptation is interpolation between the indomain and out-of-domain models, it is natural to also consider the use of non-linear int"
W04-3007,H94-1039,0,\N,Missing
W08-0119,2007.sigdial-1.37,0,0.0521487,"Missing"
W08-0119,P00-1013,0,0.016619,"ilding spoken dialogue systems which can both model these uncertainties and support policies which are robust to their effects (Young, 2002; Williams and Young, 2007a). The key idea of the POMDP is that the underlying dialogue state is hidden and dialogue management policies must therefore be based not on a single state estimate but on a distribution over all states. Whilst POMDPs are attractive theoretically, in practice, they are notoriously intractable for anything other than small state/action spaces. Hence, practical examples of their use were initially restricted to very simple domains (Roy et al., 2000; Zhang et al., 2001). More recently, however, a number of techniques have been suggested which do allow POMDPs to be scaled to handle real world tasks. The two generic mechanisms which facilitate this scaling are factoring the state space and performing policy optimisation in a reduced summary state space (Williams and Young, 2007a; Williams and Young, 2007b). Based on these ideas, a number of real-world POMDP-based systems have recently emerged. The most complex entity which must be represented in the state space is the user’s goal. In the Bayesian Update of Dialogue State (BUDS) system, the"
W08-0119,W07-0302,1,0.715176,"malisation constant (Kaelbling et al., 1998). The first term on the RHS of (1) is called the observation model and the term inside the summation is called the transition model. Maintaining this belief state as the dialogue evolves is called belief monitoring. sd Speech Understanding 1 au au Belief Estimator .. (Bui et al., 2007a; Bui et al., 2007b). An alternative approach taken in the Hidden Information State (HIS) system is to retain a complete representation of the user’s goal, but partition states into equivalence classes and prune away very low probability partitions (Young et al., 2007; Thomson et al., 2007; Williams and Young, 2007b). Whichever approach is taken, a key issue in a real POMDP-based dialogue system is its ability to be robust to noise and that is the issue that is addressed in this paper. Using the HIS system as an exemplar, evaluation results are presented for a real-world tourist information task using both simulated and real users. The results show that a POMDP system can learn noise robust policies and that N-best outputs from the speech understanding component can be exploited to further improve robustness. The paper is structured as follows. Firstly, in Section 2 a brief ove"
W09-3938,N07-2038,1,0.813235,"y Space Master Space The CUED Spoken Dialogue System Grnd UInfo ... affirm(...) Uinfo UInfo ... inform(...) b(1) ... Add items from hyp 1 Yes b(2) p h last status status uact Policy Compatible with hyp 1? No Try next Sort Figure 1: Master-summary Space Mapping. moving all act items and leaving only a reduced set of dialogue act types. When mapping back into master space, the necessary items (i.e. slot-value pairs) are inferred by inspecting the most likely dialogue state hypotheses. The optimal policy is obtained using reinforcement learning in interaction with an agenda based simulated user (Schatzmann et al., 2007). At the end of each dialogue a reward is given to the system: +20 for a successful completion and -1 for each turn. A grid-based optimisation is used to obtain the optimal policy (see next section). At each turn the belief is mapped to a summary point from which a summary action can be determined. The summary action is then mapped back to a master action by adding the relevant information. HIS Dialogue Manager The unobserved dialogue state of the HIS dialogue manager consists of the user goal, the dialogue history and the user action. The user goal is represented by a partition which is a tre"
W10-4323,N07-2038,1,0.614261,"er to generate a sufficiently large number of interactions to learn from, this effectiveness depends largely on the quality of such a user simulator. An important requirement for a simulator is for it to be realistic, i.e., it should generate behaviour that is similar to that of real users. Trained policies are then more likely to perform better on real users, and evaluation results on simulated data are more likely to predict results on real data more accurately. 2 Agenda-based user simulation In agenda-based user simulation, user acts are generated on the basis of a user goal and an agenda (Schatzmann et al., 2007a). The simulator presented here is developed and used for a tourist in∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 116–123, c The University of Tokyo, September 24-25, 2010. 2010 Association for Computational Linguistics 116 formation application, but is sufficiently generic to accommodate slot-filling applications in any domain.1 The user"
W10-4323,2007.sigdial-1.48,1,0.95671,"er to generate a sufficiently large number of interactions to learn from, this effectiveness depends largely on the quality of such a user simulator. An important requirement for a simulator is for it to be realistic, i.e., it should generate behaviour that is similar to that of real users. Trained policies are then more likely to perform better on real users, and evaluation results on simulated data are more likely to predict results on real data more accurately. 2 Agenda-based user simulation In agenda-based user simulation, user acts are generated on the basis of a user goal and an agenda (Schatzmann et al., 2007a). The simulator presented here is developed and used for a tourist in∗ This research was partly funded by the UK EPSRC under grant agreement EP/F013930/1 and by the EU FP7 Programme under grant agreement 216594 (CLASSiC project: www.classic-project.org). Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 116–123, c The University of Tokyo, September 24-25, 2010. 2010 Association for Computational Linguistics 116 formation application, but is sufficiently generic to accommodate slot-filling applications in any domain.1 The user"
W11-2002,2007.sigdial-1.23,1,\N,Missing
W12-1609,W09-3902,0,0.0733392,"Missing"
W12-1609,E09-1081,0,0.0278828,"Missing"
W13-4035,W10-4323,1,0.713546,"Missing"
W13-4035,P99-1024,0,0.0861553,"ing Department {mg436,cb404,mh521,dk449,mos25,brmt2,pt344,sjy}@eng.cam.ac.uk Abstract restaurant where I can eat outside”. In order to make this possible, techniques will be needed to extend and adapt existing dialogue policies. Adaptation can be viewed as a process of improving action selection in a different condition to the one in which the policy was originally trained. While adaptation has been extensively studied in speech recognition (see an overview in (Gales and Young, 2007)), in spoken dialogue systems it is still relatively novel and covers a wide range of possible research topics (Litman and Pan, 1999; Litman and Pan, 2002; Georgila and Lemon, 2004; Janarthanam and Lemon, 2010). A recent trend in statistical dialogue modelling has been to model dialogue as a partially observable Markov decision process (POMDP). This provides increased robustness to errors in speech understanding and automatic dialogue policy optimisation via reinforcement learning (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007; Young et al., 2010; Thomson and Young, 2010). A POMDP-based dialogue manager maintains a distribution over every possible dialogue state at every dialogue turn. This is called the b"
W13-4035,W10-4334,1,0.899559,"Missing"
W13-4035,P00-1013,0,0.0644165,". While adaptation has been extensively studied in speech recognition (see an overview in (Gales and Young, 2007)), in spoken dialogue systems it is still relatively novel and covers a wide range of possible research topics (Litman and Pan, 1999; Litman and Pan, 2002; Georgila and Lemon, 2004; Janarthanam and Lemon, 2010). A recent trend in statistical dialogue modelling has been to model dialogue as a partially observable Markov decision process (POMDP). This provides increased robustness to errors in speech understanding and automatic dialogue policy optimisation via reinforcement learning (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007; Young et al., 2010; Thomson and Young, 2010). A POMDP-based dialogue manager maintains a distribution over every possible dialogue state at every dialogue turn. This is called the belief state. Based on that distribution the system chooses the action that gives the highest expected reward, measured by the Q-function. The Q-function for a belief state and an action is the expected cumulative reward that can be obtained if that action is taken in that belief state. The optimisation typically requires O(105 ) to O(106 ) dialogues, so is normally don"
W13-4035,W10-4324,0,0.0246016,".ac.uk Abstract restaurant where I can eat outside”. In order to make this possible, techniques will be needed to extend and adapt existing dialogue policies. Adaptation can be viewed as a process of improving action selection in a different condition to the one in which the policy was originally trained. While adaptation has been extensively studied in speech recognition (see an overview in (Gales and Young, 2007)), in spoken dialogue systems it is still relatively novel and covers a wide range of possible research topics (Litman and Pan, 1999; Litman and Pan, 2002; Georgila and Lemon, 2004; Janarthanam and Lemon, 2010). A recent trend in statistical dialogue modelling has been to model dialogue as a partially observable Markov decision process (POMDP). This provides increased robustness to errors in speech understanding and automatic dialogue policy optimisation via reinforcement learning (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007; Young et al., 2010; Thomson and Young, 2010). A POMDP-based dialogue manager maintains a distribution over every possible dialogue state at every dialogue turn. This is called the belief state. Based on that distribution the system chooses the action that giv"
W13-4073,W11-2002,1,0.271518,"elief tracking has recently been alluded to by Williams (2012a) and Li et al. (2013), and was a prominent theme in the results of the DSTC. More information on the DSTC is available at http://research.microsoft.com/en-us/events/dstc/ 467 Proceedings of the SIGDIAL 2013 Conference, pages 467–471, c Metz, France, 22-24 August 2013. 2013 Association for Computational Linguistics 2 The Dialog State Tracking Challenge t This section describes the domain and methodology of the Dialog State Tracking Challenge (DSTC). The Challenge uses data collected during the course of the Spoken Dialog Challenge (Black et al., 2011), in which participants implemented dialog systems to provide bus route information in the city of Pittsburgh. This provides a large corpus of real phonecalls from members of the public with real information needs. Set train1a train1b&c Number of calls 1013 10619 train2 678 train3 779 test1 765 test2 983 test3 1037 test4 451 (0 . . . t − T ) t−T +1 f1 f1 (t, v) f1 (t − T + 1, v) f2 f2 (t, v) f2 (t − T + 1, v) fM (t, v) fM (t − T + 1, v) .. . fM Pt−T 0 t0 =0 f1 (t , Pt−T 0 t0 =0 f2 (t , Pt−T t0 =0 fM v) v) (t0 , v)   h1 = tanh(W0 f T + b0 )   h2 = tanh(W1 hT1 + b1 ) Notes Labelled training"
W13-4073,W12-1812,0,\N,Missing
W13-4073,W13-4065,0,\N,Missing
W14-4336,P13-1123,1,0.850652,"Missing"
W14-4336,W13-4026,1,0.906157,"LG) components. We demonstrate a mobile application in English and Mandarin to test and evaluate components of the Parlance dialogue system for interactive search under real-world conditions. 1 Introduction With the advent of evaluations “in the wild”, emphasis is being put on converting research prototypes into mobile applications that can be used for evaluation and data collection by real users downloading the application from the market place. This is the motivation behind the work demonstrated here where we present a modular framework whereby research components from the Parlance project (Hastie et al., 2013) can be plugged in, tested and evaluated in a mobile environment. The goal of Parlance is to perform interactive search through speech in multiple languages. The domain for the demonstration system is interactive search for restaurants in Cambridge, UK for Mandarin and San Francisco, USA for English. The scenario is that Mandarin speaking tourists would be able to download the application and use it to learn about restaurants in English speaking towns and cities. 2 Figure 1: Overview of the Parlance Mandarin mobile application system architecture Figure 2: Overview of the Parlance English mobi"
W14-4340,W13-4073,1,0.748986,"ng the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engineering. Instead of using inputs with a"
W14-4340,W14-4337,1,0.816411,"onsiders mapping directly from ASR hypotheses to an updated belief state at each 292 Proceedings of the SIGDIAL 2014 Conference, pages 292–299, c Philadelphia, U.S.A., 18-20 June 2014. 2014 Association for Computational Linguistics ASR output which includes previously unseen slot values. In summary, this paper presents a word-based approach to dialog state tracking using recurrent neural networks. The model is capable of generalising to unseen dialog state hypotheses, and requires very little feature engineering. The approach is evaluated in the second Dialog State Tracking Challenge (DSTC2) (Henderson et al., 2014) where it is shown to be extremely competitive, particularly in terms of the quality of its confidence scores. Following a brief outline of DSTC2 in section 2, the definition of the model is given in section 3. Section 4 then gives details on the initialisation methods used for training. Finally results on the DSTC2 evaluation are given in 5. tracking the restaurant search method. A DSTC2 tracker must therefore report: 2 A tracker may report the goals as a joint over all slots, but in this paper the joint is reported as a product of the marginal distributions per slot. Full details of the chal"
W14-4340,W13-4066,0,0.075663,"}@eng.cam.ac.uk Abstract turn in the dialog, omitting the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for f"
W14-4340,W13-4069,0,0.0211755,"turn in the dialog, omitting the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engi"
W14-4340,W13-4071,0,0.00701048,"based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engineering. Instead of using inputs with a select few very informative features, the appr"
W14-4340,W13-4068,0,0.0310306,"e dialog, omitting the intermediate SLU processing step. This word-based state tracking avoids the need for an explicit semantic representation and also avoids the possibility of information loss at the SLU stage. Recurrent neural networks (RNNs) provide a natural model for state tracking in dialog, as they are able to model and classify dynamic sequences with complex behaviours from step to step. Whereas, most previous approaches to discriminative state tracking have adapted stationary classifiers to the temporal process of dialog (Bohus and Rudnicky, 2006; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). One notable exception is Ren et al. (2013), which used conditional random fields to model the sequence temporally. Currently proposed methods of discriminative state tracking require engineering of feature functions to represent the turn in the dialog (Ren et al., 2013; Lee and Eskenazi, 2013; Lee, 2013; Williams, 2013; Henderson et al., 2013b). It is unclear whether differences in performance are due to feature engineering or the underlying models. This paper proposes a method of using simple ngram type features which avoid the need for feature engineering. Instead"
W15-4639,D10-1049,0,0.0325542,"ural than a rule-based generator. Moreover, by sampling utterances from the top reranked output, our system can also generate linguistically varied utterances. Section 4.4 provides a more detailed analysis of the contribution of each component of the system to the final performance. We conclude with a brief summary and future work in Section 5. 2 Statistical approaches have also been studied for sentence planning, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010). Angeli et al. (2010) train a set of log-linear models to predict individual generation decisions given the previous ones, using only domain-independent features. Along similar lines, by casting NLG as a template extraction and reranking problem, Kondadadi et al. (2013) show that outputs produced by an SVM reranker are comparable to human-authored texts. The use of neural network-based approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is a network based NLG system, in which the generation task is divided into a sememe-to-morpheme network followed by a morpheme-to-phrase net"
W15-4639,P14-1062,0,0.0291783,"icalised corpus (Henderson et al., 2014) whereby each value has been replaced by a symbol representing its corresponding slot. In a final postprocessing phase, these slot symbols are converted back to the corresponding slot values. While generating, the RNN generator is conditioned on an auxiliary dialogue act feature and a controlling gate to over-generate candidate utterances for subsequent reranking. In order to account for arbitrary slot-value pairs that cannot be routinely delexicalized in our corpus, Section 3.1 describes a convolutional neural network (CNN) (Collobert and Weston, 2008; Kalchbrenner et al., 2014) sentence model which is used to validate the semantic consistency of candidate utterances during reranking. Finally, by adding a backward RNNLM reranker into the model in Section 3.2, output fluency is further improved. Training and decoding details of the proposed system are described in Section 3.3 and 3.4. Section 4 presents an evaluation of the proposed system in the context of an application providing information about restaurants in the San Francisco area. In Section 4.2, we first show that new generator outperforms Oh and Rudnicky (2000)’s utterance class LM approach using objective me"
W15-4639,D14-1181,0,0.0047919,"ave been investigated to learn distributed representations for phrases and even sentences by training models using different structures (Collobert and Weston, 2008; Socher et al., 2013). Convolutional Neural Networks (CNNs) were first studied in computer vision for object recognition (Lecun et al., 1998). By stacking several convolutional-pooling layers followed by a fully connected feed-forward network, CNNs are claimed to be able to extract several levels of translational-invariant features that are useful in classification tasks. The convolutional sentence model (Kalchbrenner et al., 2014; Kim, 2014) adopts the same methodology but collapses the two dimensional convolution and pooling process into a single dimension. The resulting model is claimed to represent the state-of-the-art for many speech and NLP related tasks (Kalchbrenner et al., 2014; Sainath et al., 2013). 3 erated (Karpathy and Fei-Fei, 2014) or some required constraint is satisfied (Zhang and Lapata, 2014), the network can produce a sequence of tokens which can be lexicalised to form the required utterance. In order to ensure that the generated utterance represents the intended meaning, the input vectors wt are augmented by"
W15-4639,P13-1138,0,0.0157102,"the system to the final performance. We conclude with a brief summary and future work in Section 5. 2 Statistical approaches have also been studied for sentence planning, for example, generating the most likely context-free derivations given a corpus (Belz, 2008) or maximising the expected reward using reinforcement learning (Rieser and Lemon, 2010). Angeli et al. (2010) train a set of log-linear models to predict individual generation decisions given the previous ones, using only domain-independent features. Along similar lines, by casting NLG as a template extraction and reranking problem, Kondadadi et al. (2013) show that outputs produced by an SVM reranker are comparable to human-authored texts. The use of neural network-based approaches to NLG is relatively unexplored. The stock reporter system ANA by Kukich (1987) is a network based NLG system, in which the generation task is divided into a sememe-to-morpheme network followed by a morpheme-to-phrase network. Recent advances in recurrent neural network-based language models (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies for both"
W15-4639,P98-1116,0,0.0438205,"Z, UK {thw28,mg436,dk449,nm480,phs26,djv27,sjy}@cam.ac.uk Abstract 2014). However, due to the difficulty of collecting semantically-annotated corpora, the use of data-driven NLG for SDS remains relatively unexplored and rule-based generation remains the norm for most systems (Cheyer and Guzzoni, 2007; Mirkovic and Cavedon, 2011). The goal of the NLG component of an SDS is to map an abstract dialogue act consisting of an act type and a set of attribute-value pairs1 into an appropriate surface text (see Table 1 below for some examples). An early example of a statistical NLG system is HALOGEN by Langkilde and Knight (1998) which uses an n-gram language model (LM) to rerank a set of candidates generated by a handcrafted generator. In order to reduce the amount of handcrafting and make the approach more useful in SDS, Oh and Rudnicky (2000) replaced the handcrafted generator with a set of word-based n-gram LM-based generators, one for each dialogue type and then reranked the generator outputs using a set of rules to produce the final response. Although Oh and Rudnicky (2000)’s approach limits the amount of handcrafting to a small set of post-processing rules, their system incurs a large computational cost in the"
W15-4639,P13-1123,0,0.044241,"een made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains (Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 1 Here and elsewhere, attributes are frequently referred to as slots. 275 Proceedings of the SIGDIAL 2015 Conference, pages 275–284, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics face realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004; Dethlefs et al., 2013). As noted above, one of the first statistical NLG methods that requires almost no handcrafting or semantic alignments was an n-gram based approach by Oh and Rudnicky (2000). Ratnaparkhi (2002) later addressed the limitations of n-gram LMs in the overgeneration phase by using a more sophisticated generator based on a syntactic dependency tree. log act-utterance pairs without any semantic alignments between the two. We start in Section 3 by presenting a generator based on a recurrent neural network language model (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) which is trained on a delexi"
W15-4639,J14-4003,1,0.937579,"-based generators, one for each dialogue type and then reranked the generator outputs using a set of rules to produce the final response. Although Oh and Rudnicky (2000)’s approach limits the amount of handcrafting to a small set of post-processing rules, their system incurs a large computational cost in the over-generation phase and it is difficult to ensure that all of the required semantics are covered by the selected output. More recently, a phrase-based NLG system called BAGEL trained from utterances aligned with coarse-grained semantic concepts has been described (Mairesse et al., 2010; Mairesse and Young, 2014). By implicitly modelling paraphrases, Bagel can generate linguistically varied utterances. However, collecting semantically-aligned corpora is expensive and time consuming, which limits Bagel’s scalability to new domains. This paper presents a neural network based NLG system that can be fully trained from diaThe natural language generation (NLG) component of a spoken dialogue system (SDS) usually needs a substantial amount of handcrafting or a well-labeled dataset to be trained on. These limitations add significantly to development costs and make cross-domain, multi-lingual dialogue systems i"
W15-4639,P10-1157,1,0.922895,"Missing"
W15-4639,D13-1170,0,0.00157564,"utterance, and simple unconstrained RNNLMs which rely on emConventional approaches to NLG typically divide the task into sentence planning, and surface realisation. Sentence planning maps input semantic symbols into an intermediary tree-like or template structure representing the utterance, then sur276 bedding at the word level (Mikolov et al., 2013; Pennington et al., 2014) are rather poor at this. As a consequence, new methods have been investigated to learn distributed representations for phrases and even sentences by training models using different structures (Collobert and Weston, 2008; Socher et al., 2013). Convolutional Neural Networks (CNNs) were first studied in computer vision for object recognition (Lecun et al., 1998). By stacking several convolutional-pooling layers followed by a fully connected feed-forward network, CNNs are claimed to be able to extract several levels of translational-invariant features that are useful in classification tasks. The convolutional sentence model (Kalchbrenner et al., 2014; Kim, 2014) adopts the same methodology but collapses the two dimensional convolution and pooling process into a single dimension. The resulting model is claimed to represent the state-o"
W15-4639,P04-1011,0,0.760574,"icant progress has been made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains (Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 1 Here and elsewhere, attributes are frequently referred to as slots. 275 Proceedings of the SIGDIAL 2015 Conference, pages 275–284, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics face realisation converts the intermediate structure into the final text (Walker et al., 2002; Stent et al., 2004; Dethlefs et al., 2013). As noted above, one of the first statistical NLG methods that requires almost no handcrafting or semantic alignments was an n-gram based approach by Oh and Rudnicky (2000). Ratnaparkhi (2002) later addressed the limitations of n-gram LMs in the overgeneration phase by using a more sophisticated generator based on a syntactic dependency tree. log act-utterance pairs without any semantic alignments between the two. We start in Section 3 by presenting a generator based on a recurrent neural network language model (RNNLM) (Mikolov et al., 2010; Mikolov et al., 2011a) whic"
W15-4639,D14-1003,0,0.0201042,"cases. Secondly, a backward RNNLM is used to rerank utterances presented in reverse order. 3.1 where h is the size of embedding and k = 1 . . . K. Last, the K pooled feature vectors hk are passed through a nonlinearity function to obtain the final feature map. 3.2 As noted earlier, the quality of an RNN language model may be improved if both forward and backward contexts are considered. Previously, bidirectional RNNs (Schuster and Paliwal, 1997) have been shown to be effective for handwriting recognition (Graves et al., 2008), speech recognition (Graves et al., 2013), and machine translation (Sundermeyer et al., 2014). However, applying a bidirectional RNN directly in our generator is not straightforward since the generation process is sequential in time. Hence instead of integrating the bidirectional information into a single unified network, the forward and backward contexts are utilised separately by firstly generating candidates using the forward RNN generator, then using the log-likelihood computed by a backward RNNLM to rerank the candidates. Convolutional Sentence Model The CNN sentence model is shown in Figure 2. Given a candidate utterance of length n, an utterance matrix U is constructed by stack"
W15-4639,W00-0306,0,0.597199,"Missing"
W15-4639,P02-1040,0,0.112861,"y (Bergstra et al., 2010; Bastien et al., 2012). The system was trained by partitioning the 5193 utterances into a training set, validation set, and testing set in the ratio 3:1:1, respectively. The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform. Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below4 were averaged over 10 randomly initialised networks. The BLEU-4 metric was used for the objective evaluation (Papineni et al., 2002). Multiple references for each test dialogue act were obtained by mapping them back to the 228 distinct dialogue acts, merging those delexicalised templates that have the same dialogue act specification, and then lexicalising those templates back to Decoding R = −(costf RN N + costbRN N + costCN N ). Experiments (9) In order to severely penalise nonsensical utterances, λ is set to 100 for both the proposed RNN system and our implementation of Oh and Rudnicky (2000)’s n-gram based system. This reranking criterion is used for both the automatic evaluation in Section 4.2 and the human evaluation"
W15-4639,D14-1162,0,0.111104,"escribes interesting work using RNNs to generate Chinese poetry. Related Work A specific requirement of NLG for dialogue systems is that the concepts encoded in the abstract system dialogue act must be conveyed accurately by the generated surface utterance, and simple unconstrained RNNLMs which rely on emConventional approaches to NLG typically divide the task into sentence planning, and surface realisation. Sentence planning maps input semantic symbols into an intermediary tree-like or template structure representing the utterance, then sur276 bedding at the word level (Mikolov et al., 2013; Pennington et al., 2014) are rather poor at this. As a consequence, new methods have been investigated to learn distributed representations for phrases and even sentences by training models using different structures (Collobert and Weston, 2008; Socher et al., 2013). Convolutional Neural Networks (CNNs) were first studied in computer vision for object recognition (Lecun et al., 1998). By stacking several convolutional-pooling layers followed by a fully connected feed-forward network, CNNs are claimed to be able to extract several levels of translational-invariant features that are useful in classification tasks. The"
W15-4639,H94-1039,0,0.0636546,"rk structure which can be trained on dialogue act-utterance pairs without any semantic alignments or predefined grammar trees. Objective metrics suggest that this new model outperforms previous methods under the same experimental conditions. Results of an evaluation by human judges indicate that it produces not only high quality but linguistically varied utterances which are preferred compared to n-gram and rule-based systems. 1 Introduction Conventional spoken dialogue systems (SDS) are expensive to build because many of the processing components require a substantial amount of handcrafting (Ward and Issar, 1994; Bohus and Rudnicky, 2009). In the past decade, significant progress has been made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains (Young et al., 2013; Gaˇsi´c et al., 2014; Henderson et al., 1 Here and elsewhere, attributes are frequently referred to as slots. 275 Proceedings of the SIGDIAL 2015 Conference, pages 275–284, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics face realisation converts the intermedia"
W15-4639,D14-1074,0,0.0261123,"have demonstrated the value of distributed representations and the ability to model arbitrarily long dependencies for both speech recognition and machine translation tasks. Sutskever et al. (2011) describes a simple variant of the RNN that can generate meaningful sentences by learning from a character-level corpus. More recently, Karpathy and Fei-Fei (2014) have demonstrated that an RNNLM is capable of generating image descriptions by conditioning the network model on a pre-trained convolutional image feature representation. This work provides a key inspiration for the system described here. Zhang and Lapata (2014) describes interesting work using RNNs to generate Chinese poetry. Related Work A specific requirement of NLG for dialogue systems is that the concepts encoded in the abstract system dialogue act must be conveyed accurately by the generated surface utterance, and simple unconstrained RNNLMs which rely on emConventional approaches to NLG typically divide the task into sentence planning, and surface realisation. Sentence planning maps input semantic symbols into an intermediary tree-like or template structure representing the utterance, then sur276 bedding at the word level (Mikolov et al., 2013"
W15-4639,E09-1078,0,\N,Missing
W15-4639,C98-1112,0,\N,Missing
W16-3635,N09-1050,0,0.0557296,"Missing"
W16-3635,W15-4617,0,0.0221008,"Missing"
W16-3635,W13-1704,0,0.0299256,"r speech grading to automate the holistic scoring of the conversational speech of non-native speakers of English. 1 Do you work or are you a student I’m a student in university er And what subject are you studying Figure 1: Testing dialogue excerpt between an IELTS human examiner (E) and a candidate (C) (Seedhouse et al., 2014). should be able to build on. Third, there is increasing interest in building automated systems not to replace human examiners during testing, but to help candidates prepare for human testing. Similarly to systems for writing (Burstein et al., 2004; Roscoe et al., 2012; Andersen et al., 2013; Foltz and Rosenstein, 2015), automation could provide unlimited self-assessment and practice opportunities. There is already some educationally-oriented SDS work in computer assisted language learning (Su et al., 2015) and physics tutoring (ForbesRiley and Litman, 2011) to potentially build upon. On the other hand, differences between speaking assessment and traditional SDS applications can also pose research challenges. First, currently available SDS corpora do not focus on including speech from non-native speakers, and when such speech exists it is not scored for English skill. Even if one"
W16-3635,P14-1123,0,0.0335759,"Missing"
W16-3635,P15-2130,1,0.882733,"Missing"
W16-3635,W11-2002,1,0.852474,"Missing"
W16-3635,P15-1105,0,0.0291213,"Missing"
W16-3635,N13-1098,1,0.895007,"Missing"
W16-3635,N13-1101,0,0.0155052,"alogues that are our target for automatic assessment.4 Second, there is a lack of optimal technical infrastructure. Existing SDS components such as speech recognizers will likely need modification to handle nonIntroduction Speaking tests for assessing non-native speakers of English (NNSE) often include tasks involving interactive dialogue between a human examiner and a candidate. An IELTS1 example is shown in Figure 1. In contrast, most automated spoken assessment systems target only the non-interactive portions of existing speaking tests, e.g., the task of responding to a stimulus in TOEFL2 (Wang et al., 2013) or BULATS3 (van Dalen et al., 2015). This gap between the current state of manual and automated testing provides an opportunity for spoken dialogue systems (SDS) research. First, as illustrated by Figure 1, human-human testing dialogues share some features with existing computer-human dialogues, e.g., examiners use standardized topic-based scripts and utterance phrasing. Second, automatic assessment of spontaneous (but non-conversational) speech is an active research area (Chen et al., 2009; Chen and Zechner, 2011; Wang et al., 2013; Bhat et al., 2014; van Dalen et al., 2015; Shashidhar et al"
W16-3635,P11-1073,0,\N,Missing
W17-5509,W15-4603,1,0.833217,"ccessfully used: k((b, a), (b0 , a0 )) = δ(a, a0 ) · klin (b, b0 ) . (5) ! = f (rt+1 , w) + γf (Rt+1 , w) (8) must hold. This is true in case of using a linear scalarization function f (Eq. 6). To alter the kernel accordingly, a linear kernel for w is added to the state kernel1 resulting in k((b, a, w), (b0 , a0 , w0 )) (4)  = δ(a, a0 ) · klin (b, b0 ) + klin (w, w0 ) . (9) It consists of a linear kernel for the continuous belief representation b and the δ-kernel for the discrete system action a. 1 A similar type of kernel extension has been proposed previously in a different context, e.g., (Casanueva et al., 2015). 66 a suitable weight configuration, a single-objective policy may be trained. Algorithm 1: Training of the MO-GPSARSA. 1 2 3 4 5 6 7 8 Input: dialogue success reward rs , dialogue length penalty rl foreach training dialogue do select ws , wl randomly execute dialogue and record (bt , at , w) in D for each turn t // dialogue length penalty r ← wl · |D |· rl // dialogue success reward if dialogue successful then r ← r + wr · rs update GP using D and r reset D 4 The reward balancing method described in the previous section is applied to six domains: finding TVs, laptops, restaurants or hotels ("
W17-5509,P16-1230,1,0.850667,"Missing"
W17-5509,P17-4013,1,0.893124,"Missing"
W17-5509,E06-2009,0,\N,Missing
W17-5518,W17-5512,1,0.87681,"Missing"
W17-5518,W15-4653,1,0.862045,"Missing"
W17-5518,J08-4002,0,0.733963,"ng neural networkbased dialogue models, mostly in text-based systems (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2015; Wen et al., 2017; Bordes et al., 2017). These systems are directly trained on past dialogues without detailed specification of the internal dialogue state. However, there are two key limitations of using SL in SDS. Firstly, the effect of selecting an action on the future course of the dialogue is not considered and this may result in sub-optimal behaviour. Secondly, there will often be a large number of dialogue states which are not covered by the training data (Henderson et al., 2008; Li et al., 2014). Moreover, there is no reason to suppose that the recorded dialogue participants are acting optimally, especially in high noise levels. These problems are exacerbated in larger domains where multi-step planning is needed. In this paper, we propose a network-based approach to policy learning which combines the best of both SL- and RL-based dialogue management, and which capitalises on recent advances in deep RL (Mnih et al., 2015), especially off-policy algorithms (Wang et al., 2017). The main contribution of this paper is two-fold: 2 Related Work RL-based approaches to dialo"
W17-5518,W14-4340,1,0.82311,"-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management Pei-Hao Su, Paweł Budzianowski, Stefan Ultes, Milica Gaˇsi´c, and Steve Young Department of Engineering, University of Cambridge, Cambridge, UK {phs26, pfb30, su259, mg436, sjy11}@cam.ac.uk Abstract domain that the system can talk about. The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components. This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkˇsi´c et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gaˇsi´c and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has"
W17-5518,P17-1163,1,0.900144,"Missing"
W17-5518,E09-1078,0,0.0608583,"k Abstract domain that the system can talk about. The development of a robust SDS traditionally requires a substantial amount of hand-crafted rules combined with various statistical components. This includes a spoken language understanding module (Chen et al., 2016; Yang et al., 2017), a dialogue belief state tracker (Henderson et al., 2014; Perez and Liu, 2016; Mrkˇsi´c et al., 2017) to predict user intent and track the dialogue history, a dialogue policy (Young et al., 2013; Gaˇsi´c and Young, 2014; Budzianowski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurˇc´ıcˇ ek et al., 2011). In this framework, the system learn"
W17-5518,P00-1013,0,0.165669,"wski et al., 2017) to determine the dialogue flow, and a natural language generator (Rieser and Lemon, 2009; Wen et al., 2015; Hu et al., 2017) to convert conceptual representations into system responses. In a task-oriented SDS, teaching a system how to respond appropriately in all situations is nontrivial. Traditionally, this dialogue management component has been designed manually using flow charts. More recently, it has been formulated as a planning problem and solved using reinforcement learning (RL) to optimise a dialogue policy through interaction with users (Levin and Pieraccini, 1997; Roy et al., 2000; Williams and Young, 2007; Jurˇc´ıcˇ ek et al., 2011). In this framework, the system learns by a trial and error process governed by a potentially delayed learning objective called the reward. This reward is designed to encapsulate the desired behavioural features of the dialogue. Typically it provides a positive reward for success plus a per turn penalty to encourage short dialogues (El Asri et al., 2014; Su et al., 2015a; Vandyke et al., 2015; Su et al., 2016b). To allow the system to be trained on-line, Bayesian sample-efficient learning algorithms have been proposed (Gaˇsi´c and Young, 20"
W17-5518,D16-1127,0,0.0506184,"cy. Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gaˇsi´c et al., 2013). A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017). Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning. All these studies were conducted in simulation, using error-free text-based input. A similar approach was also used in a conversational model (Li et al., 2016). In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels. 3 Figure 1: A2C, TRACER and eNACER architectures using feed-forward neural networks. or policy-based methods. In both cases, the goal is to find an optimal policy π ∗ that maximises the PT −1 t discounted total return R = t=0 γ rt (bt , at ) over a dialogue with T turns where rt (bt , at ) is the reward when taking action at in dialogue belief state bt at turn t and γ is the discount factor. The main difference betwe"
W17-5518,P15-1152,0,0.0430799,"Missing"
W17-5518,E17-1042,1,0.886139,"Missing"
W17-5518,D15-1199,1,0.88724,"Missing"
W17-5518,P17-1062,0,0.279183,"ptimised Gaussian kernel learned using SL from a dialogue corpus has been proposed (Chen et al., 2015). The resulting kernel was more accurate on data correlation and achieved better performance, however, the SL corpus did not help to initialise a better policy. Better initialisation of GPRL has been studied in the context of domain adaptation by specifying a GP prior or re-using an existing model which is then pre-trained for the new domain (Gaˇsi´c et al., 2013). A number of authors have proposed training a standard neural-network policy in two stages (Fatemi et al., 2016; Su et al., 2016a; Williams et al., 2017). Asadi and Williams (2016) also explored off-policy RL methods for dialogue policy learning. All these studies were conducted in simulation, using error-free text-based input. A similar approach was also used in a conversational model (Li et al., 2016). In contrast, our work introduces two new sample-efficient actor-critic methods, combines both two-stage policy learning and off-policy RL, and testing at differing noise levels. 3 Figure 1: A2C, TRACER and eNACER architectures using feed-forward neural networks. or policy-based methods. In both cases, the goal is to find an optimal policy π ∗"
W17-5518,P16-1230,1,0.846522,"Missing"
W17-5518,W15-4655,1,0.766604,"Missing"
W17-5518,P17-4013,1,0.817383,"w. Note that yt is evaluated by a target network w− which is updated less frequently than the network w to stabilise learning, and the expectation is over the tuples (bt , at , rt+1 , bt+1 ) sampled from the experience replay pool described in §3.1.2. DQN often suffers from over-estimation on Qvalues as the max operator is used to select an action as well as to evaluate it. Double DQN (DDQN) (Van Hasselt et al., 2016) is thus used to de-couple the action selection and Q-value estimation to achieve better performance. Experimental Results Our experiments utilised the software tool-kit PyDial (Ultes et al., 2017), which provides a platform for modular SDS. The target application is a live telephone-based SDS providing restaurant information for the Cambridge (UK) area. The task is to learn a policy which manages the dialogue flow and delivers requested information to the user. The domain consists of approximately 100 venues, each with 6 slots out of which 3 can be used by the system to constrain the search (food-type, area and price-range) and 3 are system-informable properties (phone-number, address and postcode) available once a database entity has been found. The input for all models was the full d"
W17-5518,W16-3613,0,\N,Missing
W17-5521,L16-1435,1,0.845456,"f Engineering, University of Cambridge, Cambridge, UK {kyusongl,tianchez,yulund,edcai,arlu,max}@cs.cmu.edu 1 {pincus, traum}@ict.usc.edu 2 {su259,lmr46,mg436,sjy11}@eng.cam.ac.uk Abstract what users might expect, given their exposure to the Amazon ECHO1 and Google HOME2 , etc. In order to get a flow of users started, DialPort developers expanded the number of connected systems to make the portal offerings more attractive and relevant. They also made the interface easier to use. By the end of March 2017, in addition to the above systems, the portal also included Mr. Clue, a word game from USC (Pincus and Traum, 2016), a restaurant opinion bot (Let’s Discuss, CMU), and a bus information system derived from Let’s Go (Raux et al., 2005). The portal offers users the option of typing or talking and of seeing an agent or just hearing it. With few connected systems in previous versions it was difficult to assess the portal’s switching mechanisms. The increased number of systems challenges the portal to make better decisions and have better a switching strategy. It also demands changes in the frequency of recommendations to connected systems. And it challenged the nature of the agent: some users prefer no visual"
W17-5521,P94-1001,1,0.116125,"the use of a visual agent, the absence of both graphical and speech response, feedback and portal behavior. Some ES need graphics to supplement their verbal information. Since Mr Clue keeps score and timing of users’ answers, its instructions and scores are shown on a blackboard. Let’s Go shows a map with the bus trajectory from departure to arrival. Feedback and communication The portal gives users feedback for: available topics, system state, and present system state. Skylar doesn’t interrupt the dialog with a list of topics. Rather 171 to the way in which they made their earlier requests (Traum and Allen, 1994). For example, the weather system should produce the natural Yes it’s going to rain instead of a full weather report, for the third question above. We thus keep the user’s initial request intent in the global dialog context and share it with the relevant ESes. The recommendation policy has been improved in two ways: 1) All participating system developers agreed that Skylar should give ES recommendations on a rotating basis so that all systems are recommended equally. Skylar no longer makes a recommendation at the end of each system turn. Recommendations are made about every four turns and, as"
W17-5521,P17-4013,1,0.820805,"atabase of restaurant reviews obtained from Zomato and Yelp. We formed a list of general discussion points for restaurants (service, atmosphere, etc). For each discussion point, a list of relevant keywords was compiled using WordNet, thesaurus, and by categorizing the most frequently words found in reviews. Cambridge The Cambridge restaurant information system helps users find a restaurant in Cambridge, UK based on the area, the price range or the food type. The current database has just over 100 restaurants and is implemented using the multi-domain statistical dialogue system toolkit PyDial (Ultes et al., 2017). To connect PyDial to Dialport, PyDial’s dialogue server interface is used. It is implemented as an HTTP server expecting JSON messages from the Dialport client. The system runs a trained dialogue policy based on the GP-SARSA algorithm (Gaˇsi´c et al., 2010). Other Systems QuBot, a chatbot from Pohang University and CMU, is used for out-of-domain handling. Let’sForecast, from CMU, uses the NOAA website. Let’s Eat from CMU is based on Yelp, finding restaurants for cities that Cambridge does not cover and for Cambridge if that system is down. Let’s Go, derived from the Let’s Go system (Raux et"
W17-5521,W10-4334,1,\N,Missing
W18-5032,T78-1013,0,0.649284,"depicted in Figure 6. Each level produces its own belief and based on that, the system is able to act on each level. On the world level, the system might produce general dialogue behaviour like greetings or engage in a dialogue to adequately identify the entity which is addressed by the user input. On the entity level, the system talks to the user to acquire information about the concrete entity the user is talking about, e.g., to find a matching entity in the knowledge base. In addition to belief tracking, we would like to introduce another concept called focus of attention. Based on work by Grosz (1978), we define the current focus of attention F for each conversational world as a subset of conversational entities in this world F ⊆ W . Hence, the task of focus tracking is to find the new set of conversational entities which is in the current focus of attention based on the user input and the updated belief state. Even though the concept of focus is not mandatory, it may be helpful when framing the reinforcement learning problem as it allows to limit the size of the input to the reinforcement learning algorithm as well as the number of actions available to the learning algorithm at a given ti"
W18-5032,W17-5512,1,0.834933,"Missing"
W18-5032,W14-4337,0,0.0129861,"he influence of the user addressing the relation instead of the correct value (e.g., ”restaurant in the same area as the hotel” vs. ”restaurant in the centre”), we have extended the simulated agenda-based user (Schatzmann and Young, 2009) with a probability r of the user addressing the relation instead of the value. The higher r, the more often the user addresses the relation. The user simulator is equipped with an additional error model to simulate the semantic error rate (SER) caused in a real system by the noisy speech channel. For belief tracking, an extended version of the focus tracker (Henderson et al., 2014)—an effective rule-based tracker—was used for the conversational entities and the conversational world that also discounts probabilities if the respective value has been rejected by the user. As a simulated interaction is on the semantic level, no semantic dewhere s is the slot, v is the value, and bi the belief of the i-th conversational entity involved in the merging process. wi = 1 − bis (∅) is the weight of the i-th conversational entity where bis (∅) represents the probability where no information about slot s has yet been shared with the system. bi either refers to the belief bo of the c"
W18-5032,W16-3602,0,0.0677983,"elation 1 (Object 1 with Object 2) area: same Object 2 (Restaurant) name: Golden House area: centre Restaurant name area food … Figure 1: A dialogue between the system (S) and a user (U) about a restaurant and a hotel in the same area along with the mapping of fractions of the dialogue to the respective objects (of predefined types) and the relation. All objects and relations reside inside a conversational world. a comprehensive and consistent way of modelling these probabilities by defining and maintaining entity-based states. Work on statistical dialogue state modelling (Young et al., 2010; Lee and Stent, 2016; Schulz et al., 2017) also contain a variant of objects but is still based on the MDDM thus not offering any mechanism to model multiple entities or relations between objects. Ramachandran and Ratnaparkhi (2015) proposed a belief tracking approach using relational trees. However, they only consider static relations present in the ontology and are not able to handle dynamic relations. mapped to an object or a relation in the conversational world or may be mapped to the world itself (grey). In the example, the first part (blue) is about Object 1 of type hotel. When the focus shifts towards Obje"
W18-5032,N18-2112,1,0.861372,"Missing"
W18-5032,D16-1127,0,0.0585474,"tical SDS are model-based approaches1 and usually assume a modular architecture (see Fig. 2). The problem of learning the next system action is framed as a partially-observable Markov decision process (POMDP) that accounts for the uncertainty inherent in spoken communication. This uncertainty is modelled in the belief state b(s) representing a probability over all states s. Reinforcement learning (RL) is used in such a sequential decision-making process where the decision-model (the policy π) is trained based on 1 Model-free approaches like end-to-end generative networks (Serban et al., 2016; Li et al., 2016) have interesting properties (e.g., they only need text data for training) but they still seem to be limited in terms of dialogue structure complexity (not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a s"
W18-5032,W11-2033,0,0.0319607,"g of relations, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work an"
W18-5032,W17-5506,0,0.0888807,"earning (RL) is used in such a sequential decision-making process where the decision-model (the policy π) is trained based on 1 Model-free approaches like end-to-end generative networks (Serban et al., 2016; Li et al., 2016) have interesting properties (e.g., they only need text data for training) but they still seem to be limited in terms of dialogue structure complexity (not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a section of the dialogue state that belongs to a given topic, e.g., finding a restaurant or hotel. However, the resulting flat state that is widely used (Williams et al., 2005; Young et al., 2010; Thomson and Young, 2010; Lee and Stent, 2016; Schulz et al., 2017, e.g.) is not intuitive to model complex dialogue structures like relations. To overcome this limitation, we propose the conversational en"
W18-5032,D17-1237,0,0.0164082,"with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work and to illustrate the necessity of adequate modelling of relations, Figure 1 shows an example dialogue about hotels and re"
W18-5032,P17-1062,0,0.0294715,"tributes that represent the same concepts like area. Note that these relations are dynamic relations that may be drawn between objects in a conversation. This is different to static relations which are often used in knowledge bases to describe how concepts relate to each other. (2) For most real-world problems, finding the exact optimal Q-values is not feasible. Instead, RL algorithms have been proposed for dialogue policy learning based on approximating the Q-function directly or employing the policy gradient theorem (Williams and Young, 2006; Daubigney et al., 2012; Gaˇsi´c and Young, 2014; Williams et al., 2017; Su et al., 2017; Casanueva et al., 2017; Papangelis and Stylianou, 2017). Aside from the policy model, the dialogue model plays an important role: it defines the structure and internal links of the dialogue state as well as the system and user acts (i.e., the semantics the system can understand). Thus, the policy model is only able to learn system behaviour based on what is defined by the dialogue model. By defining the dialogue state, the dialogue model further represents an abstraction over the task ontology or knowledge base restricting the view on the information that is relevant so that"
W18-5032,2005.sigdial-1.4,1,0.759296,"not linguistic complexity) in cases where content from a structured knowledge base needs to be incorporated. Approaches where incorporating this information is learned along with the system responses based on dialogue data (Eric and Manning, 2017) seem hard to scale. 274 Speech Recognition Semantic Decoding Belief State Tracking Natural Language Generation Dialogue Policy waveform around domains which encapsulate all relevant information as a section of the dialogue state that belongs to a given topic, e.g., finding a restaurant or hotel. However, the resulting flat state that is widely used (Williams et al., 2005; Young et al., 2010; Thomson and Young, 2010; Lee and Stent, 2016; Schulz et al., 2017, e.g.) is not intuitive to model complex dialogue structures like relations. To overcome this limitation, we propose the conversational entity dialogue model which will be described in detail in the following section. Ontology Speech Synthesis Dialogue Manager Figure 2: The modular statistical dialogue system architecture. The dialogue manager takes the semantic interpretation as input to track the belief state. The updated state is then used by the dialogue policy to decide on the next system action. 4 sam"
W18-5032,W15-4609,0,0.0231936,"estaurant and a hotel in the same area along with the mapping of fractions of the dialogue to the respective objects (of predefined types) and the relation. All objects and relations reside inside a conversational world. a comprehensive and consistent way of modelling these probabilities by defining and maintaining entity-based states. Work on statistical dialogue state modelling (Young et al., 2010; Lee and Stent, 2016; Schulz et al., 2017) also contain a variant of objects but is still based on the MDDM thus not offering any mechanism to model multiple entities or relations between objects. Ramachandran and Ratnaparkhi (2015) proposed a belief tracking approach using relational trees. However, they only consider static relations present in the ontology and are not able to handle dynamic relations. mapped to an object or a relation in the conversational world or may be mapped to the world itself (grey). In the example, the first part (blue) is about Object 1 of type hotel. When the focus shifts towards Object 2 of type restaurant (green) at U3, the user also addresses the relation (red) in the same area between Object 1 and Object 2. Addressing a relation in this way could still be captured by the semantic interpre"
W18-5032,W10-4317,0,0.00972338,"1), no context information would be available. To capture these dialogue structures, the dialogue model and the corresponding dialogue state must be able to represent them adequately. The proposed CEDM achieves this by modelling state information about conversational entities instead of domains. More precisely, it models separate states about the objects (e.g., the hotel or restaurant) and the relations. Previous work on dialogue modelling already incorporated the idea of objects or entities to be the principal component of the dialogue state (Grosz, 1977; Bilange, 1991; Montoro et al., 2004; Xu and Seneff, 2010; Heinroth and Minker, 2013). However, these dialogue models are not based on statistical dialogue processing where a probability distribution over all dialogue states needs to be modelled and maintained. This additional complexity, though, cannot be incorporated in a straight-forward way into the proposed models. In contrast, the CEDM offers 3 Statistical Spoken Dialogue Systems Statistical SDS are model-based approaches1 and usually assume a modular architecture (see Fig. 2). The problem of learning the next system action is framed as a partially-observable Markov decision process (POMDP) th"
W18-5032,W17-2626,0,0.0313453,"Missing"
W18-5032,W17-5518,1,0.884593,"g at one aspect of the CEDM, the modelling of relations, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminol"
W18-5032,P17-4013,1,0.884457,"Missing"
W18-5032,D14-1007,0,0.0314208,"s, Section 5 describes a prototype implementation and shows the benefits of the CEDM in experiments with a simulated user. Section 6 concludes the paper with a list of open questions which need to be addressed in future work. Introduction Data-driven statistical spoken dialogue systems (SDS) (Lemon and Pietquin, 2012; Young et al., 2013) are a promising approach for realizing spoken dialogue interaction between humans and machines. Up until now, these systems have successfully been applied to single- or multi-domain taskoriented dialogues (Su et al., 2017; Casanueva et al., 2017; Lison, 2011; Wang et al., 2014; Papangelis and Stylianou, 2017; Gaˇsi´c et al., 2017; Budzianowski et al., 2017; Peng et al., 2017) where each dialogue is modelled as multiple independent single-domain sub-dialogues. However, this multi-domain dialogue model (MDDM) does not offer an intuitive way of representing multiple objects of the same type (e.g., multiple restaurants) or dynamic relations between these objects. To the best of our knowledge, neither problem has yet been addressed in statistical SDS research. 2 Motivation and Related Work To introduce the terminology that will be used in this work and to illustrate the"
