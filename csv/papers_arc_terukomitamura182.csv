2021.findings-acl.84,A Survey of Data Augmentation Approaches for {NLP},2021,-1,-1,6,1,5957,steven feng,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.conll-1.39,Cross-document Event Identity via Dense Annotation,2021,-1,-1,7,0,153,adithya pratapa,Proceedings of the 25th Conference on Computational Natural Language Learning,0,"In this paper, we study the identity of textual events from different documents. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear. Prior work on cross-document event coreference has two main drawbacks. First, they restrict the annotations to a limited set of event types. Second, they insufficiently tackle the concept of event identity. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations. We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface. In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between identity decisions and context. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks."
2020.lrec-1.253,Extraction of the Argument Structure of {T}okyo Metropolitan Assembly Minutes: Segmentation of Question-and-Answer Sets,2020,-1,-1,8,0,17149,keiichi takamaru,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this study, we construct a corpus of Japanese local assembly minutes. All speeches in an assembly were transcribed into a local assembly minutes based on the local autonomy law. Therefore, the local assembly minutes form an extremely large amount of text data. Our ultimate objectives were to summarize and present the arguments in the assemblies, and to use the minutes as primary information for arguments in local politics. To achieve this, we structured all statements in assembly minutes. We focused on the structure of the discussion, i.e., the extraction of question and answer pairs. We organized the shared task {``}QA Lab-PoliInfo{''} in NTCIR 14. We conducted a {``}segmentation task{''} to identify the scope of one question and answer in the minutes as a sub task of the shared task. For the segmentation task, 24 runs from five teams were submitted. Based on the obtained results, the best recall was 1.000, best precision was 0.940, and best F-measure was 0.895."
2020.emnlp-demos.26,A Data-Centric Framework for Composable {NLP} Workflows,2020,-1,-1,15,1,9851,zhengzhong liu,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,"Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, analysis, generation, and visualization. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The framework introduces a uniform data representation to encode heterogeneous results by a wide range of NLP tasks. It offers a large repository of processors for NLP tasks, visualization, and annotation, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation)."
2020.deelio-1.4,{G}en{A}ug: Data Augmentation for Finetuning Text Generators,2020,-1,-1,4,1,5957,steven feng,Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures,0,"In this paper, we investigate data augmentation for text generation, which we call GenAug. Text generation and language modeling are important tasks within natural language processing, and are especially challenging for low-data regimes. We propose and evaluate various augmentation methods, including some that incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp Reviews. We also examine the relationship between the amount of augmentation and the quality of the generated text. We utilize several metrics that evaluate important aspects of the generated text including its diversity and fluency. Our experiments demonstrate that insertion of character-level synthetic noise and keyword replacement with hypernyms are effective augmentation methods, and that the quality of generations improves to a peak at approximately three times the amount of original data."
W19-5041,Pentagon at {MEDIQA} 2019: Multi-task Learning for Filtering and Re-ranking Answers using Language Inference and Question Entailment,2019,0,0,7,0,23974,hemant pugaliya,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have quickly become the state of the art, bypassing previous deep and shallow learning methods by a large margin. More recently, pre-trained models from large related datasets have been able to perform well on many downstream tasks by just fine-tuning on domain-specific datasets (similar to transfer learning). However, using powerful models on non-trivial tasks, such as ranking and large document classification, still remains a challenge due to input size limitations of parallel architecture and extremely small datasets (insufficient for fine-tuning). In this work, we introduce an end-to-end system, trained in a multi-task setting, to filter and re-rank answers in the medical domain. We use task-specific pre-trained models as deep feature extractors. Our model achieves the highest Spearman{'}s Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on the ACL-BioNLP workshop MediQA Question Answering shared-task."
W19-5048,{D}r.{Q}uad at {MEDIQA} 2019: Towards Textual Inference and Question Entailment using contextualized representations,2019,12,1,5,0,10462,vinayshekhar kumar,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"This paper presents the submissions by TeamDr.Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our system is based on the prior work Liu et al. (2019) which uses a multi-task objective function for textual entailment. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating domain knowledge through data augmentation is a powerful strategy for addressing challenges posed specialized domains such as medicine."
W19-5049,Sieg at {MEDIQA} 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment,2019,0,1,5,0,23987,sai bhaskar,Proceedings of the 18th BioNLP Workshop and Shared Task,0,This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our model to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.
W18-6704,Textual Entailment based Question Generation,2018,0,0,4,0,27635,takaaki matsumoto,Proceedings of the Workshop on Intelligent Interactive Systems and Language Generation (2{IS}{\\&}{NLG}),0,None
W18-5310,Ontology-Based Retrieval {\\&} Neural Approaches for {B}io{ASQ} Ideal Answer Generation,2018,0,3,6,0,28002,ashwin kumar,Proceedings of the 6th {B}io{ASQ} Workshop A challenge on large-scale biomedical semantic indexing and question answering,0,"The ever-increasing magnitude of biomedical information sources makes it difficult and time-consuming for a human researcher to find the most relevant documents and pinpointed answers for a specific question or topic when using only a traditional search engine. Biomedical Question Answering systems automatically identify the most relevant documents and pinpointed answers, given an information need expressed as a natural language question. Generating a non-redundant, human-readable summary that satisfies the information need of a given biomedical question is the focus of the Ideal Answer Generation task, part of the BioASQ challenge. This paper presents a system for ideal answer generation (using ontology-based retrieval and a neural learning-to-rank approach, combined with extractive and abstractive summarization techniques) which achieved the highest ROUGE score of 0.659 on the BioASQ 5b batch 2 test."
W18-4702,Interoperable Annotation of Events and Event Relations across Domains,2018,-1,-1,6,1,12601,jun araki,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,None
W18-2312,{B}io{AMA}: Towards an End to End {B}io{M}edical Question Answering System,2018,0,4,6,0,27688,vasu sharma,Proceedings of the {B}io{NLP} 2018 workshop,0,"In this paper, we present a novel Biomedical Question Answering system, BioAMA: {``}Biomedical Ask Me Anything{''} on task 5b of the annual BioASQ challenge. In this work, we focus on a wide variety of question types including factoid, list based, summary and yes/no type questions that generate both exact and well-formed {`}ideal{'} answers. For summary-type questions, we combine effective IR-based techniques for retrieval and diversification of relevant snippets for a question to create an end-to-end system which achieves a ROUGE-2 score of 0.72 and a ROUGE-SU4 score of 0.71 on ideal answer questions (7{\%} improvement over the previous best model). Additionally, we propose a novel NLI-based framework to answer the yes/no questions. To train the NLI model, we also devise a transfer-learning technique by cross-domain projection of word embeddings. Finally, we present a two-stage approach to address the factoid and list type questions by first generating a candidate set using NER taggers and ranking them using both supervised or unsupervised techniques."
L18-1611,Parser combinators for {T}igrinya and {O}romo morphology,2018,0,0,7,0,12351,patrick littell,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D18-1154,Automatic Event Salience Identification,2018,0,2,3,1,9851,zhengzhong liu,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Identifying the salience (i.e. importance) of discourse units is an important task in language understanding. While events play important roles in text documents, little research exists on analyzing their saliency status. This paper empirically studies Event Salience and proposes two salience detection models based on discourse relations. The first is a feature based salience model that incorporates cohesion among discourse units. The second is a neural model that captures more complex interactions between discourse units. In our new large-scale event salience corpus, both methods significantly outperform the strong frequency baseline, while our neural model further improves the feature based one by a large margin. Our analyses demonstrate that our neural model captures interesting connections between salience and discourse unit relations (e.g., scripts and frame structures)."
C18-1007,Low-resource Cross-lingual Event Type Detection via Distant Supervision with Minimal Effort,2018,0,2,6,0,24852,aldrian muis,Proceedings of the 27th International Conference on Computational Linguistics,0,"The use of machine learning for NLP generally requires resources for training. Tasks performed in a low-resource language usually rely on labeled data in another, typically resource-rich, language. However, there might not be enough labeled data even in a resource-rich language such as English. In such cases, one approach is to use a hand-crafted approach that utilizes only a small bilingual dictionary with minimal manual verification to create distantly supervised data. Another is to explore typical machine learning techniques, for example adversarial training of bilingual word representations. We find that in event-type detection task{---}the task to classify [parts of] documents into a fixed set of labels{---}they give about the same performance. We explore ways in which the two methods can be complementary and also see how to best utilize a limited budget for manual annotation to maximize performance gain."
C18-1075,Open-Domain Event Detection using Distant Supervision,2018,0,4,2,1,12601,jun araki,Proceedings of the 27th International Conference on Computational Linguistics,0,"This paper introduces open-domain event detection, a new event detection paradigm to address issues of prior work on restricted domains and event annotation. The goal is to detect all kinds of events regardless of domains. Given the absence of training data, we propose a distant supervision method that is able to generate high-quality training data. Using a manually annotated event corpus as gold standard, our experiments show that despite no direct supervision, the model outperforms supervised models. This result indicates that the distant supervision enables robust event detection in various domains, while obviating the need for human annotation of events."
C18-1309,Graph Based Decoding for Event Sequencing and Coreference Resolution,2018,40,2,2,1,9851,zhengzhong liu,Proceedings of the 27th International Conference on Computational Linguistics,0,"Events in text documents are interrelated in complex ways. In this paper, we study two types of relation: Event Coreference and Event Sequencing. We show that the popular tree-like decoding structure for automated Event Coreference is not suitable for Event Sequencing. To this end, we propose a graph-based decoding algorithm that is applicable to both tasks. The new decoding algorithm supports flexible feature sets for both tasks. Empirically, our event coreference system has achieved state-of-the-art performance on the TAC-KBP 2015 event coreference task and our event sequencing system beats a strong temporal-based, oracle-informed baseline. We discuss the challenges of studying these event relations."
W17-2703,Event Detection Using Frame-Semantic Parser,2017,6,3,3,0,189,evangelia spiliopoulou,Proceedings of the Events and Stories in the News Workshop,0,"Recent methods for Event Detection focus on Deep Learning for automatic feature generation and feature ranking. However, most of those approaches fail to exploit rich semantic information, which results in relatively poor recall. This paper is a small {\&} focused contribution, where we introduce an Event Detection and classification system, based on deep semantic information retrieved from a frame-semantic parser. Our experiments show that our system achieves higher recall than state-of-the-art systems. Further, we claim that enhancing our system with deep learning techniques like feature ranking can achieve even better results, as it can benefit from both approaches."
W16-6005,Unsupervised Event Coreference for Abstract Words,2016,0,2,3,0,8551,dheeraj rajagopal,Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods,0,None
W16-1004,A Comparison of Event Representations in {DEFT},2016,0,3,8,0,17656,ann bies,Proceedings of the Fourth Workshop on Events,0,None
W16-1005,Event Nugget and Event Coreference Annotation,2016,9,4,5,0,23564,zhiyi song,Proceedings of the Fourth Workshop on Events,0,"In this paper, we describe the event nugget annotation created in support of the pilot Event Nugget Detection evaluation in 2014 and in support of the Event Nugget Detection and Coreference open evaluation in 2015, which was one of the Knowledge Base Population tracks within the NIST Text Analysis Conference. We present the data volume annotated for both training and evaluation data for the 2015 evaluation as well as changes to annotation in 2015 as compared to that of 2014. We also analyze the annotation for the 2015 evaluation as an example to show the annotation challenges and consistency, and identify the event types and subtypes that are most difficult for human annotators. Finally, we discuss annotation issues that we need to take into consideration in the future."
C16-1107,Generating Questions and Multiple-Choice Answers using Semantic Analysis of Texts,2016,25,16,6,1,12601,jun araki,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We present a novel approach to automated question generation that improves upon prior work both from a technology perspective and from an assessment perspective. Our system is aimed at engaging language learners by generating multiple-choice questions which utilize specific inference steps over multiple sentences, namely coreference resolution and paraphrase detection. The system also generates correct answers and semantically-motivated phrase-level distractors as answer choices. Evaluation by human annotators indicates that our approach requires a larger number of inference steps, which necessitate deeper semantic understanding of texts than a traditional single-sentence approach."
W15-0807,Evaluation Algorithms for Event Nugget Detection : A Pilot Study,2015,-1,-1,2,1,9851,zhengzhong liu,"Proceedings of the The 3rd Workshop on {EVENTS}: Definition, Detection, Coreference, and Representation",0,None
W15-0809,Event Nugget Annotation: Processes and Issues,2015,5,17,1,1,7705,teruko mitamura,"Proceedings of the The 3rd Workshop on {EVENTS}: Definition, Detection, Coreference, and Representation",0,"This paper describes the processes and issues of annotating event nuggets based on DEFT ERE Annotation Guidelines v1.3 and TAC KBP Event Detection Annotation Guidelines 1.7. Using Brat Rapid Annotation Tool (brat), newswire and discussion forum documents were annotated. One of the challenges arising from human annotation of documents is annotatorsxe2x80x99 disagreement about the way of tagging events. We propose using Event Nuggets to help meet the definitions of the specific type/subtypes which are part of this project. We present case studies of several examples of event annotation issues, including discontinuous multi-word events representing single events. Annotation statistics and consistency analysis is provided to characterize the interannotator agreement, considering single term events and multi-word events which are both continuous and discontinuous. Consistency analysis is conducted using a scorer to compare first pass annotated files against adjudicated files."
D15-1247,Joint Event Trigger Identification and Event Coreference Resolution with Structured Perceptron,2015,40,5,2,1,12601,jun araki,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Events and their coreference offer useful semantic and discourse resources. We show that the semantic and discourse aspects of events interact with each other. However, traditional approaches addressed event extraction and event coreference resolution either separately or sequentially, which limits their interactions. This paper proposes a document-level structured learning model that simultaneously identifies event triggers and resolves event coreference. We demonstrate that the joint model outperforms a pipelined model by 6.9 BLANC F1 and 1.8 CoNLL F1 points in event coreference resolution using a corpus in the biology domain."
W14-2910,Evaluation for Partial Event Coreference,2014,-1,-1,3,1,12601,jun araki,"Proceedings of the Second Workshop on {EVENTS}: Definition, Detection, Coreference, and Representation",0,None
levin-etal-2014-resources,Resources for the Detection of Conventionalized Metaphors in Four Languages,2014,11,6,2,0,17380,lori levin,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes a suite of tools for extracting conventionalized metaphors in English, Spanish, Farsi, and Russian. The method depends on three significant resources for each language: a corpus of conventionalized metaphors, a table of conventionalized conceptual metaphors (CCM table), and a set of extraction rules. Conventionalized metaphors are things like {``}escape from poverty{''} and {``}burden of taxation{''}. For each metaphor, the CCM table contains the metaphorical source domain word (such as {``}escape{''}) the target domain word (such as {``}poverty{''}) and the grammatical construction in which they can be found. The extraction rules operate on the output of a dependency parser and identify the grammatical configurations (such as a verb with a prepositional phrase complement) that are likely to contain conventional metaphors. We present results on detection rates for conventional metaphors and analysis of the similarity and differences of source domains for conventional metaphors in the four languages."
liu-etal-2014-supervised,Supervised Within-Document Event Coreference using Information Propagation,2014,32,22,4,1,9851,zhengzhong liu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Event coreference is an important task for full text analysis. However, previous work uses a variety of approaches, sources and evaluation, making the literature confusing and the results incommensurate. We provide a description of the differences to facilitate future research. Second, we present a supervised method for event coreference resolution that uses a rich feature set and propagates information alternatively between events and their arguments, adapting appropriately for each type of argument."
araki-etal-2014-detecting,Detecting Subevent Structure for Event Coreference Resolution,2014,29,16,4,1,12601,jun araki,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In the task of event coreference resolution, recent work has shown the need to perform not only full coreference but also partial coreference of events. We show that subevents can form a particular hierarchical event structure. This paper examines a novel two-stage approach to finding and improving subevent structures. First, we introduce a multiclass logistic regression model that can detect subevent relations in addition to full coreference. Second, we propose a method to improve subevent structure based on subevent clusters detected by the model. Using a corpus in the Intelligence Community domain, we show that the method achieves over 3.2 BLANC F1 gain in detecting subevent relations against the logistic regression model."
W13-1203,"Events are Not Simple: Identity, Non-Identity, and Quasi-Identity",2013,25,25,2,0,1043,eduard hovy,"Workshop on Events: Definition, Detection, Coreference, and Representation",0,"Despite considerable theoretical and computational work on coreference, deciding when two entities or events are identical is very difficult. In a project to build corpora containing coreference links between events, we have identified three levels of event identity (full, partial, and none). Event coreference annotation on two corpora was performed to validate the findings."
R13-1006,An {NLP}-based Reading Tool for Aiding Non-native {E}nglish Readers,2013,22,6,6,0,17745,mahmoud azab,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"This paper describes a text-reading tool that makes extensive use of widelyavailable NLP tools and resources to aid non-native English speakers overcome language related hindrances while reading a text. It is a web-based tool, that can be accessed from browsers running on PCs or tablets, and provides the reader with an intelligent e-book functionality."
I13-2002,An {E}nglish Reading Tool as a {NLP} Showcase,2013,11,3,6,0,17745,mahmoud azab,The Companion Volume of the Proceedings of {IJCNLP} 2013: System Demonstrations,0,"We introduce -SmartReaderan English reading tool for non-native English readers to overcome language related hindrances while reading a text. It makes extensive use of widely-available NLP tools and resources. SmartReader is a web-based application that can be accessed from standard browsers running on PCs or tablets. A user can choose a text document from the systemxe2x80x99s library they want to read or can upload a new document of their own and the system will display an interactive version of such text, that provides the reader with an intelligent e-book functionality."
shima-mitamura-2012-diversifiable,Diversifiable Bootstrapping for Acquiring High-Coverage Paraphrase Resource,2012,38,1,2,1,41296,hideki shima,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Recognizing similar or close meaning on different surface form is a common challenge in various Natural Language Processing and Information Access applications. However, we identified multiple limitations in existing resources that can be used for solving the vocabulary mismatch problem. To this end, we will propose the Diversifiable Bootstrapping algorithm that can learn paraphrase patterns with a high lexical coverage. The algorithm works in a lightly-supervised iterative fashion, where instance and pattern acquisition are interleaved, each using information provided by the other. By tweaking a parameter in the algorithm, resulting patterns can be diversifiable with a specific degree one can control."
W11-2405,Diversity-aware Evaluation for Paraphrase Patterns,2011,29,2,2,1,41296,hideki shima,Proceedings of the {T}ext{I}nfer 2011 Workshop on Textual Entailment,0,"Common evaluation metrics for paraphrase patterns do not necessarily correlate with extrinsic recognition task performance. We propose a metric which gives weight to lexical variety in paraphrase patterns; our proposed metric has a positive correlation with paraphrase recognition task performance, with a Pearson correlation of 0.5~0.7 (k=10, with strict judgment) in a statistically significant level (p-value<0.01)."
P10-2021,Automatic Collocation Suggestion in Academic Writing,2010,6,18,3,0,34550,jiancheng wu,Proceedings of the {ACL} 2010 Conference Short Papers,0,"In recent years, collocation has been widely acknowledged as an essential characteristic to distinguish native speakers from non-native speakers. Research on academic writing has also shown that collocations are not only common but serve a particularly important discourse function within the academic community. In our study, we propose a machine learning approach to implementing an online collocation writing assistant. We use a data-driven classifier to provide collocation suggestions to improve word choices, based on the result of classification. The system generates and ranks suggestions to assist learners' collocation usages in their academic writing with satisfactory results."
W09-3012,Committed Belief Annotation and Tagging,2009,12,45,3,0,7377,mona diab,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"We present a preliminary pilot study of belief annotation and automatic tagging. Our objective is to explore semantic meaning beyond surface propositions. We aim to model people's cognitive states, namely their beliefs as expressed through linguistic means. We model the strength of their beliefs and their (the human) degree of commitment to their utterance. We explore only the perspective of the author of a text. We classify predicates into one of three possibilities: committed belief, non committed belief, or not applicable. We proceed to manually annotate data to that end, then we build a supervised framework to test the feasibility of automatically predicting these belief states. Even though the data is relatively small, we show that automatic prediction of a belief class is a feasible task. Using syntactic features, we are able to obtain significant improvements over a simple baseline of 23% F-measure absolute points. The best performing automatic tagging condition is where we use POS tag, word type feature AlphaNumeric, and shallow syntactic chunk information CHUNK. Our best overall performance is 53.97% F-measure."
P07-1099,Language-independent Probabilistic Answer Ranking for Question Answering,2007,16,19,2,0.925926,22869,jeongwoo ko,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,This paper presents a language-independent probabilistic answer ranking framework for question answering. The framework estimates the probability of an individual answer candidate given the degree of answer relevance and the amount of supporting evidence provided in the set of answer candidates for the question. Our approach was evaluated by comparing the candidate answer sets generated by Chinese and Japanese answer extractors with the re-ranked answer sets produced by the answer ranking framework. Empirical results from testing on NTCIR factoid questions show a 40% performance improvement in Chinese answer selection and a 45% improvement in Japanese answer selection.
D07-1003,What is the {J}eopardy Model? A Quasi-Synchronous Grammar for {QA},2007,36,259,3,1,39074,mengqiu wang,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"This paper presents a syntax-driven approach to question answering, specifically the answer-sentence selection problem for short-answer questions. Rather than using syntactic features to augment existing statistical classifiers (as in previous work), we build on the idea that questions and their (correct) answers relate to each other via loose but predictable syntactic transformations. We propose a probabilistic quasi-synchronous grammar, inspired by one proposed for machine translation (D. Smith and Eisner, 2006), and parameterized by mixtures of a robust nonlexical syntax/alignment model with a(n optional) lexical-semantics-driven log-linear model. Our model learns soft alignments as a hidden variable in discriminative training. Experimentalresultsusing theTRECdataset are shown to significantly outperform strong state-of-the-art baselines."
W06-1905,Keyword Translation Accuracy and Cross-Lingual Question Answering in{C}hinese and {J}apanese,2006,9,10,1,1,7705,teruko mitamura,Proceedings of the Workshop on Multilingual Question Answering - {MLQA} {`}06,0,"In this paper, we describe the extension of an existing monolingual QA system for English-to-Chinese and English-to-Japanese cross-lingual question answering (CLQA). We also attempt to characterize the influence of translation on CLQA performance through experimental evaluation and analysis. The paper also describes some language-specific issues for keyword translation in CLQA."
P06-1054,"A Fast, Accurate Deterministic Parser for {C}hinese",2006,26,48,3,1,39074,mengqiu wang,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present a novel classifier-based deterministic parser for Chinese constituency parsing. Our parser computes parse trees from bottom up in one pass, and uses classifiers to make shift-reduce decisions. Trained and evaluated on the standard training and test sets, our best model (using stacked classifiers) runs in linear time and has labeled precision and recall above 88% using gold-standard part-of-speech tags, surpassing the best published results. Our SVM parser is 2-13 times faster than state-of-the-art parsers, while producing more accurate results. Our Maxent and DTree parsers run at speeds 40-270 times faster than state-of-the-art parsers, but with 5-6% losses in accuracy."
rambow-etal-2006-parallel,Parallel Syntactic Annotation of Multiple Languages,2006,12,10,10,0,1354,owen rambow,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes an effort to investigate the incrementally deepening development of an interlingua notation, validated by human annotation of texts in English plus six languages. We begin with deep syntactic annotation, and in this paper present a series of annotation manuals for six different languages at the deep-syntactic level of representation. Many syntactic differences between languages are removed in the proposed syntactic annotation, making them useful resources for multilingual NLP projects with semantic components."
shima-etal-2006-modular,Modular Approach to Error Analysis and Evaluation for Multilingual Question Answering,2006,-1,-1,4,1,41296,hideki shima,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Multilingual Question Answering systems are generally very complex, integrating several sub-modules to achieve their result. Global metrics (such as average precision and recall) are insufficient when evaluating the performance of individual sub-modules and their influence on each other. In this paper, we present a modular approach to error analysis and evaluation; we use manually-constructed, gold-standard input for each module to obtain an upper-bound for the (local) performance of that module. This approach enables us to identify existing problem areas quickly, and to target improvements accordingly."
ko-etal-2006-analyzing,Analyzing the Effects of Spoken Dialog Systems on Driving Behavior,2006,6,0,3,1,22869,jeongwoo ko,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents an evaluation of a spoken dialog system for automotive environments. Our overall goal was to measure the impact of user-system interaction on the userÂs driving performance, and to determine whether adding context-awareness to the dialog system might reduce the degree of user distraction during driving. To address this issue, we incorporated context-awareness into a spoken dialog system, and implemented three system features using user context, network context and dialog context. A series of experiments were conducted under three different configurations: driving without a dialog system, driving while using a context-aware dialog system, and driving while using a context-unaware dialog system. We measured the differences between the three configurations by comparing the average car speed, the frequency of speed changes and the angle between the carÂs direction and the centerline on the road. These results indicate that context-awareness could reduce the degree of user distraction when using a dialog system during driving."
W04-2709,Interlingual Annotation of Multilingual Text Corpora,2004,14,20,6,0,50484,stephen helmreich,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,"This paper describes a multi-site project to annotate six sizable bilingual parallel corpora for interlingual content. After presenting the background and objectives of the effort, we will go on to describe the data set that is being annotated, the interlingua representation language used, an interface environment that supports the annotation task and the annotation process itself. We will then present a preliminary version of our evaluation methodology and conclude with a summary of the current status of the project along with a number of issues which have arisen."
N04-4016,Correction Grammars for Error Handling in a Speech Dialog System,2004,6,13,2,0,49162,hirohiko sagawa,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"Speech recognition errors are inevitable in a speech dialog system. This paper presents an error handling method based on correction grammars which recognize the correction utterances which follow a recognition error. Correction grammars are dynamically created from existing grammars and a set of correction templates. We also describe a prototype dialog system which incorporates this error handling method, and provide empirical evidence that this method can improve dialog success rate and reduce the number of dialog turns required for error recovery."
kupsc-etal-2004-pronominal,Pronominal Anaphora Resolution for Unrestricted Text,2004,10,5,2,0,40003,anna kupsc,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The paper presents an anaphora resolution algorithm for unrestricted text. In particular, we examine portability of a knowledge-based approach of (Mitamura et al., 2002), proposed for a domain-specific task. We obtain up to 70% accuracy on unrestricted text, which is a significant improvement (almost 20%) over a baseline we set for general text. As the overall results leave much room for improvement, we provide a detailed error analysis and investigate possible enhancements."
pedro-etal-2004-information,An Information Repository Model for Advanced Question Answering Systems,2004,4,4,4,0,52307,vasco pedro,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents the design and implementation of the information repository which is the central core of the JAVELIN opendomain question answering system. JAVELIN is comprised of several modules that perform a wide variety of question answering (QA) tasks, such as question analysis, document and passage retrieval, answer candidate extraction, answer selection, answer justification, and planning. The architecture is designed to support comparative component-level evaluation, so that different strategies for each module can be integrated and tested in a straightforward way. Each time a module uses a particular piece of information to produce an output, a dependency is created. To support answer justification and introspective learning, the system can use this longterm memory to trace the origin of each answer it produces for a particular question. The JAVELIN Repository implements a complete, consistent relational model for all of the information associated with a question answering scenario."
lin-mitamura-2004-keyword,Keyword translation from {E}nglish to {C}hinese for multilingual {QA},2004,14,3,2,0,49728,frank lin,Proceedings of the 6th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"The Keyword Translator is a part of the Question Analyzer module in the JAVELIN Question-Answering system; it translates the keywords, which are used to query documents and extract answers, from one language to another. Much work has been in the area of query translation for CLIR or MLIR, however, many have focused on methods using hard-to-obtain and domain-specific resources, and evaluation is often based on retrieval performance rather than translation correctness. In this paper we will describe methods combining easily accessible, general-purpose MT systems to improve keyword translation correctness. We also describe methods that utilize the question sentence available to a question-answering system to improve translation correctness. We will show that using multiple MT systems and the question sentence to translate keywords from English to Mandarin Chinese can significantly improve keyword translation correctness."
reeder-etal-2004-interlingual,Interlingual annotation for {MT} development,2004,16,7,8,0,46657,florence reeder,Proceedings of the 6th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"MT systems that use only superficial representations, including the current generation of statistical MT systems, have been successful and useful. However, they will experience a plateau in quality, much like other {``}silver bullet{''} approaches to MT. We pursue work on the development of interlingual representations for use in symbolic or hybrid MT systems. In this paper, we describe the creation of an interlingua and the development of a corpus of semantically annotated text, to be validated in six languages and evaluated in several ways. We have established a distributed, well-functioning research methodology, designed a preliminary interlingua notation, created annotation manuals and tools, developed a test collection in six languages with associated English translations, annotated some 150 translations, and designed and applied various annotation metrics. We describe the data sets being annotated and the interlingual (IL) representation language which uses two ontologies and a systematic theta-role list. We present the annotation tools built and outline the annotation process. Following this, we describe our evaluation methodology and conclude with a summary of issues that have arisen."
2003.mtsummit-tttt.4,Teaching machine translation in a graduate language technologies program,2003,-1,-1,1,1,7705,teruko mitamura,Workshop on Teaching Translation Technologies and Tools,0,"This paper describes a graduate-level machine translation (MT) course taught at the Language Technologies Institute at Carnegie Mellon University. Most of the students in the course have a background in computer science. We discuss what we teach (the course syllabus), and how we teach it (lectures, homeworks, and projects). The course has evolved steadily over the past several years to incorporate refinements in the set of course topics, how they are taught, and how students {``}learn by doing{''}. The course syllabus has also evolved in response to changes in the field of MT and the role that MT plays in various social contexts."
2003.mtsummit-systems.13,"An integrated system for source language checking, analysis and term management",2003,-1,-1,2,0.583888,9610,eric nyberg,Proceedings of Machine Translation Summit IX: System Presentations,0,"This paper presents an overview of the tools provided by KANTOO MT system for controlled source language checking, source text analysis, and terminology management. The steps in each process are described, and screen images are provided to illustrate the system architecture and example tool interfaces."
2003.mtsummit-papers.34,Source language diagnostics for {MT},2003,-1,-1,1,1,7705,teruko mitamura,Proceedings of Machine Translation Summit IX: Papers,0,"This paper presents a source language diagnostic system for controlled translation. Diagnostics were designed and implemented to address the most difficult rewrites for authors, based on an empirical analysis of log files containing over 180,000 sentences. The design and implementation of the diagnostic system are presented, along with experimental results from an empirical evaluation of the completed system. We found that the diagnostic system can correctly identify the problem in 90.2{\%} of the cases. In addition, depending on the type of grammar problem, the diagnostic system may offer a rewritten sentence. We found that 89.4{\%} of the rewritten sentences were correctly rewritten. The results suggest that these methods could be used as the basis for an automatic rewriting system in the future."
2003.eamt-1.10,Diagnostics for interactive controlled language checking,2003,-1,-1,1,1,7705,teruko mitamura,EAMT Workshop: Improving MT through other language technology tools: resources and tools for building MT,0,None
W02-0106,Design and Evolution of a Language Technologies Curriculum,2002,0,1,3,0,39652,robert frederking,Proceedings of the {ACL}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,0,The Language Technologies Institute (LTI) of the School of Computer Science at Carnegie Mellon University is one of the largest programs of its kind. We present here the initial design and subsequent evolution of our MS and PhD programs in Language Technologies. The motivations for the design and evolution are also presented.
2002.tmi-papers.13,Pronominal anaphora resolution in the {KANTOO} multilingual machine translation system,2002,-1,-1,1,1,7705,teruko mitamura,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
nyberg-etal-2002-deriving,Deriving semantic knowledge from descriptive texts using an {MT} system,2002,6,6,2,0.701176,9610,eric nyberg,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper describes the results of a feasibility study which focused on deriving semantic networks from descriptive texts using controlled language. The KANT system [3,6] was used to analyze input paragraphs, producing sentence-level interlingua representations. The interlinguas were merged to construct a paragraph-level representation, which was used to create a semantic network in Conceptual Graph (CG) [1] format. The interlinguas are also translated (using the KANTOO generator) into OWL statements for entry into the Ontology Works electrical power factbase [9]. The system was extended to allow simple querying in natural language."
2001.mtsummit-papers.43,Pronominal anaphora resolution in {KANTOO} {E}nglish-to-{S}panish machine translation system,2001,9,1,1,1,7705,teruko mitamura,Proceedings of Machine Translation Summit VIII,0,"We describe the automatic resolution of pronominal anaphora using KANT Controlled English (KCE) and the KANTOO English-to-Spanish MT system. Our algorithm is based on a robust, syntax-based approach that applies a set of restrictions and preferences to select the correct antecedent. We report a success rate of 89.6{\%} on a training corpus with 289 anaphors, and 87.5{\%} on held-out data containing 145 anaphors. Resolution of anaphors is important in translation, due to gender mismatches among languages; our approach translates anaphors to Spanish with 97.2{\%} accuracy."
A00-2012,{A}rabic Morphology Generation Using a Concatenative Strategy,2000,11,43,3,0,28253,violetta cavallisforza,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Arabic inflectional morphology requires infixation, prefixation and suffixation, giving rise to a large space of morphological variation. In this paper we describe an approach to reducing the complexity of Arabic morphology generation using discrimination trees and transformational rules. By decoupling the problem of stem changes from that of prefixes and suffixes, we gain a significant reduction in the number of rules required, as much as a factor of three for certain verb types. We focus on hollow verbs but discuss the wider applicability of the approach."
2000.amta-tutorials.3,Controlled languages,2000,-1,-1,1,1,7705,teruko mitamura,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Tutorial Descriptions,0,None
nyberg-mitamura-2000-kantoo,The {KANTOO} machine translation environment,2000,3,18,2,1,9610,eric nyberg,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: System Descriptions,0,"In this paper we describe the KANTOO machine translation environment, a set of software services and tools for multilingual document production. KANTOO includes modules for source language analysis, target language generation, source terminology management, target terminology management, and knowledge source development. The KANTOOsystem represents a complete re-design and re-implementation of the KANT machine translation system."
cavalli-sforza-etal-2000-challenges,Challenges in adapting an interlingua for bidirectional {E}nglish-{I}talian translation,2000,4,3,3,0,28253,violetta cavallisforza,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"We describe our experience in adapting an existing high- quality, interlingual, unidirectional machine translation system to a new domain and bidirectional translation for a new language pair (English and Italian). We focus on the interlingua design changes which were necessary to achieve high quality output in view of the language mismatches between English and Italian. The representation we propose contains features that are interpreted differently, depending on the translation direction. This decision simplified the process of creating the interlingua for individual sentences, and allows the system to defer mapping of language-specific features (such as tense and aspect), which are realized when the target syntactic feature structure is created. We also describe a set of problems we encountered in translating modal verbs, and discuss the representation of modality in our interlingua."
1999.tmi-1.22,Multiple strategies for automatic disambiguation in technical translation,1999,-1,-1,1,1,7705,teruko mitamura,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1999.mtsummit-1.8,Controlled language for multilingual machine translation,1999,4,43,1,1,7705,teruko mitamura,Proceedings of Machine Translation Summit VII,0,"In this paper, we present an overview of the issues in designing a controlled language, the implementation of a controlled language checker, and the deployment of KANT Controlled English for multilingual machine translation. We also discuss some success criteria for introducing controlled language. Finally, future vision of KANT controlled language development is discussed."
hakkani-etal-1998-english,An {E}nglish-to-{T}urkish interlingual {MT} system,1998,10,7,4,0,55462,dilek hakkani,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper describes the integration of a Turkish generation system with the KANT knowledge-based machine translation system to produce a prototype English-Turkish interlingua-based machine translation system. These two independently constructed systems were successfully integrated within a period of two months, through development of a module which maps KANT interlingua expressions to Turkish syntactic structures. The combined system is able to translate completely and correctly 44 of 52 benchmark sentences in the domain of broadcast news captions. This study is the first known application of knowledge-based machine translation from English to Turkish, and our initial results show promise for future development."
1997.mtsummit-papers.2,A Real-Time {MT} System for Translating Broadcast Captions,1997,-1,-1,2,1,9610,eric nyberg,Proceedings of Machine Translation Summit VI: Papers,0,"This presentation demonstrates a new multi-engine machine translation system, which combines knowledge-based and example-based machine translation strategies for real-time translation of business news captions from English to German."
1995.tmi-1.12,Controlled {E}nglish for Knowledge-Based {MT}: Experience with the {KANT} System,1995,-1,-1,1,1,7705,teruko mitamura,Proceedings of the Sixth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
C94-1012,Coping With Ambiguity in a Large-Scale Machine Translation System,1994,8,22,4,0,43387,kathryn baker,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In an interlingual knowledge-based machine translation system, ambignuity arises when the source language analyzer produces more than one interlingua expression for a source sentence. This can have a negative impact on translation quality, since a target sentence may be produced from an unintended meaning. In this paper we describe the methods used in the KANT machine translation system to reduce or eliminate ambiguity in a large-scale application domain. We also test these methods on a large corpus of test sentences, in order to illustrate how the different disambiguation methods reduce the average number of parses per sentence."
C94-1013,Evaluation Metrics for Knowledge-Based Machine Translation,1994,7,20,2,0,55464,rd nyberg,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"A methodology is presented for component-based machine translation (MT) evaluation through causal error analysis to complement existing global evaluation methods. This methodology is particularly appropriate for knowledge-based machine translation (KBMT) systems. After a discussion of MT evaluation criteria and the particular evaluation metrics proposed for KBMT, we apply this methodology to a large-scale application of the KANT machine translation system, and present some sample results."
1994.amta-1.36,"{KANT}: Knowledge-Based, Accurate Natural Language Translation",1994,-1,-1,1,1,7705,teruko mitamura,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
X93-1020,The {TIPSTER/SHOGUN} Project,1993,-1,-1,5,0,56359,paul jacobs,"TIPSTER TEXT PROGRAM: PHASE {I}: Proceedings of a Workshop held at Fredricksburg, Virginia, September 19-23, 1993",0,None
C92-4202,Hierarchical Lexical Structure and Interpretive Mapping in Machine Translation,1992,10,12,1,1,7705,teruko mitamura,{COLING} 1992 Volume 4: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"Large-scale knowledge-based machine translation requires significant amounts of lexical knowledge in order to map syntactic structures to conceptual structures. This paper presents a framework in which lexical knowledge is separated into different levels of representation, which are arranged in a hierarchical model based on principles of knowledge representation and lexical semantics. The proposed methodology is language-independent, and has been used to organize lexical knowledge for both English and Japanese."
C92-3168,"The {KANT} System: Fast, Accurate, High-Quality Translation in Practical Domains",1992,1,78,2,0,57074,eric iii,{COLING} 1992 Volume 3: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"Knowledge-based interlingual machine translation systems produce semantically accurate translations, but typically require massive knowledge acquisition. Ongoing research and development at the Center for Machine Translation has focussed on reducing this requirement to produce large-scale practical applications of knowledge-based MT. This paper describes KANT, the first system to combine principled source language design, semi-automated knowledge acquisition, and knowledge compilation techniques to produce fast, high-quality translation to multiple languages."
1992.tmi-1.20,"The {KANT} perspective: a critique of pure transfer (and pure interlingua, pure statistics, .. )",1992,-1,-1,2,0,10837,jaime carbonell,Proceedings of the Fourth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1991.mtsummit-papers.9,An Efficient Interlingua Translation System for Multi-lingual Document Production,1991,2,94,1,1,7705,teruko mitamura,Proceedings of Machine Translation Summit III: Papers,0,"Knowledge-based interlingual machine translation systems produce semantically accurate translations, but typically require massive knowledge acquisition. This paper describes KANT, a system that reduces this requirement to produce practical, scalable, and accurate KBMT applications. First, the set of requirements is discussed, then the full KANT architecture is illustrated, and finally results from a fully implemented prototype are presented."
W89-0225,Massively Parallel Parsing in $\\Phi${D}m{D}ialog: Integrated Architecture for Parsing Speech Inputs,1989,0,0,2,0,48217,hiroaki kitano,Proceedings of the First International Workshop on Parsing Technologies,0,"This paper describes the parsing scheme in the $\Phi$DmDialog speech-to-speech dialog translation system, with special emphasis on the integration of speech and natural language processing. We propose an integrated architecture for parsing speech inputs based on a parallel marker-passing scheme and attaining dynamic participation of knowledge from the phonological-level to the discourse-level. At the phonological level, we employ a stochastic model using a transition matrix and a confusion matrix and markers which carry a probability measure. At a higher level, syntactic/semantic and discourse processing, we integrate a case-based and constraint-based scheme in a consistent manner so that a priori probability and constraints, which reflect linguistic and discourse factors, are provided to the phonological level of processing. A probability/cost-based scheme in our model enables ambiguity resolution at various levels using one uniform principle."
1988.tmi-1.9,The Universal Parser Compiler and its application to a speech translation system,1988,-1,-1,4,0,56874,masaru tomita,Proceedings of the Second Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
