2020.lrec-1.154,W13-4829,0,0.0277329,"Missing"
2020.lrec-1.154,R19-1123,1,0.894917,"Missing"
2020.lrec-1.154,L18-1105,0,0.0478822,"Missing"
2020.lrec-1.154,W17-6615,0,0.0265807,"Missing"
2020.lrec-1.154,L18-1407,1,0.747658,"432 5,801 76 Table 1: Corpora descriptive statistics and average document sizes range from small (E-gov) to large (Blog). Further details regarding each individual domain are discussed in the next sections. In what follows we briefly describe the kinds of text available from each domain. Facebook texts are provided by the b5-post corpus (Ramos et al., 2018; dos Santos et al., 2017), a collection of over 194k status updates written by 1019 users of Brazilian Facebook that has been previously taken as the basis in a number of single-domain author profiling and personality classification tasks (Hsieh et al., 2018; Silva and Paraboni, 2018a; Silva and Paraboni, 2018b). Facebook status updates naturally cover a wide range of topics, including significant proportions of information about the authors themselves (e.g., what they are doing, what they are eating etc.) and, as in the case of social network languages in general, are often informal and noisy. Opinion texts were obtained from an ongoing data collection task (dos Santos and Paraboni, 2019), conveying over 3400 short texts written by 433 on-line Brazilian microvolunteers. Opinion texts are mostly impersonal and highly focused on the topic under di"
2020.lrec-1.154,P17-2075,0,0.0243116,"Missing"
2020.lrec-1.154,C14-1184,0,0.050643,"Missing"
2020.lrec-1.154,L18-1183,1,0.836815,"Domain Facebook Opinion Blog E-gov Learning instances Male Female 441 578 285 148 1,038 1,564 28,805 15,893 Text statistics Vocabulary Words 63,165 2,434,215 11,004 187,118 207,947 9,119,406 77,396 3,760,126 Documents 1,019 433 5,801 49,449 Words / docs 2,389 432 5,801 76 Table 1: Corpora descriptive statistics and average document sizes range from small (E-gov) to large (Blog). Further details regarding each individual domain are discussed in the next sections. In what follows we briefly describe the kinds of text available from each domain. Facebook texts are provided by the b5-post corpus (Ramos et al., 2018; dos Santos et al., 2017), a collection of over 194k status updates written by 1019 users of Brazilian Facebook that has been previously taken as the basis in a number of single-domain author profiling and personality classification tasks (Hsieh et al., 2018; Silva and Paraboni, 2018a; Silva and Paraboni, 2018b). Facebook status updates naturally cover a wide range of topics, including significant proportions of information about the authors themselves (e.g., what they are doing, what they are eating etc.) and, as in the case of social network languages in general, are often informal and nois"
2020.lrec-1.154,D14-1121,0,0.0209,"rectly comparable) author profiling tasks. An important limitation of the current work is that all experiments were focused on gender classification only. As future work, we intend to expand the current experiments by addressing other author profiling tasks such as age and personality classification. Also as future work, we intend to take a closer look into the effects of dataset size on task performance, and build crossdomain models by making use of larger amounts of training data. Another possible investigation along these lines is the use of profiling strategies based on lexical knowledge (Sap et al., 2014; Schwartz et al., 2013). Methods of this kind, which are clearly attractive for reasons of computational efficiency and potential for generalisation, still require further investigation in cross-domain settings. Finally, we also intend to enrich an existing authorship attribution system (Cust´odio and Paraboni, 2018) with the output of the current gender classifiers and similar models. In doing so, we expect to improve overall accuracy in author identification with the aid of automated author profiling methods. Acknowledgements This work received support by FAPESP grant # 2016/14223-0 and fro"
2020.lrec-1.750,W13-4829,0,0.0269938,"Missing"
2020.lrec-1.750,W15-1204,0,0.232961,"social media text (usually Twitter or Reddit) (Resnik et al., 2013; Resnik et al., 2015; Jamil et al., 2017; Yates et al., 2017; Orabi et al., 2018). In addition to these, a second line of research has recently attempted to go beyond recognition by focusing on the early signs of these illnesses, and by analysing the users’ publication history over time to potentially anticipate treatment and prevent further harm (Trotzek et al., 2018b; Losada et al., 2019). The two kinds of study are of course overlapping, and usually make use of supervised machine learning methods based on annotated corpora (Coppersmith et al., 2015; Losada et al., 2017; Yates et al., 2017). As in many other fields, however, existing resources are largely devoted to English NLP, and there is little support for studies of this kind in under resourced languages. To help bridge this gap, this paper describes the initial steps towards building a novel language resource of this kind, namely, a Brazilian Portuguese corpus of tweets written by users with a diagnosed mental health issue. The corpus - hereby called DepressBR - is intended to support both standard recognition of depression and related issues as in Coppersmith et al. (2015), and te"
2020.lrec-1.750,R19-1123,1,0.892653,"Missing"
2020.lrec-1.750,L18-1407,1,0.880755,"Missing"
2020.lrec-1.750,W17-3104,0,0.0154149,"ds: text classification, mental health, depression 1. Introduction Depression and related mental health issues are well-known challenges of modern life, and are often reflected in the language employed by the individuals who suffer from these conditions. Accordingly, research in Natural Language Processing (NLP) and related fields have developed an increasing number of studies devoted to the computational recognition of depression, anxiety, bipolar disorder, anorexia, suicidal thought and many others from social media text (usually Twitter or Reddit) (Resnik et al., 2013; Resnik et al., 2015; Jamil et al., 2017; Yates et al., 2017; Orabi et al., 2018). In addition to these, a second line of research has recently attempted to go beyond recognition by focusing on the early signs of these illnesses, and by analysing the users’ publication history over time to potentially anticipate treatment and prevent further harm (Trotzek et al., 2018b; Losada et al., 2019). The two kinds of study are of course overlapping, and usually make use of supervised machine learning methods based on annotated corpora (Coppersmith et al., 2015; Losada et al., 2017; Yates et al., 2017). As in many other fields, however, exist"
2020.lrec-1.750,N13-1090,0,0.00446383,"ression with balanced class weights, L2 penalty and a lbfgs solver. The LR.Tfidf model takes as an input TF-IDF vectors computed from the input document, and subsequently reduced to the k=15,000 best features with the aid of univariate feature selection using ANOVA f-value as a score function. The model also uses logistic regression with balanced class weights, L2 penalty and the lbfgs solver. Finally, the MLP.WordEmb model takes as an input a document representation built from self-trained TF-IDFweighted average word embeddings of size 100, which in turn are computed using Word2vec Skipgram (Mikolov et al., 2013). Document vectors are created by computing the weighted average of individual word embedding vectors multiplied by the individual TF-IDF scores of each word. In doing so, only word embeddings corresponding to the k=15,000 best features are considered. As in the previous LR.Tfidf model, features are selected with the aid of univariExperiment 2: Focusing on self reports Using the entire set of messages written by an individual to detect mental health issues may be problematic given that many - or possibly most - messages may be neutral with respect to his/her feelings or thoughts. To shed light"
2020.lrec-1.750,W18-0609,0,0.0208787,"depression 1. Introduction Depression and related mental health issues are well-known challenges of modern life, and are often reflected in the language employed by the individuals who suffer from these conditions. Accordingly, research in Natural Language Processing (NLP) and related fields have developed an increasing number of studies devoted to the computational recognition of depression, anxiety, bipolar disorder, anorexia, suicidal thought and many others from social media text (usually Twitter or Reddit) (Resnik et al., 2013; Resnik et al., 2015; Jamil et al., 2017; Yates et al., 2017; Orabi et al., 2018). In addition to these, a second line of research has recently attempted to go beyond recognition by focusing on the early signs of these illnesses, and by analysing the users’ publication history over time to potentially anticipate treatment and prevent further harm (Trotzek et al., 2018b; Losada et al., 2019). The two kinds of study are of course overlapping, and usually make use of supervised machine learning methods based on annotated corpora (Coppersmith et al., 2015; Losada et al., 2017; Yates et al., 2017). As in many other fields, however, existing resources are largely devoted to Engl"
2020.lrec-1.750,P98-2166,1,0.595728,"Missing"
2020.lrec-1.750,L18-1183,1,0.866424,"Missing"
2020.lrec-1.750,D13-1133,0,0.0246388,"assification addressing both tasks. Keywords: text classification, mental health, depression 1. Introduction Depression and related mental health issues are well-known challenges of modern life, and are often reflected in the language employed by the individuals who suffer from these conditions. Accordingly, research in Natural Language Processing (NLP) and related fields have developed an increasing number of studies devoted to the computational recognition of depression, anxiety, bipolar disorder, anorexia, suicidal thought and many others from social media text (usually Twitter or Reddit) (Resnik et al., 2013; Resnik et al., 2015; Jamil et al., 2017; Yates et al., 2017; Orabi et al., 2018). In addition to these, a second line of research has recently attempted to go beyond recognition by focusing on the early signs of these illnesses, and by analysing the users’ publication history over time to potentially anticipate treatment and prevent further harm (Trotzek et al., 2018b; Losada et al., 2019). The two kinds of study are of course overlapping, and usually make use of supervised machine learning methods based on annotated corpora (Coppersmith et al., 2015; Losada et al., 2017; Yates et al., 2017)"
2020.lrec-1.750,W15-1207,0,0.0156398,"ng both tasks. Keywords: text classification, mental health, depression 1. Introduction Depression and related mental health issues are well-known challenges of modern life, and are often reflected in the language employed by the individuals who suffer from these conditions. Accordingly, research in Natural Language Processing (NLP) and related fields have developed an increasing number of studies devoted to the computational recognition of depression, anxiety, bipolar disorder, anorexia, suicidal thought and many others from social media text (usually Twitter or Reddit) (Resnik et al., 2013; Resnik et al., 2015; Jamil et al., 2017; Yates et al., 2017; Orabi et al., 2018). In addition to these, a second line of research has recently attempted to go beyond recognition by focusing on the early signs of these illnesses, and by analysing the users’ publication history over time to potentially anticipate treatment and prevent further harm (Trotzek et al., 2018b; Losada et al., 2019). The two kinds of study are of course overlapping, and usually make use of supervised machine learning methods based on annotated corpora (Coppersmith et al., 2015; Losada et al., 2017; Yates et al., 2017). As in many other fi"
2020.lrec-1.750,D17-1322,0,0.0176068,"ion, mental health, depression 1. Introduction Depression and related mental health issues are well-known challenges of modern life, and are often reflected in the language employed by the individuals who suffer from these conditions. Accordingly, research in Natural Language Processing (NLP) and related fields have developed an increasing number of studies devoted to the computational recognition of depression, anxiety, bipolar disorder, anorexia, suicidal thought and many others from social media text (usually Twitter or Reddit) (Resnik et al., 2013; Resnik et al., 2015; Jamil et al., 2017; Yates et al., 2017; Orabi et al., 2018). In addition to these, a second line of research has recently attempted to go beyond recognition by focusing on the early signs of these illnesses, and by analysing the users’ publication history over time to potentially anticipate treatment and prevent further harm (Trotzek et al., 2018b; Losada et al., 2019). The two kinds of study are of course overlapping, and usually make use of supervised machine learning methods based on annotated corpora (Coppersmith et al., 2015; Losada et al., 2017; Yates et al., 2017). As in many other fields, however, existing resources are la"
araujo-etal-2010-sinotas,J97-1004,0,\N,Missing
araujo-etal-2010-sinotas,E06-1040,0,\N,Missing
araujo-etal-2010-sinotas,H05-1042,0,\N,Missing
araujo-etal-2010-sinotas,W07-2315,0,\N,Missing
araujo-etal-2010-sinotas,W09-0623,0,\N,Missing
araujo-etal-2010-sinotas,P02-1040,0,\N,Missing
araujo-etal-2010-sinotas,R09-1059,1,\N,Missing
araujo-etal-2010-sinotas,W00-1401,0,\N,Missing
C98-2161,C96-1021,0,0.0525087,"Missing"
C98-2161,C94-2189,0,0.0134789,"or each anaphor. 3. Factors in PPA resolution This section describes a minimal set of factors in PPA resolution, based on corpus investigation. These factors will be considered in place of traditional syntactic constraints, which are not suitable for our present problem, as shown in section 2. In our proposal, because of the structural complexity of sentences in the domain, we have adopted a practical approach, based on simple heuristic rules, with a view to avoiding syntactic and semantic analysis. Similar strategies have been adopted in several recent works in anaphor resolution, such as T. Nasukawa (1994), R. Mitkov (1996), R. Vieira & M. Poesio (1997) and others. We have defined 6 simple factors in PPA resolution (F1 to F6) based on syntactic, semantic and pragqnatic knowledge, aiming to deternaine PPAs antecedents in our specifc domain. As a secondary goal, we apply our proposal also to PPAs in a different domain (see section 5). Factors, enunciated as heuristic rules, will act as constraints (F1 to F5) or preferences (F6), as established by J. Carbonell (1988). 3.1. Syntactic level Since typical syntactic constraints are not suitable for PPA resolution, in our approach we have limited the r"
C98-2161,C96-2158,0,0.033321,"Missing"
C98-2161,C88-1021,0,\N,Missing
C98-2161,P87-1022,0,\N,Missing
J07-2004,P89-1009,0,0.0918163,"rtant aspect of GRE is to find combinations of properties that allow the generator to refer uniquely to an entity, called the target. Crucially, GRE algorithms only use properties whose denotations are part of the common knowledge of writer and reader.2 These algorithms are typically designed in such a way that generation is performed quickly (e.g., their worst-case running time tends to be linear [Dale and Reiter 1995; van Deemter 2002]) but the processing effort of the reader is not taken into account. Some algorithms do make a point of generating descriptions that are as brief as possible (Dale 1989), and this can be argued to make interpretation easier. As we have seen, however, in relation to Examples (1a–c), brevity can make resolution difficult. For concreteness, let us focus on one of the best-known algorithms in this area. The Incremental Algorithm (Dale and Reiter 1995) starts by arranging attributes in a list, after which they are considered one by one, to see if any of their values contributes something to the description, by removing “distractors” (i.e., objects other than the referent); if an attribute (e.g., COLOR) can contribute something, then a suitable value (e.g., RED) fo"
J07-2004,E91-1028,0,0.0720446,"Missing"
J07-2004,C94-2182,0,0.128001,"Missing"
J07-2004,W05-1606,0,0.0396477,"ple of a description failing this requirement occurs in Get off one stop before I do, in an exchange between two people who have just met, as a description of where the hearer should get off the bus (Appelt 1985, cited in Dale and Reiter 1995). 231 Computational Linguistics Volume 33, Number 2 Suppose a referring expression identifies its referent uniquely. Then at least two things can stand in the way of finding its referent: the “difficulty” of the individual properties used in the description (i.e., the fact that it may be difficult to ascertain which objects have the property in question [Horacek 2005]), or the size and structure of the search space. To exemplify the first factor, suppose you are queuing up for a concert and want to explain to a friend that a girl further ahead in the queue has his ticket. Color is an attribute that speakers like to use, even if it leads to logical redundancy (Pechmann 1989). This might be done by describing the referent as the girl in a yellow dress, or as the girl with green eyes, for example. But arguably, the first property contributes more towards your friend’s search, because the color of a person’s eyes may not leap out at him from afar. In the Incr"
J07-2004,P00-1019,0,0.0269298,"r being interested in the referent) or to highlight the 1 Dale and Reiter (1995, Section 5) also mention the use of “navigational” (or “attention-directing”) information in referring expressions, which they distinguish from “discrimination information,” and whose function appears to be to move the attention of the reader/hearer towards an object. The concept is not defined precisely and it is not clear how navigational information should be used in GRE. 230 Paraboni, van Deemter, and Masthoff Making Referents Easy to Identify speaker’s awareness that the referent has the property in question (Jordan 2000, 2002). Implementations of such findings in NLG are not difficult to envisage. The present article takes this reader-oriented perspective on the redundancy of referring expressions a step further, by asking how a generator can use logically redundant information to reduce the search space within which a reader has to “find” a referent; this will be specifically useful when referents need to be found in situations where the extensions of some of the properties are not known to the reader/hearer in advance (cf., Edmonds [1994] for a related set of problems) and where some effort may be needed t"
J07-2004,W06-1409,1,0.695898,"Missing"
J07-2004,W02-2115,1,0.565138,"Missing"
J07-2004,P04-1052,0,0.0951487,"ni 2000, 2003; Paraboni and van Deemter 2002a, 2002b) but their relevance extends to many other situations. Our findings will also shed light on the egocentricity debate among psycholinguists about the extent to which speakers take hearer’s knowledge into account when they speak (Keysar, Lin, and Barr 2003). Throughout the article, we shall focus on issues of Content Determination (as opposed to, for example Lexical Choice), and on the situations in which individuals are first mentioned (as opposed to ones in which linguistic context allows them to be shortened [e.g., Krahmer and Theune 2002; Siddharthan and Copestake 2004]). 2. Ease of Resolution in the Incremental Algorithm Generation of referring expressions (GRE) is a key task of NLG systems (e.g., Reiter and Dale 2000, Section 5.4). An important aspect of GRE is to find combinations of properties that allow the generator to refer uniquely to an entity, called the target. Crucially, GRE algorithms only use properties whose denotations are part of the common knowledge of writer and reader.2 These algorithms are typically designed in such a way that generation is performed quickly (e.g., their worst-case running time tends to be linear [Dale and Reiter 1995;"
J07-2004,J02-1003,1,0.679526,"Missing"
J07-2004,P00-1012,0,\N,Missing
J17-2006,W11-2702,0,0.664394,"lp or impair identification is crucial for the design of hearer-oriented REG algorithms. Assuming that we would like to generate descriptions that are easy to identify, this knowledge may shed light on long-standing issues in REG such as the question of when to use relational properties for the purpose of identification (e.g., as in the “bird on top of the mailbox”). On the one hand, algorithms such as in Dale and Haddock (1991) make use of relations as a last resort, that is, only when it is not possible to produce a uniquely identifying atomic description. On the other hand, studies such as Viethen and Dale (2011) suggest that using relations may be common even when relations are not required for disambiguation. Clearly, one possible way of deciding when to use a relational property is by assessing its impact on identification. To investigate when referential overspecification may help or impair identification, we report on two eye-tracking experiments that measure the time spent examining objects in a visual context based on different kinds of information. Our findings suggest that easily recognizable properties may help identification, whereas other properties may have the opposite effect. These resu"
L18-1183,W09-0609,0,0.53167,"g in a corpus of 1019 texts. 1140 4.2. Referring Expressions b5-ref The b5-ref subcorpus was built for the study of the effects of human personality on the generation of referring expressions (REG), which is an active research topic in NLG (Krahmer and van Deemter, 2012). REG is hereby understood both as the task of determining the semantic contents of definite descriptions (or what to say about the intended referent), and as the surface realisation task of these expressions (or how to say it in a target language). As in much of the existing work on data collection for REG (Gatt et al., 2007; Dale and Viethen, 2009; Paraboni et al., 2017a), the b5-ref corpus was implemented as a language production task in which subjects were requested to distinguish a certain target from distractor objects in a given context by making use of a definite description. Unlike REG corpora based on simplified domains (e.g., geometric objects), however, b5-ref makes use of stimulus images that may arguably make differences across personality traits more explicit. More specifically, the referential contexts under consideration convey images extracted from Face Place (Righi et al., 2012), a collection of realistic human photogr"
L18-1183,W13-4829,0,0.425964,"Missing"
L18-1183,W07-2307,0,0.487813,"Missing"
L18-1183,L18-1407,1,0.604358,"ty is more evident in (Facebook) text than others. A machine learning approach as in this example may of course be applied to many other forms of author profiling based on the b5 corpus. These include, for instance, the classification of gender, age group and others. However, since these tasks require the additional definition of how they would be modelled in the form of a classification problem (e.g., binary, multi-class, etc.), this kind of investigation would be outside the scope of the current discussion. A number of author profiling tasks of this kind, based on b5 data, are discussed in (Hsieh et al., 2018). 6. Table 2: Learning instances As learning features, we computed 64 LIWC categories (Pennebaker et al., 2001), four additional, MRC-like (Coltheart, 1981) psycholinguistic properties and further 60 dictionary attributes. LIWC features were obtained from Brazilian Portuguese LIWC (Filho et al., 2013) by counting word categories (e.g., religion, family, money etc.). Each feature represents the number of words found in the corresponding category normalised by the length of each Facebook time line in number of words. The four additional psycholinguistic features were obtained from (dos Santos et"
L18-1183,J12-1006,0,0.178287,"Missing"
L18-1183,L18-1475,1,0.830747,"h the contents and the surface form of referring expressions. Preliminary results of a machine learning REG model based on b5-ref data in (Paraboni et al., 2017c) suggest that the selection of non-discriminatory attributes (e.g., the property of ‘being young’, which is shared by all objects in the b5-ref domain and it is therefore not discriminatory) is particularly influenced by the speaker’s personality traits, an effect that is less evident in the case of discriminatory (or more perceptual) attributes. Moreover, results from a personality-dependent lexical choice model built from b5ref in (Lan and Paraboni, 2018) showed that the lexicalisation of the most frequent properties (i.e., those for which there is sufficient data in the corpus) greatly improves when personality information is taken into account. 4.3. Scene descriptions b5-text and b5-caption Unlike b5-ref, the b5-text and b5-caption subcorpora are primarily intended for the study of more general issues of personality-based text production, such as document planDifferently from the identification task in b5-ref, the goal in this case was to investigate which pictorial elements each speaker would select to describe each image, the order and str"
L18-1183,J11-3002,0,0.0578679,"m all regions of the country. The inventory considered in (de Andrade, 2008) will be the basis of the present work as well. 1138 Figure 1: The b5 corpus structure. The information provided by the BFI enables the investigation of a range of issues related to the computational treatment of human personality. A detailed discussion of these applications would be beyond the scope of this paper, but includes the recognition of personality traits from text on ´ social networks (Iacobelli et al., 2011; Celli, 2012; AlvarezCarmona et al., 2015) and the generation of text based on a target personality (Mairesse and Walker, 2011). Applications of this kind will usually rely on text corpora annotated with personality information. An example of resource of this kind is myPersonality, a large database of Facebook status updates for the English language and corresponding Big Five information about their authors. We are not aware, however, of any similar resources for our target language (Brazilian Portuguese). In addition to the lack of language resources in this target language, we notice that existing resources are usually devoted to personality recognition applications, but they may be less suitable for personality-dep"
L18-1183,J17-2006,1,0.802874,"Missing"
L18-1183,U10-1013,0,0.116036,"se developed primarily for the purpose of personality recognition and author profiling in Portuguese. Studies of this kind would typically take the form of a supervised (Mairesse et al., 2007), or semi-supervised (Celli, 2012) learning task. The experiment described in the previous section is an (admittedly simple) example of the former. The b5-ref subcorpus intends to support studies on machine-learning referring expression generation (REG) that take personality information into account. Studies of this kind may be seen as a possible generalisation of models of human variation for this task (Viethen and Dale, 2010; Ferreira and Paraboni, 2017). Moreover, we notice that the corpus may be also useful for studies of personality-based surface realisation and lexical choice of definite descriptions. The b5-text subcorpus is potentially useful as a means to establish mapping between linguistic features and personality traits, which may guide the design of text generation models based on personality with a particular focus on multisentential phenomena. Given the relatively controlled domain - based on the same set of images described by all participants - b5-text texts make evident the different linguistic ch"
L18-1407,W13-4829,0,0.237262,"Missing"
L18-1407,L18-1475,1,0.486423,"t using logistic regression. Language-specific resources in LIWC+P and Word2Vec models (i.e., psycholinguistic dictionaries and Twitter data) concern the Brazilian Portuguese language only. 3.3. Data In our experiment we make use of a portion of the b5 corpus of texts and accompanying author demographics for the Brazilian Portuguese language (Ramos et al., 2018). The corpus has been applied to a number of NLP/NLG tasks ranging from personality recognition (dos Santos et al., 2017b; Silva and Paraboni, 2018) to personality-dependent content selection (Paraboni et al., 2017) and lexical choice (Lan and Paraboni, 2018). All models were built from the 2.2 million word b5-post subcorpus of Facebook status updates. This dataset conveys up to 1,000 status updates from 1019 users of Brazilian Portuguese Facebook. The data is partially labelled with age, gender, degrees of religiosity and IT status information2 . Gender, age and IT-background information were generally obtained from Facebook and, in some cases, provided by some of the participants of the b5-post data collection task upon request. Degrees of religiosity were provided by a small subset of participants upon request. Table 1 summarises the number of"
L18-1407,C14-1184,0,0.0645427,"Missing"
L18-1407,L18-1183,1,0.604048,"based on word embeddings hereby called Word2Vec. This consists of the average word vectors obtained from a skip-gram-600 model (Mikolov et al., 2013) using window size=5, min count=10, built from a 50-million Twitter corpus. All the above models were built using logistic regression. Language-specific resources in LIWC+P and Word2Vec models (i.e., psycholinguistic dictionaries and Twitter data) concern the Brazilian Portuguese language only. 3.3. Data In our experiment we make use of a portion of the b5 corpus of texts and accompanying author demographics for the Brazilian Portuguese language (Ramos et al., 2018). The corpus has been applied to a number of NLP/NLG tasks ranging from personality recognition (dos Santos et al., 2017b; Silva and Paraboni, 2018) to personality-dependent content selection (Paraboni et al., 2017) and lexical choice (Lan and Paraboni, 2018). All models were built from the 2.2 million word b5-post subcorpus of Facebook status updates. This dataset conveys up to 1,000 status updates from 1019 users of Brazilian Portuguese Facebook. The data is partially labelled with age, gender, degrees of religiosity and IT status information2 . Gender, age and IT-background information were"
L18-1407,D14-1121,0,0.0935505,"Missing"
L18-1474,W09-0609,0,0.290503,"aker or writer - is to produce a uniquely identifying description of the intended target. This could be accomplished, for instance, by producing a definite description as in ‘The cone next to a grey box’. Experiments involving human subjects for the collection of referring expression corpora are often implemented as a web-based data collection task, that is, without a particular addressee in mind. When there is no risk of confusion, we will hereby call these monologue situations1 . So-called monologue situations are the method of choice for collecting data in TUNA (Gatt et al., 2007), GRE3D3 (Dale and Viethen, 2009), GRE3D7 (Viethen and Dale, 2011), Wally (Clarke et al., 2013) and other similar resources. By contrast, a number of data collection tasks make use of participant pairs in some form of dialogue. These include GIVE-2 (Gargett et al., 2010), ReferIt (Kazemzadeh et al., 2014), Stars2 (Paraboni et al., 2017a), b5-ref (Ramos et al., 2018) and others. Both dialogue and monologue are of course instances of real language use but, at least from these studies, it is not entirely clear whether the two situations are truly comparable or, to be more precise, whether REG studies that rely on these methods m"
L18-1474,gargett-etal-2010-give,0,0.0353226,"s for the collection of referring expression corpora are often implemented as a web-based data collection task, that is, without a particular addressee in mind. When there is no risk of confusion, we will hereby call these monologue situations1 . So-called monologue situations are the method of choice for collecting data in TUNA (Gatt et al., 2007), GRE3D3 (Dale and Viethen, 2009), GRE3D7 (Viethen and Dale, 2011), Wally (Clarke et al., 2013) and other similar resources. By contrast, a number of data collection tasks make use of participant pairs in some form of dialogue. These include GIVE-2 (Gargett et al., 2010), ReferIt (Kazemzadeh et al., 2014), Stars2 (Paraboni et al., 2017a), b5-ref (Ramos et al., 2018) and others. Both dialogue and monologue are of course instances of real language use but, at least from these studies, it is not entirely clear whether the two situations are truly comparable or, to be more precise, whether REG studies that rely on these methods may draw conclusions regarding attribute selection (Dale and Reiter, 1995), referential overspecification (Pechmann, 1989; Paraboni et al., 2017b) and others regardless of the mode of communication. To shed light on this issue, in this wor"
L18-1474,W07-2307,0,0.0411072,"Missing"
L18-1474,W09-0629,0,0.0176658,"rd REG, in the sense proposed in (Dale and Reiter, 1995) and others. The TUNA corpus (Gatt et al., 2007) was implemented as a web-based data collection task involving single participants acting as speakers. The corpus comprises two domains: Furniture, containing descriptions of pieces of furniture (e.g., desks, chairs etc.), and People, containing descriptions of human photographs. Both Furniture and People scenes contain from three to seven objects each. The corpus was developed for the study of the content selection task of atomic descriptions, and as a dataset for a series of Shared Tasks (Gatt et al., 2009). TUNA contains 2280 descriptions produced by 60 speakers, being 1200 Furniture descriptions and 1080 People descriptions in so-called monologue situations. The GRE3D3 and GRE3D7 corpora (Dale and Viethen, 2009; Viethen and Dale, 2011) were also implemented as web-based collection tasks involving single participants in the role of speakers. In both cases, the domain consisted of visual scenes containing either three (in GRE3D3) or seven (GRE3D7) geometric objects (boxes and balls) each, with limited variation in colour and size. The goal of the data collection was to investigate the use of rel"
L18-1474,D14-1086,0,0.400169,"g expression corpora are often implemented as a web-based data collection task, that is, without a particular addressee in mind. When there is no risk of confusion, we will hereby call these monologue situations1 . So-called monologue situations are the method of choice for collecting data in TUNA (Gatt et al., 2007), GRE3D3 (Dale and Viethen, 2009), GRE3D7 (Viethen and Dale, 2011), Wally (Clarke et al., 2013) and other similar resources. By contrast, a number of data collection tasks make use of participant pairs in some form of dialogue. These include GIVE-2 (Gargett et al., 2010), ReferIt (Kazemzadeh et al., 2014), Stars2 (Paraboni et al., 2017a), b5-ref (Ramos et al., 2018) and others. Both dialogue and monologue are of course instances of real language use but, at least from these studies, it is not entirely clear whether the two situations are truly comparable or, to be more precise, whether REG studies that rely on these methods may draw conclusions regarding attribute selection (Dale and Reiter, 1995), referential overspecification (Pechmann, 1989; Paraboni et al., 2017b) and others regardless of the mode of communication. To shed light on this issue, in this work we developed a parallel, semantic"
L18-1474,J12-1006,0,0.0529083,"Missing"
L18-1474,J03-1003,0,0.211655,"Missing"
L18-1474,J17-2006,1,0.595872,"Missing"
L18-1474,L18-1183,1,0.776666,"ection task, that is, without a particular addressee in mind. When there is no risk of confusion, we will hereby call these monologue situations1 . So-called monologue situations are the method of choice for collecting data in TUNA (Gatt et al., 2007), GRE3D3 (Dale and Viethen, 2009), GRE3D7 (Viethen and Dale, 2011), Wally (Clarke et al., 2013) and other similar resources. By contrast, a number of data collection tasks make use of participant pairs in some form of dialogue. These include GIVE-2 (Gargett et al., 2010), ReferIt (Kazemzadeh et al., 2014), Stars2 (Paraboni et al., 2017a), b5-ref (Ramos et al., 2018) and others. Both dialogue and monologue are of course instances of real language use but, at least from these studies, it is not entirely clear whether the two situations are truly comparable or, to be more precise, whether REG studies that rely on these methods may draw conclusions regarding attribute selection (Dale and Reiter, 1995), referential overspecification (Pechmann, 1989; Paraboni et al., 2017b) and others regardless of the mode of communication. To shed light on this issue, in this work we developed a parallel, semantically annotated corpus of monologue and dialogue descriptions,"
L18-1474,U10-1013,0,0.600553,"as sets of semantic properties, usually in the form of attributevalue pairs as in colour-red. The primary goal of a REG algorithm of this kind is to produce a uniquely identifying description L so as to distinguish r from every other distractor object within C. Existing REG algorithms include early approaches such as the Greedy (Dale, 2002) and the Incremental (Dale and Reiter, 1995) algorithms. The Graph-based approach (Krahmer et al., 2003) allows the use of relational properties in a novel formulation of the task, and more recently the use of machine learning methods have been considered (Viethen and Dale, 2010; Ferreira and Paraboni, 2017). For a review of the main challenges in the field, see (Krahmer and van Deemter, 2012) and (van Deemter, 2016). To illustrate the work of a typical REG algorithm, and to highlight a number of issues that may influence its outcome, let us consider a simplified visual context as in Figure 2. Figure 2: A visual context. A scene of this kind may be represented as a knowledge base as follows. o1 &lt;type,box&gt;,&lt;size,small&gt; o2 &lt;type,cone&gt;,&lt;size,large&gt;,&lt;near,o3&gt; o3 &lt;type,ball&gt;,&lt;size,large&gt;,&lt;near,o2&gt; o4 &lt;type,box&gt;,&lt;size,large&gt;,&lt;near,o5&gt; o5 &lt;type,cone&gt;,&lt;size,large&gt;,&lt;near,o4&gt;"
L18-1474,W11-2702,0,0.875041,"uniquely identifying description of the intended target. This could be accomplished, for instance, by producing a definite description as in ‘The cone next to a grey box’. Experiments involving human subjects for the collection of referring expression corpora are often implemented as a web-based data collection task, that is, without a particular addressee in mind. When there is no risk of confusion, we will hereby call these monologue situations1 . So-called monologue situations are the method of choice for collecting data in TUNA (Gatt et al., 2007), GRE3D3 (Dale and Viethen, 2009), GRE3D7 (Viethen and Dale, 2011), Wally (Clarke et al., 2013) and other similar resources. By contrast, a number of data collection tasks make use of participant pairs in some form of dialogue. These include GIVE-2 (Gargett et al., 2010), ReferIt (Kazemzadeh et al., 2014), Stars2 (Paraboni et al., 2017a), b5-ref (Ramos et al., 2018) and others. Both dialogue and monologue are of course instances of real language use but, at least from these studies, it is not entirely clear whether the two situations are truly comparable or, to be more precise, whether REG studies that rely on these methods may draw conclusions regarding att"
L18-1475,W08-1132,0,0.0383856,"Missing"
L18-1475,W09-0609,0,0.551712,"Missing"
L18-1475,W08-2120,0,0.0604815,"Missing"
L18-1475,W07-2307,0,0.0853555,"Missing"
L18-1475,J12-1006,0,0.177256,"Missing"
L18-1475,W15-4627,0,0.0504277,"Missing"
L18-1475,J11-3002,0,0.38315,"Missing"
L18-1475,W15-2913,0,0.0655807,"Missing"
L18-1475,L18-1183,1,0.879877,"Missing"
L18-1475,W13-2108,0,0.0369474,"Missing"
L18-1476,W07-2307,0,0.0959359,"Missing"
L18-1476,W09-0629,0,0.0941416,"2 briefly de3005 scribes previous work on REG and related topics. Section 3 describes the experiment evolving human subjects in a reference production task. Section 4 presents and evaluates our REG algorithm. Finally, Section 5 draws a number of conclusions and suggests future work. 2. 2.1. Background REG attribute selection In the Natural Language Generation field, the attribute selection task for REG has been the focus of a wide range of computational methods (Dale and Reiter, 1995; Krahmer et al., 2003; Ferreira and Paraboni, 2014a), reference corpora (Gatt et al., 2007) and shared tasks (Gatt et al., 2009). REG is typically implemented as an algorithm that receives as an input a context C containing a target object r and additional distractor objects. Objects are represented as sets of semantic properties, usually in the form of attributevalue pairs as in type-monster. For instance, the following is a possible representation of the context conveying the eight objects labelled R1..R8 in the previous Figure 1. R1 <type,monster>,<colour,brown> R2 <type,sign>,<colour,white> R3 <type,man>,<colour,red>, <size,small>,<below,R4> R4 <type,block>,<colour,yellow>,<above,R3> R5 <type,monster>,<colour,brown"
L18-1476,J09-2005,0,0.0630045,"Missing"
L18-1476,W12-1503,0,0.015119,"generate descriptions that closely resemble those produced by human speakers in time-constrained situations. 4.1. Algorithms The experiment makes use of a modified version of the Incremental approach (IA) (Dale and Reiter, 1995), hereby called IAL, that takes as an input an additional overspecification Level parameter to enable the generation of descriptions with a customisable amount of information. The value of Level is intended to represent the average size of descriptions in the relevant domain, and may in practice be computed from a small set of training examples as discussed in, e.g., (Koolen et al., 2012). As in the original Incremental approach, IAL selects properties to compose an output description L by iterating over a domain-dependent list of preferred attributes P . At each step, properties that have some discriminatory power are selected until a uniquely identifying description is obtained, or until all properties in P have been attempted. The difference between the Incremental approach and IAL is the stop condition. Once a suitable description has been obtained, the Incremental approach terminates. IAL, by contrast, uses the value of Level as a stop condition. If the number of selected"
L18-1476,J12-1006,0,0.0525128,"Missing"
L18-1476,J03-1003,0,0.0672909,"Missing"
L18-1476,J17-2006,1,0.893387,"Missing"
L18-1476,passonneau-2006-measuring,0,0.0188096,"he P input parameter was computed from training data based on attribute frequencies (in which the most frequent attribute is to be attempted first). In the case of IAL, the additional Level parameter was also computed from the same training data as the average description length for each context. Both algorithms - and also the Greedy baseline - took as an input the same test data. Evaluation was carried out by comparing every generated description with its human counterpart available from the test corpus while computing Dice coefficients. In addition to that, overall accuracy and MASI scores (Passonneau, 2006) were computed for illustration purposes. 4.5. Results Table 2 summarised the results for the three algorithms under consideration applied to the test data. Algorithm Greedy Incremental IAL Acc. 0.18 0.22 0.33 Dice 0.62 0.66 0.72 MASI 0.36 0.40 0.48 Table 2: Time-constrained computational REG 4.6. Discussion Results suggest that the proposed IAL method generally outperforms both IA and Greedy. A Wilcoxon test shows that the difference between IAL and the second best approach - the Incremental algorithm - is significant both in terms of Dice (W =- 1203, Z =-4.32, p < 0.0001) and MASI (W = - 115"
novais-etal-2012-portuguese,A00-2023,0,\N,Missing
novais-etal-2012-portuguese,W00-0306,0,\N,Missing
novais-etal-2012-portuguese,W07-2315,0,\N,Missing
novais-etal-2012-portuguese,N03-2002,0,\N,Missing
novais-etal-2012-portuguese,P00-1012,0,\N,Missing
novais-etal-2012-portuguese,W11-2832,0,\N,Missing
novais-etal-2012-portuguese,W09-0608,0,\N,Missing
novais-etal-2012-portuguese,A00-2026,0,\N,Missing
P15-2012,P02-1013,0,0.0695165,"nguage descriptions of map locations Romina Altamirano FaMAF Nat.Univ. of C´ordoba C´ordoba, Argentina Thiago C. Ferreira EACH-USP Univ. of S˜ao Paulo S˜ao Paulo, Brazil Ivandr´e Paraboni EACH-USP Univ. of S˜ao Paulo S˜ao Paulo, Brazil Luciana Benotti FaMAF Nat.Univ. of C´ordoba C´ordoba, Argentina ialtamir@famaf.unc.edu.ar thiago.castro.ferreira@usp.br ivandre@usp.br benotti@famaf.unc.edu.ar Abstract Properties are selected for inclusion in L according to multiple - and often conflicting - criteria, including discriminatory power (i.e., the ability to rule out distractors) as in (Dale, 2002; Gardent, 2002), domain preferences (Pechmann, 1989; Gatt et al., 2013) and many others. A description that conveys more information than what is strictly required for disambiguation is said to be overspecified (Arts et al., 2011; Koolen et al., 2011; van Gompel et al., 2012; Engelhardt and Ferreira, 2006; Engelhardt et al., 2011). For a review of the research challenges in REG, see (Krahmer and van Deemter, 2012). Existing approaches to REG largely consist of algorithmic solutions, many of which have been influenced by, or adapted from, the Dale & Reiter Incremental algorithm in (Dale and Reiter, 1995). The"
P15-2012,W08-1107,0,0.0178913,"ssion for the target in the 1X map may or may not be the same as in the 2X map. For instance, the referring expression “the pub at Cowgate” is underspecified on the 1X map, but it is minimally distinguishing on the 2X map. Differences of this kind are common in interactive applications (e.g., in which the context of reference may change in structure or in the number of objects and referable properties), and the challenge for REG algorithms would be to produced an appropriate description for the modified context without starting from scratch. REG algorithms based on local context partitioning (Areces et al., 2008) may have an advantage in this respect, but further investigation is still required. Discussion This paper has introduced the Zoom corpus of natural language descriptions of map locations, a resource intended to support future research in REG and related fields. Preliminary results of a SVMbased approach to REG - which were solely presented for the future assessment of REG algorithms based on Zoom data - hint at the actual complexity of the REG task in this domain in a number of ways. First, we notice that a similar approach in (Ferreira and Paraboni, 2014) on GRE3D3 and GRE3D7 data has obtain"
P15-2012,W07-2307,0,0.0479941,"Missing"
P15-2012,W09-0629,0,0.0237294,"es in two degrees of detail (represented by low and high zoom levels), and address instances of singular and plural reference. A fragment of the experiment interface is shown in Fig. 1. Related work TUNA (Gatt et al., 2007) was the first prominent REG corpus to be made publicly available for research purposes. The corpus was developed in a series of controlled experiments, containing 2280 atomic descriptions produced by 60 speakers of English in two domains (1200 descriptions of furniture items and 1080 descriptions of people’s photographs). TUNA has been used in a series of REG shared tasks (Gatt et al., 2009). GRE3D3 and its extension GRE3D7 (Dale and Viethen, 2009; Viethen and Dale, 2011) were developed in a series of web-based experiments primarily focussed on the study of relational descriptions. GRE3D3 contains 630 descriptions produced by 63 speakers, and GRE3D7 contains 4480 descriptions produced by 287 speakers. In both cases, the language of the experiment was English. The domain consists of simple visual scenes conveying boxes and spheres. Stars (Teixeira et al., 2014) and its extension Stars2 were collected for the study of referential overspecification. Stars contains 704 descriptions p"
P15-2012,W09-0609,0,0.157992,"4)). A possible explanation for the small interest in ML for REG may be the relatively low availability of data. While research in many fields may benefit from the wide availability of text corpora (e.g., obtainable from the web), research in REG usually requires highly specialised data - hereby called REG corpora - conveying not only referring expressions produced by human speakers, but also a fully-annotated representation of the context (i.e., all objects and their semantic properties) within which the expressions have been produced. REG corpora such as TUNA (Gatt et al., 2007) and GRE3D3 (Dale and Viethen, 2009) are useful both to gain general insights on human language production, and to benefit from data-intensive computational techniques such as ML. However, being usually the final product of controlled experiments involving human subjects, REG corThis paper describes an experiment to elicit referring expressions from human subjects for research in natural language generation and related fields, and preliminary results of a computational model for the generation of these expressions. Unlike existing resources of this kind, the resulting data set - the Zoom corpus of natural language descriptions o"
P15-2012,P06-1131,0,0.0233246,"omain entities. In particular, the issue of how to determine the semantic contents of definite descriptions (e.g., ‘the Indian restaurant on 5th street’, ‘the restaurant we went to last night’, etc.) has received significant attention in the field, and it is also the focus of the present work. The input to a REG algorithm is a context set C containing an intended referent r and a number of distractor objects. All objects are represented as attribute-value pairs representing either atomic (type-restaurant) or relational (on-5thstreet) properties (Krahmer and Theune, 2002; Krahmer et al., 2003; Kelleher and Kruijff, 2006; Viethen et al., 2013). The expected output is a uniquely identifying list L of properties known to be true of r so that L distinguishes r from all distractors in C (Dale and Reiter, 1995). 69 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 69–75, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics descriptions produced by 56 speakers. Both domains make use of simple visual scenes containing up to four object types (e.g., stars,"
P15-2012,W08-2120,0,0.0388584,"Missing"
P15-2012,J12-1006,0,0.0413592,"Missing"
P15-2012,J03-1003,0,0.0586667,"Missing"
P15-2012,passonneau-2006-measuring,0,0.0363325,"scribe it as well. Since every attribute that corresponds to a positive prediction is always selected, the algorithm does not regard uniqueness as a stop condition. As a result, the output description may convey a certain amount of overspecification. For evaluation purposes, we used the subset of singular descriptions from the Portuguese portion of the corpus, comprising 821 descriptions. Evaluation was carried out by comparing the corpus description with the system output to measure overall accuracy (i.e., the number of exact matches between the two descriptions), Dice (Dice, 1945) and MASI (Passonneau, 2006) coefficients. Following (Ferreira and Paraboni, 2014), we built a REG model using support vector machines with radial basis function kernel. The classifiers were trained and tested using 6-fold cross validation. Optimal parameters were selected using grid search as follows: for each step in the main k-fold validation, one fold was reserved for testing, and the remaining k − 1 folds were subject to a secondary cross-validation procedure in which different parameter combinations were attempted. The C parameter was assigned the values 1, 10, 100 and 1000, and γ was assigned 1, 0.1, 0.001 and 0.0"
P15-2012,U10-1013,0,0.022199,"e overspecified (Arts et al., 2011; Koolen et al., 2011; van Gompel et al., 2012; Engelhardt and Ferreira, 2006; Engelhardt et al., 2011). For a review of the research challenges in REG, see (Krahmer and van Deemter, 2012). Existing approaches to REG largely consist of algorithmic solutions, many of which have been influenced by, or adapted from, the Dale & Reiter Incremental algorithm in (Dale and Reiter, 1995). The use of machine learning (ML) techniques, by contrast, seems to be less frequent than in other NLG tasks, although a number of exceptions do exist (e.g., (Jordan and Walker, 2005; Viethen and Dale, 2010; Viethen, 2011; Garoufi and Koller, 2013; Ferreira and Paraboni, 2014)). A possible explanation for the small interest in ML for REG may be the relatively low availability of data. While research in many fields may benefit from the wide availability of text corpora (e.g., obtainable from the web), research in REG usually requires highly specialised data - hereby called REG corpora - conveying not only referring expressions produced by human speakers, but also a fully-annotated representation of the context (i.e., all objects and their semantic properties) within which the expressions have bee"
P15-2012,W11-2702,0,0.022657,"dress instances of singular and plural reference. A fragment of the experiment interface is shown in Fig. 1. Related work TUNA (Gatt et al., 2007) was the first prominent REG corpus to be made publicly available for research purposes. The corpus was developed in a series of controlled experiments, containing 2280 atomic descriptions produced by 60 speakers of English in two domains (1200 descriptions of furniture items and 1080 descriptions of people’s photographs). TUNA has been used in a series of REG shared tasks (Gatt et al., 2009). GRE3D3 and its extension GRE3D7 (Dale and Viethen, 2009; Viethen and Dale, 2011) were developed in a series of web-based experiments primarily focussed on the study of relational descriptions. GRE3D3 contains 630 descriptions produced by 63 speakers, and GRE3D7 contains 4480 descriptions produced by 287 speakers. In both cases, the language of the experiment was English. The domain consists of simple visual scenes conveying boxes and spheres. Stars (Teixeira et al., 2014) and its extension Stars2 were collected for the study of referential overspecification. Stars contains 704 descriptions produced by 64 speakers in a web-based experiment. Stars2 was produced in dialogue"
P15-2012,W13-2108,0,0.0130789,"r, the issue of how to determine the semantic contents of definite descriptions (e.g., ‘the Indian restaurant on 5th street’, ‘the restaurant we went to last night’, etc.) has received significant attention in the field, and it is also the focus of the present work. The input to a REG algorithm is a context set C containing an intended referent r and a number of distractor objects. All objects are represented as attribute-value pairs representing either atomic (type-restaurant) or relational (on-5thstreet) properties (Krahmer and Theune, 2002; Krahmer et al., 2003; Kelleher and Kruijff, 2006; Viethen et al., 2013). The expected output is a uniquely identifying list L of properties known to be true of r so that L distinguishes r from all distractors in C (Dale and Reiter, 1995). 69 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 69–75, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics descriptions produced by 56 speakers. Both domains make use of simple visual scenes containing up to four object types (e.g., stars, boxes, cones and spher"
P15-2012,P89-1009,0,\N,Missing
P15-2012,C12-2006,1,\N,Missing
P15-2013,P02-1013,0,0.069814,"is more likely to be selected when it is maximally different from the other colours in the context. For instance, a red object is more likely to be described as ‘red’ when none of the distractors is red, and less so when a modifier (e.g., ‘light red’) would be required for disambiguation. Closer to our present discussion, we notice that the issue of discrimination as proposed in (Olson, 1970) has been considered by most REG algorithms to date (e.g., (Dale and Reiter, 1995; Krahmer and van Deemter, 2012)), and it has even motivated a number of greedy or minimally distinguishing REG strategies (Gardent, 2002; Dale, 2002; Areces et al., 2011). Interestingly, the work One of the first REG algorithms to take relations into account is the work in (Dale and Haddock, 1991), which generates descriptions that may include relational properties only as a last resort, that is, only when it is not possible to obtain a uniquely identifying descriptions by making use of a set of atomic properties. The algorithm prevents circularity (e.g., ‘the cup on the table that supports a cup that...’) and avoids the inclusion of redundant properties with the aid of consistency networks. As a result, the algorithm favours"
P15-2013,2007.mtsummit-ucnlg.14,0,0.0631703,"Missing"
P15-2013,P06-1131,0,0.185185,"ining p. In corpus-based REG, for instance, a plausible strategy would be to assume that the definition of p is domain-dependent, and simply select the most frequent (but still discriminatory) property in P0 as seen in training data. We will call this variation the Most Frequent overspecification strategy. Choosing the most frequent property p may lead to descriptions that closely resemble those observed in the data. However, we predict that Current work Following (Pechmann, 1989) and others, we may assume that colour should be generally (or perhaps always) preferred to size. Moreover, as in (Kelleher and Kruijff, 2006), we may follow the principle of minimal effort (Clark and Wilkes-Gibbs, 1986) and assume that atomic properties such as colour or size should be preferred to relations that lead to more complex descriptions. In our current work, however, we will argue that neither needs to be the case: under the right circumstances, a wide range of properties - colour, size and even spatial relations - may be overspecified depending on their discriminatory power alone. Thus, it may be the case that size is preferred to colour (unlike, e.g., (Pechmann, 1989)), and that longer, relational descriptions are prefe"
P15-2013,W09-0609,0,0.0269673,"os, near, right, left} For evaluation purposes we will make use the Stars2 corpus of referring expressions1 . Stars2 is an obvious choice for our experiment since these data convey visual scenes in which objects will usually have one highly discriminatory property available for reference. Moreover, descriptions in this domain may convey up to two relations (e.g., ‘the cone next to the ball, near the cone’), which gives rise to multiple opportunities for referential overspecification. In addition to this, we will also make use of the subset of relational descriptions available from the GRE3D3 (Dale and Viethen, 2009) and GRE3D7 (Viethen and Dale, 2011) corpora. Situations of reference in the GRE3D3/7 domain are in many ways simpler than those in Stars2 (i.e., by containing at most one possible relation in each scene, by not presenting any property whose discriminatory power is substantially higher than others etc.), In the case of the GRE3D3/7 corpora, we notice that not all attributes appear in both data sets. Moreover, the attributes hpos and vpos were computed from the existing pos attribute, which was originally intended to model both horizontal and vertical screen coordinates as a single property in"
P15-2013,J12-1006,0,0.0388884,"Missing"
P15-2013,J03-1003,0,0.140675,"Missing"
P15-2013,W06-1409,1,0.678905,"Missing"
P15-2013,W11-2702,0,0.0646409,"g which properties should be selected by a REG algorithm assuming that the decision to overspecify has already been made. More specifically, we will discuss whether the algorithm should include colour as in (b), size as in (c), or other alternatives, and we will assess the impact of a referential overspecification strategy that favours highly discriminatory properties over preferences that are well-established in the literature. Although this may in principle seem as a narrow research topic, the generation of relational descriptions is still subject of considerable debate in the field (e.g., (Viethen and Dale, 2011) and Introduction In Natural Language Generation (NLG) systems, Referring Expression Generation (REG) is the computational task of providing natural language descriptions of domain entities (Levelt, 1989; Dale and Reiter, 1995), as in ‘the second street on the left’, ‘the money that I found in the kitchen’ etc. In this paper we will focus on the issue of content selection of relational descriptions, that is, those in which the intended target is described via another object, hereby called a landmark. Consider the example of context in Fig. 1. Figure 1: A simple visual context. All objects are"
P15-2013,W13-2108,0,0.0130966,"can be either relational (when connecting two entities) or atomic (when forming self-loops). The task of obtaining a uniquely identifying description is implemented as a subgraph construction problem driven by domain-dependent cost functions associated with the decisions made by the algorithm. The work in (Krahmer et al., 2003) does not make specific assumptions about the actual attribute selection policy, and by varying the cost functions it is possible to implement a wide range of referential strategies. The use of the algorithm for the generation of relational descriptions is discussed in (Viethen et al., 2013). The work in (Paraboni et al., 2006) discusses the issue of ease of search by focussing on the particular case of relational description in hierarchicallyordered domains (e.g., books divided into sections and subsections etc.) Descriptions that may arguably make search difficult, as in ‘the section that contains a picture’ are prevented by producing fully-specified descriptions of each individual object (i.e., picture, section etc.). As in (Dale and Haddock, 1991), atomic properties are always attempted first, and each target (e.g., a subsection) holds only one relation (e.g., to its parent s"
P15-2013,P89-1009,0,\N,Missing
P98-2166,C96-1021,0,0.0540766,"Missing"
P98-2166,C94-2189,0,0.013445,"or each anaphor. 3. Factors in PPA resolution This section describes a minimal set of factors in PPA resolution, based on corpus investigation. These factors will be considered in place of traditional syntactic constraints, which are not suitable for our present problem, as shown in section 2. In our proposal, because of the structural complexity of sentences in the domain, we have adopted a practical approach, based on simple heuristic rules, with a view to avoiding syntactic and semantic analysis. Similar strategies have been adopted in several recent works in anaphor resolution, such as T. Nasukawa (1994), R. Mitkov (1996), R. Vieira & M. Poesio (1997) and others. We have defined 6 simple factors in PPA resolution (F 1 to F6) based on syntactic, semantic and pragmatic knowledge, aiming to determine PPAs antecedents in our specific domain. As a secondary goal, we apply our proposal also to PPAs in a different domain (see section 5). Factors, enunciated as heuristic rules, will act as constraints (F1 to F5) or preferences (F6), as established by J. Carbonell (1988). 3.1. Syntactic level Since typical syntactic constraints are not suitable for PPA resolution, in our approach we have limited the r"
P98-2166,C96-2158,0,0.031313,"Missing"
P98-2166,C88-1021,0,\N,Missing
P98-2166,P87-1022,0,\N,Missing
pereira-etal-2012-corpus,W08-1109,0,\N,Missing
pereira-etal-2012-corpus,W09-0629,0,\N,Missing
pereira-etal-2012-corpus,J07-2004,1,\N,Missing
pereira-etal-2012-corpus,J03-1003,0,\N,Missing
pereira-etal-2012-corpus,W06-1420,0,\N,Missing
pereira-etal-2012-corpus,2007.mtsummit-ucnlg.14,0,\N,Missing
R09-1042,J07-2004,1,0.800488,"the field, the Incremental algorithm in [2]) attempt to avoid the inclusion of any information not strictly necessary for the identification of the intended referent. Referring expressions produced in this way are suitably brief, but they may look unnaturally so. In extreme cases, certain instances of short descriptions may actually make the identification of the intended referent a daunting task. One such example is the case of deictic references in structurally-complex (e.g., spatial) domains. Deictic referents may be unidentifiable unless a certain amount of redundant information is added [3]. For example, a distinguishing description such as “the girl in white shoes” is not of much help if, say, the referred person is part of a large crowd. Redundancy in this case (e.g., “the girl in white shoes, next to the elevator”) may facilitate the resolution of these expression (here understood as the task of interpreting the referring expression and identifying the intend referent.) The implication of this for REG algorithms is that redundancy should be somehow taken into account at least when generating instances of space deixis, and this is precisely the kind of insight needed to design"
R09-1059,W07-2315,0,0.3395,"a generated document presents the required information in a reasonably coherent structure, then the system may be considered successful even if the text shows surface flaws or limited linguistic variation. On the other hand, if the required information is missing from the text, or if the text is poorly structured, then the overall results are most likely unsatisfactory regardless of how well the individual sentences were realised. When speaking of Data-to-Text generation1, Document Planning is often preceded by a Data 1 For a large-scale application of this kind, see [5]. Interpretation stage [2] that processes raw data application in the first place. In what follows, we discuss the early stages of a simple Data-to-Text NLG application addressing some aspects of both issues, namely, which chunks of information – or messages should be included in the generated text from the raw data provided by an underlying application, and how such messages should be structured within a standard RST framework [4]. We will argue that at least in simple NLG applications, some of these issues may be tackled using trainable and (at least partially) domainindependent methods. The focus of this paper is on"
R09-1059,2003.jeptalnrecital-long.23,0,0.0878427,"plication raw data by modelling the underlying semantics as content messages, SINotas does not convey the kind of low-level representation available from, e.g., the SUMTIMEMETEO corpus described in [8], which aligns text directly with domain data4. 3. Document Planning as Classification We will use the SINotas data-text aligned corpus described in the previous section to develop a number of modules of a simple corpus-based NLG system as a series of classifiers, using off-the-shelf learning algorithms. Serialised classifiers have been applied to other NLG tasks, e.g., surface realisation as in [9,10]5. Regarding related work in the field, we notice that the early stages of Document Planning (and particularly, Content Determination issues) seem to be somewhat misrepresented in the NLG literature, a gap that might be explained by the domain-dependent nature of the task (i.e., the dealing with raw application data.) Content Determination has been performed using statistical techniques in [11], followed by a machine learning approach to select relevant information. The same general principal is applied in [12] in the domain of American football matches, and taking contextual dependencies into"
R09-1059,W03-1016,0,0.0220504,"es of a simple corpus-based NLG system as a series of classifiers, using off-the-shelf learning algorithms. Serialised classifiers have been applied to other NLG tasks, e.g., surface realisation as in [9,10]5. Regarding related work in the field, we notice that the early stages of Document Planning (and particularly, Content Determination issues) seem to be somewhat misrepresented in the NLG literature, a gap that might be explained by the domain-dependent nature of the task (i.e., the dealing with raw application data.) Content Determination has been performed using statistical techniques in [11], followed by a machine learning approach to select relevant information. The same general principal is applied in [12] in the domain of American football matches, and taking contextual dependencies into account in a so-called ‘collective’ content selection approach. An extension of this work has been recently presented in [13] for the domain of cricket game with a novel alignment technique. In all these cases, the main focus is the automatic data-text alignment (which in our case was performed manually via corpus annotation) and they do not address our second subtask, Document Structuring. 3."
R09-1059,W09-0623,0,0.727144,"termination issues) seem to be somewhat misrepresented in the NLG literature, a gap that might be explained by the domain-dependent nature of the task (i.e., the dealing with raw application data.) Content Determination has been performed using statistical techniques in [11], followed by a machine learning approach to select relevant information. The same general principal is applied in [12] in the domain of American football matches, and taking contextual dependencies into account in a so-called ‘collective’ content selection approach. An extension of this work has been recently presented in [13] for the domain of cricket game with a novel alignment technique. In all these cases, the main focus is the automatic data-text alignment (which in our case was performed manually via corpus annotation) and they do not address our second subtask, Document Structuring. 3.1 Content Determination Content Determination can be viewed as the task of computing content messages (e.g., in the form of predicate-argument structures) from the input data provided by the underlying application. In our work this is implemented as a 2-steps process: first, we compute all possible messages derivable from the a"
R09-1059,H05-1042,0,\N,Missing
R09-1059,W03-2305,0,\N,Missing
R19-1024,W17-6615,0,0.0266659,"Missing"
R19-1024,P15-2136,0,0.0260935,"aulo, Brazil ivandre@usp.br Introduction Computational approaches to text summarization may be divided into two general categories: abstractive and extractive summarization. Extractive summarization consists of selecting relevant pieces of text to compose a subset of the original sentences, whereas the more complex abstractive summarization involves interpreting the input text and rewriting its main ideas in a new, shorter version. Both strategies may be modelled as a machine learning problem by making use of unsupervised (Ren et al., 2017), graph-based and neural methods (Wan and Yang, 2006; Cao et al., 2015), among others. The present work focuses on the issue of neural abstractive summarization, addressing the issue of personalized text generation in systems of this kind. Text-generating systems may in principle produce always the same fixed output from a given input representation. In order to generate more natural (or ‘human-like’) output, however, systems of 205 Proceedings of Recent Advances in Natural Language Processing, pages 205–212, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_024 RNN computes a sequence of outputs (y1 , ..., yt ) mapped onto sequences usin"
R19-1024,N18-1150,0,0.0150899,"anguage generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input sequence to a fixed-sized vector using a RNN, and then map the vector to the target sequence by using a second RNN. This may in principle be successful, but long term dependencies may make the training of the two networks difficult (Bengio et al., 1994; Hochreiter, 1998). As an alternative, Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), and their simplification known as Gated Recurrent Unit (GRU) (Cho et al., 2014) are known to learn problems with long range temporal dependencies, and may ther"
R19-1024,N03-1020,0,0.36472,"xt + W hh ht−1 ) yt = W yh ht Due to the capacity of neural language generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input sequence to a fixed-sized vector using a RNN, and then map the vector to the target sequence by using a second RNN. This may in principle be successful, but long term dependencies may make the training of the two networks difficult (Bengio et al., 1994; Hochreiter, 1998). As an alternative, Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), and their simplification known as Gated Recurrent Unit (GRU) (Cho et al., 2014) are known t"
R19-1024,D11-1035,0,0.0156088,"n neural sequence-tosequence text summarization. The model - consisting of two bidirectional GRUs, word embeddings and attention mechanism - was evaluated in two versions, namely, with and without an additional personality embedding layer. Initial results suggest that having access to personality information does lead to more accurate (or human-like) text summaries. The use of personality information is of course only one among many possible personalization 2 We are aware that, although popular in machine translation and text generation, BLEU may not be the ideal metrics for the present task (Liu et al., 2011; Song et al., 2013), and that it may not co-relate well with, e.g., human judgments (Reiter and Belz, 2009). 210 Table 5: Selected examples taken from the corpus, baseline (sBase) and personality-dependent (sPers) summarization models, grouped by distance (small, moderate or large) between sPers and the expected (corpus) summary in original Portuguese (Pt) and translated English (En). Error Model Summary (Pt) Summary (En) corpus homem na cerca man by fence small sBase homem idoso elderly man sPers homem na cerca man by fence corpus pessoas pedindo ajuda people asking for help moderate sBase p"
R19-1024,D15-1044,0,0.0445334,"ngs of Recent Advances in Natural Language Processing, pages 205–212, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_024 RNN computes a sequence of outputs (y1 , ..., yt ) mapped onto sequences using the following equation (Sundermeyer et al., 2012): reports two experiments comparing the proposed models against a number of alternatives, and Section 5 presents final remarks and future work. 2 Background ht = sigmoid(W hx xt + W hh ht−1 ) yt = W yh ht Due to the capacity of neural language generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input seque"
R19-1024,D15-1166,0,0.371841,"phrases and sentences. Bidirectional GRUs (Bi-GRUs) are applied to a wide range of tasks to scan and learn both leftto-right and right-to-left dependencies, which can capture complementary types of information from its inputs. The left and right hidden representations produced by GRUs can be linearly combined (θ) to form a final representation (Goodfel→ low et al., 2016): ht = h← t θ ht . 2.2 s1 = tanh(W (s) bm ) p(yj = w|x, y1:j−1 ) α exp(U [sj , cj ]) sj+1 = GRU ([φ(out) (yj ), cj ], sj ) where i  {1, ..., m}, j  {1, ..., m} and the context vector cj , is the result of general attention (Luong et al., 2015). The matrices W (s) , W (α) , U and the embedding function φ(out) are decoder parameters. Attention Mechanism Sequence-to-sequence architectures have been successfully applied to a wide range of tasks, including machine translation and natural text generation (Cho et al., 2014; Sutskever et al., 2014a) and, accordingly, have been subject to a great deal of extensions and improvements. Among these, the use of more context-aware sequence generation methods (Cho et al., 2014) and the use of attention mechanism to score and select words that best describe the intended output are discussed below."
R19-1024,P17-1099,0,0.0365143,"012): reports two experiments comparing the proposed models against a number of alternatives, and Section 5 presents final remarks and future work. 2 Background ht = sigmoid(W hx xt + W hh ht−1 ) yt = W yh ht Due to the capacity of neural language generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input sequence to a fixed-sized vector using a RNN, and then map the vector to the target sequence by using a second RNN. This may in principle be successful, but long term dependencies may make the training of the two networks difficult (Bengio et al., 1994; Hochreiter, 1998). As an"
R19-1024,P07-1063,0,0.055824,"e, and it is commonly associated with the rise of the Big Five model of human personality (Goldberg, 1990) in many related fields. The Big Five model is based on the assumption that differences in personality are reflected in natural language use, and comprises five fundamental dimensions of personality: Extraversion, Agreeableness, Conscientiousness, Neuroticism, and Openness to experience. Given its linguistic motivation, the Big Five personality traits have been addressed in a wide range of studies in both natural language understanding and generation alike. Thus, for instance, the work in Mairesse and Walker (2007) introduces PERSONAGE, a fully-functional NLG system that produces restaurant recommendations. PERSONAGE and many of its subsequent extensions support multiple stylistic variations that are controlled by personality information provided as an input. The use of personality information for text summarization, by contrast, seems to be far less common, and we are not aware of any existing work that addresses the issue of personality-dependent neural text summarization. Based on these observations, this paper introduces a personalitydependent text summarization model that makes use of a corpus of s"
R19-1024,N13-1090,0,0.00627313,"Processing, pages 205–212, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_024 RNN computes a sequence of outputs (y1 , ..., yt ) mapped onto sequences using the following equation (Sundermeyer et al., 2012): reports two experiments comparing the proposed models against a number of alternatives, and Section 5 presents final remarks and future work. 2 Background ht = sigmoid(W hx xt + W hh ht−1 ) yt = W yh ht Due to the capacity of neural language generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input sequence to a fixed-sized vector using a RNN, and th"
R19-1024,K16-1028,0,0.021486,"ces in Natural Language Processing, pages 205–212, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_024 RNN computes a sequence of outputs (y1 , ..., yt ) mapped onto sequences using the following equation (Sundermeyer et al., 2012): reports two experiments comparing the proposed models against a number of alternatives, and Section 5 presents final remarks and future work. 2 Background ht = sigmoid(W hx xt + W hh ht−1 ) yt = W yh ht Due to the capacity of neural language generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input sequence to a fixed-sized vec"
R19-1024,P02-1040,0,0.103702,"k. 2 Background ht = sigmoid(W hx xt + W hh ht−1 ) yt = W yh ht Due to the capacity of neural language generation models to learn and automatically induce representations from text (Rush et al., 2015; Nallapati et al., 2016; Mikolov et al., 2013), neural abstractive summarization has attracted a great deal of attention in the field. Architectures of this kind may not only produce high-quality summaries, but may also embed external information easily (See et al., 2017). Accordingly, these models have achieved significant results, at least in terms of intrinsic evaluation measures such as BLEU (Papineni et al., 2002) or ROUGE (Lin and Hovy, 2003), when comparing to extractive approaches (Celikyilmaz et al., 2018). 2.1 A simple strategy for general sequence learning is to map the input sequence to a fixed-sized vector using a RNN, and then map the vector to the target sequence by using a second RNN. This may in principle be successful, but long term dependencies may make the training of the two networks difficult (Bengio et al., 1994; Hochreiter, 1998). As an alternative, Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997), and their simplification known as Gated Recurrent Unit (GRU)"
R19-1024,N06-2046,0,0.0191897,"of S˜ao Paulo S˜ao Paulo, Brazil ivandre@usp.br Introduction Computational approaches to text summarization may be divided into two general categories: abstractive and extractive summarization. Extractive summarization consists of selecting relevant pieces of text to compose a subset of the original sentences, whereas the more complex abstractive summarization involves interpreting the input text and rewriting its main ideas in a new, shorter version. Both strategies may be modelled as a machine learning problem by making use of unsupervised (Ren et al., 2017), graph-based and neural methods (Wan and Yang, 2006; Cao et al., 2015), among others. The present work focuses on the issue of neural abstractive summarization, addressing the issue of personalized text generation in systems of this kind. Text-generating systems may in principle produce always the same fixed output from a given input representation. In order to generate more natural (or ‘human-like’) output, however, systems of 205 Proceedings of Recent Advances in Natural Language Processing, pages 205–212, Varna, Bulgaria, Sep 2–4, 2019. https://doi.org/10.26615/978-954-452-056-4_024 RNN computes a sequence of outputs (y1 , ..., yt ) mapped"
R19-1024,J09-4008,0,0.0238569,"d embeddings and attention mechanism - was evaluated in two versions, namely, with and without an additional personality embedding layer. Initial results suggest that having access to personality information does lead to more accurate (or human-like) text summaries. The use of personality information is of course only one among many possible personalization 2 We are aware that, although popular in machine translation and text generation, BLEU may not be the ideal metrics for the present task (Liu et al., 2011; Song et al., 2013), and that it may not co-relate well with, e.g., human judgments (Reiter and Belz, 2009). 210 Table 5: Selected examples taken from the corpus, baseline (sBase) and personality-dependent (sPers) summarization models, grouped by distance (small, moderate or large) between sPers and the expected (corpus) summary in original Portuguese (Pt) and translated English (En). Error Model Summary (Pt) Summary (En) corpus homem na cerca man by fence small sBase homem idoso elderly man sPers homem na cerca man by fence corpus pessoas pedindo ajuda people asking for help moderate sBase pessoas esperando people waiting sPers pessoas aguardam atendimento people waiting for help corpus menino com"
R19-1123,L16-1623,0,0.242554,"from text. 1 Introduction Computational sentiment analysis may be understood as a wide range of tasks intended to identify opinions, emotions and other types of stance expressed in natural language text (Tsytsarau and Palpanas, 2012; Liu, 2015). Among these, opinion mining is arguably the most well-studied form of sentiment analysis, consisting of identifying the target of an opinion, and/or the polarity (positive, negative, neutral etc.) of the sentiment expressed towards this target (Tsytsarau and Palpanas, 2012). Stance recognition (Anand et al., 2011; Hasan and Ng, 2013; Lai et al., 2016; Mohammad et al., 2016b; Zarrella and Marsh, 2016; Wei et al., 2016; Mohammad et al., 2017), by contrast, consists of deciding whether the author of a piece of text shows a favourable or unfavourable attitude (or position) towards a certain target (Mohammad et al., 2017). The distinction between sentiment and stance is motivated by the observation that a sentiment, regardless of being positive or negative, may reflect a favourable or unfavourable position towards the target (Mohammad et al., 2016b). For instance, given the target topic ’veganism’, a Ivandr´e Paraboni University of S˜ao Paulo S˜ao Paulo, Brazil ivan"
R19-1123,S16-1003,0,0.0448049,"Missing"
R19-1123,W11-1701,0,0.0354983,"e field of stance recognition and polarity classification from text. 1 Introduction Computational sentiment analysis may be understood as a wide range of tasks intended to identify opinions, emotions and other types of stance expressed in natural language text (Tsytsarau and Palpanas, 2012; Liu, 2015). Among these, opinion mining is arguably the most well-studied form of sentiment analysis, consisting of identifying the target of an opinion, and/or the polarity (positive, negative, neutral etc.) of the sentiment expressed towards this target (Tsytsarau and Palpanas, 2012). Stance recognition (Anand et al., 2011; Hasan and Ng, 2013; Lai et al., 2016; Mohammad et al., 2016b; Zarrella and Marsh, 2016; Wei et al., 2016; Mohammad et al., 2017), by contrast, consists of deciding whether the author of a piece of text shows a favourable or unfavourable attitude (or position) towards a certain target (Mohammad et al., 2017). The distinction between sentiment and stance is motivated by the observation that a sentiment, regardless of being positive or negative, may reflect a favourable or unfavourable position towards the target (Mohammad et al., 2016b). For instance, given the target topic ’veganism’, a Ivand"
R19-1123,W13-4829,0,0.501172,"Missing"
R19-1123,I13-1191,0,0.0159482,"cognition and polarity classification from text. 1 Introduction Computational sentiment analysis may be understood as a wide range of tasks intended to identify opinions, emotions and other types of stance expressed in natural language text (Tsytsarau and Palpanas, 2012; Liu, 2015). Among these, opinion mining is arguably the most well-studied form of sentiment analysis, consisting of identifying the target of an opinion, and/or the polarity (positive, negative, neutral etc.) of the sentiment expressed towards this target (Tsytsarau and Palpanas, 2012). Stance recognition (Anand et al., 2011; Hasan and Ng, 2013; Lai et al., 2016; Mohammad et al., 2016b; Zarrella and Marsh, 2016; Wei et al., 2016; Mohammad et al., 2017), by contrast, consists of deciding whether the author of a piece of text shows a favourable or unfavourable attitude (or position) towards a certain target (Mohammad et al., 2017). The distinction between sentiment and stance is motivated by the observation that a sentiment, regardless of being positive or negative, may reflect a favourable or unfavourable position towards the target (Mohammad et al., 2016b). For instance, given the target topic ’veganism’, a Ivandr´e Paraboni Univers"
R19-1123,S16-1062,0,0.0654799,"analysis may be understood as a wide range of tasks intended to identify opinions, emotions and other types of stance expressed in natural language text (Tsytsarau and Palpanas, 2012; Liu, 2015). Among these, opinion mining is arguably the most well-studied form of sentiment analysis, consisting of identifying the target of an opinion, and/or the polarity (positive, negative, neutral etc.) of the sentiment expressed towards this target (Tsytsarau and Palpanas, 2012). Stance recognition (Anand et al., 2011; Hasan and Ng, 2013; Lai et al., 2016; Mohammad et al., 2016b; Zarrella and Marsh, 2016; Wei et al., 2016; Mohammad et al., 2017), by contrast, consists of deciding whether the author of a piece of text shows a favourable or unfavourable attitude (or position) towards a certain target (Mohammad et al., 2017). The distinction between sentiment and stance is motivated by the observation that a sentiment, regardless of being positive or negative, may reflect a favourable or unfavourable position towards the target (Mohammad et al., 2016b). For instance, given the target topic ’veganism’, a Ivandr´e Paraboni University of S˜ao Paulo S˜ao Paulo, Brazil ivandre@usp.br sentence as in ‘beef tastes wonder"
R19-1123,S16-1074,0,0.111826,"n Computational sentiment analysis may be understood as a wide range of tasks intended to identify opinions, emotions and other types of stance expressed in natural language text (Tsytsarau and Palpanas, 2012; Liu, 2015). Among these, opinion mining is arguably the most well-studied form of sentiment analysis, consisting of identifying the target of an opinion, and/or the polarity (positive, negative, neutral etc.) of the sentiment expressed towards this target (Tsytsarau and Palpanas, 2012). Stance recognition (Anand et al., 2011; Hasan and Ng, 2013; Lai et al., 2016; Mohammad et al., 2016b; Zarrella and Marsh, 2016; Wei et al., 2016; Mohammad et al., 2017), by contrast, consists of deciding whether the author of a piece of text shows a favourable or unfavourable attitude (or position) towards a certain target (Mohammad et al., 2017). The distinction between sentiment and stance is motivated by the observation that a sentiment, regardless of being positive or negative, may reflect a favourable or unfavourable position towards the target (Mohammad et al., 2016b). For instance, given the target topic ’veganism’, a Ivandr´e Paraboni University of S˜ao Paulo S˜ao Paulo, Brazil ivandre@usp.br sentence as in ‘"
tadeu-etal-2010-extracting,A00-2023,0,\N,Missing
tadeu-etal-2010-extracting,W09-0613,0,\N,Missing
tadeu-etal-2010-extracting,W07-2315,0,\N,Missing
tadeu-etal-2010-extracting,P02-1040,0,\N,Missing
W02-2115,P89-1009,0,0.096073,"e the term ‘description’ loosely to refer to either the combination of properties or it linguistic realization. G RE algorithms take as their input a knowledge base that is shared between writer and reader, generating unique descriptions of entities whenever the knowledge base allows it (van Deemter 2002). These algorithms are designed in such a way that generation is made easy (i.e., quick). The implications for the reader, for example in terms of the difficulty of finding the referent, are never taken into account. Note that some algorithms do generate descriptions that are optimally brief (Dale 1989), while others approximate optimal brevity (Dale and Reiter 1995), and this can be argued to make interpretation easier. As we have seen, however, a short description can sometimes make search difficult. To illustrate, the Incremental Algorithm works roughly as follows. (See Dale and Reiter 1995 for details). Attributes represented in the shared Knowledge base are ordered in a linear preference ordering. The Attributes in the ordering are considered one by one, to see if any of their Values contributes something to the description, typically by removing ‘distractors’ (i.e., objects other than"
W02-2115,E91-1028,0,0.892772,"ally ordered (in sections, subsections, etc.), allowing us to picture it as a tree. Documents and the hierarchical relations that hold them together can be modelled in different ways. For present purposes, we stick with a simple Attribute/Value model.2 One Attribute, TYPE, says 2 At first sight, a Dale and Haddock-style modeling based on relational properties looks promising for the modeling of a hierarchy, but appearances are deceptive. Consider, for example, a description like ‘the vase on the table’, which can be said when there are many tables, as long as only one of them supports a vase (Dale and Haddock 1991). By comparison, if a document contains only two pictures, one of which occurs in the only Appendix, while the other occurs in one of the many what kind of entity it is (picture, table, section, subsection, part, etc.). Given its TYPE, the identity of the referent within its parent node can usually be determined by means of one other Attribute. For example, a picture might be identified by the property T YPE : P ICTURE and the property P ICTURE N UM BER : 3, the combination of which may be realized as ‘picture (iii)’. Often, of course, this will not be enough to identify the referent within th"
W02-2115,P00-1019,0,0.143147,"an entity is mentioned, disregarding anaphoric references (e.g., ‘it’). 2 Generating references that are easy to resolve Generation of Referring Expressions (GRE) is a key task of NLG systems (e.g., Reiter and Dale 2000, section 5.4). The task of a GRE algorithm is to find combinations of properties that allow the generator to refer uniquely to an entity, called the target of the algorithm, and to express these properties in a linguistic description. We will focus on the first part of the problem, which involves determining the semantic content of a description, paying no attention 1 Compare Jordan 2000, Jordan (forthcoming), where other factors triggering logically redundant material in referring expressions are explored. to linguistic realization (e.g., Malouf 2000). When there is no risk of confusion, we will use the term ‘description’ loosely to refer to either the combination of properties or it linguistic realization. G RE algorithms take as their input a knowledge base that is shared between writer and reader, generating unique descriptions of entities whenever the knowledge base allows it (van Deemter 2002). These algorithms are designed in such a way that generation is made easy (i."
W02-2115,P00-1012,0,0.0581529,"a key task of NLG systems (e.g., Reiter and Dale 2000, section 5.4). The task of a GRE algorithm is to find combinations of properties that allow the generator to refer uniquely to an entity, called the target of the algorithm, and to express these properties in a linguistic description. We will focus on the first part of the problem, which involves determining the semantic content of a description, paying no attention 1 Compare Jordan 2000, Jordan (forthcoming), where other factors triggering logically redundant material in referring expressions are explored. to linguistic realization (e.g., Malouf 2000). When there is no risk of confusion, we will use the term ‘description’ loosely to refer to either the combination of properties or it linguistic realization. G RE algorithms take as their input a knowledge base that is shared between writer and reader, generating unique descriptions of entities whenever the knowledge base allows it (van Deemter 2002). These algorithms are designed in such a way that generation is made easy (i.e., quick). The implications for the reader, for example in terms of the difficulty of finding the referent, are never taken into account. Note that some algorithms do"
W02-2115,J02-1003,1,\N,Missing
W06-1409,E91-1028,0,0.658701,"r can achieve the same knowledge. Many of our examples will be drawn from a simple model of a University campus, structured into buildings and rooms; the intended referent will often be a library located in one of the rooms. The location of the library is not known to the hearer, but it is known to the speaker. Each domain entity r will be University of Brighton Watts building Cockcroft building 2 Hierarchical domains Existing work on GRE tends to focus on fairly simple domains, dominated by one-place properties. When relations (i.e., two-place properties) are taken into account at all (e.g., Dale and Haddock 1991, Krahmer and Theune 2002), the motivating examples are kept so small that it is reasonable to assume that speaker and hearer know all the relevant facts in advance. Consequently, search is not much of an issue (i.e., resolution is easy): the hearer can identify the referent by simply intersecting the denotations of the properties in the description. While such simplifications permit the study of many aspects of reference, other aspects come to the fore when larger domains are considered. Interesting questions arise, for example, when a large domain is hierarchically ordered. We consider a dom"
W06-1409,C94-2182,0,0.316554,"xtually required. Uncertainty can arise, for example, if the hearer does not know about a property, or if she does not know whether it applies to the target referent. Our own work explores the need for overspecification in situations where each of the properties in question is unproblematic (i.e., certain) in principle, but where the reader has to make an effort to discover their extension (i.e., what objects are truthfully described by the property). We ask how a generator can use logically redundant information to reduce the search space within which a reader has to ‘find’ a referent. (Cf., Edmonds 1994 for a related set of problems.) A crucial question, in all such cases, is what knowledge is shared between speaker and hearer at utterance time. It will be convenient to start by focussing on the extreme case where, before the start of resolution, knows nothing about the domain. When the utterance is made, the hearer’s blindfold is removed, so to speak, and resolution can start. No similar assumption about the speaker is made: we assume that the speaker knows everything about the domain, and that he knows that the hearer can achieve the same knowledge. Many of our examples will be drawn from"
W06-1409,W05-1606,0,0.0450047,"s tend to be included when they fulfill one of a number of pragmatic functions, such as to indicate that a property is of particular importance to the speaker, or to highlight the speaker’s awareness that the referent has the property in question (Jordan 2000). However, redundancy has been built into GRE algorithms 55 Proceedings of the Fourth International Natural Language Generation Conference, pages 55–62, c Sydney, July 2006. 2006 Association for Computational Linguistics only to a very limited extent. Perhaps the most interesting account of overspecification so far is the one proposed by Horacek (2005), where logically redundant properties enter the descriptions generated when the combined certainty of other properties falls short of what is contextually required. Uncertainty can arise, for example, if the hearer does not know about a property, or if she does not know whether it applies to the target referent. Our own work explores the need for overspecification in situations where each of the properties in question is unproblematic (i.e., certain) in principle, but where the reader has to make an effort to discover their extension (i.e., what objects are truthfully described by the propert"
W06-1409,P00-1019,0,0.132789,"et) than (1b), but the additional material in (1a) makes resolution easier once interpretation is successfully completed. We explore how an GRE program should make use of logically redundant properties so as to simplify resolution (i.e., the identification of the referent). In corpus-based studies, it has been shown that logically redundant properties tend to be included when they fulfill one of a number of pragmatic functions, such as to indicate that a property is of particular importance to the speaker, or to highlight the speaker’s awareness that the referent has the property in question (Jordan 2000). However, redundancy has been built into GRE algorithms 55 Proceedings of the Fourth International Natural Language Generation Conference, pages 55–62, c Sydney, July 2006. 2006 Association for Computational Linguistics only to a very limited extent. Perhaps the most interesting account of overspecification so far is the one proposed by Horacek (2005), where logically redundant properties enter the descriptions generated when the combined certainty of other properties falls short of what is contextually required. Uncertainty can arise, for example, if the hearer does not know about a property"
W06-1409,W02-2115,1,0.93619,"Missing"
W08-1135,2007.mtsummit-ucnlg.17,0,\N,Missing
W08-1140,W07-2307,0,0.0421093,"Missing"
W08-1140,W06-1420,0,0.0482101,"Missing"
W09-0633,W08-1135,1,0.464849,"Paulo São Paulo - Brazil diego.si@usp.br Ivandré Paraboni University of São Paulo São Paulo - Brazil ivandre@usp.br attribute g such that g, if selected, would rule out all remaining distractors in the context. Abstract We present a follow-up of our previous frequency-based greedy attribute selection strategy. The current version takes into account also the instructions given to the participants of TUNA trials regarding the use of location information, showing an overall improvement on string-edit distance values driven by the results on the Furniture domain. 1 Introduction In previous work (Lucena & Paraboni, 2008) we presented a frequency-based greedy attribute selection strategy submitted to the TUNA Challenge 2008. Presently we further the issue by taking additional information into account namely, the trial condition information available from the TUNA data - and report improved results for string-edit distance as required for the 2009 competition. 2 Background In Lucena & Paraboni (2008) we presented a combined strategy based on attribute frequency and certain aspects of a greedy attribute selection strategy for referring expressions generation. A list P of attributes sorted by frequency is the cen"
W10-1617,P00-1059,0,0.0188303,"ity, as in the NP “You should enroll by the end of the month in which you are expected to complete your current assignment”, and not simply using those NPs found in the target corpus. The set of mappings from domain concepts to their dependency-trees (i.e., constituent templates) makes a dictionary of realizations in the application domain. As in related work in the field (e.g., Gatt & Reiter, 2009), we presently assume that the actual mappings are to be provided by the application. Concept-to-strings mappings are usually handcrafted, but may also be acquired automatically from corpora, as in Bangalore & Rambow (2000). For testing purposes, we have extracted 1,548 instances of concept-to-string mappings from the target corpus, being 1,298 mappings from agent/patient entities to descriptions, pronouns and proper names, and 250 mappings from actions to VPs, even though many of them will not be of practical use from the point of view of our intended application. 5 Surface Realization Using the template definitions from the previous section, we designed a simple corpus-based surface realization component for our ongoing project. Our surface realization module is currently able to accept as an input a template"
W10-1617,W08-1111,0,0.0325013,"Missing"
W10-1617,W00-0306,0,0.0268427,"agreement rules are required to modify the verb number as in (f). (d) [All students]agent [have submitted]action [their papers]patient (e) [Your teacher] agent [#have submitted]action [their papers]patient (f) [Your teacher] agent [has submitted]action [their papers]patient Table 2. An original example (d) reused with a new agent head value (e) and agreement (f). More complex or fine-grained dependencies (e.g., the anaphoric reference ‘their’ in Table 2 above) are not currently implemented. One possible approach to this is a standard generate-andselect approach to NLG as in Langkilde (2000), Oh & Rudnicky (2000) and others. More specifically, we may over-generate all possible realization alternatives and then use a statistical language model to select the most likely output. In our work we intend to apply a similar approach also to handle the lexical choice task, i.e., by selecting the most likely wording for each concept based on a language model. about students’ undergraduate projects) in order to deploy a fully functional application. Finally, template selection needs improvement to allow for a truly minimal input specification in an application-friendly fashion. With these tasks accomplished, we"
W10-1617,A00-2026,0,0.261312,"ction of syntactically-structured templates from a target corpus and Section 5 presents the current features of our template-based surface realization engine. Finally, Section 6 draws preliminary conclusions and describes ongoing work, and Section 7 hints at possible collaboration with the 126 wider NLP research community in Latin America and elsewhere. 2 Related work Mapping an application semantics to surface strings usually involves the use of surface realization grammars or similar resources, which can be either built manually (e.g., Bateman, 1997) or acquired automatically from a corpus (Ratnaparkhi, 2000; Zhong & Stent, 2005; DeVault et. al., 2008). The surface realization task proper can be divided into two relatively independent procedures: a domain-dependant mapping from the application semantics onto linguistic structures (including, e.g., lexical choice), and a language-oriented task of linearization. As pointed out in Gatt & Reiter (2009), most of the existing systems tend to perform both tasks, but in some cases they focus on the latter, assuming that all lexical choices and other domain-dependent decisions have already been made. This is the case for example of SimpleNLG (Gatt & Reite"
W10-1617,W07-2315,0,0.0253094,"of a first project of this kind, addressing the issue of surface realization for Brazilian Portuguese. Our approach, which may be particularly suitable to simpler NLG applications in which a domain corpus of the most likely output sentences happens to be available, is in principle adaptable to many closely-related languages, and paves the way to further NLG research focused on Romance languages in general. 1 Introduction Data-to-Text Natural Language Generation (NLG) systems produce text or speech from a given nonlinguistic input. Systems of this kind usually follow a pipelined architecture (Reiter, 2007) comprising data interpretation, document planning, sentence planning and surface realization tasks. In this work we discuss the latter, that is, the task of producing surface word strings from a nonlinguistic input specification. Existing approaches to surface realization may vary greatly in their input requirements and, consequently, in the level of control over the output text. On the one hand, more sophisticated, grammar-based surface realization systems such as KPML (Bateman, 1997) allow maximum flexibility and productive coverage. These advantages, however, are only useful if the underly"
W10-1617,2003.jeptalnrecital-long.23,0,0.0533301,"Missing"
W10-1617,A00-2023,0,\N,Missing
W10-1617,W09-0613,0,\N,Missing
W10-1617,J05-1002,0,\N,Missing
W13-4810,2007.mtsummit-ucnlg.14,0,0.32208,"R) e´ um dos componentes fundamentais de aplicac¸o˜ es de gerac¸a˜ o de l´ıngua natural (GLN) a partir de dados de entrada n˜ao lingu´ısticos. Algoritmos de GER tratam da tarefa de selec¸a˜ o do conte´udo a ser realizado, por exemplo, na forma de descric¸o˜ es definidas como ‘o terceiro homem a` esquerda, vestido de preto’.1 O problema computacional de GER contempla, entre outras quest˜oes, o desafio de produzir descric¸o˜ es breves e psicologicamente plaus´ıveis. GER e´ uma ativa linha de pesquisa em GLN, tendo sido inclusive objeto de uma s´erie de competic¸o˜ es (ou shared tasks) recentes [Belz and Gatt 2007, Gatt et al. 2008, Gatt et al. 2009]. Abordagens existentes, entretanto, tendem a considerar principalmente dom´ınios simplificados e/ou bidimensionais. O problema de referˆencia em dom´ınios f´ısicos mais realistas (e.g., com grande complexidade estrutural, tridimensionalidade etc.) permanece pouco explorado na pesquisa da a´ rea, possivelmente em virtude da pr´opria dificuldade em criar bons modelos computacionais deste tipo. Mais recentemente, entretanto, este cen´ario comec¸ou a mudar com iniciativas como o projeto GIVE (Generating Instructions in Virtual Environments) [Koller et al. 2009"
W13-4810,W09-0628,0,0.01926,"l da a´ rea de GER e seus principais desafios e´ apresentada em [Krahmer and van Deemter 2012]. Na proposta original, o algoritmo Incremental manipula apenas propriedades atˆomicas, mas com adaptac¸o˜ es a serem discutidas na sec¸a˜ o 4.2 pode tamb´em ser aplicado ao caso de propriedades relacionais. Esta modificac¸a˜ o e´ de especial importˆancia para o uso de relac¸o˜ es espaciais de que trata este trabalho, como em (acima,o), no qual o e´ um objeto usado como ponto de referˆencia para a descric¸a˜ o do objeto-alvo r. Alguns sistemas participantes da s´erie de competic¸o˜ es GIVE Challenge [Byron et al. 2009, Koller et al. 2010, Striegnitz et al. 2011] implementam certos recursos de manipulac¸a˜ o de relac¸o˜ es espaciais, ainda que de forma pouco documentada (e.g., [Braunias et al. 2010, Schutte and Dethlefs 2010, Garoufi and Koller 2011, Akkersdijk et al. 2011]). Entretanto, como estes sistemas foram avaliados apenas de forma extr´ınseca (i.e., medindo-se o desempenho global de usu´arios GIVE na tarefa de navegac¸a˜ o) n˜ao e´ poss´ıvel distinguir o eventual impacto do uso de relac¸o˜ es espaciais das outras funcionalidades de cada sistema, as quais incluem, por exemplo, um grande n´umero de me"
W13-4810,gargett-etal-2010-give,0,0.0642312,"10, Schutte and Dethlefs 2010, Garoufi and Koller 2011, Akkersdijk et al. 2011]). Entretanto, como estes sistemas foram avaliados apenas de forma extr´ınseca (i.e., medindo-se o desempenho global de usu´arios GIVE na tarefa de navegac¸a˜ o) n˜ao e´ poss´ıvel distinguir o eventual impacto do uso de relac¸o˜ es espaciais das outras funcionalidades de cada sistema, as quais incluem, por exemplo, um grande n´umero de melhorias n˜ao relacionadas a` tarefa de GER. 3. Extrac¸a˜ o e preparac¸a˜ o de dados O algoritmo proposto neste trabalho faz uso de dados de treinamento extra´ıdos do corpus GIVE-2 [Gargett et al. 2010]. A preparac¸a˜ o deste conjunto de dados, bem como do conjunto de teste considerado na avaliac¸a˜ o da proposta (sec¸a˜ o 5), s˜ao discutidas a seguir. 3.1. Extrac¸a˜ o de atributos espaciais do dom´ınio Objetos em um ambiente GIVE [Koller et al. 2009] possuem apenas uma propriedade atˆomica b´asica representando seu tipo (bot˜oes, portas, cadeiras etc.) e, no caso dos bot˜oes, 90 uma propriedade cor. O primeiro passo deste trabalho foi assim a implementac¸a˜ o de um conjunto de m´etodos b´asicos para computar atributos espaciais de diversos tipos em ambientes do tipo GIVE [Koller et al. 200"
W13-4810,W11-2851,0,0.0118312,"¸a˜ o 4.2 pode tamb´em ser aplicado ao caso de propriedades relacionais. Esta modificac¸a˜ o e´ de especial importˆancia para o uso de relac¸o˜ es espaciais de que trata este trabalho, como em (acima,o), no qual o e´ um objeto usado como ponto de referˆencia para a descric¸a˜ o do objeto-alvo r. Alguns sistemas participantes da s´erie de competic¸o˜ es GIVE Challenge [Byron et al. 2009, Koller et al. 2010, Striegnitz et al. 2011] implementam certos recursos de manipulac¸a˜ o de relac¸o˜ es espaciais, ainda que de forma pouco documentada (e.g., [Braunias et al. 2010, Schutte and Dethlefs 2010, Garoufi and Koller 2011, Akkersdijk et al. 2011]). Entretanto, como estes sistemas foram avaliados apenas de forma extr´ınseca (i.e., medindo-se o desempenho global de usu´arios GIVE na tarefa de navegac¸a˜ o) n˜ao e´ poss´ıvel distinguir o eventual impacto do uso de relac¸o˜ es espaciais das outras funcionalidades de cada sistema, as quais incluem, por exemplo, um grande n´umero de melhorias n˜ao relacionadas a` tarefa de GER. 3. Extrac¸a˜ o e preparac¸a˜ o de dados O algoritmo proposto neste trabalho faz uso de dados de treinamento extra´ıdos do corpus GIVE-2 [Gargett et al. 2010]. A preparac¸a˜ o deste conjunto d"
W13-4810,W08-1131,0,0.015542,"ntes fundamentais de aplicac¸o˜ es de gerac¸a˜ o de l´ıngua natural (GLN) a partir de dados de entrada n˜ao lingu´ısticos. Algoritmos de GER tratam da tarefa de selec¸a˜ o do conte´udo a ser realizado, por exemplo, na forma de descric¸o˜ es definidas como ‘o terceiro homem a` esquerda, vestido de preto’.1 O problema computacional de GER contempla, entre outras quest˜oes, o desafio de produzir descric¸o˜ es breves e psicologicamente plaus´ıveis. GER e´ uma ativa linha de pesquisa em GLN, tendo sido inclusive objeto de uma s´erie de competic¸o˜ es (ou shared tasks) recentes [Belz and Gatt 2007, Gatt et al. 2008, Gatt et al. 2009]. Abordagens existentes, entretanto, tendem a considerar principalmente dom´ınios simplificados e/ou bidimensionais. O problema de referˆencia em dom´ınios f´ısicos mais realistas (e.g., com grande complexidade estrutural, tridimensionalidade etc.) permanece pouco explorado na pesquisa da a´ rea, possivelmente em virtude da pr´opria dificuldade em criar bons modelos computacionais deste tipo. Mais recentemente, entretanto, este cen´ario comec¸ou a mudar com iniciativas como o projeto GIVE (Generating Instructions in Virtual Environments) [Koller et al. 2009]. GIVE e´ uma pla"
W13-4810,W09-0629,0,0.0134623,"de aplicac¸o˜ es de gerac¸a˜ o de l´ıngua natural (GLN) a partir de dados de entrada n˜ao lingu´ısticos. Algoritmos de GER tratam da tarefa de selec¸a˜ o do conte´udo a ser realizado, por exemplo, na forma de descric¸o˜ es definidas como ‘o terceiro homem a` esquerda, vestido de preto’.1 O problema computacional de GER contempla, entre outras quest˜oes, o desafio de produzir descric¸o˜ es breves e psicologicamente plaus´ıveis. GER e´ uma ativa linha de pesquisa em GLN, tendo sido inclusive objeto de uma s´erie de competic¸o˜ es (ou shared tasks) recentes [Belz and Gatt 2007, Gatt et al. 2008, Gatt et al. 2009]. Abordagens existentes, entretanto, tendem a considerar principalmente dom´ınios simplificados e/ou bidimensionais. O problema de referˆencia em dom´ınios f´ısicos mais realistas (e.g., com grande complexidade estrutural, tridimensionalidade etc.) permanece pouco explorado na pesquisa da a´ rea, possivelmente em virtude da pr´opria dificuldade em criar bons modelos computacionais deste tipo. Mais recentemente, entretanto, este cen´ario comec¸ou a mudar com iniciativas como o projeto GIVE (Generating Instructions in Virtual Environments) [Koller et al. 2009]. GIVE e´ uma plataforma para desen"
W13-4810,J09-2005,0,0.0144615,"2009] possuem apenas uma propriedade atˆomica b´asica representando seu tipo (bot˜oes, portas, cadeiras etc.) e, no caso dos bot˜oes, 90 uma propriedade cor. O primeiro passo deste trabalho foi assim a implementac¸a˜ o de um conjunto de m´etodos b´asicos para computar atributos espaciais de diversos tipos em ambientes do tipo GIVE [Koller et al. 2009]. Os atributos relacionais computados para um dado objeto-alvo r e ponto de referˆencia o s˜ao: acima(o), abaixo(o), esquerda(o), direita(o), frente(o) e atr´as(o). Para extrac¸a˜ o destas relac¸o˜ es, foram utilizadas as func¸o˜ es propostas em [Kelleher and Costello 2009], baseadas na posic¸a˜ o angular de um objeto em relac¸a˜ o ao outro no plano cartesiano. O algoritmo de extrac¸a˜ o de atributos espaciais utiliza uma constante de distˆancia m´axima k u´ nica para cada tipo de relac¸a˜ o. A posic¸a˜ o f´ısica das entidades no ambiente GIVE e´ definida pela coordenada de seu ponto central, e assim entidades maiores como sof´as, portas etc. possuem um ponto central mais distante das bordas. Uma entidade est´a pr´oxima de outra entidade se a diferenc¸a entre os valores para os eixos x, y e z e´ no m´aximo k. Se esta condic¸a˜ o for verdadeira, considera-se que"
W13-4810,E09-2009,0,0.0813948,"Belz and Gatt 2007, Gatt et al. 2008, Gatt et al. 2009]. Abordagens existentes, entretanto, tendem a considerar principalmente dom´ınios simplificados e/ou bidimensionais. O problema de referˆencia em dom´ınios f´ısicos mais realistas (e.g., com grande complexidade estrutural, tridimensionalidade etc.) permanece pouco explorado na pesquisa da a´ rea, possivelmente em virtude da pr´opria dificuldade em criar bons modelos computacionais deste tipo. Mais recentemente, entretanto, este cen´ario comec¸ou a mudar com iniciativas como o projeto GIVE (Generating Instructions in Virtual Environments) [Koller et al. 2009]. GIVE e´ uma plataforma para desenvolvimento e teste de sistemas de GLN em mundos virtuais interativos, na qual o sistema encarrega-se de todo gerenciamento do ambiente gr´afico e de interatividade, permitindo ao desenvolvedor concentrar-se apenas na tarefa de GLN e produzir rapidamente uma aplicac¸a˜ o de teste. A figura 1 ilustra a interface deste sistema.2 1 N˜ao tratando portanto da quest˜ao da interpretac¸a˜ o (e.g., anaf´orica) de express˜oes existentes [Paraboni 1997, Cuevas and Paraboni 2008]. 2 Extra´ıda de http://www.give-challenge.org/research/ 88 Proceedings of the 9th Brazilian"
W13-4810,W10-4233,0,0.0126751,"e seus principais desafios e´ apresentada em [Krahmer and van Deemter 2012]. Na proposta original, o algoritmo Incremental manipula apenas propriedades atˆomicas, mas com adaptac¸o˜ es a serem discutidas na sec¸a˜ o 4.2 pode tamb´em ser aplicado ao caso de propriedades relacionais. Esta modificac¸a˜ o e´ de especial importˆancia para o uso de relac¸o˜ es espaciais de que trata este trabalho, como em (acima,o), no qual o e´ um objeto usado como ponto de referˆencia para a descric¸a˜ o do objeto-alvo r. Alguns sistemas participantes da s´erie de competic¸o˜ es GIVE Challenge [Byron et al. 2009, Koller et al. 2010, Striegnitz et al. 2011] implementam certos recursos de manipulac¸a˜ o de relac¸o˜ es espaciais, ainda que de forma pouco documentada (e.g., [Braunias et al. 2010, Schutte and Dethlefs 2010, Garoufi and Koller 2011, Akkersdijk et al. 2011]). Entretanto, como estes sistemas foram avaliados apenas de forma extr´ınseca (i.e., medindo-se o desempenho global de usu´arios GIVE na tarefa de navegac¸a˜ o) n˜ao e´ poss´ıvel distinguir o eventual impacto do uso de relac¸o˜ es espaciais das outras funcionalidades de cada sistema, as quais incluem, por exemplo, um grande n´umero de melhorias n˜ao relacio"
W13-4810,J12-1006,0,0.0236862,"Missing"
W13-4810,W06-1409,1,0.852397,"Missing"
W13-4810,passonneau-2006-measuring,0,0.016658,"mos, resultando assim em 8 conjuntos de express˜oes de referˆencia aqui denominados conjuntos Sistema 1..8. A avaliac¸a˜ o propriamente dita consistiu em comparar cada conjunto Sistema 1..8 com o conjunto Referˆencia. Para a comparac¸a˜ o de cada um dos (8 ∗ 198 = 1584 ) pares SistemaReferˆencia, utilizamos duas m´etricas amplamente empregadas em trabalhos da a´ rea como [Belz and Gatt 2007, de Lucena et al. 2010]: o coeficiente Dice [Dice 1945], que mede o grau de similaridade entre os dois conjuntos de propriedades, assumindo um valor entre 0 (totalmente distintos) e 1 (idˆenticos); e MASI [Passonneau 2006], que possui correlac¸a˜ o desambiguac¸a˜ o como em ‘o livro sobre a mesa’. 94 com Dice, por´em atribuindo maior peso no caso de uma express˜ao ser subconjunto da outra. Os 8 algoritmos e seus resultados s˜ao sumarizados na tabela 2. O algoritmo originalmente proposto e´ o primeiro (#1). # 1 2 3 4 5 6 7 8 Selec¸a˜ o mais frequente mais frequente mais frequente mais frequente aleat´oria aleat´oria aleat´oria aleat´oria Tabela 2. Resultados Ordenac¸a˜ o Redundˆancia por frequˆencia n˜ao por frequˆencia sim gulosa n˜ao gulosa sim por frequˆencia n˜ao por frequˆencia sim gulosa n˜ao gulosa sim Di"
W13-4810,W11-2845,0,0.011691,"safios e´ apresentada em [Krahmer and van Deemter 2012]. Na proposta original, o algoritmo Incremental manipula apenas propriedades atˆomicas, mas com adaptac¸o˜ es a serem discutidas na sec¸a˜ o 4.2 pode tamb´em ser aplicado ao caso de propriedades relacionais. Esta modificac¸a˜ o e´ de especial importˆancia para o uso de relac¸o˜ es espaciais de que trata este trabalho, como em (acima,o), no qual o e´ um objeto usado como ponto de referˆencia para a descric¸a˜ o do objeto-alvo r. Alguns sistemas participantes da s´erie de competic¸o˜ es GIVE Challenge [Byron et al. 2009, Koller et al. 2010, Striegnitz et al. 2011] implementam certos recursos de manipulac¸a˜ o de relac¸o˜ es espaciais, ainda que de forma pouco documentada (e.g., [Braunias et al. 2010, Schutte and Dethlefs 2010, Garoufi and Koller 2011, Akkersdijk et al. 2011]). Entretanto, como estes sistemas foram avaliados apenas de forma extr´ınseca (i.e., medindo-se o desempenho global de usu´arios GIVE na tarefa de navegac¸a˜ o) n˜ao e´ poss´ıvel distinguir o eventual impacto do uso de relac¸o˜ es espaciais das outras funcionalidades de cada sistema, as quais incluem, por exemplo, um grande n´umero de melhorias n˜ao relacionadas a` tarefa de GER."
W13-4816,W11-2832,0,0.0162539,"veis: voz ativa, voz passiva, imperativo e sujeito oculto. Um exemplo de gerac¸a˜ o de ‘As lindas crianc¸as da escola est˜ao sorrindo alegremente’ e´ apresentado a seguir. vozAtiva f rase = new vozAtiva(); f rase.setSN1(sn1 ); f rase.setSN2(sn2 ); f rase.setSV(sv); ´ 2.2. Gerac¸a˜ o a partir de Arvore Subespecificada A segunda modalidade de uso do sistema proposto e´ adequada para situac¸o˜ es nas quais a informac¸a˜ o a ser gerada j´a se encontra parcialmente dispon´ıvel em forma textual. Problemas desta natureza, chamados de gerac¸a˜ o Texto-para-Texto, tˆem sido abordados, por exemplo, em [Belz et al. 2011], e possuem aplicac¸o˜ es em a´ reas como simplificac¸a˜ o textual [Aluisio et al. 2008], traduc¸a˜ o autom´atica [Aziz et al. 2008, Aziz et al. 2009] e outras. ´ Na gerac¸a˜ o a partir de Arvore Subespecificada, o sistema recebe como entrada uma a´ rvore da sentenc¸a a ser gerada e invoca de forma autˆonoma todos os m´etodos que se fac¸am necess´arios para impor concordˆancia e linearizac¸a˜ o da sentenc¸a. Esta especificac¸a˜ o pode ser incompleta, e o resultado obtido e´ assim apenas uma aproximac¸a˜ o baseada em regras de linearizac¸a˜ o simples, o que pode nem sempre corresponder a` orde"
W13-4816,N03-2002,0,0.0228333,"icativa segundo o teste de chi-quadrada sob os valores de acur´acia (χ2 = 8, 62, df = 1, p < 0, 0033). 4. Considerac¸o˜ es Este artigo apresentou um sistema de realizac¸a˜ o superficial baseado em regras para o Portuguˆes brasileiro. Os resultados superam os obtidos com uso de modelos de n-gramas padr˜ao, sugerindo uma soluc¸a˜ o de baixo custo para o problema, aos moldes do sistema existente para a l´ıngua inglesa [Gatt and Reiter 2009]. Por outro lado, os resultados apresentados ainda s˜ao inferiores aos observados em estudos mais recentes com modelos estat´ısticos ditos fatorados, ou FLMs [Bilmes and Kirchhoff 2003] utilizados em [de Novais and Paraboni 2012]. Sistemas estat´ısticos, entretanto, possuem um custo computacional elevado. O uso de FLMs como discutido em [de Novais and Paraboni 2012], por exemplo, pode n˜ao ser vi´avel em aplicac¸o˜ es de gerac¸a˜ o de l´ıngua natural em tempo real. A abordagem baseada em regras, por outro lado, n˜ao sofre destas limitac¸o˜ es. Como trabalho futuro, o presente prot´otipo ser´a documentado e expandido na forma de um sistema completo para uso de pesquisadores interessada no processamento da l´ıngua portuguesa. Agradecimentos Este trabalho contou com apoio FAPE"
W13-4816,A00-2023,0,0.0854671,"Missing"
W13-4816,P00-1012,0,0.0532583,"sar dados n˜ao lingu´ısticos em formato textual. 2. O Sistema Proposto O presente trabalho pode ser visto como um equivalente para l´ıngua portuguesa do sistema SimpleNLG [Gatt and Reiter 2009] para o inglˆes. Seguindo [Gatt and Reiter 2009], enfocamos apenas o problema da realizac¸a˜ o superficial operacional2 , pressupondo que a escolha lexical e a selec¸a˜ o da estrutura da frase j´a tenham sido decididas. Restam assim as tarefas de completar as informac¸o˜ es de entrada (se esta for subespecificada), estabelecer a concordˆancia entre os termos da sentenc¸a e escolher a ordem linear destes[Malouf 2000, Mitchell 2009]. Assim como em [Gatt and Reiter 2009], o presente trabalho e´ disponibilizado na forma de uma biblioteca de m´etodos JAVA para construc¸a˜ o de sentenc¸as. Esta biblioteca foi projetada para ser inserida no c´odigo da aplicac¸a˜ o subjacente e, em ambos os sistemas, exige um certo grau de conhecimento de programac¸a˜ o para sua utilizac¸a˜ o. 1 Ou seja, ao contr´ario da tarefa de interpretac¸a˜ o de l´ıngua natural [Cuevas and Paraboni 2008]. Problemas de gerac¸a˜ o de textos em portuguˆes com base em conhecimento profundo s˜ao abordados em [Paraboni 2003, Paraboni et al. 2006"
W13-4816,W09-0608,0,0.0132648,"o lingu´ısticos em formato textual. 2. O Sistema Proposto O presente trabalho pode ser visto como um equivalente para l´ıngua portuguesa do sistema SimpleNLG [Gatt and Reiter 2009] para o inglˆes. Seguindo [Gatt and Reiter 2009], enfocamos apenas o problema da realizac¸a˜ o superficial operacional2 , pressupondo que a escolha lexical e a selec¸a˜ o da estrutura da frase j´a tenham sido decididas. Restam assim as tarefas de completar as informac¸o˜ es de entrada (se esta for subespecificada), estabelecer a concordˆancia entre os termos da sentenc¸a e escolher a ordem linear destes[Malouf 2000, Mitchell 2009]. Assim como em [Gatt and Reiter 2009], o presente trabalho e´ disponibilizado na forma de uma biblioteca de m´etodos JAVA para construc¸a˜ o de sentenc¸as. Esta biblioteca foi projetada para ser inserida no c´odigo da aplicac¸a˜ o subjacente e, em ambos os sistemas, exige um certo grau de conhecimento de programac¸a˜ o para sua utilizac¸a˜ o. 1 Ou seja, ao contr´ario da tarefa de interpretac¸a˜ o de l´ıngua natural [Cuevas and Paraboni 2008]. Problemas de gerac¸a˜ o de textos em portuguˆes com base em conhecimento profundo s˜ao abordados em [Paraboni 2003, Paraboni et al. 2006, de Lucena et"
W13-4816,W06-1409,1,0.754591,"Missing"
W13-4816,W07-2315,0,0.0207374,"nctions, and it has been applied to the generation of newspapers headlines. Resumo. Este trabalho apresenta um sistema de realizac¸a˜ o superficial para o Portuguˆes brasileiro. O sistema e´ apresentado na forma de uma biblioteca de func¸o˜ es, e aplicado a` tarefa de gerac¸a˜ o de manchetes de jornal. 1. Introduc¸a˜ o Em sistemas de gerac¸a˜ o de l´ıngua natural (GLN), a realizac¸a˜ o superficial e´ a tarefa computacional de mapear uma representac¸a˜ o abstrata do texto - frequentemente j´a contendo algum tipo de informac¸a˜ o estrutural - para uma representac¸a˜ o linear em l´ıngua natural [Reiter 2007]. A entrada de um m´odulo de realizac¸a˜ o textual e´ algum tipo de especificac¸a˜ o abstrata da sentenc¸a, e a sa´ıda e´ um string em l´ıngua natural.1 Este trabalho enfoca a implementac¸a˜ o e avaliac¸a˜ o de um prot´otipo de sistema de realizac¸a˜ o superficial para o Portuguˆes brasileiro. O sistema proposto e´ apresentado na forma de uma biblioteca de m´etodos de gerac¸a˜ o de sintagmas e sentenc¸as completas, os quais podem ser acoplados a uma aplicac¸a˜ o subjacente que necessite expressar dados n˜ao lingu´ısticos em formato textual. 2. O Sistema Proposto O presente trabalho pode ser v"
W13-4824,P12-3009,0,0.215775,"participac¸a˜ o em uma competic¸a˜ o da a´ rea. 1. Introduc¸a˜ o Com o avanc¸o em a´ reas da ciˆencia da computac¸a˜ o como processamento gr´afico e interac¸a˜ o humano-computador, problemas de gerac¸a˜ o de l´ıngua natural (GLN) puramente textuais encontraram dom´ınios mais realistas - e efetivamente novas aplicac¸o˜ es - em diversas a´ reas que utilizam sistemas baseados em mundos virtuais interativos. Dentre estas aplicac¸o˜ es, destacamos a gerac¸a˜ o de instruc¸o˜ es de navegac¸a˜ o em l´ıngua natural em ambientes como Gruve (Giving Route instructions in Uncertain Virtual Environments) [Janarthanam et al. 2012] ilustrado na Figura 1. A gerac¸a˜ o de instruc¸o˜ es em ambientes virtuais consiste na tarefa computacional de produzir sentenc¸as na forma verbal ou escrita para guiar um usu´ario de um ponto de origem at´e um ponto de destino. A tarefa apresenta uma ampla gama de desafios computacionais ainda pouco explorados, como a incerteza inerente aos dados de entrada1 , a quest˜ao da granularidade da instruc¸a˜ o gerada, a natureza dinˆamica da aplicac¸a˜ o (que requer que instruc¸o˜ es sejam reformuladas em tempo de execuc¸a˜ o), o tratamento do hist´orico de navegac¸a˜ o e conhecimento pr´evio do d"
W13-4824,W06-1409,1,0.672891,"Missing"
W17-3536,W08-1132,0,0.359625,"d of content selection task, hereby called REG for brevity. Existing work in computational REG and related fields have identified a wide range of factors that may drive content selection. To a considerable extent, however, content selection is known to be influenced by human variation (Viethen and Dale, 2010). In other words, under identical circumstances (i.e., in the same referential context), different speakers will often produce different descriptions, and a single entity may be described by different speakers as ‘the racing driver’, ‘the McLaren pilot’, etc. Existing REG algorithms as in Bohnet (2008) and Ferreira and Paraboni (2014) usually pay regard to human variation by computing personalised features from a training set of descriptions produced by each speaker. This highly personalised training method may of course be considered an ideal account of human variation but, in practice, will only be effective if every speaker in the domain is represented by a sufficiently large number of training instances. As means to improve REG results when the amount of training data is limited, in this work we propose a simple training method for speakerdependent REG in which training referring expres"
W17-3536,P02-1012,0,0.0821343,"hows that the use of speaker’s profiles generally outperforms the personalised method found in previous work. 1 Introduction In natural language generation systems, referring expression generation (REG) is the microplanning task responsible for generating references of discourse entities (Krahmer and van Deemter, 2012). Choice of referential form (Ferreira et al., 2016), i.e., deciding whether a reference should be a proper name (‘Ayrton Senna’), a pronoun (‘He’) or a description (‘The racing driver’), is the first decision to be made in this task. Albeit notable studies on pronominalisation (Callaway and Lester, 2002) and proper name generation (Ferreira et al., 2017), research on REG has largely focused on the generation of descriptions or, more specifically, on content selection. For instance, in the previous example, Ayrton Senna’s occupation is the content selected to describe him. This work focuses on this kind of content selection task, hereby called REG for brevity. Existing work in computational REG and related fields have identified a wide range of factors that may drive content selection. To a considerable extent, however, content selection is known to be influenced by human variation (Viethen an"
W17-3536,W09-0609,0,0.157081,"accounted for by computing individual preference lists based on the attribute frequency of each speaker as observed in the training data. In the case of Full Brevity, all possible descriptions for a given referent are computed, and the description that most closely resembles those produced by the speaker is selected using a nearest neighbour approach. The work in Viethen and Dale (2010) makes use of decision-tree induction to predict content patterns (i.e., full attribute sets representing actual referring expressions) to describe geometric objects on Google SketchUp scenes (GRE3D3/7 corpus) (Dale and Viethen, 2009; Viethen and Dale, 2011). Human variation is accounted for by modelling speaker identifiers as machine learning features. Finally, the work in Ferreira and Paraboni (2014) presents a SVM-based approach to speakerdependent REG tested also on the description of geometric objects (GRE3D3/7 and Stars/Stars2 (Teixeira et al., 2014; Paraboni et al., 2016) corpora). Once again, human variation is accounted for by computing individual preference lists from the subset of descriptions produced by each speaker. 3 Current work In all the studies discussed in the previous section, personalised REG outperf"
W17-3536,P89-1009,0,0.455855,"ation, and it is shown to outperform the use of personalised information. 2 Related Work Existing methods for speaker-dependent REG generally consist of computing the relevant features for each speaker. In what follows we summarise a number of studies that follow this method. In Bohnet (2008), the Incremental algorithm (Dale and Reiter, 233 Proceedings of The 10th International Natural Language Generation conference, pages 233–237, c Santiago de Compostela, Spain, September 4-7 2017. 2017 Association for Computational Linguistics 1995) and a number of extensions of the Full Brevity algorithm (Dale, 1989) are evaluated on a corpus of furniture items and famous mathematicians (TUNA) (Gatt et al., 2007). In the case of the Incremental algorithm, human variation is accounted for by computing individual preference lists based on the attribute frequency of each speaker as observed in the training data. In the case of Full Brevity, all possible descriptions for a given referent are computed, and the description that most closely resembles those produced by the speaker is selected using a nearest neighbour approach. The work in Viethen and Dale (2010) makes use of decision-tree induction to predict c"
W17-3536,P16-1054,1,0.828234,"ta produced by every individual speaker, or may otherwise perform poorly. In this work we propose a simple personalised method for this task, in which speakers are grouped into profiles according to their referential behaviour. Intrinsic evaluation shows that the use of speaker’s profiles generally outperforms the personalised method found in previous work. 1 Introduction In natural language generation systems, referring expression generation (REG) is the microplanning task responsible for generating references of discourse entities (Krahmer and van Deemter, 2012). Choice of referential form (Ferreira et al., 2016), i.e., deciding whether a reference should be a proper name (‘Ayrton Senna’), a pronoun (‘He’) or a description (‘The racing driver’), is the first decision to be made in this task. Albeit notable studies on pronominalisation (Callaway and Lester, 2002) and proper name generation (Ferreira et al., 2017), research on REG has largely focused on the generation of descriptions or, more specifically, on content selection. For instance, in the previous example, Ayrton Senna’s occupation is the content selected to describe him. This work focuses on this kind of content selection task, hereby called"
W17-3536,E17-1062,1,0.836327,"rforms the personalised method found in previous work. 1 Introduction In natural language generation systems, referring expression generation (REG) is the microplanning task responsible for generating references of discourse entities (Krahmer and van Deemter, 2012). Choice of referential form (Ferreira et al., 2016), i.e., deciding whether a reference should be a proper name (‘Ayrton Senna’), a pronoun (‘He’) or a description (‘The racing driver’), is the first decision to be made in this task. Albeit notable studies on pronominalisation (Callaway and Lester, 2002) and proper name generation (Ferreira et al., 2017), research on REG has largely focused on the generation of descriptions or, more specifically, on content selection. For instance, in the previous example, Ayrton Senna’s occupation is the content selected to describe him. This work focuses on this kind of content selection task, hereby called REG for brevity. Existing work in computational REG and related fields have identified a wide range of factors that may drive content selection. To a considerable extent, however, content selection is known to be influenced by human variation (Viethen and Dale, 2010). In other words, under identical circ"
W17-3536,W07-2307,0,0.0455617,"Missing"
W17-3536,J12-1006,0,0.038276,"Missing"
W17-3536,U10-1013,0,0.63734,"ter, 2002) and proper name generation (Ferreira et al., 2017), research on REG has largely focused on the generation of descriptions or, more specifically, on content selection. For instance, in the previous example, Ayrton Senna’s occupation is the content selected to describe him. This work focuses on this kind of content selection task, hereby called REG for brevity. Existing work in computational REG and related fields have identified a wide range of factors that may drive content selection. To a considerable extent, however, content selection is known to be influenced by human variation (Viethen and Dale, 2010). In other words, under identical circumstances (i.e., in the same referential context), different speakers will often produce different descriptions, and a single entity may be described by different speakers as ‘the racing driver’, ‘the McLaren pilot’, etc. Existing REG algorithms as in Bohnet (2008) and Ferreira and Paraboni (2014) usually pay regard to human variation by computing personalised features from a training set of descriptions produced by each speaker. This highly personalised training method may of course be considered an ideal account of human variation but, in practice, will"
W17-3536,W11-2702,0,0.138119,"ng individual preference lists based on the attribute frequency of each speaker as observed in the training data. In the case of Full Brevity, all possible descriptions for a given referent are computed, and the description that most closely resembles those produced by the speaker is selected using a nearest neighbour approach. The work in Viethen and Dale (2010) makes use of decision-tree induction to predict content patterns (i.e., full attribute sets representing actual referring expressions) to describe geometric objects on Google SketchUp scenes (GRE3D3/7 corpus) (Dale and Viethen, 2009; Viethen and Dale, 2011). Human variation is accounted for by modelling speaker identifiers as machine learning features. Finally, the work in Ferreira and Paraboni (2014) presents a SVM-based approach to speakerdependent REG tested also on the description of geometric objects (GRE3D3/7 and Stars/Stars2 (Teixeira et al., 2014; Paraboni et al., 2016) corpora). Once again, human variation is accounted for by computing individual preference lists from the subset of descriptions produced by each speaker. 3 Current work In all the studies discussed in the previous section, personalised REG outperforms standard algorithms"
Y08-1038,C96-1021,0,0.0554,"he most widely-spoken languages in the world, and which still lacks somewhat behind as a relatively resource-poor language in NLP. In this work we extend our previous investigation on learning approaches to Portuguese personal pronoun resolution in (Cuevas et. al., 2008.) In doing so, we focus on so-called ‘lowcost’ learning features, that is, we will limit the proposed solution to the knowledge readily obtainable from basic NLP tools such as part-of-speech taggers, and we will largely bypass deep syntactic or semantic analysis. In this sense, our work resembles the knowledge-poor approach in Kennedy & Boguraev (1996), which consists of a re-interpretation of the ‘classic’ algorithm proposed in Lappin & Leass (1994) using shallow rather than in-depth analysis. In addition to that, as we do not intend to explicitly write any anaphora resolution algorithms or rules (but rather induce them automatically) our work is mainly related to machine learning approaches such as Soon et. al. (2001), McCarthy and Lehnert (1995) and Ng & Cardie (2002). However, in discussing a possible ‘low-cost’ learning approach to Portuguese third person plural pronouns (“Eles/Elas”), we will focus more on the choice of learning featu"
Y08-1038,P02-1014,0,0.0337431,"ools such as part-of-speech taggers, and we will largely bypass deep syntactic or semantic analysis. In this sense, our work resembles the knowledge-poor approach in Kennedy & Boguraev (1996), which consists of a re-interpretation of the ‘classic’ algorithm proposed in Lappin & Leass (1994) using shallow rather than in-depth analysis. In addition to that, as we do not intend to explicitly write any anaphora resolution algorithms or rules (but rather induce them automatically) our work is mainly related to machine learning approaches such as Soon et. al. (2001), McCarthy and Lehnert (1995) and Ng & Cardie (2002). However, in discussing a possible ‘low-cost’ learning approach to Portuguese third person plural pronouns (“Eles/Elas”), we will focus more on the choice of learning features, and less on the results of a particular machine learning approach, which are to be discussed elsewhere. The rest of this paper is structured as follows. Section 2 reviews previous work taken as the basis for our present investigation. Section 3 proposed an extended set of features for the problem at hand. Results of a standard decision-tree induction algorithm using the new features are presented in Section 4. Finally,"
Y08-1038,J01-4004,0,0.185035,"Missing"
Y08-1038,J94-4002,0,\N,Missing
