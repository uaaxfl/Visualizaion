2005.mtsummit-papers.32,J93-2003,0,0.00645684,"pair but using phrases as atomic units rather than words. Words are thus phrases of length one. Therefore, we arrive at the following notation h˜ e, ˜fi(0) for he, fi and h˜ e, ˜fi(N ) for h˜ e, ˜fi. The superscript in the notation denotes level of detail with 0 for the finest and N for the coarsest. Let h˜ e, ˜fi(n) be a sentence pair at an intermediate level between (n) (n) (n) (n) ˜(n) = {˜ 0 and N and e e0 , e˜1 , ...˜ ei , ...˜ el 0 } (n) (n) (n) (n) (n) and ˜f = {f˜ , f˜ , ...f˜ , ...f˜ 0 } be its tu0 (n) e˜0 1 j m (n) ples with and f˜0 represent the special token NULL as suggested in (Brown et al., 1993) and l(n) , m(n) represent the length of the corresponding sentence. Let T (n) be a set of alignments defined over the sentence pair with (n) (n) (n) t˜ij =[˜ ei , f˜j ] as its member. As in our previous work, LOD algorithm transforms h˜ e, ˜fi(0) to h˜ e, ˜fi(N ) iteratively. In every iteration, LOD performs a series of steps, similar to the pipeline followed by many other algorithms, to learn phrase translation at one level more coarse. In the generation step, LOD algorithm forms B(n) , a pool of sub-phrase alignments, as the basis for the generation of phrase alignment candidate. LOD genera"
2005.mtsummit-papers.32,P89-1010,0,0.00810421,"of only two alignments at a time and hands over the candidate generation of more coarse alignment to the subsequent iteration. By considering only two alignments, the LOD model opens the opportunity for noncontiguous phrase translation without the disadvantage of combinatorial explosion in the number of candidates. 3.3 Estimation of Phrase Alignment Candidate Probability Joining the alignment set B(n) derived in Section 3.1 and the coarser level alignment C (n) derived in Section 3.2, we form a candidate alignment set B (n) ∪ C (n) . LOD utilizes information theoretic measure as suggested by (Church and Hanks, 1989) to assess the candidacy of each entry in C (n) . Assuming that there are two alignments x ∈ B (n) ,y ∈ B (n) and a candidate alignment hx, yi ∈ C (n) , we derive the probability p(x) and p(y) from the statistics as the count of x and y normalized by the number of sentence pairs in the corpus, and derive probability p(hx, yi) in a similar way. If there is a genuine association between x and y, then we expect the joint probability p(hx, yi) À p(x)p(y). If there is no interesting relationship between x and y, then p(hx, yi) ≈ p(x)p(y) where we say that x and y are independent. If x and y are in"
2005.mtsummit-papers.32,W03-0314,0,0.01645,"cant. In SMT, phrases are learned without distinguishing non-compositional from compositional ones. Despite this problem, SMT has witnessed great benefits from learning such phrasal units. 243 ploy evidence found in parallel corpora. This is not a new idea, as there is a vast amount of literature that directly addresses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that it is quite slow, as it suffers from computational inefficiency when calculating translation candidates. In th"
2005.mtsummit-papers.32,N03-1017,0,0.022802,"um phrase length can also be introduced to limit the generation step. This limit retains most of the algorithm’s performance since the count of long phrases decreases gradually. • Scoring. This step calculates a significance score that reflects the interestingness of the candidate for each entry in the candidate pool. There have been numerous metrics used to score candidates; specific examples include mixtures of alignment map, word-based lexicon and language-specific measures (Venugopal et al., 2004), block frequency (Tillmann, 2003), relative frequency (Och et al., 1999), lexical weighting (Koehn et al., 2003) and a set of features 244 reflecting word penalty, length penalty and lexicon score (Zens and Ney, 2004). The scoring function must accommodate phrases of varying length and allow direct comparison between them. Many methods employ a normalization process over the phrase length to enable the comparison, but such normalization may not reflect the actual distribution of the phrase. • Selection. This final step selects the most probable candidates as phrase translations. The algorithm typically explores all candidates and decides their promotion based on their scores. Rank-based methods, using m"
2005.mtsummit-papers.32,W04-3250,0,0.0110362,"f 1,055,167 words and 20,138 unique words. Our experiment is conducted on English-to-French tasks on open testing set-up. We use GIZA++1 as the implementation for the word-based IBM 4 model training and ISI ReWrite2 to translate sentences in testing set. Translation performance is reported as BLEU scores, with appropriate confidence intervals computed. 4.1 Performance versus Original LOD Figure 1 shows the performance of the LOD approach using the simplified algorithm in each iteration and juxtaposes it with that of original algorithm in the English-to-French task. We apply a paired t − test (Koehn, 2004) to examine whether the performance difference is statistically significant. The result of our experiments shows that the performance of our simplified algorithm is comparable and slightly above that of original algorithm in some iterations, although the paired t − test shows that the performance difference is not statistically significant. Initially, we expect to see a reduction in translation performance by simplifying the algorithm since the algorithm operates on a smaller set of alignments sacrificing the recall in generating translation candidates. The results suggest that the simplified"
2005.mtsummit-papers.32,W02-1018,0,0.0120744,"such phrasal units. 243 ploy evidence found in parallel corpora. This is not a new idea, as there is a vast amount of literature that directly addresses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that it is quite slow, as it suffers from computational inefficiency when calculating translation candidates. In this paper, we modify the original LOD approach by simplifying the learning process and using a simpler translation model while maintaining a comparable level of performanc"
2005.mtsummit-papers.32,W97-0311,0,0.0304183,"notes a statistically significant grouping of words rather than a grouping that is linguistically significant. In SMT, phrases are learned without distinguishing non-compositional from compositional ones. Despite this problem, SMT has witnessed great benefits from learning such phrasal units. 243 ploy evidence found in parallel corpora. This is not a new idea, as there is a vast amount of literature that directly addresses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that"
2005.mtsummit-papers.32,E03-1035,0,0.0192932,"words rather than a grouping that is linguistically significant. In SMT, phrases are learned without distinguishing non-compositional from compositional ones. Despite this problem, SMT has witnessed great benefits from learning such phrasal units. 243 ploy evidence found in parallel corpora. This is not a new idea, as there is a vast amount of literature that directly addresses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that it is quite slow, as it suffers from computa"
2005.mtsummit-papers.32,W99-0604,0,0.258622,"is not a new idea, as there is a vast amount of literature that directly addresses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that it is quite slow, as it suffers from computational inefficiency when calculating translation candidates. In this paper, we modify the original LOD approach by simplifying the learning process and using a simpler translation model while maintaining a comparable level of performance. In the remainder of this paper, we will describe our simplified"
2005.mtsummit-papers.32,I05-1051,1,0.527089,"Singapore 119613 {stuhs,hli,mzhang}@i2r.a-star.edu.sg 2 School of Computing National University of Singapore Singapore 117543 hendrase@comp.nus.edu.sg Abstract One method to address this problem is to emWe propose a simplified Level Of Detail (LOD) algorithm to learn phrase translation for statistical machine translation. In particular, LOD learns unknown phrase translations from parallel texts without linguistic knowledge. LOD uses an agglomerative method to attack the combinatorial explosion that results when generating candidate phrase translations. Although LOD was previously proposed by (Setiawan et al., 2005), we improve the original algorithm in two ways: simplifying the algorithm and using a simpler translation model. Experimental results show that our algorithm provides comparable performance while demonstrating a significant reduction in computation time. 1 Introduction Many natural language processing applications, such as machine translation, treat words as the primitive unit of processing. These units are often treated as a set, discarding ordering information, and reducing an utterance as a bag of words. However, natural language often exhibits a non-compositional property where an utteran"
2005.mtsummit-papers.32,W03-1001,0,0.0536808,"resses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that it is quite slow, as it suffers from computational inefficiency when calculating translation candidates. In this paper, we modify the original LOD approach by simplifying the learning process and using a simpler translation model while maintaining a comparable level of performance. In the remainder of this paper, we will describe our simplified Level of Detail (LOD) algorithm. Section 2 discusses related work, includi"
2005.mtsummit-papers.32,C96-2141,0,0.0747395,"s a vast amount of literature that directly addresses learning phrase translation from parallel texts. The identification of meaningful phrase translation includes the learning of the translation of noncompositional compounds (Melamed, 1997), “captoids” and name entities (Moore, 2003) and both gapped and rigid multiword sequence (Kaoru et al., 2003) just to name a few. Specifically for phrase-based SMT, there are many approaches proposed for learning phrase translation, such as the joint model (Marcu and Wong, 2002), ISA (Zhang et al., 2003), alignment templates (Och et al., 1999), HMM paths (Vogel et al., 1996) and projection extensions (Tillmann, 2003). In our previous work (Setiawan et al., 2005), we introduced an agglomerative approach to learn phrase translation for SMT. While the LOD approach works well, a weakness is that it is quite slow, as it suffers from computational inefficiency when calculating translation candidates. In this paper, we modify the original LOD approach by simplifying the learning process and using a simpler translation model while maintaining a comparable level of performance. In the remainder of this paper, we will describe our simplified Level of Detail (LOD) algorithm"
2005.mtsummit-papers.32,N04-1033,0,0.0137779,"rithm’s performance since the count of long phrases decreases gradually. • Scoring. This step calculates a significance score that reflects the interestingness of the candidate for each entry in the candidate pool. There have been numerous metrics used to score candidates; specific examples include mixtures of alignment map, word-based lexicon and language-specific measures (Venugopal et al., 2004), block frequency (Tillmann, 2003), relative frequency (Och et al., 1999), lexical weighting (Koehn et al., 2003) and a set of features 244 reflecting word penalty, length penalty and lexicon score (Zens and Ney, 2004). The scoring function must accommodate phrases of varying length and allow direct comparison between them. Many methods employ a normalization process over the phrase length to enable the comparison, but such normalization may not reflect the actual distribution of the phrase. • Selection. This final step selects the most probable candidates as phrase translations. The algorithm typically explores all candidates and decides their promotion based on their scores. Rank-based methods, using maximal separation criteria (Venugopal et al., 2004) and frequency filtering (Tillmann, 2003) are common m"
2008.iwslt-evaluation.17,J03-1002,0,0.00397375,"I1 maximizing a loglinear combination of several feature models [4]: - 116 - ( eˆI1 = arg max eI1 M X ) λm hm (eI1 , f1J ) m=1 where the feature functions hm refer to the system models and the set of λm refers to the weights corresponding to these models. Proceedings of IWSLT 2008, Hawaii - U.S.A. The N gram-based approach regards translation as a stochastic process maximizing the joint probability p(f, e), leading to a decomposition based on bilingual n-grams, socalled tuples, that are extracted from a word-to-word alignment (performed with GIZA++ tool1 and generated by growdiag-final method [5]). Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [6]: languages capturing bilingual context, as described by the following equation: p(S, T ) = K Y p((˜ s, t˜)k |(˜ s, t˜)k−N +1 , ..., (˜ s, t˜)k−1 ) (1) k=1 where s refers to source, t to target, and (˜ s, t˜)k to the k tuple of a given bilingual sentence pair segmented in K tuples. The bilingual TM actually constitutes an n-gram-based language model (LM) of tuples, which approximates the joint probability between the languages under consideration and can be seen here as a LM, where t"
2008.iwslt-evaluation.17,N04-1033,0,0.0316825,"I1 , f1J ) m=1 where the feature functions hm refer to the system models and the set of λm refers to the weights corresponding to these models. Proceedings of IWSLT 2008, Hawaii - U.S.A. The N gram-based approach regards translation as a stochastic process maximizing the joint probability p(f, e), leading to a decomposition based on bilingual n-grams, socalled tuples, that are extracted from a word-to-word alignment (performed with GIZA++ tool1 and generated by growdiag-final method [5]). Given a certain word-aligned parallel corpus, tuples are extracted according to the following constraints [6]: languages capturing bilingual context, as described by the following equation: p(S, T ) = K Y p((˜ s, t˜)k |(˜ s, t˜)k−N +1 , ..., (˜ s, t˜)k−1 ) (1) k=1 where s refers to source, t to target, and (˜ s, t˜)k to the k tuple of a given bilingual sentence pair segmented in K tuples. The bilingual TM actually constitutes an n-gram-based language model (LM) of tuples, which approximates the joint probability between the languages under consideration and can be seen here as a LM, where the language is composed by tuples. th • a monotonic segmentation of each bilingual sentence pair is produced • n"
2008.iwslt-evaluation.17,W06-1609,1,0.710642,"2008, Hawaii - U.S.A. 2.5. Statistical Machine Reordering 3.1. Punctuation restoration The conception of the Statistical Machine Reordering (SMR) stems from the idea of using the powerful techniques developed for SMT and to translate the source language (S) into a reordered source language (S’), which more closely matches the order of the target language. To infer more reorderings, it makes use of word classes. To correctly integrate the SMT and SMR systems, both are concatenated by using a word graph which offers weighted reordering hypotheses to the SMT system. The details are described in [8] and [9]. We decided to embed punctuation restoration in the main translation step. For this purpose we preprocessed the training corpus as follows: 2.6. Translation models interpolation The resulting preprocessed training corpus is used to train a standard SMT system (wi stands for the i-th word). During the post-evaluation period we have implemented a TM interpolation strategy following the ideas proposed in [3], where the authors present a promising technique of target LMs linear interpolation. These findings open the way to involve additional monolingual information into the translation pr"
2008.iwslt-evaluation.17,W07-0721,1,0.843062,"awaii - U.S.A. 2.5. Statistical Machine Reordering 3.1. Punctuation restoration The conception of the Statistical Machine Reordering (SMR) stems from the idea of using the powerful techniques developed for SMT and to translate the source language (S) into a reordered source language (S’), which more closely matches the order of the target language. To infer more reorderings, it makes use of word classes. To correctly integrate the SMT and SMR systems, both are concatenated by using a word graph which offers weighted reordering hypotheses to the SMT system. The details are described in [8] and [9]. We decided to embed punctuation restoration in the main translation step. For this purpose we preprocessed the training corpus as follows: 2.6. Translation models interpolation The resulting preprocessed training corpus is used to train a standard SMT system (wi stands for the i-th word). During the post-evaluation period we have implemented a TM interpolation strategy following the ideas proposed in [3], where the authors present a promising technique of target LMs linear interpolation. These findings open the way to involve additional monolingual information into the translation process, a"
2008.iwslt-evaluation.17,2007.mtsummit-papers.29,0,0.0263997,"iod we have implemented a TM interpolation strategy following the ideas proposed in [3], where the authors present a promising technique of target LMs linear interpolation. These findings open the way to involve additional monolingual information into the translation process, and also gives a motivation to interpolate the translation and reordering tables in a linear way. Due to a small amount of available in-domain data (IWSLT training material), we have used an out-of-domain 130K-line subset from the Arabic News, English Translation of Arabic Treebank and Ummah LDC parallel corpora (VIOLIN) [10] to increase the final translation and reordering tables. Both corpus statistics can be found in table 1. Instead of time-consuming iterative TM reconstruction and using the highest BLEU score as an maximization criteria, we adjust the weights as a function of the lowest perplexity estimated by the corresponding interpolated combination of the target-side LMs and generalize the optimization results on the interpolated translation and reordering models. The word-to-word alignment was obtained from the joint database (IWSLT + VIOLIN). Then, we separately computed the translation and reordering t"
2008.iwslt-evaluation.17,P07-2045,0,0.0159161,"ssion Corpus (BTEC) Arabic to English translation task. The model weights were tuned with the 2006 development corpus (Dev6), containing 489 sentences and 6 reference translations and the 2002 development set (500 sentences and 16 reference translations) was used as an internal test, according to which we take a decision about better or worse system performance. 4.1.1. Arabic data preprocessing In this section we present a phrase-based MT system that was used in the evaluation. This system is based on the well-known MOSES2 toolkit, which is nowadays considered as a state-of-the-art SMT system [11]. The training and weights tuning procedures are explained in details in the above-mentioned publication, as well as, on the MOSES web page: http://www.statmt.org/moses/. 2 www.statmt.org/moses/ We used a similar approach to that shown in [12], namely the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic unigram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The scheme splits the following set of enclitics: w+, f+, b+, k+, l+, Al+ and pronominal enclitics. The -TAGBIES option produces Bies POS tags on all taggable t"
2008.iwslt-evaluation.17,N06-2013,0,0.0588409,"anslations) was used as an internal test, according to which we take a decision about better or worse system performance. 4.1.1. Arabic data preprocessing In this section we present a phrase-based MT system that was used in the evaluation. This system is based on the well-known MOSES2 toolkit, which is nowadays considered as a state-of-the-art SMT system [11]. The training and weights tuning procedures are explained in details in the above-mentioned publication, as well as, on the MOSES web page: http://www.statmt.org/moses/. 2 www.statmt.org/moses/ We used a similar approach to that shown in [12], namely the MADA+TOKAN system for disambiguation and tokenization. For disambiguation only diacritic unigram statistics were employed. For tokenization we used the D3 scheme with -TAGBIES option. The scheme splits the following set of enclitics: w+, f+, b+, k+, l+, Al+ and pronominal enclitics. The -TAGBIES option produces Bies POS tags on all taggable tokens. 3 http://www.slc.atr.jp/IWSLT2008/ - 118 - Proceedings of IWSLT 2008, Hawaii - U.S.A. Sentences Words Average sentence length Vocabulary IWSLT Arabic 24.45 K 170.24 K 6.96 10.89 K English 24.45 K 188.54 K 7.71 6.92 K VIOLIN Arabic 130.5"
2008.iwslt-evaluation.17,2005.iwslt-1.8,0,0.0320169,"n”) outperforms BTEC-only system by 1.8 BLEU points and 1.2 METEOR points for the CRR track and by 2.1 BLEU points and by about 1 METEOR points for the ASR track measured on the official evaluation test set. ”Supplied 2” line stands for the results obtained with the TALPtuples system as described in sub-section 4.1.3. - 119 - • TM(s), direct and inverse phrase/word based TM. • Distortion model, which assigns a cost linear to the reordering distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [15]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Target-side LM. The TM and reordering model were trained using the standard MOSES tools. Weights of feature functions were tuned by using the optimization tools from the MOSES package. The search operation was accomplished by MOSES decoder. The experiments with the Chinese to English MT were carried out on the BTEC Chinese-English data [16] augmented with HIT-corpus4 , Olympic-corpus5 and PKUcorpus6 from Chinese LDC. 20K BTEC sentence pairs were supplied for the IWSLT 2008 evaluation campaign. HI"
2008.iwslt-evaluation.17,takezawa-etal-2002-toward,0,0.0149266,"ng distance, while the cost is based on the number of source words which are skipped when translating a new source phrase. • Lexicalized word reordering model [15]. • Word and phrase penalties, which count the number of words and phrases in the target string. • Target-side LM. The TM and reordering model were trained using the standard MOSES tools. Weights of feature functions were tuned by using the optimization tools from the MOSES package. The search operation was accomplished by MOSES decoder. The experiments with the Chinese to English MT were carried out on the BTEC Chinese-English data [16] augmented with HIT-corpus4 , Olympic-corpus5 and PKUcorpus6 from Chinese LDC. 20K BTEC sentence pairs were supplied for the IWSLT 2008 evaluation campaign. HIT corpus contains 132K sentence pairs in total, and is known as a multi-source ChineseEnglish parallel corpus; Olympic corpus has 54K bilingual sentences mainly from sport and travelling domains; while PKU-corpus has about 200K parallel phrases and is considered as a domain-balanced corpus. Besides, the English part of the Tanaka corpus7 was used as a complementary training 4 http://mitlab.hit.edu.cn/index.php/resources 5 http://www.chin"
2008.iwslt-evaluation.17,W03-1730,0,0.0212439,"OR)/2 0.6016 0.6055 0.6210 0.5892 0.5320 0.5320 0.5473 0.5296 NIST 8.5253 8.5940 8.8772 8.7421 7.2878 7.2808 7.6113 7.5862 Table 2: Official and post-evaluation results for Arabic-English translation. Sentences Words Vocabulary Chinese 19,972 164K 8,506 IWSLT’08 English Spanish 19,972 19,972 182K 147K 8,301 16,953 All additional data Chinese English 379,065 379,065 4,834K 5,036K 57,055 75,156 Table 3: Corpus used during the Chinese-English training material for the target-side LM. The I2R research group performed word segmentation for the Chinese part using ICTCLAS tools8 developed in the ICT [17]. Table 3 reports the basic statistics of the principal and additional corpora that were used to build the Chinese-toEnglish SMT system. Regarding English-to-Spanish translation, no extra corpora were used. “you ’re”, and negations like “don’t”, “wouldn’t” or “can’t” were split as “do n’t”, “would n’t” and “ca n’t”. The output of this system was performed in accordance with the official evaluation specification, without any postprocessing needed. Table 5 shows the results of the EnglishSpanish system trained with the BTEC corpus. 4.2.1. Chinese-English independent results The union of the BTEC"
2008.iwslt-evaluation.17,N04-1022,0,0.0541414,"and “you’re” were split as “we ’ll” and 8 http://www.nlp.org.cn/project/project.php?proj BLEU NIST METEOR id=6 - 120 - Our primary approach to the pivot task was a system cascade. Using the 50-best list of translation hypotheses generated by the decoder for the Chinese-to-English system, a 4-best list was made for each of the first list instances, totally representing a 200-best of possible Spanish translations for each Chinese sentence. From that 200-best list, which is allowed for repetitions, the single-best translation was computed using a Minimum Bayes Risk (MBR) strategy as described in [18]. We used the MOSES implementation of the MBR algorithm. This strategy of 200-best list rescoring performed better than a single-best list selection for both systems, gaining 2.5 BLEU points in the development set. Proceedings of IWSLT 2008, Hawaii - U.S.A. 4.2.4. Secondary submission As an alternative approach to the system cascade, we followed a different strategy for the secondary submission combining the phrase translation probabilities of the two language pairs (Chinese-English and English-Spanish translations) with the strategy proposed in [19] to obtain the translation probabilities for"
2008.iwslt-evaluation.17,P07-1108,0,0.0348074,"m Bayes Risk (MBR) strategy as described in [18]. We used the MOSES implementation of the MBR algorithm. This strategy of 200-best list rescoring performed better than a single-best list selection for both systems, gaining 2.5 BLEU points in the development set. Proceedings of IWSLT 2008, Hawaii - U.S.A. 4.2.4. Secondary submission As an alternative approach to the system cascade, we followed a different strategy for the secondary submission combining the phrase translation probabilities of the two language pairs (Chinese-English and English-Spanish translations) with the strategy proposed in [19] to obtain the translation probabilities for each Chinese-Spanish phrase. The final phrase probabilities are calculated as followed: φ(fi |ei ) = X φ(fi |pi )φ(pi |ei ) (2) pi where φ(fi |ei ) corresponds to the translation probability of the Chinese phrase fi given the Spanish phrase ei , φ(fi |pi ) stands for the translation probability of the Chinese phrase fi given the English phrase pi and φ(pi |ei ) stands for the translation probability of the English phrase pi given the Spanish phrase ei . It is important to mention that the English and Spanish phrases are lowercased in this system and"
2008.iwslt-evaluation.17,carreras-etal-2004-freeling,0,0.029059,"6 sentences with 16 Spanish references for tuning the system. The basic statistics of this corpus can be seen in table 7. 4.3.1. Data preprocessing The Chinese corpus was not preprocessed before translation: the corpus was tokenized by words and the punctuation marks were separated. Note that the TM, as well as the LM and reordering model, was trained with punctuation marks and the official test set that did not contain this information, therefore it was preprocessed with the hidden-ngram tool to restore it. The Spanish part of the corpus was lowercased and tokenized using the Freeling toolkit[20], an open source tool for language analysis. It splitted the enclitics from the Spanish verbs (d´amelo → da +me +lo) and also generated the POS tags that were lately used to estimate a target-side POS LM and in postprocessing. 4.3.2. Data postprocessing Once the decoding process had finished, the output of the system was still lowercased and splitted with the enclitics and the POS tags were generated. Afterwards, a postprocess including two steps was performed: firstly, the original morphological verbs form was restored using the enclitics and POS tags information; on the next step, the case i"
2008.iwslt-evaluation.17,2007.iwslt-1.1,0,\N,Missing
2008.iwslt-evaluation.17,2006.iwslt-evaluation.1,0,\N,Missing
2008.iwslt-evaluation.6,E06-1005,0,0.054695,"system combination methods that we have explored. The performance on development and test sets are reported in detail in the paper. The system has shown competitive performance with respect to the BLEU and METEOR measures in Chinese-English Challenge and BTEC tasks. 1. Introduction This paper describes the machine translation (MT) system and approach explored by the Institute for Infocomm Research (I2R) for the International Workshop on Spoken Language Translation (IWSLT) 2008. We submitted runs under the open data conditions for Chinese-to-English BTEC and Challenge tasks. System combination [1, 2, 3] has demonstrated its advantage in the recent machine translation evaluation campaign [4, 5]. In our system, a multi-pass SMT approach is exploited which consists of decoding, regeneration, rescoring and system combination. First, multiple systems based on different translation strategies are used to generate various Nbest lists. This aims to leverage on the strength of different translation methods. Then three kinds of different system combination methods are applied in a two-stage procedure to find the 1-best translation. Figure 1 depicts our system architecture. First, we use three decoders"
2008.iwslt-evaluation.6,N07-1029,0,0.0312943,"system combination methods that we have explored. The performance on development and test sets are reported in detail in the paper. The system has shown competitive performance with respect to the BLEU and METEOR measures in Chinese-English Challenge and BTEC tasks. 1. Introduction This paper describes the machine translation (MT) system and approach explored by the Institute for Infocomm Research (I2R) for the International Workshop on Spoken Language Translation (IWSLT) 2008. We submitted runs under the open data conditions for Chinese-to-English BTEC and Challenge tasks. System combination [1, 2, 3] has demonstrated its advantage in the recent machine translation evaluation campaign [4, 5]. In our system, a multi-pass SMT approach is exploited which consists of decoding, regeneration, rescoring and system combination. First, multiple systems based on different translation strategies are used to generate various Nbest lists. This aims to leverage on the strength of different translation methods. Then three kinds of different system combination methods are applied in a two-stage procedure to find the 1-best translation. Figure 1 depicts our system architecture. First, we use three decoders"
2008.iwslt-evaluation.6,P07-2045,0,0.0105658,"ed its advantage in the recent machine translation evaluation campaign [4, 5]. In our system, a multi-pass SMT approach is exploited which consists of decoding, regeneration, rescoring and system combination. First, multiple systems based on different translation strategies are used to generate various Nbest lists. This aims to leverage on the strength of different translation methods. Then three kinds of different system combination methods are applied in a two-stage procedure to find the 1-best translation. Figure 1 depicts our system architecture. First, we use three decoders, namely Moses [6] (an open source phrasebased MT system), JosHUa [7] (a hierarchical phrase-based translation system) and Tranyu [8] (an in-house linguistically-annotated BTG-based decoder) to generate 2Nbest lists of hypotheses for each decoder. Then each 2N-best lists are rescored and re-ranked with additional feature functions. The 1-best and top N-best lists of these re-ranked lists are then used in system combination1. Secondly, we construct system combination in two-stage. In the first stage, two strategies are applied. The first strategy is n-gram expansion by which we spawn new translation entries thro"
2008.iwslt-evaluation.6,W08-0402,0,0.0242585,"evaluation campaign [4, 5]. In our system, a multi-pass SMT approach is exploited which consists of decoding, regeneration, rescoring and system combination. First, multiple systems based on different translation strategies are used to generate various Nbest lists. This aims to leverage on the strength of different translation methods. Then three kinds of different system combination methods are applied in a two-stage procedure to find the 1-best translation. Figure 1 depicts our system architecture. First, we use three decoders, namely Moses [6] (an open source phrasebased MT system), JosHUa [7] (a hierarchical phrase-based translation system) and Tranyu [8] (an in-house linguistically-annotated BTG-based decoder) to generate 2Nbest lists of hypotheses for each decoder. Then each 2N-best lists are rescored and re-ranked with additional feature functions. The 1-best and top N-best lists of these re-ranked lists are then used in system combination1. Secondly, we construct system combination in two-stage. In the first stage, two strategies are applied. The first strategy is n-gram expansion by which we spawn new translation entries through a word-based n-gram language model estimated on"
2008.iwslt-evaluation.6,P06-1066,1,0.866553,"oach is exploited which consists of decoding, regeneration, rescoring and system combination. First, multiple systems based on different translation strategies are used to generate various Nbest lists. This aims to leverage on the strength of different translation methods. Then three kinds of different system combination methods are applied in a two-stage procedure to find the 1-best translation. Figure 1 depicts our system architecture. First, we use three decoders, namely Moses [6] (an open source phrasebased MT system), JosHUa [7] (a hierarchical phrase-based translation system) and Tranyu [8] (an in-house linguistically-annotated BTG-based decoder) to generate 2Nbest lists of hypotheses for each decoder. Then each 2N-best lists are rescored and re-ranked with additional feature functions. The 1-best and top N-best lists of these re-ranked lists are then used in system combination1. Secondly, we construct system combination in two-stage. In the first stage, two strategies are applied. The first strategy is n-gram expansion by which we spawn new translation entries through a word-based n-gram language model estimated on the input hypotheses. Then input hypotheses and the newly-gener"
2008.iwslt-evaluation.6,J03-1002,0,0.00526627,"Section 3 details the rescoring models. Section 4 describes three system combination strategies: n-gram expansion, simple cascading and weighted voting. Section 5 reports the experimental setups and results while Section 6 concludes the paper. 2. The SMT Models To integrate the advantages of the state-of-the-art translation methods, we use three different SMT models, phrase-based, hierarchical phrase-based and linguistically-annotated BTGbased in the first pass to generate N-best hypotheses. The three methods share the some common features: word alignment of training data obtained from GIZA++ [9], Language model(s) (LM) trained using SRILM toolkit [10] with modified Kneser-Ney smoothing method [11]. 2.1. Phrasal translation system Phrase-based SMT systems are usually modeled through a log-linear framework [12]. By introducing the hidden word alignment variable a [13], the optimal translation can be searched for based on the following criterion: M e * = arg max(∑ m =1 λm hm (e, f , a)) where e is a string of phrases in the target language, the source language string of phrases, feature functions, weights 1 Since our system combination method n-gram expansion [3] is based on a gener"
2008.iwslt-evaluation.6,P02-1038,0,0.0901849,"ion 6 concludes the paper. 2. The SMT Models To integrate the advantages of the state-of-the-art translation methods, we use three different SMT models, phrase-based, hierarchical phrase-based and linguistically-annotated BTGbased in the first pass to generate N-best hypotheses. The three methods share the some common features: word alignment of training data obtained from GIZA++ [9], Language model(s) (LM) trained using SRILM toolkit [10] with modified Kneser-Ney smoothing method [11]. 2.1. Phrasal translation system Phrase-based SMT systems are usually modeled through a log-linear framework [12]. By introducing the hidden word alignment variable a [13], the optimal translation can be searched for based on the following criterion: M e * = arg max(∑ m =1 λm hm (e, f , a)) where e is a string of phrases in the target language, the source language string of phrases, feature functions, weights 1 Since our system combination method n-gram expansion [3] is based on a generative language model that is trained on the input hypotheses lists, the hypotheses quality is very important to the performance of the n-gram expansion method. Therefore, we filter out N-worse hypotheses from the 2N-be"
2008.iwslt-evaluation.6,P03-1021,0,0.044622,"m =1 λm hm (e, f , a)) where e is a string of phrases in the target language, the source language string of phrases, feature functions, weights 1 Since our system combination method n-gram expansion [3] is based on a generative language model that is trained on the input hypotheses lists, the hypotheses quality is very important to the performance of the n-gram expansion method. Therefore, we filter out N-worse hypotheses from the 2N-best lists before passing them to the n-gram expansion model. (1) e ,a λm hm (e, f , a ) f is are are typically optimized to maximize the scoring function [14]. Our phrasal translation system is based on the Moses open source package [6]. IBM word reordering constraints [15] are applied during decoding to reduce the computational - 46 - Proceedings of IWSLT 2008, Hawaii - U.S.A. Figure 1: system architecture complexity. The other models and feature functions employed by Moses decoder are: • Translation model(s) (TM), direct phrase/word based translation model and inverse • Distortion model, which assigns a cost linear to the reordering distance, the cost is based on the number of source words which are skipped when translating a new source phrase •"
2008.iwslt-evaluation.6,2005.iwslt-1.8,0,0.0381389,"s based on the Moses open source package [6]. IBM word reordering constraints [15] are applied during decoding to reduce the computational - 46 - Proceedings of IWSLT 2008, Hawaii - U.S.A. Figure 1: system architecture complexity. The other models and feature functions employed by Moses decoder are: • Translation model(s) (TM), direct phrase/word based translation model and inverse • Distortion model, which assigns a cost linear to the reordering distance, the cost is based on the number of source words which are skipped when translating a new source phrase • Lexicalized word reordering model [16] (RM) • Word and phrase penalties, which count the numbers of words and phrases in the target string The translation model, reordering model and feature weights are trained and optimized using Moses training and tuning toolkits. Two different N-best lists are generated by the same Moses decoder with the same source input but different preprocessing. 2.2. Hierarchical phrase-based translation system Hierarchical phrase-based translation method is a typical formally syntax-based translation modeling method. Empirically, it has demonstrated better performance than the phrase-based method because"
2008.iwslt-evaluation.6,J07-2003,0,0.103377,"ses in the target string The translation model, reordering model and feature weights are trained and optimized using Moses training and tuning toolkits. Two different N-best lists are generated by the same Moses decoder with the same source input but different preprocessing. 2.2. Hierarchical phrase-based translation system Hierarchical phrase-based translation method is a typical formally syntax-based translation modeling method. Empirically, it has demonstrated better performance than the phrase-based method because it permits phrases with gaps by generalizing the normal phrase-based models [17, 7]. Formally, the hierarchical phrase-based translation model is a weighted synchronous context free grammar. In our system combination framework, for the hierarchical phrase-based translation component, we use the default setting as discussed in [17] for training and tuning and use JosHUa [7]’s implementation for decoding. 2.3. Linguistically annotated BTG-based system Tranyu is an in-house formally and linguistically syntaxbased SMT system, which adopts the bracketing transduction grammars (BTG) as the fundamental framework for phrase translation and reordering. The BTG lexical rules (A --&gt; x/"
2008.iwslt-evaluation.6,P08-2038,1,0.868481,"el uses boundary words of neighboring phrases as features [8], which we call the boundary words based reordering model (BWR). The second model uses linguistic annotations of each BTG node as features, which are automatically learned by projecting source-side parse trees onto the corresponding binary trees generated by BTG. We call the second model the linguistically annotated reordering model (LAR). Based on these two reordering models, we developed two variations of Tranyu. The first variation Tranyu1 only uses the BWR model [8] while the second variation Tranyu2 uses both BWR and LAR models [18]. 3. Rescoring models Rescoring operation plays a very important role in our system. A rich global feature functions set benefits our system greatly. The rescoring models are the same ones which were used in our SMT system for IWSLT 2007 [4]. We apply the - 47 - Proceedings of IWSLT 2008, Hawaii - U.S.A. following feature functions. Weights of feature functions are optimized by the MERT tool in Moses package. • direct and inverse IBM model 1 and 3 and two combined systems. The feature weight of each system is tuned over the development set. If all the weights are set to 1, then we call it simp"
2008.iwslt-evaluation.6,2006.iwslt-papers.4,1,0.869059,"system greatly. The rescoring models are the same ones which were used in our SMT system for IWSLT 2007 [4]. We apply the - 47 - Proceedings of IWSLT 2008, Hawaii - U.S.A. following feature functions. Weights of feature functions are optimized by the MERT tool in Moses package. • direct and inverse IBM model 1 and 3 and two combined systems. The feature weight of each system is tuned over the development set. If all the weights are set to 1, then we call it simple voting. • association scores, i.e. hyper-geometric distribution probabilities and mutual information • lexicalized reordering rule [19] • 6-gram target language model and 8-gram target wordclass based LM, word-classes are clustered by GIZA++ • length ratio between source and target sentence • question feature [20] • Linear sum of n-grams (n=1,2,3,4) relative frequencies within all translations [20] • n-gram and sentence length posterior probabilities within the N-best translations [21] 5. Experiments We participated Chinese-to-English BTEC task (BT) and Challenge task (CT) in open data track for IWSLT 2008. 5.1. Preprocessing Preprocessing includes Chinese word segmentation, English tokenization, and transformation of numbers"
2008.iwslt-evaluation.6,J93-2003,0,\N,Missing
2008.iwslt-evaluation.6,C08-1014,1,\N,Missing
2008.iwslt-evaluation.6,2007.iwslt-1.8,1,\N,Missing
2008.iwslt-evaluation.6,P02-1040,0,\N,Missing
2008.iwslt-evaluation.6,W06-3110,0,\N,Missing
2008.iwslt-evaluation.6,takezawa-etal-2002-toward,0,\N,Missing
2008.iwslt-evaluation.6,2005.iwslt-1.11,1,\N,Missing
2008.iwslt-evaluation.6,W03-1730,1,\N,Missing
2009.iwslt-evaluation.7,N07-1029,0,0.0408514,"y optimized to maximize the scoring function [11]. IBM word reordering constraints [13] are applied during decoding to reduce the computational complexity. The other models and feature functions employed by Lavender are: • Translation model(s) (TM), direct and inverse phrase/word based translation model 1. Introduction This paper describes the machine translation (MT) system and approach explored by the Institute for Infocomm Research (I2R) for the International Workshop on Spoken Language Translation (IWSLT) 2009. Basically, our MT system is a system combination framework. System combination [1, 2, 3] has demonstrated its advantage in the recent machine translation evaluation campaign [4, 5]. In our system combination framework, we adopt mainly two kinds of statistical machine translation (SMT) methods: phrase-based SMT and syntax-based SMT. For syntax-based system, we developed three variations. Totally, we applied four SMT systems. Based on outputs of four single systems, we applied rescoring method [4] to incorporate rich global features. Finally, we adopt two kinds of system combination methods, namely, n-gram expansion [3] and weighted voting, on all rescoring outputs. The rest of pap"
2009.iwslt-evaluation.7,J03-1002,0,0.0057466,"Missing"
2009.iwslt-evaluation.7,P02-1038,0,0.373791,"f the different individual systems. Rescoring is applied on each single system output, and system combination is applied on all rescoring outputs. Finally, our system combination framework shows better performance in Chinese-English BTEC task. Lavender [19] is our newly-developed in-house SMT translation platform, including a phrase-based decoder and most of the current linguistically motivated syntax-based system. Its phrase-based component, which functions very similar to Moses [12], is used as the phrase-based decoder for this campaign. Phrase-based SMT usually adopt a log-linear framework [9]. By introducing the hidden word alignment variable a [10], the optimal translation can be searched for based on the following criterion: ~ M e~ * = arg max( λ h (e~, f , a)) e,a ∑m =1 m m ~ where ~ e is a string of phrases in the target language, f is the ~ source language string of phrases, h (e~, f , a) are feature funcm tions, weights λm are typically optimized to maximize the scoring function [11]. IBM word reordering constraints [13] are applied during decoding to reduce the computational complexity. The other models and feature functions employed by Lavender are: • Translation model(s)"
2009.iwslt-evaluation.7,P03-1021,0,0.038379,"-based system. Its phrase-based component, which functions very similar to Moses [12], is used as the phrase-based decoder for this campaign. Phrase-based SMT usually adopt a log-linear framework [9]. By introducing the hidden word alignment variable a [10], the optimal translation can be searched for based on the following criterion: ~ M e~ * = arg max( λ h (e~, f , a)) e,a ∑m =1 m m ~ where ~ e is a string of phrases in the target language, f is the ~ source language string of phrases, h (e~, f , a) are feature funcm tions, weights λm are typically optimized to maximize the scoring function [11]. IBM word reordering constraints [13] are applied during decoding to reduce the computational complexity. The other models and feature functions employed by Lavender are: • Translation model(s) (TM), direct and inverse phrase/word based translation model 1. Introduction This paper describes the machine translation (MT) system and approach explored by the Institute for Infocomm Research (I2R) for the International Workshop on Spoken Language Translation (IWSLT) 2009. Basically, our MT system is a system combination framework. System combination [1, 2, 3] has demonstrated its advantage in the r"
2009.iwslt-evaluation.7,P07-2045,0,0.00954186,"ng method to improve the individual system performance and use system combination method to combine the strengths of the different individual systems. Rescoring is applied on each single system output, and system combination is applied on all rescoring outputs. Finally, our system combination framework shows better performance in Chinese-English BTEC task. Lavender [19] is our newly-developed in-house SMT translation platform, including a phrase-based decoder and most of the current linguistically motivated syntax-based system. Its phrase-based component, which functions very similar to Moses [12], is used as the phrase-based decoder for this campaign. Phrase-based SMT usually adopt a log-linear framework [9]. By introducing the hidden word alignment variable a [10], the optimal translation can be searched for based on the following criterion: ~ M e~ * = arg max( λ h (e~, f , a)) e,a ∑m =1 m m ~ where ~ e is a string of phrases in the target language, f is the ~ source language string of phrases, h (e~, f , a) are feature funcm tions, weights λm are typically optimized to maximize the scoring function [11]. IBM word reordering constraints [13] are applied during decoding to reduce the"
2009.iwslt-evaluation.7,2005.iwslt-1.8,0,0.128635,"] and weighted voting, on all rescoring outputs. The rest of paper is organized as follows. Section 2 presents each individual SMT system used in our framework. Section 3 details the rescoring method. Section 4 describes two system combination strategies: n-gram expansion and weighted voting. Section 5 reports the experimental setups and results while Section 6 concludes the paper. • Distortion model, which assigns a cost linear to the reordering distance, the cost is based on the number of source words which are skipped when translating a new source phrase • Lexicalized word reordering model [14] (RM) • Word and phrase penalties, which count the numbers of words and phrases in the target string The translation model, reordering model and feature weights are trained and optimized using Moses training and tuning toolkits [12]. 2.2. Tranyu: Syntax-based Translation System Tranyu is our another in-house translation platform. It is a formally syntax-based SMT system, which adapts the bracketing transduction grammars (BTG) for phrase translation and reordering. The BTG lexical rules (A --&gt; x/y) are used to translate source phrase x into target phrase y while the BTG merging rules (A --&gt; [A,"
2009.iwslt-evaluation.7,2006.iwslt-papers.4,0,0.0312358,"using boundary words of these examples and finally estimate feature weights. 3. Rescoring Models Rescoring operation plays a very important role in our system. A rich global feature functions set benefits our system greatly. The rescoring models are the same ones which were used in our SMT system for IWSLT 2007 [4]. We apply the following feature functions. Weights of feature functions are optimized by the MERT tool in Moses package. • direct and inverse IBM model 1 and 3 • association scores, i.e. hyper-geometric distribution probabilities and mutual information • lexicalized reordering rule [15] • 6-gram target language model and 8-gram target wordclass based LM, word-classes are clustered by GIZA++ • length ratio between source and target sentence • question feature • Linear sum of n-grams (n=1,2,3,4) relative frequencies within all translations, which favors the hypotheses containing popular n-grams of higher order [16] • Tranyu(LAR). In order to employ more linguistic knowledge in the ITG reordering, we extend boundary word based reordering further by linguistically annotating each node involved in reordering according to the source-side parse tree. We call this linguistically ann"
2009.iwslt-evaluation.7,J93-2003,0,\N,Missing
2009.iwslt-evaluation.7,E06-1005,0,\N,Missing
2009.iwslt-evaluation.7,2007.iwslt-1.8,1,\N,Missing
2009.iwslt-evaluation.7,P09-1036,1,\N,Missing
2009.iwslt-evaluation.7,W06-3110,0,\N,Missing
2009.iwslt-evaluation.7,P06-1066,1,\N,Missing
2009.iwslt-evaluation.7,P08-2038,1,\N,Missing
2009.iwslt-evaluation.7,I08-1066,1,\N,Missing
2009.iwslt-evaluation.7,I05-3025,0,\N,Missing
2009.iwslt-evaluation.7,2005.iwslt-1.11,0,\N,Missing
2009.iwslt-evaluation.7,N06-1014,0,\N,Missing
2009.mtsummit-posters.24,P07-1019,0,0.175412,"cell is p(H) = pin (H) · π(H)λLM where pin (H) is the probability estimated from inside the hypothesis H, λLM is the weight of the language model. Note that this probability is only used for the beam thresholding. 4 Comparison to Previous Work Efficient decoding is of great importance to rapid SMT development and commercial applications. Much of previous work focuses on reducing the overwhelming overhead introduced by the intersection of the m-gram language model and the translation model (phrase-based or syntaxbased). This is the fundamental motivation for cube pruning/growing(Chiang, 2007; Huang and Chiang, 2007), and multi-pass decoding approaches(Venugopal et al., 2007; Zhang and Gildea, 2008). Other efforts have been made for A* decoding using search heuristics (Och et al., 2001; Zhang and Gildea, 2006). The Pharaoh decoder (Koehn, 2004) uses an estimated score of uncovered source sequences as an important component to compare hypotheses. In A* decoding (Och et al., 2001; Zhang and Gildea, 2006), a heuristic function is used to estimate the probability to complete a partial hypothesis. To some extent, both are similar to our LMLA probability. The biggest difference is that we emphasize the effect o"
2009.mtsummit-posters.24,W05-1507,0,0.0135781,"ing to the following two reorderings. If a straight order is preferred (Fig. 2(a)), the language model look-ahead probability πs (H) can be estimated as follows πs (H) = m-gram(T r (s1 ...si−1 ), H l ) ·m-gram(H r , T l (sj+1 ...sn )) where H l/r are the leftmost/rightmost boundary words of H, which both include m0 = min(m − 4 The reason for caching m0 words is to keep the same with what we do for each hypothesis, where m0 words are also stored on the left/right of the hypothesis for the dynamic programming to compute new m-grams in the CKY algorithm intersected with an m-gram language model (Huang et al., 2005). (a) target source 1 i-1 i j j+1 n 1 i-1 i j j+1 n (b) target source Figure 2: Two Reorderings (straight and inverted) for Language Model Look-Ahead. 1, |H|) words. If an inverted order is preferred (Fig. 2(b)), the language model look-ahead probability πi (H) can be estimated as follows πi (H) = m-gram(T r (sj+1 ...sn ), H l ) ·m-gram(H r , T l (s1 ...si−1 )) Since we don’t know which order will be preferred, we take the maximum of the straight and inverted LM look-ahead probability for the hypothesis π(H) = max(πs (H), πi (H)) The final beam thresholding measure for H when compared to the b"
2009.mtsummit-posters.24,2007.mtsummit-papers.43,0,0.0213044,"re of the full uncovered source sequence for both threshold pruning and histogram pruning (the latter). The Pharaoh-style “future cost” can not provide any discriminative information for our pruning since we compare competing hypotheses within the same cell (This means that they have the same future cost). We remains the same as the Pharaoh decoder to find the most probable path through translation options for source words that are not yet translated. But we go further to take into account the interaction of current hypotheses and the most probable path for not yet translated source sequence. Moore and Quirk (2007) present two modifications for beam-search decoding, the Pharaoh decoder in particular by improving the future cost estimation and early pruning out next-phrase translations. Their success and the high efficiency of our beam thresholding methods (verified by experiments in the next section) show that there is much room for search space reduction in widely-used beam-search decoding. 5 Experiments We carried out a series of experiments to examine the effect of our beam thresholding techniques by comparing them with the fixed beam thresholding as well as the cube pruning, and also by combining al"
2009.mtsummit-posters.24,W01-1408,0,0.0611538,"arly stage of decoding. We call this pruning strategy dynamic beam thresholding (DBT). DBT increases the parameter α to tighten the beam when more source words covered. In theory, DBT runs faster than traditional beam thresholding FBT at the same performance level, as our experiments attest. 3 Language Model Look-ahead In traditional beam thresholding used in SMT decoding, only the probability estimated from inside a partial hypothesis is used. This probability does not give information about the probability of the hypothesis in the context of the complete translation. In A* decoding for SMT (Och et al., 2001; Zhang and Gildea, 2006), different heuristic functions are used to estimate a “future” probability for completing a partial hypothesis. In CKY bottom-up parsing, (Goodman, 1997) introduces a prior probability into the beam thresholding. All of these probabilities are capable of capturing the outside context interaction, to some extent. In this paper, we discuss the LM look-ahead (LMLA) and examine the question of whether, given the complicated reordering in SMT, the LM lookahead can obtain a considerable speedup in SMT decoding. The basic idea of the LM look-ahead is to incorporate the langu"
2009.mtsummit-posters.24,P02-1040,0,0.105792,"Missing"
2009.mtsummit-posters.24,N03-1017,0,0.0224318,"Missing"
2009.mtsummit-posters.24,P96-1021,0,0.0346546,"Missing"
2009.mtsummit-posters.24,J97-3002,0,0.0947939,"r success and the high efficiency of our beam thresholding methods (verified by experiments in the next section) show that there is much room for search space reduction in widely-used beam-search decoding. 5 Experiments We carried out a series of experiments to examine the effect of our beam thresholding techniques by comparing them with the fixed beam thresholding as well as the cube pruning, and also by combining all these pruning approaches step by step. We tested them on a Chinese-to-English system with a CKYstyle decoder. The system is based on the Bracketing Transduction Grammars (BTG) (Wu, 1997), which uses the BTG lexical rules (A → x/y) to translate source phrase x into target phrase y and the BTG merging rules (A → [A, A]|hA, Ai) to combine two neighboring phrases with a straight or inverted order. The BTG lexical rules are weighted with several features, such as phrase translation, word penalty and language model, in a log-linear form. For the merging rules, a MaxEnt-based reordering model using boundary words of neighboring phrases as features is used to predict the merging order, similar to (Xiong et al., 2006). All the log-linear model weights are tuned on the development set"
2009.mtsummit-posters.24,P06-1066,1,0.833241,"e decoder. The system is based on the Bracketing Transduction Grammars (BTG) (Wu, 1997), which uses the BTG lexical rules (A → x/y) to translate source phrase x into target phrase y and the BTG merging rules (A → [A, A]|hA, Ai) to combine two neighboring phrases with a straight or inverted order. The BTG lexical rules are weighted with several features, such as phrase translation, word penalty and language model, in a log-linear form. For the merging rules, a MaxEnt-based reordering model using boundary words of neighboring phrases as features is used to predict the merging order, similar to (Xiong et al., 2006). All the log-linear model weights are tuned on the development set to maximize the BLEU score. A CKY-style decoder is developed to generate the best BTG binary tree for each input sentence, which yields the best translation. We used the FBIS corpus (7.06M Chinese words and 9.15M English words) as our bilingual training data, from which a MaxEnt-based reordering model was also trained. The 4-gram language model training data (181.1M words) consists of English texts mostly derived from Xinhua section of the English Gigaword corpus. We used the NIST MT-05 as our test set (27.4 words per sentence"
2009.mtsummit-posters.24,C04-1030,0,0.0441255,"Missing"
2009.mtsummit-posters.24,W06-1627,0,0.0762381,"ding. We call this pruning strategy dynamic beam thresholding (DBT). DBT increases the parameter α to tighten the beam when more source words covered. In theory, DBT runs faster than traditional beam thresholding FBT at the same performance level, as our experiments attest. 3 Language Model Look-ahead In traditional beam thresholding used in SMT decoding, only the probability estimated from inside a partial hypothesis is used. This probability does not give information about the probability of the hypothesis in the context of the complete translation. In A* decoding for SMT (Och et al., 2001; Zhang and Gildea, 2006), different heuristic functions are used to estimate a “future” probability for completing a partial hypothesis. In CKY bottom-up parsing, (Goodman, 1997) introduces a prior probability into the beam thresholding. All of these probabilities are capable of capturing the outside context interaction, to some extent. In this paper, we discuss the LM look-ahead (LMLA) and examine the question of whether, given the complicated reordering in SMT, the LM lookahead can obtain a considerable speedup in SMT decoding. The basic idea of the LM look-ahead is to incorporate the language model interaction of"
2009.mtsummit-posters.24,P08-1025,0,0.0186269,"side the hypothesis H, λLM is the weight of the language model. Note that this probability is only used for the beam thresholding. 4 Comparison to Previous Work Efficient decoding is of great importance to rapid SMT development and commercial applications. Much of previous work focuses on reducing the overwhelming overhead introduced by the intersection of the m-gram language model and the translation model (phrase-based or syntaxbased). This is the fundamental motivation for cube pruning/growing(Chiang, 2007; Huang and Chiang, 2007), and multi-pass decoding approaches(Venugopal et al., 2007; Zhang and Gildea, 2008). Other efforts have been made for A* decoding using search heuristics (Och et al., 2001; Zhang and Gildea, 2006). The Pharaoh decoder (Koehn, 2004) uses an estimated score of uncovered source sequences as an important component to compare hypotheses. In A* decoding (Och et al., 2001; Zhang and Gildea, 2006), a heuristic function is used to estimate the probability to complete a partial hypothesis. To some extent, both are similar to our LMLA probability. The biggest difference is that we emphasize the effect of the language model interaction on the beam thresholding. We neither use the LMLA p"
2009.mtsummit-posters.25,P05-1033,0,0.506363,"be our future work. To calculate P r(hc ), we use a source dependency model. The challenge to our source dependency model is the acquisition of training data: source dependency trees. The source dependency tree used for training has to satisfy two conditions: 1) it is not necessarily linguistically sensible; and 2) it is produced under bilingual context. We observe that we can obtain such dependency trees from word alignments because word alignments implicitly contain hierarchical structures of both source and target language. 1 We inherit the definition of the formally syntax-based MT from (Chiang, 2005). It refers to syntax-based MT which uses synchronous CFG with no linguistic commitment. To uncover the hidden structures from word alignments, we adopt the algorithm of (Zhang et al., 2008). The algorithm decomposes word-aligned sentence pairs into hierarchical trees where leaf nodes are permuted from left to right according to the target language word order. From these trees, we extract the normalized source trees. In order to obtain dependency relations of source words, we annotate nodes with head words and labels. Without introducing conflict with the original definition of dependency tree"
2009.mtsummit-posters.25,D08-1024,0,0.0133445,"et dependency trees in a similar way as the source dependency trees to produce a target dependency model. This is different from (Shen et al., 2008)’s way of inducing a target dependency language model in that we do not require an external dependency parser. 7 Related Work In the formally syntax-based machine translation, Chiang (2005) propose to add a “constituent feature” to the log-linear model in order to reward hypotheses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. All the prior work listed a"
2009.mtsummit-posters.25,P06-1121,0,0.0122002,"ses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. All the prior work listed above requires linguistically motivated parsing. The big distinction from their work is that we build our source dependency model from word alignments without using any monolingual parsing. 8 Conclusion We have presented a novel method to induce a source dependency model from word alignments without using any linguistic analysis. The induced source dependency model captures dependency relations among source words. We employ"
2009.mtsummit-posters.25,2006.amta-papers.8,0,0.0824804,"nstituent feature” to the log-linear model in order to reward hypotheses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. All the prior work listed above requires linguistically motivated parsing. The big distinction from their work is that we build our source dependency model from word alignments without using any monolingual parsing. 8 Conclusion We have presented a novel method to induce a source dependency model from word alignments without using any linguistic analysis. The induced source depend"
2009.mtsummit-posters.25,W04-3250,0,0.0525472,"ns, and applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to produce the final many-to-many word alignments. We trained a fourgram language model using Xinhua section of the English Gigaword corpus (181.1M words) with the SRILM toolkit (Stolcke, 2002). For the efficiency of MERT, we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST MT-02 set. We evaluated our systems on the NIST MT-05 and MT03 test sets using case-sensitive BLEU-4. Statistical significance in BLEU score differences was assessed by paired bootstrap re-sampling (Koehn, 2004). 5.2 Source Dependency Model Training Because SRA runs very quickly, which produces within a few minutes all decomposition trees from our word-aligned sentence pairs, we can easily train various source dependency models following the steps described in Section 2. In order to allow the normalization step to keep more source words, we removed less probable links in word alignments. First, we calculate lexicon translation probabilities in both directions (P r(C|E) and P r(E|C)) from the original word alignments. Then we search on the source side or the target side for words which are involved in"
2009.mtsummit-posters.25,2005.iwslt-1.8,0,0.0606032,"Missing"
2009.mtsummit-posters.25,P06-1077,0,0.0610526,"opose to add a “constituent feature” to the log-linear model in order to reward hypotheses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. All the prior work listed above requires linguistically motivated parsing. The big distinction from their work is that we build our source dependency model from word alignments without using any monolingual parsing. 8 Conclusion We have presented a novel method to induce a source dependency model from word alignments without using any linguistic analysis. The i"
2009.mtsummit-posters.25,W06-1606,0,0.0217437,"idden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. All the prior work listed above requires linguistically motivated parsing. The big distinction from their work is that we build our source dependency model from word alignments without using any monolingual parsing. 8 Conclusion We have presented a novel method to induce a source dependency model from word alignments without using any linguistic analysis. The induced source dependency model captures dependency relations among source words. We employ this new model in M"
2009.mtsummit-posters.25,P08-1114,0,0.190728,"ethod, we can also obtain target dependency trees in a similar way as the source dependency trees to produce a target dependency model. This is different from (Shen et al., 2008)’s way of inducing a target dependency language model in that we do not require an external dependency parser. 7 Related Work In the formally syntax-based machine translation, Chiang (2005) propose to add a “constituent feature” to the log-linear model in order to reward hypotheses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. A"
2009.mtsummit-posters.25,P00-1056,0,0.223357,"e do not expand the search space which the original decoder has to explore. These two simplifications greatly reduce potential workload caused by introducing a dependency model into decoding. 5 Experiments We carried out experiments to examine the effect of the source dependency model on Chinese-to-English translation tasks. 5.1 Experimental Setup Our baseline is a formally syntax-based system using BTG, developed by following (Xiong et al., 2006). The training data is from FBIS corpus, which contains 6.59M Chinese words and 8.04M English words. To obtain word-level alignments, we ran GIZA++ (Och and Ney, 2000) on the corpus in both directions, and applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to produce the final many-to-many word alignments. We trained a fourgram language model using Xinhua section of the English Gigaword corpus (181.1M words) with the SRILM toolkit (Stolcke, 2002). For the efficiency of MERT, we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST MT-02 set. We evaluated our systems on the NIST MT-05 and MT03 test sets using case-sensitive BLEU-4. Statistical significance in BLEU score differences was assessed by"
2009.mtsummit-posters.25,P02-1038,0,0.0688259,"ation tasks. 1 P r(h) ≈ P r(hc )P r(he ) Introduction In the word-based translation model introduced by IBM (Brown et al., 1993), the hidden variable, word alignment, associates the source sentence (c) with the target sentence (e). This model has been advanced to the phrase-based and syntax-based models, and the hidden variable has also been transformed into new forms: phrase alignment in phrasebased translation and hierarchical tree in syntaxbased translation. In all cases, we can search the best translation among all possible target sentences and hidden variables through a log-linear model (Och and Ney, 2002) eˆ = argmax(Σi λi fi (c, h, e)) (1) e,h where fi are feature functions which are dependent not only on c and e but also on the hidden variable h. (2) where hc and he are the tree projections of h on the source and target side respectively. Without loss of generality, we discuss P r(h) within the context of Bracketing Transduction Grammar (BTG) (Wu, 1997), which is a binary synchronous CFG widely adopted in machine translation. We focus on P r(hc ) in this paper and leave the modeling of P r(he ) to be our future work. To calculate P r(hc ), we use a source dependency model. The challenge to o"
2009.mtsummit-posters.25,P03-1021,0,0.00596905,"orpus. To deal with the data sparseness problem, we smooth the two probabilities through Witten-Bell interpolation, similar to (Collins, 1999). Table 2 shows the back-off structures for the smoothing. Further, for words occurring less than 5 times in training data, and words in test data which have never been seen in training, we replace them with the ”UNKNOWN” token. As described in the introduction, P r(hc ) is integrated into the log-linear translation model as a new feature. The weight of this new feature, like the weights of other features, is tuned via minimumerror-rate training (MERT) (Och, 2003) on a development set. 4 Decoding with Source Dependency Model Since we use a bottom-up CKY parsing algorithm for decoding, computing the source dependency model score is quite straightforward. When a new node of the hierarchical tree hc is being constructed, we use the predefined POS tag weight table (Table 1) to determine the head. If the BTG lexical rule (A → x/y) is used to produce a leaf node upon a source span, we select the rightmost source word with the highest POS tag weight within the source span as the head word for the leaf node. If the BTG merging rules (A → [A, A]|hA, Ai) are use"
2009.mtsummit-posters.25,P08-1066,0,0.0406647,"ildea, 2005). It is clearly shown in the experiments that noises in word alignments influence the performance of SDM considerably. To address this problem, we would explore hierarchical alignments as they contain hierarchical structures intrinsically and would enable us to obtain high quality source dependency trees without using complicated transformation. • Induce a target dependency model from word alignments. Based on our proposed method, we can also obtain target dependency trees in a similar way as the source dependency trees to produce a target dependency model. This is different from (Shen et al., 2008)’s way of inducing a target dependency language model in that we do not require an external dependency parser. 7 Related Work In the formally syntax-based machine translation, Chiang (2005) propose to add a “constituent feature” to the log-linear model in order to reward hypotheses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance signifi"
2009.mtsummit-posters.25,J97-3002,0,0.186934,"orms: phrase alignment in phrasebased translation and hierarchical tree in syntaxbased translation. In all cases, we can search the best translation among all possible target sentences and hidden variables through a log-linear model (Och and Ney, 2002) eˆ = argmax(Σi λi fi (c, h, e)) (1) e,h where fi are feature functions which are dependent not only on c and e but also on the hidden variable h. (2) where hc and he are the tree projections of h on the source and target side respectively. Without loss of generality, we discuss P r(h) within the context of Bracketing Transduction Grammar (BTG) (Wu, 1997), which is a binary synchronous CFG widely adopted in machine translation. We focus on P r(hc ) in this paper and leave the modeling of P r(he ) to be our future work. To calculate P r(hc ), we use a source dependency model. The challenge to our source dependency model is the acquisition of training data: source dependency trees. The source dependency tree used for training has to satisfy two conditions: 1) it is not necessarily linguistically sensible; and 2) it is produced under bilingual context. We observe that we can obtain such dependency trees from word alignments because word alignment"
2009.mtsummit-posters.25,P06-1066,1,0.892645,"orcedly assigned according to POS tag weights. No probability is involved in this decision. Second, we do not add the head word to the state of hypothesis. This means we do not expand the search space which the original decoder has to explore. These two simplifications greatly reduce potential workload caused by introducing a dependency model into decoding. 5 Experiments We carried out experiments to examine the effect of the source dependency model on Chinese-to-English translation tasks. 5.1 Experimental Setup Our baseline is a formally syntax-based system using BTG, developed by following (Xiong et al., 2006). The training data is from FBIS corpus, which contains 6.59M Chinese words and 8.04M English words. To obtain word-level alignments, we ran GIZA++ (Och and Ney, 2000) on the corpus in both directions, and applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to produce the final many-to-many word alignments. We trained a fourgram language model using Xinhua section of the English Gigaword corpus (181.1M words) with the SRILM toolkit (Stolcke, 2002). For the efficiency of MERT, we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST M"
2009.mtsummit-posters.25,C08-1136,0,0.0711919,"The source dependency tree used for training has to satisfy two conditions: 1) it is not necessarily linguistically sensible; and 2) it is produced under bilingual context. We observe that we can obtain such dependency trees from word alignments because word alignments implicitly contain hierarchical structures of both source and target language. 1 We inherit the definition of the formally syntax-based MT from (Chiang, 2005). It refers to syntax-based MT which uses synchronous CFG with no linguistic commitment. To uncover the hidden structures from word alignments, we adopt the algorithm of (Zhang et al., 2008). The algorithm decomposes word-aligned sentence pairs into hierarchical trees where leaf nodes are permuted from left to right according to the target language word order. From these trees, we extract the normalized source trees. In order to obtain dependency relations of source words, we annotate nodes with head words and labels. Without introducing conflict with the original definition of dependency tree, we call the annotated tree obtained from the above steps source dependency tree. Using these source dependency trees, we develop our source dependency model. To the best of our knowledge,"
2009.mtsummit-posters.25,2007.mtsummit-papers.71,1,0.770567,"o the log-linear model in order to reward hypotheses under which the hidden hierarchical tree h respects linguistic structures of source language. While no success is seen with this feature, (Marton and Resnik, 2008) and (Chiang et al., 2008) advance this effort and find that penalizing violations of syntactic boundaries of source language improves performance significantly. In the realm of linguistically syntax-based machine translation, the hidden hierarchical tree becomes more visible because it is explicitly constructed using source-language grammars (Liu et al., 2006; Huang et al., 2006; Zhang et al., 2007) or target-language grammars (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008). The modeling of h is tightly coupled with the probabilistic source/target-oriented synchronous grammars. All the prior work listed above requires linguistically motivated parsing. The big distinction from their work is that we build our source dependency model from word alignments without using any monolingual parsing. 8 Conclusion We have presented a novel method to induce a source dependency model from word alignments without using any linguistic analysis. The induced source dependency model captures d"
2020.acl-main.80,P13-2037,0,0.161584,"xample of codeswitching or code-mixing (henceforth, CS), where a bilingual speaker alternates words of two or more languages within a single sentence. The switches could happen at sentence boundaries or word boundaries and for some agglutinative languages even within words. Code-switching is common in both spoken and, to some extent, written communication in many multilingual societies, such as Southeast Asia. Hence, the study of codeswitch in linguistics and bilingual language modeling is becoming imperative, especially for NLP tasks such as code-switching automatic speech recognition (ASR) (Adel et al., 2013b; Li and Fung, 2013; Lee et al., 2019), cross-lingual language normalization. It is tempting to think that, given enough of codeswitching text data, bilingual language modeling could be approached in the same way as that for monolingual data. The main challenge is the lack of such CS data. We note that CS mainly occurs in the spoken form, and CS does not occur in every sentence. Therefore, collecting enough pure CS data is just not practical or even feasible (Lee et al., 2017; Pratapa et al., 2018). The problem is further exacerbated by the syntactic constraints of the two diverse languages,"
2020.acl-main.80,P17-1042,0,0.0157047,"g words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntactic constraints for CS as formulated in the Equivalence Constraint theory, thus not making full use of the information which could potentially improve their performance. Code-switching modeling: Another school of thoughts is to extend the monolingual language modeling technique to accommod"
2020.acl-main.80,P18-1073,0,0.0116135,"ate the idea. 2 Related Work Several prior studies related to bilingual language modeling are the inspiration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntactic constraints for CS as formulated in the Equivalence Constraint theory, thus not making full"
2020.acl-main.80,Q17-1010,0,0.0604292,"Missing"
2020.acl-main.80,W08-0336,0,0.0241996,"Missing"
2020.acl-main.80,P19-1285,0,0.0442012,"Missing"
2020.acl-main.80,N19-1423,0,0.0104966,"nsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntactic constraints for CS as formulated in the Equivalence Constraint theory, thus not making full use of the information which could potentially improve their performance. Code-switching modeling: Another school of thoughts is to extend the monolingual language modeling technique to accommodate code-switch content. Adel et al. (2013b, 2014) use factored language models and recurrent neural network (RNN) language model to improve the bilingual language model for CS ASR rescoring. They include additional linguistic information"
2020.acl-main.80,D15-1127,0,0.0614867,"Missing"
2020.acl-main.80,N13-1073,0,0.094797,"ˆ l1 = arg max w ble 1 is used for training and the same dictionary2 is used for testing for all models. l {wt1 } VecMap3 (Artetxe et al., 2018) is a projection based CLWE alignment method which gives robust results using a unsupervised strategy (Glavaˇs et al., 2019). The respective monolingual embeddings are trained using fastText4 (Bojanowski et al., 2017) with the default setup and 384 dimensions. The two monolingual embedding space are then mapped using the VecMap. BiSkip5 (Luong et al., 2015) is jointly trained with word alignment constraint. We prepare the alignment using fast align6 (Dyer et al., 2013) following the similar procedure outlined in the paper. For the BALM model, we use the embedding from the model without the SEAME adaptation phase for a fair comparison. These three models represent three distinct categories in CLWE implementation, i.e. projection-based, jointly learned, and deep learning based embedding for VecMap, BiSkip and BALM, respectively. 2 https://github.com/facebookresearch/MUSE#groundtruth-bilingual-dictionaries 3 https://github.com/artetxem/vecmap 4 https://github.com/facebookresearch/fastText 5 https://github.com/lmthang/bivec 6 https://github.com/clab/fast align"
2020.acl-main.80,E14-1049,0,0.0260586,"d to bilingual language modeling are the inspiration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntactic constraints for CS as formulated in the Equivalence Constraint theory, thus not making full use of the information which could potentially improve th"
2020.acl-main.80,P19-1070,0,0.0319711,"Missing"
2020.acl-main.80,D19-1427,0,0.26961,"Missing"
2020.acl-main.80,E17-2098,0,0.0202112,"pondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntactic constraints for CS as formulated in the Equivalence Constraint theory, thus not making full use of the information which could potentially improve their performance. Code-switching modeling: Another school of thoughts is to extend th"
2020.acl-main.80,P14-1006,0,0.0298633,"orms the best reported result on the SEAME dataset in the perplexity test. We also successfully apply BALM in bilingual lexicon induction, and language normalization tasks to validate the idea. 2 Related Work Several prior studies related to bilingual language modeling are the inspiration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et"
2020.acl-main.80,E17-1072,0,0.0121924,"fully apply BALM in bilingual lexicon induction, and language normalization tasks to validate the idea. 2 Related Work Several prior studies related to bilingual language modeling are the inspiration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntacti"
2020.acl-main.80,D14-1098,0,0.0171687,"not making full use of the information which could potentially improve their performance. Code-switching modeling: Another school of thoughts is to extend the monolingual language modeling technique to accommodate code-switch content. Adel et al. (2013b, 2014) use factored language models and recurrent neural network (RNN) language model to improve the bilingual language model for CS ASR rescoring. They include additional linguistic information such as Partof-Speech, language identifier to improve model generalization. Inversion constraints (Li and Fung, 2013) and Functional Head constraints (Li and Fung, 2014) are also used in language models for the ASR decoding process. Lee and Li (2019) use cross-lingual embedding to tie the input and output layer, and incorporate classes in the RNN language model. While these models are effective, they rely on the availability of CS training data. Therefore, they are not easily scalable. To address this, we propose a way to make use of the existing abundant parallel corpora. The method will be explained in Section 3.3. Code-switching text generation: Closer to our line of research, Pratapa et al. (2018) propose to use synthetic data following the Equivalence Co"
2020.acl-main.80,L16-1147,0,0.0240536,"d as Adapt, Valid and Test respectively in Table 1. Such split also ensures that the individual component within the Test data, e.g. Test EN, is of sufficient size. Additionally, we also split the dataset following approximately the same proportion as in the previous works (Winata et al., 2019; Lee et al., 2019) for a fair benchmarking, labeled as Train, Dev, and Eval respectively. We use a random split of 1.1M/60.8K/60.3K for the number of tokens in Train/Dev/Eval as compared to 1.2M/65K/60K in the previous works. We use a bilingual parallel corpus from Ted and OpenSubtitle (Tiedemann, 2012; Lison and Tiedemann, 2016) for BALM training because they are text transcripts of spontaneous speech similar to SEAME. The English text is tokenized using NLTK tokenizer (Bird et al., 2009) while the Chinese text is tokenized using Stanford Word Segmenter (Chang et al., 2008). We also develop a test set of 200 sentences for language normalization experiments, labeled as SEAME Norm. 4.2 Experimental Setup We conduct a series of experiments, namely BALM, Synthetic CS, CS-Only, and Mono, using the same BALM network architecture to evaluate different modeling strategies. During training, we construct a 50K vocabulary consi"
2020.acl-main.80,W15-1521,0,0.123419,"lt on the SEAME dataset in the perplexity test. We also successfully apply BALM in bilingual lexicon induction, and language normalization tasks to validate the idea. 2 Related Work Several prior studies related to bilingual language modeling are the inspiration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (L"
2020.acl-main.80,J03-1002,0,0.0251347,"ains at the utterance level. We first train the BALM on the parallel corpus as described in Section 3.4. The trained network is then adapted with SEAME Adapt to bridge the domain gap, namely from l1 l2 → l1 and l1 l2 → l2 towards l1 l2 → l1 l2 . Synthetic CS In this contrastive experiment, we remove the bilingual constraint, i.e. equation 4, from BALM, and use offline synthetic CS text outlined in Lee et al. (2019) in the training. The idea of synthetic CS is motivated by the Matrix Language Frame theory. The phrase alignment is performed on the same parallel dataset in Table 1, using Giza++ (Och and Ney, 2003). The aligned parallel sentences are then used to randomly switch phrases between the languages according to an empirical probability of 0.7. At the same, time the phrase table is used to inhibit switch within frequently occurring phrases. We train the same BALM network with both the synthetic CS data and the monolingual side of the parallel data. The model is finally adapted with SEAME Adapt. Mono & CS-Only In the Mono setting, we simply use parallel corpus as two independent monolingual corpora without any form of bilingual constraint. The monolingual sentences are passed alternating between"
2020.acl-main.80,P19-1493,0,0.0391669,"Missing"
2020.acl-main.80,P18-1143,0,0.533299,"ing imperative, especially for NLP tasks such as code-switching automatic speech recognition (ASR) (Adel et al., 2013b; Li and Fung, 2013; Lee et al., 2019), cross-lingual language normalization. It is tempting to think that, given enough of codeswitching text data, bilingual language modeling could be approached in the same way as that for monolingual data. The main challenge is the lack of such CS data. We note that CS mainly occurs in the spoken form, and CS does not occur in every sentence. Therefore, collecting enough pure CS data is just not practical or even feasible (Lee et al., 2017; Pratapa et al., 2018). The problem is further exacerbated by the syntactic constraints of the two diverse languages, such as Chinese and English. Three dominant theories seek to explain the syntactic formation of CS sentences. They are the Matrix Language Frame theory (Myers-Scotton, 1997), which shows that individual monolingual sentences will conform to the grammar of the matrix language. The Equivalence Constraint theory (Poplack, 2000; Sankoff, 1998), which further constrains the intra-sentential CS points to the syntactic boundaries shared by both languages, and the Functional Head Constraint theory (Di Sciul"
2020.acl-main.80,P98-1002,0,0.516771,"e spoken form, and CS does not occur in every sentence. Therefore, collecting enough pure CS data is just not practical or even feasible (Lee et al., 2017; Pratapa et al., 2018). The problem is further exacerbated by the syntactic constraints of the two diverse languages, such as Chinese and English. Three dominant theories seek to explain the syntactic formation of CS sentences. They are the Matrix Language Frame theory (Myers-Scotton, 1997), which shows that individual monolingual sentences will conform to the grammar of the matrix language. The Equivalence Constraint theory (Poplack, 2000; Sankoff, 1998), which further constrains the intra-sentential CS points to the syntactic boundaries shared by both languages, and the Functional Head Constraint theory (Di Sciullo et al., 1986; Belazi et al., 1994) that imposes constraints on the functional head and its 1 English: The movie last night ( ) 860 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 860–870 c July 5 - 10, 2020. 2020 Association for Computational Linguistics complements. A bilingual language model should be able to predict a word, either in the matrix language or otherwise, given either a"
2020.acl-main.80,tiedemann-2012-parallel,0,0.0518037,"portions, labeled as Adapt, Valid and Test respectively in Table 1. Such split also ensures that the individual component within the Test data, e.g. Test EN, is of sufficient size. Additionally, we also split the dataset following approximately the same proportion as in the previous works (Winata et al., 2019; Lee et al., 2019) for a fair benchmarking, labeled as Train, Dev, and Eval respectively. We use a random split of 1.1M/60.8K/60.3K for the number of tokens in Train/Dev/Eval as compared to 1.2M/65K/60K in the previous works. We use a bilingual parallel corpus from Ted and OpenSubtitle (Tiedemann, 2012; Lison and Tiedemann, 2016) for BALM training because they are text transcripts of spontaneous speech similar to SEAME. The English text is tokenized using NLTK tokenizer (Bird et al., 2009) while the Chinese text is tokenized using Stanford Word Segmenter (Chang et al., 2008). We also develop a test set of 200 sentences for language normalization experiments, labeled as SEAME Norm. 4.2 Experimental Setup We conduct a series of experiments, namely BALM, Synthetic CS, CS-Only, and Mono, using the same BALM network architecture to evaluate different modeling strategies. During training, we cons"
2020.acl-main.80,W18-3207,0,0.046192,"Missing"
2020.acl-main.80,K19-1026,0,0.487536,"t parallel corpora. The method will be explained in Section 3.3. Code-switching text generation: Closer to our line of research, Pratapa et al. (2018) propose to use synthetic data following the Equivalence Constraint theory, while Lee et al. (2019) apply the Matrix Language Frame theory. In their works, a parser or an aligner is required to process the parallel corpus, which is followed by the standard monolingual language modeling process. Such techniques suffer from inaccurate alignment or parsing errors. These errors will be carried forward when training the language model. More recently, Winata et al. (2019) propose a technique to generate neuralbased synthetic data using parallel sentences, in which a Point-Gen network is used to synthesize CS data without external aligner or parser. In this paper, we propose to learn the bilingual context and the CS language model jointly by attending to the parallel sentences directly without the need for an external aligner, parser or explicitly generating the synthetic data. 861 3 Bilingual Attention Language Model Next, we discuss the motivation and the theoretical formulation of the proposed Bilingual Attention Language Model (BALM). In a bilingual text, w"
2020.acl-main.80,N16-1156,0,0.0185872,"piration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques, such as MBERT (Devlin et al., 2019) and XLM (Lample and Conneau, 2019), do not explicitly model the syntactic constraints for CS as formulated in the Equivalence Constraint theory, thus not making full use of the information which could potentially improve their performance. Code-switching modeling:"
2020.acl-main.80,D13-1141,0,0.042259,"S data, it outperforms the best reported result on the SEAME dataset in the perplexity test. We also successfully apply BALM in bilingual lexicon induction, and language normalization tasks to validate the idea. 2 Related Work Several prior studies related to bilingual language modeling are the inspiration for this work. Cross-lingual correspondence: Several studies are focused on projecting words of different languages onto the common embedding space to establish cross-lingual correspondence. One idea is to train a model using bilingual information from corpora aligned at the sentence level (Zou et al., 2013; Hermann and Blunsom, 2014; Luong et al., 2015) and document level (Vulic and Moens, 2016; Levy et al., 2017). Another is to exploit the isomorphic structure (Conneau et al., 2017; Artetxe et al., 2018), dictionary (Mikolov et al., 2013; Faruqui and Dyer, 2014; Huang et al., 2015; Zhang et al., 2016), shared cognate, vocab (Hauer et al., 2017; Smith et al., 2017), numeral (Artetxe et al., 2017) through ad-hoc projection. As the above approaches do not explicitly consider the sequential dependency of words, the embedding doesn’t encode the word ordering information. The multilingual techniques"
2021.acl-long.402,S14-2010,0,0.0652846,"Missing"
2021.acl-long.402,S16-1081,0,0.034663,"Missing"
2021.acl-long.402,S12-1051,0,0.0128858,", 2018), and sentence BERT/RoBERTa (SBERT/SRoBERTa) (Reimers and Gurevych, 2019), which are all trained on the SNLI and MultiNLI datasets. To adapt BSL to a supervised learning setting, we first train a SBERT (SRoBERTa) model and then use the learned weights to initialize the online and target networks of BSL and perform BSL training. We denote this model variant as BSL-SBERT (BSL-SRoBERTa). 4.1 Semantic Textual Similarity (STS) Hyperparameter We tune learning rate, batch size, momentum δ, and the hyperparameter k on SentEval contains a suite of STS datasets including the STS tasks 2012-2016 (Agirre et al., 2012, 2013, 2014, 2015, 2016), the STS benchmark (STSB) (Cer et al., 2017), and the SICK-Relatedness dataset (Marelli et al., 2014). These datasets con1 We use Google translation engine. The datasets are released. 2 Hyperparameters and implementation details are attached in Appendix A 5171 Model STS-12 STS-13 STS-14 STS-15 STS-16 STS-B SICK-R Avg. Unsupervised methods Unigram-TFIDF† SDAE† SkipThought† FastSent† GloVe avg.‡ BERT avg.‡ BERT [CLS]‡ BERT-mlm IS-BERT∗ BERT-flow◦ 55.14 38.78 20.16 48.86 56.77 59.54 70.66 57.98 30.01 64.76 69.24 64.69 58.00 12.00 27.00 63.00 59.73 57.98 20.09 56.97 61.21"
2021.acl-long.402,S13-1004,0,0.0606656,"Missing"
2021.acl-long.402,D15-1075,0,0.0183507,"able to outperform strong multilingual baselines on cross-lingual STS tasks under both unsupervised and supervised settings. Detailed analysis of a few factors that could affect the model performance is provided as well to motivate future research. 2 2.1 Related Work Sentence Representation Learning Prior approaches for sentence representation learning include two main categories – supervised and unsupervised methods, while a few works might leverage on both of them. Most of the supervised methods are trained on labeled natural language inference (NLI) datasets including Stanford NLI (SNLI) (Bowman et al., 2015) and MultiNLI (Williams et al., 2018). Early methods demonstrate good performance on a wide range of tasks (Conneau et al., 2017; Cer et al., 2018). Recently, SBERT (Reimers and Gurevych, 2019) fine-tuned a pre-trained Siamese BERT network on NLI and demonstrated the state-of-the-art performance. Though effective, those methods highly rely on labeled data and could be problematic to port to new domains. Zhang et al. (2020) showed that SBERT generalizes poorly on target tasks with a data distribution significantly different from the NLI data. There are also fruitful outcomes for unsupervised me"
2021.acl-long.402,S17-2001,0,0.167326,"ate the flexibility of the proposed method, we further extend it for learning multilingual sentence representations and evaluate it on cross-lingual STS tasks. Implementation The MLP contains three linear layers. Given an input vector of dimension d, the output dimensions of the three layers are kd → kd → d, where k is a hyperparameter controlling the hidden size. Batch normalization and rectified linear units (ReLU) are applied to the intermediate linear layers. We use BERT-base or RoBERTabase to initialize the online and target networks in monolingual settings. the development set of STS-B (Cer et al., 2017). For all unsupervised experiments, we set learning rate to 5e-4, momentum to 0.999, and k to 8. Adam (Kingma and Ba, 2015) is used as the optimizer. 2 Baselines Under a unsupervised learning setting, we compare to the unigram-TFIDF model, the Sequential Denoising Auto-Encoder (SDAE) (Hill et al., 2016), the Skipthought (Kiros et al., 2015) and FastSent (Hill et al., 2016). Those models are all trained on the Toronto book corpus with 70M sentences (Zhu et al., 2015). We also compare with sentence representations obtained with the average of GloVe embeddings (GloVe avg.), the average of BERT em"
2021.acl-long.402,D18-2029,0,0.0353875,"Missing"
2021.acl-long.402,W19-4330,0,0.0157668,"sentence representations and the gold labels. ρ*100 is reported. Results of baselines are obtained from (Reimers and Gurevych, 2020). ods from (Reimers and Gurevych, 2020): mBERT/ XLM-R-nli-stsb denotes the setting where we fine-tune XLM-R and mBERT on the English NLI and the English training set of the STS benchmark (STS-B); mBERT- /XLM-R ← SBERT-nli-stsb is the knowledge-distillation method proposed in their paper where we learn mBERT and XLM-R to imitate the output of the English SBERT trained on NLI and STS-B with multilingual parallel sentence pairs. We also compared to results of mUSE (Chidambaram et al., 2019) and LaBSE (Feng et al., 2020), which use dual encoder transformer architectures. mUSE was trained on question-answer pairs, SNLI, translated SNLI data, and parallel corpora over 16 languages. LaBSE was trained on 6 billion translation pairs for 109 languages. For BSL, we initialize our online and target networks with the learned weights from XLM-R ← SBERTnli-stsb3 and then perform BSL training in a same way as described above. We denote our model in this setting as BSL-sup. Table 3 presents the results. Under the unsupervised setting, averaging the multilingual token representations yields po"
2021.acl-long.402,2020.acl-main.747,0,0.0833826,"Missing"
2021.acl-long.402,L18-1269,0,0.0597938,"imizing a predefined prediction loss. As for the target network, we apply a stop-gradient strategy (Chen and He, 2020) and update it with a weighted moving average of the online network. Hence, the outputs of the target network are iteratively bootstrapped to serve as targets, enabling enhanced representation learning of the online network while avoiding trivial solutions. Our method is evaluated through extensive experiments. Empirical results show that BSL significantly outperforms strong unsupervised baselines on a standard suite of STS and classification tasks from the SentEval benchmark (Conneau and Kiela, 2018). We also demonstrate that BSL can serve as an effective post-training approach to boost the performance of the state-of-the-art supervised SBERT model. We further extend our method for learning multilingual sentence representations and demonstrate that it is able to outperform strong multilingual baselines on cross-lingual STS tasks under both unsupervised and supervised settings. Detailed analysis of a few factors that could affect the model performance is provided as well to motivate future research. 2 2.1 Related Work Sentence Representation Learning Prior approaches for sentence represent"
2021.acl-long.402,D17-1070,0,0.114622,"tailed analysis of a few factors that could affect the model performance is provided as well to motivate future research. 2 2.1 Related Work Sentence Representation Learning Prior approaches for sentence representation learning include two main categories – supervised and unsupervised methods, while a few works might leverage on both of them. Most of the supervised methods are trained on labeled natural language inference (NLI) datasets including Stanford NLI (SNLI) (Bowman et al., 2015) and MultiNLI (Williams et al., 2018). Early methods demonstrate good performance on a wide range of tasks (Conneau et al., 2017; Cer et al., 2018). Recently, SBERT (Reimers and Gurevych, 2019) fine-tuned a pre-trained Siamese BERT network on NLI and demonstrated the state-of-the-art performance. Though effective, those methods highly rely on labeled data and could be problematic to port to new domains. Zhang et al. (2020) showed that SBERT generalizes poorly on target tasks with a data distribution significantly different from the NLI data. There are also fruitful outcomes for unsupervised methods. Some early studies attempt to learn from the internal structures within each sentence (Socher et al., 2011; Hill et al.,"
2021.acl-long.402,N19-1423,0,0.027073,") showed that SBERT generalizes poorly on target tasks with a data distribution significantly different from the NLI data. There are also fruitful outcomes for unsupervised methods. Some early studies attempt to learn from the internal structures within each sentence (Socher et al., 2011; Hill et al., 2016; Le and Mikolov, 2014) or utilize a distributional hypothesis to encode contextual information with generative (Kiros et al., 2015; Hill et al., 2016) or discriminative objectives (Jernite et al., 2017; Logeswaran and Lee, 2018). Recently, transformer-based networks attract more attentions (Devlin et al., 2019; Liu et al., 2019), however, they do not yield meaningful sentence representations directly without supervised fine-tuning. Reimers and Gurevych (2019) show that sentence embeddings obtained from BERT without fine-tuning even underperform the GloVe embeddings (Pennington et al., 2014) in terms of semantic textual similarity. More recently, a few unsupervised methods were proposed to learn sentence representations from transformer-based networks without supervised fine-tuning. Li et al. (2020) proposes to transform the representation obtained by a pre-trained language model to an isotropic Gau"
2021.acl-long.402,2020.acl-main.740,0,0.0484,"Missing"
2021.acl-long.402,N16-1162,0,0.233056,"s on multiple semantic textual similarity (STS) tasks. However, such performance is mostly induced by high-quality supervision, while labeled data are difficult and ex∗ † Equally Contributed. Corresponding author. pensive to obtain in practice. Zhang et al. (2020) showed that SBERT generalizes poorly on target tasks that differ significantly from NLI on which SBERT is fine-tuned. Many unsupervised methods learn sentence representations by optimizing over various selfsupervised learning (SSL) objectives on a largescale unlabeled corpus. Early works often use auto-encoders (Socher et al., 2011; Hill et al., 2016) or next-sentence prediction (Kiros et al., 2015) for sentence representation learning. Recently, more efforts have been devoted to representation learning with transformer-based networks using masked language modeling (MLM). However, transformer-based methods do not directly produce meaningful sentence representations. Instead, significant supervised fine-tuning steps with labeled data are commonly required to form good representations (Reimers and Gurevych, 2019). Recently, Giorgi et al. (2020) and Zhang et al. (2020) proposed novel transformer-based frameworks to directly learn sentence rep"
2021.acl-long.402,N18-1101,0,0.0144209,"gual baselines on cross-lingual STS tasks under both unsupervised and supervised settings. Detailed analysis of a few factors that could affect the model performance is provided as well to motivate future research. 2 2.1 Related Work Sentence Representation Learning Prior approaches for sentence representation learning include two main categories – supervised and unsupervised methods, while a few works might leverage on both of them. Most of the supervised methods are trained on labeled natural language inference (NLI) datasets including Stanford NLI (SNLI) (Bowman et al., 2015) and MultiNLI (Williams et al., 2018). Early methods demonstrate good performance on a wide range of tasks (Conneau et al., 2017; Cer et al., 2018). Recently, SBERT (Reimers and Gurevych, 2019) fine-tuned a pre-trained Siamese BERT network on NLI and demonstrated the state-of-the-art performance. Though effective, those methods highly rely on labeled data and could be problematic to port to new domains. Zhang et al. (2020) showed that SBERT generalizes poorly on target tasks with a data distribution significantly different from the NLI data. There are also fruitful outcomes for unsupervised methods. Some early studies attempt to"
2021.acl-long.402,2020.emnlp-main.124,1,0.237715,"Among previous approaches, supervised methods achieve state-of-the-art performance by leveraging quality sentence labels. For example, the recently proposed model Sentence-BERT (SBERT) (Reimers and Gurevych, 2019) fine-tunes a Siamese BERT network on natural language inference (NLI) tasks with labeled sentence pairs. It achieves state-of-the-art results on multiple semantic textual similarity (STS) tasks. However, such performance is mostly induced by high-quality supervision, while labeled data are difficult and ex∗ † Equally Contributed. Corresponding author. pensive to obtain in practice. Zhang et al. (2020) showed that SBERT generalizes poorly on target tasks that differ significantly from NLI on which SBERT is fine-tuned. Many unsupervised methods learn sentence representations by optimizing over various selfsupervised learning (SSL) objectives on a largescale unlabeled corpus. Early works often use auto-encoders (Socher et al., 2011; Hill et al., 2016) or next-sentence prediction (Kiros et al., 2015) for sentence representation learning. Recently, more efforts have been devoted to representation learning with transformer-based networks using masked language modeling (MLM). However, transformer"
2021.acl-long.402,2020.emnlp-main.733,0,0.39492,"l., 2017; Logeswaran and Lee, 2018). Recently, transformer-based networks attract more attentions (Devlin et al., 2019; Liu et al., 2019), however, they do not yield meaningful sentence representations directly without supervised fine-tuning. Reimers and Gurevych (2019) show that sentence embeddings obtained from BERT without fine-tuning even underperform the GloVe embeddings (Pennington et al., 2014) in terms of semantic textual similarity. More recently, a few unsupervised methods were proposed to learn sentence representations from transformer-based networks without supervised fine-tuning. Li et al. (2020) proposes to transform the representation obtained by a pre-trained language model to an isotropic Gaussian distribution. Giorgi et al. (2020) minimizes the distance between different spans sampled from the same document. However, it requires an extremely long document of 2,048 tokens as input, which limits its applications to domains with only short documents. Zhang et al. (2020) proposed IS-BERT to maximize the mutual information between the global embedding and local n-gram embeddings of a given sentence. However, IS-BERT requires careful negative sampling and the n-gram embeddings may be s"
2021.acl-long.402,2021.ccl-1.108,0,0.101849,"Missing"
2021.acl-long.402,marelli-etal-2014-sick,0,0.0100444,"NLI datasets. To adapt BSL to a supervised learning setting, we first train a SBERT (SRoBERTa) model and then use the learned weights to initialize the online and target networks of BSL and perform BSL training. We denote this model variant as BSL-SBERT (BSL-SRoBERTa). 4.1 Semantic Textual Similarity (STS) Hyperparameter We tune learning rate, batch size, momentum δ, and the hyperparameter k on SentEval contains a suite of STS datasets including the STS tasks 2012-2016 (Agirre et al., 2012, 2013, 2014, 2015, 2016), the STS benchmark (STSB) (Cer et al., 2017), and the SICK-Relatedness dataset (Marelli et al., 2014). These datasets con1 We use Google translation engine. The datasets are released. 2 Hyperparameters and implementation details are attached in Appendix A 5171 Model STS-12 STS-13 STS-14 STS-15 STS-16 STS-B SICK-R Avg. Unsupervised methods Unigram-TFIDF† SDAE† SkipThought† FastSent† GloVe avg.‡ BERT avg.‡ BERT [CLS]‡ BERT-mlm IS-BERT∗ BERT-flow◦ 55.14 38.78 20.16 48.86 56.77 59.54 70.66 57.98 30.01 64.76 69.24 64.69 58.00 12.00 27.00 63.00 59.73 57.98 20.09 56.97 61.21 64.66 68.25 63.15 36.88 70.86 75.23 72.92 63.66 61.06 38.08 64.65 70.16 71.84 58.02 46.35 16.50 64.33 69.21 58.56 52.00 46.00"
2021.acl-long.402,W16-3636,0,0.0381762,"Missing"
2021.acl-long.402,D14-1162,0,0.0882842,"., 2011; Hill et al., 2016; Le and Mikolov, 2014) or utilize a distributional hypothesis to encode contextual information with generative (Kiros et al., 2015; Hill et al., 2016) or discriminative objectives (Jernite et al., 2017; Logeswaran and Lee, 2018). Recently, transformer-based networks attract more attentions (Devlin et al., 2019; Liu et al., 2019), however, they do not yield meaningful sentence representations directly without supervised fine-tuning. Reimers and Gurevych (2019) show that sentence embeddings obtained from BERT without fine-tuning even underperform the GloVe embeddings (Pennington et al., 2014) in terms of semantic textual similarity. More recently, a few unsupervised methods were proposed to learn sentence representations from transformer-based networks without supervised fine-tuning. Li et al. (2020) proposes to transform the representation obtained by a pre-trained language model to an isotropic Gaussian distribution. Giorgi et al. (2020) minimizes the distance between different spans sampled from the same document. However, it requires an extremely long document of 2,048 tokens as input, which limits its applications to domains with only short documents. Zhang et al. (2020) prop"
2021.acl-long.402,D19-1410,0,0.110046,"opted as a post-training procedure to boost the performance of the supervised methods. We further extend our method for learning multilingual sentence representations and demonstrate its effectiveness on cross-lingual STS tasks. Our code is available at https: //github.com/yanzhangnlp/BSL. 1 Introduction Sentence representation learning aims to map sentences into vectors that capture rich semantic information. Among previous approaches, supervised methods achieve state-of-the-art performance by leveraging quality sentence labels. For example, the recently proposed model Sentence-BERT (SBERT) (Reimers and Gurevych, 2019) fine-tunes a Siamese BERT network on natural language inference (NLI) tasks with labeled sentence pairs. It achieves state-of-the-art results on multiple semantic textual similarity (STS) tasks. However, such performance is mostly induced by high-quality supervision, while labeled data are difficult and ex∗ † Equally Contributed. Corresponding author. pensive to obtain in practice. Zhang et al. (2020) showed that SBERT generalizes poorly on target tasks that differ significantly from NLI on which SBERT is fine-tuned. Many unsupervised methods learn sentence representations by optimizing over"
2021.acl-long.402,2020.emnlp-main.365,0,0.0491899,"ed in the training process. This set of tasks is the common bechmark used to evaluate the transferability of sentence representations on downstream tasks. Table 2 presents the comparison results. On average, BSL outperforms all prior unsupervised baselines. It also outperforms supervised baselines InferSent and USE, and only slightly underperforms SBERT. BSL-SBERT can marginally improve the results of SBERT. BSL-SRoBERTa achieves the best performance. 4.3 Multilingual STS In this subsection, we show that BSL can be easily extended for learning multilingual sentence representations. Following (Reimers and Gurevych, 2020), we conduct evaluation on the multilingual STS 2017 dataset (Cer et al., 2017) which contains annotated pairs for EN-EN, AR-AR, ES-ES, ENAR, EN-ES, EN-TR, EN-DE, and EN-FR. To learn multilingual representations under the unsupervised setting, we process the NLI data as follows. We translate the English NLI sentences to AR, ES, TR, DE and FR using Google translation engine and pair the original English sentence to each of its translations. We obtain 5 pairs (ENAR/ES/TR/DE/FR) from one sentence and treat the English sentence as one view and its translation as the other view. We concatenate all"
2021.acl-long.441,C18-1107,0,0.0470271,"Missing"
2021.acl-long.441,W14-3348,0,0.0489971,"rances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (Ghazarian et al., 2019; Mehri and Eskenazi, 2020b; Huang et al., 2020; Zhang et al., 2021b) demonstrate strong correlations with human judgement at the turn-level, they only focus on context-response pairs without explicitly modeling the interaction over an entire dialogue. To perform dialogue-level evaluation, we need to rely on the aggregation of turn-level scores over the dialogue as a proxy for a dialog"
2021.acl-long.441,J95-2003,0,0.776481,"Missing"
2021.acl-long.441,2020.acl-main.740,0,0.0207406,"Missing"
2021.acl-long.441,2020.emnlp-main.742,0,0.135008,"u et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (Ghazarian et al., 2019; Mehri and Eskenazi, 2020b; Huang et al., 2020; Zhang et al., 2021b) demonstrate strong correlations with human judgement at the turn-level, they only focus on context-response pairs without explicitly modeling the interaction over an entire dialogue. To perform dialogue-level evaluation, we need to rely on the aggregation of turn-level scores over the dialogue as a proxy for a dialogue-level score. Furthermore, a recent study by Mehri and Eskenazi (2020a) found out that even though state-ofthe-art chatbots outperform humans across multiple turn-level evaluation criteria, such as interestingness, engagement and specificity, their dialogue"
2021.acl-long.441,2020.acl-main.80,1,0.686386,"extual information from all connected neighbours to the current node (Section 3.3). (4) producing a dialogue-level score, which indicates whether D is ¯ (Section 3.4). preferred over D 3.1 Dialogue Utterance Representation A sentence-encoder is needed to map the individual utterances within D onto the vector space. Firstly, we fine-tune a RoBERTa-base pre-trained language model (Liu et al., 2019) with training data of the target dialogue domain, because task-adaptive finetuning of the pre-trained language model on the target domain data benefits the final performance (Gururangan et al., 2020; Lee and Li, 2020). Next, the mean pooling operation is performed on the token embeddings within each utterance of D to derive their respective utterance-level representations. Formally, let SRoBERTa denotes the sentence encoder and u∗i in D is mapped into vector representations, ui ∈ Rd , whereby ui = SRoBERTa(u∗i ) Note that ∗ can be either speaker A or speaker B. Then, to capture a more fine-grained temporal dependency among the utterances, a bidirectional LSTM is adopted to model the sequential flow of information within D. The context-aware utterance representation, ei is then obtained via: ←−−→ ei = LSTM("
2021.acl-long.441,N16-1014,0,0.0179668,"judgements across multiple dialogue evaluation aspects at both turn and dialogue level. 1 Introduction Modern dialogue systems (Smith et al., 2020; Zhang et al., 2020; Adiwardana et al., 2020) leveraging large-scale language model pre-training (Devlin et al., 2019; Radford et al., 2019) are capable of generating fluent and contextually relevant utterances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (Ghazarian et al., 2019; Mehri and Eskenazi, 2020"
2021.acl-long.441,I17-1099,0,0.0289442,"ning validation test #dialog #utterance #word #avg turn per dialogue #avg words per dialogue 17,878 262,626 3,068,672 14.69 171.64 1,000 15,566 189,374 15.57 189.37 - 4.1 DailyDialog training validation test #dialog #utterance #word #avg turn per dialogue #avg words per dialogue 10,245 84,916 1,189,527 8.29 116.11 933 7,908 109,172 8.48 117.01 918 7,536 106,627 8.21 116.15 Dialogue Datasets Three bench-marking open-domain dialogue datasets are included in our experiments, Empathetic Dialogue (Rashkin et al., 2019), ConvAI2 PERSONACHAT (Zhang et al., 2018b; Dinan et al., 2020) and DialyDialog (Li et al., 2017). For training, we remove dialogues containing less than 4 utterances or more than 30 utterances. Statistics of the three human-human dialogue corpora after filtering is presented in Table 1. Empathetic Dialogue is designed for mimicking the real-life human conversation scenario whereby the interlocutors need to recognize and acknowledge the others’ feelings in the conversation. This dataset pertains to the short conversation scenario where interlocutors stick to a single topic. ConvAI2 PERSONACHAT is a crowdsourced dataset where each pair of interlocutors try to get to know each other by cond"
2021.acl-long.441,W04-1013,0,0.0467735,"ies in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (Ghazarian et al., 2019; Mehri and Eskenazi, 2020b; Huang et al., 2020; Zhang et al., 2021b) demonstrate strong correlations with human judgement at the turn-level, they only focus on context-response pairs without explicitly modeling the interaction over an entire dialogue. To perform dialogue-level evaluation, we need to rely on the aggregation of turn-level scores over the dialogue as a proxy for a dialogue-level score. Furthe"
2021.acl-long.441,P02-1040,0,0.110857,"t and contextually relevant utterances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (Ghazarian et al., 2019; Mehri and Eskenazi, 2020b; Huang et al., 2020; Zhang et al., 2021b) demonstrate strong correlations with human judgement at the turn-level, they only focus on context-response pairs without explicitly modeling the interaction over an entire dialogue. To perform dialogue-level evaluation, we need to rely on the aggregation of turn-level scores over"
2021.acl-long.441,2021.naacl-main.120,0,0.026321,"nd FED, which leverage pretrained language model, perform significantly better than DynaEval in this category. This may be because DynaEval directly models a dialogue at the utterance level instead of at the token level, while the other metrics consider the language modeling objective, which focuses more on the token-level dependencies rendering them effective for evaluating the naturalness of a response. A remedy to this problematic aspect of DynaEval is to introduce perturbation strategies targeting the token level, such as word drop, word shuffling and word replacement (Sinha et al., 2020; Park et al., 2021). Such strategies provide negative samples mimicking the non-sensical or non-grammatical responses produced by certain seq2seq generative models. Another simple solution is to combine DynaEval with turn-level metrics specifically designed for evaluating naturalness of dialogue responses. Besides the fluency aspect, DynaEval’s performance in interestingness, engagement and specificity at the turn level is not as pronounced as that of FED. This may be because purely modeling the dialogue itself is not enough for all the aspects. The model may need to incorporate external knowledge concerning a d"
2021.acl-long.441,P19-1534,0,0.014638,",160 1,306,060 4.31 66.87 2,768 12,075 201,816 4.36 72.91 2,547 10,973 194,772 4.31 76.47 ConvAI2 training validation test #dialog #utterance #word #avg turn per dialogue #avg words per dialogue 17,878 262,626 3,068,672 14.69 171.64 1,000 15,566 189,374 15.57 189.37 - 4.1 DailyDialog training validation test #dialog #utterance #word #avg turn per dialogue #avg words per dialogue 10,245 84,916 1,189,527 8.29 116.11 933 7,908 109,172 8.48 117.01 918 7,536 106,627 8.21 116.15 Dialogue Datasets Three bench-marking open-domain dialogue datasets are included in our experiments, Empathetic Dialogue (Rashkin et al., 2019), ConvAI2 PERSONACHAT (Zhang et al., 2018b; Dinan et al., 2020) and DialyDialog (Li et al., 2017). For training, we remove dialogues containing less than 4 utterances or more than 30 utterances. Statistics of the three human-human dialogue corpora after filtering is presented in Table 1. Empathetic Dialogue is designed for mimicking the real-life human conversation scenario whereby the interlocutors need to recognize and acknowledge the others’ feelings in the conversation. This dataset pertains to the short conversation scenario where interlocutors stick to a single topic. ConvAI2 PERSONACHAT"
2021.acl-long.441,2020.acl-main.55,0,0.0868899,"ple turn-level evaluation criteria, such as interestingness, engagement and specificity, their dialoguelevel ratings like coherence, Likability and diversity are still far below human level. This further reinforces the idea that turn-level quality evaluation may be insufficient to assess the performance of open-domain dialogue systems. In this work, we address the problem of automatic open-domain dialogue evaluation by focusing on the quality of an entire dialogue. This is a departure from the way we frame the problem as a weakly supervised next sentence prediction (Mehri and Eskenazi, 2020b; Sato et al., 2020) or language modeling tasks (Nedelchev et al., 2020; Pang et al., 2020) for context-response pairs. To this end, we need to answer two important questions: (1) How to effectively represent the entire dialogue? (2) How to incorporate this dialogue-level knowledge into our evaluation framework? We propose DynaEval to provide meaningful dialogue-level representation with explicit modeling of the interactive 5676 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5676–5689 August"
2021.acl-long.441,N19-1170,0,0.0215844,"engagement (Ghazarian et al., 2020). Even though all these automatic metrics demonstrate strong correlation with human judgements, they are laser-focused on one aspect of the evaluation. In addition, they do not explicitly model the speaker-level and utterance-level interactions, which we believe is essential for the dialogue-level representation, and eventually benefits the dialogue evaluation task. Interactive Evaluation A popular human evaluation method is the interactive evaluation whereby human judges converse with dialogue systems and make the assessment at the end of the conversations (See et al., 2019; Finch and Choi, 2020; Li et al., 2019; Deriu et al., 2020). It has been shown to be more reliable than turn-level static evaluation (Mehri and Eskenazi, 2020a). There are few studies on fully automating this process. Ghandeharioun et al. (2019) propose a self-play scenario where the dialog system chats with itself and a combination of three metrics measuring sentiment, semantic coherence and engagement respectively along the conversation trajectory is computed to approximate dialogue-level quality estimation. Mehri and Eskenazi (2020a) propose the FED metric, which evaluates the quality of a"
2021.acl-long.441,2020.acl-main.220,0,0.0614496,"There are few studies on fully automating this process. Ghandeharioun et al. (2019) propose a self-play scenario where the dialog system chats with itself and a combination of three metrics measuring sentiment, semantic coherence and engagement respectively along the conversation trajectory is computed to approximate dialogue-level quality estimation. Mehri and Eskenazi (2020a) propose the FED metric, which evaluates the quality of a system utterance in an interactive setting by computing the likelihood of a particular follow-up utterance responded by dialoGPT (Zhang et al., 2020). Moreover, Sinha et al. (2020) come up with MaUde, a reference-free metric tailored for online dialogue evaluation, which leverages a pre-trained DistilBERT (Sanh et al., 2019) model to extract the semantic representation of dialogue turns and uses bidirectional LSTM to explicitly model the discourse structure. While the interactive evaluation is more reliable than the turn-level static evaluation, it still relies on the aggregation of turn-level scores. An ideal approximation of the human evaluation process is a top-down approach whereby we examine the quality of the entire dialogue at macro level before zooming into the"
2021.acl-long.441,2020.acl-main.183,0,0.014018,"DynaEval, the graph convolutional network (GCN) is adopted to model a dialogue in totality, where the graph nodes denote each individual utterance and the edges represent the dependency between pairs of utterances. A contrastive loss is then applied to distinguish well-formed dialogues from carefully constructed negative samples. Experiments show that DynaEval significantly outperforms the state-of-the-art dialogue coherence model, and correlates strongly with human judgements across multiple dialogue evaluation aspects at both turn and dialogue level. 1 Introduction Modern dialogue systems (Smith et al., 2020; Zhang et al., 2020; Adiwardana et al., 2020) leveraging large-scale language model pre-training (Devlin et al., 2019; Radford et al., 2019) are capable of generating fluent and contextually relevant utterances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of ef"
2021.acl-long.441,P19-1363,0,0.134684,"coherence model, and correlates strongly with human judgements across multiple dialogue evaluation aspects at both turn and dialogue level. 1 Introduction Modern dialogue systems (Smith et al., 2020; Zhang et al., 2020; Adiwardana et al., 2020) leveraging large-scale language model pre-training (Devlin et al., 2019; Radford et al., 2019) are capable of generating fluent and contextually relevant utterances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (G"
2021.acl-long.441,2020.acl-main.515,0,0.0321591,"multiple dialogue evaluation aspects at both turn and dialogue level. 1 Introduction Modern dialogue systems (Smith et al., 2020; Zhang et al., 2020; Adiwardana et al., 2020) leveraging large-scale language model pre-training (Devlin et al., 2019; Radford et al., 2019) are capable of generating fluent and contextually relevant utterances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialoguelevel evaluation mechanisms to guide the studies and to monitor progress. 1 https://github.com/e0397123/DynaEval Commonly used static metrics, such as BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014) and ROUGE (Lin, 2004), correlate poorly with human judgements (Liu et al., 2016) rendering them unsuitable for dialogue evaluation. While some recent automatic dialogue evaluation metrics (Ghazarian et al., 2019; Mehri and Eskenazi, 2020b; Huang et al., 2"
2021.acl-long.441,D18-1432,0,0.0518129,"Missing"
2021.acl-long.441,P18-1205,0,0.169278,"16 4.36 72.91 2,547 10,973 194,772 4.31 76.47 ConvAI2 training validation test #dialog #utterance #word #avg turn per dialogue #avg words per dialogue 17,878 262,626 3,068,672 14.69 171.64 1,000 15,566 189,374 15.57 189.37 - 4.1 DailyDialog training validation test #dialog #utterance #word #avg turn per dialogue #avg words per dialogue 10,245 84,916 1,189,527 8.29 116.11 933 7,908 109,172 8.48 117.01 918 7,536 106,627 8.21 116.15 Dialogue Datasets Three bench-marking open-domain dialogue datasets are included in our experiments, Empathetic Dialogue (Rashkin et al., 2019), ConvAI2 PERSONACHAT (Zhang et al., 2018b; Dinan et al., 2020) and DialyDialog (Li et al., 2017). For training, we remove dialogues containing less than 4 utterances or more than 30 utterances. Statistics of the three human-human dialogue corpora after filtering is presented in Table 1. Empathetic Dialogue is designed for mimicking the real-life human conversation scenario whereby the interlocutors need to recognize and acknowledge the others’ feelings in the conversation. This dataset pertains to the short conversation scenario where interlocutors stick to a single topic. ConvAI2 PERSONACHAT is a crowdsourced dataset where each pai"
2021.acl-long.441,2020.acl-demos.30,0,0.0880083,"convolutional network (GCN) is adopted to model a dialogue in totality, where the graph nodes denote each individual utterance and the edges represent the dependency between pairs of utterances. A contrastive loss is then applied to distinguish well-formed dialogues from carefully constructed negative samples. Experiments show that DynaEval significantly outperforms the state-of-the-art dialogue coherence model, and correlates strongly with human judgements across multiple dialogue evaluation aspects at both turn and dialogue level. 1 Introduction Modern dialogue systems (Smith et al., 2020; Zhang et al., 2020; Adiwardana et al., 2020) leveraging large-scale language model pre-training (Devlin et al., 2019; Radford et al., 2019) are capable of generating fluent and contextually relevant utterances. Yet, they still face difficulties in mimicking human conversations in the sense that they lack certain conversation-level attributes, such as coherence (Cervone et al., 2018), consistency (Welleck et al., 2019; Nie et al., 2020), diversity (Li et al., 2016; Wu et al., 2020) and engagement (Ghandeharioun et al., 2019; Ghazarian et al., 2020). One of the main reasons is the dearth of effective dialogueleve"
2021.acl-long.441,D19-1016,0,0.0415939,"Missing"
C04-1103,W03-0317,0,0.138161,"Missing"
C04-1103,P98-2220,0,0.225691,"Missing"
C04-1103,kang-choi-2000-automatic,0,\N,Missing
C04-1103,C02-1099,0,\N,Missing
C04-1103,C00-1056,0,\N,Missing
C04-1103,W03-1508,0,\N,Missing
C04-1103,C98-2215,0,\N,Missing
C04-1103,P02-1051,0,\N,Missing
C08-1014,J93-2003,0,0.0123935,"Missing"
C08-1014,2006.iwslt-papers.4,1,0.884309,"d either from different methods or same decoder with different models, local feature functions of each hypothesis are not directly comparable, and thus inadequate for rescoring. We hence exploit rich global feature functions in the rescoring models to compensate the loss of local feature functions. We apply the following 10 feature functions and optimize the weight of each feature function using the tool in Moses package. • direct and inverse IBM model 1 and 3 • association score, i.e. hyper-geometric distribution probabilities and mutual information • lexicalized word/block reordering rules (Chen et al., 2006) • 6-gram target LM • 8-gram target word-class based LM, wordclasses are clustered by GIZA++ • length ratio between source and target sentence • question feature (Chen et al., 2005) • linear sum of n-grams relative frequencies within N-best translations (Chen et al., 2005) • n-gram posterior probabilities within the Nbest translations (Zens and Ney, 2006) • sentence length posterior probabilities (Zens and Ney, 2006) 108 5 Experiments 5.1 data Tasks Train We carried out two sets of experiments on two different datasets. One is in spoken language domain while the other is on newswire corpus. Bo"
C08-1014,2007.mtsummit-papers.15,1,0.910881,"are generated by the decoder and the 1-best translation is returned after rescored with additional feature functions. e,a m =1 where e is a string of phrases in the target language, f is the source language string of phrases, Figure 2: Structure of a three-pass machine translation system with the new regeneration pass. The original N-best translations list (Nbest1) is expanded to generate a new N-best translations list (N-best2) before the rescoring pass. lation and reordering models that are trained on the source-to-target N-best translations generated in the first pass. N-gram expansion (Chen et al., 2007) regenerates more hypotheses by continuously expanding the partial hypotheses through an n-gram language model trained on the original N-best translations. And confusion network generates new hypotheses based on confusion network decoding (Matusov et al., 2006), where the confusion network is built on the original N-best translations. Confusion network and re-decoding have been well studied in the combination of different MT systems (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b). Researchers have used confusion network to compute cons"
C08-1014,N03-1017,0,0.0070794,"le system. We explore three different methods to implement the regeneration process: redecoding, n-gram expansion, and confusion network-based regeneration. Experiments on Chinese-to-English NIST and IWSLT tasks show that all three methods obtain consistent improvements. Moreover, the combination of the three strategies achieves further improvements and outperforms the baseline by 0.81 BLEU-score on IWSLT’06, 0.57 on NIST’03, 0.61 on NIST’05 test set respectively. 1 Introduction State-of-the-art Statistical Machine Translation (SMT) systems usually adopt a two-pass search strategy (Och, 2003; Koehn, et al., 2003) as shown in Figure 1. In the first pass, a decoding algorithm is applied to generate an N-best list of translation hypotheses, while in the second pass, the final translation is selected by rescoring and re-ranking the N-best translations through additional feature functions. The fundamental assumption behind using a second pass is that the generated N-best list may contain better transla© 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. tions than the best choice foun"
C08-1014,takezawa-etal-2002-toward,0,0.0637026,"ure (Chen et al., 2005) • linear sum of n-grams relative frequencies within N-best translations (Chen et al., 2005) • n-gram posterior probabilities within the Nbest translations (Zens and Ney, 2006) • sentence length posterior probabilities (Zens and Ney, 2006) 108 5 Experiments 5.1 data Tasks Train We carried out two sets of experiments on two different datasets. One is in spoken language domain while the other is on newswire corpus. Both experiments are on Chinese-to-English translation. Experiments on spoken language domain were carried out on the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2002) Chinese- to-English data augmented with HITcorpus 1 . BTEC is a multilingual speech corpus which contains sentences spoken by tourists. 40K sentence-pairs are used in our experiment. HITcorpus is a balanced corpus and has 500K sentence-pairs in total. We selected 360K sentencepairs that are more similar to BTEC data according to its sub-topic. Additionally, the English sentences of Tanaka corpus 2 were also used to train our LM. We ran experiments on an IWSLT 3 challenge track which uses IWSLT2006 4 DEV clean text set as development set and IWSLT-2006 TEST clean text as test set. Table 1 summ"
C08-1014,W06-3110,0,0.342533,"stem can be improved from two aspects, i.e. scoring models and the quality of the N-best hypotheses. Rescoring pass improves the performance of machine translation by enhancing the scoring models with more global sophisticated and discriminative feature functions. The idea for applying two passes instead of one is that some global feature functions cannot be easily decomposed into local scores and computed during decoding. Furthermore, rescoring allows some feature functions, such as word and n-gram posterior probabilities, to be estimated on the N-best list (Ueffing, 2003; Chen et al., 2005; Zens and Ney, 2006). In this two-pass method, translation performance hinges on the N-best hypotheses that are generated in the first pass (since rescoring occurs on these), so adding the translation candidates generated by other MT systems to these hypotheses could potentially improve the performance. This technique is called system combination (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b). We have instead chosen to regenerate new hypotheses from the original N-best list, a technique which we call regeneration. Regeneration is an intermediate pass bet"
C08-1014,P07-2045,0,0.0336091,"Missing"
C08-1014,C04-1183,1,0.757767,"are ranked, choosing the first best hypothesis as the skeleton is straightforward in our work. Aligning words: As a confusion network can be easily built from a one-to-one alignment, we develop our algorithm based on the one-to-one assumption and use competitive linking algorithm (Melamed, 2000) for our word alignment. Firstly, an association score is computed for every possible word pair from the skeleton and sentence to be aligned. Then a greedy algorithm is applied to select the best word-alignment. In this paper, we use a linear combination of multiple association scores, as suggested in (Kraif and Chen, 2004). As the two sentences to be aligned are in the same language, the association scores are computed on the following four clues. They are cognate (S1), word class (S2), synonyms (S3), and position difference (S4). The four scores are linearly combined with empirically determined weights as shown is Equation 2. 4 S ( f j , e i ) = ∑ λk × S k (2) k =1 Reordering words: After word alignment, the words in all other hypotheses are reordered to match the word order of the skeleton. The aligned words are reordered according to their alignment indices. The unaligned words are reordered in two strategie"
C08-1014,E06-1005,0,0.607335,"posed into local scores and computed during decoding. Furthermore, rescoring allows some feature functions, such as word and n-gram posterior probabilities, to be estimated on the N-best list (Ueffing, 2003; Chen et al., 2005; Zens and Ney, 2006). In this two-pass method, translation performance hinges on the N-best hypotheses that are generated in the first pass (since rescoring occurs on these), so adding the translation candidates generated by other MT systems to these hypotheses could potentially improve the performance. This technique is called system combination (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b). We have instead chosen to regenerate new hypotheses from the original N-best list, a technique which we call regeneration. Regeneration is an intermediate pass between decoding and rescoring as depicted in Figure 2. Given the original N-best list (N-best1) generated by the decoder, this regeneration pass creates new translation hypotheses from this list to form another N-best list (N-best2). These two N-best lists are then combined and given to the rescoring pass to derive the best translation. We implement three methods to regener"
C08-1014,J00-2004,0,0.0187612,"ther hypotheses on average as the skeleton. Bangalore et al. (2001) used a WER based alignment and Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate 107 (TER) based alignment to build the confusion network. Choosing alignment reference: Since the Nbest translations are ranked, choosing the first best hypothesis as the skeleton is straightforward in our work. Aligning words: As a confusion network can be easily built from a one-to-one alignment, we develop our algorithm based on the one-to-one assumption and use competitive linking algorithm (Melamed, 2000) for our word alignment. Firstly, an association score is computed for every possible word pair from the skeleton and sentence to be aligned. Then a greedy algorithm is applied to select the best word-alignment. In this paper, we use a linear combination of multiple association scores, as suggested in (Kraif and Chen, 2004). As the two sentences to be aligned are in the same language, the association scores are computed on the following four clues. They are cognate (S1), word class (S2), synonyms (S3), and position difference (S4). The four scores are linearly combined with empirically determi"
C08-1014,P03-1021,0,0.120474,"from a single system. We explore three different methods to implement the regeneration process: redecoding, n-gram expansion, and confusion network-based regeneration. Experiments on Chinese-to-English NIST and IWSLT tasks show that all three methods obtain consistent improvements. Moreover, the combination of the three strategies achieves further improvements and outperforms the baseline by 0.81 BLEU-score on IWSLT’06, 0.57 on NIST’03, 0.61 on NIST’05 test set respectively. 1 Introduction State-of-the-art Statistical Machine Translation (SMT) systems usually adopt a two-pass search strategy (Och, 2003; Koehn, et al., 2003) as shown in Figure 1. In the first pass, a decoding algorithm is applied to generate an N-best list of translation hypotheses, while in the second pass, the final translation is selected by rescoring and re-ranking the N-best translations through additional feature functions. The fundamental assumption behind using a second pass is that the generated N-best list may contain better transla© 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. tions tha"
C08-1014,J03-1002,0,0.00995435,"Missing"
C08-1014,P02-1040,0,0.0763935,"Missing"
C08-1014,N07-1029,0,0.441059,"ing decoding. Furthermore, rescoring allows some feature functions, such as word and n-gram posterior probabilities, to be estimated on the N-best list (Ueffing, 2003; Chen et al., 2005; Zens and Ney, 2006). In this two-pass method, translation performance hinges on the N-best hypotheses that are generated in the first pass (since rescoring occurs on these), so adding the translation candidates generated by other MT systems to these hypotheses could potentially improve the performance. This technique is called system combination (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b). We have instead chosen to regenerate new hypotheses from the original N-best list, a technique which we call regeneration. Regeneration is an intermediate pass between decoding and rescoring as depicted in Figure 2. Given the original N-best list (N-best1) generated by the decoder, this regeneration pass creates new translation hypotheses from this list to form another N-best list (N-best2). These two N-best lists are then combined and given to the rescoring pass to derive the best translation. We implement three methods to regenerate new hypotheses: re-decoding, n-gra"
C08-1014,P07-1040,0,0.487111,"ing decoding. Furthermore, rescoring allows some feature functions, such as word and n-gram posterior probabilities, to be estimated on the N-best list (Ueffing, 2003; Chen et al., 2005; Zens and Ney, 2006). In this two-pass method, translation performance hinges on the N-best hypotheses that are generated in the first pass (since rescoring occurs on these), so adding the translation candidates generated by other MT systems to these hypotheses could potentially improve the performance. This technique is called system combination (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b). We have instead chosen to regenerate new hypotheses from the original N-best list, a technique which we call regeneration. Regeneration is an intermediate pass between decoding and rescoring as depicted in Figure 2. Given the original N-best list (N-best1) generated by the decoder, this regeneration pass creates new translation hypotheses from this list to form another N-best list (N-best2). These two N-best lists are then combined and given to the rescoring pass to derive the best translation. We implement three methods to regenerate new hypotheses: re-decoding, n-gra"
C08-1127,P05-1033,0,0.10108,"model. We also present an annotation algorithm that captures syntactic information for BTG nodes. The experiments show that the LABTG approach significantly outperforms a baseline BTGbased system and a state-of-the-art phrasebased system on the NIST MT-05 Chineseto-English translation task. Moreover, we empirically demonstrate that the proposed method achieves better translation selection and phrase reordering. 1 Introduction Formal grammar used in statistical machine translation (SMT), such as Bracketing Transduction Grammar (BTG) proposed by (Wu, 1997) and the synchronous CFG presented by (Chiang, 2005), provides a natural platform for integrating linguistic knowledge into SMT because hierarchical structures produced by the formal grammar resemble linguistic structures.1 Chiang (2005) attempts to integrate linguistic information into his formally c 2008.  Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 1 We inherit the definitions of formal and linguistic from (Chiang, 2005) which makes a distinction between formally syntax-based SMT and linguistically syntax-based SMT."
C08-1127,P05-1067,0,0.0858963,"Missing"
C08-1127,P03-2041,0,0.0607656,"dge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The difference between their work and LABTG is significant because we annotate standard plain phrases using lingui"
C08-1127,P06-1077,0,0.0216025,"and scheme are capable of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The difference between their work and LABTG is significant becaus"
C08-1127,W06-1606,0,0.021123,"016 Manchester, August 2008 annotated reordering model. The second is that our proposed annotation algorithm and scheme are capable of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain"
C08-1127,P00-1056,0,0.208745,"prior probability which can be set based on the order preference of the language pairs. In MEBTG (Xiong et al., 2006), however, the probability is calculated more sophisticatedly using a MaxEnt-based classification model with boundary words as its features. by projecting source-side syntax tree to BTG tree, and finally extract rules from these annotated BTG trees. This way restricts learning space to only the best BTG trees2 , and leads to the loss of many useful annotated rules. Therefore, we use an alternative way to extract the annotated rules as illustrated below. Firstly, we run GIZA++ (Och and Ney, 2000) on the training corpus in both directions and then apply the ogrow-diag-finalp refinement rule (Koehn et al., 2003) to obtain many-to-many word alignments. Secondly, we extract bilingual phrases from the word-aligned corpus, then annotate their source sides with linguistic elements to obtain the annotated lexical rules.3 Finally, we learn reordering examples (Xiong et al., 2006), annotate their two neighboring sub-phrases and whole phrases, and then generalize them in the annotated merging rules. Although this alternative way may also miss reorderings due to word alignment errors, it is still"
C08-1127,P03-1021,0,0.0302069,"features for the reordering model PRb (shared by both MEBTG and LABTG systems) using the right boundary words of phrases and 85K features for the annotated reordering model PRa (only included in the LABTG system) using linguistic annotations. We ran the MaxEnt toolkit (Zhang, 2004) to tune reordering feature weights with iteration number being set to 100 and Gaussian prior to 1 to avoid overfitting. We built our four-gram language model using Xinhua section of the English Gigaword corpus (181.1M words) with the SRILM toolkit (Stolcke, 2002). For the efficiency of minimum-error-rate training (Och, 2003), we built our development set (580 sentences) using sentences not exceeding 50 characters from the NIST MT-02 evaluation test data. 5.1 LABTG vs. phrase-based SMT and BTG-based SMT We compared the LABTG system with two baseline systems. The results are given in Table 2. The LABTG outperforms Moses and MEBTG by 2.81 and 1.69 absolute BLEU points, respectively. These significant improvements indicate that BTG formal structures can be successfully extended with linguistic knowledge extracted from syntactic structures without losing the strength of phrasebased method. 5.2 The Effect of Different"
C08-1127,P05-1034,0,0.0431644,"nnotation algorithm and scheme are capable of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The difference between their work and LABTG is"
C08-1127,P07-1090,1,0.871143,"significant because we annotate standard plain phrases using linguistic elements on the source side. Compared with the target side annotation which improves fluency and grammaticality of translation output, linguistic annotation on the source side helps to improve translation adequacy. Recently, some researchers have extended and created several variations of BTG/ITG. Zhang et al. (2005) propose lexicalized ITG for better word alignment. Xiong et al. (2006) demonstrate that their MEBTG, a BTG variation with MaxEntbased reordering model, can improve phrase reordering significantly. Similarly, Setiawan et al. (2007) use an enhanced BTG variation with function words for reordering. LABTG differs from these BTG variations in that the latter does not use any external linguistic knowledge. Zhang et al. (2007) describe a phrase reordering model based on BTG-style rules which integrates source-side syntactic knowledge. Our annotated reordering model of LABTG differs from their work in two key aspects. Firstly, we allow any phrase reorderings while they only reorder syntactic phrases. In their model, only syntactic phrases can use linguistic knowledge from parse trees for reordering while non-syntactic phrases"
C08-1127,P96-1021,0,0.76653,"labelling both syntactic and non-syntactic phrases. The linguistic elements extracted from parse trees capture both internal lexical content and external context of phrases. With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT (Koehn et al., 2003) in a more effective manner. They are (1) phrase translation: translating phrases according to their contexts; (2) phrase reordering: incorporating richer linguistic features for better reordering. The proposed LABTG displays two unique characteristics when compared with BTG-based SMT (Wu, 1996; Xiong et al., 2006). The first is that two linguistically-informed sub-models are introduced for better phrase translation and reordering: annotated phrase translation model and 1009 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1009–1016 Manchester, August 2008 annotated reordering model. The second is that our proposed annotation algorithm and scheme are capable of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain t"
C08-1127,J97-3002,0,0.63124,"otivated phrase translation model and reordering model. We also present an annotation algorithm that captures syntactic information for BTG nodes. The experiments show that the LABTG approach significantly outperforms a baseline BTGbased system and a state-of-the-art phrasebased system on the NIST MT-05 Chineseto-English translation task. Moreover, we empirically demonstrate that the proposed method achieves better translation selection and phrase reordering. 1 Introduction Formal grammar used in statistical machine translation (SMT), such as Bracketing Transduction Grammar (BTG) proposed by (Wu, 1997) and the synchronous CFG presented by (Chiang, 2005), provides a natural platform for integrating linguistic knowledge into SMT because hierarchical structures produced by the formal grammar resemble linguistic structures.1 Chiang (2005) attempts to integrate linguistic information into his formally c 2008.  Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 1 We inherit the definitions of formal and linguistic from (Chiang, 2005) which makes a distinction between formally sy"
C08-1127,P07-1037,0,0.0285055,"Missing"
C08-1127,I05-1007,1,0.844533,"Missing"
C08-1127,N06-1031,0,0.0770157,"in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The difference between their work and LABTG is significant because we annotate standard plain phrases using linguistic elements on the source side. Compared with the target side annotation which improves fluency and grammaticality of translation output, linguistic annotation on the source side helps to improve translation adequacy. Rece"
C08-1127,P06-1066,1,0.861375,"both syntactic and non-syntactic phrases. The linguistic elements extracted from parse trees capture both internal lexical content and external context of phrases. With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT (Koehn et al., 2003) in a more effective manner. They are (1) phrase translation: translating phrases according to their contexts; (2) phrase reordering: incorporating richer linguistic features for better reordering. The proposed LABTG displays two unique characteristics when compared with BTG-based SMT (Wu, 1996; Xiong et al., 2006). The first is that two linguistically-informed sub-models are introduced for better phrase translation and reordering: annotated phrase translation model and 1009 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1009–1016 Manchester, August 2008 annotated reordering model. The second is that our proposed annotation algorithm and scheme are capable of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we es"
C08-1127,2006.amta-papers.8,0,0.0165304,"able of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The difference between their work and LABTG is significant because we annotate standar"
C08-1127,N03-1017,0,0.134062,"c parse trees of source or target language. Along this line, we propose a novel approach: Linguistically Annotated BTG (LABTG) for SMT. The LABTG annotates BTG rules with linguistic elements that are learned from syntactic parse trees on the source side through an annotation algorithm, which is capable of labelling both syntactic and non-syntactic phrases. The linguistic elements extracted from parse trees capture both internal lexical content and external context of phrases. With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT (Koehn et al., 2003) in a more effective manner. They are (1) phrase translation: translating phrases according to their contexts; (2) phrase reordering: incorporating richer linguistic features for better reordering. The proposed LABTG displays two unique characteristics when compared with BTG-based SMT (Wu, 1996; Xiong et al., 2006). The first is that two linguistically-informed sub-models are introduced for better phrase translation and reordering: annotated phrase translation model and 1009 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1009–1016 Manchester,"
C08-1127,D07-1091,0,0.0285451,"tures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The difference between their work and LABTG is significant because we annotate standard plain phrases using linguistic elements on the source side. Compared"
C08-1127,P07-2045,0,0.0111875,"Missing"
C08-1127,D07-1056,0,0.267646,"ause we annotate standard plain phrases using linguistic elements on the source side. Compared with the target side annotation which improves fluency and grammaticality of translation output, linguistic annotation on the source side helps to improve translation adequacy. Recently, some researchers have extended and created several variations of BTG/ITG. Zhang et al. (2005) propose lexicalized ITG for better word alignment. Xiong et al. (2006) demonstrate that their MEBTG, a BTG variation with MaxEntbased reordering model, can improve phrase reordering significantly. Similarly, Setiawan et al. (2007) use an enhanced BTG variation with function words for reordering. LABTG differs from these BTG variations in that the latter does not use any external linguistic knowledge. Zhang et al. (2007) describe a phrase reordering model based on BTG-style rules which integrates source-side syntactic knowledge. Our annotated reordering model of LABTG differs from their work in two key aspects. Firstly, we allow any phrase reorderings while they only reorder syntactic phrases. In their model, only syntactic phrases can use linguistic knowledge from parse trees for reordering while non-syntactic phrases"
C08-1127,P05-1059,0,0.11755,"Missing"
C08-1127,W06-3119,0,0.0229064,"rdering model. The second is that our proposed annotation algorithm and scheme are capable of conveying linguistic knowledge from source-side syntax structures to BTG structures. We describe the LABTG model and the annotation algorithm in Section 4. To better explain the LABTG model, we establish a unified framework of BTG-based SMT in Section 3. We conduct a series of experiments to study the effect of the LABTG in Section 5. 2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few. LABTG can be considered as, but not limited to, a new attempt that enriches translation model with source-side linguistic annotations. (Huang and Knight, 2006) and (Hassan et al., 2007) introduce relabeling and supertagging on the target side, respectively. The former re-annotates syntactified phrases to learn grammatical distinctions while the latter supertags standard plain phrases, both applied on the target side. The differ"
C08-1138,koen-2004-pharaoh,0,0.150361,"rivations3 that could lead to the same target tree T (e1I ) , the mapping probability Pr (T (e1I ) |T ( f1J )) is obtained by summing over the probabilities of all derivations. The probability of each derivation θ is given by the product of the probabilities of all the rules p (ri ) used in the derivation (here we assume that a rule is applied independently in a derivation). Pr (e1I |f1J ) = Pr (T (e1I ) |T ( f1J )) = ∑∏ p (ri ) θ (1) ri ∈θ The model is implemented under log-linear framework. We use seven basic features that are analogous to the commonly used features in phrase-based systems (Koehn, 2004): 1) bidirectional rule mapping probabilities; 2) bidirectional lexical translation probabilities; 3) the target language model; 4) the number of rules used and 5) the number of target words. Besides, we define two new features: 1) the number of lexical words in a rule to control the model’s preference for lexicalized rules over un-lexicalized rules and 2) the average tree height in a rule to balance the usage of hierarchical rules and more flat rules. 2) SCFG-based tree-to-tree model when α s = The overall training process is similar to the process in the phrase-based system (koehn et al., α"
C08-1138,J93-2003,0,0.00973221,"mainly de© 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. termined by the grammar. Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT. Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Cowan et al., 2006; Eisner, 2003; Ding and Palmer, 2005; Zhang et al., 2007; Bod, 2007; Quirk wt al., 2005; Poutsma, 2000; Hearne and Way, 2003) and so on. Although many achievements have been obtained by these advances, it is still unclear which of these important pursuits is able to best explai"
C08-1138,P07-2045,0,0.00915683,"s our development set and the NIST MT-2005 test set as our test set. We used the Stanford parser (Klein and Manning, 2003) to parse bilingual sentences on the training set and Chinese sentences on the development and test sets. The evaluation metric is casesensitive BLEU-4 (Papineni et al., 2002). We used GIZA++ and the heuristics “grow-diagfinal” to generate m-to-n word alignments. For the MER training, we modified Koehn’s MER trainer (Koehn, 2004) for our STSSG-based system. For significance test, we used Zhang et al’s implementation (Zhang et al, 2004). We compared four SMT systems: Moses (Koehn et al., 2007), SCFG-based, STSG-based and STSSGbased tree-to-tree translation models. For Moses, we used its default settings. For the others, we implemented them on the STSSG platform by adopting the same settings as used in the synchronous parsing. We optimized the decoding parameters on the development sets empirically. 4.2 Experimental Results SCFG STSG a larger span than SCFG. It reconfirms that only allowing sibling nodes reordering as done in SCFG may be inadequate for translational equivalence modeling (Galley et al., 2004)4. 3) All the three models on the FBIS corpus show much lower performance th"
C08-1138,P06-1077,0,0.629179,"nported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. termined by the grammar. Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT. Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Cowan et al., 2006; Eisner, 2003; Ding and Palmer, 2005; Zhang et al., 2007; Bod, 2007; Quirk wt al., 2005; Poutsma, 2000; Hearne and Way, 2003) and so on. Although many achievements have been obtained by these advances, it is still unclear which of these important pursuits is able to best explain human translation data, as each has its advantages and disadvantages. Therefore, it has grea"
C08-1138,P07-1089,0,0.805014,"ttp://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. termined by the grammar. Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT. Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Cowan et al., 2006; Eisner, 2003; Ding and Palmer, 2005; Zhang et al., 2007; Bod, 2007; Quirk wt al., 2005; Poutsma, 2000; Hearne and Way, 2003) and so on. Although many achievements have been obtained by these advances, it is still unclear which of these important pursuits is able to best explain human translation data, as each has its advantages and disadvantages. Therefore, it has great meaning in both t"
C08-1138,J94-4004,0,0.194206,"Missing"
C08-1138,W02-1039,0,0.253408,"ous factors in this study, including the genera of corpora (newspaper domain via spoken domain), the accuracy of word alignments and syntax parsing (automatically vs. manually). We report our experimental settings, experimental results and our findings in detail in the rest of the paper, which is organized as follows: Section 2 reviews previous work. Section 3 elaborates the general framework while Section 4 reports the experimental results. Finally, we conclude our work in Section 5. 2 Previous Work There are only a few of previous work related to the study of translation grammar comparison. Fox (2002) is the first to look at how well proposed translation models fit actual translation data empirically. She examined the issue of phrasal cohesion between English and French and discovered that while there is less cohesion than one might desire, there is still a large amount of regularity in the constructions where breakdowns occur. This suggests that reordering words by phrasal movement is a reasonable strategy (Fox, 2002). She has also examined the differences in cohesion between Treebank-style parse trees, trees with flattened verb phrases, and dependency structures. Their experimental resul"
C08-1138,P06-1121,0,0.093015,"Missing"
C08-1138,P04-1083,0,0.0235041,"arget ones. To speed up the decoder, we utilize several thresholds to limit the search beams for each span, such as the number of rules used and the number of hypotheses generated. 3.4 Synchronous Parsing A synchronous parser is an algorithm that can infer the syntactic structure of each component text in a multitext and simultaneously infer the correspondence relation between these structures. When a parser’s input can have fewer dimensions than the parser’s grammar, we call it a translator. When a parser’s grammar can have fewer dimensions than the parser’s input, we call it a synchronizer (Melamed, 2004). Therefore, synchronous parsing and MT are closed to each other. In this paper, we use synchronous parsing to compare the ability of different grammars in translational equivalence modeling. Given a bilingual sentence pair f1J and e1I , the synchronous parser is to find a derivation θ that generates &lt; T ( f1J ) , T (e1I ) >. Our synchronous parser is similar to the synchronous CKY parser presented at (Melamed, 2004). The difference is that we implement it based on our STSSG decoder. Therefore, in nature the parser is a standard synchronous chart parser but constrained by the rules of the STSS"
C08-1138,P05-1034,0,0.108909,"Missing"
C08-1138,N04-1035,0,0.716904,"cohesion between English and French and discovered that while there is less cohesion than one might desire, there is still a large amount of regularity in the constructions where breakdowns occur. This suggests that reordering words by phrasal movement is a reasonable strategy (Fox, 2002). She has also examined the differences in cohesion between Treebank-style parse trees, trees with flattened verb phrases, and dependency structures. Their experimental results indicate that the highest degree of cohesion is present in dependency structures. Motivated by the same problem raised by Fox (2002), Galley et al. (2004) study what rule can better explain human translation data. They first propose a theory that gives formal semantics to word-level alignments defined over parallel corpora, and then use the theory to introduce a linear algorithm that is used to derive from wordaligned, parallel corpora the minimal set of syntactically motivated transformation rules to explain human translation data. Their basic idea is to create transformation rules that condition on larger fragments of tree structure. Their experimental results suggest that their proposed rules provide a good, realistic indicator of the comple"
C08-1138,J97-3002,0,0.252765,"process to describe and build these alignments using mathematical models. Thus, the study of TEM is highly relevant to Statistical Machine Translation (SMT). Grammar is the most important infrastructure for TEM and SMT since translation models’ expressive and generative abilities are mainly de© 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. termined by the grammar. Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT. Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Co"
C08-1138,P01-1067,0,0.0407236,"ghts reserved. termined by the grammar. Many grammars, such as finite-state grammars (FSG), bracket/inversion transduction grammars (BTG/ITG) (Wu, 1997), context-free grammar (CFG), tree substitution grammar (TSG) (Comon et al., 2007) and their synchronous versions, have been explored in SMT. Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Cowan et al., 2006; Eisner, 2003; Ding and Palmer, 2005; Zhang et al., 2007; Bod, 2007; Quirk wt al., 2005; Poutsma, 2000; Hearne and Way, 2003) and so on. Although many achievements have been obtained by these advances, it is still unclear which of these important pursuits is able to best explain human translation data, as each has its advantages and disadvantages. Therefore, it has great meaning in both theory and practice to do comparison studies among these grammar"
C08-1138,2003.mtsummit-papers.22,0,0.0433645,"een explored in SMT. Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Cowan et al., 2006; Eisner, 2003; Ding and Palmer, 2005; Zhang et al., 2007; Bod, 2007; Quirk wt al., 2005; Poutsma, 2000; Hearne and Way, 2003) and so on. Although many achievements have been obtained by these advances, it is still unclear which of these important pursuits is able to best explain human translation data, as each has its advantages and disadvantages. Therefore, it has great meaning in both theory and practice to do comparison studies among these grammars and SMT models to see which of them are capable of better describing parallel translation data. This is a fundamental issue worth exploring in multilingual information processing. However, little effort in previous work has been put in this point. To address this issue"
C08-1138,zhang-etal-2004-interpreting,0,0.0967943,"less than 50 characters from the NIST MT-2002 test set as our development set and the NIST MT-2005 test set as our test set. We used the Stanford parser (Klein and Manning, 2003) to parse bilingual sentences on the training set and Chinese sentences on the development and test sets. The evaluation metric is casesensitive BLEU-4 (Papineni et al., 2002). We used GIZA++ and the heuristics “grow-diagfinal” to generate m-to-n word alignments. For the MER training, we modified Koehn’s MER trainer (Koehn, 2004) for our STSSG-based system. For significance test, we used Zhang et al’s implementation (Zhang et al, 2004). We compared four SMT systems: Moses (Koehn et al., 2007), SCFG-based, STSG-based and STSSGbased tree-to-tree translation models. For Moses, we used its default settings. For the others, we implemented them on the STSSG platform by adopting the same settings as used in the synchronous parsing. We optimized the decoding parameters on the development sets empirically. 4.2 Experimental Results SCFG STSG a larger span than SCFG. It reconfirms that only allowing sibling nodes reordering as done in SCFG may be inadequate for translational equivalence modeling (Galley et al., 2004)4. 3) All the thre"
C08-1138,2006.amta-papers.8,0,\N,Missing
C08-1138,2007.mtsummit-papers.8,0,\N,Missing
C08-1138,P00-1057,0,\N,Missing
C08-1138,C00-2092,0,\N,Missing
C08-1138,P03-1054,0,\N,Missing
C08-1138,P02-1040,0,\N,Missing
C08-1138,P06-1123,0,\N,Missing
C08-1138,P05-1067,0,\N,Missing
C08-1138,P03-2041,0,\N,Missing
C08-1138,W06-1628,0,\N,Missing
C08-1138,W06-1606,0,\N,Missing
C08-1138,P05-1033,0,\N,Missing
C08-1138,N03-1017,0,\N,Missing
C10-2073,J93-2003,0,0.0248122,"Missing"
C10-2073,C02-1011,0,0.0292421,"rminology can be extracted directly from these corpora, evolving or emerging terminologies can be captured much faster than lexicography and this would facilitate many tasks and applications in accessing cross-lingual information. There remain challenges in term alignment for comparable corpora. The structures of texts, paragraphs and sentences can be very different. The similarity of content in two documents varies through they talk about the same subject matter. Recent research in using transliteration (Udupa et. al., 2008; Knight and Graehl, 1998), context information (Morin et. al., 2007; Cao and Li, 2002; Fung, 1998), part-of-speech tagging, frequency distribution (Tao and Zhai, 2005) or some hybrid methods (Klementiev and Roth, 2006; Sadat et. al., 2003) have shone some light in dealing with comparable corpora. In particular, context information seems to be popular since it is ubiquitous and can be retrieved from corpora easily. In this paper, we propose an EM-based hybrid model for term alignment to address the issue. Through this model, we hope to discover new bilingual terminology from comparable corpora without supervision. In the following sections, the model will be explained in detail"
C10-2073,W04-3208,0,0.0118325,"ilingual terminology with limited usage of dictionaries. 1 Introduction Bilingual terminology extraction or term alignment has been well studied in parallel corpora. Due to the coherent nature of parallel corpora, various statistical methods, like EM algorithm (Brown et. al., 1993) have been proven to be effective and have achieved excellent performance in term of precision and recall. The limitation of parallel corpora in all domains and languages has led some researchers to explore ways to automate the parallel sentence extraction process from non-parallel corpora (Munteanu and Marcu, 2005; Fung and Cheung, 2004) before proceeding to the usual term alignment extraction using the existing techniques for parallel corpora. Nevertheless, the coverage is limited since parallel sentences in non-parallel corpora are minimal. Meanwhile, some researchers have started to exploit comparable corpora directly in a new manner. The motivations for such an approach are obvious: comparable corpora are abundantly available, from encyclopedia to daily newspapers, and the human effort is reduced in either generating or collecting these corpora. If bilingual terminology can be extracted directly from these corpora, evolvi"
C10-2073,P07-1084,0,0.026925,"Missing"
C10-2073,J05-4003,0,0.0252037,"pability to discover new bilingual terminology with limited usage of dictionaries. 1 Introduction Bilingual terminology extraction or term alignment has been well studied in parallel corpora. Due to the coherent nature of parallel corpora, various statistical methods, like EM algorithm (Brown et. al., 1993) have been proven to be effective and have achieved excellent performance in term of precision and recall. The limitation of parallel corpora in all domains and languages has led some researchers to explore ways to automate the parallel sentence extraction process from non-parallel corpora (Munteanu and Marcu, 2005; Fung and Cheung, 2004) before proceeding to the usual term alignment extraction using the existing techniques for parallel corpora. Nevertheless, the coverage is limited since parallel sentences in non-parallel corpora are minimal. Meanwhile, some researchers have started to exploit comparable corpora directly in a new manner. The motivations for such an approach are obvious: comparable corpora are abundantly available, from encyclopedia to daily newspapers, and the human effort is reduced in either generating or collecting these corpora. If bilingual terminology can be extracted directly fr"
C10-2073,W03-1108,0,0.0463416,"Missing"
C10-2073,I08-2084,1,0.857902,"Missing"
C10-2073,E09-1096,1,0.884232,"Missing"
C10-2073,P06-1103,0,\N,Missing
C10-2073,J98-4003,0,\N,Missing
C10-2112,J96-1002,0,0.0572198,"Missing"
C10-2112,P07-1016,1,0.857524,"Missing"
C10-2112,P04-1024,0,0.0390586,"Missing"
C10-2112,I08-1008,1,0.23473,"Missing"
C10-2112,J98-4003,0,\N,Missing
C10-2165,P02-1051,0,0.0827426,"king parts of the world, machine transliteration play a crucial role in most multilingual NLP, MT and CLIR applications (Hermjakob et al., 2008; Mandl and Womser-Hacker, 2004). This is because proper names account for the majority of OOV issues and translation lexicons (even derived from large parallel corpora) usually fail to provide good coverage over diverse, dynamically increasing names across languages. Much research effort has been done to address the transliteration issue in the research community (Knight and Graehl, 1998; Wan and Verspoor, 1998; Kang and Choi, 2000; Meng et al., 2001; Al-Onaizan and Knight, 2002; Gao et al., 2004; Klementiev and Roth, 2006; Sproat, 2006; Zelenko and Aone, 2006; Li et al., 2004, 2009a, 2009b; Sherif and Kondrak, 2007; Bertoldi et al., 2008; Goldwasser and Roth, 2008). These previous work can be categorized into three classes, i.e., graphemebased, phoneme-based and hybrid methods. Grapheme-based method (Li et al., 2004) treats transliteration as a direct orthographic mapping process and only uses orthographyrelated features while phoneme-based method (Knight and Graehl, 1998) treats transliteration as a phonetic mapping issue, converting source grapheme to source phone"
C10-2165,2008.iwslt-papers.1,0,0.141767,"2004). This is because proper names account for the majority of OOV issues and translation lexicons (even derived from large parallel corpora) usually fail to provide good coverage over diverse, dynamically increasing names across languages. Much research effort has been done to address the transliteration issue in the research community (Knight and Graehl, 1998; Wan and Verspoor, 1998; Kang and Choi, 2000; Meng et al., 2001; Al-Onaizan and Knight, 2002; Gao et al., 2004; Klementiev and Roth, 2006; Sproat, 2006; Zelenko and Aone, 2006; Li et al., 2004, 2009a, 2009b; Sherif and Kondrak, 2007; Bertoldi et al., 2008; Goldwasser and Roth, 2008). These previous work can be categorized into three classes, i.e., graphemebased, phoneme-based and hybrid methods. Grapheme-based method (Li et al., 2004) treats transliteration as a direct orthographic mapping process and only uses orthographyrelated features while phoneme-based method (Knight and Graehl, 1998) treats transliteration as a phonetic mapping issue, converting source grapheme to source phoneme followed by a mapping from source phoneme to target phoneme/grapheme. Hybrid method in machine transliteration refers to the combination of several different mo"
C10-2165,W06-1672,0,0.171672,"l NLP, MT and CLIR applications (Hermjakob et al., 2008; Mandl and Womser-Hacker, 2004). This is because proper names account for the majority of OOV issues and translation lexicons (even derived from large parallel corpora) usually fail to provide good coverage over diverse, dynamically increasing names across languages. Much research effort has been done to address the transliteration issue in the research community (Knight and Graehl, 1998; Wan and Verspoor, 1998; Kang and Choi, 2000; Meng et al., 2001; Al-Onaizan and Knight, 2002; Gao et al., 2004; Klementiev and Roth, 2006; Sproat, 2006; Zelenko and Aone, 2006; Li et al., 2004, 2009a, 2009b; Sherif and Kondrak, 2007; Bertoldi et al., 2008; Goldwasser and Roth, 2008). These previous work can be categorized into three classes, i.e., graphemebased, phoneme-based and hybrid methods. Grapheme-based method (Li et al., 2004) treats transliteration as a direct orthographic mapping process and only uses orthographyrelated features while phoneme-based method (Knight and Graehl, 1998) treats transliteration as a phonetic mapping issue, converting source grapheme to source phoneme followed by a mapping from source phoneme to target phoneme/grapheme. Hybrid met"
C10-2165,kang-choi-2000-automatic,0,\N,Missing
C10-2165,N10-1065,0,\N,Missing
C10-2165,C04-1103,1,\N,Missing
C10-2165,P04-1021,1,\N,Missing
C10-2165,J96-1002,0,\N,Missing
C10-2165,P07-1108,0,\N,Missing
C10-2165,P06-1103,0,\N,Missing
C10-2165,N07-1061,0,\N,Missing
C10-2165,P07-1119,0,\N,Missing
C10-2165,P06-1010,0,\N,Missing
C10-2165,W09-3501,1,\N,Missing
C10-2165,P98-2220,0,\N,Missing
C10-2165,C98-2215,0,\N,Missing
C10-2165,D08-1037,0,\N,Missing
C10-2165,P08-1045,0,\N,Missing
C10-2165,N03-1017,0,\N,Missing
C10-2165,J03-1002,0,\N,Missing
C10-2165,W09-3506,0,\N,Missing
C10-2165,P09-1018,0,\N,Missing
C10-2165,P07-1092,0,\N,Missing
C10-2165,W09-3502,1,\N,Missing
C10-2165,P09-1016,1,\N,Missing
C10-2165,I08-8003,0,\N,Missing
D07-1085,P05-1055,0,0.0914742,"red in each phone lattice with a sufficiently high normalized log likelihood, and these counts were then used in retrieval under a vector space model with tf · idf weighting. Jones et al. (1996) combined retrieval from phone lattices using variations of James’ method with retrieval from 1best word transcripts to achieve better results. Since then, a number of different methods for SDR using lattices have been proposed. For instance, Siegler (1999) used word lattices instead of phone lattices as the basis of retrieval, and generalized the tf · idf formalism to allow uncertainty in word counts. Chelba and Acero (2005) preprocessed lattices into more compact Position Specific Posterior Lattices (PSPL), and computed an aggregate score for each document based on the posterior probability of edges and the proximity of search terms in the document. Mamou et al. (2006) converted each lattice into a word confusion network (Mangu et al., 2000), and estimated the inverse document frequency (idf ) of each word t as the ratio of the total number of words in the document collection to the total number of occurrences of t. Despite the differences in the details, the above lattice-based SDR methods have all been based o"
D07-1085,N04-1017,0,0.0649589,"rs. To represent the uncertainty in speech recognition, and to incorporate information from multiple transcription hypotheses rather than only the 1-best, it is desirable to use expected word counts from lattices output by a speech recognizer. In the context of spoken document search, Siegler (1999) described expected word counts and formulated a way to estimate expected word counts from lattices based on the relative ranks of word hypothesis probabilities; Chelba and Acero (2005) used a more explicit formula for computing word counts based on summing edge posterior probabilities in lattices; Saraclar and Sproat (2004) performed word-spotting in speech lattices by looking for word occurrences whose expected counts were above a certain threshold; and Yu et al. (2005) searched for phrases in spoken documents using a similar measure, the expected word relevance. Expected counts have also been used to summarize the phonotactics of a speech recording represented in a lattice: Hatch et al. (2005) performed speaker recognition by computing the expected counts of phone bigrams in a phone lattice, and estimating an unsmoothed probability distribution of phone bigrams. Although many uses of expected counts have been"
D07-1085,I05-3025,1,0.885174,"Missing"
D07-1085,H05-1119,0,0.0322144,"desirable to use expected word counts from lattices output by a speech recognizer. In the context of spoken document search, Siegler (1999) described expected word counts and formulated a way to estimate expected word counts from lattices based on the relative ranks of word hypothesis probabilities; Chelba and Acero (2005) used a more explicit formula for computing word counts based on summing edge posterior probabilities in lattices; Saraclar and Sproat (2004) performed word-spotting in speech lattices by looking for word occurrences whose expected counts were above a certain threshold; and Yu et al. (2005) searched for phrases in spoken documents using a similar measure, the expected word relevance. Expected counts have also been used to summarize the phonotactics of a speech recording represented in a lattice: Hatch et al. (2005) performed speaker recognition by computing the expected counts of phone bigrams in a phone lattice, and estimating an unsmoothed probability distribution of phone bigrams. Although many uses of expected counts have been studied, the use of statistical language models built from expected word counts has not been well explored. 2.3 Retrieval via Statistical Language Mod"
D09-1073,P03-2041,0,0.182765,"eatures over the source phrases are very effective for BTG constraint-based phrase reordering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases."
D09-1073,D08-1089,0,0.0619998,"Missing"
D09-1073,H05-1021,0,0.0168165,"ject to parsing errors to a large extent (zhang et al., 2007a) and the impact of syntax on reordering is difficult to single out (Li et al., 2007). In phrasebased method, local word reordering1 can be effectively captured by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited. This makes the phrasebased method particularly weak in handling global phrase reordering. From machine learning viewpoint (Vapnik, 1995), it is computationally infeasible to explicitly g"
D09-1073,P07-1091,0,0.0761394,"nce syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of how to utilize structured syntactic features for phrase reordering in a phrase-based SMT system with BTG (Bracketing Transduction Grammar) constraints (Wu, 1997). Word and phrase reordering is a crucial component in a SMT system. In syntax-based method, word reordering is implicitly addressed by translation rules, thus the performance is subject to parsing errors to a large extent (zhang et al., 2007a) and the impact of syntax on reordering is difficult to single out (Li et al., 2007). In phrasebased method, local word reordering1 can be effectively captured by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear"
D09-1073,P07-1089,0,0.01819,"t-based phrase reordering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of"
D09-1073,D08-1022,0,0.0322171,"tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of how to utilize structured syntactic features for phrase reordering in a phr"
D09-1073,P04-1043,0,0.183998,"chine learning method that can implicitly explore (structured) features in a high dimensional feature space (Vapnik, 1995), in this paper we propose using convolution tree kernel (Haussler, 1999; Collins and Duffy, 2001) to explore the structured syntactic knowledge for phrase reordering and further combine the tree kernel with other diverse linear features into a composite kernel to strengthen the model’s predictive ability. Indeed, using tree kernel methods to mine structured knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2001), semantic role labeling (Moschitti, 2004; Zhang et al., 2007b), relation extraction (Zhang et al., 2006), pronoun resolution (Yang et al., 2006) and question classification (Zhang and Lee, 2003). However, to our knowledge, such technique still remains unexplored for phrase reordering. In this paper, we look into the phrase reordering problem in two aspects: 1) how to model and optimize structured features, and 2) how to combine the structured features with other linear features and further integrate them into the loglinear model-based translation framework. Our study shows that: 1) the structured syntactic features are very useful a"
D09-1073,P06-1090,0,0.0388921,"Missing"
D09-1073,P02-1038,0,0.302388,"Missing"
D09-1073,P03-1021,0,0.0185461,"ining set, the NIST MT-2002 test set as development (dev) set and the NIST MT-2005 test set as test set. The Stanford parser (Klein and Manning, 2003) is used to parse Chinese sentences on the training, dev and test sets. GIZA++ (Och and Ney, 2004) and the heuristics “growdiag-final-and” are used to generate m-to-n word alignments. The translation model is trained on the FBIS corpus and a 4-gram language model is trained on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Kenser and Ney, 1995). For the MER training (Och, 2003), we modify Koehn’s MER trainer (Koehn, 2004) to train our system. For significance test, we use Zhang et al’s implementation (Zhang et al, 2004). Baseline Systems: we set three baseline systems: B1) Moses (Koehn et al., 2007) that uses lexicalized unigram reordering model to predict three orientations: monotone, swap and discontinuous; B2) MaxEnt-based reordering model with lexical boundary word features only (Xiong et al., 2006); B3) Linguistically annotated reordering model for BTG-based (LABTG) SMT (Xiong et al., 2008). For Moses, we used the default settings. We build a CKY-style decoder"
D09-1073,J03-1002,0,0.00624359,"Missing"
D09-1073,J04-4002,0,0.599379,"the context of statistical machine translation. Our study reveals that the structured syntactic features over the source phrases are very effective for BTG constraint-based phrase reordering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-ba"
D09-1073,P02-1040,0,0.0787709,"0450736/maxent.html A normal SMT decoder filters a translation model according to the source sentences, whereas in forced decoding, a translation model is filtered based on both source sentence and target references. In other words, in forced decoding, the decoder is forced to use those phrases whose translations are already in the references. 3 703 training, dev and test data. By forced decoding, we aim to isolate the reordering problem from those of OOV and lexical selections resulting from imperfect translation model in the context of a real SMT task. Besides the the case-sensitive BLEU-4 (Papineni et al., 2002) used in the two experiments, we design another evaluation metrics Reordering Accuracy (RAcc) for forced decoding evaluation. RAcc is the percentage of the adjacent word pairs with correct word order 4 over all words in one-best translation results. Similar to BLEU score, we also use the similar Brevity Penalty BP (Papineni et al., 2002) to penalize the short translations in computing RAcc. Finally, please note for the three evaluation metrics, the higher values represent better performance. reordering since only structured information is used in the tree kernel5. The CTs performs the worst am"
D09-1073,P07-1090,1,0.884642,"act of syntax on reordering is difficult to single out (Li et al., 2007). In phrasebased method, local word reordering1 can be effectively captured by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited. This makes the phrasebased method particularly weak in handling global phrase reordering. From machine learning viewpoint (Vapnik, 1995), it is computationally infeasible to explicitly generate features involving structured information in many NLP applica1 Thi"
D09-1073,P08-1066,0,0.0260045,"ell captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of how to utilize structured syntactic features for phras"
D09-1073,N04-4026,0,0.0407902,"rformance is subject to parsing errors to a large extent (zhang et al., 2007a) and the impact of syntax on reordering is difficult to single out (Li et al., 2007). In phrasebased method, local word reordering1 can be effectively captured by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited. This makes the phrasebased method particularly weak in handling global phrase reordering. From machine learning viewpoint (Vapnik, 1995), it is computationally in"
D09-1073,D07-1077,0,0.0420116,"Missing"
D09-1073,J97-3002,0,0.46112,"als that the structured syntactic features over the source phrases are very effective for BTG constraint-based phrase reordering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased"
D09-1073,P08-2038,1,0.916679,"red by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited. This makes the phrasebased method particularly weak in handling global phrase reordering. From machine learning viewpoint (Vapnik, 1995), it is computationally infeasible to explicitly generate features involving structured information in many NLP applica1 This paper follows the term convention of global reordering and local reordering of Li et al. (2007), between which the distinction is solely de"
D09-1073,P01-1067,0,0.126493,"he structured syntactic features over the source phrases are very effective for BTG constraint-based phrase reordering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-synta"
D09-1073,P06-1006,0,0.0225869,"space (Vapnik, 1995), in this paper we propose using convolution tree kernel (Haussler, 1999; Collins and Duffy, 2001) to explore the structured syntactic knowledge for phrase reordering and further combine the tree kernel with other diverse linear features into a composite kernel to strengthen the model’s predictive ability. Indeed, using tree kernel methods to mine structured knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2001), semantic role labeling (Moschitti, 2004; Zhang et al., 2007b), relation extraction (Zhang et al., 2006), pronoun resolution (Yang et al., 2006) and question classification (Zhang and Lee, 2003). However, to our knowledge, such technique still remains unexplored for phrase reordering. In this paper, we look into the phrase reordering problem in two aspects: 1) how to model and optimize structured features, and 2) how to combine the structured features with other linear features and further integrate them into the loglinear model-based translation framework. Our study shows that: 1) the structured syntactic features are very useful and 2) our kernel-based model can well explore diverse knowledge, including previously-used linear featur"
D09-1073,C04-1030,0,0.0213454,"icitly addressed by translation rules, thus the performance is subject to parsing errors to a large extent (zhang et al., 2007a) and the impact of syntax on reordering is difficult to single out (Li et al., 2007). In phrasebased method, local word reordering1 can be effectively captured by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited. This makes the phrasebased method particularly weak in handling global phrase reordering. From machine learning view"
D09-1073,W06-3108,0,0.0417611,"based method, local word reordering1 can be effectively captured by phrase pairs directly while local phrase reordering is explicitly modeled by phrase reordering model and distortion model. Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008). However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited. This makes the phrasebased method particularly weak in handling global phrase reordering. From machine learning viewpoint (Vapnik, 1995), it is computationally infeasible to explicitly generate features involving structured information in many NLP applica1 This paper follows the term convention of global reordering and local reordering o"
D09-1073,P06-1104,1,0.942046,"d) features in a high dimensional feature space (Vapnik, 1995), in this paper we propose using convolution tree kernel (Haussler, 1999; Collins and Duffy, 2001) to explore the structured syntactic knowledge for phrase reordering and further combine the tree kernel with other diverse linear features into a composite kernel to strengthen the model’s predictive ability. Indeed, using tree kernel methods to mine structured knowledge has shown success in some NLP applications like parsing (Collins and Duffy, 2001), semantic role labeling (Moschitti, 2004; Zhang et al., 2007b), relation extraction (Zhang et al., 2006), pronoun resolution (Yang et al., 2006) and question classification (Zhang and Lee, 2003). However, to our knowledge, such technique still remains unexplored for phrase reordering. In this paper, we look into the phrase reordering problem in two aspects: 1) how to model and optimize structured features, and 2) how to combine the structured features with other linear features and further integrate them into the loglinear model-based translation framework. Our study shows that: 1) the structured syntactic features are very useful and 2) our kernel-based model can well explore diverse knowledge,"
D09-1073,D07-1056,0,0.675501,"rdering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of how to utilize struc"
D09-1073,P07-1026,1,0.628254,"rdering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of how to utilize struc"
D09-1073,2007.mtsummit-papers.71,1,0.856955,"rdering and those features can be well captured by the tree kernel. We further combine the structured features and other commonly-used linear features into a composite kernel. Experimental results on the NIST MT-2005 Chinese-English translation tasks show that our proposed phrase reordering model statistically significantly outperforms the baseline methods. 1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT). As the two technologies are complementary in many ways, an interesting research topic is how to combine the strengths of the two methods. Many research efforts have been made to address this issue, which can be summarized into two ideas. One is to add syntax into phrase-based model while another one is to enhance syntaxbased model to handle non-syntactic phrases. In this paper, we bring forward the first idea by studying the issue of how to utilize struc"
D09-1073,C08-1138,1,0.857272,"Missing"
D09-1073,C04-1073,0,\N,Missing
D09-1073,P03-1054,0,\N,Missing
D09-1073,P08-1064,1,\N,Missing
D09-1073,P06-1066,0,\N,Missing
D09-1073,W06-1628,0,\N,Missing
D09-1073,W06-1606,0,\N,Missing
D09-1073,W06-1609,0,\N,Missing
D09-1073,P05-1033,0,\N,Missing
D09-1073,N03-1017,0,\N,Missing
D09-1073,zhang-etal-2004-interpreting,0,\N,Missing
D09-1108,N04-1035,0,0.124929,"to h. A non-terminal node in a packed forest can be represented as “label [start, stop]”, where “label” is its syntax category and “[start, stop]” is the range of words it covers. For example, the node in Fig. 5 pointed by the dark arrow is labelled as “NP[3,4]”, where NP is its label and [3,4] means that it covers the span from the 3rd word to the 4th word. In forest-based translation, rule matching is much more complicated than the tree-based one. XNA declaration is related to some regulation Figure 2. A packed forest Figure 1. A tree-to-string translation process. The tree-to-string model (Galley et al. 2004; Liu et al. 2006) views the translation as a structure map1038 Zhang et al. (2009) reduce the tree sequence problem into tree problem by introducing virtual node and related forest conversion algorithms, so the algorithm proposed in this paper is also applicable to the tree sequence-based models. Figure 3. Tree 1 (T1) 3 Figure 4. Tree 2 (T2) Matching Methods in Previous Work In this section, we discuss the two typical rule matching algorithms used in previous work. 3.1 For example, if we want to extract useful rules for node NP[3,4] in Fig 5, we have to generate all the tree fragments rooted"
D09-1108,P01-1044,0,0.145454,"tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence. Fig. 1 illustrates this process. In real translation, the number of possible tree fragment segmentations for a given input tree is exponential in the number of tree nodes. 2.2 Forest-based translation To overcome parse error for SMT, Mi and Huang (2008) propose forest-based translation by using a packed forest instead of a single syntax tree as the translation input. A packed forest (Tomita 1987; Klein and Manning, 2001; Huang and Chiang, 2005) is a compact representation of many possible parse trees of a sentence, which can be for, where V is mally described as a triple the set of non-terminal nodes, E is the set of hyper-edges and S is a sentence represented as an ordered word sequence. A hyper-edge in a packed forest is a group of edges in a tree which connects a father node to all its children nodes, representing a CFG-based parse rule. Fig. 2 is a packed forest incorporating two parse trees T1 and T2 of a sentence as shown in Fig. 3 and Fig. 4. Given a hyper-edge e, let h be its father node, then we say"
D09-1108,J99-4005,0,0.0555456,"anslation rules are extracted from the entire rule set by matching the source parse tree/forest. The second step is to decode the source sentence into its target one using the extracted translation rules. Both of the two steps are very time-consuming due to the exponential number of translation rules and the complex nature of machine translation as 1 Given a source structure (either a parse tree or a parse forest), a translation rule is applicable if and only if the left hand side of the translation rule exactly matches a tree fragment of the given source structure. an NP-hard search problem (Knight, 1999). In the SMT research community, the second step has been well studied and many methods have been proposed to speed up the decoding process, such as node-based or span-based beam search with different pruning strategies (Liu et al., 2006; Zhang et al., 2008a, 2008b) and cube pruning (Huang and Chiang, 2007; Mi et al., 2008). However, the first step attracts less attention. The previous solution to this problem is to do exhaustive searching with heuristics on each tree/forest node or on each source span. This solution becomes computationally infeasible when it is applied to packed forests with"
D09-1108,P07-2045,0,0.0122955,"Missing"
D09-1108,P06-1077,0,0.15997,"node in a packed forest can be represented as “label [start, stop]”, where “label” is its syntax category and “[start, stop]” is the range of words it covers. For example, the node in Fig. 5 pointed by the dark arrow is labelled as “NP[3,4]”, where NP is its label and [3,4] means that it covers the span from the 3rd word to the 4th word. In forest-based translation, rule matching is much more complicated than the tree-based one. XNA declaration is related to some regulation Figure 2. A packed forest Figure 1. A tree-to-string translation process. The tree-to-string model (Galley et al. 2004; Liu et al. 2006) views the translation as a structure map1038 Zhang et al. (2009) reduce the tree sequence problem into tree problem by introducing virtual node and related forest conversion algorithms, so the algorithm proposed in this paper is also applicable to the tree sequence-based models. Figure 3. Tree 1 (T1) 3 Figure 4. Tree 2 (T2) Matching Methods in Previous Work In this section, we discuss the two typical rule matching algorithms used in previous work. 3.1 For example, if we want to extract useful rules for node NP[3,4] in Fig 5, we have to generate all the tree fragments rooted at node NP[3,4] as"
D09-1108,P07-1089,0,0.149621,"Missing"
D09-1108,P08-1023,0,0.272369,"Missing"
D09-1108,D08-1022,0,0.407315,"d tree-to-string translation model which serves as the translation platform in this paper. 2.1 Tree-to-string model ping process, which first breaks the source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence. Fig. 1 illustrates this process. In real translation, the number of possible tree fragment segmentations for a given input tree is exponential in the number of tree nodes. 2.2 Forest-based translation To overcome parse error for SMT, Mi and Huang (2008) propose forest-based translation by using a packed forest instead of a single syntax tree as the translation input. A packed forest (Tomita 1987; Klein and Manning, 2001; Huang and Chiang, 2005) is a compact representation of many possible parse trees of a sentence, which can be for, where V is mally described as a triple the set of non-terminal nodes, E is the set of hyper-edges and S is a sentence represented as an ordered word sequence. A hyper-edge in a packed forest is a group of edges in a tree which connects a father node to all its children nodes, representing a CFG-based parse rule."
D09-1108,J03-1002,0,0.00845557,"Missing"
D09-1108,J87-1004,0,0.554845,"source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence. Fig. 1 illustrates this process. In real translation, the number of possible tree fragment segmentations for a given input tree is exponential in the number of tree nodes. 2.2 Forest-based translation To overcome parse error for SMT, Mi and Huang (2008) propose forest-based translation by using a packed forest instead of a single syntax tree as the translation input. A packed forest (Tomita 1987; Klein and Manning, 2001; Huang and Chiang, 2005) is a compact representation of many possible parse trees of a sentence, which can be for, where V is mally described as a triple the set of non-terminal nodes, E is the set of hyper-edges and S is a sentence represented as an ordered word sequence. A hyper-edge in a packed forest is a group of edges in a tree which connects a father node to all its children nodes, representing a CFG-based parse rule. Fig. 2 is a packed forest incorporating two parse trees T1 and T2 of a sentence as shown in Fig. 3 and Fig. 4. Given a hyper-edge e, let h be its"
D09-1108,zhang-etal-2004-interpreting,0,0.105268,"Missing"
D09-1108,A00-2018,0,\N,Missing
D09-1108,C08-1138,1,\N,Missing
D09-1108,W05-1506,0,\N,Missing
D09-1108,P02-1040,0,\N,Missing
D09-1108,P09-1020,1,\N,Missing
D09-1108,P08-1064,1,\N,Missing
D09-1108,P07-1019,0,\N,Missing
D09-1108,W01-1812,0,\N,Missing
D09-1108,P03-1021,0,\N,Missing
D09-1161,E03-1005,0,0.0765955,"Missing"
D09-1161,P06-1055,0,0.260545,"a head-driven lexicalized model and a latent-annotation-based un-lexicalized model. Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively. 1 Introduction Statistical models have achieved great success in language parsing and obtained the state-of-theart results in a variety of languages. In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007). In lexicalized models, word information play a key role in modeling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual parsing models, many system combination meth"
D09-1161,N07-1051,0,0.289935,"lized model and a latent-annotation-based un-lexicalized model. Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively. 1 Introduction Statistical models have achieved great success in language parsing and obtained the state-of-theart results in a variety of languages. In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007). In lexicalized models, word information play a key role in modeling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual parsing models, many system combination methods for parsing have bee"
D09-1161,P02-1035,0,0.0204866,"versity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual parsing models, many system combination methods for parsing have been proposed (Henderson and Brill 1999; Zeman and Žabokrtský 2005; Sagae and Lavie 2006) and promising performance improvements have been reported. In addition, parsing re-ranking (Collins 2000; Riezler et al. 2002; Charniak and Johnson 2005; Huang 2008) has also been shown to be another effective technique to improve parsing performance. This technique utilizes a bunch of linguistic features to re-rank the k-best (Huang and Chiang 2005) output on the forest level or tree level. In prior work, system combination was applied on multiple parsers while re-ranking was applied on the k-best outputs of individual parsers. In this paper, we propose a linear model-based general framework for multiple parsers combination. The proposed framework leverages on the strengths of previous system combination and rerank"
D09-1161,P97-1003,0,0.239574,"both the Chinese and English Penn Treebank syntactic parsing task by combining two stateof-the-art parsing models, a head-driven lexicalized model and a latent-annotation-based un-lexicalized model. Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively. 1 Introduction Statistical models have achieved great success in language parsing and obtained the state-of-theart results in a variety of languages. In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007). In lexicalized models, word information play a key role in modeling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural"
D09-1161,N06-2033,0,0.822122,"ling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual parsing models, many system combination methods for parsing have been proposed (Henderson and Brill 1999; Zeman and Žabokrtský 2005; Sagae and Lavie 2006) and promising performance improvements have been reported. In addition, parsing re-ranking (Collins 2000; Riezler et al. 2002; Charniak and Johnson 2005; Huang 2008) has also been shown to be another effective technique to improve parsing performance. This technique utilizes a bunch of linguistic features to re-rank the k-best (Huang and Chiang 2005) output on the forest level or tree level. In prior work, system combination was applied on multiple parsers while re-ranking was applied on the k-best outputs of individual parsers. In this paper, we propose a linear model-based general framework"
D09-1161,W02-1001,0,0.114872,"and English Penn Treebank corpus. Experimental results show that our final results, an F-Score of 92.62 on English and 85.45 on Chinese, outperform the previously best-reported systems by 0.52 point and 1.21 point, respectively. This convincingly demonstrates the effectiveness of our proposed framework. Our study also shows that the simulated-annealing algorithm (Kirkpatrick et al. 1983) is more effective 1552 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1552–1560, c Singapore, 6-7 August 2009. 2009 ACL and AFNLP than the perceptron algorithm (Collins 2002) for feature weight tuning. The rest of this paper is organized as follows. Section 2 briefly reviews related work. Section 3 discusses our method while section 4 presents the feature weight tuning algorithm. In Section 5, we report our experimental results and then conclude in Section 6. 2 Related Work As discussed in the previous section, system combination and re-ranking are two techniques to improve parsing performance by postprocessing parsers’ k-best outputs. Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an ent"
D09-1161,P08-1067,0,0.121123,"rom each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual parsing models, many system combination methods for parsing have been proposed (Henderson and Brill 1999; Zeman and Žabokrtský 2005; Sagae and Lavie 2006) and promising performance improvements have been reported. In addition, parsing re-ranking (Collins 2000; Riezler et al. 2002; Charniak and Johnson 2005; Huang 2008) has also been shown to be another effective technique to improve parsing performance. This technique utilizes a bunch of linguistic features to re-rank the k-best (Huang and Chiang 2005) output on the forest level or tree level. In prior work, system combination was applied on multiple parsers while re-ranking was applied on the k-best outputs of individual parsers. In this paper, we propose a linear model-based general framework for multiple parsers combination. The proposed framework leverages on the strengths of previous system combination and reranking methods and is open to any type of f"
D09-1161,W01-1812,0,0.0341403,"Briefly speaking, latent-annotation model views each non-terminal in the Treebank as a non-terminal followed by a set of latent variables, and uses EM algorithms to automatically learn the latent variables’ probability functions to maximize the probability of the given training data. Take the following binarized rule as example, could be viewed as the set of rules The process of computing the probability of a normal tree is to first binarized all the rules in it, and then replace each rule to the corresponding set of rules with latent variables. Now the previous tree becomes a packed forest (Klein and Manning 2001; Petrov et al. 2007) in the latentannotation model, and its probability is the inside probability of the root node. This model is quite different from the head-driven model in which 1554 the probability of a tree is just the product all the rules’ probability. 3.3 Constituent Counts Besides the two model scores, we also adopt constituent count as an additional feature inspired by (Henderson and Brill 1999) and (Sagae and Lavie 2006). A constituent is a non-terminal node covering a special span. For example, “NP[2,4]” means a constituent labelled as “NP” which covers the span from the second w"
D09-1161,P03-1054,0,0.0220626,"combining two stateof-the-art parsing models, a head-driven lexicalized model and a latent-annotation-based un-lexicalized model. Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively. 1 Introduction Statistical models have achieved great success in language parsing and obtained the state-of-theart results in a variety of languages. In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007). In lexicalized models, word information play a key role in modeling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual p"
D09-1161,W99-0623,0,0.81626,"ized models, word information play a key role in modeling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity. Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper). Therefore, it is natural to combine the two models for better parsing performance. Besides individual parsing models, many system combination methods for parsing have been proposed (Henderson and Brill 1999; Zeman and Žabokrtský 2005; Sagae and Lavie 2006) and promising performance improvements have been reported. In addition, parsing re-ranking (Collins 2000; Riezler et al. 2002; Charniak and Johnson 2005; Huang 2008) has also been shown to be another effective technique to improve parsing performance. This technique utilizes a bunch of linguistic features to re-rank the k-best (Huang and Chiang 2005) output on the forest level or tree level. In prior work, system combination was applied on multiple parsers while re-ranking was applied on the k-best outputs of individual parsers. In this paper,"
D09-1161,J93-2004,0,0.0341485,"Missing"
D09-1161,N06-1020,0,0.0614305,"two parameter estimation algorithms with significant test; “SA.” is simulated annealing, “AP.” is averaged perceptron, “P-value” is the significant test p-value. 5.6 Table 6. F1 score on 50-best combination with different feature configuration. “I” means the constituent count, “B” means Berkeley parser confidence score and “C” means Charniak parser confidence score. 5.5 Algo. Lang Performance-Enhanced Parsers on English Individual For Charniak’s lexicalized parser, there are two techniques to improve its performance. One is reranking as explained in section 2. The other is the self-training (McClosky et al. 2006) which first parses and reranks the NANC corpus, and then use them as additional training data to retrain the model. In this sub-section, we apply our method to combine the Berkeley parser and the enhanced Charniak parser by using the new model confidence score output from the enhanced Charniak parser. Table 9 and Table 10 show that the Charniak parser enhanced by re-ranking and self-training is able to help to further improve the performance of our method. This is because that the enhanced Charniak parser provides more accurate model confidence score. 1558 parser accuracy P <=40 R words F P A"
D09-1161,A00-2018,0,\N,Missing
D09-1161,W05-1506,0,\N,Missing
D09-1161,J03-4003,0,\N,Missing
D09-1161,P05-1022,0,\N,Missing
D09-1161,W05-1518,0,\N,Missing
D09-1161,P05-1010,0,\N,Missing
D09-1161,D08-1092,0,\N,Missing
D10-1043,N04-1035,0,0.750571,"es to convert the source structures into target structures iteratively and recursively while from decoding viewpoint a syntax-based system segments an input tree/forest into many sub-fragments, translates each of them separately, combines the translated sub-fragments and then finds out the best combinations. Therefore, from bilingual viewpoint, we face two fundamental problems: the mapping between bilingual structures and the way of carrying out the target structures combination. For the first issue, a number of models have been proposed to model the structure mapping between tree and string (Galley et al., 2004; Liu et al., 2006; Yamada and Knight, 2001; DeNeefe and Knight, 2009) and between tree and tree (Eisner, 2003; Zhang et al., 2007 & 2008; Liu et al., 2009). However, one of the major challenges is that all the current models only allow one-to-one mapping from one source frontier non-terminal node (Galley et al., 2004) to one target frontier non-terminal node in a bilingual translation rule. Therefore, all those translation equivalents with one-to-many frontier non-terminal node mapping cannot be covered by the current state-of-the-art models. This may largely compromise the modeling ability o"
D10-1043,P08-1067,0,0.225468,"ide (string to tree model). There is no well study in considering both the source side information and the compatibility between different target syntactic structures during combination. In addition, it is well known that the traditional tree-to-tree models suffer heavily from the data sparseness issue in training and the spurious-ambiguity translation path issue (the same translation with different syntactic structures) in decoding. In addition, because of the performance limitation of automatic syntactic parser, researchers propose using packed forest (Tomita, 1987; Klein and Manning, 2001; Huang, 2008)1 instead of 1-best parse tree to carry out training (Mi and Huang, 2008) and decoding (Mi et al., 2008) in order to reduce the side effect caused by parsing errors of the one-best tree. However, when we apply the tree-to-tree model to the bilingual forest structures, both training and decoding become very complicated. In this paper, to address the first issue, we propose a framework to model the non-isomorphic translation process from source tree fragment to target tree sequence, allowing any one source frontier non-terminal node to be translated into any number of target frontier non-termina"
D10-1043,W01-1812,0,0.0401448,"onal Linguistics target side (string to tree model). There is no well study in considering both the source side information and the compatibility between different target syntactic structures during combination. In addition, it is well known that the traditional tree-to-tree models suffer heavily from the data sparseness issue in training and the spurious-ambiguity translation path issue (the same translation with different syntactic structures) in decoding. In addition, because of the performance limitation of automatic syntactic parser, researchers propose using packed forest (Tomita, 1987; Klein and Manning, 2001; Huang, 2008)1 instead of 1-best parse tree to carry out training (Mi and Huang, 2008) and decoding (Mi et al., 2008) in order to reduce the side effect caused by parsing errors of the one-best tree. However, when we apply the tree-to-tree model to the bilingual forest structures, both training and decoding become very complicated. In this paper, to address the first issue, we propose a framework to model the non-isomorphic translation process from source tree fragment to target tree sequence, allowing any one source frontier non-terminal node to be translated into any number of target fronti"
D10-1043,2003.mtsummit-papers.6,0,0.12256,"Missing"
D10-1043,D09-1076,0,0.125793,"tively and recursively while from decoding viewpoint a syntax-based system segments an input tree/forest into many sub-fragments, translates each of them separately, combines the translated sub-fragments and then finds out the best combinations. Therefore, from bilingual viewpoint, we face two fundamental problems: the mapping between bilingual structures and the way of carrying out the target structures combination. For the first issue, a number of models have been proposed to model the structure mapping between tree and string (Galley et al., 2004; Liu et al., 2006; Yamada and Knight, 2001; DeNeefe and Knight, 2009) and between tree and tree (Eisner, 2003; Zhang et al., 2007 & 2008; Liu et al., 2009). However, one of the major challenges is that all the current models only allow one-to-one mapping from one source frontier non-terminal node (Galley et al., 2004) to one target frontier non-terminal node in a bilingual translation rule. Therefore, all those translation equivalents with one-to-many frontier non-terminal node mapping cannot be covered by the current state-of-the-art models. This may largely compromise the modeling ability of translation rules. For the second problem, currently, the combinatio"
D10-1043,P03-2041,0,0.29126,"a syntax-based system segments an input tree/forest into many sub-fragments, translates each of them separately, combines the translated sub-fragments and then finds out the best combinations. Therefore, from bilingual viewpoint, we face two fundamental problems: the mapping between bilingual structures and the way of carrying out the target structures combination. For the first issue, a number of models have been proposed to model the structure mapping between tree and string (Galley et al., 2004; Liu et al., 2006; Yamada and Knight, 2001; DeNeefe and Knight, 2009) and between tree and tree (Eisner, 2003; Zhang et al., 2007 & 2008; Liu et al., 2009). However, one of the major challenges is that all the current models only allow one-to-one mapping from one source frontier non-terminal node (Galley et al., 2004) to one target frontier non-terminal node in a bilingual translation rule. Therefore, all those translation equivalents with one-to-many frontier non-terminal node mapping cannot be covered by the current state-of-the-art models. This may largely compromise the modeling ability of translation rules. For the second problem, currently, the combination is driven by only the source side (bot"
D10-1043,P07-1089,0,0.0907619,"ganized as following. Section 2 reviews the related work. In section 3 and section 4, we discuss the proposed forest-based rule extraction (non-isomorphic mapping) and decoding algorithms (target syntax information usage). Finally we report the experimental results in section 5 and conclude the paper in section 6. 2 Related Work Much effort has been done in the syntax-based translation modeling. Yamada and Knight (2001) propose a string to tree model. Galley et al. (2004) propose the GHKM scheme to model the string-to-tree mapping. Liu et al. (2006) propose a tree-to-string translation model. Liu et al. (2007) propose the tree sequence to string model to capture rules covered by continuous sequence of trees. Shieber (2007), DeNeefe and Knight (2009) and Carreras and Collins (2009) propose synchronous tree adjoin grammar to capture more tree-string mapping beyond the GHKM scheme. Zhang et al. (2009a) propose the concept of virtual node to reform a tree sequence as a tree, and design efficient algorithms for tree sequence model in forest context. All these works only consider either the source side or the target side syntax information. To capture both side syntax contexts, Eisner (2003) studies the"
D10-1043,P09-1063,0,0.509039,"ree/forest into many sub-fragments, translates each of them separately, combines the translated sub-fragments and then finds out the best combinations. Therefore, from bilingual viewpoint, we face two fundamental problems: the mapping between bilingual structures and the way of carrying out the target structures combination. For the first issue, a number of models have been proposed to model the structure mapping between tree and string (Galley et al., 2004; Liu et al., 2006; Yamada and Knight, 2001; DeNeefe and Knight, 2009) and between tree and tree (Eisner, 2003; Zhang et al., 2007 & 2008; Liu et al., 2009). However, one of the major challenges is that all the current models only allow one-to-one mapping from one source frontier non-terminal node (Galley et al., 2004) to one target frontier non-terminal node in a bilingual translation rule. Therefore, all those translation equivalents with one-to-many frontier non-terminal node mapping cannot be covered by the current state-of-the-art models. This may largely compromise the modeling ability of translation rules. For the second problem, currently, the combination is driven by only the source side (both tree-to-string model and tree-to-tree model"
D10-1043,D08-1022,0,0.35328,"both the source side information and the compatibility between different target syntactic structures during combination. In addition, it is well known that the traditional tree-to-tree models suffer heavily from the data sparseness issue in training and the spurious-ambiguity translation path issue (the same translation with different syntactic structures) in decoding. In addition, because of the performance limitation of automatic syntactic parser, researchers propose using packed forest (Tomita, 1987; Klein and Manning, 2001; Huang, 2008)1 instead of 1-best parse tree to carry out training (Mi and Huang, 2008) and decoding (Mi et al., 2008) in order to reduce the side effect caused by parsing errors of the one-best tree. However, when we apply the tree-to-tree model to the bilingual forest structures, both training and decoding become very complicated. In this paper, to address the first issue, we propose a framework to model the non-isomorphic translation process from source tree fragment to target tree sequence, allowing any one source frontier non-terminal node to be translated into any number of target frontier non-terminal nodes. For the second issue, we propose a technology to model the combi"
D10-1043,P03-1021,0,0.0713388,"of our method is consistent across data set of different size. We use the NIST 2002 test set as our dev set, and NIST 2003 and NIST 2005 test sets as our test set. A 3-gram language model is trained on the target side of the training data by the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We train Charniak’s parser (Charniak, 2000) on CTB5.0 for Chinese and ETB3.0 for English and modify it to output packed forest. GIZA++ (Och and Ney, 2003) and the heuristics “grow-diag-final-and” are used to generate m-to-n word alignments. For the MER training (Och, 2003), Koehn’s MER trainer (Koehn, 2007) is modified for our system. For significance test, we use Zhang et al.’s implementation (Zhang et al, 2004). Our evaluation metrics is case-sensitive closest BLEU-4 (Papineni et al., 2002). We use following features in our systems: 1) bidirectional tree-to-tree sequence probability, 2) bidirectional tree-to-string probability, 3) bidirectional lexical translation probability, 4) target language model, 5) source tree probability 6) the av447 erage number of unmatched nodes in the target forest. 7) the length of the target translation, 8) the number of glue ru"
D10-1043,J03-1002,0,0.00671401,"on a set of parallel data with 30K sentence pairs, and then do experiment on a larger data set to ensure that the effectiveness of our method is consistent across data set of different size. We use the NIST 2002 test set as our dev set, and NIST 2003 and NIST 2005 test sets as our test set. A 3-gram language model is trained on the target side of the training data by the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We train Charniak’s parser (Charniak, 2000) on CTB5.0 for Chinese and ETB3.0 for English and modify it to output packed forest. GIZA++ (Och and Ney, 2003) and the heuristics “grow-diag-final-and” are used to generate m-to-n word alignments. For the MER training (Och, 2003), Koehn’s MER trainer (Koehn, 2007) is modified for our system. For significance test, we use Zhang et al.’s implementation (Zhang et al, 2004). Our evaluation metrics is case-sensitive closest BLEU-4 (Papineni et al., 2002). We use following features in our systems: 1) bidirectional tree-to-tree sequence probability, 2) bidirectional tree-to-string probability, 3) bidirectional lexical translation probability, 4) target language model, 5) source tree probability 6) the av447"
D10-1043,P02-1040,0,0.0862314,"t side of the training data by the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We train Charniak’s parser (Charniak, 2000) on CTB5.0 for Chinese and ETB3.0 for English and modify it to output packed forest. GIZA++ (Och and Ney, 2003) and the heuristics “grow-diag-final-and” are used to generate m-to-n word alignments. For the MER training (Och, 2003), Koehn’s MER trainer (Koehn, 2007) is modified for our system. For significance test, we use Zhang et al.’s implementation (Zhang et al, 2004). Our evaluation metrics is case-sensitive closest BLEU-4 (Papineni et al., 2002). We use following features in our systems: 1) bidirectional tree-to-tree sequence probability, 2) bidirectional tree-to-string probability, 3) bidirectional lexical translation probability, 4) target language model, 5) source tree probability 6) the av447 erage number of unmatched nodes in the target forest. 7) the length of the target translation, 8) the number of glue rules used. 5.2 Empirical Study on Small Data We set forest pruning threshold (Mi et al., 2008) to 8 on both source and target forests for rule extraction. For each source sub-tree, we set its height up to 3, width up to 7 and"
D10-1043,D09-1021,0,0.0309264,"Missing"
D10-1043,P01-1067,0,0.192485,"o target structures iteratively and recursively while from decoding viewpoint a syntax-based system segments an input tree/forest into many sub-fragments, translates each of them separately, combines the translated sub-fragments and then finds out the best combinations. Therefore, from bilingual viewpoint, we face two fundamental problems: the mapping between bilingual structures and the way of carrying out the target structures combination. For the first issue, a number of models have been proposed to model the structure mapping between tree and string (Galley et al., 2004; Liu et al., 2006; Yamada and Knight, 2001; DeNeefe and Knight, 2009) and between tree and tree (Eisner, 2003; Zhang et al., 2007 & 2008; Liu et al., 2009). However, one of the major challenges is that all the current models only allow one-to-one mapping from one source frontier non-terminal node (Galley et al., 2004) to one target frontier non-terminal node in a bilingual translation rule. Therefore, all those translation equivalents with one-to-many frontier non-terminal node mapping cannot be covered by the current state-of-the-art models. This may largely compromise the modeling ability of translation rules. For the second problem"
D10-1043,D09-1108,1,0.366976,"the paper in section 6. 2 Related Work Much effort has been done in the syntax-based translation modeling. Yamada and Knight (2001) propose a string to tree model. Galley et al. (2004) propose the GHKM scheme to model the string-to-tree mapping. Liu et al. (2006) propose a tree-to-string translation model. Liu et al. (2007) propose the tree sequence to string model to capture rules covered by continuous sequence of trees. Shieber (2007), DeNeefe and Knight (2009) and Carreras and Collins (2009) propose synchronous tree adjoin grammar to capture more tree-string mapping beyond the GHKM scheme. Zhang et al. (2009a) propose the concept of virtual node to reform a tree sequence as a tree, and design efficient algorithms for tree sequence model in forest context. All these works only consider either the source side or the target side syntax information. To capture both side syntax contexts, Eisner (2003) studies the bilingual dependency tree-to-tree mapping in conceptual level. Zhang et al. (2008) propose tree sequence-based tree-to-tree modeling. Liu et al. (2009) propose efficient algorithms for tree-to-tree model in the forest-based training and decoding scheme. One common limitation of the above work"
D10-1043,2007.mtsummit-papers.71,1,0.74833,"system segments an input tree/forest into many sub-fragments, translates each of them separately, combines the translated sub-fragments and then finds out the best combinations. Therefore, from bilingual viewpoint, we face two fundamental problems: the mapping between bilingual structures and the way of carrying out the target structures combination. For the first issue, a number of models have been proposed to model the structure mapping between tree and string (Galley et al., 2004; Liu et al., 2006; Yamada and Knight, 2001; DeNeefe and Knight, 2009) and between tree and tree (Eisner, 2003; Zhang et al., 2007 & 2008; Liu et al., 2009). However, one of the major challenges is that all the current models only allow one-to-one mapping from one source frontier non-terminal node (Galley et al., 2004) to one target frontier non-terminal node in a bilingual translation rule. Therefore, all those translation equivalents with one-to-many frontier non-terminal node mapping cannot be covered by the current state-of-the-art models. This may largely compromise the modeling ability of translation rules. For the second problem, currently, the combination is driven by only the source side (both tree-to-string mod"
D10-1043,zhang-etal-2004-interpreting,0,0.0257989,"05 test sets as our test set. A 3-gram language model is trained on the target side of the training data by the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995). We train Charniak’s parser (Charniak, 2000) on CTB5.0 for Chinese and ETB3.0 for English and modify it to output packed forest. GIZA++ (Och and Ney, 2003) and the heuristics “grow-diag-final-and” are used to generate m-to-n word alignments. For the MER training (Och, 2003), Koehn’s MER trainer (Koehn, 2007) is modified for our system. For significance test, we use Zhang et al.’s implementation (Zhang et al, 2004). Our evaluation metrics is case-sensitive closest BLEU-4 (Papineni et al., 2002). We use following features in our systems: 1) bidirectional tree-to-tree sequence probability, 2) bidirectional tree-to-string probability, 3) bidirectional lexical translation probability, 4) target language model, 5) source tree probability 6) the av447 erage number of unmatched nodes in the target forest. 7) the length of the target translation, 8) the number of glue rules used. 5.2 Empirical Study on Small Data We set forest pruning threshold (Mi et al., 2008) to 8 on both source and target forests for rule e"
D10-1043,A00-2018,0,\N,Missing
D10-1043,W05-1506,0,\N,Missing
D10-1043,P09-1020,1,\N,Missing
D10-1043,J87-1004,0,\N,Missing
D10-1043,P08-1023,0,\N,Missing
D10-1043,P06-1077,0,\N,Missing
D10-1043,P08-1064,1,\N,Missing
D10-1043,P07-2045,0,\N,Missing
D10-1043,P07-1019,0,\N,Missing
D10-1043,J07-2003,0,\N,Missing
D11-1007,D08-1092,0,0.318764,"design a set of effective bilingual features for parsing models based on the verified results. The experimental results show that our new parsers significantly outperform state-of-theart baselines. Moreover, our approach is still able to provide improvement when we use a larger monolingual treebank that results in a much stronger baseline. Especially notable is that our approach can be used in a purely monolingual setting with the help of SMT. 1 Introduction Recently there have been several studies aiming to improve the performance of parsing bilingual texts (bitexts) (Smith and Smith, 2004; Burkett and Klein, 2008; Huang et al., 2009; Zhao et al., 2009; Chen et al., 2010). In bitext parsing, we can use the information based on “bilingual constraints” (Burkett and Klein, 2008), which do not exist in monolingual sentences. More accurate bitext parsing results can be effectively used in the training of syntax-based machine translation systems (Liu and Huang, 2010). Most previous studies rely on bilingual treebanks to provide bilingual constraints for bitext parsing. Burkett and Klein (2008) proposed joint models on bitexts to improve the performance on either or both sides. Their method uses bilingual tre"
D11-1007,D07-1101,0,0.144195,"sponding to “技巧(jiqiao)/skill” is a grandchild of the word “play” corresponding to “发挥(fahui)/demonstrate”. This is a positive evidence for supporting “发 挥(fahui)/demonstrate” as being the head of “技 巧(jiqiao)/skill”. From this example, although the sentences and parse trees on the target side are not perfect, we still can explore useful information to improve bitext parsing. In this paper, we focus on how to design a method to verify such unreliable bilingual constraints. 3 Parsing model In this paper, we implement our approach based on graph-based parsing models (McDonald and Pereira, 2006; Carreras, 2007). Note that our approach can also be applied to transition-based parsing models (Nivre, 2003; Yamada and Matsumoto, 2003). The graph-based parsing model is to search for the maximum spanning tree (MST) in a graph (McDonald and Pereira, 2006). The formulation defines the score of a dependency tree to be the sum of edge scores, s(x, y) = X g∈y score(w, x, g) = X g∈y 4.2 Bilingual constraint functions w ·f (x, g) (1) where x is an input sentence, y is a dependency tree for x, and g is a spanning subgraph of y. f (x, g) can be based on arbitrary features of the subgraph and the input sequence x an"
D11-1007,D09-1060,1,0.927841,"list of the target monolingual subtrees 1 For the second order features, Dir is the combination of the directions of two dependencies. or bilingual subtrees, this constraint will probably be reliable. We first parse the large-scale unannotated monolingual and bilingual data. Subsequently, we extract the monolingual and bilingual subtrees from the parsed data. We then verify the bilingual constraints using the extracted subtrees. Finally, we generate the bilingual features based on the verified results for the parsing models. 5.1 Verified constraint functions 5.1.1 Monolingual target subtrees Chen et al. (2009) proposed a simple method to extract subtrees from large-scale monolingual data and used them as features to improve monolingual parsing. Following their method, we parse large unannotated data with the Parsert and obtain the subtree list (STt ) on the target side. We extract two types of subtrees: bigram (two words) subtree and trigram (three words) subtree. 5.1.2 Verified target constraint function: Fvt (rtk ) We use the extracted target subtrees to verify the rtk of the bilingual constraints. In fact, rtk is a candidate subtree. If the rtk is included in STt , function Fvt (rtk ) = T ype(rt"
D11-1007,P10-1003,1,0.243719,"based on the verified results. The experimental results show that our new parsers significantly outperform state-of-theart baselines. Moreover, our approach is still able to provide improvement when we use a larger monolingual treebank that results in a much stronger baseline. Especially notable is that our approach can be used in a purely monolingual setting with the help of SMT. 1 Introduction Recently there have been several studies aiming to improve the performance of parsing bilingual texts (bitexts) (Smith and Smith, 2004; Burkett and Klein, 2008; Huang et al., 2009; Zhao et al., 2009; Chen et al., 2010). In bitext parsing, we can use the information based on “bilingual constraints” (Burkett and Klein, 2008), which do not exist in monolingual sentences. More accurate bitext parsing results can be effectively used in the training of syntax-based machine translation systems (Liu and Huang, 2010). Most previous studies rely on bilingual treebanks to provide bilingual constraints for bitext parsing. Burkett and Klein (2008) proposed joint models on bitexts to improve the performance on either or both sides. Their method uses bilingual treebanks that have human-annotated tree structures on both si"
D11-1007,P07-1003,0,0.126522,"ale unannotated data. 4.1 Auto-generated bilingual treebank Assuming that we have monolingual treebanks on the source side, an SMT system that can translate the source sentences into the target language, and a Parsert trained on the target monolingual treebank. We first translate the sentences of the source monolingual treebank into the target language using the SMT system. Usually, SMT systems can output the word alignment links directly. If they can not, we perform word alignment using some publicly available tools, such as Giza++ (Och and Ney, 2003) or Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007). The translated sentences are parsed by the Parsert . Then, we have a newly auto-generated bilingual treebank. 76 In this paper, we focus on the first- and secondorder graph models (McDonald and Pereira, 2006; Carreras, 2007). Thus we produce the constraints for bigram (a single edge) and trigram (adjacent edges) dependencies in the graph model. For the trigram dependencies, we consider the parent-sibling and parent-child-grandchild structures described in McDonald and Pereira (2006) and Carreras (2007). We leave the third-order models (Koo and Collins, 2010) for a future study. Suppose that"
D11-1007,D09-1127,0,0.0657088,"Missing"
D11-1007,N03-1017,0,0.0160094,"Missing"
D11-1007,P10-1001,0,0.0121108,"ley Aligner (Liang et al., 2006; DeNero and Klein, 2007). The translated sentences are parsed by the Parsert . Then, we have a newly auto-generated bilingual treebank. 76 In this paper, we focus on the first- and secondorder graph models (McDonald and Pereira, 2006; Carreras, 2007). Thus we produce the constraints for bigram (a single edge) and trigram (adjacent edges) dependencies in the graph model. For the trigram dependencies, we consider the parent-sibling and parent-child-grandchild structures described in McDonald and Pereira (2006) and Carreras (2007). We leave the third-order models (Koo and Collins, 2010) for a future study. Suppose that we have a (candidate) dependency relation rs that can be a bigram or trigram dependency. We examine whether the corresponding words of the source words of rs have a dependency relation rt in the target trees. We also consider the direction of the dependency relation. The corresponding word of the head should also be the head in rt . We define a binary function for this bilingual constraint: Fbn (rsn : rtk ), where n and k refers to the types of the dependencies (2 for bigram and 3 for trigram). For example, in rs2 : rt3 , rs2 is a bigram dependency on the sour"
D11-1007,P09-1058,1,0.820133,"//www.itl.nist.gov/iad/mig//tests/mt/2008/ 4 data. To extract English subtrees, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ texts. We used the MXPOST tagger (Ratnaparkhi, 1996) trained on training data to assign POS tags and used the first-order Parsert to process the sentences of the BLLIP corpus. To extract bilingual subtrees, we used the FBIS corpus and an additional bilingual corpus containing 800,000 sentence pairs from the training data of NIST MT08 evaluation campaign. On the Chinese side, we used the morphological analyzer described in (Kruengkrai et al., 2009) trained on the training data of CTBtp to perform word segmentation and POS tagging and used the first-order Parsers to parse all the sentences in the data. On the English side, we used the same procedure as we did for the BLLIP corpus. Word alignment was performed using the Berkeley Aligner. We reported the parser quality by the UAS, i.e., the percentage of tokens (excluding all punctuation tokens) with correct HEADs. 6.1 Experimental settings For baseline systems, we used the monolingual features mentioned in Section 3. We called these features basic features. To compare the results of (Burk"
D11-1007,N06-1014,0,0.079112,"ed by using large-scale unannotated data. 4.1 Auto-generated bilingual treebank Assuming that we have monolingual treebanks on the source side, an SMT system that can translate the source sentences into the target language, and a Parsert trained on the target monolingual treebank. We first translate the sentences of the source monolingual treebank into the target language using the SMT system. Usually, SMT systems can output the word alignment links directly. If they can not, we perform word alignment using some publicly available tools, such as Giza++ (Och and Ney, 2003) or Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007). The translated sentences are parsed by the Parsert . Then, we have a newly auto-generated bilingual treebank. 76 In this paper, we focus on the first- and secondorder graph models (McDonald and Pereira, 2006; Carreras, 2007). Thus we produce the constraints for bigram (a single edge) and trigram (adjacent edges) dependencies in the graph model. For the trigram dependencies, we consider the parent-sibling and parent-child-grandchild structures described in McDonald and Pereira (2006) and Carreras (2007). We leave the third-order models (Koo and Collins, 2010) for a fu"
D11-1007,P10-5002,0,0.0237031,"able is that our approach can be used in a purely monolingual setting with the help of SMT. 1 Introduction Recently there have been several studies aiming to improve the performance of parsing bilingual texts (bitexts) (Smith and Smith, 2004; Burkett and Klein, 2008; Huang et al., 2009; Zhao et al., 2009; Chen et al., 2010). In bitext parsing, we can use the information based on “bilingual constraints” (Burkett and Klein, 2008), which do not exist in monolingual sentences. More accurate bitext parsing results can be effectively used in the training of syntax-based machine translation systems (Liu and Huang, 2010). Most previous studies rely on bilingual treebanks to provide bilingual constraints for bitext parsing. Burkett and Klein (2008) proposed joint models on bitexts to improve the performance on either or both sides. Their method uses bilingual treebanks that have human-annotated tree structures on both sides. Huang et al. (2009) presented a method to train a source-language parser by using the reordering information on words between the sentences on two sides. It uses another type of bilingual treebanks that have tree structures on the source sentences and their human-translated sentences. Chen"
D11-1007,J93-2004,0,0.0430468,"ingual treebanks that have tree structures on the source sentences and their human-translated sentences. Chen et al. (2010) also used bilingual treebanks and made use of tree structures on the target side. However, the bilingual treebanks are hard to obtain, partly because of the high cost of human translation. Thus, in their experiments, they applied their methods to a small data set, the manually translated portion of the Chinese Treebank (CTB) which contains only about 3,000 sentences. On the other hand, many large-scale monolingual treebanks exist, such as the Penn English Treebank (PTB) (Marcus et al., 1993) (about 40,000 sentences in Version 3) and the latest version of CTB (over 50,000 sentences in Version 7). In this paper, we propose a bitext parsing approach in which we produce the bilingual constraints on existing monolingual treebanks with the help of SMT systems. In other words, we aim to improve source-language parsing with the help of automatic translations. In our approach, we first use an SMT system to translate the sentences of a source monolingual treebank into the target language. Then, the target sentences are parsed by a parser trained on a target monolingual treebank. We then ob"
D11-1007,E06-1011,0,0.17547,"ure, the word “skills” corresponding to “技巧(jiqiao)/skill” is a grandchild of the word “play” corresponding to “发挥(fahui)/demonstrate”. This is a positive evidence for supporting “发 挥(fahui)/demonstrate” as being the head of “技 巧(jiqiao)/skill”. From this example, although the sentences and parse trees on the target side are not perfect, we still can explore useful information to improve bitext parsing. In this paper, we focus on how to design a method to verify such unreliable bilingual constraints. 3 Parsing model In this paper, we implement our approach based on graph-based parsing models (McDonald and Pereira, 2006; Carreras, 2007). Note that our approach can also be applied to transition-based parsing models (Nivre, 2003; Yamada and Matsumoto, 2003). The graph-based parsing model is to search for the maximum spanning tree (MST) in a graph (McDonald and Pereira, 2006). The formulation defines the score of a dependency tree to be the sum of edge scores, s(x, y) = X g∈y score(w, x, g) = X g∈y 4.2 Bilingual constraint functions w ·f (x, g) (1) where x is an input sentence, y is a dependency tree for x, and g is a spanning subgraph of y. f (x, g) can be based on arbitrary features of the subgraph and the in"
D11-1007,W03-3017,0,0.0373708,"monstrate”. This is a positive evidence for supporting “发 挥(fahui)/demonstrate” as being the head of “技 巧(jiqiao)/skill”. From this example, although the sentences and parse trees on the target side are not perfect, we still can explore useful information to improve bitext parsing. In this paper, we focus on how to design a method to verify such unreliable bilingual constraints. 3 Parsing model In this paper, we implement our approach based on graph-based parsing models (McDonald and Pereira, 2006; Carreras, 2007). Note that our approach can also be applied to transition-based parsing models (Nivre, 2003; Yamada and Matsumoto, 2003). The graph-based parsing model is to search for the maximum spanning tree (MST) in a graph (McDonald and Pereira, 2006). The formulation defines the score of a dependency tree to be the sum of edge scores, s(x, y) = X g∈y score(w, x, g) = X g∈y 4.2 Bilingual constraint functions w ·f (x, g) (1) where x is an input sentence, y is a dependency tree for x, and g is a spanning subgraph of y. f (x, g) can be based on arbitrary features of the subgraph and the input sequence x and the feature weight vector w are the parameters to be learned by using MIRA (Crammer and Si"
D11-1007,J03-1002,0,0.00306085,"ased on the bilingual constraints verified by using large-scale unannotated data. 4.1 Auto-generated bilingual treebank Assuming that we have monolingual treebanks on the source side, an SMT system that can translate the source sentences into the target language, and a Parsert trained on the target monolingual treebank. We first translate the sentences of the source monolingual treebank into the target language using the SMT system. Usually, SMT systems can output the word alignment links directly. If they can not, we perform word alignment using some publicly available tools, such as Giza++ (Och and Ney, 2003) or Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007). The translated sentences are parsed by the Parsert . Then, we have a newly auto-generated bilingual treebank. 76 In this paper, we focus on the first- and secondorder graph models (McDonald and Pereira, 2006; Carreras, 2007). Thus we produce the constraints for bigram (a single edge) and trigram (adjacent edges) dependencies in the graph model. For the trigram dependencies, we consider the parent-sibling and parent-child-grandchild structures described in McDonald and Pereira (2006) and Carreras (2007). We leave the third-order"
D11-1007,W96-0213,0,0.0608525,"e trained first-order and second-order Parsert on the training data. The unlabeled attachment score (UAS) of the second-order Parsert was 91.92, indicating state-of-the-art accuracy on the test data. We used the second-order Parsert to parse the autotranslated/human-made target sentences in the CTB 3 http://www.statmt.org/moses/ http://www.speech.sri.com/projects/srilm/download.html 5 http://www.itl.nist.gov/iad/mig//tests/mt/2008/ 4 data. To extract English subtrees, we used the BLLIP corpus (Charniak et al., 2000) that contains about 43 million words of WSJ texts. We used the MXPOST tagger (Ratnaparkhi, 1996) trained on training data to assign POS tags and used the first-order Parsert to process the sentences of the BLLIP corpus. To extract bilingual subtrees, we used the FBIS corpus and an additional bilingual corpus containing 800,000 sentence pairs from the training data of NIST MT08 evaluation campaign. On the Chinese side, we used the morphological analyzer described in (Kruengkrai et al., 2009) trained on the training data of CTBtp to perform word segmentation and POS tagging and used the first-order Parsers to parse all the sentences in the data. On the English side, we used the same proced"
D11-1007,W04-3207,0,0.0134497,"ify the constraints and design a set of effective bilingual features for parsing models based on the verified results. The experimental results show that our new parsers significantly outperform state-of-theart baselines. Moreover, our approach is still able to provide improvement when we use a larger monolingual treebank that results in a much stronger baseline. Especially notable is that our approach can be used in a purely monolingual setting with the help of SMT. 1 Introduction Recently there have been several studies aiming to improve the performance of parsing bilingual texts (bitexts) (Smith and Smith, 2004; Burkett and Klein, 2008; Huang et al., 2009; Zhao et al., 2009; Chen et al., 2010). In bitext parsing, we can use the information based on “bilingual constraints” (Burkett and Klein, 2008), which do not exist in monolingual sentences. More accurate bitext parsing results can be effectively used in the training of syntax-based machine translation systems (Liu and Huang, 2010). Most previous studies rely on bilingual treebanks to provide bilingual constraints for bitext parsing. Burkett and Klein (2008) proposed joint models on bitexts to improve the performance on either or both sides. Their"
D11-1007,W03-3023,0,0.0472776,"his is a positive evidence for supporting “发 挥(fahui)/demonstrate” as being the head of “技 巧(jiqiao)/skill”. From this example, although the sentences and parse trees on the target side are not perfect, we still can explore useful information to improve bitext parsing. In this paper, we focus on how to design a method to verify such unreliable bilingual constraints. 3 Parsing model In this paper, we implement our approach based on graph-based parsing models (McDonald and Pereira, 2006; Carreras, 2007). Note that our approach can also be applied to transition-based parsing models (Nivre, 2003; Yamada and Matsumoto, 2003). The graph-based parsing model is to search for the maximum spanning tree (MST) in a graph (McDonald and Pereira, 2006). The formulation defines the score of a dependency tree to be the sum of edge scores, s(x, y) = X g∈y score(w, x, g) = X g∈y 4.2 Bilingual constraint functions w ·f (x, g) (1) where x is an input sentence, y is a dependency tree for x, and g is a spanning subgraph of y. f (x, g) can be based on arbitrary features of the subgraph and the input sequence x and the feature weight vector w are the parameters to be learned by using MIRA (Crammer and Singer, 2003) during training."
D11-1007,P09-1007,0,0.0415887,"for parsing models based on the verified results. The experimental results show that our new parsers significantly outperform state-of-theart baselines. Moreover, our approach is still able to provide improvement when we use a larger monolingual treebank that results in a much stronger baseline. Especially notable is that our approach can be used in a purely monolingual setting with the help of SMT. 1 Introduction Recently there have been several studies aiming to improve the performance of parsing bilingual texts (bitexts) (Smith and Smith, 2004; Burkett and Klein, 2008; Huang et al., 2009; Zhao et al., 2009; Chen et al., 2010). In bitext parsing, we can use the information based on “bilingual constraints” (Burkett and Klein, 2008), which do not exist in monolingual sentences. More accurate bitext parsing results can be effectively used in the training of syntax-based machine translation systems (Liu and Huang, 2010). Most previous studies rely on bilingual treebanks to provide bilingual constraints for bitext parsing. Burkett and Klein (2008) proposed joint models on bitexts to improve the performance on either or both sides. Their method uses bilingual treebanks that have human-annotated tree s"
D11-1109,D07-1101,0,0.442565,"d) = {(h,m)}⊆d m h dependency h s m sibling g + m h grandparent {(h,s)(h,m)}⊆d + g s h grand-sibling m h s t tri-sibling ∑ ∑ {(g,h),(h,m)}⊆d ∑ m + Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3 ) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3 ) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4 ) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4 ) for third-order models. In their paper, they implement two versions of third-order models, Model 1 and Model 2 according to their naming. Model 1 incorporates only grand-sibling parts, while Model 2 incorporates both grand-sibling and tri-sibling parts. Their experiments on English and Czech show that Model 1 and Model 2 obtain nearly the same parsing ac"
D11-1109,P05-1022,0,0.355797,"Missing"
D11-1109,C10-1019,1,0.878284,"Missing"
D11-1109,D07-1022,0,0.0164053,"Missing"
D11-1109,W02-1001,0,0.285248,"et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. 1181 ˆt = arg max Scorepos (x, t) t ˆ is determined Then, an optimal dependency tree d based on x and ˆt. ˆ = arg max Scoresyn (x, ˆt, d) d d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepos (x, t) = wpos · fpos (x, t) 2.2 Dependency Parsing Recently"
D11-1109,N09-1046,0,0.0525872,"Missing"
D11-1109,C96-1058,0,0.797918,"me with Model 1 in Koo and Collins (2010), but without using grand-sibling features.2 • The third-order model (O3): the same with Model 1 in Koo and Collins (2010). We adopt linear models to define the score of a dependency tree. For the third-order model, the score of a dependency tree is represented as: ∑ wdep · fdep (x, t, h, m) Scoresyn (x, t, d) = {(h,m)}⊆d m h dependency h s m sibling g + m h grandparent {(h,s)(h,m)}⊆d + g s h grand-sibling m h s t tri-sibling ∑ ∑ {(g,h),(h,m)}⊆d ∑ m + Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3 ) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3 ) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4 ) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4 ) for"
D11-1109,N09-1037,0,0.0607158,"Missing"
D11-1109,P08-1043,0,0.0977694,"Missing"
D11-1109,P10-1110,0,0.400604,"tructures. On the contrary, joint models of version 2 can incorporate both aforementioned feature sets, but have higher complexity. These two versions of models will be thoroughly compared in the experiments. 1185 We then define the allowable candidate POS tags of the word wi to be Ti (x) = {t : t ∈ T , P (ti = t|x) ≥ λt × pmaxi (x)} where λt is the pruning threshold. Ti (x) is used to constrain the POS search space by replacing T in Algorithm 1. 5 Experiments We use the Penn Chinese Treebank 5.1 (CTB5) (Xue et al., 2005). Following the setup of Duan et al. (2007), Zhang and Clark (2008b) and Huang and Sagae (2010), we split CTB5 into training (secs 001815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 11371147) sets. We use the head-finding rules of Zhang and Clark (2008b) to turn the bracketed sentences into dependency structures. We use the standard tagging accuracy to evaluate POS tagging. For dependency parsing, we use word accuracy (also known as dependency accuracy), root accuracy and complete match rate (all excluding punctuation) . For the averaged training, we train each model for 15 iterations and select the parameters that perform best on the development"
D11-1109,P08-1102,0,0.111307,"Missing"
D11-1109,P10-1001,0,0.270992,"2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepos (x, t) = wpos · fpos (x, t) 2.2 Dependency Parsing Recently, graph-based dependency parsing has gained more and more interest due to its state-ofthe-art accuracy. Graph-based dependency parsing views the problem as finding the highest scoring tree from a directed graph. Based on dynamic programming decoding, it can efficiently find an optimal tree in a huge search space. In a graph-based model, the score"
D11-1109,P09-1058,0,0.227854,"Missing"
D11-1109,P03-1056,0,0.0427835,"where ti ∈ T , 1 ≤ i ≤ n, and T is the POS tag set. A dependency tree is denoted by d = {(h, m) : 0 ≤ h ≤ n, 0 &lt; m ≤ n}, where (h, m) represents a dependency wh → wm whose head word (or father) is wh and modifier (or child) is wm . w0 is an artificial root token which is used to simplify the formalization of the problem. The pipelined method treats POS tagging and dependency parsing as two cascaded problems. First, 1 It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. 1181 ˆt = arg max Scorepos (x, t) t ˆ is determined Then, an optimal dependency tree d based on x and ˆt. ˆ = arg max Scoresyn (x, ˆt, d) d d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 20"
D11-1109,P10-1113,0,0.0383995,"Missing"
D11-1109,C10-1080,0,0.0394632,"Missing"
D11-1109,E06-1011,0,0.689881,"the third-order model, the score of a dependency tree is represented as: ∑ wdep · fdep (x, t, h, m) Scoresyn (x, t, d) = {(h,m)}⊆d m h dependency h s m sibling g + m h grandparent {(h,s)(h,m)}⊆d + g s h grand-sibling m h s t tri-sibling ∑ ∑ {(g,h),(h,m)}⊆d ∑ m + Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3 ) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3 ) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4 ) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4 ) for third-order models. In their paper, they implement two versions of third-order models, Model 1 and Model 2 according to their naming. Model 1 incorporates only grand-sibling parts, while Model 2 incorporates both grand-sibling and tri-sibling parts"
D11-1109,P05-1012,0,0.930686,"der model (O3): the same with Model 1 in Koo and Collins (2010). We adopt linear models to define the score of a dependency tree. For the third-order model, the score of a dependency tree is represented as: ∑ wdep · fdep (x, t, h, m) Scoresyn (x, t, d) = {(h,m)}⊆d m h dependency h s m sibling g + m h grandparent {(h,s)(h,m)}⊆d + g s h grand-sibling m h s t tri-sibling ∑ ∑ {(g,h),(h,m)}⊆d ∑ m + Figure 1: Different types of scoring parts used in current graph-based models (Koo and Collins, 2010). Eisner (1996) proposes an O(n3 ) decoding algorithm for dependency parsing. Based on the algorithm, McDonald et al. (2005) propose the firstorder model, in which the scoring parts only contains dependencies. The second-order model of McDonald and Pereira (2006) incorporates sibling parts and also needs O(n3 ) parsing time. The secondorder model of Carreras (2007) incorporates both sibling and grandparent parts, and needs O(n4 ) parsing time. However, the grandparent parts are restricted to those composed of outermost grandchildren. Koo and Collins (2010) propose efficient decoding algorithms of O(n4 ) for third-order models. In their paper, they implement two versions of third-order models, Model 1 and Model 2 ac"
D11-1109,J08-4003,0,0.155196,"Missing"
D11-1109,N07-1051,0,0.116748,"Missing"
D11-1109,W96-0213,0,0.524192,"d as non-terminals in the constituent structure (Levy and Manning, 2003). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. 1181 ˆt = arg max Scorepos (x, t) t ˆ is determined Then, an optimal dependency tree d based on x and ˆt. ˆ = arg max Scoresyn (x, ˆt, d) d d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score o"
D11-1109,D10-1001,0,0.0739428,"POS tag set. A dependency tree is denoted by d = {(h, m) : 0 ≤ h ≤ n, 0 &lt; m ≤ n}, where (h, m) represents a dependency wh → wm whose head word (or father) is wh and modifier (or child) is wm . w0 is an artificial root token which is used to simplify the formalization of the problem. The pipelined method treats POS tagging and dependency parsing as two cascaded problems. First, 1 It should be noted that it is straightforward to simultaneously do POS tagging and constituent parsing, as POS tags can be regarded as non-terminals in the constituent structure (Levy and Manning, 2003). In addition, Rush et al. (2010) describes an efficient and simple inference algorithm based on dual decomposition and linear programming relaxation to combine a lexicalized constituent parser and a trigram POS tagger. 1181 ˆt = arg max Scorepos (x, t) t ˆ is determined Then, an optimal dependency tree d based on x and ˆt. ˆ = arg max Scoresyn (x, ˆt, d) d d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002"
D11-1109,P07-1096,0,0.0207597,"s determined Then, an optimal dependency tree d based on x and ˆt. ˆ = arg max Scoresyn (x, ˆt, d) d d 2.1 POS Tagging POS tagging is a typical sequence labeling problem. Many models have been successfully applied to sequence labeling problems, such as maximumentropy (Ratnaparkhi, 1996), conditional random fields (CRF) (Lafferty et al., 2001) and perceptron (Collins, 2002). We use perceptron to build our POS tagging baseline for two reasons. Firstly, as a linear model, perceptron is simple, fast, and effective. It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al., 2007). Secondly, perceptron has been successfully applied to dependency parsing as well (Koo and Collins, 2010). In this paper, perceptron is used in all models including the POS tagging model, the dependency parsing models and the joint models. In a perceptron, the score of a tag sequence is Scorepos (x, t) = wpos · fpos (x, t) 2.2 Dependency Parsing Recently, graph-based dependency parsing has gained more and more interest due to its state-ofthe-art accuracy. Graph-based dependency parsing views the problem as finding the highest scoring tree from a directed graph. Based on dynamic programming de"
D11-1109,W08-2121,0,0.0983419,"Missing"
D11-1109,P09-1055,0,0.0150803,"Missing"
D11-1109,C10-1135,0,0.0414692,"Missing"
D11-1109,P08-1101,0,0.518379,"of this paper is organized as follows. Section 2 describes the pipelined method, including the POS tagging and parsing models. Section 3 discusses the joint models and the decoding algorithms, while Section 4 presents the pruning techniques. Section 5 reports the experimental results and error analysis. We review previous work closely related to our method in Section 6, and conclude this paper in Section 7. an optimal POS tag sequence ˆt is determined. 2 where fpos (x, t) refers to the feature vector and wpos is the corresponding weight vector. For POS tagging features, we follow the work of Zhang and Clark (2008a). Three feature sets are considered: POS unigram, bigram and trigram features. For brevity, we will refer to the three sets as wi ti , ti−1 ti and ti−2 ti−1 ti . Given wpos , we adopt the Viterbi algorithm to get the optimal tagging sequence. The Baseline Pipelined Method Given an input sentence x = w1 ...wn , we denote its POS tag sequence by t = t1 ...tn , where ti ∈ T , 1 ≤ i ≤ n, and T is the POS tag set. A dependency tree is denoted by d = {(h, m) : 0 ≤ h ≤ n, 0 &lt; m ≤ n}, where (h, m) represents a dependency wh → wm whose head word (or father) is wh and modifier (or child) is wm . w0 is"
D11-1109,D08-1059,0,0.828377,"of this paper is organized as follows. Section 2 describes the pipelined method, including the POS tagging and parsing models. Section 3 discusses the joint models and the decoding algorithms, while Section 4 presents the pruning techniques. Section 5 reports the experimental results and error analysis. We review previous work closely related to our method in Section 6, and conclude this paper in Section 7. an optimal POS tag sequence ˆt is determined. 2 where fpos (x, t) refers to the feature vector and wpos is the corresponding weight vector. For POS tagging features, we follow the work of Zhang and Clark (2008a). Three feature sets are considered: POS unigram, bigram and trigram features. For brevity, we will refer to the three sets as wi ti , ti−1 ti and ti−2 ti−1 ti . Given wpos , we adopt the Viterbi algorithm to get the optimal tagging sequence. The Baseline Pipelined Method Given an input sentence x = w1 ...wn , we denote its POS tag sequence by t = t1 ...tn , where ti ∈ T , 1 ≤ i ≤ n, and T is the POS tag set. A dependency tree is denoted by d = {(h, m) : 0 ≤ h ≤ n, 0 &lt; m ≤ n}, where (h, m) represents a dependency wh → wm whose head word (or father) is wh and modifier (or child) is wm . w0 is"
D11-1109,W09-1201,0,\N,Missing
D15-1265,E06-1002,0,0.00885896,"e likely to be informal and noisy than written sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each sectio"
D15-1265,C12-1028,0,0.0129421,"language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at l"
D15-1265,D13-1184,0,0.0151252,"e-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. Guide: In the morning I sugges"
D15-1265,D07-1074,0,0.0137772,"nd noisy than written sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit alon"
D15-1265,N13-1122,0,0.0803846,"ant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers"
D15-1265,P11-1138,0,0.0220007,"ssifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational"
D15-1265,P11-1095,0,0.0383067,"Missing"
D15-1265,P14-1036,0,0.0204408,"owledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers are engaged in a dial"
I05-1051,J93-2003,0,0.0170524,"ity and the length of the phrase unit. We present Level-Of-Detail (LOD) approach, an agglomerative approach for learning phrase-level alignment. Our experiments show that LOD approach signiﬁcantly improves the performance of the word-based approach. LOD demonstrates a clear advantage that the phrase translation table grows only sub-linearly over the maximum phrase length, while having a performance comparable to those of other phrase-based approaches. 1 Introduction Early approach to statistical machine translation relies on the word-based translation model to describe the translation process [1]. However, the underlying assumption of word-to-word translation often fails to capture all properties of the language, i.e. the existence of the phrase where a group of words often function together as a unit. Many researchers have proposed to move from the word-based to the phrase-based translation model [2] [3] [4]. A phrase-based approach oﬀers many advantages as a phrase translation captures word context and local reordering inherently [3]. It has become popular in statistical machine translation applications. There are typically two groups of approaches to constructing the phrasebased mo"
I05-1051,W99-0604,0,0.500578,"n table grows only sub-linearly over the maximum phrase length, while having a performance comparable to those of other phrase-based approaches. 1 Introduction Early approach to statistical machine translation relies on the word-based translation model to describe the translation process [1]. However, the underlying assumption of word-to-word translation often fails to capture all properties of the language, i.e. the existence of the phrase where a group of words often function together as a unit. Many researchers have proposed to move from the word-based to the phrase-based translation model [2] [3] [4]. A phrase-based approach oﬀers many advantages as a phrase translation captures word context and local reordering inherently [3]. It has become popular in statistical machine translation applications. There are typically two groups of approaches to constructing the phrasebased model. The ﬁrst group learns phrase translation directly from the sentence pair. It learns both word and phrase units simultaneously. Although these approaches appear intuitive, it usually suﬀers from a prohibitive computational cost. It might have to consider all possible multi-word sequences as phrase candidat"
I05-1051,C00-2163,0,0.0202859,"ble grows only sub-linearly over the maximum phrase length, while having a performance comparable to those of other phrase-based approaches. 1 Introduction Early approach to statistical machine translation relies on the word-based translation model to describe the translation process [1]. However, the underlying assumption of word-to-word translation often fails to capture all properties of the language, i.e. the existence of the phrase where a group of words often function together as a unit. Many researchers have proposed to move from the word-based to the phrase-based translation model [2] [3] [4]. A phrase-based approach oﬀers many advantages as a phrase translation captures word context and local reordering inherently [3]. It has become popular in statistical machine translation applications. There are typically two groups of approaches to constructing the phrasebased model. The ﬁrst group learns phrase translation directly from the sentence pair. It learns both word and phrase units simultaneously. Although these approaches appear intuitive, it usually suﬀers from a prohibitive computational cost. It might have to consider all possible multi-word sequences as phrase candidates a"
I05-1051,W02-1018,0,0.1513,"grows only sub-linearly over the maximum phrase length, while having a performance comparable to those of other phrase-based approaches. 1 Introduction Early approach to statistical machine translation relies on the word-based translation model to describe the translation process [1]. However, the underlying assumption of word-to-word translation often fails to capture all properties of the language, i.e. the existence of the phrase where a group of words often function together as a unit. Many researchers have proposed to move from the word-based to the phrase-based translation model [2] [3] [4]. A phrase-based approach oﬀers many advantages as a phrase translation captures word context and local reordering inherently [3]. It has become popular in statistical machine translation applications. There are typically two groups of approaches to constructing the phrasebased model. The ﬁrst group learns phrase translation directly from the sentence pair. It learns both word and phrase units simultaneously. Although these approaches appear intuitive, it usually suﬀers from a prohibitive computational cost. It might have to consider all possible multi-word sequences as phrase candidates and a"
I05-1051,C96-2141,0,0.333138,"Missing"
I05-1051,W03-1001,0,0.486944,"phrase units simultaneously. Although these approaches appear intuitive, it usually suﬀers from a prohibitive computational cost. It might have to consider all possible multi-word sequences as phrase candidates and all possible pairings as phrase translations at the same time. R. Dale et al. (Eds.): IJCNLP 2005, LNAI 3651, pp. 576–587, 2005. c Springer-Verlag Berlin Heidelberg 2005  Phrase-Based Statistical Machine Translation: A Level of Detail Approach 577 The second group of approaches learns phrase translations through word-level alignment: alignment template [2] and projection extension [6], just to name a few. In general, these approaches take the word-level alignment, a by-product of the word-based translation model, as their input and then utilize a heuristic measurement to learn the phrase translation. The heuristic measurement contains all possible conﬁgurations of word-level alignment on a phrase translation. It is noted that the underlying word-level alignment is just an approximation to the exact alignment. The approximation is reﬂected by a probability produced by the word-based translation model. The majority of approaches do not make use of this probability, whereas i"
I05-1051,N03-1017,0,0.304925,"slation model, as their input and then utilize a heuristic measurement to learn the phrase translation. The heuristic measurement contains all possible conﬁgurations of word-level alignment on a phrase translation. It is noted that the underlying word-level alignment is just an approximation to the exact alignment. The approximation is reﬂected by a probability produced by the word-based translation model. The majority of approaches do not make use of this probability, whereas it may provide a valuable clue leading to a better phrase translation from a statistical point of view. Koehn, et. al [8] compared the representative of both groups and reported that learning phrase translation using a simple heuristic from word alignment yields a better translation performance than learning phrase translation directly from the sentence pair. Many approaches try to learn all phrase translations in one step, either directly from the sentence pair or through word alignment. As a result, they may encounter a huge amount of phrase translation candidates at once. Usually, they limit the maximum phrase length to reduce the choice of candidates. Although this method is suﬃcient to satisfy the computati"
I05-1051,2001.mtsummit-papers.68,0,0.059186,"Missing"
I05-1051,N04-1033,0,0.0618716,"Missing"
I05-1051,W97-0311,0,0.127525,"th introduce an equal number of additional entries to the phrase translation table. As longer phrases occur less often, there should be fewer entries introduced into the phrase translation table. We propose an agglomerative approach to learn phrase translations. Our approach is motivated by the second group, which is to learn phrase translation through word-alignment, while addressing the common issues: the size of the phrase translation table, the use of underlying translation model probability and the length of the phrase unit. Only a few approaches move away from one-step learning. Melamed [13] presented an agglomerative approach to learn the phrases progressively from a parallel corpus by using sub-phrase bigram statistics. Moore [14] proposed a similar approach which identiﬁes the phrase candidates by parsing the raw training data. Our idea diﬀers from these approaches in that we look into the association of the alignments rather than the association of the words to discover the phrases. In this paper, we propose the Level of Detail (LOD) approach for learning of phrase translations in phrase-based statistical machine translation. Section 2 discusses the background and motivation"
I05-1051,W01-1411,0,0.0154729,"tries introduced into the phrase translation table. We propose an agglomerative approach to learn phrase translations. Our approach is motivated by the second group, which is to learn phrase translation through word-alignment, while addressing the common issues: the size of the phrase translation table, the use of underlying translation model probability and the length of the phrase unit. Only a few approaches move away from one-step learning. Melamed [13] presented an agglomerative approach to learn the phrases progressively from a parallel corpus by using sub-phrase bigram statistics. Moore [14] proposed a similar approach which identiﬁes the phrase candidates by parsing the raw training data. Our idea diﬀers from these approaches in that we look into the association of the alignments rather than the association of the words to discover the phrases. In this paper, we propose the Level of Detail (LOD) approach for learning of phrase translations in phrase-based statistical machine translation. Section 2 discusses the background and motivation and then formulates the LOD approach 578 H. Setiawan et al. while section 3 describes the learning process in details. Section 4 describes the e"
I05-1051,W04-3250,0,0.0819061,"Missing"
I05-1051,C04-1030,0,\N,Missing
I05-1051,P02-1040,0,\N,Missing
I05-1051,P03-1041,0,\N,Missing
I05-1053,W03-1501,0,0.402766,"l at the phrase level. We also present a twostep search to decode the best result from the models. Our proposed model is evaluated on the LDC Chinese-English NE translation corpus. The experiment results show that our proposed model is high effective for NE translation. 1 Introduction A Named Entity (NE) is essentially a proper noun phrase. Automatic NE translation is an indispensable component of cross-lingual applications such as machine translation and cross-lingual information retrieval and extraction. NE is translated by a combination of meaning translation and/or phoneme transliteration [1]. NE transliteration has been given much attention in the literature. Many attempts, including phoneme and grapheme-based methods, various machine learning and rule-based algorithms [2,3] and Joint Source-Channel Model (JSCM) [4], have been made recently to tackle the issue of NE transliteration. However, only a few works have been reported in NE translation. Chen et al. [1] proposed a frequency-based approach to learn formulation and transformation rules for multilingual Named Entities (NEs). Al-Onaizan and Knight [5] investigated the translation of Arabic NEs to English using monolingual and"
I05-1053,C02-1099,0,0.106662,"experiment results show that our proposed model is high effective for NE translation. 1 Introduction A Named Entity (NE) is essentially a proper noun phrase. Automatic NE translation is an indispensable component of cross-lingual applications such as machine translation and cross-lingual information retrieval and extraction. NE is translated by a combination of meaning translation and/or phoneme transliteration [1]. NE transliteration has been given much attention in the literature. Many attempts, including phoneme and grapheme-based methods, various machine learning and rule-based algorithms [2,3] and Joint Source-Channel Model (JSCM) [4], have been made recently to tackle the issue of NE transliteration. However, only a few works have been reported in NE translation. Chen et al. [1] proposed a frequency-based approach to learn formulation and transformation rules for multilingual Named Entities (NEs). Al-Onaizan and Knight [5] investigated the translation of Arabic NEs to English using monolingual and bilingual resources. Huang et al. [6] described an approach to translate rarely occurring NEs by combining phonetic and semantic similarities. In this paper, we pay special attention to"
I05-1053,P04-1021,1,0.870234,"del is high effective for NE translation. 1 Introduction A Named Entity (NE) is essentially a proper noun phrase. Automatic NE translation is an indispensable component of cross-lingual applications such as machine translation and cross-lingual information retrieval and extraction. NE is translated by a combination of meaning translation and/or phoneme transliteration [1]. NE transliteration has been given much attention in the literature. Many attempts, including phoneme and grapheme-based methods, various machine learning and rule-based algorithms [2,3] and Joint Source-Channel Model (JSCM) [4], have been made recently to tackle the issue of NE transliteration. However, only a few works have been reported in NE translation. Chen et al. [1] proposed a frequency-based approach to learn formulation and transformation rules for multilingual Named Entities (NEs). Al-Onaizan and Knight [5] investigated the translation of Arabic NEs to English using monolingual and bilingual resources. Huang et al. [6] described an approach to translate rarely occurring NEs by combining phonetic and semantic similarities. In this paper, we pay special attention to the issue of NE translation. Although NE t"
I05-1053,P02-1051,0,0.181878,"ated by a combination of meaning translation and/or phoneme transliteration [1]. NE transliteration has been given much attention in the literature. Many attempts, including phoneme and grapheme-based methods, various machine learning and rule-based algorithms [2,3] and Joint Source-Channel Model (JSCM) [4], have been made recently to tackle the issue of NE transliteration. However, only a few works have been reported in NE translation. Chen et al. [1] proposed a frequency-based approach to learn formulation and transformation rules for multilingual Named Entities (NEs). Al-Onaizan and Knight [5] investigated the translation of Arabic NEs to English using monolingual and bilingual resources. Huang et al. [6] described an approach to translate rarely occurring NEs by combining phonetic and semantic similarities. In this paper, we pay special attention to the issue of NE translation. Although NE translation is less sophisticated than machine translation (MT) in general, to some extent, the issues in NE translation are similar to those in MT. Its challenges lie in not only the ambiguity in lexical mapping such as <副(Fu),Deputy> and <副(Fu),Vice> in Fig.1 in the next page, but also the pos"
I05-1053,N04-1036,0,0.0681695,"much attention in the literature. Many attempts, including phoneme and grapheme-based methods, various machine learning and rule-based algorithms [2,3] and Joint Source-Channel Model (JSCM) [4], have been made recently to tackle the issue of NE transliteration. However, only a few works have been reported in NE translation. Chen et al. [1] proposed a frequency-based approach to learn formulation and transformation rules for multilingual Named Entities (NEs). Al-Onaizan and Knight [5] investigated the translation of Arabic NEs to English using monolingual and bilingual resources. Huang et al. [6] described an approach to translate rarely occurring NEs by combining phonetic and semantic similarities. In this paper, we pay special attention to the issue of NE translation. Although NE translation is less sophisticated than machine translation (MT) in general, to some extent, the issues in NE translation are similar to those in MT. Its challenges lie in not only the ambiguity in lexical mapping such as <副(Fu),Deputy> and <副(Fu),Vice> in Fig.1 in the next page, but also the position permutation and fertility of words. Fig.1 illustrates two excerpts of NE translation from the LDC corpus [7]"
I05-1053,2002.tmi-tutorials.2,0,0.0491198,"our study, we enhance the LMM with the PM to account for the word reordering issue in NE translation, so our model is capable of modeling the non-monotone problem. In contrast, JSCM only models the monotone problem. Both rule-based [1] and statistical model-based [5,6] methods have been proposed to address the NE translation problem. The model-based methods mostly are based on conditional probability under the noisy-channel framework [8]. Now let’s review the different modeling methods: 1) 2) 3) As far as lexical choice issue is concerned, the noisy-channel model, represented by IBM Model 1-5 [8], models lexical dependency using a context-free conditional probability. Marcu and Wong [10] proposed a phrase-based context-free joint probability model for lexical mapping. In contrast, our LMM models lexical dependency using n-order bilingual contextual information. Another characteristic of our method lies in its modeling and search strategy. NE translation and MT are usually viewed as a non-monotone search problem and it is well-known that a non-monotone search is exponentially more complex than a monotone search. Thus, we propose the two separated models and the two-step search, so that"
I05-1053,W02-1018,0,0.0349964,"nslation, so our model is capable of modeling the non-monotone problem. In contrast, JSCM only models the monotone problem. Both rule-based [1] and statistical model-based [5,6] methods have been proposed to address the NE translation problem. The model-based methods mostly are based on conditional probability under the noisy-channel framework [8]. Now let’s review the different modeling methods: 1) 2) 3) As far as lexical choice issue is concerned, the noisy-channel model, represented by IBM Model 1-5 [8], models lexical dependency using a context-free conditional probability. Marcu and Wong [10] proposed a phrase-based context-free joint probability model for lexical mapping. In contrast, our LMM models lexical dependency using n-order bilingual contextual information. Another characteristic of our method lies in its modeling and search strategy. NE translation and MT are usually viewed as a non-monotone search problem and it is well-known that a non-monotone search is exponentially more complex than a monotone search. Thus, we propose the two separated models and the two-step search, so that the lexical mapping issue can be resolved by monotone search. This results in a large improv"
I05-1053,W99-0604,0,0.114464,"Missing"
I05-1053,N03-1017,0,0.0566621,"hrase-based MT research, to carry out the same NE translation experiments as reference cases. All the experiments conducted in this paper are listed as follow: 1) 3 4 IBM method C: word-based IBM Model 4 trained by GIZA++3 [15] and ISI Decoder4 [14,16]; http://www.fjoch.com/ http://www.isi.edu/natural-language/software/decoder/manual.html A Phrase-Based Context-Dependent Joint Probability Model 2) 3) 4) 607 IBM method D: phrase-based IBM Model 4 trained by GIZA++ on phrasealigned corpus and ISI Decoder working on phrase-segmented testing corpus. Koehn method: Koehn et al.’s phrase-based model [12] and PHARAOH5 decoder6; Our method: phrase-based bi-gram LMM and bi-gram PM, and our two-step decoder. To make an accurate comparison, all the above three phrase-based models are trained on the same phrase-segmented and aligned corpus, and tested on the same phrase-segmented corpus. ISI Decoder carries out a greedy search, and PHARAOH is a beam-search stack decoder. To optimize their performances, the two decoders are allowed to do unlimited reordering without penalty. We train trigram language models in the first three experiments and bi-gram models in the forth experiment. 5.2 NE Translation"
I05-1053,P01-1030,0,0.0646095,"Missing"
I05-1053,J03-1002,0,0.00868264,"ntext-dependent joint probability model. 3 Training Following the modeling strategy discussed above, the training process consists of three steps: phrase alignment, reordering of corpus, and learning statistical parameters for lexical mapping and permutation models. 3.1 Acquiring Phrase Pairs To reduce vocabulary size and avoid sparseness, we constrain the phrase length to up to three words and the lower-frequency phrase pairs are pruned out for accurate 604 M. Zhang et al. phrase-alignment1. Given a word alignment corpus which can be obtained by means of the publicly available GIZA++ toolkit [15], it is very straightforward to construct the phrase-alignment corpus by incrementally traversing the word-aligned NE from left to right2. The set of resulting phrase pairs forms a lexical mapping table. 3.2 Reordering Corpus The context-dependent lexical mapping model assumes monotonic alignment in the bilingual training corpus. Thus, the phrase aligned corpus needs to be reordered so that it is in either source-ordered or target-ordered alignment. We choose to reorder the target phrases to follow the source order. Only in this way can we use the lexical mapping model to describe the monotoni"
I05-1053,N03-1010,0,0.0245356,"Missing"
I05-1053,J03-1005,0,0.0554023,"Missing"
I05-1053,2001.mtsummit-papers.68,0,0.0298051,"Missing"
I05-1053,W00-0508,0,0.0570397,"et us discuss the major differences between them: 610 1) 2) M. Zhang et al. Our LMM models the lexical mapping and target word selection using a context-dependent joint probability while IBM Model 1 using a contextindependent conditional probability and a target n-gram language model. Our LMM carries out the target word selection and our PM only models the target word connectivity while the language model in IBM Model 1 performs the function of target word selection. Alternatively, finite-state automata (FSA) for statistical MT were previous suggested for decoding using contextual information [21,22]. Bangalore and Riccardi [21] proposed a phrase-based variable length n-gram model followed by a reordering scheme for spoken language translation. However, their re-ordering scheme was not evaluated by empirical experiments. 7 Conclusions In this paper, we propose a new model for NE translation. We present the training and decoding methods for the proposed model. We also compare the proposed method with related work. Empirical experiments show that our method outperforms the previous methods significantly in all test cases. We conclude that our method works more effectively and efficiently in"
I05-1053,P04-1065,0,0.0254848,"et us discuss the major differences between them: 610 1) 2) M. Zhang et al. Our LMM models the lexical mapping and target word selection using a context-dependent joint probability while IBM Model 1 using a contextindependent conditional probability and a target n-gram language model. Our LMM carries out the target word selection and our PM only models the target word connectivity while the language model in IBM Model 1 performs the function of target word selection. Alternatively, finite-state automata (FSA) for statistical MT were previous suggested for decoding using contextual information [21,22]. Bangalore and Riccardi [21] proposed a phrase-based variable length n-gram model followed by a reordering scheme for spoken language translation. However, their re-ordering scheme was not evaluated by empirical experiments. 7 Conclusions In this paper, we propose a new model for NE translation. We present the training and decoding methods for the proposed model. We also compare the proposed method with related work. Empirical experiments show that our method outperforms the previous methods significantly in all test cases. We conclude that our method works more effectively and efficiently in"
I05-1053,C04-1030,0,\N,Missing
I05-1053,J93-2003,0,\N,Missing
I05-1053,P02-1040,0,\N,Missing
I05-1053,N04-1033,0,\N,Missing
I05-1053,J98-4003,0,\N,Missing
I08-1008,J96-1002,0,0.14677,"Missing"
I08-1008,P04-1024,0,0.691486,"and name entity recognition. Unfortunately, little attention has been given to name origin recognition (NOR) so far in the literature. In this paper, we are interested in two kinds of name origin recognition: the origin of names written in English (ENOR) and the origin of names written in Chinese (CNOR). For ENOR, the origins include English (Eng), Japanese (Jap), Chinese Mandarin Pinyin (Man) and Chinese Cantonese Jyutping (Can). For CNOR, they include three origins: Chinese (Chi, for both Mandarin and Cantonese), Japanese and English (refer to Latinscripted language). Unlike previous work (Qu and Grefenstette, 2004; Li et al., 2006; Li et al., 2007) where NOR was formulated with a generative model, we regard the NOR task as a classification problem. We further propose using a discriminative learning algorithm (Maximum Entropy model: MaxEnt) to solve the problem. To draw direct comparison, we conduct experiments on the same personal name corpora as that in the previous work by Li et al. (2006). We show that the MaxEnt method effectively incorporates diverse features and outperforms previous methods consistently across all test cases. The rest of the paper is organized as follows: in section 2, we review"
I08-1008,P07-1016,1,\N,Missing
I08-1008,Y04-1029,0,\N,Missing
I08-1008,J98-4003,0,\N,Missing
I08-1049,P06-1142,1,0.920854,"words, the Co-EM algorithm interchanges the probabilistic labels generated in the view of each other before a new EM iteration. In both cases, the unsupervised, multi-view algorithms use the hypotheses learned to probabilistically label the examples. ∑ n i =1 wi Pi ( EW |CW ), (8) where wi is the weight of ith learner Pi ( EW |CW ) , which can be learnt by using a development corpus. 5 Experiments To validate the effectiveness of the learning framework, we conduct a series of experiments in transliteration extraction on a development corpus described later. First, we repeat the experiment in (Kuo et al., 2006) to train a PSM using PSA and GSA feature fusion in a supervised manner, which serves as the upper bound of Co-training or Co-EM system performance. We then train the PSMs with single view V1, V2, V3 and V4 alone in an unsupervised manner. The performance achieved by each view alone can be considered as the baseline for multi-view benchmarking. Then, we run two-view Co-training for different combinations of views on the same development corpus. We expect to see positive effects with the multi-view training. Finally, we run the experiments using two-view Co-training and CoEM and compare the res"
I08-1049,P06-1010,0,0.0253402,"eme- or grapheme-based approaches. Bilac and Tanaka (2004) and Oh et al. (2006a; 2006b) recently proposed using a mix of phoneme and grapheme features, where both features are fused into a single learning process. The feature fusion was shown to be effective. However, their methods hinge on the availability of a labeled bilingual corpus. In transliteration extraction, mining translations or transliterations from the ever-growing multilingual Web has become an active research topic, for example, by exploring query logs (Brill et al., 2001) and parallel (Nie et al., 1999) or comparable corpora (Sproat et al., 2006). Transliterations in such a live corpus are typically unlabeled. For model-based transliteration extraction, recent progress in machine learning offers different options to exploit unlabeled data, that include active learning (Lewis and Catlett, 1994) and Co-training (Nigam and Ghani, 2000; Tür et al. 2005). Taking the prior work a step forward, this paper explores a new way of fusing phoneme and grapheme features through a multi-view Cotraining algorithm (Blum and Mitchell, 1998), which starts with a small number of labeled data to bootstrap a transliteration model to automatically harvest t"
I08-1049,P04-1021,1,0.882708,"honeme-based transliteration modeling (Knight and Graehl, 1998; Lee, 1999). Suppose that EW is an English word and CW is its Chinese transliteration. EW and CW form an E-C transliteration pair. The phoneme-based approach first converts EW into an intermediate phonemic representation p, and then converts p into its Chinese counterpart CW. The idea is to transform both source and target words into comparable phonemes so that the phonetic similarity between two words can be measured easily. Recently the grapheme-based approach has attracted much attention. It was proposed by Jeong et al. (1999), Li et al. (2004) and many others (Oh et al., 2006b), which is also known as direct orthography mapping. It treats the transliteration as a statistical machine translation problem under monotonic constraint. The idea is to obtain the bilingual orthographical correspondence directly to reduce the possible errors introduced in multiple conversions. However, the grapheme-based transliteration model has more parameters than phoneme-based one does, thus expects a larger training corpus. Most of the reported works have been focused on either phoneme- or grapheme-based approaches. Bilac and Tanaka (2004) and Oh et al"
I08-1049,W03-1508,0,\N,Missing
I08-4003,P98-1069,0,0.0479292,"on 3, we formulate the PSM and its batch and incremental learning algorithms while in Section 4, we discuss the practical issues in implementation. Section 5 provides a report on the experiments conducted and finally, we conclude in Section 6. 2 Related Work Much of research on extraction of transliterations has been motivated by information retrieval techniques, where attempts to extracting transliteration pairs from large bodies of corpora have been made. Some have proposed extracting translations from parallel or comparable bitexts using co-occurrence analysis or a context-vector approach (Fung and Yee, 1998; Nie et al., 1999). These methods compare the semantic similarities between source and target words without taking their phonetic similarities into account. Another direction of research is focused on esSixth SIGHAN Workshop on Chinese Language Processing tablishing the phonetic relationship between transliteration pairs. This typically involves the encoding of phoneme- or grapheme-based mapping rules using a generative model trained from a large bilingual lexicon. Suppose that EW and CW form an E-C transliteration pair. The phoneme-based approach (Knight & Graehl, 1998) first converts EW int"
I08-4003,P06-1142,1,0.680529,"ts. 1 Introduction Transliteration is a process of rewriting a word from one language into another by preserving its pronunciation in its original language, also known as translation-by-sound. It usually takes place between languages with different scripts, for example, from English to Chinese, and words, such as proper nouns, that do not have “easy” or semantic translations. The increasing size of multilingual content on the Web has made it a live information source rich in transliterations. Research on automatic acquisition of transliteration pairs in batch mode has shown promising results (Kuo et al., 2006). In dealing with the dynamic growth of the Web, it is almost impossible to collect and store all its con16 tents in local storage. Therefore, there is a need to develop an incremental learning algorithm to mine transliterations in an on-line manner. In general, an incremental learning technique is designed for adapting a model towards a changing environment. We are interested in deducing the incremental learning method for automatically constructing an English-Chinese (E-C) transliteration lexicon from Web query results. In the deduction, we start with a phonetic similarity model (PSM), which"
I08-4003,P04-1021,1,0.915219,"sed on esSixth SIGHAN Workshop on Chinese Language Processing tablishing the phonetic relationship between transliteration pairs. This typically involves the encoding of phoneme- or grapheme-based mapping rules using a generative model trained from a large bilingual lexicon. Suppose that EW and CW form an E-C transliteration pair. The phoneme-based approach (Knight & Graehl, 1998) first converts EW into an intermediate phonemic representation and then converts the phonemic representation into its Chinese counterpart CW. The grapheme-based approach, also known as direct orthographical mapping (Li et al., 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. Many efforts have also been channeled to tapping the wealth of the Web for harvesting transliteration/translation pairs. These include studying the query logs (Brill et al., 2001), unrelated corpora (Rapp, 1999), and comparable corpora (Sproat et al. 2006). To establish cross-lingual correspondence in the harvest, these algorithms usually rely on one or more statistical clues (Lam et al., 2004), such as the correlation between word frequencies, and cogna"
I08-4003,P99-1067,0,0.0227843,"h (Knight & Graehl, 1998) first converts EW into an intermediate phonemic representation and then converts the phonemic representation into its Chinese counterpart CW. The grapheme-based approach, also known as direct orthographical mapping (Li et al., 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. Many efforts have also been channeled to tapping the wealth of the Web for harvesting transliteration/translation pairs. These include studying the query logs (Brill et al., 2001), unrelated corpora (Rapp, 1999), and comparable corpora (Sproat et al. 2006). To establish cross-lingual correspondence in the harvest, these algorithms usually rely on one or more statistical clues (Lam et al., 2004), such as the correlation between word frequencies, and cognates of similar spelling or pronunciations. In doing so, two things are needed: first, a robust mechanism that establishes statistical relationships between bilingual words, such as a phonetic similarity model which is motivated by transliteration modeling research; and second, an effective learning framework that is able to adaptively discover new eve"
I08-4003,P06-1010,0,0.157794,"rts EW into an intermediate phonemic representation and then converts the phonemic representation into its Chinese counterpart CW. The grapheme-based approach, also known as direct orthographical mapping (Li et al., 2004), which treats transliteration as a statistical machine translation problem under monotonic constraints, has also achieved promising results. Many efforts have also been channeled to tapping the wealth of the Web for harvesting transliteration/translation pairs. These include studying the query logs (Brill et al., 2001), unrelated corpora (Rapp, 1999), and comparable corpora (Sproat et al. 2006). To establish cross-lingual correspondence in the harvest, these algorithms usually rely on one or more statistical clues (Lam et al., 2004), such as the correlation between word frequencies, and cognates of similar spelling or pronunciations. In doing so, two things are needed: first, a robust mechanism that establishes statistical relationships between bilingual words, such as a phonetic similarity model which is motivated by transliteration modeling research; and second, an effective learning framework that is able to adaptively discover new events from the Web. In Chinese/Japanese/Korean"
I08-4003,C98-1066,0,\N,Missing
I11-1065,J90-1003,0,0.09213,"cks cross-lingual information. Various measures for cross-lingual word semantic similarity have been proposed to explore statistical techniques and semantic network. Research works propose to use WordNet by Resnik (1999) to measure similarity between English words. Liu and Li (2002) adopt HowNet calculate word similarity in machine translation. Xia et al. (2011) propose to explore cross-lingual word similarity by observing concept definition provided by HowNet. Corpus-based measures for semantic similarity are found more interesting. The classical method is Pointwise Mutual Information (PMI) (Church and Hanks, 1990). Many researches are based on PMI, such as PMI-IR (Turney, 2001) and Second Order Co-occurrence PMI (SOCPMI) (Islam and Inkpen, 2006). SOCPMI is proved better than PMI-IR and some other similarity measures (Islam and Inkpen, 2006). In this work, we implement three representative measures: HowNet-based measure (Xia et al., 2011), SOCPMI measure (Islam and Inkpen, 2006) and COV measure (Farahat and Kamel, 2010). 3 3.1 Cross-Lingual Generalized VSM Generalized VSM be a set of docuLet ments which contain M terms, be a matrix whose element represents the weight of term in document . GVSM (Wang et"
I11-1065,W05-1203,0,0.0537671,"Missing"
I11-1065,islam-inkpen-2006-second,0,0.106272,"echniques and semantic network. Research works propose to use WordNet by Resnik (1999) to measure similarity between English words. Liu and Li (2002) adopt HowNet calculate word similarity in machine translation. Xia et al. (2011) propose to explore cross-lingual word similarity by observing concept definition provided by HowNet. Corpus-based measures for semantic similarity are found more interesting. The classical method is Pointwise Mutual Information (PMI) (Church and Hanks, 1990). Many researches are based on PMI, such as PMI-IR (Turney, 2001) and Second Order Co-occurrence PMI (SOCPMI) (Islam and Inkpen, 2006). SOCPMI is proved better than PMI-IR and some other similarity measures (Islam and Inkpen, 2006). In this work, we implement three representative measures: HowNet-based measure (Xia et al., 2011), SOCPMI measure (Islam and Inkpen, 2006) and COV measure (Farahat and Kamel, 2010). 3 3.1 Cross-Lingual Generalized VSM Generalized VSM be a set of docuLet ments which contain M terms, be a matrix whose element represents the weight of term in document . GVSM (Wang et al, , where every row and column represents a term, respectively. In tradition GVSM (Wang et al, 1985), terms are represented as vecto"
I11-1065,P00-1056,0,0.0754142,"Missing"
I11-1065,C04-1138,0,0.0689709,"Missing"
I11-1065,D09-1091,0,0.0300142,"Missing"
I11-1135,P02-1051,0,0.0471523,"Missing"
I11-1135,J96-1002,0,0.0468198,"Missing"
I11-1135,C10-2165,1,0.138036,"romising results have been reported, one of major issues is that the current transliteration methods rely heavily on significant amount of source-target parallel data to learn transliteration model. However, such corpora are not always available and the amounts of the currently available corpora, even for language pairs with English involved, are far from enough for training, letting alone many low-density language pairs. Indeed, transliteration corpora for most language pairs without English involved are unavailable and are usually rather expensive to manually construct (Khapra et al., 2010; Zhang et al., 2010). To date, only two previous works (Khapra et al., 2010; Zhang et al., 2010) touch this issue of transliterating names across low-density language pairs. Both of them resort to pivot language-based approaches to address this issue. 1207 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1207–1215, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP Khapra et al. (2010) proposes the system-based pivot strategy for machine transliteration, which learns a source-pivot model from source-pivot data and a pivot-target model from pivot-target data, respe"
I11-1135,2008.iwslt-papers.1,0,\N,Missing
I11-1135,N10-1065,0,\N,Missing
I11-1135,C02-1099,0,\N,Missing
I11-1135,C04-1103,1,\N,Missing
I11-1135,P06-1103,0,\N,Missing
I11-1135,N07-1061,0,\N,Missing
I11-1135,P06-1010,0,\N,Missing
I11-1135,W06-1672,0,\N,Missing
I11-1135,D08-1037,0,\N,Missing
I11-1135,P08-1045,0,\N,Missing
I11-1135,N03-1017,0,\N,Missing
I11-1135,J03-1002,0,\N,Missing
I11-1135,P09-1018,0,\N,Missing
I11-1135,P07-1092,0,\N,Missing
I11-1135,W09-3502,1,\N,Missing
I11-1135,P09-1016,1,\N,Missing
J10-3009,P06-1067,0,0.0764773,"ith Embedded Reordering Models. Under the IBM constraint (Zens and Ney 2003), the early work uses a distortion-based reordering model to penalize word movements (Koehn, Och, and Marcu 2003). Similarly, under the ITG constraint, the corresponding model is the ﬂat model which assigns a prior probability to the straight or inverted order (Wu 1996). These two models don’t respect the content of phrases which are moved. To address this issue, lexicalized reordering models which are sensitive to lexical information about phrases are introduced (Tillman 2004; Koehn et al. 2005; Kumar and Byrne 2005; Al-Onaizan and Papineni 2006). Xiong, Liu, and Lin (2006) introduce a more ﬂexible reordering model under the ITG constraint using discriminative features which are automatically learned from a training corpus. Zhang et al. (2007) propose a model for syntactic phrase reordering which uses syntactic knowledge from source parse trees. Our reordering approach is most similar to those in Xiong, Liu, and Lin (2006) and Zhang et al. but extends them further by using syntactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and Eisner (2003) use synchronous g"
J10-3009,1992.tmi-1.8,0,0.355669,"he test corpus when we consider the gap in syntactic reordering patterns. BWR (gap) BWR+LAR (gap) 562 Precision Recall F1 46.28 48.80 44.91 50 45.58 49.39 Xiong et al. Linguistically Annotated Reordering approach, reordering knowledge is included in synchronous rules. The last two categories reorder the source sentence during decoding, which distinguishes them from the ﬁrst approach. Note that some researchers integrate multiple reordering approaches in one decoder (Lin 2004; Quirk, Menezes, and Cherry 2005; Ge, Ittycheriah, and Papineni 2008). 9.1.1 The Preprocessing Approach. In early work, Brown et al. (1992) describe an approach to reordering French phrases in a preprocessing step. Xia and McCord (2004) present a preprocessing approach which automatically learns reordering patterns based on CFG productions. Since then, the preprocessing approach seems to have been more popular. Collins, Koehn, and Kucerova (2005) propose reordering German clauses with six types of manual rules. Similarly, Wang, Collins, and Koehn (2007) reorder Chinese parse trees using ﬁne-grained human-written rules, mostly concentrating on VP and NP structures. Li et al. (2007) improve the preprocessing approach by generating"
J10-3009,W07-0718,0,0.0483372,"em outputs in a ﬁne-grained manner with regard to reordering. In their method, common word n-grams occurring in both reference translations and system translations are extracted and generalized to part-ofspeech tag sequences. A recall is calculated for each certain tag sequence to indicate the ability of reordering models to capture this tag sequence in system translations. Popovic et al. (2006) use the relative difference between WER (word error rate) and PER (position independent word error rate) to indicate reordering errors. The larger the difference, the more reordering errors there are. Callison-Burch et al. (2007) propose a constituent-based evaluation that is very similar to our method in Steps (1)–(3). They also parse the source sentence and automatically align the parse tree with the reference/system translations. The difference is that they highlight constituents from the parse tree to enable human evaluation of the translations of these constituents, rather than automatically analyzing constituent movement. They use this method for human evaluation in the shared translation task of the 2007 and 2008 ACL Workshop on Statistical Machine Translation. Fox (2002) systematically studies syntactic cohesi"
J10-3009,P08-1009,0,0.059842,"rst combined with d d d d, which is a sub-phrase of PP preceding VP in an inverted order. The remaining part of the VP phrase is then merged. This merging process continues regardless of the source parse tree. The comparison of BTG trees of BWR+LAR and BWR in the two examples suggests that reordering models should respect syntactic structures in order to capture reorderings under these structures. Our observation on phrase movement change resonates with the recent efforts in phrasal SMT that allow the decoder to prefer translations which show more respect for syntactic constituent boundaries (Cherry 2008; Marton and Resnik 2008; Yamamoto, Okuma, and Sumita 2008). Mapping to syntactic constituent boundaries, or in other words, syntactic cohesion (Fox 2002; Cherry 2008), has been studied and used in early syntax-based SMT models (Wu 1997; Yamada and Knight 2001). But its value has receded in more powerful syntax-based models (Galley et al. 2004; Chiang 2005) and non-syntactic phrasal models (Koehn, Och, and Marcu 2003). Marton and Resnik (2008) and Cherry (2008) use syntactic cohesion as a soft constraint by penalizing hypotheses which violate constituent boundaries. Yamamoto, Okuma, and Sumita"
J10-3009,P05-1033,0,0.753435,"tricted by the ITG constraint (Wu 1997). Although it only allows two orders (straight or inverted) of nodes in any binary branching structure, it is broadly veriﬁed that the ITG constraint has good coverage of word reorderings on various language pairs (Wu, Carpuat, and Shen 2006). This makes phrase reordering in phrasal SMT a more tractable task. After enhancing phrasal SMT with a hard hierarchical skeleton, we further inject soft linguistic information into the nodes of the skeleton. We annotate each BTG node 1 In this article, we use Penn Chinese Treebank phrase labels (Xue et al. 2000). 2 Chiang (2005) also generates hierarchical structures in phrasal SMT. One difference is that Chiang’s hierarchical grammar is lexicon-sensitive because the model requires at least one pair of aligned words in each rule except for the “glue rule.” The other difference is that his grammar allows multiple nonterminals. These two differences make Chiang’s grammar more expressive than the BTG but at the cost of learning a larger model. 536 Xiong et al. Linguistically Annotated Reordering with syntactic and lexical elements by projecting the source parse tree onto the BTG binary tree. The challenge, of course, is"
J10-3009,H05-1098,0,0.0193236,"cluded in synchronous rules which are automatically learned from word-aligned corpus. In linguistically syntax-based models, stringto-tree (Marcu et al. 2006), tree-to-string (Huang, Knight, and Joshi 2006; Liu, Liu, and Lin 2006), and tree-to-tree (Zhang et al. 2008) translation rules, just to name a few, are explored. Linguistical reordering knowledge is naturally included in these syntax-based translation rules. 9.2 Automatic Analysis of Reordering Although there is a variety of work on phrase reordering, automatic analysis of phrase reordering is not widely explored in the SMT literature. Chiang et al. (2005) propose 563 Computational Linguistics Volume 36, Number 3 an automatic method to compare different system outputs in a ﬁne-grained manner with regard to reordering. In their method, common word n-grams occurring in both reference translations and system translations are extracted and generalized to part-ofspeech tag sequences. A recall is calculated for each certain tag sequence to indicate the ability of reordering models to capture this tag sequence in system translations. Popovic et al. (2006) use the relative difference between WER (word error rate) and PER (position independent word erro"
J10-3009,P05-1066,0,0.0849743,"Missing"
J10-3009,P03-2041,0,0.0375795,"; Al-Onaizan and Papineni 2006). Xiong, Liu, and Lin (2006) introduce a more ﬂexible reordering model under the ITG constraint using discriminative features which are automatically learned from a training corpus. Zhang et al. (2007) propose a model for syntactic phrase reordering which uses syntactic knowledge from source parse trees. Our reordering approach is most similar to those in Xiong, Liu, and Lin (2006) and Zhang et al. but extends them further by using syntactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and Eisner (2003) use synchronous grammars to capture reorderings between two languages. Chiang (2005) introduces formal synchronous grammars for phrase-based translation. In his work, hierarchical reordering knowledge is included in synchronous rules which are automatically learned from word-aligned corpus. In linguistically syntax-based models, stringto-tree (Marcu et al. 2006), tree-to-string (Huang, Knight, and Joshi 2006; Liu, Liu, and Lin 2006), and tree-to-tree (Zhang et al. 2008) translation rules, just to name a few, are explored. Linguistical reordering knowledge is naturally included in these syntax"
J10-3009,W02-1039,0,0.156118,"rdering when combined with BWR. We want to further study what happens when we combine BWR with LAR. In particular, we want to investigate to what extent the integrated linguistic knowledge (from LAR) changes phrase movement in an actual SMT system, and in what direction the change takes place. The investigations will enable us to have a better understanding of the relationship between phrase movement and linguistic context, and therefore to explore linguistic knowledge more effectively in phrasal SMT. Because syntactic constituents are often moved together across languages during translation (Fox 2002), we particularly study how linguistic knowledge affects syntactic constituent movement. To that end, we introduce a syntax-based analysis method. We parse source sentences, and align the parse trees with reference translations as well as system translations. We then summarize syntactic reordering patterns using contextfree grammar (CFG) rules from the obtained tree-to-string alignments. The extracted reordering patterns clearly show the trace of syntactic constituent movement in both reference translations and system translations. With the proposed analysis method, we analyze the combination"
J10-3009,N04-1035,0,0.0231289,"ctures in order to capture reorderings under these structures. Our observation on phrase movement change resonates with the recent efforts in phrasal SMT that allow the decoder to prefer translations which show more respect for syntactic constituent boundaries (Cherry 2008; Marton and Resnik 2008; Yamamoto, Okuma, and Sumita 2008). Mapping to syntactic constituent boundaries, or in other words, syntactic cohesion (Fox 2002; Cherry 2008), has been studied and used in early syntax-based SMT models (Wu 1997; Yamada and Knight 2001). But its value has receded in more powerful syntax-based models (Galley et al. 2004; Chiang 2005) and non-syntactic phrasal models (Koehn, Och, and Marcu 2003). Marton and Resnik (2008) and Cherry (2008) use syntactic cohesion as a soft constraint by penalizing hypotheses which violate constituent boundaries. Yamamoto, Okuma, and Sumita (2008) impose this as a hard constraint on the ITG constraint to allow reorderings which respect the source parse tree. They all report signiﬁcant improvements on different language pairs, which indicates that syntactic cohesion is very useful for phrasal SMT. Our analysis demonstrates that linguistically annotated reordering provides an alte"
J10-3009,W08-0408,0,0.0311117,"Missing"
J10-3009,2006.amta-papers.8,0,0.0332198,"Missing"
J10-3009,W04-3250,0,0.161864,"Missing"
J10-3009,2005.iwslt-1.8,0,0.263134,"submission received: 12 March 2010; accepted for publication: 21 April 2010. © 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 local word reorderings within phrases. Unfortunately, reordering at the phrase level is still problematic for phrasal SMT. The default distortion-based reordering model simply penalizes phrase movement according to the jump distance, without considering any linguistic contexts (morphological, lexical, or syntactic) around phrases. In order to utilize lexical information for phrase reordering, Tillman (2004) and Koehn et al. (2005) propose lexicalized reordering models which directly condition phrase movement on phrases themselves. One problem with such lexicalized reordering models is that they are restricted only to reorderings of phrases seen in training data. To eliminate this restriction, Xiong, Liu, and Lin (2006) suggest using boundary words of phrases (i.e., leftmost/rightmost words of phrases), instead of phrases, as reordering evidence. Although these lexicalized reordering models signiﬁcantly outperform the distortion-based reordering model as reported, only using lexical information (e.g., boundary words) is"
J10-3009,N03-1017,0,0.0454533,"Missing"
J10-3009,H05-1021,0,0.0226242,"ting Phrase Movement with Embedded Reordering Models. Under the IBM constraint (Zens and Ney 2003), the early work uses a distortion-based reordering model to penalize word movements (Koehn, Och, and Marcu 2003). Similarly, under the ITG constraint, the corresponding model is the ﬂat model which assigns a prior probability to the straight or inverted order (Wu 1996). These two models don’t respect the content of phrases which are moved. To address this issue, lexicalized reordering models which are sensitive to lexical information about phrases are introduced (Tillman 2004; Koehn et al. 2005; Kumar and Byrne 2005; Al-Onaizan and Papineni 2006). Xiong, Liu, and Lin (2006) introduce a more ﬂexible reordering model under the ITG constraint using discriminative features which are automatically learned from a training corpus. Zhang et al. (2007) propose a model for syntactic phrase reordering which uses syntactic knowledge from source parse trees. Our reordering approach is most similar to those in Xiong, Liu, and Lin (2006) and Zhang et al. but extends them further by using syntactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and"
J10-3009,P07-1091,0,0.066262,"precision/recall for this structure is c/b and c/a, respectively. We can further calculate the F1 -score as 2 × c/(a + b). These syntax-based metrics intuitively show how well the reordering model can reorder this structure. By summarizing all reordering patterns of all constituents, we can obtain an overall precision, recall, and F1 -score for the tested reordering model. This new syntax-based analysis for reordering is motivated in part by recent work which transforms the order of nodes in the source-side parse tree before translation (Xia and McCord 2004; Collins, Koehn, and Kucerova 2005; Li et al. 2007; Wang, Collins, and Koehn 2007). Here we focus on the order transformation of syntactic constituents performed by reordering models during translation. In addition to aligning parse trees with reference translations, we also align parse trees with system translations so that we can learn the movement of syntactic constituents carried out by the reordering models and investigate the performance of the reordering models by comparing both alignments. For notational convenience, we denote syntactic reordering patterns that are extracted from the alignments between source parse trees and reference"
J10-3009,C04-1090,0,0.0184945,"ities of movement with linguistic information. In the third Table 12 Revised overall precision and recall of BWR+LAR vs. BWR on the test corpus when we consider the gap in syntactic reordering patterns. BWR (gap) BWR+LAR (gap) 562 Precision Recall F1 46.28 48.80 44.91 50 45.58 49.39 Xiong et al. Linguistically Annotated Reordering approach, reordering knowledge is included in synchronous rules. The last two categories reorder the source sentence during decoding, which distinguishes them from the ﬁrst approach. Note that some researchers integrate multiple reordering approaches in one decoder (Lin 2004; Quirk, Menezes, and Cherry 2005; Ge, Ittycheriah, and Papineni 2008). 9.1.1 The Preprocessing Approach. In early work, Brown et al. (1992) describe an approach to reordering French phrases in a preprocessing step. Xia and McCord (2004) present a preprocessing approach which automatically learns reordering patterns based on CFG productions. Since then, the preprocessing approach seems to have been more popular. Collins, Koehn, and Kucerova (2005) propose reordering German clauses with six types of manual rules. Similarly, Wang, Collins, and Koehn (2007) reorder Chinese parse trees using ﬁne-g"
J10-3009,P06-1077,0,0.0481188,"Missing"
J10-3009,W06-1606,0,0.143376,"n ﬂuent translations for these constituents. However, the allowance of interruptions is sometimes beyond the representability of BTG rules. For example, to solve the lexical divergence problem, bilingual rules with aligned lexicons have to be introduced. To capture reorderings of these constituents, we propose to integrate special reordering rules with richer contextual information into BTG to extend BTG’s ability to deal with interruptions. Completely replacing BTG with richer formalisms, such as hierarchical phrase (Chiang 2005) and tree-to-string (Liu, Liu, and Lin 2006) or string-to-tree (Marcu et al. 2006), introduces a huge extra cost. Instead, integrating a small number of reordering rules into BTG to model reorderings of non-reorderable constituents would be more desirable. 8.5 Discussion In the deﬁnition of syntactic reordering patterns, we only consider the relative order of individual constituents on the target side. We do not consider whether or not they remain contiguous on the target side. It is possible that other words are inserted between spans of two contiguous constituents. We use the term gap to refer to when this happens. The absence of a gap in the deﬁnition of syntactic reorde"
J10-3009,P08-1114,0,0.0620184,"with d d d d, which is a sub-phrase of PP preceding VP in an inverted order. The remaining part of the VP phrase is then merged. This merging process continues regardless of the source parse tree. The comparison of BTG trees of BWR+LAR and BWR in the two examples suggests that reordering models should respect syntactic structures in order to capture reorderings under these structures. Our observation on phrase movement change resonates with the recent efforts in phrasal SMT that allow the decoder to prefer translations which show more respect for syntactic constituent boundaries (Cherry 2008; Marton and Resnik 2008; Yamamoto, Okuma, and Sumita 2008). Mapping to syntactic constituent boundaries, or in other words, syntactic cohesion (Fox 2002; Cherry 2008), has been studied and used in early syntax-based SMT models (Wu 1997; Yamada and Knight 2001). But its value has receded in more powerful syntax-based models (Galley et al. 2004; Chiang 2005) and non-syntactic phrasal models (Koehn, Och, and Marcu 2003). Marton and Resnik (2008) and Cherry (2008) use syntactic cohesion as a soft constraint by penalizing hypotheses which violate constituent boundaries. Yamamoto, Okuma, and Sumita (2008) impose this as a"
J10-3009,2001.mtsummit-papers.45,0,0.0347596,"lauses with six types of manual rules. Similarly, Wang, Collins, and Koehn (2007) reorder Chinese parse trees using ﬁne-grained human-written rules, mostly concentrating on VP and NP structures. Li et al. (2007) improve the preprocessing approach by generating n-best reordered source sentences with reordering knowledge automatically learned from the alignments between source parse trees and target translations. The approach proposed in Li et al. also enhances the connection between the preprocessing and decoding by adding a source reordering probability feature. Other approaches introduced in Nießn and Ney (2001), Popovi´c and Ney (2006), and Zhang, Zens, and Ney (2007) use morphological, POS, and chunk knowledge in the preprocessing approach, respectively. 9.1.2 Estimating Phrase Movement with Embedded Reordering Models. Under the IBM constraint (Zens and Ney 2003), the early work uses a distortion-based reordering model to penalize word movements (Koehn, Och, and Marcu 2003). Similarly, under the ITG constraint, the corresponding model is the ﬂat model which assigns a prior probability to the straight or inverted order (Wu 1996). These two models don’t respect the content of phrases which are moved."
J10-3009,P03-1021,0,0.0120847,"Missing"
J10-3009,P00-1056,0,0.0905788,"TG-based phrasal SMT system, developed following Section 2. We integrate the boundary word–based reordering model and the linguistically annotated reordering model into our system according to our reordering conﬁguration. We carried out various experiments to evaluate the reordering example extraction algorithms of Section 3, the linguistically annotated reordering model vs. boundary word–based reordering model, and the effects of linguistically annotated features on the Chinese-toEnglish translation task of the NIST MT-05 using large scale training data. 7.1 Experimental Setup We ran GIZA++ (Och and Ney 2000) on the parallel corpora (consisting of 101.93M Chinese words and 112.78M English words) listed in Table 2 in both directions and then applied the “grow-diag-ﬁnal” reﬁnement rule (Koehn, Och, and Marcu 2003) to 550 Xiong et al. Linguistically Annotated Reordering Table 2 Corpora used. Corpus LDC catalog Chinese words English words United Nations Hong Kong News Sinorama Magazine FBIS Xinhua Chinese News Translation Chinese Treebank Multiple Translation Chinese LDC2004E12 LDC2004T08 LDC2005T10 LDC2003E14 LDC2002E18 LDC2005T06 LDC2003E07 LDC2004T07 68.63M 15.07M 10.26M 7.09M 0.40M 0.28M 0.10M 0.1"
J10-3009,P02-1040,0,0.0831864,"ITG constraint. We call this two-step phrase reordering strategy linguistically annotated reordering (LAR) (Xiong et al. 2008a). Xiong, Liu, and Lin (2006) also adapt a two-step reordering strategy based on BTG. However, they use boundary words as reordering features at the second step. To distinguish this from our work, we call their approach boundary word–based reordering (BWR). LAR and BWR can be considered as two reordering variants for BTG-based phrasal SMT, which have similar training procedures. Furthermore, they can be combined. We evaluate LAR vs. BWR using the automatic metric BLEU (Papineni et al. 2002). The BLEU scores show that LAR is comparable to BWR and signiﬁcantly improves phrase reordering when combined with BWR. We want to further study what happens when we combine BWR with LAR. In particular, we want to investigate to what extent the integrated linguistic knowledge (from LAR) changes phrase movement in an actual SMT system, and in what direction the change takes place. The investigations will enable us to have a better understanding of the relationship between phrase movement and linguistic context, and therefore to explore linguistic knowledge more effectively in phrasal SMT. Beca"
J10-3009,W06-3101,0,0.344324,"Missing"
J10-3009,popovic-ney-2006-pos,0,0.273344,"The default distortion-based reordering model simply penalizes phrase movement according to the jump distance, without considering any linguistic contexts (morphological, lexical, or syntactic) around phrases. In order to utilize lexical information for phrase reordering, Tillman (2004) and Koehn et al. (2005) propose lexicalized reordering models which directly condition phrase movement on phrases themselves. One problem with such lexicalized reordering models is that they are restricted only to reorderings of phrases seen in training data. To eliminate this restriction, Xiong, Liu, and Lin (2006) suggest using boundary words of phrases (i.e., leftmost/rightmost words of phrases), instead of phrases, as reordering evidence. Although these lexicalized reordering models signiﬁcantly outperform the distortion-based reordering model as reported, only using lexical information (e.g., boundary words) is not adequate to move phrases to appropriate positions. Consider the following Chinese example with its English translation: [VP [PP d(while) dd(develop) dd(related) dd(legislation) d] [VP [VV d d(consider)] [NP [DNP [NP dd(this) dddd(referendum)] [DEG d(of)]] [NP d d(results)]]]]1 consider th"
J10-3009,P05-1034,0,0.0719418,"Missing"
J10-3009,N04-4026,0,0.654536,"eived: 24 October 2008; revised submission received: 12 March 2010; accepted for publication: 21 April 2010. © 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 local word reorderings within phrases. Unfortunately, reordering at the phrase level is still problematic for phrasal SMT. The default distortion-based reordering model simply penalizes phrase movement according to the jump distance, without considering any linguistic contexts (morphological, lexical, or syntactic) around phrases. In order to utilize lexical information for phrase reordering, Tillman (2004) and Koehn et al. (2005) propose lexicalized reordering models which directly condition phrase movement on phrases themselves. One problem with such lexicalized reordering models is that they are restricted only to reorderings of phrases seen in training data. To eliminate this restriction, Xiong, Liu, and Lin (2006) suggest using boundary words of phrases (i.e., leftmost/rightmost words of phrases), instead of phrases, as reordering evidence. Although these lexicalized reordering models signiﬁcantly outperform the distortion-based reordering model as reported, only using lexical information ("
J10-3009,D07-1077,0,0.0334249,"Missing"
J10-3009,P96-1021,0,0.353417,"important and challenging tasks in building a BTG-based phrasal SMT system is to deﬁne P(r m ). 2.2 Reordering Under the ITG Constraint Under the ITG constraint, three nodes {Al , Ar , Ap } are involved when we consider the order o between the two children {Al , Ar } in any binary subtrees. Therefore it is natural to deﬁne the ITG reordering P(r m ) as a function as follows: P(rm ) = f (Al , Ar , Ap , o) (5) where o ∈ {straight, inverted}. Based on this function, various reordering models are built according to different assumptions. For example, the ﬂat reordering model in the original BTG (Wu 1996) assigns prior probabilities for the straight and inverted order assuming the order is highly related to the properties of language pairs. It is formulated as  m P(r ) = ps , o = straight 1 − ps , o = inverted (6) Supposing French and English are the source and target language, respectively, the value of ps can be set as high as 0.8 to prefer monotone orientations because the two languages have similar word orders in most cases. The main problem of the ﬂat reordering model is also the problem of the standard distortion model (Koehn, Och, and Marcu 2003): Neither model considers linguistic con"
J10-3009,J97-3002,0,0.787827,"ch succeeding phrase should be translated ﬁrst. If high-level linguistic knowledge, such as the syntactic context VP→PP VP, is given, the position of the PP phrase can be easily determined since the pre-verbal modiﬁer PP in Chinese is frequently translated into a post-verbal counterpart in English. In this article, we focus on linguistically motivated phrase reordering, which integrates high-level linguistic knowledge in phrase reordering. We adopt a two-step strategy. In the ﬁrst step, we establish a hierarchical skeleton in phrasal SMT by incorporating Bracketing Transduction Grammar (BTG) (Wu 1997) into phrasal SMT. In the second step, we inject soft linguistic information into nodes of the skeleton. There are two signiﬁcant advantages to using BTG in phrasal SMT. First, BTG is able to generate hierarchical structures.2 This not only enhances phrasal SMT’s capability for hierarchical and long-distance reordering but also establishes a platform for phrasal SMT to incorporate knowledge from linguistic structure. Second, phrase reordering is restricted by the ITG constraint (Wu 1997). Although it only allows two orders (straight or inverted) of nodes in any binary branching structure, it i"
J10-3009,C04-1073,0,0.197301,"4 October 2008; revised submission received: 12 March 2010; accepted for publication: 21 April 2010. © 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 local word reorderings within phrases. Unfortunately, reordering at the phrase level is still problematic for phrasal SMT. The default distortion-based reordering model simply penalizes phrase movement according to the jump distance, without considering any linguistic contexts (morphological, lexical, or syntactic) around phrases. In order to utilize lexical information for phrase reordering, Tillman (2004) and Koehn et al. (2005) propose lexicalized reordering models which directly condition phrase movement on phrases themselves. One problem with such lexicalized reordering models is that they are restricted only to reorderings of phrases seen in training data. To eliminate this restriction, Xiong, Liu, and Lin (2006) suggest using boundary words of phrases (i.e., leftmost/rightmost words of phrases), instead of phrases, as reordering evidence. Although these lexicalized reordering models signiﬁcantly outperform the distortion-based reordering model as reported, only using lexical information ("
J10-3009,I05-1007,1,0.889647,"Missing"
J10-3009,P06-1066,1,0.924664,"Missing"
J10-3009,P08-2038,1,0.858008,". The challenge, of course, is that BTG hierarchical structures are not always aligned with the linguistic structures in the source language parse tree. To address this issue, we propose an annotation algorithm. The algorithm is able to label any BTG nodes during decoding with very little overhead, regardless of whether the BTG nodes are aligned with syntactic constituent nodes in the source parse tree. The annotated linguistic elements are then used to guide phrase reordering under the ITG constraint. We call this two-step phrase reordering strategy linguistically annotated reordering (LAR) (Xiong et al. 2008a). Xiong, Liu, and Lin (2006) also adapt a two-step reordering strategy based on BTG. However, they use boundary words as reordering features at the second step. To distinguish this from our work, we call their approach boundary word–based reordering (BWR). LAR and BWR can be considered as two reordering variants for BTG-based phrasal SMT, which have similar training procedures. Furthermore, they can be combined. We evaluate LAR vs. BWR using the automatic metric BLEU (Papineni et al. 2002). The BLEU scores show that LAR is comparable to BWR and signiﬁcantly improves phrase reordering when co"
J10-3009,I08-1066,1,0.939151,". The challenge, of course, is that BTG hierarchical structures are not always aligned with the linguistic structures in the source language parse tree. To address this issue, we propose an annotation algorithm. The algorithm is able to label any BTG nodes during decoding with very little overhead, regardless of whether the BTG nodes are aligned with syntactic constituent nodes in the source parse tree. The annotated linguistic elements are then used to guide phrase reordering under the ITG constraint. We call this two-step phrase reordering strategy linguistically annotated reordering (LAR) (Xiong et al. 2008a). Xiong, Liu, and Lin (2006) also adapt a two-step reordering strategy based on BTG. However, they use boundary words as reordering features at the second step. To distinguish this from our work, we call their approach boundary word–based reordering (BWR). LAR and BWR can be considered as two reordering variants for BTG-based phrasal SMT, which have similar training procedures. Furthermore, they can be combined. We evaluate LAR vs. BWR using the automatic metric BLEU (Papineni et al. 2002). The BLEU scores show that LAR is comparable to BWR and signiﬁcantly improves phrase reordering when co"
J10-3009,P01-1067,0,0.0235166,"and BWR in the two examples suggests that reordering models should respect syntactic structures in order to capture reorderings under these structures. Our observation on phrase movement change resonates with the recent efforts in phrasal SMT that allow the decoder to prefer translations which show more respect for syntactic constituent boundaries (Cherry 2008; Marton and Resnik 2008; Yamamoto, Okuma, and Sumita 2008). Mapping to syntactic constituent boundaries, or in other words, syntactic cohesion (Fox 2002; Cherry 2008), has been studied and used in early syntax-based SMT models (Wu 1997; Yamada and Knight 2001). But its value has receded in more powerful syntax-based models (Galley et al. 2004; Chiang 2005) and non-syntactic phrasal models (Koehn, Och, and Marcu 2003). Marton and Resnik (2008) and Cherry (2008) use syntactic cohesion as a soft constraint by penalizing hypotheses which violate constituent boundaries. Yamamoto, Okuma, and Sumita (2008) impose this as a hard constraint on the ITG constraint to allow reorderings which respect the source parse tree. They all report signiﬁcant improvements on different language pairs, which indicates that syntactic cohesion is very useful for phrasal SMT."
J10-3009,W08-0401,0,0.0240288,"Missing"
J10-3009,P03-1019,0,0.0283626,"n-best reordered source sentences with reordering knowledge automatically learned from the alignments between source parse trees and target translations. The approach proposed in Li et al. also enhances the connection between the preprocessing and decoding by adding a source reordering probability feature. Other approaches introduced in Nießn and Ney (2001), Popovi´c and Ney (2006), and Zhang, Zens, and Ney (2007) use morphological, POS, and chunk knowledge in the preprocessing approach, respectively. 9.1.2 Estimating Phrase Movement with Embedded Reordering Models. Under the IBM constraint (Zens and Ney 2003), the early work uses a distortion-based reordering model to penalize word movements (Koehn, Och, and Marcu 2003). Similarly, under the ITG constraint, the corresponding model is the ﬂat model which assigns a prior probability to the straight or inverted order (Wu 1996). These two models don’t respect the content of phrases which are moved. To address this issue, lexicalized reordering models which are sensitive to lexical information about phrases are introduced (Tillman 2004; Koehn et al. 2005; Kumar and Byrne 2005; Al-Onaizan and Papineni 2006). Xiong, Liu, and Lin (2006) introduce a more ﬂ"
J10-3009,D07-1056,0,0.0189614,"ITG constraint, the corresponding model is the ﬂat model which assigns a prior probability to the straight or inverted order (Wu 1996). These two models don’t respect the content of phrases which are moved. To address this issue, lexicalized reordering models which are sensitive to lexical information about phrases are introduced (Tillman 2004; Koehn et al. 2005; Kumar and Byrne 2005; Al-Onaizan and Papineni 2006). Xiong, Liu, and Lin (2006) introduce a more ﬂexible reordering model under the ITG constraint using discriminative features which are automatically learned from a training corpus. Zhang et al. (2007) propose a model for syntactic phrase reordering which uses syntactic knowledge from source parse trees. Our reordering approach is most similar to those in Xiong, Liu, and Lin (2006) and Zhang et al. but extends them further by using syntactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and Eisner (2003) use synchronous grammars to capture reorderings between two languages. Chiang (2005) introduces formal synchronous grammars for phrase-based translation. In his work, hierarchical reordering knowledge is included in sy"
J10-3009,P05-1059,0,0.0165509,"caused by the use of heuristic selection rules: keeping some block pairs as reordering examples while abandoning other block pairs. The kept block pairs are not necessarily the best training instances for tuning an ITG order predictor. To avoid this problem we can extract reordering examples from the BTG trees of sentence pairs. Reordering examples extracted in this way are naturally suitable for BTG order prediction. There are various ways to build BTG trees over sentence pairs. One can use BTG to produce bilingual parses of sentence pairs, similar to the approaches proposed by Wu (1997) and Zhang and Gildea (2005) but using the more sophisticated reordering models BWR or LAR. After parsing, reordering examples can be extracted from bilingual parse trees and a better reordering model is therefore induced from the extracted reordering examples. Using the better reordering model, the bilingual sentences are parsed again. This procedure is run iteratively until no performance gain is obtained in terms of translation or parsing accuracy. Formally, we can use expectation-maximization (EM) training in this procedure. In the expectation step, we ﬁrst estimate the likelihood of all BTG trees of sentence pairs w"
J10-3009,C08-1136,0,0.013257,"tactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and Eisner (2003) use synchronous grammars to capture reorderings between two languages. Chiang (2005) introduces formal synchronous grammars for phrase-based translation. In his work, hierarchical reordering knowledge is included in synchronous rules which are automatically learned from word-aligned corpus. In linguistically syntax-based models, stringto-tree (Marcu et al. 2006), tree-to-string (Huang, Knight, and Joshi 2006; Liu, Liu, and Lin 2006), and tree-to-tree (Zhang et al. 2008) translation rules, just to name a few, are explored. Linguistical reordering knowledge is naturally included in these syntax-based translation rules. 9.2 Automatic Analysis of Reordering Although there is a variety of work on phrase reordering, automatic analysis of phrase reordering is not widely explored in the SMT literature. Chiang et al. (2005) propose 563 Computational Linguistics Volume 36, Number 3 an automatic method to compare different system outputs in a ﬁne-grained manner with regard to reordering. In their method, common word n-grams occurring in both reference translations and"
J10-3009,P08-1064,1,0.846608,"tactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and Eisner (2003) use synchronous grammars to capture reorderings between two languages. Chiang (2005) introduces formal synchronous grammars for phrase-based translation. In his work, hierarchical reordering knowledge is included in synchronous rules which are automatically learned from word-aligned corpus. In linguistically syntax-based models, stringto-tree (Marcu et al. 2006), tree-to-string (Huang, Knight, and Joshi 2006; Liu, Liu, and Lin 2006), and tree-to-tree (Zhang et al. 2008) translation rules, just to name a few, are explored. Linguistical reordering knowledge is naturally included in these syntax-based translation rules. 9.2 Automatic Analysis of Reordering Although there is a variety of work on phrase reordering, automatic analysis of phrase reordering is not widely explored in the SMT literature. Chiang et al. (2005) propose 563 Computational Linguistics Volume 36, Number 3 an automatic method to compare different system outputs in a ﬁne-grained manner with regard to reordering. In their method, common word n-grams occurring in both reference translations and"
J10-3009,W07-0401,0,0.0144484,"ITG constraint, the corresponding model is the ﬂat model which assigns a prior probability to the straight or inverted order (Wu 1996). These two models don’t respect the content of phrases which are moved. To address this issue, lexicalized reordering models which are sensitive to lexical information about phrases are introduced (Tillman 2004; Koehn et al. 2005; Kumar and Byrne 2005; Al-Onaizan and Papineni 2006). Xiong, Liu, and Lin (2006) introduce a more ﬂexible reordering model under the ITG constraint using discriminative features which are automatically learned from a training corpus. Zhang et al. (2007) propose a model for syntactic phrase reordering which uses syntactic knowledge from source parse trees. Our reordering approach is most similar to those in Xiong, Liu, and Lin (2006) and Zhang et al. but extends them further by using syntactic knowledge and allowing non-syntactic phrase reordering. 9.1.3 Capturing Reorderings by Synchronous Grammars. Wu (1997) and Eisner (2003) use synchronous grammars to capture reorderings between two languages. Chiang (2005) introduces formal synchronous grammars for phrase-based translation. In his work, hierarchical reordering knowledge is included in sy"
J10-3009,2008.iwslt-evaluation.2,0,0.0426999,"Missing"
N10-1016,J96-1002,0,0.00599551,". In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation system, which is similar to our definition of translation boundary. They also use a maximum entropy model to predict whether a source position is a rift based on features only from source sentences. Our work differs from (Berger et al., 1996) in three major respects. 1) We distinguish a segment boundary into two categories: beginning and ending boundary due to their different distributions (see Table 1). However, Berger et al. ignore this difference. 2) We train two classifiers to predict beginning and ending boundary respectively whil"
N10-1016,H92-1053,0,0.182045,"Missing"
N10-1016,P08-1009,0,0.236099,"ins. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major probl"
N10-1016,P05-1033,0,0.123433,"ies for any source sentences. The classifiers are trained directly on word-aligned corpus without using any additional resources. We report the accuracy of our translation boundary classifiers. We show that using constraints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-toEnglish translation experiments. The new constraints also significantly outperform constituent boundary based syntactic constrains. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn"
N10-1016,P05-1066,0,0.00867273,"ide parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation system, which is similar to our definition of translation boundary. They also use a maximum entropy model to predict whether"
N10-1016,J99-4005,0,0.0418273,"sing any additional resources. We report the accuracy of our translation boundary classifiers. We show that using constraints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-toEnglish translation experiments. The new constraints also significantly outperform constituent boundary based syntactic constrains. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a countin"
N10-1016,N03-1017,0,0.0561793,"2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major problem with such constituent boundary based constraints is that syntactic structures of the source language do not necessarily"
N10-1016,W04-3250,0,0.181357,"Missing"
N10-1016,P08-1114,0,0.295696,"It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major problem with such constituent bound"
N10-1016,P00-1056,0,0.0697293,"Missing"
N10-1016,P03-1021,0,0.0107032,"add a new feature to the decoder’s loglinear model: translation boundary violation counting feature. This counting feature accumulates whenever hypotheses have a partial translation spanning ci ...cj (j > i) where ci ∈ / By or cj ∈ / Ey . The 140 LDC ID LDC2004E12 LDC2004T08 LDC2005T10 LDC2003E14 LDC2002E18 LDC2005T06 LDC2003E07 LDC2004T07 Description United Nations Hong Kong News Sinorama Magazine FBIS Xinhua News V1 beta Chinese News Translation Chinese Treebank Multiple Translation Chinese Table 5: Training corpora. weight λv of this feature is tuned via minimal error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalty of exp(−λv Cv ) where Cv is the violation count. By using soft constraints, we can enable the model to prefer hypotheses which are consistent with translation boundaries. 5 Experiment Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out v"
N10-1016,P02-1040,0,0.104176,"Missing"
N10-1016,C08-1094,0,0.0139392,"age do not necessarily reflect translation structures where the source and target language correspond to each other. In this paper, we investigate building classifiers that directly address the problem of translation boundary, rather than extracting constituent boundary from sourceside parsers built for a different purpose. A translation boundary is a position in the source sequence which begins or ends a translation zone 1 spanning multiple source words. In a translation zone, the source phrase is translated as a unit. Reorderings which cross translation zones are not desirable. Inspired by (Roark and Hollingshead, 2008) which introduces classifiers to decide if a word can begin/end a multi-word constituent, we build two discriminative classifiers to tag each word in the source sequence with a binary class label. The first classifier decides if a word can begin a multi-sourceword translation zone; the second classifier decides if a word can end a multi-source-word translation 1 We will give a formal definition of translation zone in Section 2. 136 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 136–144, c Los Angeles, California, June 2010. 2010 Associat"
N10-1016,D07-1077,0,0.00652594,"lation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation system, which is similar to our definition of translation boundary. They also use a maximum entropy model to predict whether a source position is a"
N10-1016,Y95-1025,0,0.0786103,"er. Our introduction has already briefly mentioned (Cherry, 2008) and (Marton and Resnik, 2008), which utilize source-side parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation"
N10-1016,J97-3002,0,0.0255434,"Treebank Multiple Translation Chinese Table 5: Training corpora. weight λv of this feature is tuned via minimal error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalty of exp(−λv Cv ) where Cv is the violation count. By using soft constraints, we can enable the model to prefer hypotheses which are consistent with translation boundaries. 5 Experiment Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data. 5.1 Experimental Setup Our training corpora are listed in Table 5. The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora"
N10-1016,I05-1007,1,0.393667,"Missing"
N10-1016,P06-1066,1,0.524346,"rror rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalty of exp(−λv Cv ) where Cv is the violation count. By using soft constraints, we can enable the model to prefer hypotheses which are consistent with translation boundaries. 5 Experiment Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data. 5.1 Experimental Setup Our training corpora are listed in Table 5. The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora in both directions and then applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to obtain many-to-many word a"
N10-1016,P09-1036,1,0.852114,"008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major problem with such constituent boundary based constraints is that syntactic structures of the source language do not necessarily reflect translation structures where the source and target language correspond to each other. In this paper, we investigate building classifiers that directly address the problem of translation boundary, rather"
N10-1016,C08-1136,0,0.145511,"straints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-toEnglish translation experiments. The new constraints also significantly outperform constituent boundary based syntactic constrains. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xion"
N10-1016,C04-1030,0,\N,Missing
N10-1016,I08-1066,1,\N,Missing
N10-1016,2005.iwslt-1.8,0,\N,Missing
O06-3004,O06-3004,1,0.0512899,"Missing"
O06-3004,P05-1064,1,0.429387,"Missing"
P04-1021,W03-1508,0,0.797183,"Missing"
P04-1021,C00-1056,0,\N,Missing
P05-1064,J99-3003,0,\N,Missing
P06-1142,P98-1069,0,0.0577661,"s much room for improvement if one expects to use a generative model to construct a lexicon for casual transliterations. EX research is motivated by information retrieval techniques, where people attempt to extract transliteration pairs from corpora. The EX approach aims to construct a large and up-todate transliteration lexicon from live corpora. Towards this objective, some have proposed extracting translation pairs from parallel or comparable bitext using co-occurrence analysis 1 Both phoneme and syllable based approaches are referred to as phoneme-based here. or a context-vector approach (Fung and Yee, 1998; Nie et al, 1999). These methods compare the semantic similarities between words without taking their phonetic similarities into accounts. Lee and Chang (2003) proposed using a probabilistic model to identify E-C pairs from aligned sentences using phonetic clues. Lam et al (2004) proposed using semantic and phonetic clues to extract E-C pairs from comparable corpora. However, these approaches are subject to the availability of parallel or comparable bitext. A method that explores non-aligned text was proposed by harvesting katakana-English pairs from query logs (Brill et al, 2001). It was dis"
P06-1142,H05-1061,0,0.0420267,"availability of parallel or comparable bitext. A method that explores non-aligned text was proposed by harvesting katakana-English pairs from query logs (Brill et al, 2001). It was discovered that the unsupervised learning of such a transliteration model could be overwhelmed by noisy data, resulting in a decrease in model accuracy. Many efforts have been made in using Webbased resources for harvesting transliteration/ translation pairs. These include exploring query logs (Brill et al, 2001), unrelated corpus (Rapp, 1999), and parallel or comparable corpus (Fung and Yee, 1998; Nie et al, 1999; Huang et al 2005). To establish correspondence, these algorithms usually rely on one or more statistical clues, such as the correlation between word frequencies, cognates of similar spelling or pronunciations. They include two aspects. First, a robust mechanism that establishes statistical relationships between bilingual words, such as a phonetic similarity model which is motivated by the TM research; and second, an effective learning framework that is able to adaptively discover new events from the Web. In the prior work, most of the phonetic similarity models were trained on a static lexicon. In this paper,"
P06-1142,P04-3003,1,0.828173,"it into a sequence of Chinese characters. There have been several effective algorithms for the syllabification of English words for transliteration. Typical syllabification algorithms first convert English graphemes to phonemes, referred to as the letter-to-sound transformation, then syllabify the phoneme sequence into a syllable sequence. For this method, a letter-tosound conversion is needed (Pagel, 1998; Jurafsky, 2000). The phoneme-based syllabification algorithm is referred to as PSA. Another syllabification technique attempts to map the grapheme of an English word to syllables directly (Kuo and Yang, 2004). The grapheme-based syllabification algorithm is referred to as GSA. In general, the size of a phoneme inventory is smaller than that of a grapheme inventory. The PSA therefore requires less training data for statistical modeling (Knight, 1998); on the other hand, the grapheme-based method gets rid of the letter-to-sound conversion, which is one of the main causes of transliteration errors (Li et al, 2004). Assuming that Chinese transliterations always co-occur in proximity to their original English words, we propose a phonetic similarity modeling (PSM) that measures the phonetic similarity b"
P06-1142,W03-0317,0,0.140467,"on retrieval techniques, where people attempt to extract transliteration pairs from corpora. The EX approach aims to construct a large and up-todate transliteration lexicon from live corpora. Towards this objective, some have proposed extracting translation pairs from parallel or comparable bitext using co-occurrence analysis 1 Both phoneme and syllable based approaches are referred to as phoneme-based here. or a context-vector approach (Fung and Yee, 1998; Nie et al, 1999). These methods compare the semantic similarities between words without taking their phonetic similarities into accounts. Lee and Chang (2003) proposed using a probabilistic model to identify E-C pairs from aligned sentences using phonetic clues. Lam et al (2004) proposed using semantic and phonetic clues to extract E-C pairs from comparable corpora. However, these approaches are subject to the availability of parallel or comparable bitext. A method that explores non-aligned text was proposed by harvesting katakana-English pairs from query logs (Brill et al, 2001). It was discovered that the unsupervised learning of such a transliteration model could be overwhelmed by noisy data, resulting in a decrease in model accuracy. Many effor"
P06-1142,P04-1021,1,0.922903,"in view of the current information explosion, it is labor intensive, if not impossible, to compile a complete proper nouns lexicon. The Web is growing at a fast pace and is providing a live information source that is rich in transliterations. This paper presents a novel Ying-Kuei Yang2 2 National Taiwan University of Science and Technology, Taiwan ykyang@mouse.ee. ntust.edu.tw solution for automatically constructing an English-Chinese transliteration lexicon from the Web. Research on automatic transliteration has reported promising results for regular transliteration (Wan and Verspoor, 1998; Li et al, 2004), where transliterations follow rigid guidelines. However, in Web publishing, translators in different countries and regions may not observe common guidelines. They often skew the transliterations in different ways to create special meanings to the sound equivalents, resulting in casual transliterations. In this case, the common generative models (Li et al, 2004) fail to predict the transliteration most of the time. For example, “Coca Cola” is transliterated into “ 可 口 可 樂 /Ke-Kou-Ke-Le/” as a sound equivalent in Chinese, which literately means “happiness in the mouth”. In this paper, we are i"
P06-1142,P99-1067,0,0.0208833,"ract E-C pairs from comparable corpora. However, these approaches are subject to the availability of parallel or comparable bitext. A method that explores non-aligned text was proposed by harvesting katakana-English pairs from query logs (Brill et al, 2001). It was discovered that the unsupervised learning of such a transliteration model could be overwhelmed by noisy data, resulting in a decrease in model accuracy. Many efforts have been made in using Webbased resources for harvesting transliteration/ translation pairs. These include exploring query logs (Brill et al, 2001), unrelated corpus (Rapp, 1999), and parallel or comparable corpus (Fung and Yee, 1998; Nie et al, 1999; Huang et al 2005). To establish correspondence, these algorithms usually rely on one or more statistical clues, such as the correlation between word frequencies, cognates of similar spelling or pronunciations. They include two aspects. First, a robust mechanism that establishes statistical relationships between bilingual words, such as a phonetic similarity model which is motivated by the TM research; and second, an effective learning framework that is able to adaptively discover new events from the Web. In the prior wor"
P06-1142,W03-1508,0,0.0937852,"Missing"
P06-1142,C98-1066,0,\N,Missing
P06-1142,P98-2220,0,\N,Missing
P06-1142,C98-2215,0,\N,Missing
P07-1016,2005.iwslt-1.23,0,0.0430652,"Missing"
P07-1016,P06-1142,1,0.188263,"n 6. 2 Related Work In general, computational studies of transliteration fall into two categories: transliteration modeling and extraction of transliteration pairs. In transliteration modeling, transliteration rules are trained from a large, bilingual transliteration lexicon (Lin and Chen, 2002; Oh and Choi, 2005), with the objective of translating unknown words on the fly in an open, general domain. In the extraction of transliterations, data-driven methods are adopted to extract actual transliteration pairs from a corpus, in an effort to construct a large, upto-date transliteration lexicon (Kuo et al., 2006; Sproat et al., 2006). Phonetic transliteration can be considered as an extension to the traditional grapheme-to-phoneme (G2P) conversion (Galescu and Allen, 2001), which has been a much-researched topic in the field of speech processing. If we view the grapheme and phoneme as two symbolic representations of the same word in two different languages, then G2P is a transliteration task by itself. Although G2P and phonetic transliteration are common in many ways, transliteration has its unique challenges, especially as far as E-C transliteration is concerned. E-C transliteration is the conversio"
P07-1016,P04-1021,1,0.275649,"ion system, for ease of reference. 2 Xu Quangqi (1562–1633) translated The Original Manuscript of Geometry to Chinese jointly with Matteo Ricci. 120 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 120–127, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics Unfortunately, most of the reported work in the area of machine transliteration has not ventured into semantic transliteration yet. The Latin-scripted personal names are always assumed to homogeneously follow the English phonic rules in automatic transliteration (Li et al., 2004). Therefore, the same transliteration model is applied to all the names indiscriminatively. This assumption degrades the performance of transliteration because each language has its own phonic rule and the Chinese characters to be adopted depend on the following semantic attributes of a foreign name. (1) Language of origin: An English word is not necessarily of pure English origin. In English news reports about Asian happenings, an English personal name may have been originated from Chinese, Japanese or Korean. The language origin affects the phonic rules and the characters to be used in trans"
P07-1016,W02-2017,0,0.0544039,"Zi/ female given name, Japanese origin. In Section 2, we summarize the related work. In Section 3, we discuss the linguistic feasibility of semantic transliteration for personal names. Section 4 formulates a probabilistic model for semantic transliteration. Section 5 reports the experiments. Finally, we conclude in Section 6. 2 Related Work In general, computational studies of transliteration fall into two categories: transliteration modeling and extraction of transliteration pairs. In transliteration modeling, transliteration rules are trained from a large, bilingual transliteration lexicon (Lin and Chen, 2002; Oh and Choi, 2005), with the objective of translating unknown words on the fly in an open, general domain. In the extraction of transliterations, data-driven methods are adopted to extract actual transliteration pairs from a corpus, in an effort to construct a large, upto-date transliteration lexicon (Kuo et al., 2006; Sproat et al., 2006). Phonetic transliteration can be considered as an extension to the traditional grapheme-to-phoneme (G2P) conversion (Galescu and Allen, 2001), which has been a much-researched topic in the field of speech processing. If we view the grapheme and phoneme as"
P07-1016,I05-1040,0,0.217871,"e, Japanese origin. In Section 2, we summarize the related work. In Section 3, we discuss the linguistic feasibility of semantic transliteration for personal names. Section 4 formulates a probabilistic model for semantic transliteration. Section 5 reports the experiments. Finally, we conclude in Section 6. 2 Related Work In general, computational studies of transliteration fall into two categories: transliteration modeling and extraction of transliteration pairs. In transliteration modeling, transliteration rules are trained from a large, bilingual transliteration lexicon (Lin and Chen, 2002; Oh and Choi, 2005), with the objective of translating unknown words on the fly in an open, general domain. In the extraction of transliterations, data-driven methods are adopted to extract actual transliteration pairs from a corpus, in an effort to construct a large, upto-date transliteration lexicon (Kuo et al., 2006; Sproat et al., 2006). Phonetic transliteration can be considered as an extension to the traditional grapheme-to-phoneme (G2P) conversion (Galescu and Allen, 2001), which has been a much-researched topic in the field of speech processing. If we view the grapheme and phoneme as two symbolic represe"
P07-1016,J96-3004,0,0.0231894,"ed to as unclassified. E-C J-C5 C-C6 Surname (S) 12,490 36,352 569,403 Given name (M) 3,201 35,767 345,044 Given name (F) 4,275 11,817 122,772 Unclassified 22,562 All 42,528 83,936 1,972,851 Table 1: Number of entries in 3 corpora Phonetic transliteration has not been a problem as Chinese has over 400 unique syllables that are enough to approximately transcribe all syllables in other languages. Different Chinese characters may render into the same syllable and form a range of homonyms. Among the homonyms, those arousing positive meanings can be used for personal names. As discussed elsewhere (Sproat et al., 1996), out of several thousand common Chinese characters, a subset of a few hundred characters tends to be used overwhelmingly for transliterating English names to Chinese, e.g. only 731 Chinese characters are adopted in the E-C corpus. Although the character sets are shared across languages and genders, the statistics in Table 2 show that each semantic attribute is associated with some unique characters. In the C-C corpus, out of the total of 4,507 characters, only 776 of them are for surnames. It is interesting to find that female given names are represented by a smaller set of characters than th"
P07-1016,W06-1629,0,0.134683,"d phoneme as two symbolic representations of the same word in two different languages, then G2P is a transliteration task by itself. Although G2P and phonetic transliteration are common in many ways, transliteration has its unique challenges, especially as far as E-C transliteration is concerned. E-C transliteration is the conversion between English graphemes, phonetically associated English letters, and Chinese graphemes, characters which represent ideas or meanings. As a Chinese transliteration can arouse to certain connotations, the choice of Chinese characters becomes a topic of interest (Xu et al., 2006). Semantic transliteration can be seen as a subtask of statistical machine translation (SMT) with monotonic word ordering. By treating a letter/character as a word and a group of letters/characters as a phrase or token unit in SMT, one can easily apply the traditional SMT models, such as the IBM generative model (Brown et al., 1993) or the phrase-based translation model (Crego et al., 2005) to transliteration. In transliteration, we face similar issues as in SMT, such as lexical mapping and alignment. However, transliteration is also different from general SMT in many ways. Unlike SMT where we"
P07-1016,J93-2003,0,\N,Missing
P07-1016,P06-1010,0,\N,Missing
P07-1090,P05-1069,0,0.0476481,"Missing"
P07-1090,P05-1033,0,0.158491,"del (Nagata et al., 2006) and distortion model (Al-Onaizan and Papineni, 2006). However, these models are often fully lexicalized and sensitive to individual phrases. As a result, they are not robust to unseen phrases. A careful approximation is vital to avoid data sparseness. Proposals to alleviate this problem include utilizing bilingual phrase cluster or words at the phrase boundary (Nagata et al., 2006) as the phrase identity. The benefit of introducing lexical evidence without being fully lexicalized has been demonstrated by a recent state-of-the-art formally syntax-based model1 , Hiero (Chiang, 2005). Hiero performs phrase ordering by using linked non-terminal symbols in its synchronous CFG production rules coupled with lexical evidence. However, since it is difficult to specify a well-defined rule, Hiero has to rely on weak heuristics (i.e., length-based thresholds) to extract rules. As a result, Hiero produces grammars of enormous size. Watanabe et al. (2006) further reduces the grammar’s size by enforcing all rules to comply with Greibach Normal Form. Taking the lexicalization an intuitive a step forward, we propose a novel, finer-grained solution which models the content and context i"
P07-1090,J97-3002,0,0.911836,"nce pair. greatly reducing the computational overhead that arises when moving from phrase-based to syntaxbased approach. Furthermore, by modeling only high frequency words, we are able to obtain reliable statistics even in small datasets. Second, as opposed to Hiero, where phrase ordering is done implicitly alongside phrase translation and lexical weighting, we directly model the reordering process using orientation statistics. The FWS approach is also akin to (Xiong et al., 2006) in using a synchronous grammar as a reordering constraint. Instead of using Inversion Transduction Grammar (ITG) (Wu, 1997) directly, we will discuss an ITG extension to accommodate gapping. 3 Phrase Ordering around Function Words We use the following Chinese (c) to English (e) translation in Fig.1 as an illustration to conduct an inquiry to the problem. Note that the sentence translation requires some translations of English words to be ordered far from their original position in Chinese. Recovering the correct English ordering requires the inversion of the Chinese postpositional phrase, followed by the inversion of the first smaller noun phrase, and finally the inversion of the second larger noun phrase. Neverth"
P07-1090,P06-1066,0,0.0846159,"P (  ` ( `P  P (   `P ( ( ` ```  ( (((  P a form is a coll. of data entry fields on a page Figure 1: A Chinese-English sentence pair. greatly reducing the computational overhead that arises when moving from phrase-based to syntaxbased approach. Furthermore, by modeling only high frequency words, we are able to obtain reliable statistics even in small datasets. Second, as opposed to Hiero, where phrase ordering is done implicitly alongside phrase translation and lexical weighting, we directly model the reordering process using orientation statistics. The FWS approach is also akin to (Xiong et al., 2006) in using a synchronous grammar as a reordering constraint. Instead of using Inversion Transduction Grammar (ITG) (Wu, 1997) directly, we will discuss an ITG extension to accommodate gapping. 3 Phrase Ordering around Function Words We use the following Chinese (c) to English (e) translation in Fig.1 as an illustration to conduct an inquiry to the problem. Note that the sentence translation requires some translations of English words to be ordered far from their original position in Chinese. Recovering the correct English ordering requires the inversion of the Chinese postpositional phrase, fol"
P07-1090,J04-4002,0,0.666333,"ems use statistical knowledge obtained from corpora in favor of rich natural language knowledge. Instead of using syntactic knowledge to determine function words, we approximate this by equating the most frequent words as function words. By explicitly modeling phrase ordering around these frequent words, we aim to capture the most important and prevalent ordering productions. 2 Related Work A good translation should be both faithful with adequate lexical choice to the source language and fluent in its word ordering to the target language. In pursuit of better translation, phrase-based models (Och and Ney, 2004) have significantly improved the quality over classical word-based models (Brown et al., 1993). These multiword phrasal units contribute to fluency by inherently capturing intra-phrase reordering. However, despite this progress, interphrase reordering (especially long distance ones) still poses a great challenge to statistical machine translation (SMT). The basic phrase reordering model is a simple unlexicalized, context-insensitive distortion penalty model (Koehn et al., 2003). This model assumes little or no structural divergence between language pairs, preferring the original, translated or"
P07-1090,P06-1090,0,0.335556,"the 45th Annual Meeting of the Association of Computational Linguistics, pages 712–719, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics model, but is otherwise impoverished without any lexical evidence to characterize the reordering. To address this, lexicalized context-sensitive models incorporate contextual evidence. The local prediction model (Tillmann and Zhang, 2005) models structural divergence as the relative position between the translation of two neighboring phrases. Other further generalizations of orientation include the global prediction model (Nagata et al., 2006) and distortion model (Al-Onaizan and Papineni, 2006). However, these models are often fully lexicalized and sensitive to individual phrases. As a result, they are not robust to unseen phrases. A careful approximation is vital to avoid data sparseness. Proposals to alleviate this problem include utilizing bilingual phrase cluster or words at the phrase boundary (Nagata et al., 2006) as the phrase identity. The benefit of introducing lexical evidence without being fully lexicalized has been demonstrated by a recent state-of-the-art formally syntax-based model1 , Hiero (Chiang, 2005). Hiero perf"
P07-1090,J93-2003,0,0.00931495,"ge. Instead of using syntactic knowledge to determine function words, we approximate this by equating the most frequent words as function words. By explicitly modeling phrase ordering around these frequent words, we aim to capture the most important and prevalent ordering productions. 2 Related Work A good translation should be both faithful with adequate lexical choice to the source language and fluent in its word ordering to the target language. In pursuit of better translation, phrase-based models (Och and Ney, 2004) have significantly improved the quality over classical word-based models (Brown et al., 1993). These multiword phrasal units contribute to fluency by inherently capturing intra-phrase reordering. However, despite this progress, interphrase reordering (especially long distance ones) still poses a great challenge to statistical machine translation (SMT). The basic phrase reordering model is a simple unlexicalized, context-insensitive distortion penalty model (Koehn et al., 2003). This model assumes little or no structural divergence between language pairs, preferring the original, translated order by penalizing reordering. This simple model works well when properly coupled with a well-t"
P07-1090,N03-1017,0,0.139444,"Missing"
P07-1090,P03-1019,0,0.0261056,"ed. Step 2 reorders phrases according to knowledge embedded in function words. A new indexed symbol is introduced to indicate previously reordered phrases for conciseness. Step 3 finally maps Chinese phrases to their English translation. 4 The FWS Model We first discuss the extension of standard ITG to accommodate gapping and then detail the statistical components of the model later. 4.1 Single Gap ITG (SG-ITG) The FWS model employs a synchronous grammar to describe the admissible orderings. The utility of ITG as a reordering constraint for most language pairs, is well-known both empirically (Zens and Ney, 2003) and analytically (Wu, 1997), however ITG’s straight (monotone) and inverted (reverse) rules exhibit strong cohesiveness, which is inadequate to express orientations that require gaps. We propose SG-ITG that follows Wellington et al. (2006)’s suggestion to model at most one gap. We show the rules for SG-ITG below. Rules 13 are identical to those defined in standard ITG, in which monotone and reverse orderings are represented by square and angle brackets, respectively. Rank 1 2 3 4 5 6 7 8 9 10 21 37 - Word d d d d d d dd dd d d d d U unigram 0.0580 0.0507 0.0550 0.0155 0.0153 0.0138 0.0123 0.0"
P07-1090,P06-1098,0,0.0231154,"words at the phrase boundary (Nagata et al., 2006) as the phrase identity. The benefit of introducing lexical evidence without being fully lexicalized has been demonstrated by a recent state-of-the-art formally syntax-based model1 , Hiero (Chiang, 2005). Hiero performs phrase ordering by using linked non-terminal symbols in its synchronous CFG production rules coupled with lexical evidence. However, since it is difficult to specify a well-defined rule, Hiero has to rely on weak heuristics (i.e., length-based thresholds) to extract rules. As a result, Hiero produces grammars of enormous size. Watanabe et al. (2006) further reduces the grammar’s size by enforcing all rules to comply with Greibach Normal Form. Taking the lexicalization an intuitive a step forward, we propose a novel, finer-grained solution which models the content and context information encoded by function words - approximated by high frequency words. Inspired by the success of syntaxbased approaches, we propose a synchronous grammar that accommodates gapping production rules, while focusing on the statistical modeling in relation to function words. We refer to our approach as the Function Word-centered Syntax-based approach (FWS). Our F"
P07-1090,P06-2013,0,0.0611208,"Missing"
P07-1090,P06-1067,0,0.0305046,"of Computational Linguistics, pages 712–719, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics model, but is otherwise impoverished without any lexical evidence to characterize the reordering. To address this, lexicalized context-sensitive models incorporate contextual evidence. The local prediction model (Tillmann and Zhang, 2005) models structural divergence as the relative position between the translation of two neighboring phrases. Other further generalizations of orientation include the global prediction model (Nagata et al., 2006) and distortion model (Al-Onaizan and Papineni, 2006). However, these models are often fully lexicalized and sensitive to individual phrases. As a result, they are not robust to unseen phrases. A careful approximation is vital to avoid data sparseness. Proposals to alleviate this problem include utilizing bilingual phrase cluster or words at the phrase boundary (Nagata et al., 2006) as the phrase identity. The benefit of introducing lexical evidence without being fully lexicalized has been demonstrated by a recent state-of-the-art formally syntax-based model1 , Hiero (Chiang, 2005). Hiero performs phrase ordering by using linked non-terminal sym"
P07-1090,2004.tmi-1.9,0,0.109466,"Missing"
P07-1090,P06-1123,0,\N,Missing
P08-1064,2007.mtsummit-papers.8,0,0.196123,"rase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is designed to combine the strengths of phrase-based and syntax-based methods. The proposed mod"
P08-1064,P05-1067,0,0.429194,"od statistically significantly outperforms the baseline systems. 1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is designed to combine th"
P08-1064,P03-2041,0,0.821253,"that our method statistically significantly outperforms the baseline systems. 1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is"
P08-1064,N04-1035,0,0.617925,"Missing"
P08-1064,P06-1121,0,0.542205,"ive to syntactic structures by adding a constituent feature (Chiang, 2005). In the last two years, many research efforts were devoted to integrating the strengths of phrasebased and syntax-based methods. In the following, we review four representatives of them. 1) Hassan et al. (2007) integrate supertags (a kind of lexicalized syntactic description) into the target side of translation model and language mod560 el under the phrase-based translation framework, resulting in good performance improvement. However, neither source side syntactic knowledge nor reordering model is further explored. 2) Galley et al. (2006) handle non-syntactic phrasal translations by traversing the tree upwards until a node that subsumes the phrase is reached. This solution requires larger applicability contexts (Marcu et al., 2006). However, phrases are utilized independently in the phrase-based method without depending on any contexts. 3) Addressing the issues in Galley et al. (2006), Marcu et al. (2006) create an xRS rule headed by a pseudo, non-syntactic non-terminal symbol that subsumes the phrase and its corresponding multiheaded syntactic structure; and one sibling xRS rule that explains how the pseudo symbol can be comb"
P08-1064,N04-1014,0,0.102142,"Missing"
P08-1064,2003.mtsummit-papers.22,0,0.0978139,"Missing"
P08-1064,N03-1017,0,0.108044,"igned tree sequence pairs with mapping probabilities from word-aligned biparsed parallel texts. Compared with previous models, it not only captures non-syntactic phrases and discontinuous phrases with linguistically structured features, but also supports multi-level structure reordering of tree typology with larger span. This gives our model stronger expressive power than other reported models. Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems. 1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al."
P08-1064,koen-2004-pharaoh,0,0.260163,"he proposed model works. First, the source sentence is parsed into a source parse tree. Next, the source parse tree is detached into two source tree sequences (the left hand side of rules in Fig. 3). Then the two rules in Fig. 3 are used to map the two source tree sequences to two target tree sequences, which are then combined to generate a target parse tree. Finally, a target translation is yielded from the target tree. Our model is implemented under log-linear framework (Och and Ney, 2002). We use seven basic features that are analogous to the commonly used features in phrase-based systems (Koehn, 2004): 1) bidirectional rule mapping probabilities; 2) bidirectional lexical rule translation probabilities; 3) the target language model; 4) the number of rules used and 5) the number of target words. In addition, we define two new features: 1) the number of lexical words in a rule to control the model’s preference for lexicalized rules over un-lexicalized 562 rules and 2) the average tree depth in a rule to balance the usage of hierarchical rules and flat rules. Note that we do not distinguish between larger (taller) and shorter source side tree sequences, i.e. we let these rules compete directly"
P08-1064,P06-1077,0,0.798378,"al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is designed to combine the strengths of phrase-based and syntax-based methods. The proposed model adopts tree sequence 1 as the basic tran"
P08-1064,P07-1089,0,0.865288,"d Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is designed to combine the strengths of phrase-based and syntax-based methods. The proposed model adopts tree sequence 1 as the basic translation unit and u"
P08-1064,W06-1606,0,0.778456,"hods. In the following, we review four representatives of them. 1) Hassan et al. (2007) integrate supertags (a kind of lexicalized syntactic description) into the target side of translation model and language mod560 el under the phrase-based translation framework, resulting in good performance improvement. However, neither source side syntactic knowledge nor reordering model is further explored. 2) Galley et al. (2006) handle non-syntactic phrasal translations by traversing the tree upwards until a node that subsumes the phrase is reached. This solution requires larger applicability contexts (Marcu et al., 2006). However, phrases are utilized independently in the phrase-based method without depending on any contexts. 3) Addressing the issues in Galley et al. (2006), Marcu et al. (2006) create an xRS rule headed by a pseudo, non-syntactic non-terminal symbol that subsumes the phrase and its corresponding multiheaded syntactic structure; and one sibling xRS rule that explains how the pseudo symbol can be combined with other genuine non-terminals for acquiring the genuine parse trees. The name of the pseudo non-terminal is designed to reflect the full realization of the corresponding rule. The problem i"
P08-1064,P04-1083,0,0.0266683,"Missing"
P08-1064,P02-1038,0,0.183089,"Missing"
P08-1064,P03-1021,0,0.0106146,"s (181M words) using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing. We used sentences with less than 50 characters from the NIST MT-2002 test set as our development set and the NIST MT2005 test set as our test set. We used the Stanford parser (Klein and Manning, 2003) to parse bilingual sentences on the training set and Chinese sentences on the development and test sets. The evaluation metric is case-sensitive BLEU-4 (Papineni et al., 2002). We used GIZA++ (Och and Ney, 2004) and the heuristics “grow-diag-final” to generate m-to-n word alignments. For the MER training (Och, 2003), we modified Koehn’s MER trainer (Koehn, 2004) for our tree sequence-based system. For significance test, we used Zhang et al’s implementation (Zhang et al, 2004). We set three baseline systems: Moses (Koehn et al., 2007), and SCFG-based and STSG-based treeto-tree translation models (Zhang et al., 2007). For Moses, we used its default settings. For the SCFG/STSG and our proposed model, we used the same settings except for the parameters d and h ( d = 1 and h = 2 for the SCFG; d = 1 and h = 6 for the STSG; d = 4 and h = 6 for our model). We optimized these parameters on the training and develo"
P08-1064,J04-4002,0,0.538035,"pairs with mapping probabilities from word-aligned biparsed parallel texts. Compared with previous models, it not only captures non-syntactic phrases and discontinuous phrases with linguistically structured features, but also supports multi-level structure reordering of tree typology with larger span. This gives our model stronger expressive power than other reported models. Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems. 1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al.,"
P08-1064,P02-1040,0,0.104502,"trained the translation model on the FBIS corpus (7.2M+9.2M words) and trained a 4gram language model on the Xinhua portion of the English Gigaword corpus (181M words) using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing. We used sentences with less than 50 characters from the NIST MT-2002 test set as our development set and the NIST MT2005 test set as our test set. We used the Stanford parser (Klein and Manning, 2003) to parse bilingual sentences on the training set and Chinese sentences on the development and test sets. The evaluation metric is case-sensitive BLEU-4 (Papineni et al., 2002). We used GIZA++ (Och and Ney, 2004) and the heuristics “grow-diag-final” to generate m-to-n word alignments. For the MER training (Och, 2003), we modified Koehn’s MER trainer (Koehn, 2004) for our tree sequence-based system. For significance test, we used Zhang et al’s implementation (Zhang et al, 2004). We set three baseline systems: Moses (Koehn et al., 2007), and SCFG-based and STSG-based treeto-tree translation models (Zhang et al., 2007). For Moses, we used its default settings. For the SCFG/STSG and our proposed model, we used the same settings except for the parameters d and h ( d = 1"
P08-1064,P05-1034,0,0.739531,"icantly outperforms the baseline systems. 1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is designed to combine the strengths of phra"
P08-1064,P07-1090,1,0.843636,"07b) present a STSG-based tree-to-tree translation model. Bod (2007) reports that the unsupervised STSG-based translation model performs much better than the supervised one. The motivation behind all these work is to exploit linguistically syntactic structure features to model the translation process. However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods (Koehn et al., 2003). The formally syntax-based model for SMT was first advocated by Wu (1997). Xiong et al. (2006) propose a MaxEnt-based reordering model for BTG (Wu, 1997) while Setiawan et al. (2007) propose a function word-based reordering model for BTG. Chiang (2005)’s hierarchal phrase-based model achieves significant performance improvement. However, no further significant improvement is achieved when the model is made sensitive to syntactic structures by adding a constituent feature (Chiang, 2005). In the last two years, many research efforts were devoted to integrating the strengths of phrasebased and syntax-based methods. In the following, we review four representatives of them. 1) Hassan et al. (2007) integrate supertags (a kind of lexicalized syntactic description) into the targe"
P08-1064,J97-3002,0,0.763933,"sh translation task show that our method statistically significantly outperforms the baseline systems. 1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tr"
P08-1064,P01-1067,0,0.813115,"modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well. However, it cannot handle long-distance reorderings properly and does not exploit discontinuous phrases and linguistically syntactic structure features (Quirk and Menezes, 2006). Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 3 National University of Singapore tancl@comp.nus.edu.sg 2003). Although good progress has been reported, the fundamental issues in applying linguistic syntax to SMT, such as non-isomorphic tree alignment, structure reordering and non-syntactic phrase modeling, are still worth well studying. In this paper, we propose a tree-to-tree translation model that is based on tree sequence alignment. It is designed to combine the strengths of phrase-based and syntax-based methods. The proposed model adopts tree sequence 1"
P08-1064,zhang-etal-2004-interpreting,0,0.20435,"Missing"
P08-1064,2006.amta-papers.8,0,\N,Missing
P08-1064,C00-2092,0,\N,Missing
P08-1064,P03-1054,0,\N,Missing
P08-1064,P06-1123,0,\N,Missing
P08-1064,P06-1066,0,\N,Missing
P08-1064,P03-1011,0,\N,Missing
P08-1064,P07-2045,0,\N,Missing
P08-1064,N06-1032,0,\N,Missing
P08-1064,W06-1628,0,\N,Missing
P08-1064,J08-3004,0,\N,Missing
P08-2038,P03-1021,0,0.0408658,"Missing"
P08-2038,D07-1077,0,0.060863,"ng Transduction Grammar (BTG) proposed by (Wu, 1997) has been widely used in statistical machine translation (SMT). However, the original BTG does not provide an effective mechanism to predict the most appropriate orders between two neighboring phrases. To address this problem, Xiong et al. (2006) enhance the BTG with a maximum entropy (MaxEnt) based reordering model which uses boundary words of bilingual phrases as features. Although this model outperforms previous unlexicalized models, it does not utilize any linguistically syntactic features, which have proven useful for phrase reordering (Wang et al., 2007). Zhang et al. (2007) integrates source-side syntactic knowledge into a phrase reordering model based on BTG-style rules. However, one limitation of this method is that it only reorders syntactic phrases because linguistic knowledge from parse trees is only carried by syntactic phrases as far as reordering is concerned, while non-syntactic phrases are combined monotonously with a flat reordering score. In this paper, we propose a linguistically annotated reordering model for BTG-based SMT, which is a significant extension to the work mentioned above. The new model annotates each BTG node with"
P08-2038,J97-3002,0,0.403967,"Missing"
P08-2038,I05-1007,1,0.90995,"Missing"
P08-2038,P06-1066,1,0.929388,"nclude in Section 5. 2 Baseline SMT System The baseline system is a phrase-based system which uses the BTG lexical rules (A → x/y) to translate source phrase x into target phrase y and the BTG merging rules (A → [A, A]|hA, Ai) to combine two neighboring phrases with a straight or inverted order. The BTG lexical rules are weighted with several features, such as phrase translation, word penalty and language models, in a log-linear form. For the merging rules, a MaxEnt-based reordering model using boundary words of neighboring phrases as features is used to predict the merging order, similar to (Xiong et al., 2006). We call this reordering model 149 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 149–152, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics boundary words based reordering model (BWR). In this paper, we propose to incorporate a linguistically annotated reordering model into the log-linear translation model, so as to strengthen the BWR’s phrase reordering ability. We train all the model scaling factors on the development set to maximize the BLEU score. A CKY-style decoder is developed to generate the best BTG binary tree for each input senten"
P08-2038,D07-1056,0,0.0632565,"posed by (Wu, 1997) has been widely used in statistical machine translation (SMT). However, the original BTG does not provide an effective mechanism to predict the most appropriate orders between two neighboring phrases. To address this problem, Xiong et al. (2006) enhance the BTG with a maximum entropy (MaxEnt) based reordering model which uses boundary words of bilingual phrases as features. Although this model outperforms previous unlexicalized models, it does not utilize any linguistically syntactic features, which have proven useful for phrase reordering (Wang et al., 2007). Zhang et al. (2007) integrates source-side syntactic knowledge into a phrase reordering model based on BTG-style rules. However, one limitation of this method is that it only reorders syntactic phrases because linguistic knowledge from parse trees is only carried by syntactic phrases as far as reordering is concerned, while non-syntactic phrases are combined monotonously with a flat reordering score. In this paper, we propose a linguistically annotated reordering model for BTG-based SMT, which is a significant extension to the work mentioned above. The new model annotates each BTG node with linguistic knowledge"
P08-2040,P07-2045,0,0.0115781,"ta again showed translation performance improvement and demonstrated that the translation model can be reinforced from N-best hypotheses. In this paper, we further exploit the potential of the N-best hypotheses and propose several schemes to derive the posterior knowledge from the N-best hypotheses, in an effort to enhance the language model, translation model, and source word reordering under a re-decoding framework of any phrase-based SMT system. 2 Self-Enhancement Knowledge with Posterior The self-enhancement system structure is shown in Figure 1. Our baseline system is set up using Moses (Koehn et al., 2007), a state-of-the-art phrase-base SMT open source package. In the followings, we detail the approaches to exploiting the three different kinds of posterior knowledge, namely, language model, translation model and word reordering. 157 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 157–160, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics 4. Repeat step 1-3 for a fixed number of iterations. 2.2 Figure 1: Self-enhancement system structure, where TM is translation model, LM is language model, and RM is reordering model. 2.1 Language Model We consi"
P08-2040,P07-1091,0,0.0782534,"hence improve the translation model. The procedure for translation model selfenhancement can be summarized as follows. 1. Run decoding and extract N-best hypotheses. 2. Extract “good phrase-pairs” according to the hypotheses’ phrase-alignment information and append them to the original phrase table to generate a new phrase table. 3. Score the new phrase table to create a new translation model. 4. Optimize the weights of the decoder with the above new translation model. 5. Repeat step 1-4 for a fixed number of iterations. 2.3 Word Reordering Some previous work (Costa-jussà and Fonollosa, 2006; Li et al., 2007) have shown that reordering a source sentence to match the word order in its corresponding target sentence can produce better translations for a phrase-based SMT system. We bring this idea forward to our word reordering selfenhancement framework, which similarly translates a source sentence (S) to target sentence (T) in two stages: S → S ′ → T , where S ′ is the reordered source sentence. The phrase-alignment information in each hypothesis indicates the word reordering for source sentence. We select the word reordering with the highest posterior probability as the best word reordering for a gi"
P08-2040,C02-1164,0,0.139094,"approaches to exploiting the three different kinds of posterior knowledge, namely, language model, translation model and word reordering. 157 Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 157–160, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics 4. Repeat step 1-3 for a fixed number of iterations. 2.2 Figure 1: Self-enhancement system structure, where TM is translation model, LM is language model, and RM is reordering model. 2.1 Language Model We consider self-enhancement of language model as a language model adaptation problem similar to (Nakajima et al., 2002). The original monolingual target training data is regarded as general-domain data while the test data as a domain-specific data. Obviously, the real domain-specific target data (test data) is unavailable for training. In this work, the N-best hypotheses of the test set are used as a quasi-corpus to train a language model. This new language model trained on the quasi-corpus is then used together with the language model trained on the general-domain data (original training data) to produce a new list of N-best hypotheses under our self-enhancement framework. The feature function of the language"
P08-2040,P02-1040,0,0.0731461,"Missing"
P08-2040,2006.iwslt-papers.3,0,0.553265,"erence between the two models. Nakajima et al. used only 1-best hypothesis, while we use N-best hypotheses of test set as the quasicorpus to train the language model. In the work of (Costa-jussà and Fonollosa, 2006; Li et al., 2007) which similarly translates a source sentence (S) to target sentence (T) in two stages: S → S ′ → T , they derive S ′ from training data; while we obtain S ′ based on the occurrence frequency, i.e. posterior probability of each source word reordering in the N-best hypotheses list. An alternative solution for enhancing the translation model is through self-training (Ueffing, 2006; Ueffing et al., 2007) which re-trains the source-target N-best hypotheses together with the original training data, and thus differs from ours in the way of new phrase pairs extraction. We only supplement those phrase-pairs appeared in the Nbest hypotheses to the original phrase table. Further experiment showed that improvement obtained by self-training method is not as consistent on both development and test sets as that by our method. One possible reason is that in self-training, the entire translation model is adjusted with the addition of new phrase-pairs extracted from the source-target"
P08-2040,2003.mtsummit-papers.52,0,0.0248546,"he MT system as the first decoding has discarded many undesirable translation candidates. Thus, the knowledge captured in the N-best hypotheses, such as posterior probabilities for words, n-grams, phrase-pairs, and source word reorderings, etc. is more compatible with the source sentences and thus could potentially be used to improve the translation performance. Word posterior probabilities estimated from the N-best hypotheses have been widely used for confidence measure in automatic speech recognition (Wessel, 2002) and have also been adopted into machine translation. Blatz et al. (2003) and Ueffing et al. (2003) used word posterior probabilities to estimate the confidence of machine translation. Chen et al. (2005), Zens and Ney (2006) reported performance improvements by computing target ngrams posterior probabilities estimated on the Nbest hypotheses in a rescoring framework. Transductive learning method (Ueffing et al., 2007) which repeatedly re-trains the generated sourcetarget N-best hypotheses with the original training data again showed translation performance improvement and demonstrated that the translation model can be reinforced from N-best hypotheses. In this paper, we further exploit the"
P08-2040,P07-1004,0,0.750203,"ed to improve the translation performance. Word posterior probabilities estimated from the N-best hypotheses have been widely used for confidence measure in automatic speech recognition (Wessel, 2002) and have also been adopted into machine translation. Blatz et al. (2003) and Ueffing et al. (2003) used word posterior probabilities to estimate the confidence of machine translation. Chen et al. (2005), Zens and Ney (2006) reported performance improvements by computing target ngrams posterior probabilities estimated on the Nbest hypotheses in a rescoring framework. Transductive learning method (Ueffing et al., 2007) which repeatedly re-trains the generated sourcetarget N-best hypotheses with the original training data again showed translation performance improvement and demonstrated that the translation model can be reinforced from N-best hypotheses. In this paper, we further exploit the potential of the N-best hypotheses and propose several schemes to derive the posterior knowledge from the N-best hypotheses, in an effort to enhance the language model, translation model, and source word reordering under a re-decoding framework of any phrase-based SMT system. 2 Self-Enhancement Knowledge with Posterior T"
P08-2040,W06-3110,0,0.0123789,"-best hypotheses, such as posterior probabilities for words, n-grams, phrase-pairs, and source word reorderings, etc. is more compatible with the source sentences and thus could potentially be used to improve the translation performance. Word posterior probabilities estimated from the N-best hypotheses have been widely used for confidence measure in automatic speech recognition (Wessel, 2002) and have also been adopted into machine translation. Blatz et al. (2003) and Ueffing et al. (2003) used word posterior probabilities to estimate the confidence of machine translation. Chen et al. (2005), Zens and Ney (2006) reported performance improvements by computing target ngrams posterior probabilities estimated on the Nbest hypotheses in a rescoring framework. Transductive learning method (Ueffing et al., 2007) which repeatedly re-trains the generated sourcetarget N-best hypotheses with the original training data again showed translation performance improvement and demonstrated that the translation model can be reinforced from N-best hypotheses. In this paper, we further exploit the potential of the N-best hypotheses and propose several schemes to derive the posterior knowledge from the N-best hypotheses,"
P08-2040,C04-1046,0,\N,Missing
P08-2040,W06-1609,0,\N,Missing
P08-2040,2005.iwslt-1.11,1,\N,Missing
P09-1016,P07-1016,1,0.949704,"performed via the Expectation-Maximization (EM) by starting with a random initial alignment and calculating the affinity matrix count(ei , cj ) over the whole parallel corpus, where element (i, j) is the number of times character ei was aligned to cj . From the affinity matrix conditional probabilities P (ei |cj ) can be estimated as X P (ei |cj ) = count(ei , cj )/ count(ei , cj ) (3) Figure 2 shows the correspondence between the graphemes and phonemes of English word “Alice” and its Chinese transliteration, with CMU phoneme set used for English (Chase, 1997) and IIR phoneme set for Chinese (Li et al., 2007a). A Chinese character is often mapped to a unique sequence of Chinese phonemes. Therefore, if we align English characters {ei } and Chinese phonemes {cpk } (cpk ∈ CP set of Chinese phonemes) well, we almost succeed in aligning English and Chinese grapheme tokens. Alignment between {ei } and {cpk } becomes the main task in this paper. j Alignment j = θ(i) between {ei } and {cj } that maximizes probability Y P = P (cθ(i) |ei ) (4) 3.2.1 Phoneme affinity alignment Let the phonetic transcription of English word {ei } be {epn }, epn ∈ EP , where EP is the set of English phonemes. Alignment betwee"
P09-1016,C04-1086,0,0.0135524,"night and Graehl (1998) described a transliteration approach that transfers the grapheme representation of a word via the phonetic representation, which is known as phonemebased transliteration technique (Virga and Khudanpur, 2003; Meng et al., 2001; Jung et al., 2000; Gao et al., 2004). Another technique is to directly transfer the grapheme, known as direct orthographic mapping, that was shown to be simple and effective (Li et al., 2004). Some other approaches that use both source graphemes and phonemes were also reported with good performance (Oh and Choi, 2002; Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004). To align a bilingual training corpus, some take a phonological approach, in which the crafted mapping rules encode the prior linguistic knowledge about the source and target languages directly into the system (Wan and Verspoor, 1998; Meng et al., 2001; Jiang et al., 2007; Xu et al., 2006). Others adopt a statistical approach, in which the affinity between phonemes or graphemes is learned from the corpus (Gao et al., 2004; AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003). In the phoneme-based technique where an intermediate level of phonetic representation is used as the pivot, alignm"
P09-1016,W03-0301,0,0.0240919,"ration validation, which studies the ways to validate transliteration pairs. For example Knight and Graehl 136 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 136–144, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP 2 Related Work the gold standard, or the ground truth alignment G, which is a manual alignment of the corpus or a part of it. Three evaluation metrics are used: precision, recall, and F -score, the latter being a function of the former two. They indicate how close the alignment under investigation is to the gold standard alignment (Mihalcea and Pedersen, 2003). Denoting the number of cross-lingual mappings that are common in both A and G as CAG , the number of cross-lingual mappings in A as CA and the number of cross-lingual mappings in G as CG , precision P r is given as CAG /CA , recall Rc as CAG /CG and F -score as 2P r · Rc/(P r + Rc). Note that these metrics hinge on the availability of the gold standard, which is often not available. In this paper we propose a novel evaluation metric for transliteration alignment grounded on the information theory. One important property of this metric is that it does not require a gold standard alignment as"
P09-1016,P06-2025,0,0.0508437,"eration by maximizing the joint probability of the source and target names P ({ei }, {cj }), where the source and target names are sequences of English and Chinese grapheme tokens. The joint probability is expressed as a chain product of a series of conditional probabilities of token pairs P ({ei }, {cj }) = P ((¯ ek , ck )|(¯ ek−1 , ck−1 )), k = 1 . . . N , where we limit the history to one preceding pair, resulting in a bigram model. The conditional probabilities for token pairs are estimated from the aligned training corpus. We use this model because it was shown to be simple yet accurate (Ekbal et al., 2006; Li et al., 2007b). We train a model for each of the 114 phonological alignments and the 80 affinity alignments in Section 5.1 and conduct transliteration experiment on the Xinhua test data. During transliteration, an input English name is first decoded into a lattice of all possible English and Chinese grapheme token pairs. Then the joint source-channel transliteration model is used to score the lattice to obtain a ranked list of m most likely Chinese transliterations (m-best list). We also report the MRR and F -scores for each alignment in Figures 6b and 7b, from which we observe that align"
P09-1016,C00-1056,0,0.0169421,"ment as a reference. We will also show that how this metric is used in generative transliteration modeling and transliteration validation. A number of transliteration studies have touched on the alignment issue as a part of the transliteration modeling process, where alignment is needed at levels of graphemes and phonemes. In their seminal paper Knight and Graehl (1998) described a transliteration approach that transfers the grapheme representation of a word via the phonetic representation, which is known as phonemebased transliteration technique (Virga and Khudanpur, 2003; Meng et al., 2001; Jung et al., 2000; Gao et al., 2004). Another technique is to directly transfer the grapheme, known as direct orthographic mapping, that was shown to be simple and effective (Li et al., 2004). Some other approaches that use both source graphemes and phonemes were also reported with good performance (Oh and Choi, 2002; Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004). To align a bilingual training corpus, some take a phonological approach, in which the crafted mapping rules encode the prior linguistic knowledge about the source and target languages directly into the system (Wan and Verspoor, 1998; Meng et a"
P09-1016,P04-1024,0,0.0564101,"Missing"
P09-1016,W06-1630,0,0.0163886,"ic representations of source and target words can also be achieved using the linguistic knowledge of phonetic similarity. Oh and Choi (2002) define classes of 138 phonemes and assign various distances between phonemes of different classes. In contrast, we make use of phonological descriptors to define the similarity between phonemes in this paper. Perhaps the most common way to measure the phonetic similarity is to compute the distances between phoneme features (Kessler, 2005). Such features have been introduced in many ways, such as perceptual attributes or articulatory attributes. Recently, Tao et al. (2006) and Yoon et al. (2007) have studied the use of phonological features and manually assigned phonological distance to measure the similarity of transliterated words for extracting transliterations from a comparable corpus. We adopt the binary-valued articulatory attributes as the phonological descriptors, which are used to describe the CMU and IIR phoneme sets for English and Chinese Mandarin respectively. Withgott and Chen (1993) define a feature vector of phonological descriptors for English sounds. We extend the idea by defining a 21-element binary feature vector for each English and Chinese"
P09-1016,W03-1508,0,0.128658,"that it does not require a gold standard alignment as a reference. We will also show that how this metric is used in generative transliteration modeling and transliteration validation. A number of transliteration studies have touched on the alignment issue as a part of the transliteration modeling process, where alignment is needed at levels of graphemes and phonemes. In their seminal paper Knight and Graehl (1998) described a transliteration approach that transfers the grapheme representation of a word via the phonetic representation, which is known as phonemebased transliteration technique (Virga and Khudanpur, 2003; Meng et al., 2001; Jung et al., 2000; Gao et al., 2004). Another technique is to directly transfer the grapheme, known as direct orthographic mapping, that was shown to be simple and effective (Li et al., 2004). Some other approaches that use both source graphemes and phonemes were also reported with good performance (Oh and Choi, 2002; Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004). To align a bilingual training corpus, some take a phonological approach, in which the crafted mapping rules encode the prior linguistic knowledge about the source and target languages directly into the sys"
P09-1016,P98-2220,0,0.218879,"g et al., 2001; Jung et al., 2000; Gao et al., 2004). Another technique is to directly transfer the grapheme, known as direct orthographic mapping, that was shown to be simple and effective (Li et al., 2004). Some other approaches that use both source graphemes and phonemes were also reported with good performance (Oh and Choi, 2002; Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004). To align a bilingual training corpus, some take a phonological approach, in which the crafted mapping rules encode the prior linguistic knowledge about the source and target languages directly into the system (Wan and Verspoor, 1998; Meng et al., 2001; Jiang et al., 2007; Xu et al., 2006). Others adopt a statistical approach, in which the affinity between phonemes or graphemes is learned from the corpus (Gao et al., 2004; AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003). In the phoneme-based technique where an intermediate level of phonetic representation is used as the pivot, alignment between graphemes and phonemes of the source and target words is needed (Oh and Choi, 2005). If source and target languages have different phoneme sets, alignment between the the different phonemes is also required (Knight and Gra"
P09-1016,W06-1629,0,0.0143546,"echnique is to directly transfer the grapheme, known as direct orthographic mapping, that was shown to be simple and effective (Li et al., 2004). Some other approaches that use both source graphemes and phonemes were also reported with good performance (Oh and Choi, 2002; Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004). To align a bilingual training corpus, some take a phonological approach, in which the crafted mapping rules encode the prior linguistic knowledge about the source and target languages directly into the system (Wan and Verspoor, 1998; Meng et al., 2001; Jiang et al., 2007; Xu et al., 2006). Others adopt a statistical approach, in which the affinity between phonemes or graphemes is learned from the corpus (Gao et al., 2004; AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003). In the phoneme-based technique where an intermediate level of phonetic representation is used as the pivot, alignment between graphemes and phonemes of the source and target words is needed (Oh and Choi, 2005). If source and target languages have different phoneme sets, alignment between the the different phonemes is also required (Knight and Graehl, 1998). Although the direct orthographic mapping appr"
P09-1016,P07-1015,0,0.0129597,"source and target words can also be achieved using the linguistic knowledge of phonetic similarity. Oh and Choi (2002) define classes of 138 phonemes and assign various distances between phonemes of different classes. In contrast, we make use of phonological descriptors to define the similarity between phonemes in this paper. Perhaps the most common way to measure the phonetic similarity is to compute the distances between phoneme features (Kessler, 2005). Such features have been introduced in many ways, such as perceptual attributes or articulatory attributes. Recently, Tao et al. (2006) and Yoon et al. (2007) have studied the use of phonological features and manually assigned phonological distance to measure the similarity of transliterated words for extracting transliterations from a comparable corpus. We adopt the binary-valued articulatory attributes as the phonological descriptors, which are used to describe the CMU and IIR phoneme sets for English and Chinese Mandarin respectively. Withgott and Chen (1993) define a feature vector of phonological descriptors for English sounds. We extend the idea by defining a 21-element binary feature vector for each English and Chinese phoneme. Each element"
P09-1016,P04-1021,1,0.917627,"have touched on the alignment issue as a part of the transliteration modeling process, where alignment is needed at levels of graphemes and phonemes. In their seminal paper Knight and Graehl (1998) described a transliteration approach that transfers the grapheme representation of a word via the phonetic representation, which is known as phonemebased transliteration technique (Virga and Khudanpur, 2003; Meng et al., 2001; Jung et al., 2000; Gao et al., 2004). Another technique is to directly transfer the grapheme, known as direct orthographic mapping, that was shown to be simple and effective (Li et al., 2004). Some other approaches that use both source graphemes and phonemes were also reported with good performance (Oh and Choi, 2002; Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004). To align a bilingual training corpus, some take a phonological approach, in which the crafted mapping rules encode the prior linguistic knowledge about the source and target languages directly into the system (Wan and Verspoor, 1998; Meng et al., 2001; Jiang et al., 2007; Xu et al., 2006). Others adopt a statistical approach, in which the affinity between phonemes or graphemes is learned from the corpus (Gao et al"
P09-1016,C02-1099,0,\N,Missing
P09-1016,W02-0505,0,\N,Missing
P09-1016,P97-1017,0,\N,Missing
P09-1020,P03-2041,0,0.260919,"work while section 3 defines our translation model. In section 4 and section 5, the key rule extraction and decoding algorithms are elaborated. Experimental results are reported in section 6 and the paper is concluded in section 7. 2 Related work As discussed in section 1, two of the major challenges to syntax-based SMT are structure divergence and parse errors. Many techniques have been proposed to address the structure divergence issue while only fewer studies are reported in addressing the parse errors in the SMT research community. To address structure divergence issue, many researchers (Eisner, 2003; Zhang et al., 2007) propose using the Synchronous Tree Substitution Grammar (STSG) grammar in syntax-based SMT since the STSG uses larger tree fragment as translation unit. Although promising results have been reported, STSG only uses one single subtree as translation unit which is still committed to the syntax strictly. Motivated by the fact that non-syntactic phrases make non-trivial contribution to phrase-based SMT, the tree sequencebased translation model is proposed (Liu et al., 2007; Zhang et al., 2008a) that uses tree sequence as the basic translation unit, rather than using single su"
P09-1020,N04-1035,0,0.445227,"as translation input, where a forest is a compact representation of exponentially number of n-best parse trees. Mi and Huang (2008) propose a forest-based rule extraction algorithm, which learn tree to string rules from source forest and target string. By using forest in rule extraction and decoding, their methods are able to well address the parse error issue. From the above discussion, we can see that traditional tree sequence-based method uses single tree as translation input while the forestbased model uses single sub-tree as the basic translation unit that can only learn tree-to-string (Galley et al. 2004; Liu et al., 2006) rules. Therefore, the two methods display different strengths, and which would be complementary to each other. To integrate their strengths, in this paper, we propose a forest-based tree sequence to string translation model. 3 Forest-based tree sequence to string model In this section, we first explain what a packed forest is and then define the concept of the tree sequence in the context of forest followed by the discussion on our proposed model. 3.1 Packed Forest A packed forest (forest in short) is a special kind of hyper-graph (Klein and Manning, 2001; Huang and Chiang,"
P09-1020,P08-1067,0,0.479802,"ms. 1 Introduction Recently syntax-based statistical machine translation (SMT) methods have achieved very promising results and attracted more and more interests in the SMT research community. Fundamentally, syntax-based SMT views translation as a structural transformation process. Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT (Zhang et al., 2008a; Mi et al., 2008). Many solutions have been proposed to address the above two issues. Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported. Forest-based modeling aims to improve translation accuracy through digging the potential better parses from n-bests (i.e. forest) while tree sequence-based modeling aims to model non-syntactic translations with structured syntactic knowledge. In nature, the two methods would be complementary to each other since they manage to solve the negative impacts of monolingual parse errors and cross-lingual structure divergence on translation results from differ"
P09-1020,P07-1019,0,0.172606,"vel process in a small span. Finally, we re-build the NSS of current span for upper level NSS combination use (line 20-22). In Fig. 8, the hyper-edge “IP=&gt;NP VV+VV NP” is an auxiliary hyper-edge introduced by Algorithm 2. By Algorithm 2, we convert the translation forest into a complete translation forest. We then use a bottom-up node-based search 4 The concept of translation forest is proposed in Mi et al. (2008). It is a forest that consists of only the hyperedges induced from translation rules. algorithm to do decoding on the complete translation forest. We also use Cube Pruning algorithm (Huang and Chiang 2007) to speed up the translation process. Figure 8. Auxiliary hyper-edge in a translation forest Algorithm 2. add auxiliary hyper-edges into mt forest F Input: mt forest F Output: complete forest F with auxiliary hyper-edges 1. for i := 1 to L do 2. for each node n of span [i, i] do 3. add n into NSS(i, i) 4. for length := 1 to L - 1 do 5. for start := 1 to L - length do 6. stop := start + length 7. for pivot := start to stop-1 do 8. for each ns1 in NSS (start, pivot) do for each ns2 in NSS (pivot+1,stop) do 9. 10. create 1 2 11. if ns is not in NSS(start, stop) then 12. add ns into NSS (start, st"
P09-1020,W01-1812,0,0.155074,"y learn tree-to-string (Galley et al. 2004; Liu et al., 2006) rules. Therefore, the two methods display different strengths, and which would be complementary to each other. To integrate their strengths, in this paper, we propose a forest-based tree sequence to string translation model. 3 Forest-based tree sequence to string model In this section, we first explain what a packed forest is and then define the concept of the tree sequence in the context of forest followed by the discussion on our proposed model. 3.1 Packed Forest A packed forest (forest in short) is a special kind of hyper-graph (Klein and Manning, 2001; Huang and Chiang, 2005), which is used to represent all derivations (i.e. parse trees) for a given sentence under a context free grammar (CFG). A forest F is defined as a triple , , , where is non-terminal node set, is hyper-edge set and is leaf node set (i.e. all sentence words). A forest F satisfies the following two conditions: 1) Each node in should cover a phrase, which is a continuous word sub-sequence in . 2) Each hyper-edge in is defined as … … , , , where … … covers a sequence of contiis the father nuous and non-overlap phrases, node of the children sequence … … . The is just the su"
P09-1020,N03-1017,0,0.0217877,"Missing"
P09-1020,P07-2045,0,0.0395597,"Missing"
P09-1020,P06-1077,0,0.317991,"t, where a forest is a compact representation of exponentially number of n-best parse trees. Mi and Huang (2008) propose a forest-based rule extraction algorithm, which learn tree to string rules from source forest and target string. By using forest in rule extraction and decoding, their methods are able to well address the parse error issue. From the above discussion, we can see that traditional tree sequence-based method uses single tree as translation input while the forestbased model uses single sub-tree as the basic translation unit that can only learn tree-to-string (Galley et al. 2004; Liu et al., 2006) rules. Therefore, the two methods display different strengths, and which would be complementary to each other. To integrate their strengths, in this paper, we propose a forest-based tree sequence to string translation model. 3 Forest-based tree sequence to string model In this section, we first explain what a packed forest is and then define the concept of the tree sequence in the context of forest followed by the discussion on our proposed model. 3.1 Packed Forest A packed forest (forest in short) is a special kind of hyper-graph (Klein and Manning, 2001; Huang and Chiang, 2005), which is us"
P09-1020,P07-1089,0,0.738499,"tical machine translation (SMT) methods have achieved very promising results and attracted more and more interests in the SMT research community. Fundamentally, syntax-based SMT views translation as a structural transformation process. Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT (Zhang et al., 2008a; Mi et al., 2008). Many solutions have been proposed to address the above two issues. Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported. Forest-based modeling aims to improve translation accuracy through digging the potential better parses from n-bests (i.e. forest) while tree sequence-based modeling aims to model non-syntactic translations with structured syntactic knowledge. In nature, the two methods would be complementary to each other since they manage to solve the negative impacts of monolingual parse errors and cross-lingual structure divergence on translation results from different viewpoints. Therefore, one natural way is to co"
P09-1020,P08-1023,0,0.650639,"rimental results on the NIST MT-2003 Chinese-English translation task show that our method statistically significantly outperforms the four baseline systems. 1 Introduction Recently syntax-based statistical machine translation (SMT) methods have achieved very promising results and attracted more and more interests in the SMT research community. Fundamentally, syntax-based SMT views translation as a structural transformation process. Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT (Zhang et al., 2008a; Mi et al., 2008). Many solutions have been proposed to address the above two issues. Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported. Forest-based modeling aims to improve translation accuracy through digging the potential better parses from n-bests (i.e. forest) while tree sequence-based modeling aims to model non-syntactic translations with structured syntactic knowledge. In nature, the two methods would be complementary to each other"
P09-1020,D08-1022,0,0.756548,"e systems. 1 Introduction Recently syntax-based statistical machine translation (SMT) methods have achieved very promising results and attracted more and more interests in the SMT research community. Fundamentally, syntax-based SMT views translation as a structural transformation process. Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT (Zhang et al., 2008a; Mi et al., 2008). Many solutions have been proposed to address the above two issues. Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported. Forest-based modeling aims to improve translation accuracy through digging the potential better parses from n-bests (i.e. forest) while tree sequence-based modeling aims to model non-syntactic translations with structured syntactic knowledge. In nature, the two methods would be complementary to each other since they manage to solve the negative impacts of monolingual parse errors and cross-lingual structure divergence on translation results from differ"
P09-1020,P02-1038,0,0.0183765,"n model is formulated as: Pr , , ∑ , , , ∏ By the above Eq., translation becomes a tree sequence structure to string mapping issue. Given the F, TS and A, there are multiple derivations that could map F to TS under the constraint A. in our The mapping probability Pr , , study is obtained by summing over the probabilities of all derivations Θ. The probability of each derivation is given as the product of the probabilities of all the rules p (ri ) used in the derivation (here we assume that each rule is applied independently in a derivation). Our model is implemented under log-linear framework (Och and Ney, 2002). We use seven basic features that are analogous to the commonly used features in phrase-based systems (Koehn, 2003): 1) bidirectional rule mapping probabilities, 2) bidirectional lexical rule translation probabilities, 3) target language model, 4) number of rules used and 5) number of target words. In addition, we define two new features: 1) number of leaf nodes in auxiliary rules (the auxiliary rule will be explained later in this paper) and 2) product of the probabilities of all hyper-edges of the tree sequences in forest. 4 Training This section discusses how to extract our transla. As we"
P09-1020,P03-1021,0,0.400511,"Missing"
P09-1020,J03-1002,0,0.00270206,"Missing"
P09-1020,P02-1040,0,0.105492,"Missing"
P09-1020,zhang-etal-2004-interpreting,0,0.0526669,"Missing"
P09-1020,2006.amta-papers.8,0,\N,Missing
P09-1020,A00-2018,0,\N,Missing
P09-1020,C08-1138,1,\N,Missing
P09-1020,W05-1506,0,\N,Missing
P09-1020,P08-1064,1,\N,Missing
P09-1036,P08-1009,0,0.602914,"uent translations and reorderings. This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries. To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side. On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. These constituent matching/violation counts are used as a feature in the decoder’s log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003). In this way, syntactic constraint is integrated into decoding as a soft constraint to enable the decoder to reward hypotheses that respect syntactic analyses or to peSyntactic analysis influences the way in which the source sentence is translated. Previous efforts add syntactic constraints to phrase-based translation by directly rewarding/punishi"
P09-1036,P05-1033,0,0.731805,"nly on phrase movement but also on the lexical selection for the multi-meaning word “节”1 . To avert such errors, the decoder can fully respect linguistic structures by only allowing syntactic constituent translations and reorderings. This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries. To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side. On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. These constituent matching/violation counts are used as a feature in the decoder’s log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003). In this way, syntactic constraint is integrated into decoding as a soft constraint to enable the decoder to reward hypotheses that respect syntactic"
P09-1036,D08-1024,0,0.0439355,"Missing"
P09-1036,N03-1017,0,0.34237,"r inadequately breaks up the second NP phrase and translates the two words “航海” and “节” separately. However, the parse tree of the source fragment constrains the phrase “航海 节” to be translated as a unit. Without considering syntactic constraints from the parse tree, the decoder makes wrong decisions not only on phrase movement but also on the lexical selection for the multi-meaning word “节”1 . To avert such errors, the decoder can fully respect linguistic structures by only allowing syntactic constituent translations and reorderings. This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries. To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side. On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. These constituent matching/v"
P09-1036,W04-3250,0,0.433632,"Missing"
P09-1036,C02-1003,0,0.0654943,"Missing"
P09-1036,P08-1114,0,0.39465,"ly allowing syntactic constituent translations and reorderings. This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries. To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side. On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. These constituent matching/violation counts are used as a feature in the decoder’s log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003). In this way, syntactic constraint is integrated into decoding as a soft constraint to enable the decoder to reward hypotheses that respect syntactic analyses or to peSyntactic analysis influences the way in which the source sentence is translated. Previous efforts add syntactic constraints to phrase-based translation by directly"
P09-1036,P00-1056,0,0.707896,"Missing"
P09-1036,P03-1021,0,0.160074,"on-syntactic translations which violate constituent boundaries. To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side. On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. These constituent matching/violation counts are used as a feature in the decoder’s log-linear model and their weights are tuned via minimal error rate training (MERT) (Och, 2003). In this way, syntactic constraint is integrated into decoding as a soft constraint to enable the decoder to reward hypotheses that respect syntactic analyses or to peSyntactic analysis influences the way in which the source sentence is translated. Previous efforts add syntactic constraints to phrase-based translation by directly rewarding/punishing a hypothesis whenever it matches/violates source-side constituents. We present a new model that automatically learns syntactic constraints, including but not limited to constituent matching/violation, from training corpus. The model brackets a sou"
P09-1036,P02-1040,0,0.0758415,"ot use any syntactic constraints on Chinese-to-English translation. To compare with the CMVC, we also conduct experiments using (Marton and Resnik, 2008)’s XP+. The XP+ accumulates a count for each hypothesis whenever it violates the boundaries of a constituent with a label from {NP, VP, CP, IP, PP, ADVP, QP, LCP, DNP}. The XP+ is the best feature among all features that Marton and Resnik use for Chinese-toEnglish translation. Our experimental results display that our SDB model achieves a substantial improvement over the baseline and significantly outperforms XP+ according to the BLEU metric (Papineni et al., 2002). In addition, our analysis shows further evidences of the performance gain from a different perspective than that of BLEU. The paper proceeds as follows. In section 2 we describe how to learn bracketing instances from a training corpus. In section 3 we elaborate the syntax-driven bracketing model, including feature generation and the integration of the SDB model into phrase-based SMT. In section 4 and 5, we present our experiments and analysis. And we finally conclude in section 6. 2 The Acquisition of Bracketing Instances In this section, we formally define the bracketing instance, comprisin"
P09-1036,J97-3002,0,0.783539,"Missing"
P09-1036,I05-1007,1,0.887578,"Missing"
P09-1036,P06-1066,1,0.890811,"ndaries of a constituent. Otherwise, a lower probability is given. Through this additional feature, we want the decoder to prefer hypotheses that translate source spans which can be translated as a unit, and avoids translating those which are discontinuous after translation. The weight of this new feature is tuned via MERT, which measures the extent to which this feature should be trusted. In this paper, we implement the SDB model in a state-of-the-art phrase-based system which adapts a binary bracketing transduction grammar (BTG) (Wu, 1997) to phrase translation and reordering, described in (Xiong et al., 2006). Whenever a BTG merging rule (s → [s1 s2 ] or s → hs1 s2 i) is used, the SDB model gives a probability to the span s covered by the rule, which estimates the extent to which the span is bracketable. For the unary SDB model, we only consider the features from τ (s). For the binary SDB model, we use all features from τ (s1 ), τ (s2 ) and τ (s) since the binary SDB model is naturally suitable to the binary BTG rules. The SDB model, however, is not only limited to phrase-based SMT using BTG rules. Since it is applied on a source span each time, any other hierarchical phrase-based or syntax-based"
P09-1036,C08-1127,1,0.822854,"s up the second NP phrase and translates the two words “航海” and “节” separately. However, the parse tree of the source fragment constrains the phrase “航海 节” to be translated as a unit. Without considering syntactic constraints from the parse tree, the decoder makes wrong decisions not only on phrase movement but also on the lexical selection for the multi-meaning word “节”1 . To avert such errors, the decoder can fully respect linguistic structures by only allowing syntactic constituent translations and reorderings. This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries. To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side. On the contrary, Marton and Resnik (2008) and Cherry (2008) accumulate a count whenever hypotheses violate constituent boundaries. These constituent matching/violation counts are u"
P09-1036,W02-1039,0,\N,Missing
P09-1036,2005.iwslt-1.8,0,\N,Missing
P09-1037,D08-1024,1,0.851317,"o hierdriven syntactic modeling, we address this archical phrases that violate syntactic boundaries problem by observing the inuential role in the source language, and he explored the use of function words in determining syntacof a constituent feature intended to reward the tic structure, and introducing soft conapplication of hierarchical phrases which respect straints on function word relationships as source language syntactic categories. part of a standard log-linear hierarchithis did not yield signicant improvements, Marcal phrase-based model. Experimentation ton and Resnik (2008) and Chiang et al. (2008) on Chinese-English and Arabic-English extended this approach by introducing soft syntranslation demonstrates that the approach tactic constraints similar to the constituent feature, yields signicant gains in performance. but more ne-grained and sensitive to distinctions Although among syntactic categories; these led to substanIntroduction tial improvements in performance. Zollman et al. Hierarchical phrase-based models (Chiang, 2005; (2006) took a complementary approach, constrainChiang, 2007) offer a number of attractive beneing the application of hierarchical rules to respect ts in stati"
P09-1037,P08-1066,0,0.16649,"Missing"
P09-1037,J07-2003,0,0.343694,"gnicant improvements, Marcal phrase-based model. Experimentation ton and Resnik (2008) and Chiang et al. (2008) on Chinese-English and Arabic-English extended this approach by introducing soft syntranslation demonstrates that the approach tactic constraints similar to the constituent feature, yields signicant gains in performance. but more ne-grained and sensitive to distinctions Although among syntactic categories; these led to substanIntroduction tial improvements in performance. Zollman et al. Hierarchical phrase-based models (Chiang, 2005; (2006) took a complementary approach, constrainChiang, 2007) offer a number of attractive beneing the application of hierarchical rules to respect ts in statistical machine translation (SMT), while syntactic boundaries in the target language synmaintaining the strengths of phrase-based systems tax. Whether the focus is on constraints from the (Koehn et al., 2003). The most important of these source language or the target language, the main is the ability to model long-distance reordering efingredient in both previous approaches is the idea ciently. of constraining the spans of hierarchical phrases to To model such a reordering, a hierarrespect syntac"
P09-1037,N03-1017,0,0.133033,"Missing"
P09-1037,2003.mtsummit-papers.51,0,0.0330186,"s signicant gains in performance. but more ne-grained and sensitive to distinctions Although among syntactic categories; these led to substanIntroduction tial improvements in performance. Zollman et al. Hierarchical phrase-based models (Chiang, 2005; (2006) took a complementary approach, constrainChiang, 2007) offer a number of attractive beneing the application of hierarchical rules to respect ts in statistical machine translation (SMT), while syntactic boundaries in the target language synmaintaining the strengths of phrase-based systems tax. Whether the focus is on constraints from the (Koehn et al., 2003). The most important of these source language or the target language, the main is the ability to model long-distance reordering efingredient in both previous approaches is the idea ciently. of constraining the spans of hierarchical phrases to To model such a reordering, a hierarrespect syntactic boundaries. chical phrase-based system demands no additional parameters, since long and short distance reorderIn this paper, we pursue a different approach ings are modeled identically using synchronous to improving reordering choices in a hierarchical context free grammar (SCFG) rules. The same phras"
P09-1037,P02-1038,0,0.163241,"model, we used a 5- the baseline, but without further improvements gram model with modied Kneser-Ney smoothing over (Kneser and Ney, 1995) trained on the English side Arabic-to-English experiments. of our training data as well as portions of the Gigamarizes the results of our Arabic-to-English exword v2 English corpus. We used the NIST MT03 periments. This set of experiments shows a pattest set as the development set for optimizing intertern consistent with what we observed in Chinesepolation weights using minimum error rate trainto-English translation, again generally consistent ing (MERT; (Och and Ney, 2002)). We carried out across MT06 and MT08 test sets although modLarger values of N N = 128. Table 3 sumevaluation of the systems on the NIST 2006 evaleling a small number of lexical items (N uation test (MT06) and the NIST 2008 evaluation brings a marginal improvement over the baseline. test (MT08). We segmented Chinese as a preproIn addition, we again nd that the pairwise domcessing step using the Harbin segmenter (Zhao et inance model with al., 2001). signicant gain over the baseline in the MT06, Arabic-to-English experiments. We trained N = 128 = 32) produces the most although, interestingly"
P09-1037,J04-4002,0,0.110896,"r our running example. span of the hierarchical phrases, and (2) the span of a hierarchical phrase at a higher level is al6 ways a superset of the span of all other hierarchical Experimental Setup phrases at the lower level of its substructure. Thus, We tested the effect of introducing the pairwise to establish soft estimates of dominance counts, dominance model into hierarchical phrase-based we utilize alignment information available in the translation on Chinese-to-English and Arabic-torule together with the consistent alignment heurisEnglish translation tasks, thus studying its effect tic (Och and Ney, 2004) traditionally used to guess in two languages where the use of function words phrase alignments. differs signicantly. Following Setiawan et al. (2007), we identify function words as the Specically, we dene the span of a function N most word as a maximal, consistent alignment in the frequent words in the corpus, rather than identifysource language that either starts from or ends ing them according to linguistic criteria; this apwith the function word. (Requiring that spans be proximation removes the need for any additional maximal ensures their uniqueness.) language-specic resources. We wil"
P09-1037,E09-1044,0,\N,Missing
P09-1037,P02-1040,0,\N,Missing
P09-1037,W08-0403,0,\N,Missing
P09-1037,P08-1114,1,\N,Missing
P09-1037,P05-1033,0,\N,Missing
P09-1037,2008.iwslt-papers.7,0,\N,Missing
P09-1037,J97-3002,0,\N,Missing
P09-1037,P07-1090,1,\N,Missing
P09-1037,W06-3119,0,\N,Missing
P09-1037,W04-3250,0,\N,Missing
P09-1106,C08-1005,0,0.185663,"Missing"
P09-1106,C08-1014,1,0.832383,"e (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A through and fair comparison among them would be of great meaning to t"
P09-1106,J07-2003,0,0.0421201,"the training, dev and test data for IWSLT and NIST tasks. task data Sent. Words Dev Sent. IWSLT Words Test Sent. Words Add. Words Train Sent. Words Dev Sent. NIST 2002 Words Test Sent. 2005 Words Add. Words Train Ch En 406K 4.4M 4.6M 489 489 × 7 5,896 45,449 500 500 × 7 6,296 51,227 1.7M 238K 7.0M 8.9M 878 878 × 4 23,248 108,616 1,082 1,082 × 4 30,544 141,915 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r ) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from eac"
P09-1106,D08-1011,0,0.634478,"um Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A through and fair comparison among them would be of great meaning to the MT sys941 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 941–948, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP tem combination research. In this paper, we implement a confusion network-based decoder. Based on this decoder, we compare four commonly used wo"
P09-1106,D07-1029,0,0.129059,"Missing"
P09-1106,P05-3026,0,0.0260536,"is. 3) Confusion network construction: to build a confusion network based on hypothesis alignments. 4) Confusion network decoding: to decode the best translation from a confusion network. Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et"
P09-1106,P08-2021,0,0.037903,"fusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A th"
P09-1106,C04-1183,1,0.869719,"Missing"
P09-1106,P07-2045,0,0.00783503,"Missing"
P09-1106,N04-1022,0,0.147586,"cludes the paper. 2 Confusion network combination based system In order to compare different hypothesis alignment methods, we implement a confusion network decoding system as follows: Backbone selection: in the previous work, Matusov et al. (2006, 2008) let every hypothesis play the role of the backbone (also called “skeleton” or “alignment reference”) once. We follow the work of (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; He et al., 2008) and choose the hypothesis that best agrees with other hypotheses on average as the backbone by applying Minimum Bayes Risk (MBR) decoding (Kumar and Byrne, 2004). TER score (Snover et al, 2006) is used as the loss function in MBR decoding. Given a hypothesis set H, the backbone can be computed using the following equation, where TER(•, •) returns the TER score of two hypotheses. Eb = arg min ∑ TER ( Eˆ , E ) Eˆ ∈H (1) E∈H Hypothesis alignment: all hypotheses are word-aligned to the corresponding backbone in a many-to-one manner. We apply four word alignment methods: GIZA++-based, TER-based, CLA-based, and IHMM-based word alignment algorithm. For each method, we will give details in the next section. Confusion network construction: confusion network is"
P09-1106,E06-1031,0,0.0608531,"Missing"
P09-1106,E06-1005,0,0.490885,"confusion network. Among the four steps, the hypothesis alignment presents the biggest challenge to the method due to the varying word orders between outputs from different MT systems (Rosti et al, 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alig"
P09-1106,J00-2004,0,0.132613,"allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources. Although many methods have been attempted, no systematic comparison among them has been reported. A through and fair comparison among them would be of great meaning to the MT sys941 Proceedings of the 47th Annual Meeting of th"
P09-1106,P03-1021,0,0.0185165,"probabilities (arc scores of the confusion network), • N-gram frequencies (Chen et al., 2005), • N-gram posterior probabilities (Zens and Ney, 2006). Word alignment algorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. bigram ei′ei′+1 observed in the hypothesis list; e2 Word penalty, The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). where p (ei′ei′+1 ) is the occurrence probability of e1 • Hypothesis-to-backbone ment word alignGIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an exte"
P09-1106,J03-1002,0,0.00892965,"lgorithms We compare four word alignment methods which are widely used in confusion network based system combination or bilingual parallel corpora word alignment. bigram ei′ei′+1 observed in the hypothesis list; e2 Word penalty, The n-grams used in the last two feature functions are collected from the original hypotheses list from each single system. The weights of feature functions are optimized to maximize the scoring measure (Och, 2003). where p (ei′ei′+1 ) is the occurrence probability of e1 • Hypothesis-to-backbone ment word alignGIZA++: Matusov et al. (2006, 2008) proposed using GIZA++ (Och and Ney, 2003) to align words between the backbone and hypothesis. This method uses enhanced HMM model bootstrapped from IBM Model-1 to estimate the alignment model. All hypotheses of the whole test set are collected to create sentence pairs for GIZA++ training. GIZA++ produces hypothesisbackbone many-to-1 word alignments. TER-based: TER-based word alignment method (Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b) is an extension of multiple string matching algorithm based on Levenshtein edit distance (Bangalore et al., 2001). The TER (translation error rate) score (Snover et al., 2006) measures"
P09-1106,P02-1040,0,0.0768188,"Missing"
P09-1106,N07-1029,0,0.405741,"ur word alignment methods on both Chinese-to-English spoken and written language tasks. 1 Introduction Machine translation (MT) system combination technique leverages on multiple MT systems to achieve better performance by combining their outputs. Confusion network based system combination for machine translation has shown promising advantage compared with other techniques based system combination, such as sentence level hypothesis selection by voting and source sentence re-decoding using the phrases or translation models that are learned from the source sentences and target hypotheses pairs (Rosti et al., 2007a; Huang and Papineni, 2007). In general, the confusion network based system combination method for MT consists of four steps: 1) Backbone selection: to select a backbone (also called “skeleton”) from all hypotheses. The backbone defines the word orders of the final translation. 2) Hypothesis alignment: to build word-alignment between backbone and each hypothesis. 3) Confusion network construction: to build a confusion network based on hypothesis alignments. 4) Confusion network decoding: to decode the best translation from a confusion network. Among the four steps, the hypothesis alignment pr"
P09-1106,P07-1040,0,0.145783,"Missing"
P09-1106,W08-0329,0,0.0334511,"e. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a"
P09-1106,2006.amta-papers.25,0,0.473331,", 2007). Many techniques have been studied to address this issue. Bangalore et al. (2001) used the edit distance alignment algorithm which is extended to multiple strings to build confusion network, it only allows monotonic alignment. Jayaraman and Lavie (2005) proposed a heuristic-based matching algorithm which allows nonmonotonic alignments to align the words between the hypotheses. More recently, Matusov et al. (2006, 2008) used GIZA++ to produce word alignment for hypotheses pairs. Sim et al. (2007), Rosti et al. (2007a), and Rosti et al. (2007b) used minimum Translation Error Rate (TER) (Snover et al., 2006) alignment to build the confusion network. Rosti et al. (2008) extended TER algorithm which allows a confusion network as the reference to compute word alignment. Karakos et al. (2008) used ITG-based method for hypothesis alignment. Chen et al. (2008) used Competitive Linking Algorithm (CLA) (Melamed, 2000) to align the words to construct confusion network. Ayan et al. (2008) proposed to improve alignment of hypotheses using synonyms as found in WordNet (Fellbaum, 1998) and a two-pass alignment strategy based on TER word alignment approach. He et al. (2008) proposed an IHMM-based word alignmen"
P09-1106,takezawa-etal-2002-toward,0,0.0321791,"two links share a same hypothesis or backbone word and also satisfy the constraints, we choose the link that with the highest similarity score. For example, in Figure 2, since MCS-based similarity scores S ( shot , shoot ) > S ( shot , the) , we choose alignment (a). 4 4.1 Experiments and results Tasks and single systems Experiments are carried out in two domains. One is in spoken language domain while the other is on newswire corpus. Both experiments are on Chinese-to-English translation. Experiments on spoken language domain were carried out on the Basic Traveling Expression Corpus (BTEC) (Takezawa et al., 2002) Chinese- to-English data augmented with HITcorpus1 . BTEC is a multilingual speech corpus which contains sentences spoken by tourists. 40K sentence-pairs are used in our experiment. HIT-corpus is a balanced corpus and has 500K sentence-pairs in total. We selected 360K sentence-pairs that are more similar to BTEC data according to its sub-topic. Additionally, the English sentences of Tanaka corpus2 were also used to train our language model. We ran experiments on an IWSLT challenge task which uses IWSLT20063 DEV clean text set as development set and IWSLT-2006 TEST clean text as test set. b Fi"
P09-1106,P06-1066,0,0.0199915,"ent. Words Dev Sent. IWSLT Words Test Sent. Words Add. Words Train Sent. Words Dev Sent. NIST 2002 Words Test Sent. 2005 Words Add. Words Train Ch En 406K 4.4M 4.6M 489 489 × 7 5,896 45,449 500 500 × 7 6,296 51,227 1.7M 238K 7.0M 8.9M 878 878 × 4 23,248 108,616 1,082 1,082 × 4 30,544 141,915 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r ) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four"
P09-1106,W06-3110,0,0.0565219,"Missing"
P09-1106,P08-1064,1,0.843256,"NIST 2002 Words Test Sent. 2005 Words Add. Words Train Ch En 406K 4.4M 4.6M 489 489 × 7 5,896 45,449 500 500 × 7 6,296 51,227 1.7M 238K 7.0M 8.9M 878 878 × 4 23,248 108,616 1,082 1,082 × 4 30,544 141,915 61.5M Table 1: Statistics of training, dev and test data for IWSLT and NIST tasks. In both experiments, we used four systems, as listed in Table 2, they are phrase-based system Moses (Koehn et al., 2007), hierarchical phrasebased system (Chiang, 2007), BTG-based lexicalized reordering phrase-based system (Xiong et al., 2006) and a tree sequence alignment-based tree-to-tree translation system (Zhang et al., 2008). Each system for the same task is trained on the same data set. 4.2 Experiments setting For each system, we used the top 10 scored hypotheses to build the confusion network. Similar to (Rosti et al., 2007a), each word in the hypothesis is assigned with a rank-based score of 1/ (1 + r ) , where r is the rank of the hypothesis. And we assign the same weights to each system. For selecting the backbone, only the top hypothesis from each system is considered as a candidate for the backbone. Concerning the four alignment methods, we use the default setting for GIZA++; and use toolkit TERCOM (Snover"
P09-1106,zhang-etal-2004-interpreting,0,0.0683296,"Missing"
P09-1106,2005.eamt-1.20,0,\N,Missing
P09-1106,2005.iwslt-1.11,1,\N,Missing
P09-1106,2006.iwslt-evaluation.15,0,\N,Missing
P09-4006,I08-2084,1,0.829486,"pulate the corpora in three levels of abstraction – clusters, documents and terms. And our key task over here is to find the underlying associations of documents or terminologies in each level across different languages. First, monolingual documents are grouped into clusters by k-means algorithm using simple word vectors. Then, monolingual noun terms are extracted from each cluster using linguistic patterns and filtered by occurrence statistics globally (within cluster) and locally (within document), so that they are good representatives for cluster as a whole as well as individual documents (Vu et al., 2008). The extracted terms are then used in document clustering in a new cycle and the whole process is repeated until the result converges. Next, cluster alignment is carried out between the pivot language (English) and the other languages (Chinese, Malay). Clusters can be conceptualized as the collection of documents with the same themes (e.g. finance, politics or sports) and their alignments as the correspondents in the other languages. Since there may be overlaps among themes, e.g. finance and economy, each cluster is allowed to align to more than one cluster with varying degree of alignment sc"
P09-4006,W03-1108,0,\N,Missing
P09-4006,E09-1096,1,\N,Missing
P10-1016,P09-1088,0,0.0329656,"Missing"
P10-1016,J93-2003,0,0.118946,"a kind of basic multi-word expression that characterizes minimal sequence of consecutive words in sense of translation. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain. 1 Introduction The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus generated from word-based models (Brown et al., 1993), proceeds with step of induction of phrase table (Koehn et al., 2003) or synchronous grammar (Chiang, 2007) and with model weights tuning step. Words are taken as inputs to PB-SMT at the very beginning of the pipeline. But there is a deficiency in such manner that word is too finegrained in some cases such as non-compositional phrasal equivalences, where clear word alignments do not exist. For example in Chinese-toEnglish translation, “ 想 ” and “would like to” constitute a 1-to-n phrasal equivalence, “多 少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignment"
P10-1016,W08-0336,0,0.0431284,"tion word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Lingui"
P10-1016,W07-0403,0,0.0132778,"equivalence, “多 少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to bui"
P10-1016,H05-1022,0,0.146358,"it is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics pressions by monotonically segmenting a given Spanish-English sentence pair into bilingual units, where word aligner is also used. IBM model 3, 4, 5 (Brown et al., 1993) and Deng and Byrne (2005) are another kind of related works that allow 1-to-n alignments, but they rarely questioned if such alignments exist in word units level, that is, they rarely questioned word as basic translational unit. Moreover, m-ton alignments were not modeled. This paper focuses on determining the basic translational units on both language sides without using word aligner before feeding them into PBSMT pipeline. We call such basic translational unit as pseudo-word to differentiate with word. Pseudo-word is a kind of multi-word expression (includes both unary word and multi-word). Pseudo-word searching pro"
P10-1016,P07-2045,0,0.013411,"Missing"
P10-1016,J97-3002,0,0.185169,"l equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. X"
P10-1016,W04-3250,0,0.0430311,"into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translatio"
P10-1016,P07-1039,0,0.491414,"to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for C"
P10-1016,E09-1063,0,0.622793,"egment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics pressions by monotonically segmenting a given Spanish-English sentence pair into bilingual units, where word aligner is also used. IBM model 3, 4, 5 (Brown et al., 1993) and Deng and Byrne (2005) are another kind of related works that allow"
P10-1016,2002.tmi-tutorials.2,0,0.0319943,"anner that word is too finegrained in some cases such as non-compositional phrasal equivalences, where clear word alignments do not exist. For example in Chinese-toEnglish translation, “ 想 ” and “would like to” constitute a 1-to-n phrasal equivalence, “多 少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational u"
P10-1016,P03-1021,0,0.0199466,"e is computed only on pairs of blank boxes, solid boxes are excluded in this computation to represent NULL alignment cases. is ks1 ks2 js it kt1 kt2 jt a) non-reversed is ks1 ks2 js it kt1 kt2 jt Experiments and Results In our experiments, pseudo-words are fed into PB-SMT pipeline. The pipeline uses GIZA++ model 4 (Brown et al., 1993; Och and Ney, 2003) for pseudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language translation in travel domain (Paul, 2008), the other is large corpus in news domain, which consists Hong Kong News (LDC2004T08), Sinorama Magazine (LDC2005T10), FBIS (LDC2003E14), Xinhua (LDC2002E18), Chinese News Translation (LDC2005T06), Chinese Treebank (LDC2003E07), Multiple"
P10-1016,J03-1002,0,0.016175,"ottom-up way, and the optimal decomposition of the sentence pair is obtained correspondingly. z Algorithm of Excluded Synchronous Searching for Pseudo-words (ESSP) The algorithm of SSP in Figure 2 explores all span-pairs, but it neglects NULL alignments, where words and “empty” word are aligned. In fact, SSP requires that all parts of a sentence pair should be aligned. This requirement is too strong because NULL alignments are very common in many language pairs. In SSP, words that should be aligned to “empty” word are programmed to be aligned to real words. Unlike most word alignment methods (Och and Ney, 2003) that add “empty” word to account for NULL alignment entries, we propose a method to naturally exclude such NULL alignments. We call this method as Excluded Synchronous Searching for Pseudo-words (ESSP). The main difference between ESSP and SSP is in steps 3-6 in Figure 3. We illustrate Figure 3’s span-pair configuration in Figure 4. 151 Initialization: if is = js or it = jt then W i s , j s , i t , j t = Sig i s , j s ,it , jt ; else W i s , j s , it , jt = 0 ; 1: for ds = 2 … ns, dt = 2 … nt do 2: for all is, js, it, jt s.t. js-is=ds-1 and jt-it=dt-1 do 3: for ks1=is+1 … js, ks2=ks1-1 … js-1"
P10-1016,C08-1128,0,\N,Missing
P10-1016,P02-1040,0,\N,Missing
P10-1016,W05-0909,0,\N,Missing
P10-1016,W07-0734,0,\N,Missing
P10-1016,P08-1012,0,\N,Missing
P10-1016,N03-1017,0,\N,Missing
P10-1016,W08-0335,0,\N,Missing
P10-1016,J07-2003,0,\N,Missing
P10-1016,2005.mtsummit-posters.11,0,\N,Missing
P10-1016,W04-1118,0,\N,Missing
P10-1016,2008.iwslt-evaluation.1,0,\N,Missing
P10-1062,P03-1021,0,0.003576,"Missing"
P10-1062,P02-1040,0,0.101194,"Missing"
P10-1062,2009.eamt-1.15,0,0.0390746,"Missing"
P10-1062,2007.mtsummit-papers.54,0,0.830199,"tic features, according to their final results. Ueffing and Ney (2007) exhaustively explore various word-level confidence measures to label each word in a generated translation hypothesis as correct or incorrect. All their measures are based on word posterior probabilities, which are estimated from 1) system output, such as word lattices or N -best lists and 2) word or phrase translation table. Their experimental results show that word posterior probabilities directly estimated from phrase translation table are better than those from system output except for the Chinese-English language pair. Sanchis et al. (2007) adopt a smoothed naive Bayes model to combine different word posterior probability based confidence features which are estimated from N -best lists, similar to (Ueffing and Ney, 2007). Raybaud et al. (2009) study several confidence features based on mutual information between words and n-gram and backward n-gram language model for word-level and sentence-level CE. They also explore linguistic features using information from syntactic category, tense, gender and so on. Unfortunately, such linguistic features neither improve performance at the word level nor at the sentence level. Our work depa"
P10-1062,1993.iwpt-1.22,0,0.00848038,"o be incorrect. The challenge of using syntactic knowledge for error detection is that machinegenerated hypotheses are rarely fully grammatical. They are mixed with grammatical and ungrammatical parts, which hence are not friendly to traditional parsers trained on grammatical sentences because ungrammatical parts of a machinegenerated sentence could lead to a parsing failure. To overcome this challenge, we select the Link Grammar (LG) parser 3 as our syntactic parser to generate syntactic features. The LG parser produces a set of labeled links which connect pairs of words with a link grammar (Sleator and Temperley, 1993). The main reason why we choose the LG parser is that it provides a robustness feature: null-link scheme. The null-link scheme allows the parser to parse a sentence even when the parser can not fully interpret the entire sentence (e.g. including ungrammatical parts). When the parser fail to parse the entire sentence, it ignores one word each time until it finds linkages for remaining words. After parsing, those ignored words are not connected to any other words. We call them null-linked words. Our hypothesis is that null-linked words are prone to be syntactically incorrect. We hence straightfo"
P10-1062,C04-1047,0,0.0535615,"Missing"
P10-1062,H05-1006,0,0.0326993,"development set. Sometimes the step 2) is not necessary if only one effective feature is used (Ueffing and Ney, 2007); and sometimes the step 2) and 3) can be merged into a single step if we directly output predicting results from binary classifiers instead of making thresholding decision. Various features from different SMT models and system outputs are investigated (Blatz et al., 2003; Ueffing and Ney, 2007; Sanchis et al., 2007; Raybaud et al., 2009). Experimental results show that they are useful for error detection. However, it is not adequate to just use these features as discussed in (Shi and Zhou, 2005) because the information that they carry is either from the inner components of SMT systems or from system outputs. To some extent, it has already been considered by SMT systems. Hence finding external information Introduction Translation hypotheses generated by a statistical machine translation (SMT) system always contain both correct parts (e.g. words, n-grams, phrases matched with reference translations) and incorrect parts. Automatically distinguishing incorrect parts from correct parts is therefore very desirable not only for post-editing and interactive machine translation (Ueffing and N"
P10-1062,J96-1002,0,0.0522358,"Missing"
P10-1062,2003.mtsummit-papers.52,0,0.344912,"likely to be incorrect than words in frequently occurring patterns. To some extent, these two features have similar function to a target language model or pos-based target language model. yes, w has links no, otherwise In Figure 1 we show an example of a generated translation hypothesis with its link parse. Here links are denoted with dotted lines which are annotated with link types (e.g., Jp, Op). Bracketed words, namely “,” and “including”, are null-linked words. 3.3 Word Posterior Probability Features Our word posterior probability is calculated on N best list, which is first proposed by (Ueffing et al., 2003) and widely used in (Blatz et al., 2003; Ueffing and Ney, 2007; Sanchis et al., 2007). Given a source sentence f , let {en }N 1 be the N best list generated by an SMT system, and let ein is the i-th word in en . The major work of calculating word posterior probabilities is to find the Levenshtein alignment (Levenshtein, 1966) between the best hypothesis e1 and its competing hypothesis 3.2 Syntactic Features High-level linguistic knowledge such as syntactic information about a word is a very natural and promising indicator to decide whether this word is syntactically correct or not. Words occur"
P10-1062,W06-3110,0,0.0456356,"sidered by SMT systems. Hence finding external information Introduction Translation hypotheses generated by a statistical machine translation (SMT) system always contain both correct parts (e.g. words, n-grams, phrases matched with reference translations) and incorrect parts. Automatically distinguishing incorrect parts from correct parts is therefore very desirable not only for post-editing and interactive machine translation (Ueffing and Ney, 2007) but also for SMT itself: either by rescoring hypotheses in the N -best list using the probability of correctness calculated for each hypothesis (Zens and Ney, 2006) or by generating new hypotheses using N best lists from one SMT system or multiple sys604 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 604–611, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics confidence estimation at the word level as well as at the sentence level. The features they use for word level CE include word posterior probabilities estimated from N -best lists, features based on SMT models, semantic features extracted from WordNet as well as simple syntactic features, i.e. parentheses and quotation m"
P10-1062,W03-0413,0,0.0622143,"Missing"
P10-1062,P05-3026,0,0.0200006,"Missing"
P10-1062,N03-1017,0,0.00275441,"variable c to indicate whether this word is correct or not. In the feature vector, we look at 2 words before and 2 words after the current word position (w−2 , w−1 , w, w1 , w2 ). We collect features {wd, pos, link, dwpp} for each word among these words and combine them into the feature vector ψ for w. As such, we want the feature vector to capture the contextual environment, e.g., pos sequence pattern, syntactic pattern, where the word w occurs. To obtain machine-generated translation hypotheses for our error detection, we use a state-of-the-art phrase-based machine translation system MOSES (Koehn et al., 2003; Koehn et al., 2007). The translation task is on the official NIST Chineseto-English evaluation data. The training data consists of more than 4 million pairs of sentences (including 101.93M Chinese words and 112.78M English words) from LDC distributed corpora. Table 2 shows the corpora that we use for the translation task. We build a four-gram language model using the SRILM toolkit (Stolcke, 2002), which is trained 607 Feature wd pos link dwpp Example { 1, f (c, ψ) = { 0, 1, f (c, ψ) = { 0, 1, f (c, ψ) = { 0, 1, f (c, ψ) = 0, ψ.w.wd = ”.”, c = correct otherwise ψ.w2 .pos = ”N N ”, c = incorre"
P10-1062,J07-1003,0,\N,Missing
P10-1062,P07-2045,0,\N,Missing
P10-1062,C04-1046,0,\N,Missing
P10-1062,2005.eamt-1.20,0,\N,Missing
P10-1090,W06-1673,0,0.0167499,"(10) reviewer of the paper, we can consider the forest ?? ???? ?1 ∙ ?? ???? ?2 kernel as an alternative solution proposed for the general problem of noisy inference pipelines (eg. Finally, since the size of input forests is not speech translation by composition of FSTs, maconstant, the forest kernel value is normalized chine translation by translating over 'lattices' of using the following equation. segmentations (Dyer et al., 2008) or using parse ?? ?1 , ?2 tree info for downstream applications in our cas?? ?1 , ?2 = (11) es) . Following this line, Bunescu (2008) and ?? ?1 , ?1 ∙ ?? ?2 , ?2 Finkel et al. (2006) are two typical related works done in reducing cascading noisy. However, our From the above discussion, we can see that the works are not overlapped with each other as proposed forest kernel is defined together by eqs. there are two totally different solutions for the (11), (10), (9) and (8). Thanks to the compact same general problem. In addition, the main morepresentation of trees in forest and the recursive tivation of this paper is also different from theirs. nature of the kernel function, the introduction of fractional counts and normalization do not 4 Experiments change the convolution"
P10-1090,P06-1104,1,0.917321,"product in a high-dimensional space over the original representations of objects, has made kernel methods an effective solution to modeling structured objects in NLP. In the context of parse tree, convolution tree kernel (Collins and Duffy, 2002) defines a feature space consisting of all subtree types of parse trees and counts the number of common subtrees as the syntactic similarity between two parse trees. The tree kernel has shown much success in many NLP applications like parsing (Collins and Duffy, 2002), semantic role labeling (Moschitti, 2004; Zhang et al., 2007), relation extraction (Zhang et al., 2006), pronoun resolution (Yang et al., 2006), question classification (Zhang and Lee, 2003) and machine translation (Zhang and Li, 2009), where the tree kernel is used to compute the similarity between two NLP application instances that are usually represented by parse trees. However, in those studies, the tree kernel only covers the features derived from single 1875 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 875–885, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics PP IN DT NN in the bank PP IN DT NN in the bank"
P10-1090,P08-1064,1,0.833375,"illustrate the concept of packed forest and then give a detailed discussion on the covered feature space, fractional count, feature value and the forest kernel function itself. 3.1 Packed forest of parse trees Informally, a packed parse forest, or (packed) forest in short, is a compact representation of all the derivations (i.e. parse trees) for a given sentence under context-free grammar (Tomita, 1987; Billot and Lang, 1989; Klein and Manning, 2001). It is the core data structure used in natural language parsing and other downstream NLP applications, such as syntax-based machine translation (Zhang et al., 2008; Zhang et al., 2009a). In parsing, a sentence corresponds to exponential number of parse trees with different tree probabilities, where a forest can compact all the parse trees by sharing their common subtrees in a bottom-up manner. Formally, a packed forest ? can be described as a triple: ? = &lt; ?, ?, ? &gt; where ?is the set of non-terminal nodes, ? is the set of hyper-edges and ? is a sentence 877 represented as an ordered word sequence. A hyper-edge ? is a group of edges in a parse tree which connects a father node and its all child nodes, representing a CFG rule. A non-terminal node in a for"
P10-1090,D08-1022,0,\N,Missing
P10-1090,N06-2025,0,\N,Missing
P10-1090,C02-1132,0,\N,Missing
P10-1090,D08-1070,0,\N,Missing
P10-1090,W04-3212,0,\N,Missing
P10-1090,D09-1108,1,\N,Missing
P10-1090,J03-4003,0,\N,Missing
P10-1090,P09-1020,1,\N,Missing
P10-1090,J87-1004,0,\N,Missing
P10-1090,D09-1073,1,\N,Missing
P10-1090,P04-1043,0,\N,Missing
P10-1090,P06-1006,0,\N,Missing
P10-1090,P05-1022,0,\N,Missing
P10-1090,W05-0620,0,\N,Missing
P10-1090,P08-1067,0,\N,Missing
P10-1090,P01-1017,0,\N,Missing
P10-1090,P08-1115,0,\N,Missing
P10-1090,J05-1004,0,\N,Missing
P10-1090,P06-2010,1,\N,Missing
P10-1090,P07-1026,1,\N,Missing
P10-1090,P89-1018,0,\N,Missing
P10-1090,W01-1812,0,\N,Missing
P11-1129,D07-1090,0,0.234408,"the efforts that advance translation models from word-based paradigm to syntax-based philosophy, in recent years we have also witnessed increasing efforts dedicated to extend standard n-gram language models for SMT. We roughly categorize these efforts into two directions: data-volume-oriented and data-depth-oriented. In the first direction, more data is better. In order to benefit from monolingual corpora (LDC news data or news data collected from web pages) that consist of billions or even trillions of English words, huge language models are built in a distributed manner (Zhang et al., 2006; Brants et al., 2007). Such language models yield better translation results but at the cost of huge storage and high computation. The second direction digs deeply into monolingual data to build linguistically-informed language models. For example, Charniak et al. (2003) present a syntax-based language model for machine translation which is trained on syntactic parse trees. Again, Shen et al. (2008) explore a dependency language model to improve translation quality. To some extent, these syntactically-informed language models are consistent with syntax-based translation models in capturing long-distance dependenci"
P11-1129,J93-2003,0,0.016013,"information trigger model which captures long-distance dependencies that go beyond the scope of standard n-gram language models. We integrate the two proposed models into phrase-based statistical machine translation and conduct experiments on large-scale training data to investigate their effectiveness. Our experimental results show that both models are able to significantly improve translation quality and collectively achieve up to 1 BLEU point over a competitive baseline. 1 Introduction Language model is one of the most important knowledge sources for statistical machine translation (SMT) (Brown et al., 1993). The standard n-gram language model (Goodman, 2001) assigns probabilities to hypotheses in the target language conditioning on a context history of the preceding n − 1 words. Along with the efforts that advance translation models from word-based paradigm to syntax-based philosophy, in recent years we have also witnessed increasing efforts dedicated to extend standard n-gram language models for SMT. We roughly categorize these efforts into two directions: data-volume-oriented and data-depth-oriented. In the first direction, more data is better. In order to benefit from monolingual corpora (LDC"
P11-1129,2003.mtsummit-papers.6,0,0.593667,"rts into two directions: data-volume-oriented and data-depth-oriented. In the first direction, more data is better. In order to benefit from monolingual corpora (LDC news data or news data collected from web pages) that consist of billions or even trillions of English words, huge language models are built in a distributed manner (Zhang et al., 2006; Brants et al., 2007). Such language models yield better translation results but at the cost of huge storage and high computation. The second direction digs deeply into monolingual data to build linguistically-informed language models. For example, Charniak et al. (2003) present a syntax-based language model for machine translation which is trained on syntactic parse trees. Again, Shen et al. (2008) explore a dependency language model to improve translation quality. To some extent, these syntactically-informed language models are consistent with syntax-based translation models in capturing long-distance dependencies. In this paper, we pursue the second direction without resorting to any linguistic resources such as a syntactic parser. With a belief that a language model that embraces a larger context provides better prediction ability, we learn additional inf"
P11-1129,J07-2003,0,0.832723,"language model assigns a probability Pb (w1m ) to w1m by looking at the succeeding context according to Pb (w1m ) = m ∏ i=1 m )≈ P (wi |wi+1 m ∏ i+n−1 P (wi |wi+1 ) (2) i=1 3.1 Training et al., 2006) and 2) a standard phrase-based decoder (Koehn et al., 2003). Both decoders translate source sentences from the beginning of a sentence to the ending. Wu (1996) introduce a dynamic programming algorithm to integrate a forward bigram language model with inversion transduction grammar. His algorithm is then adapted and extended for integrating forward n-gram language models into synchronous CFGs by Chiang (2007). Our algorithms are different from theirs in two major aspects 1. The string input to the algorithms is in a reverse order. 2. We adopt a different way to calculate language model probabilities for partial hypotheses so that we can utilize incomplete n-grams. Before we introduce the integration algorithms, we define three functions P, L, and R on strings (in a reverse order) over the English terminal alphabet T . The function P is defined as follows. P(wk ...w1 ) = P (wk )...P (wk−n+2 |wk ...wk−n+3 ) {z } | a ∏ P (wi |wi+n−1 ...wi+1 ) × 1≤i≤k−n+1 | For the convenience of training, we invert t"
P11-1129,J90-1003,0,0.0548025,"n that long-distance dependencies between words are very important for statistical language modeling. However, n-gram language models can only capture short-distance dependencies within an n-word window. In order to model long-distance dependencies, previous work such as (Rosenfeld et al., 1994) and (Zhou, 2004) exploit trigger pairs. A trigger pair is defined as an ordered 2-tuple (x, y) where word x occurs in the preceding context of word y. It can also be denoted in a more visual manner as x → y with x being the trigger and y the triggered word5 . We use pointwise mutual information (PMI) (Church and Hanks, 1990) to measure the strength of the association between x and y, which is defined as follows P M I(x, y) = log( P (x, y) ) P (x)P (y) (12) 5 In this paper, we require that word x and y occur in the same sentence. 1292 i−1 P (wi |wi−n+1 )) m i−n ∏ ∏ exp(P M I(wk , wi , i − k − 1)) i=n+1 k=1 (13) There are two components in his model. The first component is still the standard n-gram language model. The second one is the MI trigger model which multiples all exponential PMI values for trigger pairs where the current word is the triggered word and all preceding words outside the n-gram window of the cu"
P11-1129,D09-1117,0,0.277157,"build contextually-informed language models by using backward n-grams and MI triggers, we discuss previous work that explore these two techniques (backward n-grams and MI triggers) in this section. Since the context “history” in the backward language model (BLM) is actually the future words to be generated, BLM is normally used in a postprocessing where all words have already been generated or in a scenario where sentences are proceeded from the ending to the beginning. Duchateau et al. (2002) use the BLM score as a confidence measure to detect wrongly recognized words in speech recognition. Finch and Sumita (2009) use the BLM in their reverse translation decoder where source sentences are proceeded from the ending to the beginning. Our BLM is different from theirs in that we access the BLM during decoding (rather than after decoding) where source sentences are still proceeded from the beginning to the ending. Rosenfeld et al. (1994) introduce trigger pairs into a maximum entropy based language model as features. The trigger pairs are selected according to their mutual information. Zhou (2004) also propose an enhanced language model (MI-Ngram) which consists of a standard forward n-gram language model a"
P11-1129,N03-1017,0,0.482736,"= m ∏ P (wi |w1i−1 ) ≈ m ∏ i−1 ) (1) P (wi |wi−n+1 i=1 i=1 where the approximation is based on the nth order Markov assumption. In other words, when we predict the current word wi , we only consider the preceding n − 1 words wi−n+1 ...wi−1 instead of the whole context history w1 ...wi−1 . Different from the forward n-gram language model, the backward n-gram language model assigns a probability Pb (w1m ) to w1m by looking at the succeeding context according to Pb (w1m ) = m ∏ i=1 m )≈ P (wi |wi+1 m ∏ i+n−1 P (wi |wi+1 ) (2) i=1 3.1 Training et al., 2006) and 2) a standard phrase-based decoder (Koehn et al., 2003). Both decoders translate source sentences from the beginning of a sentence to the ending. Wu (1996) introduce a dynamic programming algorithm to integrate a forward bigram language model with inversion transduction grammar. His algorithm is then adapted and extended for integrating forward n-gram language models into synchronous CFGs by Chiang (2007). Our algorithms are different from theirs in two major aspects 1. The string input to the algorithms is in a reverse order. 2. We adopt a different way to calculate language model probabilities for partial hypotheses so that we can utilize incomp"
P11-1129,W04-3250,0,0.221159,"Missing"
P11-1129,D09-1022,0,0.0230483,"guage model and an MI trigger model. The latter model measures the mutual information of distancedependent trigger pairs. Our MI trigger model is mostly inspired by the work of these two papers, especially by Zhou’s MI-Ngram model (2004). The difference is that our model is distance-independent and, of course, we are interested in an SMT problem rather than a speech recognition one. Raybaud et al. (2009) use MI triggers in their confidence measures to assess the quality of translation results after decoding. Our method is different from theirs in the MI calculation and trigger pair selection. Mauser et al. (2009) propose bilingual triggers where two source words trigger one target word to 1 Language model adaptation is not very related to our work so we ignore it. improve lexical choice of target words. Our analysis (Section 6) show that our monolingual triggers can also help in the selection of target words. 3 Backward Language Model Given a sequence of words w1m = (w1 ...wm ), a standard forward n-gram language model assigns a probability Pf (w1m ) to w1m as follows. Pf (w1m ) = m ∏ P (wi |w1i−1 ) ≈ m ∏ i−1 ) (1) P (wi |wi−n+1 i=1 i=1 where the approximation is based on the nth order Markov assumpti"
P11-1129,P03-1021,0,0.0184105,"istance-dependent since trigger pairs (wk , wi ) are sensitive to their distance i − k − 1 (zero distance for adjacent words). Therefore the distance between word x and word y should be taken into account when calculating their PMI. In this paper, for simplicity, we adopt a distanceindependent MI trigger model as follows M I(w1m ) = m i−n ∏ ∏ exp(P M I(wk , wi )) (14) i=n+1 k=1 We integrate the MI trigger model into the loglinear model of machine translation as an additional knowledge source which complements the standard n-gram language model in capturing long-distance dependencies. By MERT (Och, 2003), we are even able to tune the weight of the MI trigger model against the weight of the standard n-gram language model while Zhou (2004) sets equal weights for both models. 4.1 Training We can use the maximum likelihood estimation method to calculate PMI for each trigger pair by taking counts from training data. Let C(x, y) be the co-occurrence count of the trigger pair (x, y) in the training data. The joint probability of (x, y) is calculated as C(x, y) x,y C(x, y) P (x, y) = ∑ (15) phrase-based decoder. But we still can handle it by dynamic programming as follows M I(e1 e2 ) = M I(e1 )M I(e2"
P11-1129,P02-1040,0,0.0811835,"English Gigaword corpus (306 million words). Firstly, we built a forward 5-gram language model using the SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing. Then we trained a backward 5-gram language model on the same monolingual corpus in the way described in Section 3.1. Finally, we trained our MI trigger model still on this corpus according to the method in Section 4.1. The trained MI trigger model consists of 2.88M trigger pairs. We used the NIST MT03 evaluation test data as the development set, and the NIST MT04, MT05 as the test sets. We adopted the case-insensitive BLEU4 (Papineni et al., 2002) as the evaluation metric, which uses the shortest reference sentence length for the brevity penalty. Statistical significance in BLEU differences is tested by paired bootstrap re-sampling (Koehn, 2004). 5.3 Experimental Results The experimental results on the two NIST test sets are shown in Table 2. When we combine the backward language model with the forward language 7 LDC2004E12, LDC2004T08, LDC2005T10, LDC2003E14, LDC2002E18, LDC2005T06, LDC2003E07 and LDC2004T07. 1294 Model Forward (Baseline) Forward+Backward Forward+MI Forward+Backward+MI MT-04 35.67 36.16+ 36.00+ 36.76+ MT-05 34.41 34.9"
P11-1129,2008.amta-papers.16,0,0.0143574,"in more detail, describe the training procedures and explain how the models are integrated into the phrase-based decoder. Section 5 will empirically evaluate the effectiveness of these two models. Section 6 will conduct an indepth analysis. In the end, we conclude in Section 7. 2 Related Work Previous work devoted to improving language models in SMT mostly focus on two categories as we 1289 mentioned before1 : large language models (Zhang et al., 2006; Emami et al., 2007; Brants et al., 2007; Talbot and Osborne, 2007) and syntax-based language models (Charniak et al., 2003; Shen et al., 2008; Post and Gildea, 2008). Since our philosophy is fundamentally different from them in that we build contextually-informed language models by using backward n-grams and MI triggers, we discuss previous work that explore these two techniques (backward n-grams and MI triggers) in this section. Since the context “history” in the backward language model (BLM) is actually the future words to be generated, BLM is normally used in a postprocessing where all words have already been generated or in a scenario where sentences are proceeded from the ending to the beginning. Duchateau et al. (2002) use the BLM score as a confide"
P11-1129,P08-1066,0,0.2483,"from monolingual corpora (LDC news data or news data collected from web pages) that consist of billions or even trillions of English words, huge language models are built in a distributed manner (Zhang et al., 2006; Brants et al., 2007). Such language models yield better translation results but at the cost of huge storage and high computation. The second direction digs deeply into monolingual data to build linguistically-informed language models. For example, Charniak et al. (2003) present a syntax-based language model for machine translation which is trained on syntactic parse trees. Again, Shen et al. (2008) explore a dependency language model to improve translation quality. To some extent, these syntactically-informed language models are consistent with syntax-based translation models in capturing long-distance dependencies. In this paper, we pursue the second direction without resorting to any linguistic resources such as a syntactic parser. With a belief that a language model that embraces a larger context provides better prediction ability, we learn additional information from training data to enhance conventional n-gram language models and extend their ability to capture richer contexts and"
P11-1129,P07-1065,0,0.060148,"ork. Section 3 and 4 will elaborate the backward language model and the MI trigger model respectively in more detail, describe the training procedures and explain how the models are integrated into the phrase-based decoder. Section 5 will empirically evaluate the effectiveness of these two models. Section 6 will conduct an indepth analysis. In the end, we conclude in Section 7. 2 Related Work Previous work devoted to improving language models in SMT mostly focus on two categories as we 1289 mentioned before1 : large language models (Zhang et al., 2006; Emami et al., 2007; Brants et al., 2007; Talbot and Osborne, 2007) and syntax-based language models (Charniak et al., 2003; Shen et al., 2008; Post and Gildea, 2008). Since our philosophy is fundamentally different from them in that we build contextually-informed language models by using backward n-grams and MI triggers, we discuss previous work that explore these two techniques (backward n-grams and MI triggers) in this section. Since the context “history” in the backward language model (BLM) is actually the future words to be generated, BLM is normally used in a postprocessing where all words have already been generated or in a scenario where sentences are"
P11-1129,P96-1021,0,0.127851,"arkov assumption. In other words, when we predict the current word wi , we only consider the preceding n − 1 words wi−n+1 ...wi−1 instead of the whole context history w1 ...wi−1 . Different from the forward n-gram language model, the backward n-gram language model assigns a probability Pb (w1m ) to w1m by looking at the succeeding context according to Pb (w1m ) = m ∏ i=1 m )≈ P (wi |wi+1 m ∏ i+n−1 P (wi |wi+1 ) (2) i=1 3.1 Training et al., 2006) and 2) a standard phrase-based decoder (Koehn et al., 2003). Both decoders translate source sentences from the beginning of a sentence to the ending. Wu (1996) introduce a dynamic programming algorithm to integrate a forward bigram language model with inversion transduction grammar. His algorithm is then adapted and extended for integrating forward n-gram language models into synchronous CFGs by Chiang (2007). Our algorithms are different from theirs in two major aspects 1. The string input to the algorithms is in a reverse order. 2. We adopt a different way to calculate language model probabilities for partial hypotheses so that we can utilize incomplete n-grams. Before we introduce the integration algorithms, we define three functions P, L, and R"
P11-1129,J97-3002,0,0.0282538,"age model without any other changes. To be consistent with training, we also need to reverse the order of translation hypotheses when we access the trained backward language model2 . Note that the Markov context history of Eq. (2) is wi+n−1 ...wi+1 instead of wi+1 ...wi+n−1 after we invert the order. The words are the same but the order is completely reversed. 3.2 Decoding In this section, we will present two algorithms to integrate the backward n-gram language model into two kinds of phrase-based decoders respectively: 1) a CKY-style decoder that adopts bracketing transduction grammar (BTG) (Wu, 1997; Xiong 2 This is different from the reverse decoding in (Finch and Sumita, 2009) where source sentences are reversed in the order. 1290 {z } b (3) This function consists of two parts: • The first part (a) calculates incomplete n-gram language model probabilities for word wk to wk−n+2 . That means, we calculate the unigram probability for wk (P (wk )), bigram probability for wk−1 (P (wk−1 |wk )) and so on until we take n − 1-gram probability for wk−n+2 (P (wk−n+2 |wk ...wk−n+3 )). This resembles the way in which the forward language model probability in the future cost is computed in the stand"
P11-1129,P06-1066,1,0.940398,"2 )P (b1 |b2 ) P (a3 )P (a2 |a3 ) P (a3 )P (a2 |a3 )P (a1 |a3 a2 ) P (b3 )P (b2 |b3 )P (b1 |b3 b2 ) P (b2 )P (b1 |b2 ) P (a3 |b2 b1 )P (a2 |b1 a3 ) P (b3 )P (b2 |b3 )P (b1 |b3 b2 ) P (a3 |b2 b1 )P (a2 |b1 a3 )P (a1 |a3 a2 ) Table 1: Values of P, L, and R in a 3-gram example . (4) P(e2 e1 ) = P(e1 )P(e2 ) (5) The L and R function return the leftmost and rightmost n − 1 words from a string in a reverse order respectively. Following Chiang (2007), we describe our algorithms in a deductive system. We firstly show the algorithm3 that integrates the backward language model into a BTG-style decoder (Xiong et al., 2006) in Figure 1. The item [A, i, j; l|r] indicates that a BTG node A has been constructed spanning from i to j on the source side with the leftmost|rightmost n − 1 words l|r on the target side. As mentioned before, all target strings assessed by the defined functions (P, L, and R) are in an inverted order (denoted by e). We only display the backward language model probability for each item, ignoring all other scores such as phrase translation probabilities. The Eq. (8) in Figure 1 shows how we calculate the backward language model probability for the axiom which applies a BTG lexicon rule to tran"
P11-1129,W06-1626,0,0.307465,"1 words. Along with the efforts that advance translation models from word-based paradigm to syntax-based philosophy, in recent years we have also witnessed increasing efforts dedicated to extend standard n-gram language models for SMT. We roughly categorize these efforts into two directions: data-volume-oriented and data-depth-oriented. In the first direction, more data is better. In order to benefit from monolingual corpora (LDC news data or news data collected from web pages) that consist of billions or even trillions of English words, huge language models are built in a distributed manner (Zhang et al., 2006; Brants et al., 2007). Such language models yield better translation results but at the cost of huge storage and high computation. The second direction digs deeply into monolingual data to build linguistically-informed language models. For example, Charniak et al. (2003) present a syntax-based language model for machine translation which is trained on syntactic parse trees. Again, Shen et al. (2008) explore a dependency language model to improve translation quality. To some extent, these syntactically-informed language models are consistent with syntax-based translation models in capturing lo"
P11-1129,C04-1014,0,0.354464,"use the BLM score as a confidence measure to detect wrongly recognized words in speech recognition. Finch and Sumita (2009) use the BLM in their reverse translation decoder where source sentences are proceeded from the ending to the beginning. Our BLM is different from theirs in that we access the BLM during decoding (rather than after decoding) where source sentences are still proceeded from the beginning to the ending. Rosenfeld et al. (1994) introduce trigger pairs into a maximum entropy based language model as features. The trigger pairs are selected according to their mutual information. Zhou (2004) also propose an enhanced language model (MI-Ngram) which consists of a standard forward n-gram language model and an MI trigger model. The latter model measures the mutual information of distancedependent trigger pairs. Our MI trigger model is mostly inspired by the work of these two papers, especially by Zhou’s MI-Ngram model (2004). The difference is that our model is distance-independent and, of course, we are interested in an SMT problem rather than a speech recognition one. Raybaud et al. (2009) use MI triggers in their confidence measures to assess the quality of translation results aft"
P11-2027,P07-1038,0,0.0252942,"ational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency have been conducted in WMT after year 2007, a"
P11-2027,W05-0909,0,0.044527,"entation. Section 4 presents the results of the conducted comparative evaluations. Finally, section 5 presents the main conclusions and relevant issues to be dealt with in future research. 153 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 153–158, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation"
P11-2027,2005.eamt-1.15,0,0.0161368,"sociation for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency have been conducted i"
P11-2027,C04-1072,0,0.0335804,"llowed by Meteor and AM-FM, while NIST exhibits the lowest correlation coefficient values. Recall that our proposed AM-FM metric is not using reference translations for assessing translation quality, while the other three metrics are. In a similar exercise, the correlation coefficients were also computed at the sentence level (i.e. the units of analysis were sentences). These results are summarized in Table 3. As metrics are computed 4 As no development dataset was available for this particular task, a subset of the same evaluation dataset had to be used. at the sentence level, smoothed-bleu (Lin and Och, 2004) was used in this case. Again, all correlation coefficients presented in the table are statistically significant with p<0.01. Metric sBLEU NIST Meteor AM-FM Adequacy 0.3089 0.1208 0.3220 0.2142 Fluency 0.3361 0.0834 0.3065 0.2256 Metric sBLEU NIST Meteor AM-FM AM FM H Mean 0.3486 0.1201 0.3405 0.2406 Table 3: Pearson’s correlation coefficients (computed at the sentence level) between automatic metrics and human-generated scores As seen from the table, in this case, BLEU and Meteor are the metrics exhibiting the largest correlation coefficients, followed by AM-FM and NIST. 4.2 by looking at the"
P11-2027,P02-1040,0,0.0837101,"ork and the specific dataset that has been used in the experimental work. Section 3, provides details on the proposed AM-FM framework and the specific metric implementation. Section 4 presents the results of the conducted comparative evaluations. Finally, section 5 presents the main conclusions and relevant issues to be dealt with in future research. 153 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 153–158, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machi"
P11-2027,quirk-2004-training,0,0.0213381,"2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency h"
P11-2027,U05-1019,0,0.0123316,"on for Computational Linguistics:shortpapers, pages 153–158, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 Related Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset"
P11-2027,2009.mtsummit-papers.16,0,0.0462511,"lated Work and Dataset Although BLEU (Papineni et al., 2002) has become a de facto standard for machine translation evaluation, other metrics such as NIST (Doddington, 2002) and, more recently, Meteor (Banerjee and Lavie, 2005), are commonly used too. Regarding the specific idea of evaluating machine translation without using reference translations, several works have proposed and evaluated different approaches, including round-trip translation (Somers, 2005; Rapp, 2009), as well as other regression- and classification-based approaches (Quirk, 2004; Gamon et al., 2005; Albrecht and Hwa, 2007; Specia et al., 2009). As part of the recent efforts on machine translation evaluation, two workshops have been organizing shared-tasks and evaluation campaigns over the last four years: the NIST Metrics for Machine Translation Challenge 1 (MetricsMATR) and the Workshop on Statistical Machine Translation 2 (WMT); which were actually held as one single event in their most recent edition in 2010. The dataset used in this work corresponds to WMT-07. This dataset is used, instead of a more recent one, because no human judgments on adequacy and fluency have been conducted in WMT after year 2007, and human evaluation da"
P11-2027,C04-1046,0,\N,Missing
P11-2027,W07-0718,0,\N,Missing
P11-2027,P09-2034,0,\N,Missing
P12-1023,W06-2920,0,0.149607,"Missing"
P12-1023,D07-1101,0,0.447259,"irstly we utilize rich high-order features defined over a view of large scope and additional large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. McDonald et al. (2005) and Covington (2001) develop models that represent first-order features over a single arc in graphs. By extending the firstorder model, McDonald and Pereira (2006) and Carreras (2007) exploit second-order features over two adjacent arcs in second-order models. Koo and Collins (2010) further propose a third-order model that uses third-order features. These models utilize higher-order feature representations and achieve better performance than the first-order models. But this achievement is at the cost of the higher decoding complexity, from O(n2 ) to O(n4 ), where n is the length of the input sentence. Thus, it is very hard to develop higher-order models further in this way. 1 Introduction In recent years, there are many data-driven models that have been proposed for depend"
P12-1023,I08-1012,1,0.920814,"on words of WSJ text.3 We used the MXPOST tagger trained on training data to assign part-of-speech tags and used the Baseline parser to process the sentences of the BLLIP corpus. For Chinese, we used the Chinese Treebank (CTB) version 4.04 in the experiments. We also used the “Penn2Malt” tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work (Chen et al., 2008; Yu et al., 2008; Chen et al., 2009). For the unannotated data, we used the XIN CMN portion of Chinese Gigaword5 Version 2.0 (LDC2009T14) (Huang, 2009), 2 http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. 4 http://www.cis.upenn.edu/˜chinese/. 5 We excluded the sentences of the CTB data from the Gigaword data 3 which has approximately 311 million words whose segmentation and POS tags are given. We discarded the annotations due to the differences in annotation policy between CTB and this"
P12-1023,D09-1060,1,0.857031,"XPOST tagger trained on training data to assign part-of-speech tags and used the Baseline parser to process the sentences of the BLLIP corpus. For Chinese, we used the Chinese Treebank (CTB) version 4.04 in the experiments. We also used the “Penn2Malt” tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work (Chen et al., 2008; Yu et al., 2008; Chen et al., 2009). For the unannotated data, we used the XIN CMN portion of Chinese Gigaword5 Version 2.0 (LDC2009T14) (Huang, 2009), 2 http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. 4 http://www.cis.upenn.edu/˜chinese/. 5 We excluded the sentences of the CTB data from the Gigaword data 3 which has approximately 311 million words whose segmentation and POS tags are given. We discarded the annotations due to the differences in annotation policy between CTB and this corpus. We used the MMA system (Kruen"
P12-1023,C96-1058,0,0.393535,"n et al., 2008). We can use an original parser to produce the K-best list. This method has the potential to be very fast. However, because the performance of this method is restricted to the K-best list, we may have to set K to a high number in order to find the best parsing tree (with DLM) or a tree acceptably close to the best (Shen et al., 2008). 4.2 created from pairs of smaller ones in a bottom-up style. In the following figures, complete items are represented by triangles and incomplete items are represented by trapezoids. Figure 2 illustrates the cubic parsing actions of the algorithm (Eisner, 1996) in the right direction, where s, r, and t refer to the start and end indices of the chart items. In Figure 2-(a), all the items on the left side are complete and the algorithm creates the incomplete item (trapezoid on the right side) of s – t. This action builds a dependency relation from s to t. In Figure 2-(b), the item of s – r is incomplete and the item of r – t is complete. Then the algorithm creates the complete item of s – t. In this action, all the children of r are generated. In Figure 2, the longer vertical edge in a triangle or a trapezoid corresponds to the subroot of the structur"
P12-1023,P10-1001,0,0.261279,"large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. McDonald et al. (2005) and Covington (2001) develop models that represent first-order features over a single arc in graphs. By extending the firstorder model, McDonald and Pereira (2006) and Carreras (2007) exploit second-order features over two adjacent arcs in second-order models. Koo and Collins (2010) further propose a third-order model that uses third-order features. These models utilize higher-order feature representations and achieve better performance than the first-order models. But this achievement is at the cost of the higher decoding complexity, from O(n2 ) to O(n4 ), where n is the length of the input sentence. Thus, it is very hard to develop higher-order models further in this way. 1 Introduction In recent years, there are many data-driven models that have been proposed for dependency parsing (McDonald and Nivre, 2007). Among them, graphbased dependency parsing models have achie"
P12-1023,P08-1068,0,0.18586,"mpared, where McDonald06 refers to the second-order parser of McDonald 219 System McDonald06 Koo08-standard Koo10-model1 Koo08-dep2c Suzuki09 Chen09-ord2s Zhou11 MSTB-DLM2 UAS 91.5 92.02 93.04 93.16 93.79 92.51 92.64 92.76 Cost O(n3 ) O(n4 ) O(n4 ) O(n4 ) O(n4 ) O(n3 ) O(n4 ) O(Kn3 ) Table 7: Relevant results for English. G denotes the supervised graph-based parsers, S denotes the graph-based parsers with semi-supervised methods, D denotes our new parsers 6.7 Table 6: Main results for Chinese 6.6 and Pereira (2006), Koo08-standard refers to the second-order parser with the features defined in Koo et al. (2008), Koo10-model1 refers to the third-order parser with model1 of Koo and Collins (2010), Koo08-dep2c refers to the second-order parser with cluster-based features of (Koo et al., 2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09-ord2s refers to the second-order parser with subtree-based features of Chen et al. (2009), and Zhou11 refers to the second-order parser with web-derived selectional preference features of Zhou et al. (2011). The results showed that our MSTB-DLM2 obtained the comparable accuracy with the previous state-of-the-art systems. Koo10-model1 (Koo and Collins,"
P12-1023,P09-1058,0,0.0270839,"2009). For the unannotated data, we used the XIN CMN portion of Chinese Gigaword5 Version 2.0 (LDC2009T14) (Huang, 2009), 2 http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. 4 http://www.cis.upenn.edu/˜chinese/. 5 We excluded the sentences of the CTB data from the Gigaword data 3 which has approximately 311 million words whose segmentation and POS tags are given. We discarded the annotations due to the differences in annotation policy between CTB and this corpus. We used the MMA system (Kruengkrai et al., 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse all the sentences in the data. 6.2 set for English. We added the DLM-based features to MST1. Figure 4 shows the UAS curves on the development set, where K is beam size for Intersect and K-best for Rescoring, the X-axis represents K, and the Y-axis represents the UAS scores. The parsing performance generally increased as the K increased. The parser with Intersect always outperformed the one with Rescoring. Features for basic and enhanced parsers 0.928 0.926 System MST1 MSTB1 MST2 MST"
P12-1023,J93-2004,0,0.0440292,"Missing"
P12-1023,P06-1043,0,0.0373156,"s from a large amount of data and used them as the additional features to improve dependency parsing. They approaches were still restricted in a small number of arcs in the graphs. Suzuki et al. (2009) presented a semisupervised learning approach. They extended a Semi-supervised Structured Conditional Model (SSSCM)(Suzuki and Isozaki, 2008) to the dependency parsing problem and combined their method with the approach of Koo et al. (2008). In future work, we may consider apply their methods on our parsers to improve further. Another group of methods are the cotraining/self-training techniques. McClosky et al. (2006) presented a self-training approach for phrase structure parsing. Sagae and Tsujii (2007) used the co-training technique to improve performance. First, two parsers were used to parse the sentences in unannotated data. Then they selected some sentences which have the same trees produced by those two parsers. They retrained a parser on newly parsed sentences and the original labeled data. We are able to use the output of our systems for co-training/self-training techniques. 9 Conclusion We have presented an approach to utilizing the dependency language model to improve graph-based dependency par"
P12-1023,D07-1013,0,0.302751,"d-order features over two adjacent arcs in second-order models. Koo and Collins (2010) further propose a third-order model that uses third-order features. These models utilize higher-order feature representations and achieve better performance than the first-order models. But this achievement is at the cost of the higher decoding complexity, from O(n2 ) to O(n4 ), where n is the length of the input sentence. Thus, it is very hard to develop higher-order models further in this way. 1 Introduction In recent years, there are many data-driven models that have been proposed for dependency parsing (McDonald and Nivre, 2007). Among them, graphbased dependency parsing models have achieved state-of-the-art performance for a wide range of languages as shown in recent CoNLL shared tasks ∗ Corresponding author How to enrich high-order feature representations without increasing the decoding complexity for graph-based models becomes a very challenging problem in the dependency parsing task. In this paper, we solve this issue by enriching the feature representations for a graph-based model using a dependency language model (DLM) (Shen et al., 2008). The N-gram DLM has the ability to predict the next child based on the N-"
P12-1023,E06-1011,0,0.437851,"r approach has two advantages. Firstly we utilize rich high-order features defined over a view of large scope and additional large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. McDonald et al. (2005) and Covington (2001) develop models that represent first-order features over a single arc in graphs. By extending the firstorder model, McDonald and Pereira (2006) and Carreras (2007) exploit second-order features over two adjacent arcs in second-order models. Koo and Collins (2010) further propose a third-order model that uses third-order features. These models utilize higher-order feature representations and achieve better performance than the first-order models. But this achievement is at the cost of the higher decoding complexity, from O(n2 ) to O(n4 ), where n is the length of the input sentence. Thus, it is very hard to develop higher-order models further in this way. 1 Introduction In recent years, there are many data-driven models that have been"
P12-1023,P05-1012,0,0.412625,"epresent a set of features for the parsing model. Finally, the features are efficiently integrated into the parsing model during decoding using beam search. Our approach has two advantages. Firstly we utilize rich high-order features defined over a view of large scope and additional large raw corpus. Secondly our approach does not increase the decoding complexity. We evaluate the proposed approach on English and Chinese data. The experimental results show that our new parser achieves the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. McDonald et al. (2005) and Covington (2001) develop models that represent first-order features over a single arc in graphs. By extending the firstorder model, McDonald and Pereira (2006) and Carreras (2007) exploit second-order features over two adjacent arcs in second-order models. Koo and Collins (2010) further propose a third-order model that uses third-order features. These models utilize higher-order feature representations and achieve better performance than the first-order models. But this achievement is at the cost of the higher decoding complexity, from O(n2 ) to O(n4 ), where n is the length of the input"
P12-1023,W04-2407,0,0.0332134,"Missing"
P12-1023,W96-0213,0,0.364741,"Missing"
P12-1023,D07-1111,0,0.0671497,"ency parsing. They approaches were still restricted in a small number of arcs in the graphs. Suzuki et al. (2009) presented a semisupervised learning approach. They extended a Semi-supervised Structured Conditional Model (SSSCM)(Suzuki and Isozaki, 2008) to the dependency parsing problem and combined their method with the approach of Koo et al. (2008). In future work, we may consider apply their methods on our parsers to improve further. Another group of methods are the cotraining/self-training techniques. McClosky et al. (2006) presented a self-training approach for phrase structure parsing. Sagae and Tsujii (2007) used the co-training technique to improve performance. First, two parsers were used to parse the sentences in unannotated data. Then they selected some sentences which have the same trees produced by those two parsers. They retrained a parser on newly parsed sentences and the original labeled data. We are able to use the output of our systems for co-training/self-training techniques. 9 Conclusion We have presented an approach to utilizing the dependency language model to improve graph-based dependency parsing. We represent new features based on the dependency language model and integrate them"
P12-1023,P08-1066,0,0.757145,"data-driven models that have been proposed for dependency parsing (McDonald and Nivre, 2007). Among them, graphbased dependency parsing models have achieved state-of-the-art performance for a wide range of languages as shown in recent CoNLL shared tasks ∗ Corresponding author How to enrich high-order feature representations without increasing the decoding complexity for graph-based models becomes a very challenging problem in the dependency parsing task. In this paper, we solve this issue by enriching the feature representations for a graph-based model using a dependency language model (DLM) (Shen et al., 2008). The N-gram DLM has the ability to predict the next child based on the N-1 immediate previous children and their head (Shen et al., 2008). The basic idea behind is that we use the DLM to evaluate whether a valid dependency tree (McDonald and Nivre, 2007) 213 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 213–222, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics is well-formed from a view of large scope. The parsing model searches for the final dependency trees by considering the original scores and the sc"
P12-1023,P08-1076,0,0.265603,"(2009), Chen09-ord2s refers to the second-order parser with subtree-based features of Chen et al. (2009), and Zhou11 refers to the second-order parser with web-derived selectional preference features of Zhou et al. (2011). The results showed that our MSTB-DLM2 obtained the comparable accuracy with the previous state-of-the-art systems. Koo10-model1 (Koo and Collins, 2010) used the third-order features and achieved the best reported result among the supervised parsers. Suzuki2009 (Suzuki et al., 2009) reported the best reported result by combining a Semisupervised Structured Conditional Model (Suzuki and Isozaki, 2008) with the method of (Koo et al., 2008). However, their decoding complexities were higher than ours and we believe that the performance of our parser can be further enhanced by integrating their methods with our parser. Compare with previous work on Chinese Table 8 shows the comparative results, where Chen08 refers to the parser of (Chen et al., 2008), Yu08 refers to the parser of (Yu et al., 2008), Zhao09 refers to the parser of (Zhao et al., 2009), and Chen09-ord2s refers to the second-order parser with subtree-based features of Chen et al. (2009). The results showed that our score for this d"
P12-1023,D09-1058,0,0.366989,"O(n4 ) O(n4 ) O(n4 ) O(n4 ) O(n3 ) O(n4 ) O(Kn3 ) Table 7: Relevant results for English. G denotes the supervised graph-based parsers, S denotes the graph-based parsers with semi-supervised methods, D denotes our new parsers 6.7 Table 6: Main results for Chinese 6.6 and Pereira (2006), Koo08-standard refers to the second-order parser with the features defined in Koo et al. (2008), Koo10-model1 refers to the third-order parser with model1 of Koo and Collins (2010), Koo08-dep2c refers to the second-order parser with cluster-based features of (Koo et al., 2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09-ord2s refers to the second-order parser with subtree-based features of Chen et al. (2009), and Zhou11 refers to the second-order parser with web-derived selectional preference features of Zhou et al. (2011). The results showed that our MSTB-DLM2 obtained the comparable accuracy with the previous state-of-the-art systems. Koo10-model1 (Koo and Collins, 2010) used the third-order features and achieved the best reported result among the supervised parsers. Suzuki2009 (Suzuki et al., 2009) reported the best reported result by combining a Semisupervised Structured Conditional Model (Suzuki"
P12-1023,W03-3023,0,0.67974,"Missing"
P12-1023,C08-1132,0,0.307062,"t.3 We used the MXPOST tagger trained on training data to assign part-of-speech tags and used the Baseline parser to process the sentences of the BLLIP corpus. For Chinese, we used the Chinese Treebank (CTB) version 4.04 in the experiments. We also used the “Penn2Malt” tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development. We used gold standard segmentation and part-of-speech tags in the CTB. The data partition and part-of-speech settings were chosen to match previous work (Chen et al., 2008; Yu et al., 2008; Chen et al., 2009). For the unannotated data, we used the XIN CMN portion of Chinese Gigaword5 Version 2.0 (LDC2009T14) (Huang, 2009), 2 http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html We ensured that the text used for extracting subtrees did not include the sentences of the Penn Treebank. 4 http://www.cis.upenn.edu/˜chinese/. 5 We excluded the sentences of the CTB data from the Gigaword data 3 which has approximately 311 million words whose segmentation and POS tags are given. We discarded the annotations due to the differences in annotation policy between CTB and this corpus. We used t"
P12-1023,D08-1059,0,0.094736,"algorithm is in the bottom-up style, the nearer children are generated earlier than the farther ones of the same head. Thus, we calculate the left or right side probability for a new child when a new dependency relation is built. For Figure 2-(a), we add the features of PRc (xt |HIS). Figure 3 shows the structure, where cRs refers to the current children (nearer than xt ) of xs . In the figure, HIS includes cRs and xs . Figure 3: Add DLM-based features in cubic parsing We use beam search to choose the one having the overall best score as the final parse, where K spans are built at each step (Zhang and Clark, 2008). At each step, we perform the parsing actions in the current beam and then choose the best K resulting spans for the next step. The time complexity of the new decoding algorithm is O(Kn3 ) while the original one is O(n3 ), where n is the length of the input sentence. With the rich feature set in Table 1, the running time of Intersect is longer than the time of Rescoring. But Intersect considers more combination of spans with the DLM-based features than Rescoring that is only given a K-best list. 5 Implementation Details 5.1 Baseline parser We implement our parsers based on the MSTParser1 , a"
P12-1023,P09-1007,0,0.0234185,"ised parsers. Suzuki2009 (Suzuki et al., 2009) reported the best reported result by combining a Semisupervised Structured Conditional Model (Suzuki and Isozaki, 2008) with the method of (Koo et al., 2008). However, their decoding complexities were higher than ours and we believe that the performance of our parser can be further enhanced by integrating their methods with our parser. Compare with previous work on Chinese Table 8 shows the comparative results, where Chen08 refers to the parser of (Chen et al., 2008), Yu08 refers to the parser of (Yu et al., 2008), Zhao09 refers to the parser of (Zhao et al., 2009), and Chen09-ord2s refers to the second-order parser with subtree-based features of Chen et al. (2009). The results showed that our score for this data was the best reported so far and significantly higher than the previous scores. System Chen08 Yu08 Zhao09 Chen09-ord2s MSTB-DLM2 UAS 86.52 87.26 87.0 89.43 91.59 Table 8: Relevant results for Chinese 7 Analysis Dependency parsers tend to perform worse on heads which have many children. Here, we studied the effect of DLM-based features for this structure. We calculated the number of children for each head and listed the accuracy changes for diff"
P12-1023,P11-1156,0,0.277527,"Missing"
P12-1023,D07-1096,0,\N,Missing
P12-1095,W11-2136,0,0.123696,"rectly project semantic roles from the source side to the target side through word alignments during decoding (Liu and Gildea, 2010). There are other previous studies that explore only source side predicate-argument structures. Komachi and Matsumoto (2006) reorder arguments in source language (Japanese) sentences using heuristic rules defined on source side predicate-argument structures in a pre-processing step. Wu et al. (2011) automate this procedure by automatically extracting reordering rules from predicate-argument structures and applying these rules to reorder source language sentences. Aziz et al. (2011) incorporate source language semantic role labels into a tree-to-string SMT system. Although we also focus on source side predicateargument structures, our models differ from the previous work in two main aspects: 1) we propose two separate discriminative models to exploit predicateargument structures for predicate translation and argument reordering respectively; 2) we consider argument reordering as an argument movement (rel903 ative to its predicate) prediction problem and use a discriminatively trained classifier for such predictions. Our predicate translation model is also related to prev"
P12-1095,J96-1002,0,0.0224461,"s into a tree-to-string SMT system. Although we also focus on source side predicateargument structures, our models differ from the previous work in two main aspects: 1) we propose two separate discriminative models to exploit predicateargument structures for predicate translation and argument reordering respectively; 2) we consider argument reordering as an argument movement (rel903 ative to its predicate) prediction problem and use a discriminatively trained classifier for such predictions. Our predicate translation model is also related to previous discriminative lexicon translation models (Berger et al., 1996; Venkatapathy and Bangalore, 2007; Mauser et al., 2009). While previous models predict translations for all words in vocabulary, we only focus on verbal predicates. This will tremendously reduce the amount of training data required, which usually is a problem in discriminative lexicon translation models (Mauser et al., 2009). Furthermore, the proposed translation model also differs from previous lexicon translation models in that we use both lexical and semantic features. Our experimental results show that semantic features are able to further improve translation accuracy. 3 Predicate Transla"
P12-1095,J07-2003,0,0.609026,"tion 3.3 to train the maximum entropy classifier as formulated in Eq. (4). We perform 100 iterations of L-BFGS. 5 Integrating the Two Models into SMT In this section, we elaborate how to integrate the two models into phrase-based SMT. In particular, we integrate the models into a phrase-based system which uses bracketing transduction grammars (BTG) (Wu, 1997) for phrasal translation (Xiong et al., 2006). Since the system is based on a CKY-style decoder, the integration algorithms introduced here can be easily adapted to other CKY-based decoding systems such as the hierarchical phrasal system (Chiang, 2007). 5.1 Integrating the Predicate Translation Model It is straightforward to integrate the predicate translation model into phrase-based SMT (Koehn et al., 906 2003; Xiong et al., 2006). We maintain word alignments for each phrase pair in the phrase table. Given a source sentence with its predicateargument structure, we detect all verbal predicates and load trained predicate translation classifiers for these verbs. Whenever a hypothesis covers a new verbal predicate v, we find the target translation e for v through word alignments and then calculate its translation probability pt (e|C(v)) accord"
P12-1095,N03-1017,0,0.107241,"(v).Ah1 = d e = adjourn and C(v).Ar2 = null e = adjourn and C(v).Ah3 = null This will increase the number of classes to be predicted by the maximum entropy classifier. But according to our observation, it is still computationally tractable (see Section 3.3). If a verbal predicate is not translated, we set e = NULL so that we can also capture null translations for verbal predicates. Table 1: Semantic feature examples. 3.2 Features The apparent advantage of discriminative lexicon translation models over generative translation models (e.g., conventional lexical translation model as described in (Koehn et al., 2003)) is that discriminative models allow us to integrate richer contexts (lexical, syntactic or semantic) into target translation prediction. We use two kinds of features to predict translations for verbal predicates: 1) lexical features and 2) semantic features. All features are in the following binary form. f (e, C(v)) =  1, if e = ♣ and C(v).♥ = ♠ 0, else (3) where the symbol ♣ is a placeholder for a possible target translation (up to 4 words), the symbol ♥ indicates a contextual (lexical or semantic) element for the verbal predicate v, and the symbol ♠ represents the value of ♥. Lexical Feat"
P12-1095,W04-3250,0,0.219224,"ntic role labeler6 (Li et al., 2010) on all source parse trees to annotate semantic roles for all verbal predicates. After we obtained semantic roles on the source side, we extracted features as described in Section 3.2 and 4.2 and used these features to train our two models as described in Section 3.3 and 4.3. We used the NIST MT03 evaluation test data as our development set, and the NIST MT04, MT05 as the test sets. We adopted the case-insensitive BLEU-4 (Papineni et al., 2002) as the evaluation metric. Statistical significance in BLEU differences was tested by paired bootstrap re-sampling (Koehn, 2004). 6.2 Results Our first group of experiments is to investigate whether the predicate translation model is able to improve translation accuracy in terms of BLEU and whether semantic features are useful. The experimental results are shown in Table 4. From the table, we have the following two observations. • The proposed predicate translation models achieve an average improvement of 0.57 BLEU points across the two NIST test sets when all features (lex+sem) are used. Such an improvement is statistically significant (p < 0.01). According to our statistics, there are 5.07 verbal predicates per sente"
P12-1095,2006.iwslt-evaluation.11,0,0.121648,"ork. As PAS analysis widely employs global and sentence-wide features, it is computationally expensive to integrate target side predicateargument structures into the dynamic programming style of SMT decoding (Wu and Fung, 2009b). Therefore they either postpone the integration of target side PASs until the whole decoding procedure is completed (Wu and Fung, 2009b), or directly project semantic roles from the source side to the target side through word alignments during decoding (Liu and Gildea, 2010). There are other previous studies that explore only source side predicate-argument structures. Komachi and Matsumoto (2006) reorder arguments in source language (Japanese) sentences using heuristic rules defined on source side predicate-argument structures in a pre-processing step. Wu et al. (2011) automate this procedure by automatically extracting reordering rules from predicate-argument structures and applying these rules to reorder source language sentences. Aziz et al. (2011) incorporate source language semantic role labels into a tree-to-string SMT system. Although we also focus on source side predicateargument structures, our models differ from the previous work in two main aspects: 1) we propose two separa"
P12-1095,P10-1113,0,0.215021,"Missing"
P12-1095,C10-1081,0,0.636321,"nt reordering model automatically predicts the moving direction of an argument relative to its predicate after translation using semantic features. The two models are integrated into a state-of-theart phrase-based machine translation system and evaluated on Chinese-to-English translation tasks with large-scale training data. Experimental results demonstrate that the two models significantly improve translation accuracy. 1 Introduction Recent years have witnessed increasing efforts towards integrating predicate-argument structures into statistical machine translation (SMT) (Wu and Fung, 2009b; Liu and Gildea, 2010). In this paper, we take a step forward by introducing a novel approach to incorporate such semantic structures into SMT. Given a source side predicate-argument structure, we attempt to translate each semantic frame (predicate and its associated arguments) into an appropriate target string. We believe that the translation of predicates and reordering of arguments are the two central ∗ issues concerning the transfer of predicate-argument structure across languages. Predicates1 are essential elements in sentences. Unfortunately they are usually neither correctly translated nor translated at all"
P12-1095,D09-1022,0,0.0179658,"cus on source side predicateargument structures, our models differ from the previous work in two main aspects: 1) we propose two separate discriminative models to exploit predicateargument structures for predicate translation and argument reordering respectively; 2) we consider argument reordering as an argument movement (rel903 ative to its predicate) prediction problem and use a discriminatively trained classifier for such predictions. Our predicate translation model is also related to previous discriminative lexicon translation models (Berger et al., 1996; Venkatapathy and Bangalore, 2007; Mauser et al., 2009). While previous models predict translations for all words in vocabulary, we only focus on verbal predicates. This will tremendously reduce the amount of training data required, which usually is a problem in discriminative lexicon translation models (Mauser et al., 2009). Furthermore, the proposed translation model also differs from previous lexicon translation models in that we use both lexical and semantic features. Our experimental results show that semantic features are able to further improve translation accuracy. 3 Predicate Translation Model In this section, we present the features and"
P12-1095,P02-1040,0,0.0970476,"ordering model, we first parsed all source sentences using the Berkeley Chinese parser (Petrov et al., 2006) and then ran the Chinese semantic role labeler6 (Li et al., 2010) on all source parse trees to annotate semantic roles for all verbal predicates. After we obtained semantic roles on the source side, we extracted features as described in Section 3.2 and 4.2 and used these features to train our two models as described in Section 3.3 and 4.3. We used the NIST MT03 evaluation test data as our development set, and the NIST MT04, MT05 as the test sets. We adopted the case-insensitive BLEU-4 (Papineni et al., 2002) as the evaluation metric. Statistical significance in BLEU differences was tested by paired bootstrap re-sampling (Koehn, 2004). 6.2 Results Our first group of experiments is to investigate whether the predicate translation model is able to improve translation accuracy in terms of BLEU and whether semantic features are useful. The experimental results are shown in Table 4. From the table, we have the following two observations. • The proposed predicate translation models achieve an average improvement of 0.57 BLEU points across the two NIST test sets when all features (lex+sem) are used. Such"
P12-1095,P06-1055,0,0.00611792,"rs with 96.9M Chinese words and 109.5M English words. We ran GIZA++ on these corpora in both directions and then applied the “grow-diag-final” refinement rule to obtain word alignments. We then used all these word-aligned corpora to generate our phrase table. Our 5-gram language model was trained on the Xinhua section of the English Gigaword corpus (306 million words) using the SRILM toolkit (Stolcke, 2002) with modified Kneser-Ney smoothing. To train the proposed predicate translation model and argument reordering model, we first parsed all source sentences using the Berkeley Chinese parser (Petrov et al., 2006) and then ran the Chinese semantic role labeler6 (Li et al., 2010) on all source parse trees to annotate semantic roles for all verbal predicates. After we obtained semantic roles on the source side, we extracted features as described in Section 3.2 and 4.2 and used these features to train our two models as described in Section 3.3 and 4.3. We used the NIST MT03 evaluation test data as our development set, and the NIST MT04, MT05 as the test sets. We adopted the case-insensitive BLEU-4 (Papineni et al., 2002) as the evaluation metric. Statistical significance in BLEU differences was tested by"
P12-1095,W07-0413,0,0.0437434,"Missing"
P12-1095,2009.eamt-1.30,0,0.497454,"redicate. The argument reordering model automatically predicts the moving direction of an argument relative to its predicate after translation using semantic features. The two models are integrated into a state-of-theart phrase-based machine translation system and evaluated on Chinese-to-English translation tasks with large-scale training data. Experimental results demonstrate that the two models significantly improve translation accuracy. 1 Introduction Recent years have witnessed increasing efforts towards integrating predicate-argument structures into statistical machine translation (SMT) (Wu and Fung, 2009b; Liu and Gildea, 2010). In this paper, we take a step forward by introducing a novel approach to incorporate such semantic structures into SMT. Given a source side predicate-argument structure, we attempt to translate each semantic frame (predicate and its associated arguments) into an appropriate target string. We believe that the translation of predicates and reordering of arguments are the two central ∗ issues concerning the transfer of predicate-argument structure across languages. Predicates1 are essential elements in sentences. Unfortunately they are usually neither correctly translate"
P12-1095,N09-2004,0,0.55119,"redicate. The argument reordering model automatically predicts the moving direction of an argument relative to its predicate after translation using semantic features. The two models are integrated into a state-of-theart phrase-based machine translation system and evaluated on Chinese-to-English translation tasks with large-scale training data. Experimental results demonstrate that the two models significantly improve translation accuracy. 1 Introduction Recent years have witnessed increasing efforts towards integrating predicate-argument structures into statistical machine translation (SMT) (Wu and Fung, 2009b; Liu and Gildea, 2010). In this paper, we take a step forward by introducing a novel approach to incorporate such semantic structures into SMT. Given a source side predicate-argument structure, we attempt to translate each semantic frame (predicate and its associated arguments) into an appropriate target string. We believe that the translation of predicates and reordering of arguments are the two central ∗ issues concerning the transfer of predicate-argument structure across languages. Predicates1 are essential elements in sentences. Unfortunately they are usually neither correctly translate"
P12-1095,I11-1004,0,0.200715,"yle of SMT decoding (Wu and Fung, 2009b). Therefore they either postpone the integration of target side PASs until the whole decoding procedure is completed (Wu and Fung, 2009b), or directly project semantic roles from the source side to the target side through word alignments during decoding (Liu and Gildea, 2010). There are other previous studies that explore only source side predicate-argument structures. Komachi and Matsumoto (2006) reorder arguments in source language (Japanese) sentences using heuristic rules defined on source side predicate-argument structures in a pre-processing step. Wu et al. (2011) automate this procedure by automatically extracting reordering rules from predicate-argument structures and applying these rules to reorder source language sentences. Aziz et al. (2011) incorporate source language semantic role labels into a tree-to-string SMT system. Although we also focus on source side predicateargument structures, our models differ from the previous work in two main aspects: 1) we propose two separate discriminative models to exploit predicateargument structures for predicate translation and argument reordering respectively; 2) we consider argument reordering as an argume"
P12-1095,J97-3002,0,0.28733,"Missing"
P12-1095,P06-1066,1,0.600139,"): the function finds all predicateargument pairs that cross the two neighboring spans (i, k) and (k + 1, j). S It can be formulated as A(i, j, τ ) − (A(i, k, τ ) A(k + 1, j, τ )). We then define another function Pr to calculate the argument reordering model probability on all arguments which are found by the previous two functions A and N as follows. Y Pr (B) = pr (mA |C(A)) (6) A∈B where B denotes either A or N . Following (Chiang, 2007), we describe the algorithm in a deductive system. It is shown in Figure 2. The algorithm integrates the argument reordering model into a CKY-style decoder (Xiong et al., 2006). The item [X, i, j] denotes a BTG node X spanning from i to j on the source side. For notational convenience, we only show the argument reordering model probability for each item, ignoring all other sub-model probabilities such as the language model probability. The Eq. (7) shows how we calculate the argument reordering model probability when a lexical rule is applied to translate a source phrase c to a target phrase e. The Eq. (8) shows how we compute the argument reordering model probability for a span (i, j) in a dynamic programming manner when a merging rule is applied to combine its two"
P12-1095,J08-2004,0,0.0947935,"tly translated nor translated at all in many SMT systems according to the error study by Wu and Fung (2009a). This suggests that conventional lexical and phrasal translation models adopted in those SMT systems are not sufficient to correctly translate predicates in source sentences. Thus we propose a discriminative, feature-based predicate translation model that captures not only lexical information (i.e., surrounding words) but also high-level semantic contexts to correctly translate predicates. Arguments contain information for questions of who, what, when, where, why, and how in sentences (Xue, 2008). One common error in translating arguments is about their reorderings: arguments are placed at incorrect positions after translation. In order to reduce such errors, we introduce a discriminative argument reordering model that uses the position of a predicate as the reference axis to estimate positions of its associated arguments on the target side. In this way, the model predicts moving directions of arguments relative to their predicates with semantic features. We integrate these two discriminative models into a state-of-the-art phrase-based system. Experimental results on large-scale Chine"
P12-3007,W10-4351,0,0.0208001,"samples. Additional strategies allowing for system adaptation and learning implemented over the same vector model space framework are also described and discussed. 1 Introduction Dialogue systems have been gaining popularity recently as the demand for such kind of applications have increased in many different areas. Additionally, recent advances in other related language technologies such as speech recognition, discourse analysis and natural language understanding have made possible for dialogue systems to find practical applications that are commercially exploitable (Pieraccini et al., 2009; Griol et al., 2010). From the application point of view, dialogue systems can be categorized into two major classes: task-oriented and chat-oriented. In the case of taskoriented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participa"
P12-3007,W03-2112,0,0.124206,"ted systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al., 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is performed by computing the cosine similarity metric into the vector space model representation, in which each utterance in the dialogue database is represented by a vector. Different from example-based question answering systems (Vicedo, 2002; Xue et al., 2008), IRIS uses a dual search strategy. In addition to the current user input, which is compared with all existent utterances in the database, a vector representation o"
P12-3007,W03-2108,0,0.0275964,"ented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al., 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is performed by computing the cosine similarity metric into the vector space model represent"
P12-3007,W10-2705,0,0.0365337,"ms, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational point of view, IRIS belongs to the category of example-based dialogue systems (Murao et al., 2003). Its dialogue strategy is supported by a large database of dialogues that is used to provide candidate responses to a given user input. The search for candidate responses is performed by computing the cosine similarity metric into the vector space model representation, in which"
P12-3007,P12-2040,1,0.20203,"its last selected utterance towards the vector space representation of the previous user turn, so that the probability of generating the same response given a similar user input will be increased.  Discourage (–): IRIS will push the vector space representation of its last selected utterance apart from the vector space representation of the previous user turn, so that the probability of generating the same response given a similar user input will be decreased. 2.2 Dialogue Data Collection For the current implementation of IRIS, a subset of the Movie-DiC dialogue data collection has been used (Banchs, 2012). Movie-DiC is a dialogue corpus that has been extracted from movie scripts which are freely available at The Internet Movie Script Data Collection (http://www.imsdb.com/). In this subsection, we present a brief description on the specific data subset used for the implementation of IRIS, as well as we briefly review the process followed for collecting the data and extracting the dialogues. First of all, dialogues have to be identified and parsed from the collected html files. Three basic elements are extracted from the scripts: speakers, utterances and context. The speaker and utterance elemen"
P12-3007,A97-1006,0,0.305741,"ion, discourse analysis and natural language understanding have made possible for dialogue systems to find practical applications that are commercially exploitable (Pieraccini et al., 2009; Griol et al., 2010). From the application point of view, dialogue systems can be categorized into two major classes: task-oriented and chat-oriented. In the case of taskoriented dialogue systems, the main objective of such a system is to help the user to complete a task, which typically includes booking transportation or accommodation services, requesting specific information from a service facility, etc. (Busemann et al., 1997; Seneff and Polifroni, 2000; Stallard, 2000). On the other hand, chat-oriented systems are not intended to help the user completing any specific task, but to provide a means for participating in a game, or just for chitchat or entertainment. Typical examples of chat-oriented dialogue systems are the so called chat bots (Weizenbaum, 1966; Ogura et al., 2003, Wallis, 2010). In this paper, we introduce IRIS (Informal Response Interactive System), a chat-oriented dialogue system that is based on the vector space model framework (Salton et al., 1975; van Rijsbergen, 2005). From the operational poi"
P12-3007,A00-1010,0,\N,Missing
P13-2034,P09-2067,0,0.0321081,"Missing"
P13-2034,P06-1004,0,0.0670156,"Missing"
P13-2034,P97-1048,0,0.129621,"on refers to partitioning a multimedia stream into homogenous segments each embodying a main topic or coherent story (Allan, 2002). With the explosive growth of multimedia data, it becomes difficult to retrieve the most relevant components. For indexing broadcast news programs, it is desirable to divide each of them into a number of independent stories. Manual segmentation is accurate but labor-intensive and costly. Therefore, automatic story segmentation approaches are highly demanded. Lexical-cohesion based approaches have been widely studied for automatic broadcast news story segmentation (Beeferman et al., 1997; Choi, 1999; Hearst, 1997; Rosenberg and Hirschberg, 2006; ∗ corresponding author 190 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 190–195, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics 2.2 Construction of weight matrix in Laplacian Eigenmaps Laplacian Eigenmaps (LE) is introduced to project high-dimensional data into a low-dimensional representation while preserving its locality property. Given the ASR transcripts of N text blocks, we apply LDA algorithm to compute the corresponding latent topic distributi"
P13-2034,W01-0514,0,0.0446074,"ms. Term repetition is one of the most common appearances. These rigid lexical-cohesion based approaches simply take term repetition into consideration, while term association in lexical cohesion is ignored. Moreover, polysemy and synonymy are not considered. To deal with these problems, some topic model techniques which provide conceptual level matching have been introduced to text and story segmentation task (Hearst, 1997). Probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) is a typical instance and used widely. PLSA is the probabilistic variant of latent semantic analysis (LSA) (Choi et al., 2001), and offers a more solid statistical foundation. PLSA provides more significant improvement than LSA for story segmentation (Lu et al., 2011; Blei and Moreno, 2001). Despite the success of PLSA, there are concerns that the number of parameters in PLSA grows linearly with the size of the corpus. This makes PLSA not desirable if there is a considerable amount of data available, and causes serious over-fitting problems (Blei, 2012). To deal with this issue, Latent Dirichlet Allocation (LDA) (Blei et al., 2003) has been proposed. LDA has been proved to be effective in many segmentation tasks (Aro"
P13-2034,A00-2004,0,0.126284,"Missing"
P13-2034,D08-1038,0,0.0386254,"d statistical foundation. PLSA provides more significant improvement than LSA for story segmentation (Lu et al., 2011; Blei and Moreno, 2001). Despite the success of PLSA, there are concerns that the number of parameters in PLSA grows linearly with the size of the corpus. This makes PLSA not desirable if there is a considerable amount of data available, and causes serious over-fitting problems (Blei, 2012). To deal with this issue, Latent Dirichlet Allocation (LDA) (Blei et al., 2003) has been proposed. LDA has been proved to be effective in many segmentation tasks (Arora and Ravindran, 2008; Hall et al., 2008; Sun et al., 2008; Riedl and Biemann, 2012; Chien and Chueh, 2012). Recent studies have shown that intrinsic dimensionality of natural text corpus is significantly lower than its ambient Euclidean space (Belkin and Niyogi, 2002; Xie et al., 2012). Therefore, We present an efficient approach for broadcast news story segmentation using a manifold learning algorithm on latent topic distributions. The latent topic distribution estimated by Latent Dirichlet Allocation (LDA) is used to represent each text block. We employ Laplacian Eigenmaps (LE) to project the latent topic distributions into low-d"
P13-2034,P08-2068,0,0.0150584,"ation. PLSA provides more significant improvement than LSA for story segmentation (Lu et al., 2011; Blei and Moreno, 2001). Despite the success of PLSA, there are concerns that the number of parameters in PLSA grows linearly with the size of the corpus. This makes PLSA not desirable if there is a considerable amount of data available, and causes serious over-fitting problems (Blei, 2012). To deal with this issue, Latent Dirichlet Allocation (LDA) (Blei et al., 2003) has been proposed. LDA has been proved to be effective in many segmentation tasks (Arora and Ravindran, 2008; Hall et al., 2008; Sun et al., 2008; Riedl and Biemann, 2012; Chien and Chueh, 2012). Recent studies have shown that intrinsic dimensionality of natural text corpus is significantly lower than its ambient Euclidean space (Belkin and Niyogi, 2002; Xie et al., 2012). Therefore, We present an efficient approach for broadcast news story segmentation using a manifold learning algorithm on latent topic distributions. The latent topic distribution estimated by Latent Dirichlet Allocation (LDA) is used to represent each text block. We employ Laplacian Eigenmaps (LE) to project the latent topic distributions into low-dimensional semanti"
P13-2034,J97-1003,0,0.751981,"atic speech recognition (ASR) system. Lexical cues are extracted from the ASR transcripts. Lexical cohesion is the phenomenon that different stories tend to employ different sets of terms. Term repetition is one of the most common appearances. These rigid lexical-cohesion based approaches simply take term repetition into consideration, while term association in lexical cohesion is ignored. Moreover, polysemy and synonymy are not considered. To deal with these problems, some topic model techniques which provide conceptual level matching have been introduced to text and story segmentation task (Hearst, 1997). Probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) is a typical instance and used widely. PLSA is the probabilistic variant of latent semantic analysis (LSA) (Choi et al., 2001), and offers a more solid statistical foundation. PLSA provides more significant improvement than LSA for story segmentation (Lu et al., 2011; Blei and Moreno, 2001). Despite the success of PLSA, there are concerns that the number of parameters in PLSA grows linearly with the size of the corpus. This makes PLSA not desirable if there is a considerable amount of data available, and causes serious over-fittin"
P13-2034,N06-2032,0,0.0236048,"homogenous segments each embodying a main topic or coherent story (Allan, 2002). With the explosive growth of multimedia data, it becomes difficult to retrieve the most relevant components. For indexing broadcast news programs, it is desirable to divide each of them into a number of independent stories. Manual segmentation is accurate but labor-intensive and costly. Therefore, automatic story segmentation approaches are highly demanded. Lexical-cohesion based approaches have been widely studied for automatic broadcast news story segmentation (Beeferman et al., 1997; Choi, 1999; Hearst, 1997; Rosenberg and Hirschberg, 2006; ∗ corresponding author 190 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 190–195, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics 2.2 Construction of weight matrix in Laplacian Eigenmaps Laplacian Eigenmaps (LE) is introduced to project high-dimensional data into a low-dimensional representation while preserving its locality property. Given the ASR transcripts of N text blocks, we apply LDA algorithm to compute the corresponding latent topic distributions X = [x1 , x2 , . . . , xN ] in RK , where K is the num"
P13-2034,J01-1002,0,\N,Missing
P13-2042,J92-4003,0,0.114588,"proposed trigger model (Lau et al. 1993, Rosenfeld 1996) that relies on the bigrams of arbitrary distance, i.e. distance-independent. Latent-semantic language model approaches (Bellegarda 1998, Coccaro 2005) weight word counts with TFIDF to highlight their semantic importance towards the prediction. In this type of approach, count statistics are accumulated from long contexts, typically beyond ten to twenty words. In order to confine the complexity introduced by such long contexts, word ordering is ignored (i.e. bag-of-words paradigm). Other approaches such as the class-based language model (Brown 1992, Kneser & Ney 1993) 233 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 233–237, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics use POS or POS-like classes of the history-words for prediction. The structured language model (Chelba & Jelinek 2000) determines the “heads” in the history-context by using a parsing tree. There are also works on skipping irrelevant history-words in order to reveal more informative ngrams (Siu & Ostendorf 2000, Guthrie et al. 2006). Cache language models exploit temporal word frequenc"
P13-2042,P96-1041,0,0.178362,",   0, which results in a division by zero. For the first problem, we have attempted to redistribute the counts among the word-pairs at different distances (as observed within the window). We assumed that the counts of word-pairs are smooth in the distance domain and that the influence of a word decays as the distance increases. Accordingly, we used a weighted moving-average filter for performing the smoothing. Similar approaches have also been used in other works (Coccaro 2005, Lv & Zhai 2009). Notice, however, that this strategy is different from other conventional smoothing techniques (Chen & Goodman 1996), which rely mainly on the countof-count statistics for re-estimating and smoothing the original counts. For the second problem, when a word-pair was not seen at any distance (within the window), we arbitrarily assigned a small probability value, ∆ |   ,   0.01 , to provide a slight chance for such a word-pair   ,  to occur at close distances. 4.3 Term-Occurrence Model Component During the decoupling operation (from Eq.2 to Eq.3), the TD model held only the distance information while the count information has been ignored. Notice the normalization of word-pair counts in Eq.6. As a"
P13-2042,P98-2239,0,0.0605763,"roduces and motivates our proposed approach. Section 4 presents in detail the derivation of both TD and TO model components. Section 5 presents some perplexity evaluation results. Finally, section 6 presents our conclusions and proposed future work. 2 Related Work The distant bigram model (Huang et.al 1993, Simon et al. 1997, Brun et al. 2007) disassembles the n-gram into (n−1) word-pairs, such that each pair is modeled by a distance-k bigram model, where 1      1 . Each distance-k bigram model predicts the target-word based on the occurrence of a history-word located k positions behind. Zhou & Lua (1998) enhanced the effectiveness of the model by filtering out those wordpairs exhibiting low correlation, so that only the well associated distant bigrams are retained. This approach is referred to as the distance-dependent trigger model, and is similar to the earlier proposed trigger model (Lau et al. 1993, Rosenfeld 1996) that relies on the bigrams of arbitrary distance, i.e. distance-independent. Latent-semantic language model approaches (Bellegarda 1998, Coccaro 2005) weight word counts with TFIDF to highlight their semantic importance towards the prediction. In this type of approach, count st"
P13-2042,guthrie-etal-2006-closer,0,0.0185418,"digm). Other approaches such as the class-based language model (Brown 1992, Kneser & Ney 1993) 233 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 233–237, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics use POS or POS-like classes of the history-words for prediction. The structured language model (Chelba & Jelinek 2000) determines the “heads” in the history-context by using a parsing tree. There are also works on skipping irrelevant history-words in order to reveal more informative ngrams (Siu & Ostendorf 2000, Guthrie et al. 2006). Cache language models exploit temporal word frequencies in the history (Kuhn & Mori 1990, Clarkson & Robinson 1997). 3 Motivation of the Proposed Approach The attributes of distance and co-occurrence are exploited and modeled differently in each language modeling approach. In the n-gram model, for example, these two attributes are jointly taken into account in the ordered word-sequence. Consequently, the n-gram model can only be effectively implemented within a short history-context (e.g. of size of three or four). Both, the conventional trigger model and the latent-semantic model capture th"
P13-2042,H93-1016,0,0.279295,"Missing"
P13-2042,C98-2234,0,\N,Missing
P14-2004,W02-0702,0,0.224513,"ing multi-topic conversations with users to provide them a more natural interaction with the system. However, the majority of previous work on dialog interfaces has focused on dealing with only a single target task. Although some multitask dialog systems have been proposed (Lin et al., 1999; Ikeda et al., 2008; Celikyilmaz et al., 2011), they have aimed at just choosing the most probable one for each input from the sub-systems, each of which is independently operated from others. To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) have considered this dialog topic identification as a separate sub-problem of dialog management and attempted to solve it with text categorization approaches for the recognized utterances in a given turn. The major obstacle to the success of these approaches results from the differences between 19 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 19–23, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics t 0 1 Speaker Guide Tourist Guide 2 3 4"
P14-2004,P06-1093,0,0.666074,"ization tasks, the proper category for each textual unit can be assigned based only on its own content. However, the dialog topic at each turn can be determined not only by the user’s intentions captured from the given utterances, but also by the system’s decisions for dialog management purposes. Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related expressions explicitly in their utterances. The other direction of dialog topic tracking approaches made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources. However, this aspect can limit the flexibility to handle the user’s responses which are contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for"
P14-2004,W12-6006,0,0.0242007,"get there from Orchard Road? You can take the north-south line train from Orchard Road and stop at Raffles Place station. Is this walking distance from the station to the destination? Yes, it’ll take only ten minutes on foot. Alright. Well, you can also enjoy some seafoods at the riverside near the place. What food do you have any recommendations to try there? If you like spicy foods, you must try chilli crab which is one of our favourite dishes here in Singapore. Great! I’ll try that. Topic Transition NONE→NONE effort toward building resources for topic tracking. Recently, some researchers (Wilcock, 2012; Breuing et al., 2011) have shown the feasibility of using Wikipedia knowledge to build dialog systems. While each of these studies mainly focuses only on a single type of information including category relatedness or hyperlink connectedness, this work aims at incorporating various knowledge obtained from Wikipedia into the model using a composite kernel method. Our composite kernel consists of two different kernels: a history sequence kernel and a domain context tree kernel. Both represent the current dialog context at a given turn with a set of relevant Wikipedia paragraphs which are select"
P14-2004,P06-1104,0,0.0336331,"contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain. In this paper, we propose a composite kernel to explore various types of information obtained from Wikipedia for mixed-initiative dialog topic tracking without significant costs for building resources. Composite kernels have been successfully applied to improve the performances in other NLP problems (Zhao and Grishman, 2005; Zhang et al., 2006) by integrating multiple individual kernels, which aim to overcome the errors occurring at one level by information from other levels. Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context. Dialog topic tracking aims at analyzing and maintaining topic transitions in ongoing dialogs. This paper proposes a composite kernel approach for dialog topic tracking to utilize various types of domain knowledge obtained from Wikipedia. Two kernels are defined based on"
P14-2004,P02-1034,0,0.101364,"h of which is a subtree rooted at each paragraph node in: Pt = {pi |sim (xt , pi ) > θ}, where θ is a threshold value to select the relevant paragraphs. Each subtree consists of a set of features from a given paragraph in the Wikipedia collection in a hierarchical structure. Figure 3 shows an example of a constructed tree. Since this constructed tree structure represents semantic, discourse, and structural information extracted from the similar Wikipedia paragraphs to each given instance, we can explore these more enriched features to build the topic tracking model using a subset tree kernel (Collins and Duffy, 2002) which computes the similarity between each pair of trees in the feature space as follows: X X △ (n1 , n2 ) , Kt (T1 , T2 ) = Figure 3: An example of domain context tree the linear kernel between the vectors representing fundamental features extracted from the utterances themselves and the results of linguistic preprocessors. The composition is performed by linear combination as follows: K(x1 , x2 ) =α · Kl (V1 , V2 ) + β · Ks (S1 , S2 ) + γ · Kt (T1 , T2 ), where Vi , Si , and Ti are the feature vector, history sequence, and domain context tree of xi , respectively, Kl is the linear kernel co"
P14-2004,P05-1052,0,0.0255996,"ser’s responses which are contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain. In this paper, we propose a composite kernel to explore various types of information obtained from Wikipedia for mixed-initiative dialog topic tracking without significant costs for building resources. Composite kernels have been successfully applied to improve the performances in other NLP problems (Zhao and Grishman, 2005; Zhang et al., 2006) by integrating multiple individual kernels, which aim to overcome the errors occurring at one level by information from other levels. Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context. Dialog topic tracking aims at analyzing and maintaining topic transitions in ongoing dialogs. This paper proposes a composite kernel approach for dialog topic tracking to utilize various types of domain knowledge obtained from Wikipedia. Two kernels"
P14-2004,W02-0214,0,0.400567,"rsations with users to provide them a more natural interaction with the system. However, the majority of previous work on dialog interfaces has focused on dealing with only a single target task. Although some multitask dialog systems have been proposed (Lin et al., 1999; Ikeda et al., 2008; Celikyilmaz et al., 2011), they have aimed at just choosing the most probable one for each input from the sub-systems, each of which is independently operated from others. To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) have considered this dialog topic identification as a separate sub-problem of dialog management and attempted to solve it with text categorization approaches for the recognized utterances in a given turn. The major obstacle to the success of these approaches results from the differences between 19 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 19–23, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics t 0 1 Speaker Guide Tourist Guide 2 3 4 5 6 7 Tourist Guide Touri"
P14-2004,P08-1072,0,0.195535,"nt. However, the dialog topic at each turn can be determined not only by the user’s intentions captured from the given utterances, but also by the system’s decisions for dialog management purposes. Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related expressions explicitly in their utterances. The other direction of dialog topic tracking approaches made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources. However, this aspect can limit the flexibility to handle the user’s responses which are contradictory to the system’s suggestions. Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain. In this paper, we propose a composite kernel to explore various type"
P14-2004,C02-1082,0,\N,Missing
P16-1091,D13-1106,0,0.074876,"Missing"
P16-1091,P14-1062,0,0.390605,"h three different channels for current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output Figure 2: Convolutional neural network architecture for dialogue topic tracking. 3 Models successes of bag-of-words or bag-of-ngrams considering the existence of each linguistic unit independently and the important roles of compositional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks (Collobert et al., 2011; Shen et al., 2014; Yih et al., 2014; Kalchbrenner et al., 2014a; Kim, 2014). The classifier f can be built with supervised machine learning techniques, when a set of example dialogues manually annotated with gold standard labels are available as a training set. The earlier studies (Kim et al., 2014a; Kim et al., 2014b) also proposed supervised classification approaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues. This work, on the other hand, aims at improving the classification capabilities"
P16-1091,P14-2004,1,0.90801,"tell, 2008; Ikeda et al., 2008; Celikyilmaz et al., 2011). In these approaches, a given user input at each turn is categorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the 963 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 963–973, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics in mixed-initiative human-human conversations, which is called dialogue topic tracking (Kim et al., 2014a; Kim et al., 2014b). In these studies, the tracking task is formulated as a classification problem for each utterance-level, similar to the sentence categorization approaches. But the target of the classification is not just an individual topic category to which each input sentence belongs, but the decision whether a topic transition occurs at a given turn as well as what the most probable topic category will follow after the transition. This paper presents our work also on dialogue topic tracking mainly focusing on the following issues. Firstly, in addition to transitions between dialogue s"
P16-1091,D14-1181,0,0.00730014,"or current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output Figure 2: Convolutional neural network architecture for dialogue topic tracking. 3 Models successes of bag-of-words or bag-of-ngrams considering the existence of each linguistic unit independently and the important roles of compositional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks (Collobert et al., 2011; Shen et al., 2014; Yih et al., 2014; Kalchbrenner et al., 2014a; Kim, 2014). The classifier f can be built with supervised machine learning techniques, when a set of example dialogues manually annotated with gold standard labels are available as a training set. The earlier studies (Kim et al., 2014a; Kim et al., 2014b) also proposed supervised classification approaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues. This work, on the other hand, aims at improving the classification capabilities only with th"
P16-1091,W02-0214,0,0.0393585,"contextually related to each other. In this scenario, every participant in the conversation is required to understand the on-going topic discussed at each moment, detect any topic shift made by others, and make a decision to selfinitiate a new topic. These human capabilities for handling topics are also expected from dialogue systems to achieve natural and human-like conversations. Many studies have been conducted on multidomain or multi-task dialogue systems by means of sentence-level topic identification as a subtask of natural language understanding (Lin et al., 1999; Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008; Ikeda et al., 2008; Celikyilmaz et al., 2011). In these approaches, a given user input at each turn is categorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the 963 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 963–973, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics in mixed-initiative human-human conversations, which is called dialogue t"
P16-1091,P14-1140,0,0.0177072,"ut sequence. In a traditional RNN, hidden states connecting between input sequences and output labels are repeatedly updated with the operation s~t = g(U xt + W st−1 ), where xt is the t-th element in a given input sequence, s~t ∈ R|s |is the hidden state at t with |s |hidden units, and g is a non-linear activation function. The parameters U and W are shared all the time steps. RNNs have been successfully applied to several natural language processing tasks including language modeling (Mikolov et al., 2010), text generation (Sutskever et al., 2011), and machine translation (Auli et al., 2013; Liu et al., 2014), all of which focus on dealing with variable length word sequences. On the other hand, an input sequence to be handled in dialogue topic tracking is composed of utterance-level units instead of words. In our model (Figure 3), each utterance is represented by the k-dimensional vector ~ut ∈ Rk assigned with pre-trained sentence-level embeddings (Le and Mikolov, 2014). And then, a sequence of the utterance vectors within h time steps are connected in the recurrent layers. The default sequence of applying the recurrent operation is the ascending order from the former to the recent utterances, whi"
P16-1091,C00-2137,0,0.102675,"Missing"
P16-1091,P14-2105,0,0.0134265,"mbedding layer with three different channels for current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output Figure 2: Convolutional neural network architecture for dialogue topic tracking. 3 Models successes of bag-of-words or bag-of-ngrams considering the existence of each linguistic unit independently and the important roles of compositional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks (Collobert et al., 2011; Shen et al., 2014; Yih et al., 2014; Kalchbrenner et al., 2014a; Kim, 2014). The classifier f can be built with supervised machine learning techniques, when a set of example dialogues manually annotated with gold standard labels are available as a training set. The earlier studies (Kim et al., 2014a; Kim et al., 2014b) also proposed supervised classification approaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues. This work, on the other hand, aims at improving the"
P16-1091,W02-0702,0,0.07709,"es of multiple topics contextually related to each other. In this scenario, every participant in the conversation is required to understand the on-going topic discussed at each moment, detect any topic shift made by others, and make a decision to selfinitiate a new topic. These human capabilities for handling topics are also expected from dialogue systems to achieve natural and human-like conversations. Many studies have been conducted on multidomain or multi-task dialogue systems by means of sentence-level topic identification as a subtask of natural language understanding (Lin et al., 1999; Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008; Ikeda et al., 2008; Celikyilmaz et al., 2011). In these approaches, a given user input at each turn is categorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the 963 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 963–973, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics in mixed-initiative human-human conversations,"
P16-1091,W95-0107,0,0.185358,"ds, you must try chilli crab which is one of our favourite dishes. Great! I’ll try that. f (t) B-OPEN B-ATTR I-ATTR B-ATTR I-ATTR B-TRSP I-TRSP I-TRSP I-TRSP I-TRSP B-TRSP I-TRSP B-FOOD I-FOOD I-FOOD I-FOOD Figure 1: Examples of dialogue topic tracking on a tour guide dialogue labelled with BIO tags. ATTR, TRSP and FOOD denotes the topic categories of attraction, transportation, and food, respectively. Dialogue Topic Tracking Dialogue topic tracking is defined as a multi-class classification problem to categorize the topic state at each time step into the labels encoded in BIO tagging scheme (Ramshaw and Marcus, 1995) as follows:  B-{c ∈ C} if ut is at the beginning     of a segment belongs to c,  I-{c ∈ C} else if ut is inside a f (t) =   segment belongs to c,    O otherwise, where ut is the t-th utterance in a given dialogue session and C is a closed set of topic categories. 964 Figure 1 shows an example of topic tracking on a dialogue fragment between a tour guide and a tourist. Since each tag starting with ‘B’ should occur at the beginning of a new segment after a topic transition from its previous one, the label sequence indicates that this conversation is divided into six segments at t = {"
P16-1091,C02-1082,0,\N,Missing
P16-1091,P08-1072,0,\N,Missing
W09-3501,W09-3517,0,0.0374294,"ementations are based on approaches that are language-independent. Indeed, many of the participants fielded their systems on multiple languages, as can be seen from Table 3. We also note that combination of several different models via re-ranking of their outputs (CRF, Maximum Entropy Model, Margin Infused Relaxed Algorithm) proves to be very successful (Oh et al., 2009); their system (reported as Team ID 6) produced the best or second-best transliteration performance consistently across all metrics, in all tasks, except Japanese back-transliteration. Examples of other model combinations are (Das et al., 2009). At least two teams (reported as Team IDs 14 and 27) incorporate language origin detection in their system (Bose and Sarkar, 2009; Khapra and Bhattacharyya, 2009). The Indian language corpora contains names of both English and Indic origin. Khapra and Bhattacharyya (2009) demonstrate how much the transliteration performance can be improved when language of origin detection is employed, followed by a language-specific transliteration model for decoding. Some systems merit specific mention as they adopt are rather unique approaches. Jiampojamarn et al. (2009) propose DirectTL discriminative seq"
W09-3501,N03-1017,0,0.00241786,"umber of runs submitted for each task. Number of participants coincides with the number of standard runs submitted. evaluation results published for this edition of the transliteration shared task. Note that two teams have updated their results (after fixing bugs in their systems) after the deadline; their results are identified specifically. We find that two approaches to transliteration are most popular in the shared task submissions. One of these approaches is Phrase-based statistical machine transliteration (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003). Systems that adopted this approach are (Song, 2009; Haque et al., 2009; Noeman, 2009; Rama and Gali, 2009; Chinnakotla and Damani, 2009).1 The other is Conditional Random Fields(Lafferty et al., 2001) (CRF), adopted by (Aramaki and Abekawa, 2009; Shishtla et al., 2009). With only a few exceptions, most implementations are based on approaches that are language-independent. Indeed, many of the participants fielded their systems on multiple languages, as can be seen from Table 3. We also note that combination of several different models via re-ranking of their outputs (CRF, Maximum Entropy Mode"
W09-3501,I08-8003,0,0.0610299,"h to Russian English to Chinese EnKa EnRu 14 5 13 16 English to Kannada Table 2: Number of runs submitted for each task. Number of participants coincides with the number of standard runs submitted. evaluation results published for this edition of the transliteration shared task. Note that two teams have updated their results (after fixing bugs in their systems) after the deadline; their results are identified specifically. We find that two approaches to transliteration are most popular in the shared task submissions. One of these approaches is Phrase-based statistical machine transliteration (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003). Systems that adopted this approach are (Song, 2009; Haque et al., 2009; Noeman, 2009; Rama and Gali, 2009; Chinnakotla and Damani, 2009).1 The other is Conditional Random Fields(Lafferty et al., 2001) (CRF), adopted by (Aramaki and Abekawa, 2009; Shishtla et al., 2009). With only a few exceptions, most implementations are based on approaches that are language-independent. Indeed, many of the participants fielded their systems on multiple languages, as can be seen from Table 3. We also note that combination of sever"
W09-3501,W09-3506,0,0.0583655,"2009; Noeman, 2009; Rama and Gali, 2009; Chinnakotla and Damani, 2009).1 The other is Conditional Random Fields(Lafferty et al., 2001) (CRF), adopted by (Aramaki and Abekawa, 2009; Shishtla et al., 2009). With only a few exceptions, most implementations are based on approaches that are language-independent. Indeed, many of the participants fielded their systems on multiple languages, as can be seen from Table 3. We also note that combination of several different models via re-ranking of their outputs (CRF, Maximum Entropy Model, Margin Infused Relaxed Algorithm) proves to be very successful (Oh et al., 2009); their system (reported as Team ID 6) produced the best or second-best transliteration performance consistently across all metrics, in all tasks, except Japanese back-transliteration. Examples of other model combinations are (Das et al., 2009). At least two teams (reported as Team IDs 14 and 27) incorporate language origin detection in their system (Bose and Sarkar, 2009; Khapra and Bhattacharyya, 2009). The Indian language corpora contains names of both English and Indic origin. Khapra and Bhattacharyya (2009) demonstrate how much the transliteration performance can be improved when language"
W09-3501,P08-1045,0,0.0839769,"Missing"
W09-3501,W09-3528,0,0.020518,"bmitted. evaluation results published for this edition of the transliteration shared task. Note that two teams have updated their results (after fixing bugs in their systems) after the deadline; their results are identified specifically. We find that two approaches to transliteration are most popular in the shared task submissions. One of these approaches is Phrase-based statistical machine transliteration (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003). Systems that adopted this approach are (Song, 2009; Haque et al., 2009; Noeman, 2009; Rama and Gali, 2009; Chinnakotla and Damani, 2009).1 The other is Conditional Random Fields(Lafferty et al., 2001) (CRF), adopted by (Aramaki and Abekawa, 2009; Shishtla et al., 2009). With only a few exceptions, most implementations are based on approaches that are language-independent. Indeed, many of the participants fielded their systems on multiple languages, as can be seen from Table 3. We also note that combination of several different models via re-ranking of their outputs (CRF, Maximum Entropy Model, Margin Infused Relaxed Algorithm) proves to be very successful (Oh et al., 2009); their system (reported"
W09-3501,P04-1021,1,\N,Missing
W09-3501,W09-3512,0,\N,Missing
W09-3501,W09-3526,0,\N,Missing
W09-3501,P06-1103,0,\N,Missing
W09-3501,P07-1119,0,\N,Missing
W09-3501,P06-1010,0,\N,Missing
W09-3501,W09-3508,0,\N,Missing
W09-3501,W09-3514,0,\N,Missing
W09-3501,W06-1672,0,\N,Missing
W09-3501,D08-1037,0,\N,Missing
W09-3501,W09-3525,0,\N,Missing
W09-3501,W09-3530,0,\N,Missing
W09-3501,W09-3513,0,\N,Missing
W09-3501,W09-3523,0,\N,Missing
W09-3501,J98-4003,0,\N,Missing
W09-3501,W09-3518,0,\N,Missing
W09-3501,W09-3507,0,\N,Missing
W09-3501,W09-3504,0,\N,Missing
W09-3502,P04-1021,1,\N,Missing
W10-2401,P06-1103,0,0.0614407,"hou Li† , A Kumaran‡ , Min Zhang† and Vladimir Pervouchine† † Institute for Infocomm Research, A*STAR, Singapore 138632 {hli,mzhang,vpervouchine}@i2r.a-star.edu.sg ‡ Multilingual Systems Research, Microsoft Research India A.Kumaran@microsoft.com Abstract tems. Much research effort has been made to address the transliteration issue in the research community (Knight and Graehl, 1998; Meng et al., 2001; Li et al., 2004; Zelenko and Aone, 2006; Sproat et al., 2006; Sherif and Kondrak, 2007; Hermjakob et al., 2008; Al-Onaizan and Knight, 2002; Goldwasser and Roth, 2008; Goldberg and Elhadad, 2008; Klementiev and Roth, 2006; Oh and Choi, 2002; Virga and Khudanpur, 2003; Wan and Verspoor, 1998; Kang and Choi, 2000; Gao et al., 2004; Zelenko and Aone, 2006; Li et al., 2009b; Li et al., 2009a). These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods. Graphemebased method (Li et al., 2004) treats transliteration as a direct orthographic mapping and only uses orthography-related features while phonemebased method (Knight and Graehl, 1998) makes use of phonetic correspondence to generate the transliteration. Hybrid method refers to the combination of several different mod"
W10-2401,I08-8003,0,0.0263392,"ageindependent approach but added languagespecific pre- or post-processing (Jiampojamarn et al., 2010; Das et al., 2010; Song et al., 2010), including name origin recognition for English to Hindi task (Jiampojamarn et al., 2010). 5.1 Standard runs All the results are presented numerically in Tables 4–15, for all evaluation metrics. These are the official evaluation results published for this edition of the transliteration shared task. Among the four submitted system papers1 , Song et al. (2010) and Finch and Sumita (2010) adopt the approach of phrase-based statistical machine transliteration (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003) while Das et al. (2010) adopts the approach of Conditional Random Fields (CRF) (Lafferty et al., 2001). Jiampojamarn et al. (2010) further develop DirectTL approach presented at the previous NEWS workshop (Jiampojamarn et al., 2009), achieving very good performance in the NEWS 2010. An example of a completely languageCombination of different models via re-ranking of their outputs has been used in most of the systems (Das et al., 2010; Song et al., 2010; Finch and Sumita, 2010). In fact, one system (Song et al., 2010"
W10-2401,W10-2406,0,0.156882,"nKa EnJa EnKo JnJk ArAe EnBa Standard runs Non-standard runs 3 1 2 0 1 0 1 0 2 0 3 2 Table 2: Number of runs submitted for each task. Number of participants coincides with the number of standard runs submitted. Team Organisation ID 1∗ 2 3 4 5 6 7 IIT, Bombay University of Alberta City University Hong Kong NICT of EnCh ChEn EnTh ThEn EnHi EnTa EnKa EnJa EnKo JnJk ArAe EnBa x x x x x x x x x x x x x x x x x x x x x x x x x x x x x Jadavpur University x Table 3: Participation of teams in different tasks. ∗ Participation without a system paper. 5 Task Results and Analysis independent approach is (Finch and Sumita, 2010). Other participants used languageindependent approach but added languagespecific pre- or post-processing (Jiampojamarn et al., 2010; Das et al., 2010; Song et al., 2010), including name origin recognition for English to Hindi task (Jiampojamarn et al., 2010). 5.1 Standard runs All the results are presented numerically in Tables 4–15, for all evaluation metrics. These are the official evaluation results published for this edition of the transliteration shared task. Among the four submitted system papers1 , Song et al. (2010) and Finch and Sumita (2010) adopt the approach of phrase-based statis"
W10-2401,W10-2405,0,\N,Missing
W10-2401,C02-1099,0,\N,Missing
W10-2401,P04-1021,1,\N,Missing
W10-2401,W03-1508,0,\N,Missing
W10-2401,W02-0505,0,\N,Missing
W10-2401,P07-1119,0,\N,Missing
W10-2401,W09-3511,0,\N,Missing
W10-2401,P06-1010,0,\N,Missing
W10-2401,W09-3501,1,\N,Missing
W10-2401,P98-2220,0,\N,Missing
W10-2401,C98-2215,0,\N,Missing
W10-2401,W06-1672,0,\N,Missing
W10-2401,D08-1037,0,\N,Missing
W10-2401,P08-1045,0,\N,Missing
W10-2401,N03-1017,0,\N,Missing
W10-2401,W10-2409,0,\N,Missing
W10-2401,W10-2411,0,\N,Missing
W10-2401,J98-4003,0,\N,Missing
W10-2401,W09-3504,0,\N,Missing
W10-2402,P04-1021,1,0.854044,"Missing"
W10-2403,P07-1083,0,0.0172327,"sed method where a pair of strings is classified as a transliteration pair if the Normalized Edit Distance (NED) between them is above a certain threshold. To calculate the NED, the target language string is first Romanized by replacing each target grapheme by the source grapheme having the highest conditional probability. These conditional probabilities are obtained by aligning the seed set of transliteration pairs using an M2Maligner approach (Jiampojamarn et. al., 2007). The second system uses a SVM based discriminative classifier trained using an improved feature representation (BK 2007) (Bergsma and Kondrak, 2007). These features include all substring pairs up to a maximum length of three as extracted from the aligned word pairs. The transliteration pairs in the seed data provided for the shared task were used as positive examples. The negative examples were obtained by generating all possible source-target pairs in the seed data and taking those pairs which are not transliterations but have a longest common subsequence ratio above a certain threshold. One drawback of this system is that longer substrings cannot be used due to the combinatorial explosion in the number of unique features as the substrin"
W10-2403,W10-2407,0,0.126423,"Missing"
W10-2403,W10-2412,0,0.178331,"Missing"
W10-2403,W10-2408,0,0.0557878,"Missing"
W10-2403,E09-1091,1,0.746389,"Missing"
W10-2403,W10-2405,0,\N,Missing
W10-2403,P06-1103,0,\N,Missing
W10-2403,J98-4003,0,\N,Missing
W10-2403,W10-2404,1,\N,Missing
W11-3201,P08-1045,0,0.144492,"Missing"
W11-3201,W10-2401,1,0.257521,"ndence to generate the transliteration. Hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation. The first machine transliteration shared task (Li et al., 2009b; Li et al., 2009a) was held in NEWS 2009 at ACL-IJCNLP 2009. It was the first time to provide common benchmarking data in diverse language pairs for evaluation of state-of-the-art techniques. While the focus of the 2009 shared task was on establishing the quality metrics and on baselining the transliteration quality based on those metrics, the 2010 shared task (Li et al., 2010a; Li et al., 2010b) expanded the scope of the transliteration generation task to about a dozen languages, and explored the quality depending on the direction of transliteration, between the languages. NEWS 2011 was a continued effort of NEWS 2010 and NEWS 2009. The rest of the report is organised as follows. Section 2 outlines the machine transliteration task and the corpora used and Section 3 discusses the metrics chosen for evaluation, along with the ratioThis report documents the Machine Transliteration Shared Task conducted as a part of the Named Entities Workshop (NEWS 2011), an IJCNLP 2"
W11-3201,W11-3213,0,0.120956,"ery good performance. This system is based on phrase-based statistical machine transliteration (SMT) (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003), where the SMT system’s log-linear model is augmented with a set of features specifically suited to the task of transliteration. In particular, the model utilizes a feature based on a joint source-channel model, and a feature based on a maximum entropy model that predicts target grapheme sequences using the local context of graphemes and grapheme sequences in both source and target languages. Jiang et al. (2011) extensively explore the use of accessor variety (a similarity measure) of the source graphemes as a feature under CRF framework for machine transliteration and report promising results. Kruengkrai et al. (2011) study discriminative training based on the Margin Infused Relaxed Algorithm with simple character alignments under SMT framework for machine transliteration. They report very impressive results. Bhargava et al. (2011) attemp to improve transliteration performance by leveraging transliterations from multiple languages. Dasigi and Diab (2011) adopt the approach of phrase-based statistica"
W11-3201,W03-1508,0,0.23567,"maran‡ and Ming Liu † † Institute for Infocomm Research, A*STAR, Singapore 138632 {mzhang,hli,mliu}@i2r.a-star.edu.sg ‡ Multilingual Systems Research, Microsoft Research India A.Kumaran@microsoft.com Abstract tems. Much research effort has been made to address the transliteration issue in the research community (Knight and Graehl, 1998; Meng et al., 2001; Li et al., 2004; Zelenko and Aone, 2006; Sproat et al., 2006; Sherif and Kondrak, 2007; Hermjakob et al., 2008; Al-Onaizan and Knight, 2002; Goldwasser and Roth, 2008; Goldberg and Elhadad, 2008; Klementiev and Roth, 2006; Oh and Choi, 2002; Virga and Khudanpur, 2003; Wan and Verspoor, 1998; Kang and Choi, 2000; Gao et al., 2004; Zelenko and Aone, 2006; Li et al., 2009b; Li et al., 2009a). These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods. Graphemebased method (Li et al., 2004) treats transliteration as a direct orthographic mapping and only uses orthography-related features while phonemebased method (Knight and Graehl, 1998) makes use of phonetic correspondence to generate the transliteration. Hybrid method refers to the combination of several different models or knowledge sources to support the transl"
W11-3201,W11-3217,0,\N,Missing
W11-3201,W10-2402,1,\N,Missing
W11-3201,C02-1099,0,\N,Missing
W11-3201,P04-1021,1,\N,Missing
W11-3201,W02-0505,0,\N,Missing
W11-3201,P06-1103,0,\N,Missing
W11-3201,P07-1119,0,\N,Missing
W11-3201,P06-1010,0,\N,Missing
W11-3201,W09-3501,1,\N,Missing
W11-3201,P98-2220,0,\N,Missing
W11-3201,C98-2215,0,\N,Missing
W11-3201,W06-1672,0,\N,Missing
W11-3201,D08-1037,0,\N,Missing
W11-3201,N03-1017,0,\N,Missing
W11-3201,W11-3206,0,\N,Missing
W11-3201,W11-3205,0,\N,Missing
W11-3201,W11-3215,0,\N,Missing
W11-3201,W10-2411,0,\N,Missing
W11-3201,W11-3212,0,\N,Missing
W11-3201,W11-3216,0,\N,Missing
W11-3201,I08-8003,0,\N,Missing
W11-3201,J98-4003,0,\N,Missing
W11-3201,W11-3204,0,\N,Missing
W11-3201,W11-3203,0,\N,Missing
W11-3202,P04-1021,1,0.839488,"Missing"
W12-4401,P04-1021,1,\N,Missing
W12-4402,P06-1103,0,0.0603668,"source for name equivalence, the bilingual dictionaries — whether handcrafted or statistical — offer only limited support because new names always emerge. All of the above point to the critical need for robust Machine Transliteration technology and sys10 tems. Much research effort has been made to address the transliteration issue in the research community (Knight and Graehl, 1998; Meng et al., 2001; Li et al., 2004; Zelenko and Aone, 2006; Sproat et al., 2006; Sherif and Kondrak, 2007; Hermjakob et al., 2008; Al-Onaizan and Knight, 2002; Goldwasser and Roth, 2008; Goldberg and Elhadad, 2008; Klementiev and Roth, 2006; Oh and Choi, 2002; Virga and Khudanpur, 2003; Wan and Verspoor, 1998; Kang and Choi, 2000; Gao et al., 2004; Zelenko and Aone, 2006; Li et al., 2009b; Li et al., 2009a). These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods. Graphemebased method (Li et al., 2004) treats transliteration as a direct orthographic mapping and only uses orthography-related features while phonemebased method (Knight and Graehl, 1998) makes use of phonetic correspondence to generate the transliteration. Hybrid method refers to the combination of several different mod"
W12-4402,N03-1017,0,0.038172,"esented numerically in Tables 4–17, for all evaluation metrics. These are the official evaluation results published for this edition of the transliteration shared task. The methodologies used in the ten submitted system papers are summarized as follows. Similar to their NEWS 2011 system, Finch et al. (2012) employ non-Parametric Bayesian method to cosegment bilingual named entities for model training and report very good performance. This system is based on phrase-based statistical machine transliteration (SMT) (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003), where the SMT system’s log-linear model is augmented with a set of features specifically suited to the task of transliteration. In particular, the model utilizes a fea14 ture based on a joint source-channel model, and a feature based on a maximum entropy model that predicts target grapheme sequences using the local context of graphemes and grapheme sequences in both source and target languages. Different from their NEWS 2011 system, in order to solve the data sparseness issue, they use two RNN-based LM to project the grapheme set onto a smaller hidden representation: one for the target graph"
W12-4402,W12-4411,0,0.107555,"performance at English-Korean tasks. Okuno (2012) studies the mpaligner (an improvement of m2m-aligner) and shows that mpaligner is more effective than m2maligner. They also find that de-romanization is crucial to JnJk task and mora is the best alignment unit for EnJa task. Ammar et al. (2012) use CRF as the basic model but with two innovations: a training objective that optimizes toward any of a set of possible correct labels (i.e., multiple references) and a k-best reranking with non-local features. Their results on ArEn show that the two features are very effective in accuracy improvement. Kondrak et al. (2012) study the languagespecific adaptations in the context of two language pairs: English to Chinese (Pinyin representation) and Arabic to English (letter mapping). They conclude that Pinyin representation is useful while letter mapping is less effective. Kuo et al. (2012) explore two-stage CRF for Enligsh-to-Chinese task and show that the two-stage CRF outperform traditional one-stage CRF. 5.2 Non-standard runs For the non-standard runs, we pose no restrictions on the use of data or other linguistic resources. The purpose of non-standard runs is to see how best personal name transliteration can b"
W12-4402,W12-4412,0,0.233735,"tion Yuan Ze University CMU EnCh ChEn EnTh ThEn EnHi EnTa EnKa EnJa EnKo JnJk ArEn EnBa EnPe EnHe x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x Table 3: Participation of teams in different tasks. 5 5.1 Task Results and Analysis Standard runs All the results are presented numerically in Tables 4–17, for all evaluation metrics. These are the official evaluation results published for this edition of the transliteration shared task. The methodologies used in the ten submitted system papers are summarized as follows. Similar to their NEWS 2011 system, Finch et al. (2012) employ non-Parametric Bayesian method to cosegment bilingual named entities for model training and report very good performance. This system is based on phrase-based statistical machine transliteration (SMT) (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003), where the SMT system’s log-linear model is augmented with a set of features specifically suited to the task of transliteration. In particular, the model utilizes a fea14 ture based on a joint source-channel model, and a feature based on a maximum entropy model that predicts target graph"
W12-4402,P04-1021,1,0.956117,"he correct conversion of names between the languages in several studies (Demner-Fushman and Oard, 2002; Mandl and Womser-Hacker, 2005; Hermjakob et al., 2008; Udupa et al., 2009). The traditional source for name equivalence, the bilingual dictionaries — whether handcrafted or statistical — offer only limited support because new names always emerge. All of the above point to the critical need for robust Machine Transliteration technology and sys10 tems. Much research effort has been made to address the transliteration issue in the research community (Knight and Graehl, 1998; Meng et al., 2001; Li et al., 2004; Zelenko and Aone, 2006; Sproat et al., 2006; Sherif and Kondrak, 2007; Hermjakob et al., 2008; Al-Onaizan and Knight, 2002; Goldwasser and Roth, 2008; Goldberg and Elhadad, 2008; Klementiev and Roth, 2006; Oh and Choi, 2002; Virga and Khudanpur, 2003; Wan and Verspoor, 1998; Kang and Choi, 2000; Gao et al., 2004; Zelenko and Aone, 2006; Li et al., 2009b; Li et al., 2009a). These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods. Graphemebased method (Li et al., 2004) treats transliteration as a direct orthographic mapping and only uses orthograp"
W12-4402,D08-1037,0,0.0370038,"kob et al., 2008; Udupa et al., 2009). The traditional source for name equivalence, the bilingual dictionaries — whether handcrafted or statistical — offer only limited support because new names always emerge. All of the above point to the critical need for robust Machine Transliteration technology and sys10 tems. Much research effort has been made to address the transliteration issue in the research community (Knight and Graehl, 1998; Meng et al., 2001; Li et al., 2004; Zelenko and Aone, 2006; Sproat et al., 2006; Sherif and Kondrak, 2007; Hermjakob et al., 2008; Al-Onaizan and Knight, 2002; Goldwasser and Roth, 2008; Goldberg and Elhadad, 2008; Klementiev and Roth, 2006; Oh and Choi, 2002; Virga and Khudanpur, 2003; Wan and Verspoor, 1998; Kang and Choi, 2000; Gao et al., 2004; Zelenko and Aone, 2006; Li et al., 2009b; Li et al., 2009a). These previous work fall into three categories, i.e., grapheme-based, phoneme-based and hybrid methods. Graphemebased method (Li et al., 2004) treats transliteration as a direct orthographic mapping and only uses orthography-related features while phonemebased method (Knight and Graehl, 1998) makes use of phonetic correspondence to generate the transliteration. Hybrid me"
W12-4402,W10-2401,1,0.455916,"ndence to generate the transliteration. Hybrid method refers to the combination of several different models or knowledge sources to support the transliteration generation. The first machine transliteration shared task (Li et al., 2009b; Li et al., 2009a) was held in NEWS 2009 at ACL-IJCNLP 2009. It was the first time to provide common benchmarking data in diverse language pairs for evaluation of state-of-the-art techniques. While the focus of the 2009 shared task was on establishing the quality metrics and on baselining the transliteration quality based on those metrics, the 2010 shared task (Li et al., 2010a; Li et al., 2010b) expanded the scope of the transliteration generation task to about a dozen languages, and explored the quality depending on the direction of transliteration, between the languages. In NEWS 2011 (Zhang et al., 2011a; Zhang et al., 2011b), we significantly increased the hand-crafted parallel named entities corpora to include 14 different language pairs from 11 language families, and made them available as the common dataset for the shared task. NEWS 2012 was a continued effort of NEWS 2011, NEWS Proceedings of the 50th Annual Meeting of the Association for Computational Ling"
W12-4402,W11-3201,1,0.256256,"009b; Li et al., 2009a) was held in NEWS 2009 at ACL-IJCNLP 2009. It was the first time to provide common benchmarking data in diverse language pairs for evaluation of state-of-the-art techniques. While the focus of the 2009 shared task was on establishing the quality metrics and on baselining the transliteration quality based on those metrics, the 2010 shared task (Li et al., 2010a; Li et al., 2010b) expanded the scope of the transliteration generation task to about a dozen languages, and explored the quality depending on the direction of transliteration, between the languages. In NEWS 2011 (Zhang et al., 2011a; Zhang et al., 2011b), we significantly increased the hand-crafted parallel named entities corpora to include 14 different language pairs from 11 language families, and made them available as the common dataset for the shared task. NEWS 2012 was a continued effort of NEWS 2011, NEWS Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 10–20, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics 2010 and NEWS 2009. The rest of the report is organised as follows. Section 2 outlines the machine transliteration task an"
W12-4402,W12-4410,0,\N,Missing
W12-4402,W10-2402,1,\N,Missing
W12-4402,C02-1099,0,\N,Missing
W12-4402,W03-1508,0,\N,Missing
W12-4402,W02-0505,0,\N,Missing
W12-4402,P07-1119,0,\N,Missing
W12-4402,P06-1010,0,\N,Missing
W12-4402,W09-3501,1,\N,Missing
W12-4402,P98-2220,0,\N,Missing
W12-4402,C98-2215,0,\N,Missing
W12-4402,W06-1672,0,\N,Missing
W12-4402,P08-1045,0,\N,Missing
W12-4402,W12-4408,0,\N,Missing
W12-4402,W11-3202,1,\N,Missing
W12-4402,W12-4409,0,\N,Missing
W12-4402,W11-3216,0,\N,Missing
W12-4402,I08-8003,0,\N,Missing
W12-4402,W12-4407,0,\N,Missing
W12-4402,J98-4003,0,\N,Missing
W12-4402,W12-4406,0,\N,Missing
W12-4402,W11-3203,0,\N,Missing
W13-3301,W12-3129,0,0.0892933,"Missing"
W13-3301,W02-1801,0,0.0452804,"f identifying meaningful endpoints of utterances before transmitting a translation. For example, there is a perceived lag time for speakers when trying to book flights or order products over the phone. This lag time diminishes conversation quality since it takes too long for each speaker to receive a translation at either end of the system (Paulik et al., 2009). If we can develop a method to automatically identify segments of meaning as they are spoken, then we could significantly reduce the perceived lag time in real-time speech-to-speech translation systems and improve conversation quality (Baobao et al., 2002; Hamon et al., 2009). The problem of absence of correspondence arises when there is a lexical unit (single words or groups of words) that occurs in L1 but not in L2 (Lambert et al., 2005). It happens when words belonging to a concept do not correspond to phrases that can be aligned in both languages. This 3 Similarity Agreement We implemented segmentation similarity (S) from Fournier and Inkpen (2012). Segmentation similarity was formulated to address some gaps of the WindowDiff (W D) metric, including unequal penalty for errors as well as the need to add padding to the ends of each segmentat"
W13-3301,P98-2141,0,0.30242,"eal-time, they naturally segment speech in “minimal sense units” (Ol´eron & Nanpon, 1965; Ben´ıtez & Bajo, 1998) in order to convey the same information from one language to another as though there were a 1-to-1 mapping of concepts between both languages. Further, it is known that people can hold up to 7+/- 2 “chunks” of information in memory at a time by creating and applying meaningful organization schemes to input (Miller, 1956). However, there is no definitive linguistic description for the kind of “meaning units” that human translators create (Signorelli et al., 2011; Hamon et al., 2009; Mima et al., 1998). The ability to chunk text according to units of meaning is key to developing more sophisticated machine translation (MT) systems that operate in • At what level of granularity do English and Chinese speakers construct meaning units in text? • Do English and Chinese speakers organize meaning units systematically such that meaning unit segmentations are not random? • How well do English and Chinese speakers agree on meaning unit boundaries? • Are there salient syntactic features of meaning units in English and Chinese? • Can we automatically identify a 1-to-1 mapping of concepts for parallel t"
W13-3301,N12-1016,0,0.079346,"omatically identify segments of meaning as they are spoken, then we could significantly reduce the perceived lag time in real-time speech-to-speech translation systems and improve conversation quality (Baobao et al., 2002; Hamon et al., 2009). The problem of absence of correspondence arises when there is a lexical unit (single words or groups of words) that occurs in L1 but not in L2 (Lambert et al., 2005). It happens when words belonging to a concept do not correspond to phrases that can be aligned in both languages. This 3 Similarity Agreement We implemented segmentation similarity (S) from Fournier and Inkpen (2012). Segmentation similarity was formulated to address some gaps of the WindowDiff (W D) metric, including unequal penalty for errors as well as the need to add padding to the ends of each segmentation (Pevzner & Hearst, 2002). There are 3 types of segmentation errors for (S), listed below: 1. s1 contains a boundary that is off by n potential boundaries in s2 2. s1 contains a boundary that s2 does not, or 3. s2 contains a boundary that s1 does not These three types of errors are understood as transpositions in the case of error type 1, and as 2 4 substitutions in the case of error types 2 and 3."
W13-3301,C96-1070,0,0.809452,"Missing"
W13-3301,E09-1040,0,0.330363,"Missing"
W13-3301,J02-1002,0,0.104128,"Missing"
W13-3301,N04-1030,0,0.106586,"Missing"
W13-3301,C88-1057,0,0.162679,"Missing"
W13-3301,P10-2012,0,0.0729024,"Missing"
W13-3301,W10-1733,0,0.0352146,"Missing"
W13-3301,P03-1054,0,0.00665411,"Missing"
W13-3301,W03-1730,0,0.00868617,"Universal Declaration of Human Rights. The number of words and number of sentences by language and genre is presented below in Table 1. Preprocessing: To prepare the text samples for annotation, we did some preprocessing. We removed periods and commas in both languages, since these markings can give structure and meaning to the text which could influence annotator decisions about meaning unit boundaries. For the English data, we did not fold to lowercase and we acknowledge that this was a design oversight. The Chinese text was automatically segmented into words before the task using ICTCLAS (Zhang et al., 2003). This was done in order to encourage Chinese speakers to look beyond the characterlevel and word-level, since word segmentation is a well-known NLP task for the Chinese language. The Chinese UDHR data consisted of 856 characters. We placed checkboxes between each word in the text. In their analysis and comparison of this new metric, Fournier and Inkpen (2012) demonstrated the advantages of using (S) over using (W D) for different kinds of segmentation cases such as maximal/minimal segmentation, full misses, near misses, and segmentation mass scale effects. They found that in each of these cas"
W13-3301,C98-2136,0,\N,Missing
W15-3901,P04-1021,1,\N,Missing
W15-3902,J98-4003,0,0.37313,"2015 Machine Transliteration Shared Task Rafael E. Banchs1, Min Zhang2, Xiangyu Duan2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {minzhang,xiangyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-re"
W15-3902,P07-2045,0,0.00686568,"Missing"
W15-3902,P07-1119,0,0.0443311,"A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {minzhang,xiangyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondenc"
W15-3902,P06-1010,0,0.0359544,"Duan2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {minzhang,xiangyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use"
W15-3902,W15-3912,0,0.127502,"Missing"
W15-3902,W15-3911,0,0.0752468,"Missing"
W15-3902,C02-1099,0,0.0658677,"gyuduan}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the tr"
W15-3902,N10-1103,0,\N,Missing
W15-3902,W10-2402,1,\N,Missing
W15-3902,P04-1021,1,\N,Missing
W15-3902,W03-1508,0,\N,Missing
W15-3902,W02-0505,0,\N,Missing
W15-3902,N07-1047,0,\N,Missing
W15-3902,P06-1103,0,\N,Missing
W15-3902,W10-2401,1,\N,Missing
W15-3902,P98-2220,0,\N,Missing
W15-3902,C98-2215,0,\N,Missing
W15-3902,W06-1672,0,\N,Missing
W15-3902,D08-1037,0,\N,Missing
W15-3902,P08-1045,0,\N,Missing
W15-3902,W11-3202,1,\N,Missing
W15-3902,W15-3913,0,\N,Missing
W15-3902,W15-3909,0,\N,Missing
W15-3902,W11-3201,1,\N,Missing
W15-3902,W09-3504,0,\N,Missing
W15-4615,P08-1072,0,0.0325984,"empted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). While 124 Proceedings of the SIGDIAL 2015 Conference, pages 124–128, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics t 0 1 Speaker Guide Tourist 2 Tourist Guide Tourist Guide Guide 3 4 Tourist Guide 5 Tourist 6 Guide Tourist Guide 7 Tourist Guide 8 Tourist Utterance How can I help you? Can you recommend some good places to visit in Singapore? Well if you like to visit an icon of Singapore, Merlion park will be a nice place to visit. That is a symbol for your country, right? Yes, we use that to symbolise Singapore. Okay. The lion head symbolised th"
W15-4615,E06-1002,0,0.0128954,"obtained from both given texts and Wikipedia collection, our proposed method utilizing the results from Wikification contributes to improve the tracking performances compared to the former approaches based on dialogue segment-level correspondences. 2 t 1 Wikification of Concept Mentions in Spoken Dialogues Wikification aims at linking mentions to the relevant entries in Wikipedia. As shown in the examples in Figure 2 for the dialogue in Figure 1, this task is performed by dealing with co-references, ambiguities, and variabilities of the mentions. Following most previous work on Wikification (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Dredze et al., 2010; Han and Sun, 2011; Chen and Ji, 2011), this work also takes a supervised learning to rank algorithm for determining the most relevant concept for each mention in transcribed utterances. In this work, every noun phrase in a given dialogue session is defined as a single mention. To capture more abstract concepts, we take not only named entities or base noun phrases, but also every complex or recursive noun phrase in a dialogue as the instance to be linked. For each mention, a set of candidates are retrieved from a Lucene 1"
W15-4615,D11-1071,0,0.0136063,"n contributes to improve the tracking performances compared to the former approaches based on dialogue segment-level correspondences. 2 t 1 Wikification of Concept Mentions in Spoken Dialogues Wikification aims at linking mentions to the relevant entries in Wikipedia. As shown in the examples in Figure 2 for the dialogue in Figure 1, this task is performed by dealing with co-references, ambiguities, and variabilities of the mentions. Following most previous work on Wikification (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Dredze et al., 2010; Han and Sun, 2011; Chen and Ji, 2011), this work also takes a supervised learning to rank algorithm for determining the most relevant concept for each mention in transcribed utterances. In this work, every noun phrase in a given dialogue session is defined as a single mention. To capture more abstract concepts, we take not only named entities or base noun phrases, but also every complex or recursive noun phrase in a dialogue as the instance to be linked. For each mention, a set of candidates are retrieved from a Lucene 1 index on the whole Wikipedia collection divided by section-level. The ranking score s(m, c) for a given pair o"
W15-4615,W02-0702,0,0.063244,"atures can significantly improve the performances of the task in mixed-initiative human-human dialogues. 1 Introduction Dialogue topic tracking aims at detecting topic transitions and predicting topic categories in ongoing dialogues which address more than a single topic. Since human communications in real-world situations tend to consist of a series of multiple topics even for a single domain, tracking dialogue topics plays a key role in analyzing human-human dialogues as well as improving the naturalness of human-machine interactions by conducting multitopic conversations. Some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) attempted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Youn"
W15-4615,C10-1032,0,0.0294281,"d utilizing the results from Wikification contributes to improve the tracking performances compared to the former approaches based on dialogue segment-level correspondences. 2 t 1 Wikification of Concept Mentions in Spoken Dialogues Wikification aims at linking mentions to the relevant entries in Wikipedia. As shown in the examples in Figure 2 for the dialogue in Figure 1, this task is performed by dealing with co-references, ambiguities, and variabilities of the mentions. Following most previous work on Wikification (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Dredze et al., 2010; Han and Sun, 2011; Chen and Ji, 2011), this work also takes a supervised learning to rank algorithm for determining the most relevant concept for each mention in transcribed utterances. In this work, every noun phrase in a given dialogue session is defined as a single mention. To capture more abstract concepts, we take not only named entities or base noun phrases, but also every complex or recursive noun phrase in a dialogue as the instance to be linked. For each mention, a set of candidates are retrieved from a Lucene 1 index on the whole Wikipedia collection divided by section-level. The r"
W15-4615,P06-1093,0,0.0371547,"tions. Some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) attempted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agendas (Bohus and Rudnicky, 2003; Lee et al., 2008). While 124 Proceedings of the SIGDIAL 2015 Conference, pages 124–128, c Prague, Czech Republic, 2-4 September 2015. 2015 Association for Computational Linguistics t 0 1 Speaker Guide Tourist 2 Tourist Guide Tourist Guide Guide 3 4 Tourist Guide 5 Tourist 6 Guide Tourist Guide 7 Tourist Guide 8 Tourist Utterance How can I help you? Can you recommend some good places to visit in Singapore? Well if you like to visit an icon of Singapore, Merlion park will be a nice place to visit. That is a symbol for your"
W15-4615,P11-1095,0,0.0351157,"Missing"
W15-4615,P14-2004,1,0.717279,"khwan Kim, Rafael E. Banchs, Haizhou Li Human Language Technology Department Institute for Infocomm Research Singapore 138632 {kims,rembanchs,hli}@i2r.a-star.edu.sg Abstract these knowledge-based methods have an advantage of dealing with system-initiative dialogues by controlling dialogue flows based on given resources, they have drawbacks in low flexibility to handle the user’s responses and high costs for building the resources. Recently, we have proposed to explore domain knowledge from Wikipedia for mixed-initiative dialogue topic tracking without significant costs for building resources (Kim et al., 2014a; Kim et al., 2014b). In these methods, a set of articles that have similar contents to a given dialogue segment are selected using vector space model. Then various types of information obtained from the articles are utilized to learn topic trackers based on kernel methods. In this work, we focus on the following limitations of our former work in retrieving relevant concepts at a given turn with the term vector similarity between each pair of dialogue segment and Wikipedia article. Firstly, the contents of conversation could be expressed in totally different ways from the descriptions in the"
W15-4615,W02-0214,0,0.0362271,"tly improve the performances of the task in mixed-initiative human-human dialogues. 1 Introduction Dialogue topic tracking aims at detecting topic transitions and predicting topic categories in ongoing dialogues which address more than a single topic. Since human communications in real-world situations tend to consist of a series of multiple topics even for a single domain, tracking dialogue topics plays a key role in analyzing human-human dialogues as well as improving the naturalness of human-machine interactions by conducting multitopic conversations. Some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) attempted to solve this problem with text categorization approaches for the utterances in a given turn. However, these approaches can only be effective for the cases when users mention the topic-related expressions explicitly in their utterances, because the models for text categorization assume that the proper category for each textual unit can be assigned based only on its own contents. The other direction of dialogue topic tracking made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agend"
W15-4615,C02-1082,0,\N,Missing
W16-2703,P05-1045,0,0.0336585,"Missing"
W16-2703,W03-0419,0,0.0437085,"Missing"
W16-2703,W95-0107,0,0.0925598,"6.0). It is based on linear chain Conditional Random Field (Jenny Rose Finkel et al., 2005). The models were trained on a mixture of CoNLL, MUC-6, MUC-7 and ACE named entity corpora. The basic required output tags are “PERSON”, “LOCATION” and “ORGANIZATION”. 1 Integration https://spacy.io/ 22 Fig. 1. System diagram for automated evaluation 3 The overall system structure of the integrated evaluation system is shown in Fig. 1. In the process of evaluation, an annotated (gold-standard) input document must be provided. Currently, the supported format is IOB (short for Inside, Outside, Beginning) (Ramshaw and Marcus, 1995). In this scheme, every line in the file represents one token with two fields: the word itself and its named entity type. Empty lines denote sentence boundaries. Following is an example of the representation: Albert I-PERSON Einstein I-PERSON was O born O in O Ulm I-LOCATION .O With the methodology defined in section 2, it is ready to evaluate all the selected tools with any data file annotated in the IOB format. Evaluation 3.1 Evaluation Corpus Since all the selected NER tools are able to classify the three entity types: PERSON, LOCATION and ORGANIZATION, the evaluation corpus must contain at"
W16-2703,W09-3302,0,0.0167464,"is an example of the representation: Albert I-PERSON Einstein I-PERSON was O born O in O Ulm I-LOCATION .O With the methodology defined in section 2, it is ready to evaluate all the selected tools with any data file annotated in the IOB format. Evaluation 3.1 Evaluation Corpus Since all the selected NER tools are able to classify the three entity types: PERSON, LOCATION and ORGANIZATION, the evaluation corpus must contain at least the above three entity types. The format is better to be in the supported IOB chunk representation. We found that WikiGold 2 meets the above requirements. WikiGold (Balasuriya et al. 2009) is an annotated corpus over a small sample of Wikipedia articles in CoNLL format (IOB). It contains 145 documents (separated by “DOCSTART-”), 1696 sentences and 39152 tokens. The statistics of named entities is shown in table 1. The prefix “I-” in the tag means that the tag is inside a chunk. While the prefix “B-” indicates that the tag is the beginning of a chunk and is only used when a tag is followed by a tag of the same type without “O” tag between them. The “O” tag just means it is out of the chunk. This IOB chunk representation is much easier for manual annotation than inside XML annota"
W16-2703,W09-1119,0,0.162953,"Missing"
W16-2703,C96-1079,0,0.649285,"Missing"
W16-2703,W99-0613,0,0.0897117,"Missing"
W16-2703,W03-1306,0,0.019176,"he configuration of the proposed hybrid NER system. Both tools showed good scores in our previous evaluation and are able to identify DATE entity without any extra setting (Stanford NER 7-class model includes the DATE type). Our first target domain of application is Wikipedia pages about Singapore. To construct the hybrid NER system, we simply combined the outputs of the Stanford NER system and spaCy NER by using union method. In addition, a dictionary with limited entries on PERSON, LOCATION and ORGANIZATION about Singapore was also created with the expectation of improving system precision (Tsuruoka and Tsujii 2003; Cohen and Sarawagi, 2004). We set the dictionary to have the highest priority when there is any conflict with the outputs from other tools. Then followed by Stanford NER tool, it 24 has the second highest priority determination of final named entities. 4.2 on the Table 4. Evaluation results on History testing dataset Data for Evaluation P Stanford In order to evaluate the performance of the hybrid system, we manually annotated twenty two web pages. All the web pages are from Singapore National Library Board eResources3 . Half of the web pages are about Singapore history, another half are fro"
W16-2703,W03-0430,0,0.0366912,"Missing"
W16-2703,W02-2029,0,0.0490196,"Missing"
W16-2703,A00-1034,0,0.0282468,"Missing"
W16-2703,W11-0207,0,\N,Missing
W16-2708,P04-1021,1,0.668693,"Missing"
W16-2709,W16-2713,0,0.0529993,"Missing"
W16-2709,W15-3912,0,0.0431505,"Missing"
W16-2709,W16-2711,0,0.147552,"Missing"
W16-2709,P04-1021,1,0.691542,"Xiangyu Duan2,Rafael E. Banchs1, Min Zhang2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based met"
W16-2709,D08-1037,0,0.0235887,"mbanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combinatio"
W16-2709,W10-2401,1,0.722231,"rs to the combination of several different models or knowledge sources to support the transliteration generation process. The first machine transliteration shared task (Li et al. 2009b, Li et al. 2009a) was organized and conducted aspart of NEWS 2009 at ACLIJCNLP 2009. It was the first time that common benchmarking data in diverse language pairs was provided for evaluating state-of-the-art machine transliteration. While the focus of the 2009 shared task was on establishing the quality metrics and on setting up a baselinefor transliteration quality based on those metrics, the 2010 shared task (Li et al. 2010a, Li et al. 2010b) focused on expanding the scope of the transliteration generation task to about a dozen languages and on exploring the quality of the task depending on the direction of transliteration. In NEWS 2011 (Zhang et al. 2011a, Zhang et al. 2011b), Abstract This report presents the results from the Machine Transliteration Shared Task conducted as part of The Sixth Named Entities Workshop (NEWS 2016) held at ACL 2016in Berlin, Germany. Similar to previous editions of NEWS Workshop, the Shared Task featured machine transliteration of proper names over 14 different language pairs, incl"
W16-2709,W09-3504,0,0.0634137,"Missing"
W16-2709,W15-3911,0,0.117942,"Missing"
W16-2709,N10-1103,0,0.0421265,"Missing"
W16-2709,C02-1099,0,0.0830346,",minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the tran"
W16-2709,W16-2710,0,0.20966,"Missing"
W16-2709,P06-1103,0,0.0441788,"China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources t"
W16-2709,P07-1119,0,0.0158206,"A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences t"
W16-2709,P06-1010,0,0.0387549,"hang2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of p"
W16-2709,P98-2220,0,0.225327,"s Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the transliteration generation process. The first machine"
W16-2709,W15-3910,0,0.0327487,"Missing"
W16-2709,W15-3913,0,0.0273111,"Missing"
W16-2709,W06-1672,0,0.0300352,"afael E. Banchs1, Min Zhang2, Haizhou Li1, A. Kumaran3 1 Institute for Infocomm Research, A*STAR, Singapore 138632 {rembanchs,hli}@i2r.a-star.edu.sg 2 Soochow University, China 215006 {xiangyuduan,minzhang}@suda.edu.cn 3 Multilingual Systems Research, Microsoft Research India a.kumaran@microsoft.com All of the above points to the critical need for robust Machine Transliteration methods and systems. During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, Al-Onaizan and Knight 2002,Goldwasser and Roth 2008, Goldberg and Elhadad 2008,Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004,Li et al. 2009a, Li et al. 2009b). These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Graphemebased methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods (Knight and Graehl"
W16-2709,W03-1508,0,\N,Missing
W16-2709,W02-0505,0,\N,Missing
W16-2709,N07-1047,0,\N,Missing
W16-2709,P07-2045,0,\N,Missing
W16-2709,C98-2215,0,\N,Missing
W16-2709,W11-3202,1,\N,Missing
W16-2709,W12-4402,1,\N,Missing
W16-2709,J98-4003,0,\N,Missing
W16-2709,W11-3201,1,\N,Missing
W18-2407,Q16-1027,0,0.0684715,"Missing"
W18-2407,W17-4742,0,0.569541,"are often rare words in the document, and generally NMT cannot produce good translation for these local contexts with local named entities. Identifying local named entities and generating their translation with local context is also a challenging task which we will address in this paper. (e.g., the English name for 张志贤 is ‘Teo Chee Hean’ in Singapore while it’s pinyin translation is ‘Zhang Zhi Xian’ in China) To address the NE translation issue, some researchers work on separate models or methods while others incorporate these separate models/methods with the main NMT models (Li et al., 2016; Wang et al., 2017). They use NER to identify and align the NE pairs at both of source and target sentences, then NE pairs are replaced with NE tags for training the model; at reference stage the NE tags at target are replaced by the separate NE translation model or bilingual NE dictionary. The disadvantages of the replacement methods include NE information loss and NE alignment errors. To avoid the complexity and disadvantages of separate model training and integration, in this paper, we add the NE type information and boundary information directly to the source sentence by a NER tool, we hope NMT will learn an"
W18-2407,D15-1166,0,0.0586737,"boundary tags, we can increase the BLEU score by around 1 to 2 points using the standard test sets from WMT2017. We also show that adding NE tags using NER and applying indomain adaptation can be combined to further improve customized machine translation. 1 Introduction As generic machine translation cannot deal well with the translation with local or specific domain context, customized machine translation is adopted to focus on the terminology of local or domain context especially for named-entities translation. Neural machine translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2014; Luong et al., 2015) is a more recent and effective approach than the traditional statistical machine translation (SMT). It uses a large recurrent neural network (RNN) to encode a source sentence into a vector, 41 Proceedings of the Seventh Named Entities Workshop, pages 41–46 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics In general, named entities are more difficult to translate for NMT than SMT. This is because and NMT is weaker in translating less frequent words as compared to SMT. In addition, since there are different types of named entities, e.g. Person, Place, Organi"
W18-2407,J09-4006,0,0.0578878,"Missing"
W18-2407,W16-2209,0,0.0480366,"2016; Zhou et al. 2017; Gehring et al. 2017). Conventional NMT systems do not use linguistic features explicitly. They expect the NMT model to learn these complex sentence structures and linguistic features from big data as word embedding vectors. However, because of uneven data distribution and high linguistic complexity, there is no guarantee that NMT can capture this information and produce proper translation in all cases, especially for those terms which do not occur very often. Recently, researchers have shown the potential benefit of explicitly encoding the linguistic features into NMT. Sennrich and Haddow (2016) proposed to include linguistic features (part-ofspeech tag, lemmatized form and dependency label, morphology) at NMT source encoder side. Roee et al. (2017) instead incorporated syntactic information of target language as linearized, lexicalized constituency trees into NMT target decoder side. Their experiments showed adding linguistic information at both the source and target side can be beneficial for NMT. Based on these findings, in this paper, we propose to incorporate named-entity (NE) features to further improve neural machine translation. Named entities play a crucial role in many mono"
W18-2407,P16-1162,0,0.765532,"apart from the original words in the sentence, we generate and insert NE tags which include both the NE class and NE boundary type for each NE into the sentence, thus we present the NMT encoder with the combined sentence sequence with additional NE tags. The NE tags can be applied to both word-based and character-based source input of any language. For Chinese-to-English translation, the Chinese input can be either a word sequence or a character sequence, the English side is still word-based tokens. We segment all the unknown words as a sequence of subword units using the byte-pair encoding (Sennrich et al., 2016b). 3.1 Figure 1: System Architecture the out of vocabulary (OOV) words after tokenization: Original Source: Patrick coach • NE class and boundary tags: <PERSON&gt; </PERSON&gt; 2 as Avalanche <PERSON&gt; Patrick Roy </PERSON&gt; resigns <ORG&gt; Avalan @@che </ORG&gt; coach When the source language is Chinese, we can use either word-based input or character-based input. To generate character-based input sequence for the Chinese sentence, we just split all Chinese word tokens into character tokens (English tokens are not split). Original Source: 凯发集团成功进军中国 Words with NE tags: <ORG&gt; 凯发 集团 </ORG&gt; 成功 进军 中国 Charact"
W18-2407,P17-2021,0,0.0319443,"Missing"
W18-2407,P82-1020,0,0.82845,"Missing"
W18-2408,P04-1021,1,0.453791,"Missing"
W18-2409,W18-2414,0,0.0493369,"Missing"
W18-2409,P04-1021,1,0.614661,"en1, Rafael E. Banchs2, Min Zhang3, Xiangyu Duan3, Haizhou Li4 1 Singapore University of Technology and Design, Singapore nancychen@alum.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods"
W18-2409,W10-2401,1,0.712599,"ently, neural network approaches have been explored with varying successes, depending on the size of the training data. The first machine transliteration shared task (Li et al. 2009a, Li et al. 2009b) was organized and conducted as part of NEWS 2009 at ACLIJCNLP 2009. It was the first time that common benchmarking data in diverse language pairs was provided for evaluating state-of-the-art machine transliteration. While the focus of the 2009 shared task was on establishing the quality metrics and on setting up a baseline for transliteration quality based on those metrics, the 2010 shared task (Li et al. 2010a, Li et al. 2010b) foAbstract This report presents the results from the Named Entity Transliteration Shared Task conducted as part of The Seventh Named Entities Workshop (NEWS 2018) held at ACL 2018 in Melbourne, Australia. Similar to previous editions of NEWS, the Shared Task featured 19 tasks on proper name transliteration, including 13 different languages and two different Japanese scripts. A total of 6 teams from 8 different institutions participated in the evaluation, submitting 424 runs, involving different transliteration methodologies. Four performance metrics were used to report the"
W18-2409,D08-1037,0,0.0247158,"um.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of"
W18-2409,P17-4012,0,0.0145929,"e-based machine translation). All other systems used some version of neural modeling. It is interesting to note that non-neural systems by SINGA, while not the highest in performance, are generally comparable to neural systems or system combinations which include neural models. Regarding the systems participating in this year evaluation, the UALB’s system (Najafi et al. 2018) was based on multiple system combinations. They presented experimental results involving five different well-known transliteration approaches: DirecTL+ (Jiampojamarn et al. 2009), Sequitur (Bisani and Ney 2008), OpenNMT (Klein et al. 2017), BaseNMT (Sutskever et al. 2014), and RL-NMT (Najafi et al., 2018). They T)EnPe 0 WIPO 0.2 0.4 SINGA UQAM 0.6 UJUS 0.8 EDI 1 UALB Figure 1: Mean F-scores (Top-1) on the evaluation set for all primary submissions and tasks. The UJUS system (Kundu et al. 2018) used an RNN-based NMT framework and a CNN-based NMT framework, where both byte-pair encoding and character-based segmentation were employed for both cases. They also adopted an ensemble method to choose the hypothesis that has the highest frequency of occurrence to further improve accuracy. The EDI system (Grundkiewicz et al. 2018) system"
W18-2409,C02-1099,0,0.129101,"oochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to support the transliter"
W18-2409,P06-1103,0,0.0560026,"ore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to generate the transliteration. The hybrid approach refers to the combination of several different models or knowledge sources to supp"
W18-2409,P07-1119,0,0.0417746,"Li4 1 Singapore University of Technology and Design, Singapore nancychen@alum.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonetic correspondences to gen"
W18-2409,P07-2045,0,0.0067284,"Missing"
W18-2409,P06-1010,0,0.0603142,"ngyu Duan3, Haizhou Li4 1 Singapore University of Technology and Design, Singapore nancychen@alum.mit.edu 2 Nanyang Technological University, Singapore rbanchs@ntu.edu.sg 3 Soochow University, China {minzhang,xiangyuduan}@suda.edu.cn 4 National University of Singapore, Singapore haizhou.li@nus.edu.sg All of the above points to the critical need for robust machine transliteration methods and systems. Significant efforts has been conducted by the research community to address the problem of machine transliteration (Knight and Graehl 1998, Meng et al. 2001, Li et al. 2004, Zelenko and Aone 2006, Sproat et al. 2006, Sherif and Kondrak 2007, Hermjakob et al. 2008, AlOnaizan and Knight 2002, Goldwasser and Roth 2008, Goldberg and Elhadad 2008, Klementiev and Roth 2006, Oh and Choi 2002, Virga and Khudanpur 2003, Wan and Verspoor 1998, Kang and Choi 2000, Gao et al. 2004, Li et al. 2009a, Li et al. 2009b). These efforts fall into three main categories: grapheme-based, phoneme-based and hybrid methods. Grapheme based methods (Li et al. 2004) treat transliteration as a direct orthographic mapping and only uses orthographyrelated features while phoneme-based methods (Knight and Graehl 1998) make use of phonet"
Y08-1004,P05-1064,1,0.919401,"uage, Information and Computation, pages 46–57 46 Infocomm Research (IIR) team has participated in the 2005 and 2007 NIST LREs and demonstrated the state-of-the-art technologies. One of the fundamental issues in SLR is to explore the discriminative cues for spoken languages. In the state-of-the-art language recognition systems, these cues mainly come from the acoustic features (Sugiyama, 1991; Torres-Carassquilo et al., 2002; Burget et al., 2006; Campbell et al., 2006) and phonotactic representations (Hazen and Zue, 1994; Zissman, 1996; Berkling and Barnard, 1994; Corredor-Ardoy et al., 1997; Li and Ma, 2005; Ma, Li, and Tong, 2007), which reflect different aspects of spoken language characteristics. Another issue is how to effectively organize and exploit these language cues obtained from multiple sources in the recognition system design for the best performance. Significant improvements in automatic speech recognition (ASR) have been achieved through exploiting the acoustic features representing the temporal properties of speech spectrum. These acoustic features, such as Mel-frequency Cepstral Coefficients (MFCCs), are also good choices to be the front-ends in language recognition systems. Gaus"
Y98-1020,O91-1004,0,0.0550793,"system[3, 4, 5]. Next we will summarize some of the work under Viterbi framework which is considered as a mainstream approach. 3. LINGUISTIC KNOWLEDGE BASED METHOD Linguistic knowledge based approaches still rely very much on the lexicon. They usually start with all possible segmentations of a sentence, then pick the most likely segmentation from the set of possible segmentations using a probabilistic or cost-based scoring mechanism. The simplest approach, for instance, scores the paths based on the word frequency and picks the sentence with lowest cost as is described by Chang, Chen and Chen[13]. Approaches differ by their scoring or path searching processes. In addition to the word frequency, that is word unigram, some other information is also used to rank the possibilities. The literature involves part-of-speech information, morphological analysis, Chinese proper name automata[14], etc. 3.1 Using word unigram In [14], Chinese word segmentation is viewed as a stochastic transduction problem. A dictionary or lexicon is represented as a Weighted Finite State Transducer[14], or WFST. The weight associated with a word is its word unigram. The summed unigram cost over all the possible p"
Y98-1020,J96-3004,0,0.185529,"a sentence, then pick the most likely segmentation from the set of possible segmentations using a probabilistic or cost-based scoring mechanism. The simplest approach, for instance, scores the paths based on the word frequency and picks the sentence with lowest cost as is described by Chang, Chen and Chen[13]. Approaches differ by their scoring or path searching processes. In addition to the word frequency, that is word unigram, some other information is also used to rank the possibilities. The literature involves part-of-speech information, morphological analysis, Chinese proper name automata[14], etc. 3.1 Using word unigram In [14], Chinese word segmentation is viewed as a stochastic transduction problem. A dictionary or lexicon is represented as a Weighted Finite State Transducer[14], or WFST. The weight associated with a word is its word unigram. The summed unigram cost over all the possible paths are evaluated and the path with lowest cost is selected as the output sequence. The decoding process is a typical instance of Viterbi algorithm. As only the word unigram is used, the segmenter under discussion here is a zeroth-order model. 214 Language, Information and Computation (PACLIC"
