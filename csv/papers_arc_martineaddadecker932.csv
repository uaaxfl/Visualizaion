2020.sltu-1.31,Lenition and Fortition of Stop Codas in {R}omanian,2020,-1,-1,5,0,14727,mathilde hutin,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),0,"The present paper aims at providing a first study of lenition- and fortition-type phenomena in coda position in Romanian, a language that can be considered as less-resourced. Our data show that there are two contexts for devoicing in Romanian: before a voiceless obstruent, which means that there is regressive voicelessness assimilation in the language, and before pause, which means that there is a tendency towards final devoicing proper. The data also show that non-canonical voicing is an instance of voicing assimilation, as it is observed mainly before voiced consonants (voiced obstruents and sonorants alike). Two conclusions can be drawn from our analyses. First, from a phonetic point of view, the two devoicing phenomena exhibit the same behavior regarding place of articulation of the coda, while voicing assimilation displays the reverse tendency. In particular, alveolars, which tend to devoice the most, also voice the least. Second, the two assimilation processes have similarities that could distinguish them from final devoicing as such. Final devoicing seems to be sensitive to speech style and gender of the speaker, while assimilation processes do not. This may indicate that the two kinds of processes are phonologized at two different degrees in the language, assimilation being more accepted and generalized than final devoicing."
2020.jeptalnrecital-jep.33,L{\\'e}nition et fortition des occlusives en coda finale dans deux langues romanes : le fran{\\c{c}}ais et le roumain (Lenition and fortition of word-final stops in two {R}omance languages: {F}rench and {R}omanian),2020,-1,-1,5,0,14727,mathilde hutin,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"L{'}exploration automatis{\'e}e de grands corpus permet d{'}analyser plus finement la relation entre motifs de variation phon{\'e}tique synchronique et changements diachroniques : les erreurs dans les transcriptions automatiques sont riches d{'}enseignements sur la variation contextuelle en parole continue et sur les possibles mutations syst{\'e}miques sur le point d{'}appara{\^\i}tre. D{\`e}s lors, il est int{\'e}ressant de se pencher sur des ph{\'e}nom{\`e}nes phonologiques largement attest{\'e}s dans les langues en diachronie comme en synchronie pour {\'e}tablir leur {\'e}mergence ou non dans des langues qui n{'}y sont pas encore sujettes. La pr{\'e}sente {\'e}tude propose donc d{'}utiliser l{'}alignement forc{\'e} avec variantes de prononciation pour observer les alternances de voisement en coda finale de mot dans deux langues romanes : le fran{\c{c}}ais et le roumain. Il sera mis en {\'e}vidence, notamment, que voisement et d{\'e}voisement non-canoniques des codas fran{\c{c}}aises comme roumaines ne sont pas le fruit du hasard mais bien des instances de d{\'e}voisement final et d{'}assimilation r{\'e}gressive de trait laryngal, qu{'}il s{'}agisse de voisement ou de non-voisement."
2020.jeptalnrecital-jep.70,"R{\\'e}duction temporelle en fran{\\c{c}}ais spontan{\\'e} : o{\\`u} se cache-t-elle ? Une {\\'e}tude des segments, des mots et s{\\'e}quences de mots fr{\\'e}quemment r{\\'e}duits ()",2020,-1,-1,2,0,18740,yaru wu,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"Cette {\'e}tude vise {\`a} proposer une m{\'e}thode adapt{\'e}e {\`a} l{'}{\'e}tude de divers ph{\'e}nom{\`e}nes de variation dans les grands corpus utilisant l{'}alignement automatique de la parole. Cette m{\'e}thode est appliqu{\'e}e pour {\'e}tudier la r{\'e}duction temporelle en fran{\c{c}}ais spontan{\'e}. Nous proposons de qualifier la r{\'e}duction temporelle comme la r{\'e}alisation de suites de segments courts cons{\'e}cutifs. Environ 14{\%} du corpus est consid{\'e}r{\'e} comme r{\'e}duit. Les r{\'e}sultats de l{'}alignement montrent que ces zones impliquent le plus souvent plus d{'}un mot (81{\%}), et que sinon, la position interne du mot est la plus concern{\'e}e. Parmi les exemples de suites de mots les plus r{\'e}duits, on trouve des locutions utilis{\'e}es comme des marqueurs discursifs."
W18-5804,{A}daptor {G}rammars for the Linguist: Word Segmentation Experiments for Very Low-Resource Languages,2018,0,1,4,0,27865,pierre godard,"Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"Computational Language Documentation attempts to make the most recent research in speech and language technologies available to linguists working on language preservation and documentation. In this paper, we pursue two main goals along these lines. The first is to improve upon a strong baseline for the unsupervised word discovery task on two very low-resource Bantu languages, taking advantage of the expertise of linguists on these particular languages. The second consists in exploring the Adaptor Grammar framework as a decision and prediction tool for linguists studying a new language. We experiment 162 grammar configurations for each language and show that using Adaptor Grammars for word segmentation enables us to test hypotheses about a language. Specializing a generic grammar with language specific knowledge leads to great improvements for the word discovery task, ultimately achieving a leap of about 30{\%} token F-score from the results of a strong baseline."
L18-1233,The {F}rench-{A}lgerian Code-Switching Triggered audio corpus ({FACST}),2018,0,5,2,0,29757,amazouz djegdjiga,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"The French Algerian Code-Switching Triggered corpus (FACST) was created in order to support a variety of studies in phonetics, prosody and natural language processing. The first aim of the FACST corpus is to collect a spontaneous Code-switching speech (CS) corpus. In order to obtain a large quantity of spontaneous CS utterances in natural conversations experiments were carried out on how to elicit CS. Applying a triggering protocol by means of code-switched questions was found to be effective in eliciting CS in the responses. To ensure good audio quality, all recordings were made in a soundproof room or in a very calm room. This paper describes FACST corpus, along with the principal steps to build a CS speech corpus in French-Algerian languages and data collection steps. We also explain the selection criteria for the CS speakers and the recording protocols used. We present the methods used for data segmentation and annotation, and propose a conventional transcription of this type of speech in each language with the aim of being well-suited for both computational linguistic and acoustic-phonetic studies. We provide an a quantitative description of the FACST corpus along with results of linguistic studies, and discuss some of the challenges we faced in collecting CS data."
L18-1531,A Very Low Resource Language Speech Corpus for Computational Language Documentation Experiments,2018,0,4,3,0,27865,pierre godard,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Most speech and language technologies are trained with massive amounts of speech and text information. However, most of the world languages do not have such resources and some even lack a stable orthography. Building systems under these almost zero resource conditions is not only promising for speech technology but also for computational language documentation. The goal of computational language documentation is to help field linguists to (semi-)automatically analyze and annotate audio recordings of endangered, unwritten languages. Example tasks are automatic phoneme discovery or lexicon discovery from the speech signal. This paper presents a speech corpus collected during a realistic language documentation process. It is made up of 5k speech utterances in Mboshi (Bantu C25) aligned to French text translations. Speech transcriptions are also made available: they correspond to a non-standard graphemic form close to the language phonology. We detail how the data was collected, cleaned and processed and we illustrate its use through a zero-resource task: spoken term discovery. The dataset is made available to the community for reproducible computational language documentation experiments and their evaluation."
L18-1674,"Parallel Corpora in {M}boshi ({B}antu {C}25, {C}ongo-{B}razzaville)",2018,0,3,2,0,27867,annie rialland,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This article presents multimodal and parallel data collections in Mboshi, as part of the French-German BULB project. It aims at supporting documentation and providing digital resources for less resourced languages with the help of speech and language-based technology. The data collection specifications thus have to meet both field linguists' and computer scientists' requirements, which are large corpora for the latter and linguistically dense data for the former. Beyond speech, the collection comprises pictures and videos documenting social practices, agriculture, wildlife and plants. Visual supports aimed at encouraging people to comment on objects which are meaningful in their daily lives. Speech recordings are composed of the original speech in Mboshi, a respoken version and a translated version to French. These three speech streams remain time-aligned thanks to LIG-AIKUMA, which adds new features to a previous AIKUMA application. The speech corpus includes read material (5k sentences, Bible), verb conjugations and a large part of spontaneous speech (conversations, picture descriptions) resulting in over 50 hours of Mboshi speech, of which 20 hours are already respoken and orally translated to French. These parallel oral data are intended for linguistic documentation (tonology, phonology...) and automatic processing (corpus annotation, alignment between Mboshi speech and French translations)."
L16-1512,{F}rench Learners Audio Corpus of {G}erman Speech ({FLACGS}),2016,10,0,2,0,17001,jane wottawa,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The French Learners Audio Corpus of German Speech (FLACGS) was created to compare German speech production of German native speakers (GG) and French learners of German (FG) across three speech production tasks of increasing production complexity: repetition, reading and picture description. 40 speakers, 20 GG and 20 FG performed each of the three tasks, which in total leads to approximately 7h of speech. The corpus was manually transcribed and automatically aligned. Analysis that can be performed on this type of corpus are for instance segmental differences in the speech production of L2 learners compared to native speakers. We chose the realization of the velar nasal consonant engma. In spoken French, engma does not appear in a VCV context which leads to production difficulties in FG. With increasing speech production complexity (reading and picture description), engma is realized as engma + plosive by FG in over 50{\%} of the cases. The results of a two way ANOVA with unequal sample sizes on the durations of the different realizations of engma indicate that duration is a reliable factor to distinguish between engma and engma + plosive in FG productions compared to the engma productions in GG in a VCV context. The FLACGS corpus allows to study L2 production and perception."
2016.jeptalnrecital-jep.6,Alignement de s{\\'e}quences phon{\\'e}tiques pour une analyse phonologique des erreurs de transcription automatique (Phonetic sequences alignment for a phonemic analysis of automatic speech transcription errors ),2016,-1,-1,2,1,35957,camille dutrey,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"La transcription automatique de la parole obtient aujourd{'}hui des performances {\'e}lev{\'e}es avec des taux d{'}erreur qui tombent facilement en dessous de 10{\%} pour une parole journalistique. Cependant, pour des conversations plus libres, ils stagnent souvent autour de 20{--}30{\%}. En fran{\c{c}}ais, une grande partie des erreurs sont dues {\`a} des confusions entre homophones n{'}impliquant pas les niveaux acousticophon{\'e}tique et phonologique. Cependant, de nombreuses erreurs peuvent s{'}expliquer par des variantes de productions non pr{\'e}vues par le syst{\`e}me. Afin de mieux comprendre quels processus phonologiques pourraient expliquer ces variantes sp{\'e}cifiques de la parole spontan{\'e}e, nous proposons une analyse des erreurs en comparant prononciations attendue (r{\'e}f{\'e}rence) et reconnue (hypoth{\`e}se) via un alignement phon{\'e}tique par programmation dynamique. Les distances locales entre paires de phon{\`e}mes appari{\'e}s correspondent au nombre de traits phon{\'e}tiques disjoints. Nos analyses permettent d{'}identifier les traits phon{\'e}tiques les plus fr{\'e}quemment impliqu{\'e}s dans les erreurs et donnent des pistes pour des interpr{\'e}tations phonologiques."
2016.jeptalnrecital-jep.61,Production des voyelles parl{\\'e}es et chant{\\'e}es dans le Cantu in Paghjella (Production of spoken and sung vowels in Cantu in Paghjella),2016,-1,-1,6,0,18714,claire pillotloiseau,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"Quelles sont les caract{\'e}ristiques acoustiques et articulatoires des voyelles parl{\'e}es et chant{\'e}es du Cantu in Paghjella (polyphonie corse {\`a} trois voix), en fonction du chanteur, de la voyelle et de la fr{\'e}quence fondamentale ? L{'}analyse acoustique des quatre premiers formants de la parole au chant et celle des mouvements articulatoires lingual et labial, montrent g{\'e}n{\'e}ralement (i) une significative augmentation de F1 avec abaissement lingual mais fermeture labiale, en lien avec une corr{\'e}lation entre F0 et F1 ; (ii) une baisse de F2 pour les voyelles ant{\'e}rieures, une post{\'e}riorisation linguale et un recul de l{'}ombre hyo{\""\i}dienne uniquement pour le bassu ; (iii) une nette augmentation de F3 et F4 surtout chez le bassu ; (iv) une augmentation du Singing Power Ratio surtout chez les bassu et secunda. Ses valeurs sont toutefois inf{\'e}rieures {\`a} celles de chanteurs lyriques, et ne correspondant pas comme ces derniers {\`a} un rapprochement de F3 et F4."
2016.jeptalnrecital-jep.71,R{\\^o}le des contextes lexical et post-lexical dans la r{\\'e}alisation du schwa : apports du traitement automatique de grands corpus (Role of lexical and post-lexical contexts in {F}rench schwa realisations : benefits of automatic processing of large corpora ),2016,-1,-1,2,0,18740,yaru wu,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"Le r{\^o}le du contexte est connu dans la r{\'e}alisation ou non du schwa en fran{\c{c}}ais. Deux grands corpus oraux de parole journalistique (ETAPE) et de parole famili{\`e}re (NCCFr), dans lesquels la realisation de schwa est d{\'e}termin{\'e}e {\`a} partir d{'}un alignement automatique, ont {\'e}t{\'e} utilis{\'e}s pour examiner la contribution du contexte au sein du mot contenant schwa (lexical) vs. au travers de la fronti{\`e}re avec le mot pr{\'e}c{\'e}dent (post-lexical). Nos r{\'e}sultats montrent l{'}importance du contexte pr{\'e}-fronti{\`e}re dans l{'}explication de la chute du schwa dans la premi{\`e}re syllabe d{'}un mot polysyllabique en parole spontan{\'e}e. Si le mot pr{\'e}c{\'e}dant se termine par une consonne, nous pouvons faire appel {\`a} la loi des trois consonnes et au principe de sonorit{\'e} pour expliquer des diff{\'e}rences de comportement en fonction de la nature des consonnes en contact."
2016.jeptalnrecital-jep.78,Sur les traces acoustiques de /Ê/ et /{\\c{c}}/ en allemand {L}2 (Acoustic tracing of /{S}/ and /{\\c{c}}/ in {G}erman {L}2),2016,-1,-1,2,0,17001,jane wottawa,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"Les apprenants fran{\c{c}}ais de l{'}allemand ont des difficult{\'e}s {\`a} produire la fricative palatale sourde allemande /{\c{c}}/ (Ich-Laut) et ont tendance {\`a} la remplacer par la fricative post-alv{\'e}olaire /S/. Nous nous demandons si avec des mesures acoustiques ces impr{\'e}cisions de production peuvent {\^e}tre quantifi{\'e}es d{'}une mani{\`e}re plus objective. Deux mesures acoustiques ont {\'e}t{\'e} examin{\'e}es afin de distinguer au mieux /S/ et /{\c{c}}/ dans un contexte VC en position finale de mot dans des productions de locuteurs germanophones natifs. Elles servent ensuite {\`a} quantifier les difficult{\'e}s de production des apprenants fran{\c{c}}ais. 285 tokens de 20 locuteurs natifs et 20 locuteurs L2 ont {\'e}t{\'e} analys{\'e}s. Les mesures appliqu{\'e}es sont le centre de gravit{\'e} spectral et des rapports d{'}intensit{\'e} par bande de fr{\'e}quence. Sur les productions de locuteurs natifs, les r{\'e}sultats montrent que la mesure la plus fiable pour distinguer acoustiquement /S/ et /{\c{c}}/ est le ratio d{'}intensit{\'e} entre fr{\'e}quences hautes (4-7 kHz) et basses (1-4 kHz). Les mesures confirment {\'e}galement les difficult{\'e}s de production des locuteurs natifs fran{\c{c}}ais."
2016.jeptalnrecital-jep.81,Utilisation des repr{\\'e}sentations continues des mots et des param{\\`e}tres prosodiques pour la d{\\'e}tection d{'}erreurs dans les transcriptions automatiques de la parole (Combining continuous word representation and prosodic features for {ASR} error detection),2016,-1,-1,6,0,862,sahar ghannay,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"R{\'e}cemment, l{'}utilisation des repr{\'e}sentations continues de mots a connu beaucoup de succ{\`e}s dans plusieurs t{\^a}ches de traitement du langage naturel. Dans cet article, nous proposons d{'}{\'e}tudier leur utilisation dans une architecture neuronale pour la t{\^a}che de d{\'e}tection des erreurs au sein de transcriptions automatiques de la parole. Nous avons {\'e}galement exp{\'e}riment{\'e} et {\'e}valu{\'e} l{'}utilisation de param{\`e}tres prosodiques en suppl{\'e}ments des param{\`e}tres classiques (lexicaux, syntaxiques, . . .). La principale contribution de cet article porte sur la combinaison de diff{\'e}rentes repr{\'e}sentations continues de mots : plusieurs approches de combinaison sont propos{\'e}es et {\'e}valu{\'e}es afin de tirer profit de leurs compl{\'e}mentarit{\'e}s. Les exp{\'e}riences sont effectu{\'e}es sur des transcriptions automatiques du corpus ETAPE g{\'e}n{\'e}r{\'e}es par le syst{\`e}me de reconnaissance automatique du LIUM. Les r{\'e}sultats obtenus sont meilleurs que ceux d{'}un syst{\`e}me {\'e}tat de l{'}art bas{\'e} sur les champs al{\'e}atoires conditionnels. Pour terminer, nous montrons que la mesure de confiance produite est particuli{\`e}rement bien calibr{\'e}e selon une {\'e}valuation en terme d{'}Entropie Crois{\'e}e Normalis{\'e}e (NCE)."
lavergne-etal-2014-automatic,Automatic language identity tagging on word and sentence-level in multilingual text sources: a case-study on {L}uxembourgish,2014,9,1,3,0,8590,thomas lavergne,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Luxembourgish, embedded in a multilingual context on the divide between Romance and Germanic cultures, remains one of Europe{'}s under-described languages. This is due to the fact that the written production remains relatively low, and linguistic knowledge and resources, such as lexica and pronunciation dictionaries, are sparse. The speakers or writers will frequently switch between Luxembourgish, German, and French, on a per-sentence basis, as well as on a sub-sentence level. In order to build resources like lexicons, and especially pronunciation lexicons, or language models needed for natural language processing tasks such as automatic speech recognition, language used in text corpora should be identified. In this paper, we present the design of a manually annotated corpus of mixed language sentences as well as the tools used to select these sentences. This corpus of difficult sentences was used to test a word-based language identification system. This language identification system was used to select textual data extracted from the web, in order to build a lexicon and language models. This lexicon and language model were used in an Automatic Speech Recognition system for the Luxembourgish language which obtain a 25{\textbackslash}{\%} WER on the Quaero development data."
luzzati-etal-2014-human,Human annotation of {ASR} error regions: Is {``}gravity{''} a sharable concept for human annotators?,2014,12,1,4,0,39857,daniel luzzati,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper is concerned with human assessments of the severity of errors in ASR outputs. We did not design any guidelines so that each annotator involved in the study could consider the {``}seriousness{''} of an ASR error using their own scientific background. Eight human annotators were involved in an annotation task on three distinct corpora, one of the corpora being annotated twice, hiding this annotation in duplicate to the annotators. None of the computed results (inter-annotator agreement, edit distance, majority annotation) allow any strong correlation between the considered criteria and the level of seriousness to be shown, which underlines the difficulty for a human to determine whether a ASR error is serious or not."
ben-jannet-etal-2014-eter,{ETER} : a new metric for the evaluation of hierarchical named entity recognition,2014,12,3,2,0,35025,mohamed jannet,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper addresses the question of hierarchical named entity evaluation. In particular, we focus on metrics to deal with complex named entity structures as those introduced within the QUAERO project. The intended goal is to propose a smart way of evaluating partially correctly detected complex entities, beyond the scope of traditional metrics. None of the existing metrics are fully adequate to evaluate the proposed QUAERO task involving entity detection, classification and decomposition. We are discussing the strong and weak points of the existing metrics. We then introduce a new metric, the Entity Tree Error Rate (ETER), to evaluate hierarchical and structured named entity detection, classification and decomposition. The ETER metric builds upon the commonly accepted SER metric, but it takes the complex entity structure into account by measuring errors not only at the slot (or complex entity) level but also at a basic (atomic) entity level. We are comparing our new metric to the standard one using first some examples and then a set of real data selected from the ETAPE evaluation results."
W12-1301,"{M}bochi : corpus oral, traitement automatique et exploration phonologique ({M}boshi: oral corpus, automatic processing {\\&} phonological mining) [in {F}rench]",2012,-1,-1,3,0,27867,annie rialland,"{JEP}-{TALN}-{RECITAL} 2012, Workshop {TALA}f 2012: Traitement Automatique des Langues Africaines ({TALA}f 2012: {A}frican Language Processing)",0,None
vasilescu-etal-2012-cross,Cross-lingual studies of {ASR} errors: paradigms for perceptual evaluations,2012,15,5,2,1,14729,ioana vasilescu,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"It is well-known that human listeners significantly outperform machines when it comes to transcribing speech. This paper presents a progress report of the joint research in the automatic vs human speech transcription and of the perceptual experiments developed at LIMSI that aims to increase our understanding of automatic speech recognition errors. Two paradigms are described here in which human listeners are asked to transcribe speech segments containing words that are frequently misrecognized by the system. In particular, we sought to gain information about the impact of increased context to help humans disambiguate problematic lexical items, typically homophone or near-homophone words. The long-term aim of this research is to improve the modeling of ambiguous contexts so as to reduce automatic transcription errors."
doukhan-etal-2012-designing,Designing {F}rench Tale Corpora for Entertaining Text To Speech Synthesis,2012,0,5,5,0,29766,david doukhan,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Text and speech corpora for training a tale telling robot have been designed, recorded and annotated. The aim of these corpora is to study expressive storytelling behaviour, and to help in designing expressive prosodic and co-verbal variations for the artificial storyteller). A set of 89 children tales in French serves as a basis for this work. The tales annotation principles and scheme are described, together with the corpus description in terms of coverage and inter-annotator agreement. Automatic analysis of a new tale with the help of this corpus and machine learning is discussed. Metrics for evaluation of automatic annotation methods are discussed. A speech corpus of about 1 hour, with 12 tales has been recorded and aligned and annotated. This corpus is used for predicting expressive prosody in children tales, above the level of the sentence."
F12-2028,Quel est l{'}apport de la d{\\'e}tection d{'}entit{\\'e}s nomm{\\'e}es pour l{'}extraction d{'}information en domaine restreint ? (What is the contribution of named entities detection for information extraction in restricted domain ?) [in {F}rench],2012,-1,-1,5,1,35957,camille dutrey,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
F12-1042,Une comparaison de la d{\\'e}clinaison de F0 entre le fran{\\c{c}}ais et l{'}allemand journalistiques (F0-declination : a comparison between {F}rench and {G}erman journalistic speech) [in {F}rench],2012,-1,-1,3,0,43487,carolin schmid,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
F12-1069,La liaison dans la parole spontan{\\'e}e famili{\\`e}re : explorations semi-automatiques de grands corpus ({F}rench Liaison in casual speech : automatic and manual investigations) [in {F}rench],2012,-1,-1,1,1,14731,martine addadecker,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
F12-1082,Comparaison de parole journalistique et de parole spontan{\\'e}e : analyses de s{\\'e}quences entre pauses (Comparison of journalistic and spontaneous speech: analysis of sequences between pauses) [in {F}rench],2012,-1,-1,2,0,18634,cedric gendrot,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
snoeren-etal-2010-study,The Study of Writing Variants in an Under-resourced Language: Some Evidence from Mobile N-Deletion in {L}uxembourgish,2010,9,2,2,0,45967,natalie snoeren,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The national language of the Grand-Duchy of Luxembourg, Luxembourgish, has often been characterized as one of Europe's under-described and under-resourced languages. Because of a limited written production of Luxembourgish, poorly observed writing standardization (as compared to other languages such as English and French) and a large diversity of spoken varieties, the study of Luxembourgish poses many interesting challenges to automatic speech processing studies as well as to linguistic enquiries. In the present paper, we make use of large corpora to focus on typical writing and derived pronunciation variants in Luxembourgish, elicited by mobile -n deletion (hereafter shortened to MND). Using transcriptions from the House of Parliament debates and 10k words from news reports, we examine the reality of MND variants in written transcripts of speech. The goal of this study is manyfold: quantify the potential of variation due to MND in written Luxembourgish, check the mandatory status of the MND rule and discuss the arising problems for automatic spoken Luxembourgish processing."
nemoto-etal-2010-word,Word Boundaries in {F}rench: Evidence from Large Speech Corpora,2010,18,1,2,0,46068,rena nemoto,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The goal of this paper is to investigate French word segmentation strategies using phonemic and lexical transcriptions as well as prosodic and part-of-speech annotations. Average fundamental frequency (f0) profiles and phoneme duration profiles are measured using 13 hours of broadcast news speech to study prosodic regularities of French words. Some influential factors are taken into consideration for f0 and duration measurements: word syllable length, word-final schwa, part-of-speech. Results from average f0 profiles confirm word final syllable accentuation and from average duration profiles, we can observe long word final syllable length. Both are common tendencies in French. From noun phrase studies, results of average f0 profiles illustrate higher noun first syllable after determiner. Inter-vocalic duration profile results show long inter-vocalic duration between determiner vowel and preceding word vowel. These results reveal measurable cues contributing to word boundary location. Further studies will include more detailed within syllable f0 patterns, other speaking styles and languages."
vasilescu-etal-2010-role,On the Role of Discourse Markers in Interactive Spoken Question Answering Systems,2010,26,3,3,1,14729,ioana vasilescu,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents a preliminary analysis of the role of some discourse markers and the vocalic hesitation ''``euh'''' in a corpus of spoken human utterances collected with the Ritel system, an open domain and spoken dialog system. The frequency and contextual combinatory of classical discourse markers and of the vocalic hesitation have been studied. This analysis pointed out some specificity in terms of combinatory of the analyzed items. The classical discourse markers seem to help initiating larger discursive blocks both at initial and medial positions of the on-going turns. The vocalic hesitation stand also for marking the user's embarrassments and wish to close the dialog."
bernard-etal-2010-question,A Question-answer Distance Measure to Investigate {QA} System Progress,2010,8,6,3,0,29860,guillaume bernard,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The performance of question answering system is evaluated through successive evaluations campaigns. A set of questions are given to the participating systems which are to find the correct answer in a collection of documents. The creation process of the questions may change from one evaluation to the next. This may entail an uncontroled question difficulty shift. For the QAst 2009 evaluation campaign, a new procedure was adopted to build the questions. Comparing results of QAst 2008 and QAst 2009 evaluations, a strong performance loss could be measured in 2009 for French and English, while the Spanish systems globally made progress. The measured loss might be related to this new way of elaborating questions. The general purpose of this paper is to propose a measure to calibrate the difficulty of a question set. In particular, a reasonable measure should output higher values for 2009 than for 2008. The proposed measure relies on a distance measure between the critical elements of a question and those of the associated correct answer. An increase of the proposed distance measure for French and English 2009 evaluations as compared to 2008 could be established. This increase correlates with the previously observed degraded performances. We conclude on the potential of this evaluation criterion: the importance of such a measure for the elaboration of new question corpora for questions answering systems and a tool to control the level of difficulty for successive evaluation campaigns."
rouas-etal-2010-comparison,"Comparison of Spectral Properties of Read, Prepared and Casual Speech in {F}rench",2010,9,2,3,0,18211,jeanluc rouas,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we investigate the acoustic properties of phonemes in three speaking styles: read speech, prepared speech and spontaneous speech. Our aim is to better understand why speech recognition systems still fails to achieve good performances on spontaneous speech. This work follows the work of Nakamura et al. on Japanese speaking styles, with the difference that we here focus on French. Using Nakamura's method, we use classical speech recognition features, MFCC, and try to represent the effects of the speaking styles on the spectral space. Two measurements are defined in order to represent the spectral space reduction and the spectral variance extension. Experiments are then carried on to investigate if indeed we find some differences between the three speaking styles using these measurements. We finally compare our results to those obtained by Nakamura on Japanese to see if the same phenomenon appears. We happen to find some cues, and it also seems that phone duration also plays an important role regarding spectral reduction, especially for spontaneous speech."
adda-decker-etal-2008-annotation,Annotation and analysis of overlapping speech in political interviews,2008,11,16,1,1,14731,martine addadecker,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Looking for a better understanding of spontaneous speech-related phenomena and to improve automatic speech recognition (ASR), we present here a study on the relationship between the occurrence of overlapping speech segments and disfluencies (filled pauses, repetitions, revisions) in political interviews. First we present our data, and our overlap annotation scheme. We detail our choice of overlapping tags and our definition of disfluencies; the observed ratios of the different overlapping tags are examined, as well as their correlation with of the speaker role and propose two measures to characterise speakersÂ interacting attitude: the attack/resist ratio and the attack density. We then study the relationship between the overlapping speech segments and the disfluencies in our corpus, before concluding on the perspectives that our experiments offer."
adda-decker-etal-2008-developments,"Developments of {``}L{\\\e}tzebuergesch{''} Resources for Automatic Speech Processing and Linguistic Studies""",2008,5,8,1,1,14731,martine addadecker,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In the present contribution we start with an overview of the linguistic situation of Luxembourg. We then describe specificities of spoken and written L{\""e}tzebuergesch, with respect to automatic speech processing. Multilingual code-switching and code-mixing, poor writing standardization as compared to languages such as English or French, a large diversity of spoken varieties, together with a limited written production of L{\""e}tzebuergesch language contribute to pose many interesting challenges to automatic speech processing both for speech technologies and linguistic studies. Multilingual filtering has been investigated to sort out Luxembourgish from German and French. Word list coverage and language model perplexity results, using sibling resources collected from the Web, are presented. A phonemic inventory has been adopted for pronunciation dictionary development, a grapheme-phoneme tool has been developed and pronunciation research issues related to the multilingual context are highlighted. Results achieved in resource development allow to envision the realisation of an ASR system."
nemoto-etal-2008-speech,Speech Errors on Frequently Observed Homophones in {F}rench: Perceptual Evaluation vs Automatic Classification,2008,10,6,3,0,46068,rena nemoto,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The present contribution aims at increasing our understanding of automatic speech recognition (ASR) errors involving frequent homophone or almost homophone words by confronting them to perceptual results. The long-term aim is to improve acoustic modelling of these items to reduce automatic transcription errors. A first question of interest addressed in this paper is whether homophone words such as ÂetÂ (and); and ÂestÂ (to be), for which ASR systems rely on language model weights, can be discriminated in a perceptual transcription test with similar n-gram constraints. A second question concerns the acoustic separability of the two homophone words using appropriate acoustic and prosodic attributes. The perceptual test reveals that even though automatic and perceptual errors correlate positively, human listeners deal with local ambiguity more efficiently than the ASR system in conditions which attempt to approximate the information available for decision for a 4-gram language model. The corresponding acoustic analysis shows that the two homophone words may be distinguished thanks to some relevant acoustic and prosodic attributes. A first experiment in automatic classification of the two words using data mining techniques highlights the role of the prosodic (duration and voicing) and contextual information (pauses co-occurrence) in distinguishing the two words. Current results, even though preliminary, suggests that new levels of information, so far unexplored in pronunciationsÂ modelling for ASR, may be considered in order to efficiently factorize the word variants observed in speech and to improve the automatic speech transcription."
P01-1002,Invited Talk: Processing Broadcast Audio for Information Access,2001,18,2,4,0,40380,jeanluc gauvain,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"This paper addresses recent progress in speaker-independent, large vocabulary, continuous speech recognition, which has opened up a wide range of near and mid-term applications. One rapidly expanding application area is the processing of broadcast audio for information access. At LIMSI, broadcast news transcription systems have been developed for English, French, German, Mandarin and Portuguese, and systems for other languages are under development. Audio indexation must take into account the specificities of audio data, such as needing to deal with the continuous data stream and an imperfect word transcription. Some near-term applications areas are audio data mining, selective dissemination of information and media monitoring."
