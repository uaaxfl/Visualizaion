2021.wnut-1.11,Can images help recognize entities? A study of the role of images for Multimodal {NER},2021,-1,-1,4,0,133,shuguang chen,Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),0,"Multimodal named entity recognition (MNER) requires to bridge the gap between language understanding and visual context. While many multimodal neural techniques have been proposed to incorporate images into the MNER task, the model{'}s ability to leverage multimodal interactions remains poorly understood. In this work, we conduct in-depth analyses of existing multimodal fusion techniques from different perspectives and describe the scenarios where adding information from the image does not always boost performance. We also study the use of captions as a way to enrich the context for MNER. Experiments on three datasets from popular social platforms expose the bottleneck of existing multimodal models and the situations where using captions is beneficial."
2021.socialnlp-1.14,Mitigating Temporal-Drift: A Simple Approach to Keep {NER} Models Crisp,2021,-1,-1,3,0,133,shuguang chen,Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media,0,"Performance of neural models for named entity recognition degrades over time, becoming stale. This degradation is due to temporal drift, the change in our target variables{'} statistical properties over time. This issue is especially problematic for social media data, where topics change rapidly. In order to mitigate the problem, data annotation and retraining of models is common. Despite its usefulness, this process is expensive and time-consuming, which motivates new research on efficient model updating. In this paper, we propose an intuitive approach to measure the potential trendiness of tweets and use this metric to select the most informative instances to use for training. We conduct experiments on three state-of-the-art models on the Temporal Twitter Dataset. Our approach shows larger increases in prediction accuracy with less training data than the alternatives, making it an attractive, practical solution."
2021.findings-emnlp.141,{C}har2{S}ubword: Extending the Subword Embedding Space Using Robust Character Compositionality,2021,-1,-1,6,1,134,gustavo aguilar,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword tokenization process of language models as it provides multiple benefits. However, this process is solely based on pre-training data statistics, making it hard for the tokenizer to handle infrequent spellings. On the other hand, though robust to misspellings, pure character-level models often lead to unreasonably long sequences and make it harder for the model to learn meaningful words. To alleviate these challenges, we propose a character-based subword module (char2subword) that learns the subword embedding table in pre-trained models like BERT. Our char2subword module builds representations from characters out of the subword vocabulary, and it can be used as a drop-in replacement of the subword embedding table. The module is robust to character-level alterations such as misspellings, word inflection, casing, and punctuation. We integrate it further with BERT through pre-training while keeping BERT transformer parameters fixed{--}and thus, providing a practical method. Finally, we show that incorporating our module to mBERT significantly improves the performance on the social media linguistic code-switching evaluation (LinCE) benchmark."
2021.findings-emnlp.332,From None to Severe: {P}redicting Severity in Movie Scripts,2021,-1,-1,4,0,7235,yigeng zhang,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"In this paper, we introduce the task of predicting severity of age-restricted aspects of movie content based solely on the dialogue script. We first investigate categorizing the ordinal severity of movies on 5 aspects: Sex, Violence, Profanity, Substance consumption, and Frightening scenes. The problem is handled using a siamese network-based multitask framework which concurrently improves the interpretability of the predictions. The experimental results show that our method outperforms the previous state-of-the-art model and provides useful information to interpret model predictions. The proposed dataset and source code are publicly available at our GitHub repository."
2021.findings-acl.377,{PSED}: A Dataset for Selecting Emphasis in Presentation Slides,2021,-1,-1,7,1,8389,amirreza shirani,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.434,Data Augmentation for Cross-Domain Named Entity Recognition,2021,-1,-1,4,0,133,shuguang chen,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Current work in named entity recognition (NER) shows that data augmentation techniques can produce more robust models. However, most existing techniques focus on augmenting in-domain data in low-resource scenarios where annotated data is quite limited. In this work, we take this research direction to the opposite and study cross-domain data augmentation for the NER task. We investigate the possibility of leveraging data from high-resource domains by projecting it into the low-resource domains. Specifically, we propose a novel neural architecture to transform the data representation from a high-resource to a low-resource domain by learning the patterns (e.g. style, noise, abbreviations, etc.) in the text that differentiate them and a shared feature space where both domains are aligned. We experiment with diverse datasets and show that transforming the data to the low-resource domain representation achieves significant improvements over only using data from high-resource domains."
2021.calcs-1.15,Normalization and Back-Transliteration for Code-Switched Data,2021,-1,-1,2,0,12028,dwija parikh,Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching,0,"Code-switching is an omnipresent phenomenon in multilingual communities all around the world but remains a challenge for NLP systems due to the lack of proper data and processing techniques. Hindi-English code-switched text on social media is often transliterated to the Roman script which prevents from utilizing monolingual resources available in the native Devanagari script. In this paper, we propose a method to normalize and back-transliterate code-switched Hindi-English text. In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data. We also release a dataset of script-corrected Hindi-English code-switched sentences labeled for the named entity recognition and part-of-speech tagging tasks to facilitate further research."
2020.trac-1.20,Aggression and Misogyny Detection using {BERT}: A Multi-Task Approach,2020,-1,-1,6,1,14326,niloofar samghabadi,"Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying",0,"In recent times, the focus of the NLP community has increased towards offensive language, aggression, and hate-speech detection.This paper presents our system for TRAC-2 shared task on {``}Aggression Identification{''} (sub-task A) and {``}Misogynistic Aggression Identification{''} (sub-task B). The data for this shared task is provided in three different languages - English, Hindi, and Bengali. Each data instance is annotated into one of the three aggression classes - Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes - Gendered and Non-Gendered. We propose an end-to-end neural model using attention on top of BERT that incorporates a multi-task learning paradigm to address both the sub-tasks simultaneously. Our team, {``}na14{''}, scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task. The code and the model weights are publicly available at https://github.com/NiloofarSafi/TRAC-2. Keywords: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media"
2020.trac-1.23,Detecting Early Signs of Cyberbullying in Social Media,2020,-1,-1,3,1,14326,niloofar samghabadi,"Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying",0,"Nowadays, the amount of users{'} activities on online social media is growing dramatically. These online environments provide excellent opportunities for communication and knowledge sharing. However, some people misuse them to harass and bully others online, a phenomenon called cyberbullying. Due to its harmful effects on people, especially youth, it is imperative to detect cyberbullying as early as possible before it causes irreparable damages to victims. Most of the relevant available resources are not explicitly designed to detect cyberbullying, but related content, such as hate speech and abusive language. In this paper, we propose a new approach to create a corpus suited for cyberbullying detection. We also investigate the possibility of designing a framework to monitor the streams of users{'} online messages and detects the signs of cyberbullying as early as possible."
2020.semeval-1.100,{S}em{E}val-2020 Task 9: Overview of Sentiment Analysis of Code-Mixed Tweets,2020,-1,-1,8,0,11186,parth patwa,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"In this paper, we present the results of the SemEval-2020 Task 9 on Sentiment Analysis of Code-Mixed Tweets (SentiMix 2020). We also release and describe our Hinglish (Hindi-English)and Spanglish (Spanish-English) corpora annotated with word-level language identification and sentence-level sentiment labels. These corpora are comprised of 20K and 19K examples, respectively. The sentiment labels are - Positive, Negative, and Neutral. SentiMix attracted 89 submissions in total including 61 teams that participated in the Hinglish contest and 28 submitted systems to the Spanglish competition. The best performance achieved was 75.0{\%} F1 score for Hinglish and 80.6{\%} F1 for Spanglish. We observe that BERT-like models and ensemble methods are the most common and successful approaches among the participants."
2020.semeval-1.184,{S}em{E}val-2020 Task 10: Emphasis Selection for Written Text in Visual Media,2020,-1,-1,6,1,8389,amirreza shirani,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"In this paper, we present the main findings and compare the results of SemEval-2020 Task 10, Emphasis Selection for Written Text in Visual Media. The goal of this shared task is to design automatic methods for emphasis selection, i.e. choosing candidates for emphasis in textual content to enable automated design assistance in authoring. The main focus is on short text instances for social media, with a variety of examples, from social media posts to inspirational quotes. Participants were asked to model emphasis using plain text with no additional context from the user or other design considerations. SemEval-2020 Emphasis Selection shared task attracted 197 participants in the early phase and a total of 31 teams made submissions to this task. The highest-ranked submission achieved 0.823 Matchm score. The analysis of systems submitted to the task indicates that BERT and RoBERTa were the most common choice of pre-trained models used, and part of speech tag (POS) was the most useful feature. Full results can be found on the task{'}s website."
2020.lrec-1.166,Age Suitability Rating: Predicting the {MPAA} Rating Based on Movie Dialogues,2020,-1,-1,4,0,7236,mahsa shafaei,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Movies help us learn and inspire societal change. But they can also contain objectionable content that negatively affects viewers{'} behaviour, especially children. In this paper, our goal is to predict the suitability of movie content for children and young adults based on scripts. The criterion that we use to measure suitability is the MPAA rating that is specifically designed for this purpose. We create a corpus for movie MPAA ratings and propose an RNN based architecture with attention that jointly models the genre and the emotions in the script to predict the MPAA rating. We achieve 81{\%} weighted F1-score for the classification model that outperforms the traditional machine learning method by 7{\%}."
2020.lrec-1.223,{L}in{CE}: A Centralized Benchmark for Linguistic Code-switching Evaluation,2020,39,0,3,1,134,gustavo aguilar,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Recent trends in NLP research have raised an interest in linguistic code-switching (CS); modern approaches have been proposed to solve a wide range of NLP tasks on multiple language pairs. Unfortunately, these proposed methods are hardly generalizable to different code-switched languages. In addition, it is unclear whether a model architecture is applicable for a different task while still being compatible with the code-switching setting. This is mainly because of the lack of a centralized benchmark and the sparse corpora that researchers employ based on their specific needs and interests. To facilitate research in this direction, we propose a centralized benchmark for Linguistic Code-switching Evaluation (LinCE) that combines eleven corpora covering four different code-switched language pairs (i.e., Spanish-English, Nepali-English, Hindi-English, and Modern Standard Arabic-Egyptian Arabic) and four tasks (i.e., language identification, named entity recognition, part-of-speech tagging, and sentiment analysis). As part of the benchmark centralization effort, we provide an online platform where researchers can submit their results while comparing with others in real-time. In addition, we provide the scores of different popular models, including LSTM, ELMo, and multilingual BERT so that the NLP community can compare against state-of-the-art systems. LinCE is a continuous effort, and we will expand it with more low-resource languages and tasks."
2020.emnlp-main.454,Multi-view Story Characterization from Movie Plot Synopses and Reviews,2020,-1,-1,4,1,7094,sudipta kar,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"This paper considers the problem of characterizing stories by inferring properties such as theme and style using written synopses and reviews of movies. We experiment with a multi-label dataset of movie synopses and a tagset representing various attributes of stories (e.g., genre, type of events). Our proposed multi-view model encodes the synopses and reviews using hierarchical attention and shows improvement over methods that only use synopses. Finally, we demonstrate how we can take advantage of such a model to extract a complementary set of story-attributes from reviews without direct supervision. We have made our dataset and source code publicly available at https://ritual.uh.edu/multiview-tag-2020."
2020.alw-1.10,Attending the Emotions to Detect Online Abusive Language,2020,-1,-1,5,1,14326,niloofar samghabadi,Proceedings of the Fourth Workshop on Online Abuse and Harms,0,"In recent years, abusive behavior has become a serious issue in online social networks. In this paper, we present a new corpus for the task of abusive language detection that is collected from a semi-anonymous online platform, and unlike the majority of other available resources, is not created based on a specific list of bad words. We also develop computational models to incorporate emotions into textual cues to improve aggression identification. We evaluate our proposed methods on a set of corpora related to the task and show promising results with respect to abusive language detection."
2020.acl-main.716,From {E}nglish to Code-Switching: Transfer Learning with Strong Morphological Clues,2020,-1,-1,2,1,134,gustavo aguilar,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Linguistic Code-switching (CS) is still an understudied phenomenon in natural language processing. The NLP community has mostly focused on monolingual and multi-lingual scenarios, but little attention has been given to CS in particular. This is partly because of the lack of resources and annotated data, despite its increasing occurrence in social media platforms. In this paper, we aim at adapting monolingual models to code-switched text in various tasks. Specifically, we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs (i.e., Nepali-English, Spanish-English, and Hindi-English) using the task of language identification. Our method, CS-ELMo, is an extension of ELMo with a simple yet effective position-aware attention mechanism inside its character convolutions. We show the effectiveness of this transfer learning step by outperforming multilingual BERT and homologous CS-unaware ELMo models and establishing a new state of the art in CS tasks, such as NER and POS tagging. Our technique can be expanded to more English-paired code-switched languages, providing more resources to the CS community."
2020.acl-main.762,Let Me Choose: From Verbal Context to Font Selection,2020,37,0,6,1,8389,amirreza shirani,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we aim to learn associations between visual attributes of fonts and the verbal context of the texts they are typically applied to. Compared to related work leveraging the surrounding visual context, we choose to focus only on the input text, which can enable new applications for which the text is the only visual element in the document. We introduce a new dataset, containing examples of different topics in social media posts and ads, labeled through crowd-sourcing. Due to the subjective nature of the task, multiple fonts might be perceived as acceptable for an input text, which makes this problem challenging. To this end, we investigate different end-to-end models to learn label distributions on crowd-sourced data, to capture inter-subjectivity across all annotations."
R19-1080,Jointly Learning Author and Annotated Character N-gram Embeddings: A Case Study in Literary Text,2019,0,0,6,1,15228,suraj maharjan,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"An author{'}s way of presenting a story through his/her writing style has a great impact on whether the story will be liked by readers or not. In this paper, we learn representations for authors of literary texts together with representations for character n-grams annotated with their functional roles. We train a neural character n-gram based language model using an external corpus of literary texts and transfer learned representations for use in downstream tasks. We show that augmenting the knowledge from external works of authors produces results competitive with other style-based methods for book likability prediction, genre classification, and authorship attribution."
P19-1112,Learning Emphasis Selection for Written Text in Visual Media from Crowd-Sourced Label Distributions,2019,0,1,7,1,8389,amirreza shirani,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"In visual communication, text emphasis is used to increase the comprehension of written text to convey the author{'}s intent. We study the problem of emphasis selection, i.e. choosing candidates for emphasis in short written text, to enable automated design assistance in authoring. Without knowing the author{'}s intent and only considering the input text, multiple emphasis selections are valid. We propose a model that employs end-to-end label distribution learning (LDL) on crowd-sourced data and predicts a selection distribution, capturing the inter-subjectivity (common-sense) in the audience as well as the ambiguity of the input. We compare the model with several baselines in which the problem is transformed to single-label learning by mapping label distributions to absolute labels via majority voting."
W18-4402,{R}i{TUAL}-{UH} at {TRAC} 2018 Shared Task: Aggression Identification,2018,0,2,4,1,14326,niloofar samghabadi,"Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying ({TRAC}-2018)",0,"This paper presents our system for {``}TRAC 2018 Shared Task on Aggression Identification{''}. Our best systems for the English dataset use a combination of lexical and semantic features. However, for Hindi data using only lexical features gave us the best results. We obtained weighted F1-measures of 0.5921 for the English Facebook task (ranked 12th), 0.5663 for the English Social Media task (ranked 6th), 0.6292 for the Hindi Facebook task (ranked 1st), and 0.4853 for the Hindi Social Media task (ranked 2nd)."
W18-3206,Language Identification and Analysis of Code-Switched Social Media Text,2018,0,7,3,0,25319,deepthi mave,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"In this paper, we detail our work on comparing different word-level language identification systems for code-switched Hindi-English data and a standard Spanish-English dataset. In this regard, we build a new code-switched dataset for Hindi-English. To understand the code-switching patterns in these language pairs, we investigate different code-switching metrics. We find that the CRF model outperforms the neural network based models by a margin of 2-5 percentage points for Spanish-English and 3-5 percentage points for Hindi-English."
W18-3219,Named Entity Recognition on Code-Switched Data: Overview of the {CALCS} 2018 Shared Task,2018,0,10,6,1,134,gustavo aguilar,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"In the third shared task of the Computational Approaches to Linguistic Code-Switching (CALCS) workshop, we focus on Named Entity Recognition (NER) on code-switched social-media data. We divide the shared task into two competitions based on the English-Spanish (ENG-SPA) and Modern Standard Arabic-Egyptian (MSA-EGY) language pairs. We use Twitter data and 9 entity types to establish a new dataset for code-switched NER benchmarks. In addition to the CS phenomenon, the diversity of the entities and the social media challenges make the task considerably hard to process. As a result, the best scores of the competitions are 63.76{\%} and 71.61{\%} for ENG-SPA and MSA-EGY, respectively. We present the scores of 9 participants and discuss the most common challenges among submissions."
N18-2042,Letting Emotions Flow: Success Prediction by Modeling the Flow of Emotions in Books,2018,17,0,5,1,15228,suraj maharjan,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"Books have the power to make us feel happiness, sadness, pain, surprise, or sorrow. An author{'}s dexterity in the use of these emotions captivates readers and makes it difficult for them to put the book down. In this paper, we model the flow of emotions over a book using recurrent neural networks and quantify its usefulness in predicting success in books. We obtained the best weighted F1-score of 69{\%} for predicting books{'} success in a multitask setting (simultaneously predicting success and genre of books)."
N18-1110,Early Text Classification Using Multi-Resolution Concept Representations,2018,0,2,5,1,26153,adrian lopezmonroy,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"The intensive use of e-communications in everyday life has given rise to new threats and risks. When the vulnerable asset is the user, detecting these potential attacks before they cause serious damages is extremely important. This paper proposes a novel document representation to improve the early detection of risks in social media sources. The goal is to effectively identify the potential risk using as few text as possible and with as much anticipation as possible. Accordingly, we devise a Multi-Resolution Representation (MulR), which allows us to generate multiple {``}views{''} of the analyzed text. These views capture different semantic meanings for words and documents at different levels of detail, which is very useful in early scenarios to model the variable amounts of evidence. Intuitively, the representation captures better the content of short documents (very early stages) in low resolutions, whereas large documents (medium/large stages) are better modeled with higher resolutions. We evaluate the proposed ideas in two different tasks where anticipation is critical: sexual predator detection and depression detection. The experimental evaluation for these early tasks revealed that the proposed approach outperforms previous methodologies by a considerable margin."
N18-1127,Modeling Noisiness to Recognize Named Entities using Multitask Neural Networks on Social Media,2018,31,12,4,1,134,gustavo aguilar,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Recognizing named entities in a document is a key task in many NLP applications. Although current state-of-the-art approaches to this task reach a high performance on clean text (e.g. newswire genres), those algorithms dramatically degrade when they are moved to noisy environments such as social media domains. We present two systems that address the challenges of processing social media data using character-level phonetics and phonology, word embeddings, and Part-of-Speech tags as features. The first model is a multitask end-to-end Bidirectional Long Short-Term Memory (BLSTM)-Conditional Random Field (CRF) network whose output layer contains two CRF classifiers. The second model uses a multitask BLSTM network as feature extractor that transfers the learning to a CRF classifier for the final prediction. Our systems outperform the current F1 scores of the state of the art on the Workshop on Noisy User-generated Text 2017 dataset by 2.45{\%} and 3.69{\%}, establishing a more suitable approach for social media environments."
L18-1274,{MPST}: A Corpus of Movie Plot Synopses with Tags,2018,1,2,4,1,7094,sudipta kar,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Social tagging of movies reveals a wide range of heterogeneous information about movies, like the genre, plot structure, soundtracks, metadata, visual and emotional experiences. Such information can be valuable in building automatic systems to create tags for movies. Automatic tagging systems can help recommendation engines to improve the retrieval of similar movies as well as help viewers to know what to expect from a movie in advance. In this paper, we set out to the task of collecting a corpus of movie plot synopses and tags. We describe a methodology that enabled us to build a fine-grained set of around 70 tags exposing heterogeneous characteristics of movie plots and the multi-label associations of these tags with some 14K movie plot synopses. We investigate how these tags correlate with movies and the flow of emotions throughout different types of movies. Finally, we use this corpus to explore the feasibility of inferring tags from plot synopses. We expect the corpus will be useful in other tasks where analysis of narratives is relevant."
D18-1375,A Genre-Aware Attention Model to Improve the Likability Prediction of Books,2018,0,4,4,1,15228,suraj maharjan,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Likability prediction of books has many uses. Readers, writers, as well as the publishing industry, can all benefit from automatic book likability prediction systems. In order to make reliable decisions, these systems need to assimilate information from different aspects of a book in a sensible way. We propose a novel multimodal neural architecture that incorporates genre supervision to assign weights to individual feature types. Our proposed method is capable of dynamically tailoring weights given to feature types based on the characteristics of each book. Our architecture achieves competitive results and even outperforms state-of-the-art for this task."
C18-1244,{F}olksonomication: Predicting Tags for Movies from Plot Synopses using Emotion Flow Encoded Neural Network,2018,34,0,3,1,7094,sudipta kar,Proceedings of the 27th International Conference on Computational Linguistics,0,"Folksonomy of movies covers a wide range of heterogeneous information about movies, like the genre, plot structure, visual experiences, soundtracks, metadata, and emotional experiences from watching a movie. Being able to automatically generate or predict tags for movies can help recommendation engines improve retrieval of similar movies, and help viewers know what to expect from a movie in advance. In this work, we explore the problem of creating tags for movies from plot synopses. We propose a novel neural network model that merges information from synopses and emotion flows throughout the plots to predict a set of tags for movies. We compare our system with multiple baselines and found that the addition of emotion flows boosts the performance of the network by learning {\mbox{$\approx$}}18{\%} more tags than a traditional machine learning system."
W17-4419,A Multi-task Approach for Named Entity Recognition in Social Media Data,2017,25,26,4,1,134,gustavo aguilar,Proceedings of the 3rd Workshop on Noisy User-generated Text,0,"Named Entity Recognition for social media data is challenging because of its inherent noisiness. In addition to improper grammatical structures, it contains spelling inconsistencies and numerous informal abbreviations. We propose a novel multi-task approach by employing a more general secondary task of Named Entity (NE) segmentation together with the primary task of fine-grained NE categorization. The multi-task neural network architecture learns higher order feature representations from word and character sequences along with basic Part-of-Speech tags and gazetteer information. This neural network acts as a feature extractor to feed a Conditional Random Fields classifier. We were able to obtain the first position in the 3rd Workshop on Noisy User-generated Text (WNUT-2017) with a 41.86{\%} entity F1-score and a 40.24{\%} surface F1-score."
W17-3010,Detecting Nastiness in Social Media,2017,8,9,5,1,14326,niloofar samghabadi,Proceedings of the First Workshop on Abusive Language Online,0,"Although social media has made it easy for people to connect on a virtually unlimited basis, it has also opened doors to people who misuse it to undermine, harass, humiliate, threaten and bully others. There is a lack of adequate resources to detect and hinder its occurrence. In this paper, we present our initial NLP approach to detect invective posts as a first step to eventually detect and deter cyberbullying. We crawl data containing profanities and then determine whether or not it contains invective. Annotations on this data are improved iteratively by in-lab annotations and crowdsourcing. We pursue different NLP approaches containing various typical and some newer techniques to distinguish the use of swear words in a neutral way from those instances in which they are used in an insulting way. We also show that this model not only works for our data set, but also can be successfully applied to different data sets."
S17-2150,{R}i{TUAL}-{UH} at {S}em{E}val-2017 Task 5: Sentiment Analysis on Financial Data Using Neural Networks,2017,12,8,3,1,7094,sudipta kar,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"In this paper, we present our systems for the {``}SemEval-2017 Task-5 on Fine-Grained Sentiment Analysis on Financial Microblogs and News{''}. In our system, we combined hand-engineered lexical, sentiment and metadata features, the representations learned from Convolutional Neural Networks (CNN) and Bidirectional Gated Recurrent Unit (Bi-GRU) with Attention model applied on top. With this architecture we obtained weighted cosine similarity scores of 0.72 and 0.74 for subtask-1 and subtask-2, respectively. Using the official scoring system, our system ranked the second place for subtask-2 and eighth place for the subtask-1. It ranked first for both of the subtasks by the scores achieved by an alternate scoring system."
E17-2106,Convolutional Neural Networks for Authorship Attribution of Short Texts,2017,0,30,6,1,11296,prasha shrestha,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,We present a model to perform authorship attribution of tweets using Convolutional Neural Networks (CNNs) over character n-grams. We also present a strategy that improves model interpretability by estimating the importance of input text fragments in the predicted classification. The experimental evaluation shows that text CNNs perform competitively and are able to outperform previous methods.
E17-1114,A Multi-task Approach to Predict Likability of Books,2017,35,7,5,1,15228,suraj maharjan,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"We investigate the value of feature engineering and neural network models for predicting successful writing. Similar to previous work, we treat this as a binary classification task and explore new strategies to automatically learn representations from book contents. We evaluate our feature set on two different corpora created from Project Gutenberg books. The first presents a novel approach for generating the gold standard labels for the task and the other is based on prior research. Using a combination of hand-crafted and recurrent neural network learned representations in a dual learning setting, we obtain the best performance of 73.50{\%} weighted F1-score."
W16-6203,Why Do They Leave: Modeling Participation in Online Depression Forums,2016,14,7,3,1,22246,farig sadeque,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,None
W16-6105,Analysis of Anxious Word Usage on Online Health Forums,2016,16,2,7,0,33400,nicolas reyvillamizar,Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis,0,None
W16-5805,Overview for the Second Shared Task on Language Identification in Code-Switched Data,2016,-1,-1,7,0,33428,giovanni molina,Proceedings of the Second Workshop on Computational Approaches to Code Switching,0,None
W16-5806,Multilingual Code-switching Identification via {LSTM} Recurrent Neural Networks,2016,17,12,5,0,484,younes samih,Proceedings of the Second Workshop on Computational Approaches to Code Switching,0,None
W16-5812,Part of Speech Tagging for Code Switched Data,2016,11,7,4,1,24834,fahad alghamdi,Proceedings of the Second Workshop on Computational Approaches to Code Switching,0,None
W16-5311,{C}og{AL}ex-{V} Shared Task: {GHHH} - Detecting Semantic Relations via Word Embeddings,2016,21,7,5,0,24071,mohammed attia,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"This paper describes our system submission to the CogALex-2016 Shared Task on Corpus-Based Identification of Semantic Relations. Our system won first place for Task-1 and second place for Task-2. The evaluation results of our system on the test set is 88.1{\%} (79.0{\%} for TRUE only) f-measure for Task-1 on detecting semantic similarity, and 76.0{\%} (42.3{\%} when excluding RANDOM) for Task-2 on identifying finer-grained semantic relations. In our experiments, we try word analogy, linear regression, and multi-task Convolutional Neural Networks (CNNs) with word embeddings from publicly available word vectors. We found that linear regression performs better in the binary classification (Task-1), while CNNs have better performance in the multi-class semantic classification (Task-2). We assume that word analogy is more suited for deterministic answers rather than handling the ambiguity of one-to-many and many-to-many relationships. We also show that classifier performance could benefit from balancing the distribution of labels in the training data."
W16-0322,Semi-supervised {CLP}sych 2016 Shared Task System Submission,2016,2,1,3,0,33400,nicolas reyvillamizar,Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology,0,None
S16-1126,{UH}-{PRHLT} at {S}em{E}val-2016 Task 3: Combining Lexical and Semantic-based Features for Community Question Answering,2016,20,20,3,0,12613,marc francosalvador,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
P16-1210,Domain Adaptation for Authorship Attribution: Improved Structural Correspondence Learning,2016,12,5,2,1,34541,upendra sapkota,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
L16-1541,Age and Gender Prediction on Health Forum Data,2016,6,3,6,1,11296,prasha shrestha,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Health support forums have become a rich source of data that can be used to improve health care outcomes. A user profile, including information such as age and gender, can support targeted analysis of forum data. But users might not always disclose their age and gender. It is desirable then to be able to automatically extract this information from users{'} content. However, to the best of our knowledge there is no such resource for author profiling of health forum data. Here we present a large corpus, with close to 85,000 users, for profiling and also outline our approach and benchmark results to automatically detect a user{'}s age and gender from their forum posts. We use a mix of features from a user{'}s text as well as forum specific features to obtain accuracy well above the baseline, thus showing that both our dataset and our method are useful and valid."
W15-2602,Predicting Continued Participation in Online Health Forums,2015,14,4,2,1,22246,farig sadeque,Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis,0,"Online health forums provide advice and emotional solace to their users from a social network of people who have faced similar conditions. Continued participation of users is thus critical to their success. In this paper, we develop machine learning models for predicting whether or not a user will continue to participate in an online health forum. The prediction models are trained and tested over a large dataset collected from the support group based social networking site dailystrength.org. We find that our models can predict continued participation with over 83% accuracy after as little as 1 month observing the userxe2x80x99s activities, and that performance increases rapidly up to 1 year of observation. We also show that features such as the time since a userxe2x80x99s last activity are consistently predictive regardless of the length of the observation period, while other features, such as the number of times a user replies to others, decrease in predictiveness as the observation period grows."
W15-1608,Developing Language-tagged Corpora for Code-switching Tweets,2015,20,9,4,1,15228,suraj maharjan,Proceedings of The 9th Linguistic Annotation Workshop,0,"Code-switching, where a speaker switches between languages mid-utterance, is frequently used by multilingual populations worldwide. Despite its prevalence, limited effort has been devoted to develop computational approaches or even basic linguistic resources to support research into the processing of such mixedlanguage data. We present a user-centric approach to collecting code-switched utterances from social media posts, and develop language universal guidelines for the annotation of codeswitched data. We also present results for several baseline language identification models on our corpora and demonstrate that language identification in code-switched text is a difficult task that calls for deeper investigation."
N15-1010,Not All Character N-grams Are Created Equal: A Study in Authorship Attribution,2015,20,59,4,1,34541,upendra sapkota,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Character n-grams have been identified as the most successful feature in both singledomain and cross-domain Authorship Attribution (AA), but the reasons for their discriminative value were not fully understood. We identify subgroups of charactern-grams that correspond to linguistic aspects commonly claimed to be covered by these features: morphosyntax, thematic content and style. We evaluate the predictiveness of each of these groups in two AA settings: a single domain setting and a cross-domain setting where multiple topics are present. We demonstrate that characterngrams that capture information about affixes and punctuation account for almost all of the power of character n-grams as features. Our study contributes new insights into the use of n-grams for future AA work and other classification tasks."
W14-3907,Overview for the First Shared Task on Language Identification in Code-Switched Data,2014,16,46,1,1,136,thamar solorio,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"We present an overview of the first shared task on language identification on codeswitched data. The shared task included code-switched data from four language pairs: Modern Standard ArabicDialectal Arabic (MSA-DA), MandarinEnglish (MAN-EN), Nepali-English (NEPEN), and Spanish-English (SPA-EN). A total of seven teams participated in the task and submitted 42 system runs. The evaluation showed that language identification at the token level is more difficult when the languages present are closely related, as in the case of MSA-DA, where the prediction performance was the lowest among all language pairs. In contrast, the language pairs with the higest F-measure where SPA-EN and NEP-EN. The task made evident that language identification in code-switched data is still far from solved and warrants further research."
solorio-etal-2014-sockpuppet,Sockpuppet Detection in {W}ikipedia: A Corpus of Real-World Deceptive Writing for Linking Identities,2014,7,10,1,1,136,thamar solorio,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes a corpus of sockpuppet cases from Wikipedia. A sockpuppet is an online user account created with a fake identity for the purpose of covering abusive behavior and/or subverting the editing regulation process. We used a semi-automated method for crawling and curating a dataset of real sockpuppet investigation cases. To the best of our knowledge, this is the first corpus available on real-world deceptive writing. We describe the process for crawling the data and some preliminary results that can be used as baseline for benchmarking research. The dataset has been released under a Creative Commons license from our project website (http://docsig.cis.uab.edu/tools-and-datasets/)."
C14-1116,Cross-Topic Authorship Attribution: Will Out-Of-Topic Data Help?,2014,25,12,2,1,34541,upendra sapkota,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Most previous research on authorship attribution (AA) assumes that the training and test data are drawn from same distribution. But in real scenarios, this assumption is too strong. The goal of this study is to improve the prediction results in cross-topic AA (CTAA), where the training data comes from one topic but the test data comes from another. Our proposed idea is to build a predictive model for one topic using documents from all other available topics. In addition to improving the performance of CTAA, we also make a thorough analysis of the sensitivity to changes in topic of four most commonly used feature types in AA. We empirically illustrate that our proposed framework is significantly better than the one trained on a single out-of-domain topic and is as effective, in some cases, as same-topic setting."
W13-1911,Exploring Word Class N-grams to Measure Language Development in Children,2013,21,4,2,0,41023,gabriela rosa,Proceedings of the 2013 Workshop on Biomedical Natural Language Processing,0,We present a set of new measures designed to reveal latent information of language use in children at the lexico-syntactic level. We used these metrics to analyze linguistic patterns in spontaneous narratives from children developing typically and children identified as having a language impairment. We observed significant differences in the z-scores of both populations for most of the metrics. These findings suggest we can use these metrics to aid in the task of language assessment in children.
W13-1914,Using {L}atent {D}irichlet {A}llocation for Child Narrative Analysis,2013,7,5,3,0,41027,khairunnisa hassanali,Proceedings of the 2013 Workshop on Biomedical Natural Language Processing,0,"Child language narratives are used for language analysis, measurement of language development, and the detection of language impairment. In this paper, we explore the use of Latent Dirichlet Allocation (LDA) for detecting topics from narratives, and use the topics derived from LDA in two classification tasks: automatic prediction of coherence and language impairment. Our experiments show LDA is useful for detecting the topics that correspond to the narrative structure. We also observed improved performance for the automatic prediction of coherence and language impairment when we use features derived from the topic words provided by LDA."
W13-1729,Native Language Identification: a Simple n-gram Based Approach,2013,15,5,3,1,24644,binod gyawali,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"This paper describes our approaches to Native Language Identification (NLI) for the NLI shared task 2013. NLI as a sub area of author profiling focuses on identifying the first language of an author given a text in his second language. Researchers have reported several sets of features that have achieved relatively good performance in this task. The type of features used in such works are: lexical, syntactic and stylistic features, dependency parsers, psycholinguistic features and grammatical errors. In our approaches, we selected lexical and syntactic features based on n-grams of characters, words, Penn TreeBank (PTB) and Universal Parts Of Speech (POS) tagsets, and perplexity values of character of n-grams to build four different models. We also combine all the four models using an ensemble based approach to get the final result. We evaluated our approach over a set of 11 native languages reaching 75% accuracy."
W13-1107,A Case Study of Sockpuppet Detection in {W}ikipedia,2013,-1,-1,1,1,136,thamar solorio,Proceedings of the Workshop on Language Analysis in Social Media,0,None
W12-3717,On the Impact of Sentiment and Emotion Based Features in Detecting Online Sexual Predators,2012,22,18,3,0,33018,dasha bogdanova,Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis,0,"According to previous work on pedophile psychology and cyberpedophilia, sentiments and emotions in texts could be a good clue to detect online sexual predation. In this paper, we have suggested a list of high-level features, including sentiment and emotion based ones, for detection of online sexual predation. In particular, since pedophiles are known to be emotionally unstable, we were interested in investigating if emotion-based features could help in their detection. We have used a corpus of predators' chats with pseudo-victims downloaded from www.perverted-justice.com and two negative datasets of different nature: cybersex logs available online and the NPS chat corpus. Naive Bayes classification based on the proposed features achieves accuracies of up to 94% while baseline systems of word and character n-grams can only reach up to 72%."
W12-2422,Grading the Quality of Medical Evidence,2012,18,2,2,1,24644,binod gyawali,{B}io{NLP}: Proceedings of the 2012 Workshop on Biomedical Natural Language Processing,0,"Evidence Based Medicine (EBM) is the practice of using the knowledge gained from the best medical evidence to make decisions in the effective care of patients. This medical evidence is extracted from medical documents such as research papers. The increasing number of available medical documents has imposed a challenge to identify the appropriate evidence and to access the quality of the evidence. In this paper, we present an approach for the automatic grading of evidence using the dataset provided by the 2011 Australian Language Technology Association (ALTA) shared task competition. With the feature sets extracted from publication types, Medical Subject Headings (MeSH), title, and body of the abstracts, we obtain a 73.77% grading accuracy with a stacking based approach, a considerable improvement over previous work."
W12-0413,Modelling Fixated Discourse in Chats with Cyberpedophiles,2012,-1,-1,3,0,33018,dasha bogdanova,Proceedings of the Workshop on Computational Approaches to Deception Detection,0,None
S12-1036,{UABC}o{RAL}: A Preliminary study for Resolving the Scope of Negation,2012,8,2,2,1,24644,binod gyawali,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper describes our participation in the closed track of the *SEM 2012 Shared Task of finding the scope of negation. To perform the task, we propose a system that has three components: negation cue detection, scope of negation detection, and negated event detection. In the first phase, the system creates a lexicon of negation signals from the training data and uses the lexicon to identify the negation cues. Then, it applies machine learning approaches to detect the scope and negated event for each negation cue identified in the first phase. Using a preliminary approach, our system achieves a reasonably good accuracy in identifying the scope of negation."
P11-1030,Local Histograms of Character N-grams for Authorship Attribution,2011,28,76,2,0,1107,hugo escalante,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"This paper proposes the use of local histograms (LH) over character n-grams for authorship attribution (AA). LHs are enriched histogram representations that preserve sequential information in documents; they have been successfully used for text categorization and document visualization using word histograms. In this work we explore the suitability of LHs over n-grams at the character-level for AA. We show that LHs are particularly helpful for AA, because they provide useful information for uncovering, to some extent, the writing style of authors. We report experimental results in AA data sets that confirm that LHs over character n-grams are more helpful for AA than the usual global histograms, yielding results far superior to state of the art approaches. We found that LHs are even more advantageous in challenging conditions, such as having imbalanced and small training sets. Our results motivate further research on the use of LHs for modeling the writing style of authors for related tasks, such as authorship verification and plagiarism detection."
I11-1018,Modality Specific Meta Features for Authorship Attribution in Web Forum Posts,2011,18,20,1,1,136,thamar solorio,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper presents a new method for Authorship Attribution (AA) on online forum posts. The idea behind the method is to generate meta features that capture modality specific similarity relations among texts from different authors. Each modality represents a particular linguistic dimension (syntactic, lexical, stylistic). To evaluate this approach we measure prediction accuracy on data from an online forum with up to 100 candidate authors. We also compare our results with a state of the art approach that has shown to perform well across different genres. We have found the meta features to be especially helpful in the online forum domain, where the documents are very short, showing this to be a very promising direction for AA on a realistic web forum scenario."
N09-1006,A Corpus-Based Approach for the Prediction of Language Impairment in Monolingual {E}nglish and {S}panish-{E}nglish Bilingual Children,2009,23,22,3,0,47330,keyur gabani,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"In this paper we explore a learning-based approach to the problem of predicting language impairment in children. We analyzed spontaneous narratives of children and extracted features measuring different aspects of language including morphology, speech fluency, language productivity and vocabulary. Then, we evaluated a learning-based approach and compared its predictive accuracy against a method based on language models. Empirical results on monolingual English-speaking children and bilingual Spanish-English speaking children show the learning-based approach is a promising direction for automatic language assessment."
W08-0626,Using Language Models to Identify Language Impairment in {S}panish-{E}nglish Bilingual Children,2008,-1,-1,1,1,136,thamar solorio,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,None
D08-1102,Learning to Predict Code-Switching Points,2008,14,64,1,1,136,thamar solorio,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Predicting possible code-switching points can help develop more accurate methods for automatically processing mixed-language text, such as multilingual language models for speech recognition systems and syntactic analyzers. We present in this paper exploratory results on learning to predict potential code-switching points in Spanish-English. We trained different learning algorithms using a transcription of code-switched discourse. To evaluate the performance of the classifiers, we used two different criteria: 1) measuring precision, recall, and F-measure of the predictions against the reference in the transcription, and 2) rating the naturalness of artificially generated code-switched sentences. Average scores for the code-switched sentences generated by our machine learning approach were close to the scores of those generated by humans."
D08-1110,{P}art-of-{S}peech Tagging for {E}nglish-{S}panish Code-Switched Text,2008,30,63,1,1,136,thamar solorio,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Code-switching is an interesting linguistic phenomenon commonly observed in highly bilingual communities. It consists of mixing languages in the same conversational event. This paper presents results on Part-of-Speech tagging Spanish-English code-switched discourse. We explore different approaches to exploit existing resources for both languages that range from simple heuristics, to language identification, to machine learning. The best results are achieved by training a machine learning algorithm with features that combine the output of an English and a Spanish Part-of-Speech tagger."
N07-2012,A Filter-Based Approach to Detect End-of-Utterances from Prosody in Dialog Systems,2007,14,3,3,0,49305,olac fuentes,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"We propose an efficient method to detect end-of-utterances from prosodic information in conversational speech. Our method is based on the application of a large set of binary and ramp filters to the energy and fundamental frequency signals obtained from the speech signal. These filter responses, which can be computed very efficiently, are used as input to a learning algorithm that generates the final detector. Preliminary experiments using data obtained from conversations show that an accurate classifier can be trained efficiently and that good results can be obtained without requiring a speech recognition system."
W06-2004,Improving Name Discrimination: A Language Salad Approach,2006,9,4,5,0,1754,ted pedersen,Proceedings of the Cross-Language Knowledge Induction Workshop,0,"This paper describes a method of discriminating ambiguous names that relies upon features found in corpora of a more abundant language. In particular, we discriminate ambiguous names in Bulgarian, Romanian, and Spanish corpora using information derived from much larger quantities of English data. We also mix together occurrences of the ambiguous name found in English with the occurrences of the name in the language in which we are trying to discriminate. We refer to this as a language salad, and find that it often results in even better performance than when only using English or the language itself as the source of information for discrimination."
P05-2005,Exploiting Named Entity Taggers in a Second Language,2005,21,2,1,1,136,thamar solorio,Proceedings of the {ACL} Student Research Workshop,0,"In this work we present a method for Named Entity Recognition (NER). Our method does not rely on complex linguistic resources, and apart from a hand coded system, we do not use any language-dependent tools. The only information we use is automatically extracted from the documents, without human intervention. Moreover, the method performs well even without the use of the hand coded system. The experimental results are very encouraging. Our approach even outperformed the hand coded system on NER in Spanish, and it achieved high accuracies in Portuguese."
C04-1201,A Language Independent Method for Question Classification,2004,21,35,1,1,136,thamar solorio,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Previous works on question classification are based on complex natural language processing techniques: named entity extractors, parsers, chunkers, etc. While these approaches have proven to be effective they have the disadvantage of being targeted to a particular language. We present here a simple approach that exploits lexical features and the Internet to train a classifier, namely a Support Vector Machine. The main feature of this method is that it can be applied to different languages without requiring major modifications. Experimental results of this method on English, Italian and Spanish show that this approach can be a practical tool for question answering systems, reaching a classification accuracy as high as 88.92%."
