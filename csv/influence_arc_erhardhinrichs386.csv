2019.gwc-1.4,W97-0802,0,0.628577,"Missing"
2019.gwc-1.4,henrich-hinrichs-2010-gernedit,1,0.827358,"Missing"
2020.coling-main.269,Q16-1037,0,0.0792431,"Missing"
2020.coling-main.269,N15-1142,0,0.0385364,"Missing"
2020.coling-main.269,N18-1202,0,0.0621995,"Missing"
2020.coling-main.269,W18-5441,0,0.0380268,"Missing"
2020.coling-main.269,P06-1042,0,0.0836238,"Missing"
2020.coling-main.269,Q19-1027,0,0.0329255,"Missing"
2020.coling-main.269,N19-1077,0,0.0342042,"Missing"
2020.lrec-1.538,D10-1115,0,0.0626277,". Neither static, nor contextualized embeddings can achieve human performance, and although these features are much stronger than association scores, a simple non-linear classifier is not able to generalize perfectly on adjectives it has not encountered in training. Further research questions can be investigated with the presented data set in the future. The representation of the adjective-noun phrase can be constructed with the aim of capturing more interaction between the individual parts of the word combinations. This can be achieved by using a composition model (Mitchell and Lapata, 2010; Baroni and Zamparelli, 2010; Dima et al., 2019), that takes the individual word vectors as input and combines them in a way such that the combined representation is more suitable for a specific task. Additional semantic information (sense gloss or semantic class from GermaNet) may contain information that is not implicit in the representations of context and phrases and can further provide information that is necessary to solve such tasks. 7. Acknowledgements We would like to thank our student assistants Eva Huber, Alina Leippert, and Mareile Winkler for their help with the annotations. We would also like to acknowledge"
2020.lrec-1.538,J90-1003,0,0.563182,"a speaker, and a collocate, the choice of which is restricted depending on the base (Mel’čuk, 2012). In that aspect, they differ from free phrases, e.g. golden crown or old lady, where neither of the constituents is lexically constrained. However, collocations are not fully lexicalized as opposed to semantically opaque idiomatic expressions such as golden ticket ‘good opportunity’ or old flame ‘former romantic partner’. In the recent decades, collocations have been extensively studied with the focus predominantly on their statistical properties and methods of automatic collocation extraction (Church and Hanks, 1990; Smadja, 1993; Evert, 2004; Pecina, 2008a; Bouma, 2009; Evert et al., 2017; Garcia et al., 2019). Identifying and extracting collocations, either manually or automatically, is a challenging task that requires clear definitions of concepts and reliable tools and resources. In spite of the growing interest in collocations, there exist only a few resources that can serve as gold standards in collocation research. This paper reports on the construction of the dataset annotated by experts that comprises 4,732 instances of collocations and non-collocations (free phrases, idioms, named entities, ter"
2020.lrec-1.538,N19-1423,0,0.0472226,"n about words as they are designed to capture information about similar words and words they co-occur with. Static word embeddings, such as GloVe (Pennington et al., 2014) or Word2Vec (Mikolov et al., 2013), represent the meaning of a word based on its distribution in language (large corpora) but suffer from the meaning conflation deficiency: all the possible senses of a word are represented by the same vector. Recent work in natural language processing has revealed that this issue can be overcome by computing dynamic representations of words conditioned on local context (Peters et al., 2018; Devlin et al., 2019). These representations are not only dynamic in the sense that they are able to capture different meanings of a word depending on the context, but they are designed to work well for predicting other words in contexts, making them general enough to be applicable for a wide range of natural-language applications out-of-the-box. In the following line of experiments we would like to find out whether semantic representations of words in general are useful for detecting collocations and how much contextual information is needed to classify the examples correctly. If the sense of the adjective is mai"
2020.lrec-1.538,Q19-1025,1,0.851109,"Missing"
2020.lrec-1.538,P19-1576,0,0.0185742,"e 12 AMs are compared in the experiments on collocation extraction in English, Portuguese, and Spanish. They also show that the performance of individual AMs is similar for these languages. The approach for constructing the above described datasets is to randomly extract a certain amount of dependency bigrams, filter them based on their frequencies, and give the list of candidates to annotators. The databases created in this way contain a wide variety of bases and their collocates, but no information about the semantics of the phrases. A different kind of a collocation dataset is described in Espinosa-Anke et al. (2019). The LexFunc dataset comprises 10,077 English collocations annotated with relations in terms of Mel’čuk’s Lexical Functions (Mel’čuk, 1996) where each keyword is disambiguated. LexFunc includes only positive instances of collocations and has been used in multi-class machine learning experiments for classifying the semantic relations that hold between the constituents of collocations. Our main motivation for creating the GerCo dataset was to provide an annotation scheme that can be used for the following classification tasks: for the binary classification between collocations and non-collocati"
2020.lrec-1.538,W19-5107,0,0.0716131,". In that aspect, they differ from free phrases, e.g. golden crown or old lady, where neither of the constituents is lexically constrained. However, collocations are not fully lexicalized as opposed to semantically opaque idiomatic expressions such as golden ticket ‘good opportunity’ or old flame ‘former romantic partner’. In the recent decades, collocations have been extensively studied with the focus predominantly on their statistical properties and methods of automatic collocation extraction (Church and Hanks, 1990; Smadja, 1993; Evert, 2004; Pecina, 2008a; Bouma, 2009; Evert et al., 2017; Garcia et al., 2019). Identifying and extracting collocations, either manually or automatically, is a challenging task that requires clear definitions of concepts and reliable tools and resources. In spite of the growing interest in collocations, there exist only a few resources that can serve as gold standards in collocation research. This paper reports on the construction of the dataset annotated by experts that comprises 4,732 instances of collocations and non-collocations (free phrases, idioms, named entities, terms). The dataset includes only adjective-noun phrases as they have been studied less extensively"
2020.lrec-1.538,geyken-schrader-2006-lexikonet,0,0.0258035,"0.31 0.3 0.39 0.45 0.45 0.46 0.4 0.66 0.63 0.7 0.54 0.7 0.77 0.67 0.61 0.86 0.84 0.83 0.86 0.52 0.49 0.65 0.64 +sensedef 0.15 0.15 0.31 0.27 0.47 0.34 0.54 0.59 0.69 0.61 0.84 0.91 0.6 0.74 contextualized embeddings per-class Accuracy phrase +context +sensedef 0.85 0.9 0.79 0.25 0.25 0.25 0.12 0.27 0.38 0.25 0.25 0.25 0.31 0.31 0.4 0.39 0.39 0.42 0.11 0.11 0.11 0.17 0.22 0.25 0.8 0.74 0.69 0.5 0.61 0.56 0.81 0.86 0.95 0.5 0.52 0.59 0.88 0.78 0.85 0.89 0.8 0.92 Table 7: Sample of adjectives with test set accuracy. LexikoNet, a large lexical ontology of German nouns developed by the DWDS team (Geyken and Schrader, 2006). Each noun from the dataset is manually assigned a corresponding semantic label from LexikoNet. This information is integrated into the Wortprofil application, which allows its users to do semantic queries. The result of a query in this extended tool corresponds to a list of co-occurrences ordered by statistical salience and grouped not only by the syntactic relations, but also by the semantic classes. Thus, the adjective tief (‘deep’, ‘low’, ‘profound’) co-occurs with nouns from 43 semantic classes: e.g. [feeling] tiefe Trauer ‘deep sorrow’, [social relation] tiefe Freundschaft ‘close friend"
2020.lrec-1.538,W97-0802,0,0.374122,"provides lists of statistical co-occurrences for a given word based on the frequencies obtained from the DWDS corpora. In the Wortprofil, the co-occurrences are classified according to their grammatical relations (is an attribute of, is a subject of, etc.) and are sorted according to their logDice scores (Rychly, 2008). A high score for a phrase serves as an indication that the phrase may be lexically restricted. 3.1. Annotation We follow a systematic approach to collocation analysis and aim at covering different semantic classes of the German lexicon. We rely on the German wordnet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) in choosing the adjectives for analysis: there are 16 semantic classes for adjectives in GermaNet. From each class we randomly selected three adjectives. Table 1 gives an overview of the 48 adjectives selected for investigation together with their semantic classes as defined in GermaNet. The co-occurring nouns were obtained from the Wortprofil that provides maximum 100 candidates for each adjective (relation “is an attribute of""). This resulted in a collection of 4,732 adjective-noun pairs that were given to two annotators. The annotation of the dataset has been p"
2020.lrec-1.538,henrich-hinrichs-2010-gernedit,1,0.85674,"dioms, named entities, terms). The dataset includes only adjective-noun phrases as they have been studied less extensively than verbal collocations. In our current research, we focus on the German language since digital resources and tools are available for German that identify relevant adjective-noun cooccurrences. The DWDS (short for Digitales Wörterbuch der deutschen Sprache) (DWDS, 2019) and its collocation extraction application the Wortprofil1 serve as our empirical basis, and the German wordnet GermaNet (Hamp and 1 https://www.dwds.de/wp/, last accessed November 22, 2019 Feldweg, 1997; Henrich and Hinrichs, 2010) provides information about the semantic classes of adjectives and nouns. The data cover all the 16 semantic classes of adjectives defined in GermaNet. The dataset serves as the empirical basis for the lexicographic work on extending the Wortprofil and for the enrichment of GermaNet with new lexical relations. The dataset is intended to be used not only for linguistic studies of collocations, but also in computational linguistics. As the dataset contains both positive and negative instances of collocations, it can serve as a suitable resource for evaluating different models of automatic colloc"
2020.lrec-1.538,2005.mtsummit-papers.11,0,0.0279223,"ualized word representations are more useful because of their ability to model different meanings of the same word depending on the context. 4.1. Data In order to obtain context-aware representations of meaning, we extracted sentences containing the adjective-noun pairs from the GerCo dataset. The source corpora stem from different domains (encyclopedia, newspaper, blogs) 4371 and are publicly available. These corpora include Wikipedia (dumps from 2017, 2018, 2019), the One Million Posts Corpus (Schabus et al., 2017; Schabus and Skowron, 2018), the German proceedings from the EuroParl corpus (Koehn, 2005; Tiedemann, 2012) and the German Political Speeches Corpus (Barbaresi, 2018). We were able to extract context sentences for 3,652 free phrases and collocations. We randomly selected one context sentence per phrase with a sentence length between 15 and 30 words. To be able to analyse the performance for each of the 48 adjectives, we created six splits, each split containing a different set of adjectives in the test set. On top of that, the adjectives in the test set, are not present in the training data, thus it can be investigated whether the models can generalize above the word level. Figure"
2020.lrec-1.538,N15-1142,0,0.0353553,"Missing"
2020.lrec-1.538,P06-2084,0,0.270003,"efan Evert (Evert, 2004) to compute 22 different AMs, including standard measures, such as mutual information or log-likelihood.5 In order to be able to use the measures as features for machine learning, we applied normalization and scaled each measure independently between 0 and 1. We tuned the threshold for each AM on the training set and classified each test instances based on the best threshold. We then classify every instance in the test set based on a combination of the individual predictions of each AM classifier and use the majority (Bishop, 2006) as the final prediction. Similarly to Pecina and Schlesinger (2006), we use the AMs as input to train a linear and a non-linear classifier that predicts the class based on a combination of AMs for a given adjective-noun pair. The idea is that the neural classifier learns a good internal feature representation given the available AMs as input. The weights of the classifier are optimized for minimizing the cross-entropy loss on the training set. An adjective-noun pair is represented by a vector of 22 dimensions, each dimension associated with a different type of association strength. For the linear classifier, we use a Support Vector Machine with a Radial Basis"
2020.lrec-1.538,D14-1162,0,0.0882709,"candidates, but that the feature representations based on these measures alone do not suffice for a more fine-grained and more semantically restricted classification task. 4.3. Word Embeddings Since the findings from the first experiment indicate that additional semantic information is necessary, the second set of experiments makes use of a richer source of semantic information, namely word representations. Word embeddings encode semantic information about words as they are designed to capture information about similar words and words they co-occur with. Static word embeddings, such as GloVe (Pennington et al., 2014) or Word2Vec (Mikolov et al., 2013), represent the meaning of a word based on its distribution in language (large corpora) but suffer from the meaning conflation deficiency: all the possible senses of a word are represented by the same vector. Recent work in natural language processing has revealed that this issue can be overcome by computing dynamic representations of words conditioned on local context (Peters et al., 2018; Devlin et al., 2019). These representations are not only dynamic in the sense that they are able to capture different meanings of a word depending on the context, but they"
2020.lrec-1.538,N18-1202,0,0.00992401,"e semantic information about words as they are designed to capture information about similar words and words they co-occur with. Static word embeddings, such as GloVe (Pennington et al., 2014) or Word2Vec (Mikolov et al., 2013), represent the meaning of a word based on its distribution in language (large corpora) but suffer from the meaning conflation deficiency: all the possible senses of a word are represented by the same vector. Recent work in natural language processing has revealed that this issue can be overcome by computing dynamic representations of words conditioned on local context (Peters et al., 2018; Devlin et al., 2019). These representations are not only dynamic in the sense that they are able to capture different meanings of a word depending on the context, but they are designed to work well for predicting other words in contexts, making them general enough to be applicable for a wide range of natural-language applications out-of-the-box. In the following line of experiments we would like to find out whether semantic representations of words in general are useful for detecting collocations and how much contextual information is needed to classify the examples correctly. If the sense o"
2020.lrec-1.538,L18-1253,0,0.0130979,"base and the collocate suffice for the classification or whether deep-contextualized word representations are more useful because of their ability to model different meanings of the same word depending on the context. 4.1. Data In order to obtain context-aware representations of meaning, we extracted sentences containing the adjective-noun pairs from the GerCo dataset. The source corpora stem from different domains (encyclopedia, newspaper, blogs) 4371 and are publicly available. These corpora include Wikipedia (dumps from 2017, 2018, 2019), the One Million Posts Corpus (Schabus et al., 2017; Schabus and Skowron, 2018), the German proceedings from the EuroParl corpus (Koehn, 2005; Tiedemann, 2012) and the German Political Speeches Corpus (Barbaresi, 2018). We were able to extract context sentences for 3,652 free phrases and collocations. We randomly selected one context sentence per phrase with a sentence length between 15 and 30 words. To be able to analyse the performance for each of the 48 adjectives, we created six splits, each split containing a different set of adjectives in the test set. On top of that, the adjectives in the test set, are not present in the training data, thus it can be investigated"
2020.lrec-1.538,schafer-bildhauer-2012-building,0,0.0340523,"iation measures can be used as features for training a linear or non-linear classifier. Previous work has revealed that the type of co-occurrence chosen as the basis for the computation of the association measures has an impact on the quality of the collocation extraction and classification, and that syntactic co-occurrence outperforms window-based approaches (Evert et al., 2017). For that reason, we extracted adjective-noun pairs3 with an attributive dependency relation from three large, automatically annotated treebanks (Wikipedia 2017 and Wikipedia 2018 (de Kok and Pütz, 2019) , decow16ax (Schäfer and Bildhauer, 2012; Schäfer, 2015)). We used the UCS-toolkit4 by Stefan Evert (Evert, 2004) to compute 22 different AMs, including standard measures, such as mutual information or log-likelihood.5 In order to be able to use the measures as features for machine learning, we applied normalization and scaled each measure independently between 0 and 1. We tuned the threshold for each AM on the training set and classified each test instances based on the best threshold. We then classify every instance in the test set based on a combination of the individual predictions of each AM classifier and use the majority (Bis"
2020.lrec-1.538,J93-1007,0,0.8741,"te, the choice of which is restricted depending on the base (Mel’čuk, 2012). In that aspect, they differ from free phrases, e.g. golden crown or old lady, where neither of the constituents is lexically constrained. However, collocations are not fully lexicalized as opposed to semantically opaque idiomatic expressions such as golden ticket ‘good opportunity’ or old flame ‘former romantic partner’. In the recent decades, collocations have been extensively studied with the focus predominantly on their statistical properties and methods of automatic collocation extraction (Church and Hanks, 1990; Smadja, 1993; Evert, 2004; Pecina, 2008a; Bouma, 2009; Evert et al., 2017; Garcia et al., 2019). Identifying and extracting collocations, either manually or automatically, is a challenging task that requires clear definitions of concepts and reliable tools and resources. In spite of the growing interest in collocations, there exist only a few resources that can serve as gold standards in collocation research. This paper reports on the construction of the dataset annotated by experts that comprises 4,732 instances of collocations and non-collocations (free phrases, idioms, named entities, terms). The datas"
2020.lrec-1.538,W19-5112,1,0.846054,"ation The presented dataset is suitable not only for evaluating statistical measures and conducting machine learning experiments, but also for a more fine-grained semantic classification of adjective-noun phrases. There are two ongoing studies to find the right level of granularity for such a semantic classification. In the first approach, we describe the relations that hold between the base and its collocate, similarly to the idea of Lexical Functions (Mel’čuk, 1996). We have examined different theoretical frameworks that can serve as a basis for semantic modelling of adjective-noun phrases (Strakatova and Hinrichs, 2019). In the current study, we rely on the information about the semantic subclasses of adjectives provided in GermaNet to define the relations between the adjective and the noun. Consider the phrase alte Frau ‘old lady’: here, the adjective alt ‘old’ expresses the value for the noun’s attribute age. However, in the collocation alter Freund ‘old friend’ the adjective ‘alt’ in most cases does not make a reference to the age of a person, but rather describes the duration of a friendship. Table 6 presents further examples of such attribute relations. Almost all the adjectives in the dataset are polys"
2020.lrec-1.538,tiedemann-2012-parallel,0,0.0454577,"representations are more useful because of their ability to model different meanings of the same word depending on the context. 4.1. Data In order to obtain context-aware representations of meaning, we extracted sentences containing the adjective-noun pairs from the GerCo dataset. The source corpora stem from different domains (encyclopedia, newspaper, blogs) 4371 and are publicly available. These corpora include Wikipedia (dumps from 2017, 2018, 2019), the One Million Posts Corpus (Schabus et al., 2017; Schabus and Skowron, 2018), the German proceedings from the EuroParl corpus (Koehn, 2005; Tiedemann, 2012) and the German Political Speeches Corpus (Barbaresi, 2018). We were able to extract context sentences for 3,652 free phrases and collocations. We randomly selected one context sentence per phrase with a sentence length between 15 and 30 words. To be able to analyse the performance for each of the 48 adjectives, we created six splits, each split containing a different set of adjectives in the test set. On top of that, the adjectives in the test set, are not present in the training data, thus it can be investigated whether the models can generalize above the word level. Figure 2 gives an overvi"
C10-1052,kunze-lemnitzer-2002-germanet,0,0.341606,"peronymy relation of synsets. Figure 1. Structure of the XML synset files. 3 Current GermaNet XML Format The structure of the XML files closely follows the internal structure of GermaNet, which means that the file structure mirrors the underlying relational organization of the data. There are two DTDs that jointly describe the XMLencoded GermaNet. One DTD represents all synsets with their lexical units and their attributes (see subsection 3.1). The other DTD represents all relations, both conceptual and lexical relations (see subsection 3.2). The GermaNet XML format was initially developed by Kunze and Lemnitzer (2002), but modifications of the GermaNet data itself led to an adopted XML format, which is presented here.8 3.1 XML Synset Files The XML files that represent all synsets and lexical units of GermaNet are organized around the three word categories currently included in GermaNet: nouns, adjectives, and verbs (altogether 54 synset files since the semantic space for each word category is divided into a number of semantic subfields). The structure of each of these files is illustrated in Figure 19. Each synset represents a set of lexical units (lexUnits) which all express the same meaning. This groupin"
C10-1052,henrich-hinrichs-2010-gernedit,1,0.774447,"hat was designed for the English Princeton WordNet (Fellbaum, 1998). It is a plain-text format for storing wordnet data and allows lexicographers to encode lexical and conceptual relations among lexical units and synsets by use of special-purpose diacritics. There exist numerous tools that can process WordNet 1.6 lexicographer files to extract relevant information or to transform the data into other special-purpose formats such as Prolog-fact databases. Even tough still widely used for the reasons just mentioned, the complexity of the format itself has a number of undesirable consequences. As Henrich and Hinrichs (2010) have pointed out, 1 See http://www.tei-c.org See http://www.iso.org 3 See http://www.w3.org/TR/REC-xml/ 2 4 See http://wordnet.princeton.edu/man/lexnames.5 WN.html 456 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 456–464, Beijing, August 2010 the editing of lexicographer files is highly error-prone and time-consuming in actual lexicographic development. Moreover, format validation of the data as well as development of new tools for data visualization and data extraction become increasingly difficult since they cannot be based on generic st"
C10-1052,W09-3418,0,0.0316422,"perspective contrasts the synset-driven relational structure of wordnets – the grouping of word senses (i.e., lexical units) that express the same meaning into synsets. Exactly these two radically different organizing principles (relation-based in the case of wordnets versus lexical-entry-based in the case of LMF) constitute the challenge of encoding wordnets in LMF. We take up this challenge: How can a synset-based wordnet, e.g. GermaNet, be represented in a word-driven format like LMF? 4.2 Apply LMF to Wordnets The conversion of GermaNet to LMF will build on Wordnet-LMF (Soria et al., 2009; Lee et al., 2009), an existing Lexical Markup Framework subset11. Wordnet-LMF has been developed in the context of the EU KYOTO 11 Wordnet-LMF is a proper subset of LMF since there are specifications in LMF that are not in Wordnet-LMF and since there is nothing in Wordnet-LMF which is not in LMF. Soria et al. (2009) themselves refer to WordnetLMF as an LMF dialect. Figure 5. The Wordnet-LMF structure. project12 and is especially tailored to encode wordnets in the LMF standard. Wordnet-LMF is specified by a Document Type Definition (see Appendix E in (Soria and Monachini, 2008)) and fully complies with standard"
C10-1052,francopoulo-etal-2006-lexical,0,\N,Missing
C90-2025,C88-2128,0,0.0715582,"Missing"
C90-2025,P89-1002,0,0.0468331,"Missing"
C90-2025,W89-0216,0,0.0373935,"Missing"
C90-2025,C86-1045,0,\N,Missing
C90-2025,C86-1016,0,\N,Missing
C90-2025,P87-1011,0,\N,Missing
C96-1092,J91-3003,0,\N,Missing
C96-1092,C94-1039,0,\N,Missing
C96-1092,E93-1052,0,\N,Missing
C96-1092,P95-1010,0,\N,Missing
C96-1092,P86-1038,0,\N,Missing
de-smedt-etal-2014-clara,Y12-1015,0,\N,Missing
de-smedt-etal-2014-clara,W11-2153,0,\N,Missing
de-smedt-etal-2014-clara,W12-3903,0,\N,Missing
de-smedt-etal-2014-clara,W11-2605,0,\N,Missing
de-smedt-etal-2014-clara,W13-1728,0,\N,Missing
de-smedt-etal-2014-clara,R11-1041,1,\N,Missing
de-smedt-etal-2014-clara,W11-4647,0,\N,Missing
de-smedt-etal-2014-clara,W13-2907,1,\N,Missing
de-smedt-etal-2014-clara,W11-4604,1,\N,Missing
de-smedt-etal-2014-clara,P13-1054,1,\N,Missing
de-smedt-etal-2014-clara,Y12-1014,0,\N,Missing
de-smedt-etal-2014-clara,P11-3013,0,\N,Missing
de-smedt-etal-2014-clara,ramasamy-zabokrtsky-2012-prague,0,\N,Missing
de-smedt-etal-2014-clara,W13-2805,0,\N,Missing
de-smedt-etal-2014-clara,larasati-2012-identic,0,\N,Missing
de-smedt-etal-2014-clara,alonso-etal-2012-voting,1,\N,Missing
de-smedt-etal-2014-clara,W12-3410,0,\N,Missing
de-smedt-etal-2014-clara,drobac-etal-2014-heuristic,1,\N,Missing
de-smedt-etal-2014-clara,P13-2127,1,\N,Missing
de-smedt-etal-2014-clara,W11-4406,0,\N,Missing
de-smedt-etal-2014-clara,dione-2014-pruning,0,\N,Missing
de-smedt-etal-2014-clara,R11-2019,0,\N,Missing
de-smedt-etal-2014-clara,W12-6304,0,\N,Missing
de-smedt-etal-2014-clara,W14-1203,1,\N,Missing
de-smedt-etal-2014-clara,W12-5017,0,\N,Missing
de-smedt-etal-2014-clara,lis-2012-polish,0,\N,Missing
de-smedt-etal-2014-clara,W14-0808,0,\N,Missing
de-smedt-etal-2014-clara,schumann-2012-knowledge,0,\N,Missing
de-smedt-etal-2014-clara,C12-1065,1,\N,Missing
de-smedt-etal-2014-clara,dione-2012-morphological,0,\N,Missing
de-smedt-etal-2014-clara,escartin-2012-design,0,\N,Missing
de-smedt-etal-2014-clara,W12-2019,1,\N,Missing
de-smedt-etal-2014-clara,lenkiewicz-etal-2012-avatech,1,\N,Missing
de-smedt-etal-2014-clara,W11-3302,1,\N,Missing
de-smedt-etal-2014-clara,escartin-2014-chasing,0,\N,Missing
de-smedt-etal-2014-clara,W12-0503,0,\N,Missing
de-smedt-etal-2014-clara,W13-5411,1,\N,Missing
de-smedt-etal-2014-clara,gebre-etal-2012-towards,1,\N,Missing
dima-etal-2012-metadata,dima-etal-2012-repository,1,\N,Missing
dima-etal-2012-metadata,broeder-etal-2010-data,1,\N,Missing
dima-etal-2012-repository,dima-etal-2012-metadata,1,\N,Missing
dima-etal-2012-repository,broeder-etal-2012-standardizing,1,\N,Missing
dima-etal-2012-repository,broeder-etal-2010-data,1,\N,Missing
dima-etal-2012-repository,hinrichs-etal-2010-sustainability,1,\N,Missing
E09-1047,J94-4001,0,0.309468,"Missing"
E09-1047,P92-1003,0,0.519481,"Missing"
E09-1047,C02-1131,0,0.0357558,"Missing"
E09-1047,W08-1005,0,0.0522758,"). BitPar is an efficient implementation of an Earley style parser that uses bit vectors. However, BitPar cannot handle pre-bracketed input. For this reason, we used LoPar for the experiments where such input was required. LoPar, as it is used here, is a pure PCFG parser, which allows the input to be partially bracketed. We are aware that the results that can be obtained by pure PCFG parsers are not state of the art as reported in the shared task of the ACL 2008 Workshop on Parsing German (K¨ubler, 2008). While BitPar reaches an F-score of 69.76 (see next section), the best performing parser (Petrov and Klein, 2008) reaches an Fscore of 83.97 on T¨uBa-D/Z (but with a different split of training and test data). However, our experiments require certain features in the parsers, namely the capability to provide n-best analyses and to parse pre-bracketed input. To our knowledge, the parsers that took part in the shared task do not provide these features. Should they become available, the methods presented here could be applied to such parsers. We see no reason why our The Treebank The data source used for the experiments is the T¨ubingen Treebank of Written German (T¨uBaD/Z) (Telljohann et al., 2005). T¨uBa-D"
E09-1047,P05-1022,0,0.303414,"Missing"
E09-1047,C04-1024,0,0.14491,"Missing"
E09-1047,J05-1003,0,0.31486,"phenomena are particularly hard for pure PCFG parsing, due to the independence assumption inherent in the statistical models for PCFGs. Sentence (4) has the following Viterbi parse: methods should not be able to improve the results of these parsers further. Since we are interested in parsing coordinations, all experiments are conducted with gold POS tags, so as to abstract away from POS tagging errors. Although the treebank contains morphological information, this type of information is not used in the experiments presented here. The reranking experiments were conducted using the reranker by Collins and Koo (2005). This reranker uses a set of candidate parses for a sentence and reranks them based on a set of features that are extracted from the trees. The reranker uses a boosting method based on the approach by Freund et al. (1998). We used a similar feature set to the one Collins and Koo used; the following types of features were included: rules, bigrams, grandparent rules, grandparent bigrams, lexical bigrams, two-level rules, two-level bigrams, trigrams, head-modifiers, PPs, and distance for headmodifier relations, as well as all feature types involving rules extended by closed class lexicalization."
E09-1047,telljohann-etal-2004-tuba,1,0.905351,"Missing"
E09-1047,P07-1086,0,0.815425,"error analysis of his WSJ parsing results that coordination is one of the most frequent cases of incorrect parses, particularly if the conjuncts involved are complex. He manages to reduce errors for simple cases of NP coordination by introducing a special phrasal category of base NPs. In the experiments presented above, no explicit distinction is made between simple and complex cases of coordination, and no transformations are performed on the treebank annotations used for training. Our experiment 1, reranking 50-best parses, is similar to the approaches of Charniak and Johnson (2005) and of Hogan (2007). However, it differs from their experiments in two crucial ways: 1) Compared to Charniak and Johnson, who use 1.1 mio. features, our feature set is appr. five times larger (more than 5 mio. features), with the same threshold of at least five occurrences in the training set. 2) Both Hogan and Charniak and Johnson use special features for coordinate structures, such as a Boolean feature for marking parallelism (Charniak and Johnson) or for distinguishing between coordination of base NPs and coordination of complex conjuncts (Hogan), while our approach refrains from such special-purpose features"
E09-1047,J03-4003,0,\N,Missing
E09-1047,W08-1008,1,\N,Missing
E12-1039,agirre-de-lacalle-2004-publicly,0,0.0623836,"Missing"
E12-1039,henrich-hinrichs-2010-gernedit,1,0.882172,"ference of the European Chapter of the Association for Computational Linguistics, pages 387–396, c Avignon, France, April 23 - 27 2012. 2012 Association for Computational Linguistics Wikipedia2 . As a proof of concept, this automatic method has been applied to German, a language for which sense-annotated corpora are still in short supply and fail to satisfy most if not all of the criteria under (3) above. While the present paper focuses on one particular language, the method as such is language-independent. In the case of German, the sense inventory is taken from the German wordnet GermaNet3 (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002). The web-harvesting relies on an existing mapping of GermaNet to the German version of the web-based dictionary Wiktionary. This mapping is described in Henrich et al. (2011). The resulting resource consists of a web-harvested corpus WebCAGe (short for: Web-Harvested Corpus Annotated with GermaNet Senses), which is freely available at: http://www.sfs.unituebingen.de/en/webcage.shtml The remainder of this paper is structured as follows: Section 2 provides a brief overview of the resources GermaNet and Wiktionary. Section 3 introduces the mapping of GermaNet to Wikti"
E12-1039,raileanu-etal-2002-evaluation,0,\N,Missing
E12-1039,J98-1006,0,\N,Missing
E12-1039,S07-1000,0,\N,Missing
E12-1039,P95-1026,0,\N,Missing
E12-1039,P10-1023,0,\N,Missing
E12-1039,J03-3006,0,\N,Missing
E12-1039,I11-1099,0,\N,Missing
E12-1039,kunze-lemnitzer-2002-germanet,0,\N,Missing
E12-1039,S10-1000,0,\N,Missing
E17-2050,N15-1142,0,0.0127659,"nd total correlation (Van de Cruys, 2011), both of which can simultaneously take into account three variables, which are the preposition, object and candidate in our case. Overall, our auxiliary distributions consist of 5 types of association scores that are estimated from automatically parsed corpora. Word and tag embeddings Traditional methods for PP attachment represent the word and tag features as one-hot vectors. For the embedding representations of these two types of features, we use the embeddings of de Kok (2015), which were trained on corpora of 800 millions tokens, using WANG 2 VEC (Ling et al., 2015), a variation of WORD 2 VEC that is tailored to syntactic tasks. Topological fields As mentioned in the Introduction, topological fields are informative for the distributions of syntactic relations in general. Our analysis of the T¨uBa-D/Z dependency treebank (Telljohann et al., 2006) for German shows that this observation also holds for the PP attachment relation. For example, when the preposition is in the initial field, the preposition is highly likely to attach to the candidate in either the initial field or the left bracket. We use the method of de Kok and Hinrichs (2016) to predict the t"
E17-2050,P06-2029,0,0.566627,"Missing"
E17-2050,P12-1082,0,0.426046,"Missing"
E17-2050,P00-1014,0,0.428512,"e effective in solving PP attachment ambiguities (Brunner et al., 1992; Whittemore et al., 1990). Two words have a strong bi-lexical preference if the words are likely to occur in a head-dependent relation. These preferences are usually stated in terms of information-theoretical measures, such as point-wise mutual information. Since hand-annotated treebanks usually do not have enough material to obtain reliable bilexical statistics, these statistics were extracted from raw text (Volk, 2001), automatically tagged (Ratnaparkhi, 1998), chunk parsed (Volk, 2002) or parsed (Hindle and Rooth, 1993; Pantel and Lin, 2000; Mirroshandel et al., 2012) corpora, resulting in auxiliary distributions. Since these seminal works in PP attachment, parsers have become faster (K¨ubler et al., 2009) and more accurate (Chen and Manning, 2014), opening the possibility to obtain better co-occurrence statistics. 2 PP attachment disambiguation model Following the discussion in the Introduction, this paper considers a realistic setup for PP attachment disambiguation, where each disambiguation instance involves choosing the correct attachment site from an arbitrary number of candidates. As the number of classes/candidates varies"
E17-2050,J93-1005,0,0.691551,"i-lexical preferences are effective in solving PP attachment ambiguities (Brunner et al., 1992; Whittemore et al., 1990). Two words have a strong bi-lexical preference if the words are likely to occur in a head-dependent relation. These preferences are usually stated in terms of information-theoretical measures, such as point-wise mutual information. Since hand-annotated treebanks usually do not have enough material to obtain reliable bilexical statistics, these statistics were extracted from raw text (Volk, 2001), automatically tagged (Ratnaparkhi, 1998), chunk parsed (Volk, 2002) or parsed (Hindle and Rooth, 1993; Pantel and Lin, 2000; Mirroshandel et al., 2012) corpora, resulting in auxiliary distributions. Since these seminal works in PP attachment, parsers have become faster (K¨ubler et al., 2009) and more accurate (Chen and Manning, 2014), opening the possibility to obtain better co-occurrence statistics. 2 PP attachment disambiguation model Following the discussion in the Introduction, this paper considers a realistic setup for PP attachment disambiguation, where each disambiguation instance involves choosing the correct attachment site from an arbitrary number of candidates. As the number of cla"
E17-2050,D14-1162,0,0.085915,"ility) pairs that are constructed from the training data. Correct and incorrect attachments are assigned probabilities 1 and 0 respectively. To learn the model parameters, we minimize the cross-entropy loss using mini-batch gradient descent. During learning, the global learning rate follows an exponential decay and the perparameter learning rate is adjusted using Adagrad (Duchi et al., 2011). Many tasks in natural language processing have seen substantial improvements in recent years through the use of word embeddings in combination with neural networks. Word embeddings (Mikolov et al., 2013; Pennington et al., 2014) improve the lexical coverage of systems beyond supervised training sets by giving words that occur in similar contexts similar vector representations. Embeddings work especially well with neural networks, as neural networks are able to capture nonlinear interactions between features. Considering these ideas and techniques that can have an impact on modeling PP attachment, the question we want to address is where do we stand in PP attachment? Our contributions are threefold: (1) we evaluate PP attachment on a realistic multiple-candidate PP attachment data set for German; (2) we integrate the"
E17-2050,A00-2021,0,0.119558,"used in creating the auxiliary distributions. We split the remaining 43,906 instances with a 4:1 ratio for respectively training and evaluation. Initially, a subset of the training data is used to tune hyper-parameters. Then we train the model on the full training set using the chosen hyper-parameters.1 Finally, the model performance is evaluated on the test set, using standard per-preposition accuracy, i.e the percentage of prepositions that are correctly attached. Auxiliary distributions of bi-lexical preferences have been shown to be useful for resolving syntactical ambiguities in general (Johnson and Riezler, 2000; van Noord, 2007), besides their particular benefits for PP attachment as discussed in Section 1. Such bi-lexical preferences can be captured, for example, by point-wise mutual information (PMI) that is estimated from large machine-annotated corpora. Our approach makes use of a state-of-the-art dependency parser (de Kok and Hinrichs, 2016) to parse a large corpus, namely articles from the German newspaper taz (die tageszeitung) from 1986 to 2009 (28.8 million sentences, 393.7 million tokens). The parser-predicted PP attachments are represented as <preposition, object of the preposition, candi"
E17-2050,P98-2177,0,0.892844,"attributed to the system. Previous work has shown that bi-lexical preferences are effective in solving PP attachment ambiguities (Brunner et al., 1992; Whittemore et al., 1990). Two words have a strong bi-lexical preference if the words are likely to occur in a head-dependent relation. These preferences are usually stated in terms of information-theoretical measures, such as point-wise mutual information. Since hand-annotated treebanks usually do not have enough material to obtain reliable bilexical statistics, these statistics were extracted from raw text (Volk, 2001), automatically tagged (Ratnaparkhi, 1998), chunk parsed (Volk, 2002) or parsed (Hindle and Rooth, 1993; Pantel and Lin, 2000; Mirroshandel et al., 2012) corpora, resulting in auxiliary distributions. Since these seminal works in PP attachment, parsers have become faster (K¨ubler et al., 2009) and more accurate (Chen and Manning, 2014), opening the possibility to obtain better co-occurrence statistics. 2 PP attachment disambiguation model Following the discussion in the Introduction, this paper considers a realistic setup for PP attachment disambiguation, where each disambiguation instance involves choosing the correct attachment site"
E17-2050,D12-1096,0,0.459912,"Missing"
E17-2050,W11-1303,0,0.366726,"Missing"
E17-2050,W07-2201,0,0.257967,"Missing"
E17-2050,C02-1004,0,0.316235,"s work has shown that bi-lexical preferences are effective in solving PP attachment ambiguities (Brunner et al., 1992; Whittemore et al., 1990). Two words have a strong bi-lexical preference if the words are likely to occur in a head-dependent relation. These preferences are usually stated in terms of information-theoretical measures, such as point-wise mutual information. Since hand-annotated treebanks usually do not have enough material to obtain reliable bilexical statistics, these statistics were extracted from raw text (Volk, 2001), automatically tagged (Ratnaparkhi, 1998), chunk parsed (Volk, 2002) or parsed (Hindle and Rooth, 1993; Pantel and Lin, 2000; Mirroshandel et al., 2012) corpora, resulting in auxiliary distributions. Since these seminal works in PP attachment, parsers have become faster (K¨ubler et al., 2009) and more accurate (Chen and Manning, 2014), opening the possibility to obtain better co-occurrence statistics. 2 PP attachment disambiguation model Following the discussion in the Introduction, this paper considers a realistic setup for PP attachment disambiguation, where each disambiguation instance involves choosing the correct attachment site from an arbitrary number o"
E17-2050,P90-1004,0,0.0777249,"ly difficult is that the ambiguities can often not be solved using only structural preferences. Example 1 from 311 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 311–317, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics clause structure annotations. form an error analysis to gauge how many of the remaining errors can be attributed to the system. Previous work has shown that bi-lexical preferences are effective in solving PP attachment ambiguities (Brunner et al., 1992; Whittemore et al., 1990). Two words have a strong bi-lexical preference if the words are likely to occur in a head-dependent relation. These preferences are usually stated in terms of information-theoretical measures, such as point-wise mutual information. Since hand-annotated treebanks usually do not have enough material to obtain reliable bilexical statistics, these statistics were extracted from raw text (Volk, 2001), automatically tagged (Ratnaparkhi, 1998), chunk parsed (Volk, 2002) or parsed (Hindle and Rooth, 1993; Pantel and Lin, 2000; Mirroshandel et al., 2012) corpora, resulting in auxiliary distributions."
E17-2050,Q14-1043,0,\N,Missing
E17-2050,D14-1082,0,\N,Missing
H01-1072,C00-1011,0,0.164592,"of each level serving as input for the next higher level. The first level is part-of-speech (POS) tagging of the input string with the help of the bigram tagger LIKELY [10].1 The parts of speech serve as pre-terminal elements for the next step, i.e. the chunk analysis. Chunk parsing is carried out by an adapted version of Abney’s [2] scol parser, which is realized as a cascade of finite-state transducers. The chunks, which extend if possible to the simplex clause level, are then remodeled into complete trees in the tree construction level. The tree construction is similar to the DOP approach [3, 4] in that it uses complete tree structures instead of rules. Contrary to Bod, we do not make use of probabilities and do not allow tree cuts, instead we only use the complete trees and minimal tree modifications. Thus the number of possible combinations of partial trees is strictly controlled. The resulting parser is highly efficient (3770 English sentences took 106.5 seconds to parse on an Ultra Sparc 10). 3. CHUNK PARSING AND TREE CONSTRUCTION The division of labor between the chunking and tree construction modules can best be illustrated by an example. . 1 The inventory of POS tags is based"
H01-1072,W98-1207,0,0.23362,"mmatical function or constituents with several possible functions may be found so that an additional classifier is needed for selecting the most appropriate assignment (cf. [6]). The second approach, which we have chosen, is to regard the complete parse trees as classes so that the task is defined as the selection of the most similar tree from the instance base. Since in 2 All trees in this contribution follow the data format for trees defined by the NEGRA project of the Sonderforschungsbereich 378 at the University of the Saarland, Saarbr¨ucken. They were printed by the NEGRA annotation tool [5]. 3 Memory-based learning has recently been applied to a variety of NLP classification tasks, including part-of-speech tagging, noun phrase chunking, grapheme-phoneme conversion, word sense disambiguation, and pp attachment (see [9], [14], [15] for details). construct tree(chunk list, treebank): while (chunk list is not empty) do remove first chunk from chunk list process chunk(chunk, treebank) Figure 3: Pseudo-code for tree construction, main routine. process chunk(chunk, treebank): words := string yield(chunk) tree := complete match(words, treebank) if (tree is not empty) then output(tree) e"
H01-1072,W99-0629,0,0.0323722,"ed as a classification task. There are two fundamentally different, possible approaches: the one is to split parsing up into different subtasks, that is, one needs separate classifiers for each functional category and for each level in a recursive structure. Since the classifiers for the functional categories as well as the individual decisions of the classifiers are independent, multiple or no candidates for a specific grammatical function or constituents with several possible functions may be found so that an additional classifier is needed for selecting the most appropriate assignment (cf. [6]). The second approach, which we have chosen, is to regard the complete parse trees as classes so that the task is defined as the selection of the most similar tree from the instance base. Since in 2 All trees in this contribution follow the data format for trees defined by the NEGRA project of the Sonderforschungsbereich 378 at the University of the Saarland, Saarbr¨ucken. They were printed by the NEGRA annotation tool [5]. 3 Memory-based learning has recently been applied to a variety of NLP classification tasks, including part-of-speech tagging, noun phrase chunking, grapheme-phoneme conver"
H01-1072,P79-1022,0,0.0504144,"rd the complete parse trees as classes so that the task is defined as the selection of the most similar tree from the instance base. Since in 2 All trees in this contribution follow the data format for trees defined by the NEGRA project of the Sonderforschungsbereich 378 at the University of the Saarland, Saarbr¨ucken. They were printed by the NEGRA annotation tool [5]. 3 Memory-based learning has recently been applied to a variety of NLP classification tasks, including part-of-speech tagging, noun phrase chunking, grapheme-phoneme conversion, word sense disambiguation, and pp attachment (see [9], [14], [15] for details). construct tree(chunk list, treebank): while (chunk list is not empty) do remove first chunk from chunk list process chunk(chunk, treebank) Figure 3: Pseudo-code for tree construction, main routine. process chunk(chunk, treebank): words := string yield(chunk) tree := complete match(words, treebank) if (tree is not empty) then output(tree) else tree := partial match(words, treebank) if (tree is not empty) then if (tree = postfix of chunk) then tree1 := attach next chunk(tree, treebank) if (tree is not empty) then tree := tree1 if ((chunk - tree) is not empty) then tree"
H01-1072,W97-1016,0,0.238208,"lete parse trees as classes so that the task is defined as the selection of the most similar tree from the instance base. Since in 2 All trees in this contribution follow the data format for trees defined by the NEGRA project of the Sonderforschungsbereich 378 at the University of the Saarland, Saarbr¨ucken. They were printed by the NEGRA annotation tool [5]. 3 Memory-based learning has recently been applied to a variety of NLP classification tasks, including part-of-speech tagging, noun phrase chunking, grapheme-phoneme conversion, word sense disambiguation, and pp attachment (see [9], [14], [15] for details). construct tree(chunk list, treebank): while (chunk list is not empty) do remove first chunk from chunk list process chunk(chunk, treebank) Figure 3: Pseudo-code for tree construction, main routine. process chunk(chunk, treebank): words := string yield(chunk) tree := complete match(words, treebank) if (tree is not empty) then output(tree) else tree := partial match(words, treebank) if (tree is not empty) then if (tree = postfix of chunk) then tree1 := attach next chunk(tree, treebank) if (tree is not empty) then tree := tree1 if ((chunk - tree) is not empty) then tree := extend t"
H01-1072,J03-4003,0,\N,Missing
H86-1001,P84-1085,1,\N,Missing
H86-1001,P86-1036,1,\N,Missing
H86-1001,H86-1008,1,\N,Missing
heid-etal-2010-corpus,hinrichs-etal-2010-weblicht,1,\N,Missing
heid-etal-2010-corpus,C04-1024,1,\N,Missing
heid-etal-2010-corpus,W07-1501,0,\N,Missing
heid-etal-2010-corpus,kountz-etal-2008-laf,1,\N,Missing
heid-etal-2010-corpus,P10-4005,1,\N,Missing
heid-etal-2010-term,weller-heid-2010-extraction,1,\N,Missing
heid-etal-2010-term,ivanova-etal-2008-evaluating,1,\N,Missing
heid-etal-2010-term,C04-1024,0,\N,Missing
heid-etal-2010-term,E03-1087,0,\N,Missing
heid-etal-2010-term,W03-0804,0,\N,Missing
heid-etal-2010-term,hinrichs-etal-2010-weblicht,1,\N,Missing
heid-etal-2010-term,P10-4005,1,\N,Missing
heid-etal-2010-term,heid-etal-2010-corpus,1,\N,Missing
henrich-hinrichs-2010-gernedit,kunze-lemnitzer-2002-germanet,0,\N,Missing
henrich-hinrichs-2012-comparative,E12-1039,1,\N,Missing
henrich-hinrichs-2012-comparative,W03-1302,0,\N,Missing
henrich-hinrichs-2012-comparative,E09-1005,0,\N,Missing
henrich-hinrichs-2012-comparative,O97-1002,0,\N,Missing
henrich-hinrichs-2012-comparative,P95-1026,0,\N,Missing
henrich-hinrichs-2012-comparative,N07-1044,0,\N,Missing
henrich-hinrichs-2012-comparative,P04-1036,0,\N,Missing
henrich-hinrichs-2012-comparative,P06-1014,0,\N,Missing
henrich-hinrichs-2012-comparative,P94-1019,0,\N,Missing
henrich-hinrichs-2012-comparative,J06-1003,0,\N,Missing
henrich-hinrichs-2012-comparative,J01-2002,0,\N,Missing
henrich-hinrichs-2012-comparative,W02-1004,0,\N,Missing
henrich-hinrichs-2012-comparative,kunze-lemnitzer-2002-germanet,0,\N,Missing
henrich-hinrichs-2012-comparative,W04-0827,0,\N,Missing
hinrichs-etal-2002-hybrid,borin-2000-something,0,\N,Missing
hinrichs-etal-2002-hybrid,W96-0102,0,\N,Missing
hinrichs-etal-2002-hybrid,W99-0707,0,\N,Missing
hinrichs-etal-2002-hybrid,H01-1072,1,\N,Missing
hinrichs-etal-2002-hybrid,W98-1207,0,\N,Missing
hinrichs-etal-2002-hybrid,E93-1007,0,\N,Missing
hinrichs-etal-2002-hybrid,A97-1012,0,\N,Missing
hinrichs-etal-2002-hybrid,A00-1033,0,\N,Missing
hinrichs-etal-2002-hybrid,C00-1046,0,\N,Missing
hinrichs-etal-2002-hybrid,P01-1045,1,\N,Missing
hinrichs-etal-2002-hybrid,grover-etal-2000-lt,0,\N,Missing
hinrichs-etal-2002-hybrid,P98-1081,0,\N,Missing
hinrichs-etal-2002-hybrid,C98-1078,0,\N,Missing
hinrichs-etal-2010-sustainability,kunze-lemnitzer-2002-germanet,0,\N,Missing
hinrichs-etal-2010-weblicht,W07-1501,0,\N,Missing
hinrichs-etal-2010-weblicht,heid-etal-2010-corpus,1,\N,Missing
hinrichs-krauwer-2014-clarin,meister-vilo-2008-strengthening,0,\N,Missing
hinrichs-krauwer-2014-clarin,nygaard-etal-2008-glossa,0,\N,Missing
hinrichs-krauwer-2014-clarin,telljohann-etal-2004-tuba,1,\N,Missing
hinrichs-krauwer-2014-clarin,van-uytvanck-etal-2010-virtual,0,\N,Missing
hinrichs-krauwer-2014-clarin,C10-1052,1,\N,Missing
hinrichs-krauwer-2014-clarin,P10-4005,1,\N,Missing
hinrichs-krauwer-2014-clarin,kupietz-etal-2010-german,0,\N,Missing
hinrichs-krauwer-2014-clarin,W13-5643,0,\N,Missing
hinrichs-krauwer-2014-clarin,osenova-simov-2012-political,0,\N,Missing
hinrichs-krauwer-2014-clarin,biber-breiteneder-2004-aac,0,\N,Missing
hinrichs-krauwer-2014-clarin,simov-etal-2002-building,0,\N,Missing
hinrichs-lau-2008-contrast,J88-2002,1,\N,Missing
hinrichs-lau-2008-contrast,J03-4002,0,\N,Missing
hinrichs-lau-2008-contrast,J02-4002,0,\N,Missing
hinrichs-lau-2008-contrast,N07-1040,0,\N,Missing
hinrichs-zastrow-2012-automatic,telljohann-etal-2004-tuba,1,\N,Missing
hinrichs-zastrow-2012-automatic,dima-etal-2012-repository,1,\N,Missing
hinrichs-zastrow-2012-automatic,hinrichs-etal-2010-weblicht,1,\N,Missing
hinrichs-zastrow-2012-automatic,heid-etal-2010-corpus,1,\N,Missing
J88-2002,P87-1005,0,0.0611509,"Missing"
J88-2002,P86-1032,0,0.0177121,"ss rating of C3 or better are salient in the context, since only such ships are deployable. By instantiating R appropriately, the formula in (42) turns into (43). 43. QUERY [ ^ A x [x ~ POW [h y 3 t&apos; [ ship&apos; (y) (t&apos;) & readiness-rating&apos; (y) (t&apos;) &gt;- C3 & t&apos; = ts]] & 3 t [t = ts & t C_ tr & in&apos; (Indian-Ocean&apos;) (x) (t)]]] T h e instantiation of R in (42) follows from recognizing the user&apos;s plan as that of immediate ship deployment. The importance of plan recognition for designing question-answering systems that generate cooperative responses was emphasized in Allen/Perrault 1980, Allen 1983, and Pollack 1986. In the context of Example 41, if it turned out that two ships, Frederick and Vincent, are in the Indian Ocean, but both ships are rated C4, then a cooperative response would be (44), instead of merely listing the ship names. 41. a. I need to deploy a ship immediately for a searchand-rescue mission. b. Which ships are in the Indian Ocean? 44. Frederick and Vincent, but they are rated C4 and cannot be deployed. Recognizing the user&apos;s intention, which in the given context leads to the recognition of the current readiness rating of ships as a salient property, will make such a response possible."
J88-2002,P87-1002,1,\N,Missing
K17-3013,W06-2922,0,0.0291698,"Missing"
K17-3013,D07-1013,0,0.0720949,"Missing"
K17-3013,J08-4003,0,0.125896,"tilize FEATS as well. This setting, along with the other hyperparameters, were tuned by the sample data.4 3 shift (σ, [wi |β], A) 7→ ([wi |σ], β, A) left arcl ([wj , wi |σ], β, A) 7→ ([wj |σ], β, A∪{(wj , l, wi )}) right arcl ([wj , wi |σ], β, A) 7→ ([wi |σ], β, A∪{(wi , l, wj )}) where 0 = i Primary system: darc swap ([wj , wi |σ], β, A) 7→ ([wj |σ], [wi |β], A) where 0 &lt; i &lt; j Our primary system employs a transition-based parser. We adapted our parser from Chen and Manning (2014), who used a neural network classifier in a transition-based parsing algorithm known as the arc-standard system (Nivre, 2008). The neural network classifier requires little feature engineering, and therefore is easily adaptable for different languages, making it ideal for 3.2 Input features As input features, we use the set of 18 graph nodes from Chen and Manning (2014): • The top three words on the stack & buffer • The first & second leftmost & rightmost children of the top two words on the stack 4 In the end, we used the Polish treebank for Buryat and Kurmanji, Finnish for North Sami, and Slovenian for Upper Sorbian. The FEATS field was used in the models for Buryat and North Sami. 5 127 Persian, Spanish, and Viet"
K17-3013,D14-1082,0,0.0288835,"parser models to pick the best treebank for training a delexicalized model. These delexicalized models rely mostly on UPOSTAG, but may utilize FEATS as well. This setting, along with the other hyperparameters, were tuned by the sample data.4 3 shift (σ, [wi |β], A) 7→ ([wi |σ], β, A) left arcl ([wj , wi |σ], β, A) 7→ ([wj |σ], β, A∪{(wj , l, wi )}) right arcl ([wj , wi |σ], β, A) 7→ ([wi |σ], β, A∪{(wi , l, wj )}) where 0 = i Primary system: darc swap ([wj , wi |σ], β, A) 7→ ([wj |σ], [wi |β], A) where 0 &lt; i &lt; j Our primary system employs a transition-based parser. We adapted our parser from Chen and Manning (2014), who used a neural network classifier in a transition-based parsing algorithm known as the arc-standard system (Nivre, 2008). The neural network classifier requires little feature engineering, and therefore is easily adaptable for different languages, making it ideal for 3.2 Input features As input features, we use the set of 18 graph nodes from Chen and Manning (2014): • The top three words on the stack & buffer • The first & second leftmost & rightmost children of the top two words on the stack 4 In the end, we used the Polish treebank for Buryat and Kurmanji, Finnish for North Sami, and Sl"
K17-3013,P09-1040,0,0.080203,"Missing"
K17-3013,L16-1262,0,0.102519,"Missing"
K17-3013,C12-1059,0,0.0401788,"Missing"
K17-3013,W09-3811,0,0.443473,"Missing"
K17-3013,N15-1142,0,0.0431077,"Missing"
K17-3013,H05-1066,0,0.268506,"Missing"
K17-3013,L16-1680,0,0.12024,"Missing"
K17-3013,P14-5003,0,0.0639144,"Missing"
K17-3013,D15-1159,0,\N,Missing
L18-1206,W06-2920,0,0.0607984,"Missing"
L18-1206,W14-5211,0,0.072335,"Missing"
L18-1206,hinrichs-krauwer-2014-clarin,1,0.875661,"Missing"
L18-1206,L16-1262,1,0.886086,"Missing"
L18-1206,L16-1680,1,0.905458,"Missing"
P01-1045,W97-1016,0,\N,Missing
P01-1045,W97-0307,0,\N,Missing
P01-1045,H01-1072,1,\N,Missing
P01-1045,C94-1061,0,\N,Missing
P01-1045,J03-4003,0,\N,Missing
P01-1045,H94-1020,0,\N,Missing
P01-1045,C00-1011,0,\N,Missing
P01-1045,lesmo-lombardo-2000-automatic,0,\N,Missing
P01-1045,A97-1011,0,\N,Missing
P10-4004,kunze-lemnitzer-2002-germanet,0,0.0286343,"ypes of semantic relations in GermaNet: conceptual and lexical relations. Conceptual relations hold between two semantic concepts, i.e. synsets. They include relations such as hyperonymy, part-whole relations, entailment, or causation. GermaNet is hierarchically structured in terms of the hyperonymy relation. Lexical relations hold between two individual lexical units. Antonymy, a pair of opposites, is an example of a lexical relation. Introduction The main purpose of the GermaNet Editing Tool GernEdiT tool is to support lexicographers in accessing, modifying, and extending the GermaNet data (Kunze and Lemnitzer, 2002; Henrich and Hinrichs, 2010) in an easy and adaptive way and to aid in the navigation through the GermaNet word class hierarchies, so as to find the appropriate place in the hierarchy for new synsets (short for: synonymy set) and lexical units. GernEdiT replaces the traditional GermaNet development based on lexicographer files (Fellbaum, 1998) by a more user-friendly visual tool that supports versioning and collaborative annotation by several lexicographers working in parallel. Furthermore, GernEdiT facilitates internal consistency of the GermaNet data such as appropriate linking of lexical u"
P10-4004,henrich-hinrichs-2010-gernedit,1,0.468639,"in GermaNet: conceptual and lexical relations. Conceptual relations hold between two semantic concepts, i.e. synsets. They include relations such as hyperonymy, part-whole relations, entailment, or causation. GermaNet is hierarchically structured in terms of the hyperonymy relation. Lexical relations hold between two individual lexical units. Antonymy, a pair of opposites, is an example of a lexical relation. Introduction The main purpose of the GermaNet Editing Tool GernEdiT tool is to support lexicographers in accessing, modifying, and extending the GermaNet data (Kunze and Lemnitzer, 2002; Henrich and Hinrichs, 2010) in an easy and adaptive way and to aid in the navigation through the GermaNet word class hierarchies, so as to find the appropriate place in the hierarchy for new synsets (short for: synonymy set) and lexical units. GernEdiT replaces the traditional GermaNet development based on lexicographer files (Fellbaum, 1998) by a more user-friendly visual tool that supports versioning and collaborative annotation by several lexicographers working in parallel. Furthermore, GernEdiT facilitates internal consistency of the GermaNet data such as appropriate linking of lexical units with synsets, connectedn"
P10-4005,heid-etal-2010-corpus,1,0.838467,"Missing"
P15-1167,P14-1129,0,0.0945679,"Missing"
P15-1167,I05-3017,0,0.296869,"n for cj and i is a compact notation for i(bj ). In (4), δ(aj,k ) is an indicator function deﬁned by the following formula, where aˆj denotes the correct action. { 1, if aj,k = aˆj δ(aj,k ) = 0, otherwise character number, as compared with search, only a few constant time operations of gradient computation and parameter updates are performed for each character. 4 Experiments 4.1 Data and Evaluation Metric In the experiments, we use two widely used and freely available1 manually word-segmented corpora, namely, PKU and MSR, from the second SIGHAN international Chinese word segmentation bakeoff (Emerson, 2005). Table 2 shows the details of the two dataset. All evaluations in this paper are conducted with ofﬁcial training/testing set split using ofﬁcial scoring script.2 Word types Word tokens Character types Character tokens PKU 5.5 × 104 1.1 × 106 5 × 103 1.8 × 106 MSR 8.8 × 104 2.4 × 106 5 × 103 4.1 × 106 Table 2: Corpus details of PKU and MSR To counteract over-ﬁtting, we add L2 regularization term to the loss function, as follows: J =J+ K ∑ k=1 ) λ( 2 ||i ||+ ||o(aj,k )||2 2 (5) The formula in (4) and (5) are similar to that of a standard softmax regression, except that both input and output emb"
P15-1167,D14-1002,0,0.0139274,"ate for the absence of sentence level optimization. To model interactions between tags and characters, which are absent in these two CWS models, Pei et al. (2014) introduced the tag embedding and used a tensor hidden layer in the neural net. In contrast, our work uses character-speciﬁc action embeddings to explicitly capture such interactions. In addition, our work gains efﬁciency by avoiding hidden layers, similar as Mikolov et al. (2013). Learning to match. Matching heterogeneous objects has been studied in various contexts before, and is currently ﬂourishing, thanks to embeddingbased deep (Gao et al., 2014) and convolutional (Huang et al., 2013; Hu et al., 2014) neural networks. This work develops a matching model for CWS and differs from others in its “shallow”yet effective architecture. 6 Discussion Simple architecture. It is possible to adopt standard feed-forward neural network for our embedding matching model with character-action embeddings as both feature and output. Nevertheless, we designed the proposed architecture to avoid hidden layers for simplicity, efﬁciency and easytuning, inspired by word2vec. Our simple architecture is effective, demonstrated by the improved results over previo"
P15-1167,P08-1102,0,0.0553584,"Missing"
P15-1167,D12-1132,0,0.0400398,"d structures. Our work generalizes the sequence labeling to a 5 6 https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur et al. (2013) was inspired by Bengio et al. (2003) and used character big"
P15-1167,D14-1093,0,0.0652191,"https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur et al. (2013) was inspired by Bengio et al. (2003) and used character bigram embeddings to compensate for the absence of sentence level o"
P15-1167,W12-6304,1,0.893891,"Missing"
P15-1167,ma-2014-automatic,1,0.869711,"Missing"
P15-1167,I13-1181,0,0.37563,"h respect to the limited amount of training data. This has motivated the introduction of low-dimensional, realvalued vectors, known as embeddings, as a tool to deal with the sparseness of the input. Embeddings allow linguistic units appearing in similar contexts to share similar vectors. The success of embeddings has been observed in many NLP tasks. For CWS, Zheng et al. (2013) adapted Collobert et al. (2011) and uses character embeddings in local windows as input for a two-layer network. The network predicts individual character position tags, the transitions of which are learned separately. Mansur et al. (2013) also developed a similar architecture, which labels individual characters and uses character bigram embeddings as additional features to compensate the absence of sentence-level modeling. Pei et al. (2014) improved upon Zheng et al. (2013) by capturing the combinations of context and history via a tensor neural network. Despite their differences, these CWS approaches are all sequence labeling models. In such models, the target character can only inﬂuence the prediction as features. Consider the the segmentation conﬁguration in (1), where the dot appears before the target character in consider"
P15-1167,P14-1028,0,0.768713,"allow linguistic units appearing in similar contexts to share similar vectors. The success of embeddings has been observed in many NLP tasks. For CWS, Zheng et al. (2013) adapted Collobert et al. (2011) and uses character embeddings in local windows as input for a two-layer network. The network predicts individual character position tags, the transitions of which are learned separately. Mansur et al. (2013) also developed a similar architecture, which labels individual characters and uses character bigram embeddings as additional features to compensate the absence of sentence-level modeling. Pei et al. (2014) improved upon Zheng et al. (2013) by capturing the combinations of context and history via a tensor neural network. Despite their differences, these CWS approaches are all sequence labeling models. In such models, the target character can only inﬂuence the prediction as features. Consider the the segmentation conﬁguration in (1), where the dot appears before the target character in consideration and the box (2) represents any character that can occur in the conﬁguration. In that example, the known history is that the ﬁrst two characters 中国 ‘China’ are joined together, which is denoted by the"
P15-1167,C04-1081,0,0.826342,"edy segmenter is developed and evaluated on benchmark corpora. Experiments show that our greedy segmenter achieves improved results over previous neural network-based word segmenters, and its performance is competitive with state-of-the-art methods, despite its simple feature set and the absence of external resources for training. 1 Introduction Chinese sentences are written as character sequences without word delimiters, which makes word segmentation a prerequisite of Chinese language processing. Since Xue (2003), most work has formulated Chinese word segmentation (CWS) as sequence labeling (Peng et al., 2004) with character position tags, which has lent itself to structured discriminative learning with the beneﬁt of allowing rich features of segmentation conﬁgurations, including (i) context of character/word ngrams within local windows, (ii) segmentation history of previous characters, or the combinations of both. These feature-based models still form the backbone of most state-of-the art systems. Nevertheless, many feature weights in such models are inevitably poorly estimated because the number of parameters is so large with respect to the limited amount of training data. This has motivated the"
P15-1167,D12-1046,0,0.0550865,"ork generalizes the sequence labeling to a 5 6 https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur et al. (2013) was inspired by Bengio et al. (2003) and used character bigram embeddings to com"
P15-1167,P13-1045,0,0.0601031,"rom suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur et al. (2013) was inspired by Bengio et al. (2003) and used character bigram embeddings to compensate for the absence of sentence level optimization. To model interactions between tags and characters, which are absent in these two CWS models, Pei et al. (2014) introduced the tag embedding and used a tensor hidden layer in the neural net. In contrast, our work uses character-spec"
P15-1167,D11-1090,0,0.288533,"et al., 2012; Ma, 2014; Zhang et al., 2014), which explicitly model word structures. Our work generalizes the sequence labeling to a 5 6 https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur"
P15-1167,N09-1007,0,0.610065,"Missing"
P15-1167,P12-1027,0,0.26835,"Missing"
P15-1167,P09-1054,0,0.132606,"Missing"
P15-1167,O03-4002,0,0.578019,"g and prediction algorithms have linear-time complexity. Based on the proposed model, a greedy segmenter is developed and evaluated on benchmark corpora. Experiments show that our greedy segmenter achieves improved results over previous neural network-based word segmenters, and its performance is competitive with state-of-the-art methods, despite its simple feature set and the absence of external resources for training. 1 Introduction Chinese sentences are written as character sequences without word delimiters, which makes word segmentation a prerequisite of Chinese language processing. Since Xue (2003), most work has formulated Chinese word segmentation (CWS) as sequence labeling (Peng et al., 2004) with character position tags, which has lent itself to structured discriminative learning with the beneﬁt of allowing rich features of segmentation conﬁgurations, including (i) context of character/word ngrams within local windows, (ii) segmentation history of previous characters, or the combinations of both. These feature-based models still form the backbone of most state-of-the art systems. Nevertheless, many feature weights in such models are inevitably poorly estimated because the number of"
P15-1167,D14-1010,0,0.0339039,"le.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur et al. (2013) was inspired by Bengio et al. (2003) and used character bigram embeddings to compensate for the absence of sentence level optimization. To model in"
P15-1167,P13-1076,0,0.0371385,"2014), which explicitly model word structures. Our work generalizes the sequence labeling to a 5 6 https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag transition. Mansur et al. (2013) was inspired by Bengio et"
P15-1167,P07-1106,0,0.780075,"the N is the word token count of the testing set, which is 104,372 and 106,873 for PKU and MSR, respectively. We see 3 Our implementation: https://zenodo.org/record/17645. The results for Zheng et al. (2013) are from the reimplementation of Pei et al. (2014). 4 that the conﬁdence intervals of our results do not overlap with that of (Pei et al., 2014), meaning that our improvements are statistically signiﬁcant. 4.3 Comparison with the State-of-the-Art Systems Table 5 shows that the results of our greedy segmenter are competitive with the state-of-the-art supervised systems (Best05 closed-set, Zhang and Clark, 2007), although our feature set is much simpler. More recent state-of-the-art systems rely on both extensive feature engineering and extra raw corpora to boost performance, which are semi-supervised learning. For example, Zhang et al (2013) developed 8 types of static and dynamic features to maximize the co-training system that used extra corpora of Chinese Gigaword and Baike, each of which contains more than 1 billion character tokens. Such systems are not directly comparable with our supervised model. We leave the development of semi-supervised learning methods for our model as future work. 4.4 F"
P15-1167,J11-1005,0,0.0413065,"xact-search segmenter is no better or even worse than that of the greedy-search segmenter. We hypothesize that since the training updates parameters with regard to search errors, the ﬁnal model is “tailored” for the speciﬁc search method used, which makes the model-search combination of greedy search segmenter not necessarily worse than that of exact search segmenter. Another way of looking at it is that search is less important when the model is accurate. In this case, most step-wise decisions are correct in the ﬁrst place, which requires no correction from the search algorithm. Empirically, Zhang and Clark (2011) also reported exact-search segmenter performing worse than beam-search segmenters. Despite that the greedy segmenter is incapable of considering future labels, this rarely causes problems in practice. Our greedy segmenter has good results, compared with the exact-search segmenter above and previous approaches, most of which utilize exact search. Moreover, the greedy segmenter has additional advantages of faster training and prediction. Sequence labeling and matching. A traditional sequence labeling model such as CRF has K (number of labels) target-character-independent weight vectors, where t"
P15-1167,N06-2049,0,0.341769,"Missing"
P15-1167,W12-6308,0,0.19521,"Missing"
P15-1167,D13-1031,0,0.654673,"of Pei et al. (2014). 4 that the conﬁdence intervals of our results do not overlap with that of (Pei et al., 2014), meaning that our improvements are statistically signiﬁcant. 4.3 Comparison with the State-of-the-Art Systems Table 5 shows that the results of our greedy segmenter are competitive with the state-of-the-art supervised systems (Best05 closed-set, Zhang and Clark, 2007), although our feature set is much simpler. More recent state-of-the-art systems rely on both extensive feature engineering and extra raw corpora to boost performance, which are semi-supervised learning. For example, Zhang et al (2013) developed 8 types of static and dynamic features to maximize the co-training system that used extra corpora of Chinese Gigaword and Baike, each of which contains more than 1 billion character tokens. Such systems are not directly comparable with our supervised model. We leave the development of semi-supervised learning methods for our model as future work. 4.4 Features Inﬂuence Table 6 shows the F-scores of our model on PKU dataset when different features are removed (‘w/o’) or when only a subset of features are used. Features complement each other and removing any group of features leads to"
P15-1167,P14-1125,0,0.0508365,"Missing"
P15-1167,I08-4017,0,0.0171578,"vel features and (Ma et al., 2012; Ma, 2014; Zhang et al., 2014), which explicitly model word structures. Our work generalizes the sequence labeling to a 5 6 https://code.google.com/p/word2vec/ https://catalog.ldc.upenn.edu/LDC2005T14 more ﬂexible framework of matching, and predicts actions as in (Zhang and Clark, 2007; Zhang et al., 2012) instead of position tags to prevent the greedy search from suffering tag inconsistencies. To better utilize resources other than training data, our model might beneﬁt from techniques used in recent state-of-the-art systems, such as semi-supervised learning (Zhao and Kit, 2008; Sun and Xu, 2011; Zhang et al., 2013; Zeng et al., 2013), joint models (Li and Zhou, 2012; Qian and Liu, 2012), and partial annotations (Liu et al., 2014; Yang and Vozila, 2014). Distributed representation and CWS. Distributed representation are useful for various NLP tasks, such as POS tagging (Collobert et al., 2011), machine translation (Devlin et al., 2014) and parsing (Socher et al., 2013). Inﬂuenced by Collobert et al. (2011), Zheng et al. (2013) modeled CWS as tagging and treated sentence-level tag sequence as the combination of individual tag predictions and context-independent tag t"
P15-1167,D13-1061,0,0.48286,"e combinations of both. These feature-based models still form the backbone of most state-of-the art systems. Nevertheless, many feature weights in such models are inevitably poorly estimated because the number of parameters is so large with respect to the limited amount of training data. This has motivated the introduction of low-dimensional, realvalued vectors, known as embeddings, as a tool to deal with the sparseness of the input. Embeddings allow linguistic units appearing in similar contexts to share similar vectors. The success of embeddings has been observed in many NLP tasks. For CWS, Zheng et al. (2013) adapted Collobert et al. (2011) and uses character embeddings in local windows as input for a two-layer network. The network predicts individual character position tags, the transitions of which are learned separately. Mansur et al. (2013) also developed a similar architecture, which labels individual characters and uses character bigram embeddings as additional features to compensate the absence of sentence-level modeling. Pei et al. (2014) improved upon Zheng et al. (2013) by capturing the combinations of context and history via a tensor neural network. Despite their differences, these CWS"
P16-2001,C02-1093,0,0.71123,"Missing"
P16-2001,D14-1082,0,0.0401834,"adding gold topological field annotations provides a marked improvement over parsing without topological fields. Although the parser does not achieve quite the same performance with the output of the LSTM-based sequence labeler, it is still a relatively large improvement over the parser of De Kok (2015). All differences are significant at p &lt; 0.0001.5 Parsing with topological fields To evaluate the effectiveness of adding topological fields to the input, we use the publicly available neural network parser described by De Kok (2015). This parser uses an architecture that is similar to that of Chen and Manning (2014). However, it learns morphological analysis as an embedded task of parsing. Since most inflectional information that can be relevant for parsing German is available in the prefix or suffix, this parser learns morphological representations over character embeddings of prefixes and suffixes. We use the same parser configuration as that of De Kok (2015), with the addition of topological field annotations. We encode the topological fields as one-hot vectors in the input of the parser. This information is included for the four tokens on top of the stack and the next three tokens on the buffer. 5 Ac"
P16-2001,P09-1008,0,0.316036,"ve (MC) and verb-final relative (RC) clauses. Certain syntactic restrictions can be described in terms of topological fields. For instance, only a single constituent is typically allowed in the VF, while multiple constituents are allowed in the MF and the NF. Many ordering preferences can also be stated using the model. For example, in a main clause, placing the subject in the VF and the direct object in the MF is preferred over the opposite order. In parsing, topological field analysis is often seen as a task that is embedded in parsing itself. For instance, K¨ubler (2005), Maier (2006), and Cheung and Penn (2009) train PCFG parsers on 2 Motivation and corpus analysis Transition-based dependency parsers (Nivre, 2003; K¨ubler et al., 2009) typically use two transitions (LEFT ARC and RIGHT ARC) to introduce a dependency relation between the token that is on top of the processing stack and the next token on the buffer of unprocessed tokens. The decision to make an attachment, the direction of attachment, and the label of the attachment is made by a classifier. Consequently, a good classifier is tasked to learn syntactic constraints, ordering preferences, and selectional preferences. Since transition-based"
P16-2001,P06-3004,0,0.0147716,"b-second declarative (MC) and verb-final relative (RC) clauses. Certain syntactic restrictions can be described in terms of topological fields. For instance, only a single constituent is typically allowed in the VF, while multiple constituents are allowed in the MF and the NF. Many ordering preferences can also be stated using the model. For example, in a main clause, placing the subject in the VF and the direct object in the MF is preferred over the opposite order. In parsing, topological field analysis is often seen as a task that is embedded in parsing itself. For instance, K¨ubler (2005), Maier (2006), and Cheung and Penn (2009) train PCFG parsers on 2 Motivation and corpus analysis Transition-based dependency parsers (Nivre, 2003; K¨ubler et al., 2009) typically use two transitions (LEFT ARC and RIGHT ARC) to introduce a dependency relation between the token that is on top of the processing stack and the next token on the buffer of unprocessed tokens. The decision to make an attachment, the direction of attachment, and the label of the attachment is made by a classifier. Consequently, a good classifier is tasked to learn syntactic constraints, ordering preferences, and selectional prefere"
P16-2001,W03-3017,0,0.0982514,"al fields. For instance, only a single constituent is typically allowed in the VF, while multiple constituents are allowed in the MF and the NF. Many ordering preferences can also be stated using the model. For example, in a main clause, placing the subject in the VF and the direct object in the MF is preferred over the opposite order. In parsing, topological field analysis is often seen as a task that is embedded in parsing itself. For instance, K¨ubler (2005), Maier (2006), and Cheung and Penn (2009) train PCFG parsers on 2 Motivation and corpus analysis Transition-based dependency parsers (Nivre, 2003; K¨ubler et al., 2009) typically use two transitions (LEFT ARC and RIGHT ARC) to introduce a dependency relation between the token that is on top of the processing stack and the next token on the buffer of unprocessed tokens. The decision to make an attachment, the direction of attachment, and the label of the attachment is made by a classifier. Consequently, a good classifier is tasked to learn syntactic constraints, ordering preferences, and selectional preferences. Since transition-based dependency parsers process sentences in one deterministic linear-time left-to-right sweep, the classifi"
P16-2001,P15-1033,0,0.130675,"y, a good classifier is tasked to learn syntactic constraints, ordering preferences, and selectional preferences. Since transition-based dependency parsers process sentences in one deterministic linear-time left-to-right sweep, the classifier typically has little global information. One popular approach for reducing the effect of early attachment errors is to retain some competition between alternative parses using a globally optimized model with beam search (Zhang and Clark, 2008). Beam search presents a trade-off between speed (smaller beam) and higher accuracy (larger beam). More recently, Dyer et al. (2015) have proposed to use Long short-term memory networks (LSTMs) to maintain (unbounded) representations of the buffer of unprocessed words, previous parsing ac1 The abbreviations are derived from the German terms linke Klammer, rechte Klammer, Mittelfeld, Vorfeld, and Nachfeld. 1 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1–7, c Berlin, Germany, August 7-12, 2016. 2016 Association for Computational Linguistics MC: RC: VF In Tansania In Tansania LK ist is der who MF das Rad mehr the bike more f¨unfmal mehr nach Bremerhaven five-times more to Bre"
P16-2001,W02-2032,0,0.777204,"Missing"
P16-2001,W04-1911,0,0.0931527,"Missing"
Q19-1025,D15-1188,1,0.108974,"e and car and are able to express, in vector space, different types of word similarity (the similarity between color adjectives like black and purple, between car and truck, etc.). Creating phrasal representations, and in particular representing low-frequency phrases like The evaluation of existing approaches shows that state-of-the-art composition models lie at opposite ends of the spectrum. On one end, they use the same matrix transformation (Socher et al., 2010) for all words, leading to a very general composition. On the other end, there are composition models that use individual vectors (Dima, 2015) or matrices (Socher et al., 2012) for each dictionary word, leading to word-specific compositions with a multitude of parameters. Although 437 Transactions of the Association for Computational Linguistics, vol. 7, pp. 437–451, 2019. https://doi.org/10.1162/tacl a 00275. Action Editor: Sebastian Pado. Submission batch: 12/2018; Revision batch: 3/2019; Published 7/2019. c 2019 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.  2 Previous Work in Composition Models the latter perform better, they require training data for each word. These lexicalized composition"
Q19-1025,W13-3206,0,0.320849,"to model phrases. Because of the productivity of phrase construction, only a small fraction of all grammatically correct phrases will actually occur in corpora. Composition models attempt to solve this problem through a bottom–up approach, where a phrase representation is constructed from its parts. Composition models have succeeded in building representations for English adjectivenoun phrases like red car (Baroni and Zamparelli, 2010), nominal compounds in English (telephone number; Mitchell and Lapata, 2010) and German (Apfelbaum ‘apple tree’; Dima, 2015), determiner phrases like no memory (Dinu et al., 2013), and for modeling derivational morphology in English (e.g., re-+build→rebuild; Lazaridou et al., 2013) and German (e.g., taub ‘deaf’+-heit → Taubheit ‘deafness’; Pad´o et al., 2016). In this section, we discuss several composition models from the literature, summarized in Table 1. They range from simple additive models to multilayered word-specific models. In our descriptions, the inputs to the composition functions are two vectors, u, v ∈ Rn , where n is the dimensionality of the word representation. u and v are the representations of the first and second element of the phrase and are fixed"
Q19-1025,W97-0802,0,0.811332,"order to extract both real adverbs (e.g., Dutch: zeer giftig ‘very poisonous’) and adjectives which function as an adverb (e.g., Dutch: buitensporig groot ‘exceptionally large’). To be able to learn phrase representations in word2vec’s training regime (Section 4.3), we additionally require that the dependent immediately precedes the head. Similarly to adjective-noun phrases, the representations of adverbs and adjectives are consequently based on the remaining occurrences. Compounds For German, we use the data set introduced by Dima (2015), which was extracted from the German WordNet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2011). Dutch noun-noun compounds were extracted from the Celex lexicon (Baayen et al., 1993). The English compounds come from the Tratz (2011) data set and from the English WordNet (Fellbaum, 1998) (the data.noun entries with two constituents separated by dash or underscore). 4.3 Training For each phrase type, each target representation ˜ was trained jointly with the representations of p the constituent words u and v using word2vec (Mikolov et al., 2013) and the hyperparameters in Appendix 6. For phrases where words are separated by a space (adjective-noun phrases, adve"
Q19-1025,D10-1115,0,0.831811,"hat word representations can be trained on large, unannotated corpora using unsupervised techniques based on word co-occurrences. However, the same modeling paradigm cannot be readily used to model phrases. Because of the productivity of phrase construction, only a small fraction of all grammatically correct phrases will actually occur in corpora. Composition models attempt to solve this problem through a bottom–up approach, where a phrase representation is constructed from its parts. Composition models have succeeded in building representations for English adjectivenoun phrases like red car (Baroni and Zamparelli, 2010), nominal compounds in English (telephone number; Mitchell and Lapata, 2010) and German (Apfelbaum ‘apple tree’; Dima, 2015), determiner phrases like no memory (Dinu et al., 2013), and for modeling derivational morphology in English (e.g., re-+build→rebuild; Lazaridou et al., 2013) and German (e.g., taub ‘deaf’+-heit → Taubheit ‘deafness’; Pad´o et al., 2016). In this section, we discuss several composition models from the literature, summarized in Table 1. They range from simple additive models to multilayered word-specific models. In our descriptions, the inputs to the composition functions"
Q19-1025,P13-1088,0,0.0216956,"ons. 6 Conclusion In this paper we have introduced TransWeight, a new composition model that uses a set of weighted transformations, as a middle ground between a fully lexicalized model and models based on a single transformation. TransWeight outperforms all other models in our experiments. In this work, we have trained TransWeight for specific phrase types. In the future, we would like to investigate whether a single TransWeight model can be used to perform composition of different phrase types, possibly while integrating information about the structure of the phrases and their context as in Hermann and Blunsom (2013), Yu et al. (2014), and Yu and Dredze (2015). Another extension that we are interested in is to use TransWeight to compose more than two words. We plan to follow the lead of Socher et al. (2012) here, who use the FullLex composition function in a recursive neural network to compose an arbitrary number of words. Similarly, we could The training hyperparameters are unchanged. 448 use TransWeight in a recursive neural network in order to compose more than two words. In our experiments, 100 transformations yielded optimal results for all phrase sets. However, further investigation is needed to det"
Q19-1025,schafer-bildhauer-2012-building,0,0.0683371,"Missing"
Q19-1025,2005.mtsummit-papers.11,0,0.0164644,"; v]) n  t    Wc,i,j (T[u; v])j,i pc = i=1 j =1 n  t   Wc,i,j 2n  i=1 j =1 Tj,i,k [u; v]k k=1 (4) Wc,∗,∗ is a matrix of component-specific weightings of the transformed representations T[u; v]. We replace T by a component-specific transformation tensor Tc = Wc,∗,∗  T: pc = 2n n  t   German We use three sections of the T¨uBaD/DP treebank (de Kok and P¨utz, 2019) to train lemma and phrase representations for German: (1) articles from the German newspaper taz from 1986 to 2009; (2) the German Wikipedia dump of January 20, 2018; and (3) the German proceedings from the EuroParl corpus (Koehn, 2005; Tiedemann, 2012). Together, these sections contain 64.9M sentences and 1.3B tokens. Tcj,i,k [u; v]k i=1 j =1 k=1 = c n  t    Tcj,i · [u; v] (5) i=1 j =1 c If t = i j Tj,i , then it follows from the distributive property of the dot product that pc = tc · [u; v]. Without a non-linearity, the transformation weighting model thus reduces to the Matrix model. This does not hold for the transformation with the non-linearity—because αg (a) = g (αa) for a non-linearity g , we cannot precompute a component-specific transformation matrix Tc . Dutch Lemma and phrase representations for Dutch were tr"
Q19-1025,P13-1149,0,0.0182348,"grammatically correct phrases will actually occur in corpora. Composition models attempt to solve this problem through a bottom–up approach, where a phrase representation is constructed from its parts. Composition models have succeeded in building representations for English adjectivenoun phrases like red car (Baroni and Zamparelli, 2010), nominal compounds in English (telephone number; Mitchell and Lapata, 2010) and German (Apfelbaum ‘apple tree’; Dima, 2015), determiner phrases like no memory (Dinu et al., 2013), and for modeling derivational morphology in English (e.g., re-+build→rebuild; Lazaridou et al., 2013) and German (e.g., taub ‘deaf’+-heit → Taubheit ‘deafness’; Pad´o et al., 2016). In this section, we discuss several composition models from the literature, summarized in Table 1. They range from simple additive models to multilayered word-specific models. In our descriptions, the inputs to the composition functions are two vectors, u, v ∈ Rn , where n is the dimensionality of the word representation. u and v are the representations of the first and second element of the phrase and are fixed during the training process. In this work, the composed representation has the same dimensionality as t"
Q19-1025,D12-1110,0,0.120836,"Missing"
Q19-1025,D13-1170,0,0.00747194,"r A ∈ R|V |×n×n , where |V |is the vocabulary size. u and v are transformed crosswise using the transformation matrices Au , Av ∈ Rn×n . The transformed representations Av u and Au v are then the input of the Matrix model. Every matrix Aw in the FullLex model is initialized using the identity matrix I with some small perturbations. Because Iu = u, the FullLex model starts as an approximation of the Matrix model. The matrices of the words that occur in the training data are updated during parameter estimation to better predict phrase representations. BiLinear The BiLinear model was proposed by Socher et al. (2013a,b) as an alternative to the FullLex model. This model allows for stronger interactions between word representations than the Matrix model. At the same time, BiLinear has fewer parameters than FullLex, because it avoids per-word matrices. Socher et al.’s (2013a,b) goal is to build a model that is better able to generalize over different inputs. The core of the bilinear composition model is a tensor E ∈ Rn×d×n that stores d bilinear forms. Each of the bilinear forms is multiplied by u and v (u Ev) to form a composed vector of dimensionality d. Because the size of the phrase representation is"
Q19-1025,C16-1122,0,0.0316276,"Missing"
Q19-1025,tiedemann-2012-parallel,0,0.0145177,"Wc,i,j (T[u; v])j,i pc = i=1 j =1 n  t   Wc,i,j 2n  i=1 j =1 Tj,i,k [u; v]k k=1 (4) Wc,∗,∗ is a matrix of component-specific weightings of the transformed representations T[u; v]. We replace T by a component-specific transformation tensor Tc = Wc,∗,∗  T: pc = 2n n  t   German We use three sections of the T¨uBaD/DP treebank (de Kok and P¨utz, 2019) to train lemma and phrase representations for German: (1) articles from the German newspaper taz from 1986 to 2009; (2) the German Wikipedia dump of January 20, 2018; and (3) the German proceedings from the EuroParl corpus (Koehn, 2005; Tiedemann, 2012). Together, these sections contain 64.9M sentences and 1.3B tokens. Tcj,i,k [u; v]k i=1 j =1 k=1 = c n  t    Tcj,i · [u; v] (5) i=1 j =1 c If t = i j Tj,i , then it follows from the distributive property of the dot product that pc = tc · [u; v]. Without a non-linearity, the transformation weighting model thus reduces to the Matrix model. This does not hold for the transformation with the non-linearity—because αg (a) = g (αa) for a non-linearity g , we cannot precompute a component-specific transformation matrix Tc . Dutch Lemma and phrase representations for Dutch were trained on the Lassy"
Q19-1025,Q15-1017,0,0.0196828,"TransWeight, a new composition model that uses a set of weighted transformations, as a middle ground between a fully lexicalized model and models based on a single transformation. TransWeight outperforms all other models in our experiments. In this work, we have trained TransWeight for specific phrase types. In the future, we would like to investigate whether a single TransWeight model can be used to perform composition of different phrase types, possibly while integrating information about the structure of the phrases and their context as in Hermann and Blunsom (2013), Yu et al. (2014), and Yu and Dredze (2015). Another extension that we are interested in is to use TransWeight to compose more than two words. We plan to follow the lead of Socher et al. (2012) here, who use the FullLex composition function in a recursive neural network to compose an arbitrary number of words. Similarly, we could The training hyperparameters are unchanged. 448 use TransWeight in a recursive neural network in order to compose more than two words. In our experiments, 100 transformations yielded optimal results for all phrase sets. However, further investigation is needed to determine whether this number is optimal for an"
Q19-1025,D14-1162,0,\N,Missing
Q19-1025,R11-1058,1,\N,Missing
R11-1057,W04-3224,0,0.106227,"nded QA system is English, the simplest solution would be to use a statistical parser such as the Berkeley (Petrov and Klein, 2007) or Stanford (Klein and Manning, 2003) parser with an existing language model obtained from the Penn Treebank (Marcus et al., 1993). However, it is well known that parser performance drops when analyzing text from domains other than that represented in the training data (Sekine, 1997; Gildea, 2001). In particular, Judge et al. (2006) have shown that language models obtained from the Penn Treebank perform far worse on questions than on their original test data. The Bikel (2004) parser they employ has an F-Score of 82.97 when tested on Section 23 of the Penn-II Treebank and an F-Score of 78.77 when tested on the 4000 questions in QuestionBank. Judge et al. (2006) attribute this loss of perIn this paper we present the development process of NLP-QT, a question treebank that will be used for data-driven parsing in the context of a domain-specific QA system for querying NLP resource metadata. We motivate the need to build NLP-QT as a resource in its own right, by comparing the Penn Treebank-style annotation scheme used for QuestionBank (Judge et al., 2006) with the modif"
R11-1057,W01-0521,0,0.0346128,"h hand-crafted grammar rules, it employs a robust data-driven parser that requires annotated training data in the form of a treebank. Since the natural language front end for the intended QA system is English, the simplest solution would be to use a statistical parser such as the Berkeley (Petrov and Klein, 2007) or Stanford (Klein and Manning, 2003) parser with an existing language model obtained from the Penn Treebank (Marcus et al., 1993). However, it is well known that parser performance drops when analyzing text from domains other than that represented in the training data (Sekine, 1997; Gildea, 2001). In particular, Judge et al. (2006) have shown that language models obtained from the Penn Treebank perform far worse on questions than on their original test data. The Bikel (2004) parser they employ has an F-Score of 82.97 when tested on Section 23 of the Penn-II Treebank and an F-Score of 78.77 when tested on the 4000 questions in QuestionBank. Judge et al. (2006) attribute this loss of perIn this paper we present the development process of NLP-QT, a question treebank that will be used for data-driven parsing in the context of a domain-specific QA system for querying NLP resource metadata."
R11-1057,W01-0710,0,0.825234,"Missing"
R11-1057,P03-1054,0,0.00601397,"he tradition of the earlier, domain-specific QA systems in that it aims to provide a natural language front-end to large repositories of metadata about language tools and resources that are made available by the CLARIN1 project. However, instead of relying on a parser with hand-crafted grammar rules, it employs a robust data-driven parser that requires annotated training data in the form of a treebank. Since the natural language front end for the intended QA system is English, the simplest solution would be to use a statistical parser such as the Berkeley (Petrov and Klein, 2007) or Stanford (Klein and Manning, 2003) parser with an existing language model obtained from the Penn Treebank (Marcus et al., 1993). However, it is well known that parser performance drops when analyzing text from domains other than that represented in the training data (Sekine, 1997; Gildea, 2001). In particular, Judge et al. (2006) have shown that language models obtained from the Penn Treebank perform far worse on questions than on their original test data. The Bikel (2004) parser they employ has an F-Score of 82.97 when tested on Section 23 of the Penn-II Treebank and an F-Score of 78.77 when tested on the 4000 questions in Qu"
R11-1057,P07-1031,0,0.225838,"d on Section 23 of the Penn-II Treebank and an F-Score of 78.77 when tested on the 4000 questions in QuestionBank. Judge et al. (2006) attribute this loss of perIn this paper we present the development process of NLP-QT, a question treebank that will be used for data-driven parsing in the context of a domain-specific QA system for querying NLP resource metadata. We motivate the need to build NLP-QT as a resource in its own right, by comparing the Penn Treebank-style annotation scheme used for QuestionBank (Judge et al., 2006) with the modified NP annotation for the Penn Treebank introduced by Vadas and Curran (2007). We argue that this modified annotation scheme provides a better interface representation for semantic interpretation and show how it can be incorporated into the NLP-QT resource, without significant loss in parser performance. The parsing experiments reported in the paper confirm the feasibility of an iterative, semi-automatic construction of the NLP-QT resource similar to the approach taken for QuestionBank. At the same time, we propose to improve the iterative refinement technique used for QuestionBank by adopting Hwa (2001)’s heuristics for selecting additional material to be handcorrecte"
R11-1057,J93-2004,0,0.0369974,"uage front-end to large repositories of metadata about language tools and resources that are made available by the CLARIN1 project. However, instead of relying on a parser with hand-crafted grammar rules, it employs a robust data-driven parser that requires annotated training data in the form of a treebank. Since the natural language front end for the intended QA system is English, the simplest solution would be to use a statistical parser such as the Berkeley (Petrov and Klein, 2007) or Stanford (Klein and Manning, 2003) parser with an existing language model obtained from the Penn Treebank (Marcus et al., 1993). However, it is well known that parser performance drops when analyzing text from domains other than that represented in the training data (Sekine, 1997; Gildea, 2001). In particular, Judge et al. (2006) have shown that language models obtained from the Penn Treebank perform far worse on questions than on their original test data. The Bikel (2004) parser they employ has an F-Score of 82.97 when tested on Section 23 of the Penn-II Treebank and an F-Score of 78.77 when tested on the 4000 questions in QuestionBank. Judge et al. (2006) attribute this loss of perIn this paper we present the develo"
R11-1057,N07-1051,0,0.019163,"ted in the present paper is more in the tradition of the earlier, domain-specific QA systems in that it aims to provide a natural language front-end to large repositories of metadata about language tools and resources that are made available by the CLARIN1 project. However, instead of relying on a parser with hand-crafted grammar rules, it employs a robust data-driven parser that requires annotated training data in the form of a treebank. Since the natural language front end for the intended QA system is English, the simplest solution would be to use a statistical parser such as the Berkeley (Petrov and Klein, 2007) or Stanford (Klein and Manning, 2003) parser with an existing language model obtained from the Penn Treebank (Marcus et al., 1993). However, it is well known that parser performance drops when analyzing text from domains other than that represented in the training data (Sekine, 1997; Gildea, 2001). In particular, Judge et al. (2006) have shown that language models obtained from the Penn Treebank perform far worse on questions than on their original test data. The Bikel (2004) parser they employ has an F-Score of 82.97 when tested on Section 23 of the Penn-II Treebank and an F-Score of 78.77 w"
R11-1057,A97-1015,0,\N,Missing
R11-1057,P06-1063,0,\N,Missing
R11-1058,W02-1004,0,0.0118948,"splitter is further processed in order to better fit the needs of the present project. To enhance the reliability of the determined constituents, the enhanced compound splitter ASV-CS searches for entries in GermaNet. If a result consists of more than two constituents, the different bracketing alternatives need to be verified. This is done by incorporating GermaNet’s graph structure in the same way as for GN-CS (see section 5.1). 6 Combination of Compound Splitters It has been shown for various NLP tasks, such as part-of-speech tagging (van Halteren et al., 2001) or word sense disambiguation (Florian and Yarowsky, 2002), that multiple classifier systems outperform single decision systems. Further, the performance of such methods is usually better the more diverse the individual systems are (Polikar, 2006). Thus, having three classifiers7 (compound splitters) available that produce diverse results, the application of a combined method seems reasonable. As the compound splitters in the present project each return exactly one decision, the range of applicable combination algorithms is restricted. In the following subsection, the application of majority voting and weighted majority voting is described. Further,"
R11-1058,schmid-etal-2004-smor,0,0.231498,"onstituents of this compound are Kraftfahrzeug and steuer, with the first constituent then splitting further into Kraft and fahrzeug, etc. (see Figure 1). In order to be able to systematically link compounds in GermaNet to their constituent parts, compound splitting needs to be applied recursively and has to identify only the immediate constituents at each level of analysis. Figure 1. Compounds in GermaNet. 4 Related Work on Compound Splitting For German, there are a number of morphological tools available that include compound splitting, such as GERTWOL (Haapalainen and Majorin, 1994), SMOR (Schmid et al., 2004), ASV Toolbox (Witschel and Biemann, 2005), BananaSplit 3 , and Morfessor (Creutz and Lagus, 2005). After an initial evaluation of all publicly available tools, SMOR and ASV Toolbox are used as baseline tools for the present project. 3 421 See http://niels.drni.de/s9y/pages/bananasplit.html SMOR is a morphological analyzer for German inﬂection and productive word formation including composition, which has been developed at the University of Stuttgart. It provides analyses consisting of sequences of morphemes enriched with morphological information, however without grouping them into immediate"
R11-1058,J01-2002,0,0.0842217,"Missing"
R11-1058,kunze-lemnitzer-2002-germanet,0,\N,Missing
telljohann-etal-2004-tuba,W98-1207,0,\N,Missing
telljohann-etal-2004-tuba,C02-1131,0,\N,Missing
W05-0303,J00-4005,0,0.287918,"Missing"
W05-0303,P89-1032,0,0.135142,"annot be anaphorically related to the object NP Ihre Schulkameradin Cassie Bernall since they are coarguments of the same verb. However, the possessive pronoun ihre and the subject pronoun sie of the subordinate clause, can be and, in fact, are anaphorically related, since they are not co-arguments of the same verb. This can be directly inferred from the treebank annotation, specifically from the sentence structure and the grammatical function information encoded on the edge labels. Most published computational algorithms of anaphora resolution, including (Hobbs, 1978; Lappin and Leass, 1994; Ingria and Stallard, 1989), rely on such binding-constraint filters to minimize the set of potential antecedents for pronouns and reflexives. As already pointed out, the sample sentence contains four markables: one possessive pronoun Ihre, two occurrences of the pronoun sie and one complex NP Ihre Schulkameradin Cassie Bernall. The latter NP is a good example of SYN-RA’s longest-match principle for identifying markables. In case of complex NPs, the entire NP counts as a markable, but so do its subconstituents – in the case at hand, particularly the possessive pronoun ihre. All of this information can be directly derive"
W05-0303,J94-4002,0,0.0249672,"the main clause, sie, cannot be anaphorically related to the object NP Ihre Schulkameradin Cassie Bernall since they are coarguments of the same verb. However, the possessive pronoun ihre and the subject pronoun sie of the subordinate clause, can be and, in fact, are anaphorically related, since they are not co-arguments of the same verb. This can be directly inferred from the treebank annotation, specifically from the sentence structure and the grammatical function information encoded on the edge labels. Most published computational algorithms of anaphora resolution, including (Hobbs, 1978; Lappin and Leass, 1994; Ingria and Stallard, 1989), rely on such binding-constraint filters to minimize the set of potential antecedents for pronouns and reflexives. As already pointed out, the sample sentence contains four markables: one possessive pronoun Ihre, two occurrences of the pronoun sie and one complex NP Ihre Schulkameradin Cassie Bernall. The latter NP is a good example of SYN-RA’s longest-match principle for identifying markables. In case of complex NPs, the entire NP counts as a markable, but so do its subconstituents – in the case at hand, particularly the possessive pronoun ihre. All of this inform"
W05-0303,W03-2117,0,0.162936,"es and anaphoric uses with an NP antecedent, the pronoun es can also be used in cases of event anaphora as in sentence (9). Here es refers to the event of Jochen’s winning the lottery. Currently, the annotation in SYNRA is restricted to NP anaphora and therefore event anaphors such as in sentence (9) remain unannotated for anaphora. (9) Jochen hat im Lotto gewonnen. Aber er Jochen has in the lottery won. But he weiss es noch nicht. knows it yet not. ’Jochen has won the lottery. But he does not know it yet.’ The annotation of such relations is performed manually with the annotation tool MMAX (Müller and Strube, 2003). Its graphical user interface allows for easy selection of the relevant markables and the accompanying relation between the contextually dependent expression and its antecedent. 15 3 Automatic Extraction of Markables and of Semantic Information Annotation of referential relations involves two main tasks: the identification of markables, i.e., identifying the class of expressions that can enter into referential relations, and the identification of the particular referential relations that two or more expressions enter into. Identification of markables requires at least partial syntactic annota"
W05-0303,W99-0309,0,0.0309254,"tion 1 See e.g. nlp.cs.nyu.edu/meyers/pie-in-the-sky/ analysis5. This section introduces the inventory of referential relations adopted in the SYN-RA project. We define referential relations as a cover-term for all contextually dependent reference relations. The inventory of such relations adopted for SYN-RA is inspired by the annotation scheme first developed in the MATE project (Davies et al., 1998). However, it takes a cautious approach in that it only adopts those referential relations from MATE for which the developers of MATE report a sufficiently high level of interannotator agreement (Poesio et al., 1999). SYN-RA currently uses the following subset of relations: coreferential, anaphoric, cataphoric, bound, split antecedent, instance, and expletive. The potential markables are definite NPs, personal pronouns, relative, reflexive, and reciprocal pronouns, demonstrative, indefinite and possessive pronouns. There is a second research effort under way at the European Media Laboratory Heidelberg, which also annotates German text corpora and dialog data with referential relations. Since their corpora are not publicly available, it is difficult to verify their inventory of referential relations. Kouch"
W05-0303,P04-2010,0,\N,Missing
W06-1101,E95-1009,0,0.0392376,"aver, the author of the most widely used textbook in phonetics, claimed that “one of the 1 Proceedings of the Workshop on Linguistic Distances, pages 1–6, c Sydney, July 2006. 2006 Association for Computational Linguistics tions of sequence similarity and/or, e.g., the idea that distance may be operationalized by the number or replacements needed to derive one word from another—ignoring the problem of similarity among words of different lengths (Vitevitch and Luce, 1999). Perhaps more sophisticated computational models of pronunciation distance could play a role in these models in the future. Kessler (1995) showed how to employ edit distance to operationalize pronunciation difference in order to investigate dialectology more precisely, an idea which, particular, Heeringa (2004) pursued at great length. Kondrak (2002) created a variant of the dynamic programming algorithm used to compute edit distance which he used to identify cognates in historical linguistics. McMahon & McMahon (2005) include investigations of pronunciation similarity in their recent book on phylogenetic techniques in historical linguistics. Several of the contributions to this volume build on these earlier efforts or are relev"
W06-1101,P98-1013,0,0.0129796,"8), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al. (1999) and by Wagner (2004). A third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses. This type of approach has led to two highly valued semantic resources: the Princeton WordNet (Fellbaum, 1998) and the Berkeley Framenet (Baker et al., 1998). While originally developed for English, both approaches have been successfully generalized to other languages. The three approaches to word meaning discussed above try to capture different aspects of the notion of semantic similarity, all of which are highly relevant for current and future research in computational linguistics. In fact, the five papers that discuss issues of semantic similarity in the present volume build on insights from these three frameworks or address open research questions posed by these frameworks. Zesch and Gurevych (this volume) discuss how measures of semantic simi"
W06-1101,J90-1003,0,0.0155589,"detection as well as for sentence selection in question-answering tasks than simple word-overlap metrics. Hachey considers an automatic content extraction (ACE) task, a particular subtask of information extraction. He demonstrates that representations based on term cooccurrence outperform representations based on term-by-document matrices for the task of identifying relationships between named objects in texts. linguist J.R. Firth: “You shall know a word by the company it keeps.” (Firth, 1957, p. 11) Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks (1990) and by Dunning (1993), of identifying word senses, e.g. by Yarowski (1995) and by Sch¨utze (1998), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al. (1999) and by Wagner (2004). A third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses. This type of approach has led to two high"
W06-1101,J93-1003,0,0.0323236,"tence selection in question-answering tasks than simple word-overlap metrics. Hachey considers an automatic content extraction (ACE) task, a particular subtask of information extraction. He demonstrates that representations based on term cooccurrence outperform representations based on term-by-document matrices for the task of identifying relationships between named objects in texts. linguist J.R. Firth: “You shall know a word by the company it keeps.” (Firth, 1957, p. 11) Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks (1990) and by Dunning (1993), of identifying word senses, e.g. by Yarowski (1995) and by Sch¨utze (1998), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al. (1999) and by Wagner (2004). A third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses. This type of approach has led to two highly valued semantic res"
W06-1101,P99-1014,0,0.0211732,"outperform representations based on term-by-document matrices for the task of identifying relationships between named objects in texts. linguist J.R. Firth: “You shall know a word by the company it keeps.” (Firth, 1957, p. 11) Context similarity has been used as a means of extracting collocations from corpora, e.g. by Church & Hanks (1990) and by Dunning (1993), of identifying word senses, e.g. by Yarowski (1995) and by Sch¨utze (1998), of clustering verb classes, e.g. by Schulte im Walde (2003), and of inducing selectional restrictions of verbs, e.g. by Resnik (1993), by Abe & Li (1996), by Rooth et al. (1999) and by Wagner (2004). A third approach to lexical semantics, developed by linguists and by cognitive psychologists, primarily relies on the intuition of lexicographers for capturing word meanings, but is also informed by corpus evidence for determining word usage and word senses. This type of approach has led to two highly valued semantic resources: the Princeton WordNet (Fellbaum, 1998) and the Berkeley Framenet (Baker et al., 1998). While originally developed for English, both approaches have been successfully generalized to other languages. The three approaches to word meaning discussed ab"
W06-1101,J98-1004,0,0.102849,"Missing"
W06-1101,P95-1026,0,0.039919,"Missing"
W06-1101,J06-2001,0,\N,Missing
W06-1101,C98-1013,0,\N,Missing
W06-1614,A97-1014,0,\N,Missing
W06-1614,J06-2001,0,\N,Missing
W06-1614,J03-4003,0,\N,Missing
W06-1614,P03-1054,0,\N,Missing
W06-1614,P03-1014,0,\N,Missing
W06-1614,P06-3004,1,\N,Missing
W06-1614,C04-1056,0,\N,Missing
W06-1614,P03-1056,0,\N,Missing
W06-1614,P05-1039,0,\N,Missing
W06-1614,P03-1013,0,\N,Missing
W10-1821,kermes-evert-2002-yac,0,0.0352578,"he CoNLL shared task definition of chunks is 147 Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 147–151, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics Figure 1: Treebank annotation for the sentence in (2). useful for machine learning based approaches to chunking since it only requires one level of analysis, which can be represented as IOB-chunking (Tjong Kim Sang and Buchholz, 2000). For English, this definition of chunks has become standard in the literature on machine learning. For German, chunk parsing has been investigated by Kermes and Evert (2002) and by M¨uller (2004). Both approaches used an Abney-style chunk definition. However, there is no corresponding flat chunk representation for German because of the complexity of pre-head modification in German noun phrases. Sentence (1) provides a typical example of this kind. (1) [N C der [N C seinen Sohn] liebende Vater] the his son loving father ‘the father who loves his son’ The structure in (1) violates both the Abneystyle and the CoNLL-style definitions of chunks – Abney’s because it is recursive and the CoNLLstyle definition because of the embedding. A single-level, CoNLL-style chunk a"
W10-1821,W09-3820,0,0.0172775,"t for approaches that require an efficient analysis but not necessarily a complete syntactic analysis. German allows a higher degree of syntactic complexity in prenominal modification of the syntactic head of an NP compared to English. This is particularly evident in written texts annotated in the T¨uBa-D/Z. The complexity of German NPs that causes problems in the conversion to CoNLL-style chunks also affects PCFG parsing approaches to German.The complexity of NPs is one of the phenomena that have been addressed in tree transformation approaches for German parsing (Trushkina, 2004; Ule, 2007; Versley and Rehbein, 2009). The notion of a chunk is orginally due to Abney (1991), who considers chunks as non-recursive phrases which span from the left periphery of a phrase to the phrasal head. Accordingly, the sentence “The woman in the lab coat thought you had bought an expensive book.” is assigned the chunk structure: “[S [NP The woman] [PP in [NP the lab coat] ] [VP thought] ] [S [NP you] [VP had bought] [NP an [ADJP expensive] book]] .”. Abney-style chunk parsing is implemented as cascaded, finite-state transduction (cf. (Abney, 1996; Karlsson et al., 1995)). Notice that cascaded, finite-state transduction all"
W10-1821,C04-1039,0,0.0388403,"Missing"
W10-1821,W95-0107,0,0.0701576,"er is to investigate how the annotation of noun phrases in the T¨ubingen Treebank of Written German (T¨uBa-D/Z) can be transformed into chunks with no internal structure, as proposed in the CoNLL 2000 shared task (Tjong Kim Sang and Buchholz, 2000). Chunk parsing is a form of partial parsing, in which non-recursive phrases are annotated while difficult decisions, such as prepositional phrase attachment, are left unsolved. Flat chunk representations are particularly suitable for machine learning approaches to partial parsing and are inspired by the IOB approach to NP chunking first proposed by Ramshaw and Marcus (1995). They are particularly relevant for approaches that require an efficient analysis but not necessarily a complete syntactic analysis. German allows a higher degree of syntactic complexity in prenominal modification of the syntactic head of an NP compared to English. This is particularly evident in written texts annotated in the T¨uBa-D/Z. The complexity of German NPs that causes problems in the conversion to CoNLL-style chunks also affects PCFG parsing approaches to German.The complexity of NPs is one of the phenomena that have been addressed in tree transformation approaches for German parsin"
W10-1821,telljohann-etal-2004-tuba,1,0.876416,"Missing"
W10-1821,W00-0726,0,0.818297,"unk representation for the T¨ubingen Treebank of Written German, which assumes a flat chunk structure so that each word belongs to at most one chunk. For German, such a chunk definition causes problems in cases of complex prenominal modification. We introduce a flat annotation that can handle these structures via a stranded noun chunk. 1 Introduction The purpose of this paper is to investigate how the annotation of noun phrases in the T¨ubingen Treebank of Written German (T¨uBa-D/Z) can be transformed into chunks with no internal structure, as proposed in the CoNLL 2000 shared task (Tjong Kim Sang and Buchholz, 2000). Chunk parsing is a form of partial parsing, in which non-recursive phrases are annotated while difficult decisions, such as prepositional phrase attachment, are left unsolved. Flat chunk representations are particularly suitable for machine learning approaches to partial parsing and are inspired by the IOB approach to NP chunking first proposed by Ramshaw and Marcus (1995). They are particularly relevant for approaches that require an efficient analysis but not necessarily a complete syntactic analysis. German allows a higher degree of syntactic complexity in prenominal modification of the s"
W12-3624,P07-1086,0,0.445015,"n allows the retrieval of a considerable number of coordinate structures beyond the ones having a coordinating conjunction. 1 1.1 Introduction Motivation Coordination is a difficult topic, in terms of linguistic description and analysis as well as for NLP approaches. Most linguistic frameworks still struggle with finding an account for coordination that is descriptively fully adequate (Hartmann, 2000). This is also the reason why coordination is not adequately encoded in the annotation of major treebanks. From an NLP perspective, coordination is one of the major sources for errors in parsing (Hogan, 2007). If parsing of coordinate structures can be improved, overall parsing quality also benefits (K¨ubler et al., 2009). 166 And consequently, downstream NLP applications, such as question answering or machine translation, would benefit as well. However, since linguistic frameworks in general are challenged by the diverse phenomena of coordination, a consistent annotation of coordinate structures, clearly marking the phenomenon as such as well as its scope, is a difficult enterprise. Consequently, this makes the detection of conjuncts and their boundaries a highly non-trivial task. Nevertheless, a"
W12-3624,E09-1047,1,0.936618,"Missing"
W12-3624,H05-1105,0,0.0143213,"1 shows an example sentence with two coordinate structures, the inside one a coordinate noun phrase (NP) with 3 conjuncts, and the outside one a coordinate verb phrase (VP) with two complex conjuncts. These coordinate structures are labeled by ordinary phrasal categories such as VP and NP and can thus not be distinguished at the phrasal level from VPs and NP that do not involve coordination. There are approaches to improving parsing for coordinations, but most of these approaches are restricted to very narrow definitions such as coordinations of noun compounds such as “oil and gas resources” (Nakov and Hearst, 2005), coordinations of symmetrical NPs (Hogan, 2007; Shimbo and Hara, 2007), or coordinations of “A CC B” where A and B are conjuncts, and CC is an overt conjunction (K¨ubler et al., 2009). To our knowledge, there is no attempt at covering all coordination types. One goal of this paper is to demonstrate a wide range of coordination phenomena that have to be taken into account in a thorough treatment of coordinations. We additionally present a proposal for an enhanced annotation of coordination for the Penn Treebank. The annotation is focused on punctuation and allows for an in-depth investigation"
W12-3624,D07-1064,0,0.262261,"ne a coordinate noun phrase (NP) with 3 conjuncts, and the outside one a coordinate verb phrase (VP) with two complex conjuncts. These coordinate structures are labeled by ordinary phrasal categories such as VP and NP and can thus not be distinguished at the phrasal level from VPs and NP that do not involve coordination. There are approaches to improving parsing for coordinations, but most of these approaches are restricted to very narrow definitions such as coordinations of noun compounds such as “oil and gas resources” (Nakov and Hearst, 2005), coordinations of symmetrical NPs (Hogan, 2007; Shimbo and Hara, 2007), or coordinations of “A CC B” where A and B are conjuncts, and CC is an overt conjunction (K¨ubler et al., 2009). To our knowledge, there is no attempt at covering all coordination types. One goal of this paper is to demonstrate a wide range of coordination phenomena that have to be taken into account in a thorough treatment of coordinations. We additionally present a proposal for an enhanced annotation of coordination for the Penn Treebank. The annotation is focused on punctuation and allows for an in-depth investigation of coordinations, for example for linguistic treatments, but also for w"
W12-3624,telljohann-etal-2004-tuba,1,0.831414,"Missing"
W12-3624,J93-2004,0,\N,Missing
W14-0107,W97-0802,0,0.754429,"aNet Christina Hoppermann Department of Linguistics University of Tübingen, Germany christina.hoppermann@unituebingen.de Abstract Verbal word formation processes involving prefixes and particles are highly productive in Germanic languages. The compositional semantics of such prefix and particle verbs requires an in-depth analysis of the interdependence of their constituent parts for adequately representing these types of complex verbs in lexical-semantic networks. The present paper introduces modeling principles that account for such language-specific phenomena in the German wordnet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010), considering the continuum between full semantic transparency and highly lexicalized meanings as well as the semantic contribution of the prefix or particle to the meaning of the complex verb as a whole. 1 Erhard Hinrichs Department of Linguistics University of Tübingen, Germany erhard.hinrichs@unituebingen.de constituent depending on the clause type2 that the particle verb appears in. The host constituent of a prefix or particle verb can either be a simplex (or: base verb) as in the examples above or a nominal or adjectival base as in bedachen ‘put on a roof’ or"
W14-0107,henrich-hinrichs-2010-gernedit,1,0.844238,"n Department of Linguistics University of Tübingen, Germany christina.hoppermann@unituebingen.de Abstract Verbal word formation processes involving prefixes and particles are highly productive in Germanic languages. The compositional semantics of such prefix and particle verbs requires an in-depth analysis of the interdependence of their constituent parts for adequately representing these types of complex verbs in lexical-semantic networks. The present paper introduces modeling principles that account for such language-specific phenomena in the German wordnet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010), considering the continuum between full semantic transparency and highly lexicalized meanings as well as the semantic contribution of the prefix or particle to the meaning of the complex verb as a whole. 1 Erhard Hinrichs Department of Linguistics University of Tübingen, Germany erhard.hinrichs@unituebingen.de constituent depending on the clause type2 that the particle verb appears in. The host constituent of a prefix or particle verb can either be a simplex (or: base verb) as in the examples above or a nominal or adjectival base as in bedachen ‘put on a roof’ or erblassen ‘grow pale’. A syst"
W14-0109,W97-0802,0,0.0738495,"ce has undertaken considerable efforts to find external knowledge sources that can aid in distinguishing and identifying word senses. The external knowledge sources that are most widely used for this purpose are very large electronic corpora that can be harvested for a given word under lexicographic consideration. Another type of resource that has also been explored as an external reference point is the comparison with another semantic dictionary that has been constructed independently for the same language. The present paper reports on an ongoing project in which the German wordnet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) is compared to the word senses contained in the Digital Dictionary of the German Language (Digitales Wörterbuch der Deutschen Sprache 1 , DWDS; Klein and Geyken, 2010). Both resources are long-term lexicographic projects aiming at a comprehensive coverage of contemporary standard German in electronic form. What makes a comparison between these resources particularly interesting and useful is the fact that they utilize two different methods for constructing word meanings. The DWDS is based on the digital versions of three pre-existing dictionaries: the Dictionary o"
W14-0109,henrich-hinrichs-2010-gernedit,1,0.836132,"erable efforts to find external knowledge sources that can aid in distinguishing and identifying word senses. The external knowledge sources that are most widely used for this purpose are very large electronic corpora that can be harvested for a given word under lexicographic consideration. Another type of resource that has also been explored as an external reference point is the comparison with another semantic dictionary that has been constructed independently for the same language. The present paper reports on an ongoing project in which the German wordnet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) is compared to the word senses contained in the Digital Dictionary of the German Language (Digitales Wörterbuch der Deutschen Sprache 1 , DWDS; Klein and Geyken, 2010). Both resources are long-term lexicographic projects aiming at a comprehensive coverage of contemporary standard German in electronic form. What makes a comparison between these resources particularly interesting and useful is the fact that they utilize two different methods for constructing word meanings. The DWDS is based on the digital versions of three pre-existing dictionaries: the Dictionary of Contemporary German (Wörter"
W14-0109,W98-0710,0,0.101184,"he harvesting of sense-specific information and the external support of sense distinctions for matching senses as well as indicators for revisiting and possibly revising the lexical entries in question for nonmatching senses. 6 Related Work There has been a considerable body of research for English that investigates the alignment of the Princeton WordNet with Wikipedia (including Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011), with Wiktionary (including Meyer and Gurevych, 2011), with the Longman Dictionary of Contemporary English and with Roget's thesaurus (Kwong, 1998), with the Hector lexicon (Litkowski, 1999), or with the Oxford Dictionary of English (Navigli, 2006). Previous work for German has been on the alignment of GermaNet with the German version of Wiktionary (Henrich et al., 2011) and with the German Wikipedia (Henrich et al., 2012). However, there is no other previous research that tries to align GermaNet to the DWDS. 7 Conclusion and Future Work This initial pilot study has proven the feasibility of a sense alignment between GermaNet and the DWDS both in term of quantity and appropriateness. We have learned about the differences in the distincti"
W14-0109,W99-0505,0,0.0852481,"tion and the external support of sense distinctions for matching senses as well as indicators for revisiting and possibly revising the lexical entries in question for nonmatching senses. 6 Related Work There has been a considerable body of research for English that investigates the alignment of the Princeton WordNet with Wikipedia (including Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011), with Wiktionary (including Meyer and Gurevych, 2011), with the Longman Dictionary of Contemporary English and with Roget's thesaurus (Kwong, 1998), with the Hector lexicon (Litkowski, 1999), or with the Oxford Dictionary of English (Navigli, 2006). Previous work for German has been on the alignment of GermaNet with the German version of Wiktionary (Henrich et al., 2011) and with the German Wikipedia (Henrich et al., 2012). However, there is no other previous research that tries to align GermaNet to the DWDS. 7 Conclusion and Future Work This initial pilot study has proven the feasibility of a sense alignment between GermaNet and the DWDS both in term of quantity and appropriateness. We have learned about the differences in the distinction of senses that are due to different pers"
W14-0109,I11-1099,0,0.212516,"t between GermaNet and the DWDS. This will open up a wide range of benefits for both resources, including the harvesting of sense-specific information and the external support of sense distinctions for matching senses as well as indicators for revisiting and possibly revising the lexical entries in question for nonmatching senses. 6 Related Work There has been a considerable body of research for English that investigates the alignment of the Princeton WordNet with Wikipedia (including Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011), with Wiktionary (including Meyer and Gurevych, 2011), with the Longman Dictionary of Contemporary English and with Roget's thesaurus (Kwong, 1998), with the Hector lexicon (Litkowski, 1999), or with the Oxford Dictionary of English (Navigli, 2006). Previous work for German has been on the alignment of GermaNet with the German version of Wiktionary (Henrich et al., 2011) and with the German Wikipedia (Henrich et al., 2012). However, there is no other previous research that tries to align GermaNet to the DWDS. 7 Conclusion and Future Work This initial pilot study has proven the feasibility of a sense alignment between GermaNet and the DWDS both i"
W14-0109,P06-1014,0,0.19941,"hing senses as well as indicators for revisiting and possibly revising the lexical entries in question for nonmatching senses. 6 Related Work There has been a considerable body of research for English that investigates the alignment of the Princeton WordNet with Wikipedia (including Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011), with Wiktionary (including Meyer and Gurevych, 2011), with the Longman Dictionary of Contemporary English and with Roget's thesaurus (Kwong, 1998), with the Hector lexicon (Litkowski, 1999), or with the Oxford Dictionary of English (Navigli, 2006). Previous work for German has been on the alignment of GermaNet with the German version of Wiktionary (Henrich et al., 2011) and with the German Wikipedia (Henrich et al., 2012). However, there is no other previous research that tries to align GermaNet to the DWDS. 7 Conclusion and Future Work This initial pilot study has proven the feasibility of a sense alignment between GermaNet and the DWDS both in term of quantity and appropriateness. We have learned about the differences in the distinction of senses that are due to different perspectives and guidelines of how to model word senses that t"
W14-0109,P10-1154,0,\N,Missing
W14-0109,W11-0122,0,\N,Missing
W15-0122,P98-1015,0,0.328053,"Tratz dataset is the largest publicly-available annotated noun compound dataset, containing 19158 compounds annotated with 37 semantic relations. Table 1, which is an abbreviated version of Table 4.5 in Tratz (2011), illustrates these relations by characteristic examples and indicates the relative frequency of each relation within the dataset as a whole. The inventory of relations consists of seman1 The dataset fanseparser/ is available for download at http://www.isi.edu/publications/licensed-sw/ 174 tic categories that resemble but are not identical to the inventories previously proposed by Barker and Szpakowicz (1998) and Girju et al. (2005). Tratz and Hovy (2010) motivate their new inventory by the necessity to achieve more reliable inter-annotator agreement than was obtained for these earlier inventories. The original Tratz and Hovy dataset consisted of 17509 compounds annotated with 43 semantic relations. Tratz (2011)’s motivation for creating a revised noun compound relation inventory with only 37 semantic relations was to create a better mapping between prepositional paraphrases and noun compound relations. The compound classification experiments described in Tratz and Hovy (2010) were, however, not r"
W15-0122,I05-1082,0,0.831197,"Missing"
W15-0122,E14-1051,0,0.385671,"assification experiments described in Tratz and Hovy (2010) were, however, not re-run on the revised dataset. Since only the Tratz dataset is publicly available as part of the semantically-enriched parser described in Tratz (2011), this dataset was used in the experiments reported on in the present paper. 4 The embeddings The automatic classification experiments presented in section 5 use a selection of publicly available word embeddings: the CW embeddings2 , decribed in Collobert et al. (2011), the GloVe embeddings3 , presented in Pennington et al. (2014), the HPCA embeddings4 , described in Lebret and Collobert (2014) and the word2vec embeddings5 introduced by Mikolov et al. (2013). The vector size, the dictionary size, the amount of training data as well as the specific corpora used for creating each of these word embeddings are summarized in Table 2. A word embedding W : D → Rn is a function that assigns each word from the embedding dictionary D an n-dimensional, real-valued vector. The words in the dictionary D are embedded in a high-dimensional vector space, such that the representations of syntactically and/or semantically similar words are close together in the vector space. Word embeddings are the r"
W15-0122,D14-1162,0,0.0859515,"hose reported in Tratz and Hovy (2010) in a crossvalidation setting, but outperform their system on unseen compounds by a large margin. 1 Introduction Recent research in computational semantics has increasingly made use of vector space representations of words in combination with deep neural network classifiers. This recent trend builds on the earlier successes of such representations and classifiers for morphological and syntactic NLP tasks (Collobert et al., 2011), and now also includes semantic tasks such as word similarity, word analogy as well as sentiment analysis (Mikolov et al., 2013; Pennington et al., 2014). The fact that the same type of vector representations can be initially trained for one or more NLP tasks and then be re-used and fine-tuned for a new, seemingly unrelated task suggests that such models can provide a unified architecture for NLP (Collobert and Weston, 2008). The fact that the performance of word embeddings, when combined with deep neural networks, improves in a multi-task learning scenario and can provide state of the art results for NLP further adds to the attractiveness of such methods. One of the ways to further test the viability of such models and methods is to subject t"
W15-0122,P10-1070,0,0.691748,"present paper reports on the results of automatic noun compound interpretation for English using a deep neural network classifier and a selection of publicly available word embeddings to represent the individual compound constituents. The task at hand consists of identifying the semantic relation that holds between the constituents of a compound (e.g. WHOLE + PART _ OR _ MEMBER _ OF in the case of ‘robot arm’, LOCATION in the case of ‘hillside home’). The experiments reported in the present paper use the noun compound dataset described in Tratz (2011), a revised version of the dataset used by Tratz and Hovy (2010) for training their Maximum Entropy classifier. Our experiments yield results that are comparable to those reported in Tratz and Hovy (2010) in a crossvalidation setting, but outperform their system on unseen compounds by a large margin. 1 Introduction Recent research in computational semantics has increasingly made use of vector space representations of words in combination with deep neural network classifiers. This recent trend builds on the earlier successes of such representations and classifiers for morphological and syntactic NLP tasks (Collobert et al., 2011), and now also includes sema"
W15-0122,S13-2025,0,\N,Missing
W15-0122,C98-1015,0,\N,Missing
W15-0122,W01-0511,0,\N,Missing
W16-1908,N09-1036,0,0.0541335,"Missing"
W16-1908,W14-0505,1,0.841297,"Missing"
W16-1908,P15-1167,1,0.833007,"purely symbolic representations, such distributed representations allow input units that appear in similar contexts to share similar vectors (embeddings). The model can, then, exploit the similarities between the embeddings during segmentation and learning. This paper studies the learning and use of embeddings of phone1 uni- and bi-grams for computational models of word segmentation in child language acquisition. Our work is inspired by recent success of embeddings in NLP (Devlin et al., 2014; Socher et al., 2013), especially in Chinese word segmentation (Zheng et al., 2013; Pei et al., 2014; Ma and Hinrichs, 2015). However, this work differs from Chinese word segmentaThis paper presents a novel model that learns and exploits embeddings of phone ngrams for word segmentation in child language acquisition. Embedding-based models are evaluated on a phonemically transcribed corpus of child-directed speech, in comparison with their symbolic counterparts using the common learning framework and features. Results show that learning embeddings significantly improves performance. We make use of extensive visualization to understand what the model has learned. We show that the learned embeddings are informative fo"
W16-1908,J01-3002,0,0.198198,"Missing"
W16-1908,D13-1061,0,0.032469,"es that are learned from data. Unlike purely symbolic representations, such distributed representations allow input units that appear in similar contexts to share similar vectors (embeddings). The model can, then, exploit the similarities between the embeddings during segmentation and learning. This paper studies the learning and use of embeddings of phone1 uni- and bi-grams for computational models of word segmentation in child language acquisition. Our work is inspired by recent success of embeddings in NLP (Devlin et al., 2014; Socher et al., 2013), especially in Chinese word segmentation (Zheng et al., 2013; Pei et al., 2014; Ma and Hinrichs, 2015). However, this work differs from Chinese word segmentaThis paper presents a novel model that learns and exploits embeddings of phone ngrams for word segmentation in child language acquisition. Embedding-based models are evaluated on a phonemically transcribed corpus of child-directed speech, in comparison with their symbolic counterparts using the common learning framework and features. Results show that learning embeddings significantly improves performance. We make use of extensive visualization to understand what the model has learned. We show that"
W16-1908,P14-1028,0,0.0205512,"from data. Unlike purely symbolic representations, such distributed representations allow input units that appear in similar contexts to share similar vectors (embeddings). The model can, then, exploit the similarities between the embeddings during segmentation and learning. This paper studies the learning and use of embeddings of phone1 uni- and bi-grams for computational models of word segmentation in child language acquisition. Our work is inspired by recent success of embeddings in NLP (Devlin et al., 2014; Socher et al., 2013), especially in Chinese word segmentation (Zheng et al., 2013; Pei et al., 2014; Ma and Hinrichs, 2015). However, this work differs from Chinese word segmentaThis paper presents a novel model that learns and exploits embeddings of phone ngrams for word segmentation in child language acquisition. Embedding-based models are evaluated on a phonemically transcribed corpus of child-directed speech, in comparison with their symbolic counterparts using the common learning framework and features. Results show that learning embeddings significantly improves performance. We make use of extensive visualization to understand what the model has learned. We show that the learned embed"
W16-1908,P13-1045,0,0.0210797,"of low-dimensional, real-valued vector representation of features that are learned from data. Unlike purely symbolic representations, such distributed representations allow input units that appear in similar contexts to share similar vectors (embeddings). The model can, then, exploit the similarities between the embeddings during segmentation and learning. This paper studies the learning and use of embeddings of phone1 uni- and bi-grams for computational models of word segmentation in child language acquisition. Our work is inspired by recent success of embeddings in NLP (Devlin et al., 2014; Socher et al., 2013), especially in Chinese word segmentation (Zheng et al., 2013; Pei et al., 2014; Ma and Hinrichs, 2015). However, this work differs from Chinese word segmentaThis paper presents a novel model that learns and exploits embeddings of phone ngrams for word segmentation in child language acquisition. Embedding-based models are evaluated on a phonemically transcribed corpus of child-directed speech, in comparison with their symbolic counterparts using the common learning framework and features. Results show that learning embeddings significantly improves performance. We make use of extensive visuali"
W16-1908,P09-1054,0,0.0384984,"r utterance boundaries and sampled intra-utterance positions, respectively. To offset over-fitting, we add an L2 regularization term (||ij ||2 + ||w||2 ) to the loss function, as follows:  λ ||ij ||2 + ||w||2 (3) 2 The λ is a factor that adjusts the contribution of the regularization term. To minimize the regularized loss function, which is is still convex, we perform stochastic gradient descent to iteratively update the embeddings and the weight vector in turn, each time considering the other as constant. The gradients and update rules are similar to that of logistic regression model as in Tsuruoka et al. (2009), except that the input embeddings i are also updated besides the standard weight vector. In particular, the gradient of input embeddings ij for each particular position j is computed according to (4), where w is the weight vector and yj is the assumed label. The input embeddings are then updated by (5), where α is the learning rate. 3.1 Jj ← Jj + ∂Jj = (f (j) − yj ) · w + λij ∂ij ∂Jj ij ← ij − α ∂ij 2.3 Data In the experiments reported in this paper, we use the de facto standard corpus for evaluating segmentation models. The corpus was collected by Bernstein Ratner (1987) and converted to a p"
W16-1908,P08-1016,0,\N,Missing
W16-1908,P14-1129,0,\N,Missing
W16-2012,P08-2064,0,0.0203422,"n the best model from the last subsection using modified GN data, which has longer noncompounds up to 15 letters in length and excludes words that also appear in the PE data. The model is evaluated on the PE data using the same metrics as described in Section 3.2, except that the evaluation is by token rather than by type, to be compatible with the original PE results. Table 3 shows the results, which are analyzed in the remainder of this section. Splitting compounds. Accuracy and precision 4 Discussion and Related Work Work on compound splitting emerged in the context of machine translation (Alfonseca et al., 2008b; Stymne, 2008; El-Kahlout and Yvon, 2010) and speech recognition (Larson et al., 2000) for German, Turkish (Bisazza and Federico, 2009), Finnish (Virpioja et al., 2007) and other languages (Alfonseca et al., 2008a; Stymne and Holmqvist, 2008). Most works, including discriminative learning methods (Alfonseca et al., 2008a; Dyer, 2009), follow the frequency approach. A few exceptions include, for example, Macherey et al. (2011) and Geyken and Hanneforth (2005), the latter of which builds finite-state morphological analyzer for German, where compound splitting is also covered. In contrast to mo"
W16-2012,2009.iwslt-papers.1,0,0.0334485,"des words that also appear in the PE data. The model is evaluated on the PE data using the same metrics as described in Section 3.2, except that the evaluation is by token rather than by type, to be compatible with the original PE results. Table 3 shows the results, which are analyzed in the remainder of this section. Splitting compounds. Accuracy and precision 4 Discussion and Related Work Work on compound splitting emerged in the context of machine translation (Alfonseca et al., 2008b; Stymne, 2008; El-Kahlout and Yvon, 2010) and speech recognition (Larson et al., 2000) for German, Turkish (Bisazza and Federico, 2009), Finnish (Virpioja et al., 2007) and other languages (Alfonseca et al., 2008a; Stymne and Holmqvist, 2008). Most works, including discriminative learning methods (Alfonseca et al., 2008a; Dyer, 2009), follow the frequency approach. A few exceptions include, for example, Macherey et al. (2011) and Geyken and Hanneforth (2005), the latter of which builds finite-state morphological analyzer for German, where compound splitting is also covered. In contrast to most previous work, this paper models compound splitting on the lower level of letters, which can better generalize to unknown compounds an"
W16-2012,W14-0505,0,0.0214236,"eling model, by adding features such as “the current letter starts a letter sequence that matches a known word in the lexicon”. The basic idea of letter or phoneme sequencebased analysis goes back to early structural linguistics work. Harris (1955) studies the distribution of distinct phoneme unigrams and bigrams before or after a particular phoneme, i.e. predecessor/successor variety. The change of these variety scores in an utterance is used to determine the word boundaries. That idea has been adopted and further developed in the context of word segmentation of child-directed speech (C ¸ o¨ ltekin and Nerbonne, 2014), where all the intra-utterance word boundaries are absent. Another instance of such sentence-wise word segmentation is Chinese word segmentation (Peng et al., 2004), where it is a standard solution to conduct CRF-based sequence labeling, using ngrams of orthographic units as features. To some extent, compound splitting can be seen as a special case of the above two word segmentation tasks. In particular, our method is clearly inspired by that of Chinese word segmentation, such as Peng et al. (2004). Although it might seem obvious to model compound splitting as letter sequence labeling in hind"
W16-2012,W97-0802,0,0.397954,"d in various NLP tasks, such as POS tagging (Hovy et al., 2014) and Chinese word segmentation (Ma and Hinrichs, 2015). As many state-of-the-art NLP systems, we build conditional random fields models to conduct sequence labeling, which are detailed in the next subsections. CRF models can leverage rich features of letter ngrams (Section 2.3), such as ung (a German nominalization suffix), which are shared among words and applicable to many unknown compounds and constituents. Our method is language independent, although this paper focuses on German. Evaluated with the compound data from GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) and Parra Escart´ın (2014), experiments in Section 3 show that our approach significantly outperforms previously developed splitters. The contributions of this paper are two-fold: • A novel letter sequence labeling approach to compound splitting 2.2 Conditional random fields (CRFs) Conditional random fields (Lafferty et al., 2001) are a discriminative learning framework, which is capable of utilizing a vast amount of arbitrary, interactive features to achieve high accuracy. The probability assigned to a label sequence for a particular letter sequence of length T b"
W16-2012,2008.eamt-1.25,0,0.0230629,"described in Section 3.2, except that the evaluation is by token rather than by type, to be compatible with the original PE results. Table 3 shows the results, which are analyzed in the remainder of this section. Splitting compounds. Accuracy and precision 4 Discussion and Related Work Work on compound splitting emerged in the context of machine translation (Alfonseca et al., 2008b; Stymne, 2008; El-Kahlout and Yvon, 2010) and speech recognition (Larson et al., 2000) for German, Turkish (Bisazza and Federico, 2009), Finnish (Virpioja et al., 2007) and other languages (Alfonseca et al., 2008a; Stymne and Holmqvist, 2008). Most works, including discriminative learning methods (Alfonseca et al., 2008a; Dyer, 2009), follow the frequency approach. A few exceptions include, for example, Macherey et al. (2011) and Geyken and Hanneforth (2005), the latter of which builds finite-state morphological analyzer for German, where compound splitting is also covered. In contrast to most previous work, this paper models compound splitting on the lower level of letters, which can better generalize to unknown compounds and constituents. Moreover, it is possible to integrate word-level knowledge into 1 Parra Escart´ın (2014) ev"
W16-2012,henrich-hinrichs-2010-gernedit,1,0.803084,"such as POS tagging (Hovy et al., 2014) and Chinese word segmentation (Ma and Hinrichs, 2015). As many state-of-the-art NLP systems, we build conditional random fields models to conduct sequence labeling, which are detailed in the next subsections. CRF models can leverage rich features of letter ngrams (Section 2.3), such as ung (a German nominalization suffix), which are shared among words and applicable to many unknown compounds and constituents. Our method is language independent, although this paper focuses on German. Evaluated with the compound data from GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) and Parra Escart´ın (2014), experiments in Section 3 show that our approach significantly outperforms previously developed splitters. The contributions of this paper are two-fold: • A novel letter sequence labeling approach to compound splitting 2.2 Conditional random fields (CRFs) Conditional random fields (Lafferty et al., 2001) are a discriminative learning framework, which is capable of utilizing a vast amount of arbitrary, interactive features to achieve high accuracy. The probability assigned to a label sequence for a particular letter sequence of length T by a CRF is given by the follo"
W16-2012,R11-1058,1,0.778048,"Missing"
W16-2012,2007.mtsummit-papers.65,0,0.087641,"Missing"
W16-2012,P14-2062,0,0.0309124,"SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 76–81, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics by extracting either single letters that are labeled as S or the consecutive letters such that (1) the first letter is labeled as B; (2) the last letter is labeled as E; (3) all the others in between are labeled as M. We call the above formulation of compound splitting letter sequence labeling. It falls into the broader category of sequence labeling, which is widely used in various NLP tasks, such as POS tagging (Hovy et al., 2014) and Chinese word segmentation (Ma and Hinrichs, 2015). As many state-of-the-art NLP systems, we build conditional random fields models to conduct sequence labeling, which are detailed in the next subsections. CRF models can leverage rich features of letter ngrams (Section 2.3), such as ung (a German nominalization suffix), which are shared among words and applicable to many unknown compounds and constituents. Our method is language independent, although this paper focuses on German. Evaluated with the compound data from GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) and Parra E"
W16-2012,weller-heid-2012-analyzing,0,0.365037,"n, compounds are written as single word-tokens without word delimiters separating their constituent words. For example, the German term for ‘place name’ is Ortsname, which is formed by Ort ‘place’ and Name ‘name’ together with the linking element ‘s’ between constituents. Given the productive nature of compounding, treating each compound as a unique word would dramatically increase the vocabulary size. Information about the existence of compounds and about their constituent parts is thus helpful to many NLP applications such as machine translation (Koehn and Knight, 2003) and term extraction (Weller and Heid, 2012). Compound splitting is the NLP task that automatically breaks compounds into their constituent words. As the inputs to compound splitters often include unknown words, which are not necessarily compounds, splitters usually also need to distinguish between compounds and non-compounds. Many state-of-the-art splitters for German (Popovi´c et al., 2006; Weller and Heid, 2012) 76 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 76–81, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics by extra"
W16-2012,E03-1076,0,0.837564,"be a non-compound. 2. Choosing the hypothesis with the highest geometric mean of frequencies of constituents as the best splitting. If the frequency of the input word is higher than the geometric mean of all possible splittings, non-splitting is chosen. The frequency approach is simple and efficient. However, frequency criteria are not necessarily optimal for identifying the best splitting decisions. In practice, this often leads to splitting compounds at wrong positions, erroneously splitting non-compounds, and incorrectly predicting frequent compounds to be non-compounds. Parallel corpora (Koehn and Knight, 2003; Popovi´c et al., 2006) and linguistic analysis (Fritzinger and Fraser, 2010) etc. were used to improve the frequency approach, but the above-mentioned issues remain. Moreover, frequencies encode no information about word forms, which hinders knowledge transfer between words with similar forms. In an extreme yet common case, when one or more compound constituents are unknown words, the correct splitting is not even generated in Step 1 of the frequency approach. To address the above-mentioned problems, this paper proposes a letter sequence labeling (LSL) approach (Section 2) to compound splitt"
W16-2012,P10-1052,0,0.104352,"Missing"
W16-2012,P15-1167,1,0.84425,"honetics, Phonology, and Morphology, pages 76–81, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics by extracting either single letters that are labeled as S or the consecutive letters such that (1) the first letter is labeled as B; (2) the last letter is labeled as E; (3) all the others in between are labeled as M. We call the above formulation of compound splitting letter sequence labeling. It falls into the broader category of sequence labeling, which is widely used in various NLP tasks, such as POS tagging (Hovy et al., 2014) and Chinese word segmentation (Ma and Hinrichs, 2015). As many state-of-the-art NLP systems, we build conditional random fields models to conduct sequence labeling, which are detailed in the next subsections. CRF models can leverage rich features of letter ngrams (Section 2.3), such as ung (a German nominalization suffix), which are shared among words and applicable to many unknown compounds and constituents. Our method is language independent, although this paper focuses on German. Evaluated with the compound data from GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010) and Parra Escart´ın (2014), experiments in Section 3 show that ou"
W16-2012,P11-1140,0,0.219918,"der of this section. Splitting compounds. Accuracy and precision 4 Discussion and Related Work Work on compound splitting emerged in the context of machine translation (Alfonseca et al., 2008b; Stymne, 2008; El-Kahlout and Yvon, 2010) and speech recognition (Larson et al., 2000) for German, Turkish (Bisazza and Federico, 2009), Finnish (Virpioja et al., 2007) and other languages (Alfonseca et al., 2008a; Stymne and Holmqvist, 2008). Most works, including discriminative learning methods (Alfonseca et al., 2008a; Dyer, 2009), follow the frequency approach. A few exceptions include, for example, Macherey et al. (2011) and Geyken and Hanneforth (2005), the latter of which builds finite-state morphological analyzer for German, where compound splitting is also covered. In contrast to most previous work, this paper models compound splitting on the lower level of letters, which can better generalize to unknown compounds and constituents. Moreover, it is possible to integrate word-level knowledge into 1 Parra Escart´ın (2014) evaluated Weller and Heid (2012) ‘as is’, using a model pre-trained on unknown data, which might have overlaps with the test data. 79 pacts the performance of NLP applications. It is intere"
W16-2012,escartin-2014-chasing,0,0.0375162,"Missing"
W16-2012,C04-1081,0,0.17547,"ased analysis goes back to early structural linguistics work. Harris (1955) studies the distribution of distinct phoneme unigrams and bigrams before or after a particular phoneme, i.e. predecessor/successor variety. The change of these variety scores in an utterance is used to determine the word boundaries. That idea has been adopted and further developed in the context of word segmentation of child-directed speech (C ¸ o¨ ltekin and Nerbonne, 2014), where all the intra-utterance word boundaries are absent. Another instance of such sentence-wise word segmentation is Chinese word segmentation (Peng et al., 2004), where it is a standard solution to conduct CRF-based sequence labeling, using ngrams of orthographic units as features. To some extent, compound splitting can be seen as a special case of the above two word segmentation tasks. In particular, our method is clearly inspired by that of Chinese word segmentation, such as Peng et al. (2004). Although it might seem obvious to model compound splitting as letter sequence labeling in hindsight, it is not really so in foresight. Both the dominance of word frequency-based approach and the extra challenges in morphology makes is less natural to think in"
W16-2012,W10-1734,0,\N,Missing
W16-2012,N09-1046,0,\N,Missing
W17-0404,P13-2017,0,0.0977457,"Missing"
W17-0404,foth-etal-2014-size,0,0.32101,"Missing"
W17-0404,seeker-kuhn-2012-making,0,0.0324346,"¨uBa-D/Z and TIGER treebanks were used in their original form, and as converted dependency treebanks. There have been other constituency-todependency conversion efforts for German treebanks. Bohnet (2003) and Daum et al. (2004) present methods for converting NEGRA to a dependency treebank. Hajiˇc et al. (2009) convert TIGER to a dependency treebank for use in the CoNLL-2009 multi-lingual dependency parsing shared task. The same conversion method is also used in Zeman et al. (2012), again in a multilingual setting, but also with an effort to unify the annotation scheme. In a more recent study, Seeker and Kuhn (2012) convert TIGER to a dependency treebank. They focus on representation of empty nodes in resulting dependency annotations. In all of the earlier studies listed above, with the exception of Zeman et al. (2012), the target dependency treebanks share the tagsets for POS and morphological annotations, and to a large extent the dependency heads already annotated in the source treebank. However, in the present study the morphosyntactic annotations have to diverge, sometimes in non-trivial manner, from the source annotations. We will describe these differences in detail below. 28 Figure 1: An example"
W17-0404,telljohann-etal-2004-tuba,1,0.849413,"Missing"
W17-0404,W04-3231,1,0.751987,"Missing"
W17-7603,P16-2001,1,0.84532,"Missing"
W17-7603,E17-2050,1,0.840181,"Missing"
W17-7603,D12-1096,0,0.0354448,"Missing"
W17-7603,P12-1082,0,0.0296579,"Missing"
W17-7603,D14-1162,0,0.0798144,"sformational, interpretative account. In non-derivational, lexicalist theories of grammar such as Head-Driven Phrase Structure Grammar, the sharing of argument structure for lexical roots realized in different word classes is modeled by the non-transformational mechanism of lexical rules and sharing of valence information (see Gerdemann (1994) for such an account for nominalizations in German). Most recently, distributional theories of natural language have also served as an inspiration for distributional modeling of words as word embeddings in computational linguistics (Mikolov et al., 2013; Pennington et al., 2014). Linguistically annotated corpora, so-called treebanks, offer excellent empirical resources for the study of the realization of lexical roots in different morpho-syntactic categories and constructions, provided that their annotations are rich enough to capture relevant information about derivational morphology and lemmatization. 2 Case Study The purpose of the present paper is to systematically study similarities and divergences in syntactic distributions across different realizations of lexical roots. In particular, we are interested in finding out if the syntactic distribution of a particul"
W17-7603,schmid-etal-2004-smor,0,0.0459677,"r (de Kok, 2014). In our study, we consider prepositions in (i) prepositional phrase modifications (PP) and (ii) prepositional complements (OBJP), along with their respective verb or verbal adjective governor. In contrast to the Dutch treebank where lexical tags indicate an adjective’s verbal origin, such information was not available for the German adjectives. In the German treebank, verbal adjectives are lemmatized to their adjective lemmas. For example, beschrifteter ‘labeled’ is lemmatized to beschriftet ‘labeled’. Therefore, all adjectives are analyzed by the SMOR morphological analyzer (Schmid et al., 2004) in order to detect verbal components in the adjectives. When the SMOR analysis of an adjective reveals components that imply a verbal reading, the forms are labeled as verb-derived in the treebank. In addition, the corresponding base verb lemma is reconstructed from the analysis. In contrast to the Dutch data, the availability of a wide-coverage morphological analyzer has also made it possible to include many adjectives that have transitioned from verbal adjectives to full adjectives in the data set. For instance, the adjective unbegrenzbar ‘illimitable’ is recognized as a verb-derived adject"
W17-7603,2006.jeptalnrecital-invite.2,0,0.0344329,"Missing"
W19-5112,W97-0802,0,0.860418,"that Frame Semantics (Fillmore, 1982) provides a good framework for semantic modelling of adjective-noun collocations. More specifically, the notion of a frame is rich enough to account for nouns from different semantic classes and to model semantic relations that hold between an adjective and a noun in terms of Frame Elements. We have substantiated these findings by considering a sample of adjectivenoun collocations from German such as enger Freund ‘close friend’ and starker Regen ‘heavy rain’. The data sample is taken from different semantic fields identified in the German wordnet GermaNet (Hamp and Feldweg, 1997; Henrich and Hinrichs, 2010). The study is based on the electronic dictionary DWDS (Klein and Geyken, 2010) and uses the collocation extraction tool Wortprofil (Geyken et al., 2009). The FrameNet modelling is based on the online resource available at http://framenet.icsi.berkeley.edu. Since FrameNets are available for a range of typologically different languages, it is feasible to extend the current case study to other languages. 1 Introduction Collocations such as to make a mistake and black coffee are multi-word expressions (MWEs) in which the choice of one constituent (base) is free, and t"
W19-5112,bel-etal-2000-simple,0,0.45368,"Missing"
W19-5112,J91-4003,0,0.497879,"Missing"
W19-5112,J93-1007,0,0.773726,"take or *dark coffee are not acceptable and sound unnatural to the native speakers, but they still can be interpreted correctly. Idiomatic MWEs such as black sheep are semantically opaque and belong to the domain of figurative language. In spite of the fact that collocations have been getting more attention in the recent decades, there is a lack of systematic empirical studies on their semantic properties. Most of the previous corpus studies of collocations are concerned with their statistical properties and the ways to improve methods of automatic collocation extraction (Church et al., 1991; Smadja, 1993; Evert, 2004; Pecina, 2008; Bouma, 2009). These authors have shown that automatic and/or manual extraction of collocations is not an easy task. Our research does not attempt to contribute to this growing body of research. Rather, we focus on the classification and modelling of semantic relations that hold between a base and its collocate, e.g. the relation of degree that holds between the collocate heavy and its nominal base rain. More specifically, we will focus on the semantic relations that hold in adjective-noun collocations, since such collocations have received considerably less attenti"
