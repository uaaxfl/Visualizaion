2020.acl-main.126,W05-0909,0,0.0727094,"ystem evaluation is a longlasting challenge. It has been shown that previous automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), or learning based (Tao et al., 2018; Lowe et al., 2017). Given the aforementioned limitations, Likertscore based rating is the de-facto standard for current dialog research and social conversational systems such as in Amazon Alexa Prize Challenge (Yu et al., 2019; Chen et al., 2018). Various forms of evaluation settings have been explored to better measure human judgments. Single-turn pairwise comparison (Vinyals and Le, 2015; Li et al., 2016) is primarily used for comparing two dialog systems. Each system predicts a single utter"
2020.acl-main.126,W09-3935,0,0.0126954,"wise comparison (Vinyals and Le, 2015; Li et al., 2016) is primarily used for comparing two dialog systems. Each system predicts a single utterance given the static “gold” context utterance from human-human logs. Although such A/B test setting is robust to annotator score bias, it cannot capture the multiturn nature of dialogs. A more complete multiturn evaluation is typically measured with a Likert scale for the full dialog history, where either a third-person rater or the chatbot user (P´erez-Rosas et al., 2019) reports a Likert score on user experience (Venkatesh et al., 2018), engagement (Bohus and Horvitz, 2009) or appropriateness (Lowe et al., 2017). However, as observed in (Kulikov et al., 2018; Ram et al., 2018a; Venkatesh et al., 2018) Likert scores suffer from bias and variance among different users. Different from previous empirical observations, we conduct a large-scale quantitative and qualitative data analysis of Likert score based ratings. To address the issue of Likert scores, the Alexa team proposed a rule-based ensemble of turn-granularity expert ratings (Yi et al., 2019), and automatic metrics like topical diversity (Guo et al., 2018) and conversational breadth. ACUTEEVAL (Li et al., 20"
2020.acl-main.126,N19-1423,0,0.0210952,"Missing"
2020.acl-main.126,N18-5020,0,0.0413779,"Missing"
2020.acl-main.126,W19-5944,0,0.0941138,"Missing"
2020.acl-main.126,P16-1094,0,0.0268745,"sed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), or learning based (Tao et al., 2018; Lowe et al., 2017). Given the aforementioned limitations, Likertscore based rating is the de-facto standard for current dialog research and social conversational systems such as in Amazon Alexa Prize Challenge (Yu et al., 2019; Chen et al., 2018). Various forms of evaluation settings have been explored to better measure human judgments. Single-turn pairwise comparison (Vinyals and Le, 2015; Li et al., 2016) is primarily used for comparing two dialog systems. Each system predicts a single utterance given the static “gold” context utterance from human-human logs. Although such A/B test setting is robust to annotator score bias, it cannot capture the multiturn nature of dialogs. A more complete multiturn evaluation is typically measured with a Likert scale for the full dialog history, where either a third-person rater or the chatbot user (P´erez-Rosas et al., 2019) reports a Likert score on user experience (Venkatesh et al., 2018), engagement (Bohus and Horvitz, 2009) or appropriateness (Lowe et al"
2020.acl-main.126,W04-1013,0,0.0752688,"in dialog system evaluation is a longlasting challenge. It has been shown that previous automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), or learning based (Tao et al., 2018; Lowe et al., 2017). Given the aforementioned limitations, Likertscore based rating is the de-facto standard for current dialog research and social conversational systems such as in Amazon Alexa Prize Challenge (Yu et al., 2019; Chen et al., 2018). Various forms of evaluation settings have been explored to better measure human judgments. Single-turn pairwise comparison (Vinyals and Le, 2015; Li et al., 2016) is primarily used for comparing two dialog systems. Each sys"
2020.acl-main.126,D16-1230,0,0.0364883,"s in the dialog community. Open-domain chatbots have a user-centric goal: to provide human with enjoyable user experience. However, user experience is difficult to quantify due to bias and variance among different users. Previous research has optimized on automatic dialog evaluation metrics such as BLUE (Papineni et al., 2002), which measures the difference between the generated responses and the reference responses. Due to the contrast between the one-tomany nature of open-domain conversations and the limited number of available references, such metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). Designing a fully automatic dialog evaluation metric is still an open research problem. Currently, both academia and industry (Ram et al., 2018a; Li et al., 2019b; Liang et al., 2019) rely on human ratings to evaluate open-domain dialogs. Following the ubiquitous application of Likert scores in survey research like online reviews (Godes and Silva, 2012) and consumer satisfaction (Peterson and Wilson, 1992), a common practice of human evaluation on dialogs is to ask either a third-person rater or the chatbot user to report a Likert score. However, co"
2020.acl-main.126,P17-1103,0,0.41415,"mmunity. Open-domain chatbots have a user-centric goal: to provide human with enjoyable user experience. However, user experience is difficult to quantify due to bias and variance among different users. Previous research has optimized on automatic dialog evaluation metrics such as BLUE (Papineni et al., 2002), which measures the difference between the generated responses and the reference responses. Due to the contrast between the one-tomany nature of open-domain conversations and the limited number of available references, such metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). Designing a fully automatic dialog evaluation metric is still an open research problem. Currently, both academia and industry (Ram et al., 2018a; Li et al., 2019b; Liang et al., 2019) rely on human ratings to evaluate open-domain dialogs. Following the ubiquitous application of Likert scores in survey research like online reviews (Godes and Silva, 2012) and consumer satisfaction (Peterson and Wilson, 1992), a common practice of human evaluation on dialogs is to ask either a third-person rater or the chatbot user to report a Likert score. However, concerns have been ra"
2020.acl-main.126,W12-2018,0,0.103838,"It has been shown that previous automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), or learning based (Tao et al., 2018; Lowe et al., 2017). Given the aforementioned limitations, Likertscore based rating is the de-facto standard for current dialog research and social conversational systems such as in Amazon Alexa Prize Challenge (Yu et al., 2019; Chen et al., 2018). Various forms of evaluation settings have been explored to better measure human judgments. Single-turn pairwise comparison (Vinyals and Le, 2015; Li et al., 2016) is primarily used for comparing two dialog systems. Each system predicts a single utterance given the static “gold” context utt"
2020.acl-main.126,Q18-1026,0,0.0282463,"ccuracy on this binary classification problem, which is far from usable in real-world settings. 1365 3.3 Pairwise Comparison Based Evaluation Selecting the better dialog from two options is easier for a human evaluator than giving an absolute number like the Likert score, which requires the evaluator to maintain a consistent standard. People’s perception is inherently relative, and pair-wise comparison is local and does not require the user to have global consistency. There are many other examples where humans find it easier to perform pairwise comparisons rather than providing direct labels (Simpson and Gurevych, 2018; Mailthody et al., 2019; Liang et al., 2018), including content search (F¨urnkranz and H¨ullermeier, 2010), image retrieval (Wah et al., 2014; Feng et al., 2019), and age estimation (Zhang et al., 2017). We randomly sample 400 dialog pairs for experts to annotate. We ask the question, “If you were the user, in which scenario would you be more likely to come back and talk to the system again? ” We guide the experts to focus on the user experience rather than calibrating the performance of any specific module of the dialog system. Two researchers with conversational training experience annotate"
2020.acl-main.126,D17-1238,0,0.035212,"n chatbots have a user-centric goal: to provide human with enjoyable user experience. However, user experience is difficult to quantify due to bias and variance among different users. Previous research has optimized on automatic dialog evaluation metrics such as BLUE (Papineni et al., 2002), which measures the difference between the generated responses and the reference responses. Due to the contrast between the one-tomany nature of open-domain conversations and the limited number of available references, such metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). Designing a fully automatic dialog evaluation metric is still an open research problem. Currently, both academia and industry (Ram et al., 2018a; Li et al., 2019b; Liang et al., 2019) rely on human ratings to evaluate open-domain dialogs. Following the ubiquitous application of Likert scores in survey research like online reviews (Godes and Silva, 2012) and consumer satisfaction (Peterson and Wilson, 1992), a common practice of human evaluation on dialogs is to ask either a third-person rater or the chatbot user to report a Likert score. However, concerns have been raised about the validity"
2020.acl-main.126,P02-1040,0,0.111314,"Related Work Open-domain dialog system evaluation is a longlasting challenge. It has been shown that previous automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), or learning based (Tao et al., 2018; Lowe et al., 2017). Given the aforementioned limitations, Likertscore based rating is the de-facto standard for current dialog research and social conversational systems such as in Amazon Alexa Prize Challenge (Yu et al., 2019; Chen et al., 2018). Various forms of evaluation settings have been explored to better measure human judgments. Single-turn pairwise comparison (Vinyals and Le, 2015; Li et al., 2016) is primarily used for comparing two dialog system"
2020.acl-main.126,P19-1088,0,0.0594803,"Missing"
2020.acl-main.126,W19-8608,0,\N,Missing
2020.acl-main.567,P17-1171,0,0.0145503,"logues have more than one tasks. Because the manual effort grows exponentially with the complexity of the dialogues. In (Wu et al., 2019), Wu et al. introduced a transferable dialogue state generator (TRADE), which can generate dialogue states from utterances using a copy mechanism. This generative model achieved relative good performance, but it still has trouble in extracting relevant information from the original dialogues. For example, a user may tell the agent that he/she needs a taxi in a turn, but the taxi’s departure location is implicitly mentioned several turns ago. Inspired by the (Chen et al., 2017; Chen, 2018), (Chen et al., 2019) studied on utilizing attention mechanism to deal with the long distance slot carryover problem. In their work, they ﬁrst fused the information of the slot, its corresponding value and the dialogue distance into a single vector. Then they computed the attention between this single vector and the concatenation of dialogue and intent information. We simplify the attention method and introduce it into the dialogue state tracking task. Moreover, it is a common sense that there is some kind of relevance between two slots involving the same domain or the same attrib"
2020.acl-main.567,W19-4111,0,0.0201109,"Because the manual effort grows exponentially with the complexity of the dialogues. In (Wu et al., 2019), Wu et al. introduced a transferable dialogue state generator (TRADE), which can generate dialogue states from utterances using a copy mechanism. This generative model achieved relative good performance, but it still has trouble in extracting relevant information from the original dialogues. For example, a user may tell the agent that he/she needs a taxi in a turn, but the taxi’s departure location is implicitly mentioned several turns ago. Inspired by the (Chen et al., 2017; Chen, 2018), (Chen et al., 2019) studied on utilizing attention mechanism to deal with the long distance slot carryover problem. In their work, they ﬁrst fused the information of the slot, its corresponding value and the dialogue distance into a single vector. Then they computed the attention between this single vector and the concatenation of dialogue and intent information. We simplify the attention method and introduce it into the dialogue state tracking task. Moreover, it is a common sense that there is some kind of relevance between two slots involving the same domain or the same attribute. For example, people tend to h"
2020.acl-main.567,D17-1206,0,0.0515286,"Missing"
2020.acl-main.567,W14-4340,0,0.161718,"system a more popular topic in research. The major difference between dialogue systems and questionanswering is that dialogue systems need to track dialogue history effectively. So, we normally use a dialogue state tracking component to track user’s intention throughout the conversation. A dialogue state is typically composed as a set of slot value pairs in a task-oriented dialogue, such as “hotelinternet-yes”. It means the slot “hotel-internet” has a value of “yes”. Early dialogue state tracking model needs a predeﬁned ontology which means the values of every slot are enumerated in advance (Henderson et al., 2014; Mrkˇsi´c et al., 2017; Zhong et al., 2018; Sharma et al., 2019). Such practice is inefﬁcient and costly. The large number of possible slot-value pairs makes deploying these models in the real-life ∗ *Corresponding author. applications difﬁcult (Rastogi et al., 2017). This difﬁculty is further ampliﬁed in multi-domain dialogue state tracking where the dialogues have more than one tasks. Because the manual effort grows exponentially with the complexity of the dialogues. In (Wu et al., 2019), Wu et al. introduced a transferable dialogue state generator (TRADE), which can generate dialogue state"
2020.acl-main.567,P17-1163,0,0.0708809,"Missing"
2020.acl-main.567,D14-1162,0,0.0850233,"Missing"
2020.acl-main.567,E17-1029,0,0.0300912,"Missing"
2020.acl-main.567,P18-2069,0,0.0443815,"e network will automatically decrease its learning rate to improve the performance. We apply dropout with 0.2 dropout rate for regularization (Srivastava et al., 2014). Besides that, a word dropout technique is also utilized in the way proposed by (Bowman et al., 2015) which simulates the out-of-vocabulary setting. Our k-means clustering algorithm is implemented with the sklearn module, and we set all the hyperparameter in k-means algorithm as default. 5.3 Baseline Methods We compare SAS with several previous methods: MDBT, GLAD, GCE, SpanPtr and TRADE. Based on the classical NBT model, MDBT (Ramadan et al., 2018) extended the task into multiple domains. MDBT makes full use of the semantic similarities between the dialogue and the slot ontology to track the domain and the value of the slot jointly. GLAD relies on global modules to learn the general information and local modules to catch the slotspeciﬁc information (Zhong et al., 2018) from the dialogues. GCE efﬁciently improves and simpliﬁes GLAD, while keeping the excellent performance of GLAD (Nouri and Hosseini-Asl, 2018). SpanPtr ﬁrst introduces the pointer network (Vinyals et al., 2015) into the dialogue state tracking task to extract unknown slot"
2020.acl-main.567,N19-1057,0,0.0177626,"een dialogue systems and questionanswering is that dialogue systems need to track dialogue history effectively. So, we normally use a dialogue state tracking component to track user’s intention throughout the conversation. A dialogue state is typically composed as a set of slot value pairs in a task-oriented dialogue, such as “hotelinternet-yes”. It means the slot “hotel-internet” has a value of “yes”. Early dialogue state tracking model needs a predeﬁned ontology which means the values of every slot are enumerated in advance (Henderson et al., 2014; Mrkˇsi´c et al., 2017; Zhong et al., 2018; Sharma et al., 2019). Such practice is inefﬁcient and costly. The large number of possible slot-value pairs makes deploying these models in the real-life ∗ *Corresponding author. applications difﬁcult (Rastogi et al., 2017). This difﬁculty is further ampliﬁed in multi-domain dialogue state tracking where the dialogues have more than one tasks. Because the manual effort grows exponentially with the complexity of the dialogues. In (Wu et al., 2019), Wu et al. introduced a transferable dialogue state generator (TRADE), which can generate dialogue states from utterances using a copy mechanism. This generative model a"
2020.acl-main.567,W13-4067,0,0.224762,"Missing"
2020.acl-main.567,E17-1042,0,0.10031,"Missing"
2020.acl-main.567,W14-4339,0,0.205831,"Missing"
2020.acl-main.567,P19-1078,0,0.376573,"g model needs a predeﬁned ontology which means the values of every slot are enumerated in advance (Henderson et al., 2014; Mrkˇsi´c et al., 2017; Zhong et al., 2018; Sharma et al., 2019). Such practice is inefﬁcient and costly. The large number of possible slot-value pairs makes deploying these models in the real-life ∗ *Corresponding author. applications difﬁcult (Rastogi et al., 2017). This difﬁculty is further ampliﬁed in multi-domain dialogue state tracking where the dialogues have more than one tasks. Because the manual effort grows exponentially with the complexity of the dialogues. In (Wu et al., 2019), Wu et al. introduced a transferable dialogue state generator (TRADE), which can generate dialogue states from utterances using a copy mechanism. This generative model achieved relative good performance, but it still has trouble in extracting relevant information from the original dialogues. For example, a user may tell the agent that he/she needs a taxi in a turn, but the taxi’s departure location is implicitly mentioned several turns ago. Inspired by the (Chen et al., 2017; Chen, 2018), (Chen et al., 2019) studied on utilizing attention mechanism to deal with the long distance slot carryove"
2020.acl-main.567,P18-1134,0,0.0963239,"the task into multiple domains. MDBT makes full use of the semantic similarities between the dialogue and the slot ontology to track the domain and the value of the slot jointly. GLAD relies on global modules to learn the general information and local modules to catch the slotspeciﬁc information (Zhong et al., 2018) from the dialogues. GCE efﬁciently improves and simpliﬁes GLAD, while keeping the excellent performance of GLAD (Nouri and Hosseini-Asl, 2018). SpanPtr ﬁrst introduces the pointer network (Vinyals et al., 2015) into the dialogue state tracking task to extract unknown slot values (Xu and Hu, 2018). And in that paper, they also apply an effective dropout technique for training. TRADE directly generates slot values from the dialogues by using the copy mechanism and gets rid of the predeﬁned value list (Wu et al., 2019). It achieves the previous state-ofthe-art performance. We use the ﬁx combination version of SAS in Table 1 with the integration ratio α of 0.8 and the threshold β of 0.8. That’s the best hyperparameters we ﬁnd for MultiWOZ. 6 Results In this section, we ﬁrst show the result of our model on MultiWoZ dataset, then on MultiWoZ(restaurant) and MultiWOZ (except hotel) dataset."
2020.acl-main.567,P18-1135,0,0.641353,"ajor difference between dialogue systems and questionanswering is that dialogue systems need to track dialogue history effectively. So, we normally use a dialogue state tracking component to track user’s intention throughout the conversation. A dialogue state is typically composed as a set of slot value pairs in a task-oriented dialogue, such as “hotelinternet-yes”. It means the slot “hotel-internet” has a value of “yes”. Early dialogue state tracking model needs a predeﬁned ontology which means the values of every slot are enumerated in advance (Henderson et al., 2014; Mrkˇsi´c et al., 2017; Zhong et al., 2018; Sharma et al., 2019). Such practice is inefﬁcient and costly. The large number of possible slot-value pairs makes deploying these models in the real-life ∗ *Corresponding author. applications difﬁcult (Rastogi et al., 2017). This difﬁculty is further ampliﬁed in multi-domain dialogue state tracking where the dialogues have more than one tasks. Because the manual effort grows exponentially with the complexity of the dialogues. In (Wu et al., 2019), Wu et al. introduced a transferable dialogue state generator (TRADE), which can generate dialogue states from utterances using a copy mechanism. T"
2020.acl-main.60,D18-1547,0,0.0633278,"Missing"
2020.acl-main.60,N06-1003,0,0.108955,"ski et al., 2018). After dialogs are collected, we also need to annotate dialog states and dialog acts, which are then used to train language understanding models and learn dialog policy. Hiring crowd-sourcing workers to perform these annotations is very costly. Therefore, we propose automated data augmentation methods to expand existing well-annotated dialog datasets, and thereby train better dialog systems. We propose to augment existing dialog data sets through paraphrase. Paraphrase-based dataaugmentation methods have been proved to be useful in various tasks, such as machine translation (Callison-Burch et al., 2006), text classification (Zhang et al., 2015), question answering (Fader et al., 2013) and semantic parsing (Jia and Liang, 2016). All these approaches first find a set of semantically similar sentences. However, finding isolated similar sentences are not enough to construct a dialog utterances’ paraphrase. Because an utterance’s paraphrase must fit the dialog history as well. For example, when the system says “Do you prefer a cheap or expensive restaurant?”, the user may state his intent of asking for a cheap restaurant by “Cheap please.” or “Could you find me a cheap restaurant?” . However, the"
2020.acl-main.60,P17-2090,0,0.0663319,"Missing"
2020.acl-main.60,P13-1158,0,0.0523054,"ialog acts, which are then used to train language understanding models and learn dialog policy. Hiring crowd-sourcing workers to perform these annotations is very costly. Therefore, we propose automated data augmentation methods to expand existing well-annotated dialog datasets, and thereby train better dialog systems. We propose to augment existing dialog data sets through paraphrase. Paraphrase-based dataaugmentation methods have been proved to be useful in various tasks, such as machine translation (Callison-Burch et al., 2006), text classification (Zhang et al., 2015), question answering (Fader et al., 2013) and semantic parsing (Jia and Liang, 2016). All these approaches first find a set of semantically similar sentences. However, finding isolated similar sentences are not enough to construct a dialog utterances’ paraphrase. Because an utterance’s paraphrase must fit the dialog history as well. For example, when the system says “Do you prefer a cheap or expensive restaurant?”, the user may state his intent of asking for a cheap restaurant by “Cheap please.” or “Could you find me a cheap restaurant?” . However, the latter is obviously an improper response which is not coherent with the system que"
2020.acl-main.60,P16-1154,0,0.0600481,"ly the paraphrase decoder decodes the paraphrase Utp based on the hidden states of both the encoder and the action decoder. At−1 h Utp = Seq2Seq(Rt−1 , Ut ) = Seq2Seq(Rt−1 , Ut |h the response generation model to back-propagate to the paraphrase generation model. So the response generation model can guide the paraphrase decoder to generate better paraphrases and vice versa. This process can be formulated as: 0 0 (2) At−1 ) p hBt = Seq2Seq(Rt−1 , Ut , Bt−1 |hUt ) Rt = Seq2Seq(Rt−1 , Ut |hBt ) (3) (4) (5) p where hAt−1 denotes the hidden states of the action decoder. We leverage copy mechanism (Gu et al., 2016) to copy words from input utterances to previous system action and paraphrase. The action decoding process is used to help paraphrase decoding through an attention connection between the decoders, whose significance lies in improving dialog context awareness. Paraphrase Filter. We then send the generated paraphrase into a filter module to determine if it qualifies as an additional training instance. We aim to keep paraphrases that can serve the same dialog function with the original utterance. So we filter out paraphrases that did not include all of the slots mentioned in the original utteranc"
2020.acl-main.60,C18-1105,0,0.135457,"uter vision, many classical data augmentation methods such as random copy (Krizhevsky et al., 2012) and image pair interpolation (Zhang et al., 2017) have been widely used. However, those approaches are not applicable for natural language processing since language is not spatially invariant like images. The word order in a sentence impacts its semantic meaning (Zhang et al., 2015). Therefore, human language augmentation methods aim to generate samples with the same semantic meaning but in different surface forms. Such an idea led to recent augmentation work on the language understanding task (Hou et al., 2018; Kim et al., 2019; Yoo et al., 2019; Zhao et al., 2019). However, there is no data augmentation work on task-oriented dialog generation. Paraphrase is the technique that generates alternative expressions. Most of the existing work on paraphrase aims to improve the quality of generated sentences. For example, phrase dictionary (Cao et al., 2017) and semantic annotations (Wang et al., 2019) are used to assist the paraphrase model to improve the language quality. To make a controllable paraphrase model, syntactic information (Iyyer et al., 2018) is also adopted. And, recently, different levels o"
2020.acl-main.60,N18-1170,0,0.0411893,"augmentation work on the language understanding task (Hou et al., 2018; Kim et al., 2019; Yoo et al., 2019; Zhao et al., 2019). However, there is no data augmentation work on task-oriented dialog generation. Paraphrase is the technique that generates alternative expressions. Most of the existing work on paraphrase aims to improve the quality of generated sentences. For example, phrase dictionary (Cao et al., 2017) and semantic annotations (Wang et al., 2019) are used to assist the paraphrase model to improve the language quality. To make a controllable paraphrase model, syntactic information (Iyyer et al., 2018) is also adopted. And, recently, different levels of granularity (Li et al., 2019b) are considered to make paraphrase decomposable and interpretable. In this paper, we utilize a language environment to assist paraphrase, and use paraphrase as a tool to augment the training data of dialog systems. 3 Proposed Framework In this section, we first introduce how to construct a paraphrase dataset to train paraphrase generation models. Then we describe the work flow of the proposed PARG model. 3.1 Paraphrase Data Construction We propose a three-step procedure to find dialog utterances that are a parap"
2020.acl-main.60,P16-1002,0,0.0271571,"anguage understanding models and learn dialog policy. Hiring crowd-sourcing workers to perform these annotations is very costly. Therefore, we propose automated data augmentation methods to expand existing well-annotated dialog datasets, and thereby train better dialog systems. We propose to augment existing dialog data sets through paraphrase. Paraphrase-based dataaugmentation methods have been proved to be useful in various tasks, such as machine translation (Callison-Burch et al., 2006), text classification (Zhang et al., 2015), question answering (Fader et al., 2013) and semantic parsing (Jia and Liang, 2016). All these approaches first find a set of semantically similar sentences. However, finding isolated similar sentences are not enough to construct a dialog utterances’ paraphrase. Because an utterance’s paraphrase must fit the dialog history as well. For example, when the system says “Do you prefer a cheap or expensive restaurant?”, the user may state his intent of asking for a cheap restaurant by “Cheap please.” or “Could you find me a cheap restaurant?” . However, the latter is obviously an improper response which is not coherent with the system question. In other words, a paraphrased dialog"
2020.acl-main.60,N19-3014,0,0.0237327,"classical data augmentation methods such as random copy (Krizhevsky et al., 2012) and image pair interpolation (Zhang et al., 2017) have been widely used. However, those approaches are not applicable for natural language processing since language is not spatially invariant like images. The word order in a sentence impacts its semantic meaning (Zhang et al., 2015). Therefore, human language augmentation methods aim to generate samples with the same semantic meaning but in different surface forms. Such an idea led to recent augmentation work on the language understanding task (Hou et al., 2018; Kim et al., 2019; Yoo et al., 2019; Zhao et al., 2019). However, there is no data augmentation work on task-oriented dialog generation. Paraphrase is the technique that generates alternative expressions. Most of the existing work on paraphrase aims to improve the quality of generated sentences. For example, phrase dictionary (Cao et al., 2017) and semantic annotations (Wang et al., 2019) are used to assist the paraphrase model to improve the language quality. To make a controllable paraphrase model, syntactic information (Iyyer et al., 2018) is also adopted. And, recently, different levels of granularity (Li"
2020.acl-main.60,P18-1133,0,0.259536,"omising performance on dialog generation tasks if given a huge data set. However, the lack of high-quality dialog data and the expensive data annotation process greatly limit their application in real-world settings. We propose a paraphrase augmented response generation (PARG) framework that jointly trains a paraphrase model and a response generation model to improve the dialog generation performance. We also design a method to automatically construct paraphrase training data set based on dialog state and dialog act labels. PARG is applicable to various dialog generation models, such as TSCP (Lei et al., 2018) and DAMD (Zhang et al., 2019). Experimental results show that the proposed framework improves these state-of-the-art dialog models further on CamRest676 and MultiWOZ. PARG also significantly outperforms other data augmentation methods in dialog generation tasks, especially under low resource settings. 1 2 1 Introduction Task-oriented dialog systems that are applied to restaurant reservation and ticket booking have attracted extensive attention recently (Young et al., 2013; Wen et al., 2017; Bordes et al., 2016; Eric and Manning, 2017). Specifically, with the progress on sequence-to-sequence ("
2020.acl-main.60,P19-1332,0,0.028759,"019; Yoo et al., 2019; Zhao et al., 2019). However, there is no data augmentation work on task-oriented dialog generation. Paraphrase is the technique that generates alternative expressions. Most of the existing work on paraphrase aims to improve the quality of generated sentences. For example, phrase dictionary (Cao et al., 2017) and semantic annotations (Wang et al., 2019) are used to assist the paraphrase model to improve the language quality. To make a controllable paraphrase model, syntactic information (Iyyer et al., 2018) is also adopted. And, recently, different levels of granularity (Li et al., 2019b) are considered to make paraphrase decomposable and interpretable. In this paper, we utilize a language environment to assist paraphrase, and use paraphrase as a tool to augment the training data of dialog systems. 3 Proposed Framework In this section, we first introduce how to construct a paraphrase dataset to train paraphrase generation models. Then we describe the work flow of the proposed PARG model. 3.1 Paraphrase Data Construction We propose a three-step procedure to find dialog utterances that are a paraphrase of each other. First, we perform delexicalization to pre-process dialog utt"
2020.acl-main.60,W19-5921,0,0.0882752,"Missing"
2020.acl-main.60,P02-1040,0,0.107443,"is different from asking for a restaurant. The previous system act is considered to ensure a coherent dialog context, since each turn’s user utterance is a reply to the previous system response. Fig.1 gives out an example of dialog function. For each user utterance in the dialog dataset, we go through all the available training data and find all utterances with the same dialog function as paraphrase candidates of it. As each utterance may have many paraphrase candidates, we only keep the high-quality paraphrase pairs that are similar in semantic but different in surface form. We use the BLEU (Papineni et al., 2002) score and the diversity score proposed in Hou et al. (2018) to evaluate the paraphrase qualAction Decoder Attention Copy Paraphrase Generation Model Sure. Which kind of food would you like? DFt = (Dt , St , At−1 ) Copy Copy Paraphrase Decoder ?? ???? Attention Belief Span Decoder Copy Copy Response Decoder ???? Figure 2: Overview of our Paraphrase Augmented Response Generation (PARG) framework. Solid arrows denote the input or output word sequence. Dash arrows denote hidden states shared between modules. Ut , Bt and Rt represent turn t’s user utterance, dialog state and system response respec"
2020.acl-main.60,P15-2070,0,0.0508384,"Missing"
2020.acl-main.60,E17-1042,0,0.103067,"Missing"
2020.acl-main.60,W17-5505,0,0.0606787,"Missing"
2020.acl-main.60,D19-1375,0,0.0852235,"such as random copy (Krizhevsky et al., 2012) and image pair interpolation (Zhang et al., 2017) have been widely used. However, those approaches are not applicable for natural language processing since language is not spatially invariant like images. The word order in a sentence impacts its semantic meaning (Zhang et al., 2015). Therefore, human language augmentation methods aim to generate samples with the same semantic meaning but in different surface forms. Such an idea led to recent augmentation work on the language understanding task (Hou et al., 2018; Kim et al., 2019; Yoo et al., 2019; Zhao et al., 2019). However, there is no data augmentation work on task-oriented dialog generation. Paraphrase is the technique that generates alternative expressions. Most of the existing work on paraphrase aims to improve the quality of generated sentences. For example, phrase dictionary (Cao et al., 2017) and semantic annotations (Wang et al., 2019) are used to assist the paraphrase model to improve the language quality. To make a controllable paraphrase model, syntactic information (Iyyer et al., 2018) is also adopted. And, recently, different levels of granularity (Li et al., 2019b) are considered to make"
2020.emnlp-main.148,N19-1423,0,0.0251664,"oser to the ground truth and better. Our method with BERT, VRNN-LinearCRF-BERT performs the best. K-means clustering performs worse than VRNN-based models because it only considers utterances’ surface format and ignores the context information. Hidden Markov Model is similar to VRNN but lacks a continuous propagating hidden state layer. VRNN-LinearCRF observes the entire history of latent states but ignores the redundant transitions due to the structure attention. The model’s performance further improves when replacing the vanilla LSTM encoder with a large scale pre-trained encoder like BERT (Devlin et al., 2019), as BERT provides better representations. greeting request a bus 0.93 request #from_loc inform #from_loc 0.95 Figure 5: All models’ performance in (a) Structure Euclidean Distance (SED) and (b) Structure CrossEntropy (SCE) in four dialogue domains. request #to_loc inform #to_loc 0.93 request #datetime inform #datetime 0.26 inform default request #duration 0.84 inform duration goodbye 0.64 0.10 inform default goodbye 0.14 0.96 0.97 goodbye silence 5.2 inform default request #arrival 0.16 0.95 0.78 inform arrival goodbye Figure 4: Learned semantic structure of SimDial bus domain (Zhao and Esken"
2020.emnlp-main.148,P08-1095,0,0.302082,"of VRNNs and Hierarchical Recurrent Encoder-Decoder (HRED) (Sordoni et al., 2015) for dialogue generation. Similarly, Zhao et al. (2018) proposed to use VAEs to learn discrete sentence representations. Shi et al. (2019) used two variants of VRNNs to learn the dialogue semantic structures and discussed how to use learned structure to improve reinforcement learning-based dialogue systems. But none of the previous work has tried to incorporate structured attention in VRNNs to learn dialogue structure. Compared to semantic structures, the interactive structure of dialogues is not clearly defined. Elsner and Charniak (2008) initiated some work about dialogue disentanglement, which is defined as dividing a transcript into a set of distinct conversations. Serban and Pineau (2015) tested standard RNN and its conditional variant for turn taking and speaker identification. Both of the tasks are highly related to understanding the interactive structure but not identical. Our task, different from both of them, aims to construct an utterance dependency tree to represent a multi-party dialogue’s turn taking. The tree can not only be used to disentangle the conversations but also label each utterance’s speakers and addres"
2020.emnlp-main.148,N19-1357,0,0.0300816,"dependency tree attention layer is embedded to learn an interactive structure that could help identify speaker/addressee information in multi-party dialogues that have tangled conversation threads, such as forum discussions. This paper makes the following contributions. We propose to incorporate a structured attention layer in VRNN to learn latent structures in dialogues. To our knowledge, no work connecting Related Work Attention mechanism (Vaswani et al., 2017) has been widely adopted as a way for embedding categorical inference in neural networks for performance gain and interpretability (Jain and Wallace, 2019; Wiegreffe and Pinter, 2019). However, for many tasks, we want to model richer structural dependencies without abandoning end-to-end training. Structured Attention Networks (Kim et al., 2017) can extend attention beyond the standard soft-selection approach by attending to partial segments or subtrees. People have proven its effectiveness on a variety of synthetic and real tasks: tree transduction, neural machine translation, question answering, and natural language inference (Rush, 2020). In this paper, we propose to utilize structured attention to explore dialogue structures. Specifically, w"
2020.emnlp-main.148,N10-1008,0,0.0463059,"Missing"
2020.emnlp-main.148,W15-4640,0,0.134606,"on Liang Qiu1 , Yizhou Zhao1 , Weiyan Shi2 , Yuan Liang3 , Feng Shi1 , Tao Yuan1 , Zhou Yu2 , Song-Chun Zhu1 1 UCLA Center for Vision, Cognition, Learning, and Autonomy 2 University of California, Davis 3 University of California, Los Angeles {liangqiu,yizhouzhao,liangyuandg,shifeng,taoyuan}@ucla.edu {wyshi,joyu}@ucdavis.edu sczhu@stat.ucla.edu Abstract example dialogue as shown in Table 1. Another interesting type of dialogue structure is the interactive structure in multi-party dialogues. Figure 2 illustrates the interactive structure we learned from a dialogue sample in Ubuntu Chat Corpus (Lowe et al., 2015). Each node represents an utterance from different speakers in the dialogue with darker linkages represent stronger dependency relations between utterances. When speaker/addressee information is unavailable in the corpus, learning such a structure allows disentangling the conversation (Serban and Pineau, 2015) and estimating the speaker labels. Discovering dialogue structures is crucial for various areas in computational linguistics, such as dialogue system building (Young, 2006), discourse analysis (Grosz and Sidner, 1986), and dialogue summarization (Murray et al., 2005; Liu et al., 2010). T"
2020.emnlp-main.148,D14-1162,0,0.0891522,", a,b∈{1,2,...,N } (16) where Ts0a ,sb is the learned transition probability from state sa to state sb and Tsa ,sb is the true transition probability. 5.1.3 Results and Analysis We compare the proposed VRNN-LinearCRF against other unsupervised methods: K-means clustering, Hidden Markov Model, D-VRNN (Shi et al., 2019) and VRNN with vanilla attention. D-VRNN is similar to our work but without structured attention. We use a bidirectional LSTM with 300 hidden units as the sentence encoder and a forward LSTM for decoding. 300-dimensional word embeddings are initialized with GloVe word embedding (Pennington et al., 2014). A dropout rate of 0.5 is adopted during training. We set the BOWloss weight λ to be 0.5. The whole network is trained with the Adam optimizer with a learning rate of 0.001 on GTX Titan X GPUs for 60 epochs. The training takes on average 11.2 hours to finish. ground truth dialogue structure in Figure 1. A dialogue structure learned by VRNN without structured attention is also shown in the Appendix. We find our method generates similar structure compared to ground truth in the bus domain. Figure 5 shows all models’ quantitative results. Having a lower value in SED and SCE indicates the learned"
2020.emnlp-main.148,N10-1020,0,0.056687,"ing, and natural language inference (Rush, 2020). In this paper, we propose to utilize structured attention to explore dialogue structures. Specifically, we work on two types of dialogue structures, semantic structures (dialogue intent transitions), and interactive structures (addressee/speaker changes). Semantic structures have been studied extensively. Some previous works, such as (Jurafsky, 1997), learned semantic structures relying on human annotations, while such annotations are costly and can vary in quality. Other unsupervised studies used Hidden Markov Model (HMM) (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014). Recently, Variational Autoencoders (VAEs) (Kingma and Welling, 2013) and their recurrent version, Variational Recurrent Neural Networks (VRNNs) (Chung et al., 2015), connects neural networks and traditional Bayes methods. Because VRNNs apply a point-wise nonlinearity to the output at every timestamp, they are 1890 also more suitable to model highly non-linear dynamics over the simpler dynamic Bayesian network models. Serban et al. (2017) proposed the VHRED model by combining the idea of VRNNs and Hierarchical Recurrent Encoder-Decoder (HRED) (Sordoni et al., 2015) f"
2020.emnlp-main.148,2020.acl-demos.38,0,0.0140215,"r embedding categorical inference in neural networks for performance gain and interpretability (Jain and Wallace, 2019; Wiegreffe and Pinter, 2019). However, for many tasks, we want to model richer structural dependencies without abandoning end-to-end training. Structured Attention Networks (Kim et al., 2017) can extend attention beyond the standard soft-selection approach by attending to partial segments or subtrees. People have proven its effectiveness on a variety of synthetic and real tasks: tree transduction, neural machine translation, question answering, and natural language inference (Rush, 2020). In this paper, we propose to utilize structured attention to explore dialogue structures. Specifically, we work on two types of dialogue structures, semantic structures (dialogue intent transitions), and interactive structures (addressee/speaker changes). Semantic structures have been studied extensively. Some previous works, such as (Jurafsky, 1997), learned semantic structures relying on human annotations, while such annotations are costly and can vary in quality. Other unsupervised studies used Hidden Markov Model (HMM) (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014). R"
2020.emnlp-main.148,N19-1178,1,0.912854,"rsion, Variational Recurrent Neural Networks (VRNNs) (Chung et al., 2015), connects neural networks and traditional Bayes methods. Because VRNNs apply a point-wise nonlinearity to the output at every timestamp, they are 1890 also more suitable to model highly non-linear dynamics over the simpler dynamic Bayesian network models. Serban et al. (2017) proposed the VHRED model by combining the idea of VRNNs and Hierarchical Recurrent Encoder-Decoder (HRED) (Sordoni et al., 2015) for dialogue generation. Similarly, Zhao et al. (2018) proposed to use VAEs to learn discrete sentence representations. Shi et al. (2019) used two variants of VRNNs to learn the dialogue semantic structures and discussed how to use learned structure to improve reinforcement learning-based dialogue systems. But none of the previous work has tried to incorporate structured attention in VRNNs to learn dialogue structure. Compared to semantic structures, the interactive structure of dialogues is not clearly defined. Elsner and Charniak (2008) initiated some work about dialogue disentanglement, which is defined as dividing a transcript into a set of distinct conversations. Serban and Pineau (2015) tested standard RNN and its conditi"
2020.emnlp-main.148,W18-5001,0,0.437159,"icit human annotation.1 1 Introduction greeting request a bus Grammatical induction for capturing a structural representation of knowledge has been studied for some time (De la Higuera, 2010). Given the achievement in related areas like learning Hidden Markov acoustic models in speech recognition (Bahl et al., 1986) and sentence dependency parsing in language understanding (Covington, 2001), our work aims to explore a more sophisticated topic: learning structures in dialogues. Figure 1 shows the underlying semantic structure of conversations about bus information request from SimDial dataset (Zhao and Eskenazi, 2018), with one 1 The code is released at https://github.com/ Liang-Qiu/SVRNN-dialogues. request #from_loc inform #from_loc request #to_loc inform #to_loc inform default inform #from_loc 0.01 0.26 request #datetime inform #datetime 0.01 0.49 0.23 inform default inform #to_loc inform default request #duration inform default goodbye inform default request #arrival inform duration goodbye goodbye silence inform arrival goodbye Figure 1: Original dialogue structure of the bus information request domain in SimDial (Zhao and Eskenazi, 2018). User intents are marked in bold. 1889 Proceedings of the 2020 C"
2020.emnlp-main.148,P18-1101,0,0.0209048,"y, Variational Autoencoders (VAEs) (Kingma and Welling, 2013) and their recurrent version, Variational Recurrent Neural Networks (VRNNs) (Chung et al., 2015), connects neural networks and traditional Bayes methods. Because VRNNs apply a point-wise nonlinearity to the output at every timestamp, they are 1890 also more suitable to model highly non-linear dynamics over the simpler dynamic Bayesian network models. Serban et al. (2017) proposed the VHRED model by combining the idea of VRNNs and Hierarchical Recurrent Encoder-Decoder (HRED) (Sordoni et al., 2015) for dialogue generation. Similarly, Zhao et al. (2018) proposed to use VAEs to learn discrete sentence representations. Shi et al. (2019) used two variants of VRNNs to learn the dialogue semantic structures and discussed how to use learned structure to improve reinforcement learning-based dialogue systems. But none of the previous work has tried to incorporate structured attention in VRNNs to learn dialogue structure. Compared to semantic structures, the interactive structure of dialogues is not clearly defined. Elsner and Charniak (2008) initiated some work about dialogue disentanglement, which is defined as dividing a transcript into a set of d"
2020.emnlp-main.148,P17-1061,0,0.0192759,"rrent Neural Network (VRNN) is to compress the essential information of the dialogue history into a lower-dimensional latent code. The latent code z is a random vector sampled from a prior p(z) and the data generation model is described by p(x|z). The VRNN contains a Variational Autoencoder (VAE) at each time step. The VAE consists of an encoder qλ (z|x) for approximating the posterior p(z|x), and a decoder pθ (x|z) i + log p(xt |z≤t , x&lt;t )) . (5) In addition, to mitigate the vanishing latent variable problem in VAE, we incorporate Bag-ofWords (BOW) loss and Batch Prior Regularization (BPR) (Zhao et al., 2017) with a tunable weight λ. By adjusting the λ, the VRNN based models can achieve a balance between clustering the utterance surface formats and attention on the context. 1892 4.2 Linear CRF Attention Algorithm 1: Forward-Backward for LinearCRF Attention Input: potential θ α[0, hti] ← 0 β[n + 1, hti] ← 0 for i = 1, ...,L n; c ∈ C do α[i, c] ← y α[i − 1, y] ⊗ θi−1,i [y, c] end for for i = n, ...,L 1; c ∈ C do β[i, c] ← y β[i + 1, y] ⊗ θi,i+1 [c, y] end for A ← α[n + 1, hti] for i = 1, ..., n; c ∈ C do p(ξi = c|x) ← exp(α[i, c] ⊗ β[i, c] ⊗ −A) end for return p As we formulate the semantic structur"
2020.emnlp-main.148,D19-1002,0,0.0169794,"on layer is embedded to learn an interactive structure that could help identify speaker/addressee information in multi-party dialogues that have tangled conversation threads, such as forum discussions. This paper makes the following contributions. We propose to incorporate a structured attention layer in VRNN to learn latent structures in dialogues. To our knowledge, no work connecting Related Work Attention mechanism (Vaswani et al., 2017) has been widely adopted as a way for embedding categorical inference in neural networks for performance gain and interpretability (Jain and Wallace, 2019; Wiegreffe and Pinter, 2019). However, for many tasks, we want to model richer structural dependencies without abandoning end-to-end training. Structured Attention Networks (Kim et al., 2017) can extend attention beyond the standard soft-selection approach by attending to partial segments or subtrees. People have proven its effectiveness on a variety of synthetic and real tasks: tree transduction, neural machine translation, question answering, and natural language inference (Rush, 2020). In this paper, we propose to utilize structured attention to explore dialogue structures. Specifically, we work on two types of dialog"
2020.emnlp-main.148,P14-1004,0,0.281535,"uage inference (Rush, 2020). In this paper, we propose to utilize structured attention to explore dialogue structures. Specifically, we work on two types of dialogue structures, semantic structures (dialogue intent transitions), and interactive structures (addressee/speaker changes). Semantic structures have been studied extensively. Some previous works, such as (Jurafsky, 1997), learned semantic structures relying on human annotations, while such annotations are costly and can vary in quality. Other unsupervised studies used Hidden Markov Model (HMM) (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014). Recently, Variational Autoencoders (VAEs) (Kingma and Welling, 2013) and their recurrent version, Variational Recurrent Neural Networks (VRNNs) (Chung et al., 2015), connects neural networks and traditional Bayes methods. Because VRNNs apply a point-wise nonlinearity to the output at every timestamp, they are 1890 also more suitable to model highly non-linear dynamics over the simpler dynamic Bayesian network models. Serban et al. (2017) proposed the VHRED model by combining the idea of VRNNs and Hierarchical Recurrent Encoder-Decoder (HRED) (Sordoni et al., 2015) for dialogue generation. Si"
2020.emnlp-main.355,N18-1197,0,0.0406355,"Missing"
2020.emnlp-main.355,P18-1175,0,0.0719784,"Missing"
2020.emnlp-main.355,2020.acl-main.126,1,0.573659,"Missing"
2020.emnlp-main.355,2020.acl-main.436,0,0.0861825,"ciding factor to distinguish California gull and ringbilled gull. If we receive abstract knowledge from human experts through a natural language format, such as “Ring-billed gull has a bill with a black ring near the tip while California gull has a red spot near the tip of lower mandible” and incorporate it in the model, then the model will discover that Image A is a California gull instead of a ringbilled gull based on its bill. Previous work has shown that incorporating natural language explanation into the classification training loop is effective in various settings (Andreas et al., 2018; Mu et al., 2020). However, previous work neglects the fact that there is usually a limited time budget to interact with domain experts (e.g., medical experts, biologists) (Liang et al., 2019, 2020) and high-quality natural language explanations are expensive, by nature. Therefore, we focus on eliciting fewer but more informative explanations to reduce expert involvement. We propose Active Learning with Contrastive Explanations (ALICE), an expert-in-the-loop training framework that utilizes contrastive natural language explanations to improve data efficiency in learning. Although we focus on image classificati"
2020.emnlp-main.355,2020.acl-main.190,0,0.0195334,"Missing"
2020.emnlp-main.355,D17-1161,0,0.0507044,"Missing"
2020.emnlp-main.355,D08-1004,0,0.129033,"Missing"
2020.emnlp-main.654,N19-1423,0,0.0151782,"Missing"
2020.emnlp-main.654,2020.lrec-1.71,0,0.0396594,"Missing"
2020.emnlp-main.654,W93-0231,0,0.634024,"Missing"
2020.emnlp-main.654,D19-1203,1,0.7887,"isney + and Dataset and code are available at https://github. com/sweetpeach/Inspired No problem! Hope you enjoy it as I did! Figure 1: An example snippet of human-human recommendation dialog in I NSPIRED. REC refers a person who recommends a movie and SEEK refers a person who looks for a recommendation. Above each recommender’s utterance is the recommendation strategy annotated by human workers. Best seen in colors. lect the dataset in scenario-based settings or convert product review datasets into question-answering conversations (Reschke et al., 2013; Yan et al., 2017; Sun and Zhang, 2018; Kang et al., 2019; Li et al., 2018). Common issues with these types of datasets are: (1) homologous utterances, (2) mostly question-answering pairs, and (3) lack of user engagement. In this work, we aim to validate whether sociable recommendation strategies are effective for making a successful recommendation in a dialog. To do so, 8142 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 8142–8152, c November 16–20, 2020. 2020 Association for Computational Linguistics Dataset Naturalness Sociable Strategies Movie Information Conversation Types #Dialogs #Utterances I NS"
2020.emnlp-main.654,D17-2014,0,0.0672027,"Missing"
2020.emnlp-main.654,P02-1040,0,0.110788,"prepend method. 8149 PPL↓ BLEU-4↑ 24 Baseline Strategy 9.28 8.93 5.11 6.63 20 #Participants Model Table 7: Results for automatic metrics. proxy to decide whether the system needs to recommend a movie or not, it is not strictly supervised. Thus, if a generated sentence is labeled as “recommendation”, we enforce our dialog system to recommend a new movie. 6.3 Results We compare the baseline dialog model without strategy supervision against our dialog model with strategy supervision. We use both automatic metrics and human evaluation. For automatic metrics, we compute perplexity and BLEU scores (Papineni et al., 2002), suggesting that prepending strategies improves the model performance as shown in Table 7. For human evaluation, twenty-eight participants chat with both models for 2-3 times for a more reliable judgment. We randomize which model they will chat first, in order to avoid exposure bias. After chatting, they are asked to decide which model is better in these five aspects: fluency, consistency, naturalness, persuasiveness, and engagingness. If they are unable to distinguish the dialog systems, they are allowed to choose “can’t tell” option. Results in Figure 5 suggest that human users prefer the m"
2020.emnlp-main.654,W19-5941,0,0.124054,"on the movie 8143 3 Recommendation Dialog Collection 3.1 Movie Database Creation To ensure that the recommended movie has trailers and metadata information, we curate a database 2 with all movie trailers from Movieclips Trailer released between 2008 and 2020, and movies from MovieLens dataset (Harper and Konstan, 2015). In total, we have 17,869 movies with trailers and metadata information. We design a simple movie search interface (Figure 2) to assist recommenders in searching for a movie. Figure 2: Movie search interface for recommenders. preference. 3.2 Our work is also closely related to Radlinski et al. (2019) on movie preference elicitation and Fabian Galetzka1 (2020) on movie discussion in the dialog setting. Preference elicitation is an important step for the human recommender to comprehend seeker’s taste before recommendation, but these datasets are not recommendation conversations. We recruit crowd-workers from Amazon Mechanical Turk. In each conversation, two workers are randomly paired and assigned different roles: one as a recommender and another as a seeker. Our collection set-up is more realistic compared to prior works as (1) recommenders have no limitations of the number of movies to re"
2020.emnlp-main.654,P19-1534,0,0.038469,"Missing"
2020.emnlp-main.654,P13-2089,0,0.479362,"l1 PERSONAL EXPERIENCE REC: Yeah, I love Disney too! I have Disney + and Dataset and code are available at https://github. com/sweetpeach/Inspired No problem! Hope you enjoy it as I did! Figure 1: An example snippet of human-human recommendation dialog in I NSPIRED. REC refers a person who recommends a movie and SEEK refers a person who looks for a recommendation. Above each recommender’s utterance is the recommendation strategy annotated by human workers. Best seen in colors. lect the dataset in scenario-based settings or convert product review datasets into question-answering conversations (Reschke et al., 2013; Yan et al., 2017; Sun and Zhang, 2018; Kang et al., 2019; Li et al., 2018). Common issues with these types of datasets are: (1) homologous utterances, (2) mostly question-answering pairs, and (3) lack of user engagement. In this work, we aim to validate whether sociable recommendation strategies are effective for making a successful recommendation in a dialog. To do so, 8142 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 8142–8152, c November 16–20, 2020. 2020 Association for Computational Linguistics Dataset Naturalness Sociable Strategies Movi"
2020.emnlp-main.654,P18-1140,1,0.816388,"e preference, and (3) we record if seekers actually watch the video trailer or not. Meanwhile, dialogs in I NSPIRED have both stages: preference elicitation and recommendation. I NSPIRED also captures sociable recommendation strategies in conversations and measures recommendation with ratings. Sociability in dialog systems. In human-human conversations, people engage in a talk that does not only contain task-oriented topics (Bickmore and Cassell, 2005). Thus, sociability has raised more attention in dialog systems as they become more sociable, engaging, and user-adaptive (Zhang et al., 2018a; Shi and Yu, 2018; G¨oker and Thompson, 2000). Zhang et al. (2018a) proposed a chit-chat dataset and presented the task of more personalized dialogs system conditioned on user profile information. Sociability leads to a more persuasive conversation (Yoo et al., 2012), so social skills are essential for dialog systems to make successful recommendations. Communication strategies on specific tasks, such as donation and product price negotiation, have been found useful for task completion (Wang et al., 2019; Zhou et al., 2019). In this work, we connect different sociable strategies with recommendation in dialog se"
2020.emnlp-main.654,D13-1170,0,0.00503279,"Missing"
2020.emnlp-main.654,P18-1205,0,0.232928,"n strategies. Conversational recommendation systems. While studies on conversational recommendation systems have been done, none of them focus on the sociable recommendation strategies for persuasive outcome. This is is due to the lack of existing datasets for studying effective strategies in recommendation dialog. Table 1 compares different factors across the recommendation dialog datasets including I NSPIRED. Prior works on recommendation dialogs collect data based on template-based question-answering pairs from user reviews (Thompson et al., 2004; Reschke et al., 2013; Sun and Zhang, 2018; Zhang et al., 2018b). These datasets contain structured utterances where the recommender continuously asks for the seeker’s product preference. Kang et al. (2019) collected goal-driven recommendation dialogs (G O R EC D IAL) in a gamified setting where both speakers are given a small set of movies with descriptions to find the best recommendation. This role-play game setting may not effectively reflect the real-world situation since the seeker pretends that they like the given movies. The most similar work to ours is Li et al. (2018)’s R E D IAL dataset which consists of chit-chats for movie recommendation. How"
2020.emnlp-main.654,W19-5943,0,0.0833103,"og systems as they become more sociable, engaging, and user-adaptive (Zhang et al., 2018a; Shi and Yu, 2018; G¨oker and Thompson, 2000). Zhang et al. (2018a) proposed a chit-chat dataset and presented the task of more personalized dialogs system conditioned on user profile information. Sociability leads to a more persuasive conversation (Yoo et al., 2012), so social skills are essential for dialog systems to make successful recommendations. Communication strategies on specific tasks, such as donation and product price negotiation, have been found useful for task completion (Wang et al., 2019; Zhou et al., 2019). In this work, we connect different sociable strategies with recommendation in dialog settings and show that sociable strategies have a positive impact on recommendation success. Recommendation Task Recommender. Recommenders’ task is to recommend a movie successfully to the seeker. Before chatting, we show them tips for sociable recommendation strategies with example utterances. Then they chat with the seekers in two phases: user information gathering and movie recommendation. In the user information gathering phase, recommenders are asked to understand the seekers’ movie tastes. In the recom"
2020.emnlp-main.654,P19-1566,1,0.917801,"e attention in dialog systems as they become more sociable, engaging, and user-adaptive (Zhang et al., 2018a; Shi and Yu, 2018; G¨oker and Thompson, 2000). Zhang et al. (2018a) proposed a chit-chat dataset and presented the task of more personalized dialogs system conditioned on user profile information. Sociability leads to a more persuasive conversation (Yoo et al., 2012), so social skills are essential for dialog systems to make successful recommendations. Communication strategies on specific tasks, such as donation and product price negotiation, have been found useful for task completion (Wang et al., 2019; Zhou et al., 2019). In this work, we connect different sociable strategies with recommendation in dialog settings and show that sociable strategies have a positive impact on recommendation success. Recommendation Task Recommender. Recommenders’ task is to recommend a movie successfully to the seeker. Before chatting, we show them tips for sociable recommendation strategies with example utterances. Then they chat with the seekers in two phases: user information gathering and movie recommendation. In the user information gathering phase, recommenders are asked to understand the seekers’ movie"
2020.findings-emnlp.282,D11-1141,0,0.236582,"target task could borrow from the source task, and larger DS is. If researchers want to simplify the hyper-parameters tuning process or constrain the influence of source data, α can be set by DS : α = DS · (1 − λ)/B 3 (5) Experimental Design We validate it by two popular model LSTM and BERT on three tasks: named entity recognition (NER), part-of-speech tagging (POS), and chunking. These tasks have much better performance on formal text (such as news) than informal text (such as tweets). 3.1 Datasets We use OntoNotes-nw (Ralph Weischedel, 2013) as the source dataset, and Ritter11-NER dataset (Ritter et al., 2011) as the target dataset to validate the NER task. While we use Penn Treebank (PTB) POS tagging dataset (Mitchell P. Marcus, 1999) as the source data set, and Ritter11-POS (Ritter et al., 2011) as the target dataset in the POS tagging task. For the chunking task, we use CoNLL 2000 (Sang and Buchholz, 2000) as the source dataset, and Ritter11-CHUNK (Ritter et al., 2011) as the target dataset. Please refer to Appendix B for more details about datasets. 3.2 Model Setting We implemented BERT and LSTM to validate the effect of data annealing on all three tasks. BERT. We implemented both BERTBASE mode"
2020.findings-emnlp.282,D18-1275,0,0.0499561,"Missing"
2020.findings-emnlp.282,W00-0726,0,0.327911,"tasks: named entity recognition (NER), part-of-speech tagging (POS), and chunking. These tasks have much better performance on formal text (such as news) than informal text (such as tweets). 3.1 Datasets We use OntoNotes-nw (Ralph Weischedel, 2013) as the source dataset, and Ritter11-NER dataset (Ritter et al., 2011) as the target dataset to validate the NER task. While we use Penn Treebank (PTB) POS tagging dataset (Mitchell P. Marcus, 1999) as the source data set, and Ritter11-POS (Ritter et al., 2011) as the target dataset in the POS tagging task. For the chunking task, we use CoNLL 2000 (Sang and Buchholz, 2000) as the source dataset, and Ritter11-CHUNK (Ritter et al., 2011) as the target dataset. Please refer to Appendix B for more details about datasets. 3.2 Model Setting We implemented BERT and LSTM to validate the effect of data annealing on all three tasks. BERT. We implemented both BERTBASE model and BERTLARGE model. CRF has been validated as a good classifier by many researchers (Lafferty et al., 2001; Tseng et al., 2005). We use CRF as a decoder on the top of the BERT structure. In some tasks, the source dataset and target dataset do not have the same set of labels. Therefore, we use two sepa"
2020.findings-emnlp.282,W18-5104,0,0.0175158,"g is simulated annealing (Bertsimas and Tsitsiklis, 1993). It reduces the probability of a model converging to a bad local optimal by introducing random noise in the training process. Data annealing has similar functionality with simulated annealing but replaces random noise with source data. By doing this, the model explores more space at the beginning of the training process and is guided by the knowledge learned from the source domain. Current state-of-the-art models on informal language tasks are usually designed specifically for a particular task and cannot generalize to different tasks (Kshirsagar et al., 2018; Gui et al., 2018). Data annealing is model-independent and could be employed in various informal language tasks. We validate our learning procedure with two popular neural network models in NLP, LSTM, and BERT, on three popular natural language understanding tasks, i.e., named entity recognition (NER), partof-speech (POS) tagging and chunking on twitter. When BERT is fine-tuned with data annealing procedure, it outperforms all three state-of-the-art models with the same structure. By doing this, we also set the new state-of-the-art result for the three 3153 Findings of the Association for Co"
2020.findings-emnlp.282,I05-3027,0,0.016229,"P. Marcus, 1999) as the source data set, and Ritter11-POS (Ritter et al., 2011) as the target dataset in the POS tagging task. For the chunking task, we use CoNLL 2000 (Sang and Buchholz, 2000) as the source dataset, and Ritter11-CHUNK (Ritter et al., 2011) as the target dataset. Please refer to Appendix B for more details about datasets. 3.2 Model Setting We implemented BERT and LSTM to validate the effect of data annealing on all three tasks. BERT. We implemented both BERTBASE model and BERTLARGE model. CRF has been validated as a good classifier by many researchers (Lafferty et al., 2001; Tseng et al., 2005). We use CRF as a decoder on the top of the BERT structure. In some tasks, the source dataset and target dataset do not have the same set of labels. Therefore, we use two separate CRF decoder for source task and target task. LSTM. We used character and word embedding as input features following previous works (Yang and Zhang, 2018; Yang et al., 2017). We use one layer bidirectional LSTM to process the input features. For the same reason as in the implementation of BERT, we use two separate CRF classifiers on the top of the LSTM structure. 3154 Figure 1: Performance on named entity recognition"
2020.findings-emnlp.282,D18-1226,0,0.0149451,"models and complicated adaptation methods. Meanwhile, our proposed data annealing algorithm is applied to the same structure without fancy decoration across different tasks. Within our appropriate range set of (0.9, 0.99) for α and λ, we find the data annealing consistently outperforms other transfer learning methods and the state-of-the-art method. In most cases, it is a moderate annealing speed that leads to an optimal result. We noticed that the improvement in recently reported literature on these tasks is usually less than 0.5 in absolute value on either F1 or accuracy (Gui et al., 2018; Lin and Lu, 2018). Our data annealing moves the state-of-the-art performance a big step forward. For more experiment detail such as hyper-parameters, please refer to Appendix C Named Entity Recognition (NER). Our annealing procedure outperforms other transfer learning procedures in terms of F1 , meaning our data annealing is especially effective in striking a balance between the precision and recall in extracting named entities. Usually, a sentence contains more words that are not entities. So if the model is not sure whether a word is an entity, the model is likely to predict it as not an entity in order to r"
2020.findings-emnlp.282,P18-4013,0,0.050782,"e advantages of a proper parameter initialization from the clean nature of formal data. The proportion of source data keeps decreasing exponentially while the proportion of target data keeps increasing, which empowers the model with more freedom to explore the direction of its next update. The philosophy behind data annealing is shared with other commonly used annealing techniques. One popular usage of annealing is learning rate annealing. A gradually decayed learning rate enhances the model with more freedom of exploration at the beginning and leads to better model performance (Zeiler, 2012; Yang and Zhang, 2018; Devlin et al., 2018). Another widespread implementation of annealing is simulated annealing (Bertsimas and Tsitsiklis, 1993). It reduces the probability of a model converging to a bad local optimal by introducing random noise in the training process. Data annealing has similar functionality with simulated annealing but replaces random noise with source data. By doing this, the model explores more space at the beginning of the training process and is guided by the knowledge learned from the source domain. Current state-of-the-art models on informal language tasks are usually designed specific"
2020.findings-emnlp.282,D16-1046,0,0.0164324,"used character and word embedding as input features following previous works (Yang and Zhang, 2018; Yang et al., 2017). We use one layer bidirectional LSTM to process the input features. For the same reason as in the implementation of BERT, we use two separate CRF classifiers on the top of the LSTM structure. 3154 Figure 1: Performance on named entity recognition task. DA BERTLARGE indicates Vanilla BERTLARGE finetuned with data annealing. We compare data annealing with two popular transfer learning paradigms, parameter initialization (INIT) and multi-task learning (MULT) (Weiss et al., 2016; Mou et al., 2016). Now we introduce the training procedure in experiments. Data annealing. In all data annealing experiments, the initial source data ratio α and decay rate λ are tuned in range (0.9, 0.99). When training the BERT model, we also calculated the estimated total batches from source data DS that fed into the model by equation 5. By avoiding a large DS , the model has a lower probability of suffering from catastrophic forgetting as mentioned in section 2. MULT. Multi-task transfer learning optimizes an auxiliary task to improve the performance on the target task. We implemented MULT on both LSTM-CRF"
2020.findings-emnlp.282,2020.emnlp-demos.2,0,0.0131074,"e BERT models receive high performance by both covering more entities and predicting them correctly. Part-of-speech Tagging (POS tagging). All the BERT models and LSTM models under our data annealing procedure outperform other transfer learning procedures. The improvement over the state-ofthe-art model DCNN (Gui et al., 2018) is 1.37 in accuracy measure in POS tagging. It is worth noting that improvement in this task was limited before our work. For example, DCNN only improved 0.26 in accuracy comparing research works before it. Our method also outperforms a recent pre-training work BERTweet (Nguyen et al., 2020) by 2.24 in accuracy. Chunking. When LSTM, BERTBASE , and BERTLARGE are used as the training model under our data annealing procedure, they achieve better performances compared to other transfer learning paradigms. Our best model outperforms the stateof-the-art model by 3.03 in F1 . 3155 model Vanilla LSTM MULT LSTM DA LSTM Vanilla BERTBASE INIT BERTBASE MULT BERTBASE DA BERTBASE Vanilla BERTLARGE INIT BERTLARGE MULT BERTLARGE DA BERTLARGE *Over state-of-the-art **State-of-the-art P 75.55 74.51 75.51 68.73 69.28 70.42 71.09 68.41 68.85 70.05 70.61 -5.51 76.12 NER R 55.75 58.48 61.01 62.74 63.7"
2020.findings-emnlp.282,D17-1312,0,\N,Missing
2020.findings-emnlp.282,N18-1202,0,\N,Missing
2020.findings-emnlp.282,N19-1423,0,\N,Missing
2020.findings-emnlp.282,L18-1708,0,\N,Missing
2020.findings-emnlp.431,W17-5102,0,0.0285895,"idation Self Assertions Figure 1: The preliminary resistance strategy framework Fransen et al. (2015) tics, these resistant utterances all collapse into one dialog-act “negative-reactions-towards-persuasion” in the provided annotation scheme, which makes it harder for the persuasive system to respond accordingly. Therefore, to achieve more efficient persuasion, we propose to study the resistance to persuasion in more details. Introduction and Related Work Persuasion plays a prominent role in human communication and has attracted more and more attentions in the NLP community (Tan et al., 2016; Hidey et al., 2017; Hidey and McKeown, 2018; Wang et al., 2019; Yang et al., 2019). During persuasion, the persuader attempts to convince the persuadee to change his/her attitude, opinion or behavior. Previous research on persuasive dialogs mainly study the persuader’s strategies (Wang et al., 2019; Shi et al., 2020; Li et al., 2019), which is helpful when the persuadee shows positive altitude towards the persuasion; but in other situations, the persuadees resists rather than embrace the persuasive attempt. For instance, in P ERSUASION F OR G OOD (Wang et al., 2019), 166 out of 1,017 persuasive dialogs contains"
2020.findings-emnlp.431,P19-1566,1,0.919835,"ing the content Persuasive dialog systems have various usages, such as donation persuasion and physical exercise persuasion. Previous persuasive dialog systems research mostly focused on analyzing the persuader’s strategies, and paid little attention to the persuadee (user). However, understanding and addressing users’ resistance strategies is an essential job of a persuasive dialog system. So, we adopt a preliminary framework on persuasion resistance in psychology, and design a fine-grained resistance strategy annotation scheme. We annotate the P ERSUASION F OR G OOD dataset with the scheme (Wang et al., 2019). With the enriched annotations, we build a classifier to predict the resistance strategies. Furthermore, we analyze the relationships between persuasion strategies and persuasion resistance strategies. Our work lays the ground for developing a persuasive dialogue system that can understand and address user resistance strategy appropriately. The code and data will be released. 1 Contesting Resistance Strategy Contesting the source Contesting the strategies used Weighting attributes Biased Processing Reducing impact Optimism Bias Attitude Bolstering Empowerment Social Validation Self Assertions"
2020.findings-emnlp.431,N19-1364,0,0.0209522,"ategy framework Fransen et al. (2015) tics, these resistant utterances all collapse into one dialog-act “negative-reactions-towards-persuasion” in the provided annotation scheme, which makes it harder for the persuasive system to respond accordingly. Therefore, to achieve more efficient persuasion, we propose to study the resistance to persuasion in more details. Introduction and Related Work Persuasion plays a prominent role in human communication and has attracted more and more attentions in the NLP community (Tan et al., 2016; Hidey et al., 2017; Hidey and McKeown, 2018; Wang et al., 2019; Yang et al., 2019). During persuasion, the persuader attempts to convince the persuadee to change his/her attitude, opinion or behavior. Previous research on persuasive dialogs mainly study the persuader’s strategies (Wang et al., 2019; Shi et al., 2020; Li et al., 2019), which is helpful when the persuadee shows positive altitude towards the persuasion; but in other situations, the persuadees resists rather than embrace the persuasive attempt. For instance, in P ERSUASION F OR G OOD (Wang et al., 2019), 166 out of 1,017 persuasive dialogs contains resistance strategy; although individuals resist persuasive att"
2020.findings-emnlp.431,D16-1076,0,0.0470442,"Missing"
2021.acl-demo.38,2020.sigdial-1.29,0,0.0328889,"It was shown that even different phrasings can result in weaker levels of agreement (Li et al., 2019). Thus, it is not trivial to reproduce the human evaluation results from scratch. To address these problems, we present LEGOEval, an open-source toolkit that enables researchers to easily build and deploy their human evaluation tasks on AMT in one click. LEGOEval supports representative human evaluation tasks, such as static evaluation, where crowdworkers are asked to rate sampled dialogues, and interactive evaluation, where crowdworkers interact with two systems and evaluate their responses (Finch and Choi, 2020; Adiwardana et al., 2020). Furthermore, researchers are also able to customize their own human evaluation procedures easily with LEGOEval. Existing tools typically provide rigid human evaluation templates. For example, DialCrowd (Lee et al., 2018) follows the speech synthesis evaluation toolkit (Parlikar, 2012) and provides a small number of standard evaluation experiments, however, researchers have to manually create the web services and then post the evaluation task on AMT. Sedoc et al. (2019) developed ChatEval, which posts a response comparison task (Otani et al., 2016) on AMT. It is only"
2021.acl-demo.38,W07-0734,0,0.0562689,"chers can personalize their evaluation procedures easily with our built-in pages as if playing with LEGO blocks. Thus, LEGOEval provides a fast, consistent method for reproducing human evaluation results. Besides the flexible task design, LEGOEval also offers an easy API to review collected data. 1 ‡ Introduction As dialogue systems are becoming an increasingly trending topic, the need for standardized and reliable evaluation procedures has grown significantly. Typically, the evaluation of dialogue systems is accomplished by the use of both automatic metrics (Papineni et al., 2002; Lin, 2004; Lavie and Agarwal, 2007) and human evaluation (Serban et al., 2016; Park et al., 2018). Automatic metrics are reliable measurements, but common automatic metrics correlate weakly with human judgment (Liu et al., 2016; Lowe et al., 2017; Gu et al., 2020). Thus, human evaluation has become a primary method for dialogue system evaluation. Previously, researchers invited participants to the lab to physically interact with dialogue systems; recently, the popular approach is crowdsourcing using platforms such as Amazon Mechanical Turk (AMT) (Deriu et al., 2020; Eskenazi et al., 2013). * Equal contribution. Source code and"
2021.acl-demo.38,W18-5028,0,0.0218648,"kit that enables researchers to easily build and deploy their human evaluation tasks on AMT in one click. LEGOEval supports representative human evaluation tasks, such as static evaluation, where crowdworkers are asked to rate sampled dialogues, and interactive evaluation, where crowdworkers interact with two systems and evaluate their responses (Finch and Choi, 2020; Adiwardana et al., 2020). Furthermore, researchers are also able to customize their own human evaluation procedures easily with LEGOEval. Existing tools typically provide rigid human evaluation templates. For example, DialCrowd (Lee et al., 2018) follows the speech synthesis evaluation toolkit (Parlikar, 2012) and provides a small number of standard evaluation experiments, however, researchers have to manually create the web services and then post the evaluation task on AMT. Sedoc et al. (2019) developed ChatEval, which posts a response comparison task (Otani et al., 2016) on AMT. It is only effective for specific dialogue systems and is not generalizable. The widely used toolkit ParlAI (Miller et al., 2018) supports crowd317 Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistic"
2021.acl-demo.38,D16-1230,0,0.073373,"Missing"
2021.acl-demo.38,P17-1103,0,0.0207443,"lexible task design, LEGOEval also offers an easy API to review collected data. 1 ‡ Introduction As dialogue systems are becoming an increasingly trending topic, the need for standardized and reliable evaluation procedures has grown significantly. Typically, the evaluation of dialogue systems is accomplished by the use of both automatic metrics (Papineni et al., 2002; Lin, 2004; Lavie and Agarwal, 2007) and human evaluation (Serban et al., 2016; Park et al., 2018). Automatic metrics are reliable measurements, but common automatic metrics correlate weakly with human judgment (Liu et al., 2016; Lowe et al., 2017; Gu et al., 2020). Thus, human evaluation has become a primary method for dialogue system evaluation. Previously, researchers invited participants to the lab to physically interact with dialogue systems; recently, the popular approach is crowdsourcing using platforms such as Amazon Mechanical Turk (AMT) (Deriu et al., 2020; Eskenazi et al., 2013). * Equal contribution. Source code and documentation are available at https: //github.com/yooli23/LEGOEval. A demo video is available at https://www. youtube.com/watch?v=Dg6mafRGOpg&ab_ channel=JoshArnold. However, human evaluation via crowdsourcing"
2021.acl-demo.38,D16-1049,0,0.0227118,"their responses (Finch and Choi, 2020; Adiwardana et al., 2020). Furthermore, researchers are also able to customize their own human evaluation procedures easily with LEGOEval. Existing tools typically provide rigid human evaluation templates. For example, DialCrowd (Lee et al., 2018) follows the speech synthesis evaluation toolkit (Parlikar, 2012) and provides a small number of standard evaluation experiments, however, researchers have to manually create the web services and then post the evaluation task on AMT. Sedoc et al. (2019) developed ChatEval, which posts a response comparison task (Otani et al., 2016) on AMT. It is only effective for specific dialogue systems and is not generalizable. The widely used toolkit ParlAI (Miller et al., 2018) supports crowd317 Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, pages 317–324, August 1st - August 6th, 2021. ©2021 Association for Computational Linguistics Toolkit Sample Templates Flexible Interface Design Branching Logic Plug & Play Data Reviewing Tool LEGOEval DialCrowd (Lee et al., 2018) P"
2021.acl-demo.38,P02-1040,0,0.113276,"ct.js interface components. Researchers can personalize their evaluation procedures easily with our built-in pages as if playing with LEGO blocks. Thus, LEGOEval provides a fast, consistent method for reproducing human evaluation results. Besides the flexible task design, LEGOEval also offers an easy API to review collected data. 1 ‡ Introduction As dialogue systems are becoming an increasingly trending topic, the need for standardized and reliable evaluation procedures has grown significantly. Typically, the evaluation of dialogue systems is accomplished by the use of both automatic metrics (Papineni et al., 2002; Lin, 2004; Lavie and Agarwal, 2007) and human evaluation (Serban et al., 2016; Park et al., 2018). Automatic metrics are reliable measurements, but common automatic metrics correlate weakly with human judgment (Liu et al., 2016; Lowe et al., 2017; Gu et al., 2020). Thus, human evaluation has become a primary method for dialogue system evaluation. Previously, researchers invited participants to the lab to physically interact with dialogue systems; recently, the popular approach is crowdsourcing using platforms such as Amazon Mechanical Turk (AMT) (Deriu et al., 2020; Eskenazi et al., 2013). *"
2021.acl-demo.38,N18-1162,0,0.0331248,"Missing"
2021.acl-demo.38,N19-4011,0,0.0180592,"nteractive evaluation, where crowdworkers interact with two systems and evaluate their responses (Finch and Choi, 2020; Adiwardana et al., 2020). Furthermore, researchers are also able to customize their own human evaluation procedures easily with LEGOEval. Existing tools typically provide rigid human evaluation templates. For example, DialCrowd (Lee et al., 2018) follows the speech synthesis evaluation toolkit (Parlikar, 2012) and provides a small number of standard evaluation experiments, however, researchers have to manually create the web services and then post the evaluation task on AMT. Sedoc et al. (2019) developed ChatEval, which posts a response comparison task (Otani et al., 2016) on AMT. It is only effective for specific dialogue systems and is not generalizable. The widely used toolkit ParlAI (Miller et al., 2018) supports crowd317 Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, pages 317–324, August 1st - August 6th, 2021. ©2021 Association for Computational Linguistics Toolkit Sample Templates Flexible Interface Design Branchi"
2021.acl-long.189,Q17-1010,0,0.0118731,"al., 1990) contains 4,978 utterances with 79 slots and 17 intents in the flights domain.9 As sources of weak supervision providing slot candidates, we mainly use the frame semantic parsers SEMAFOR (Das et al., 2010) and open-sesame (Swayamdipta et al., 2017) – a union of labels provided by both parsers is used in all our setups. In addition, to explore combined sources on the namedentity-heavy ATIS dataset, we include a generic convolutional NER model provided by SpaCy.10 To provide features for slot candidate merging and selection, we use AllenNLP (Gardner et al., 2017) for SRL and FastText (Bojanowski et al., 2017) as pretrained word embeddings. Slot merging and selection parameters were set heuristically in an initial trial run on the CamRest676 data and proved stable across domains. Slot tagger hyperparameters are chosen according to grid search on a portion of the training data, as described in Section 3.3.11 5.2 System Variants and Baselines We test multiple ablation variants of our method: • Ours-full is the full version of our method (full annotation setup and trained slot tagger). 8 MultiWOZ contains more domains such as restaurant, train search, bus search. However, we decided to not include the"
2021.acl-long.189,D18-1547,0,0.0276754,"Missing"
2021.acl-long.189,2020.acl-main.11,0,0.0329446,"Missing"
2021.acl-long.189,N10-1138,0,0.0531226,"is a multi-domain corpus; we picked two domains – hotel reservation and attraction recommendation – to form WOZ-hotel (WH) with 14,435 utterances, 9 slots, 3 intents and WOZ-attr (WA) with 7524 utterances, 8 slots and 3 intents respectively.8 • Cambridge SLU (Henderson et al., 2012) (CS) contains 10,569 utterances and tracks 5 slots with 5 intents in the restaurant domain. • ATIS (AT) (Hemphill et al., 1990) contains 4,978 utterances with 79 slots and 17 intents in the flights domain.9 As sources of weak supervision providing slot candidates, we mainly use the frame semantic parsers SEMAFOR (Das et al., 2010) and open-sesame (Swayamdipta et al., 2017) – a union of labels provided by both parsers is used in all our setups. In addition, to explore combined sources on the namedentity-heavy ATIS dataset, we include a generic convolutional NER model provided by SpaCy.10 To provide features for slot candidate merging and selection, we use AllenNLP (Gardner et al., 2017) for SRL and FastText (Bojanowski et al., 2017) as pretrained word embeddings. Slot merging and selection parameters were set heuristically in an initial trial run on the CamRest676 data and proved stable across domains. Slot tagger hyper"
2021.acl-long.189,N18-2118,0,0.0253841,"generalize and capture unseen values (cf. Figure 3). One source of errors is the relatively low recall of the frame-semantic parsers used. We successfully address this issue by introducing the slot tagger, however, many slot values remain untagged. This is expected as our method’s performance is inherently limited by the input linguistic annotation quality. Another type of errors is caused by the can14 Note that our measurements of slot F1 only consider the ‘O’ tag as negative (the average is computed over slots only). This results in lower numbers than those reported in literature (cf. e.g. Goo et al., 2018), but we believe that this reflects the actual performance more accurately. 15 We present results taken in unsupervised setting, i.e. when no ontology is available. However, since Jin et al. (2018) consider only slot values that are known from the ontology by default, we provide the extended results in Appendix A.2. 2436 method Jin et al. supervised Jin et al. unsupervised Jin et al. weak-labels Ours-full (unsupervised) Slot F1 0.967 ± .001 0.719 ± .002 0.709 ± .011 0.756 ± .004 Joint Goal Accuracy 0.897 ± .002 0.385 ± .003 0.335 ± .008 0.465 ± .007 Entity Match Rate 0.869 ± .004 0.019 ± .002"
2021.acl-long.189,H90-1021,0,0.0943409,"Missing"
2021.acl-long.189,W03-1028,0,0.353143,"identify domain-relevant slots based on the annotation labels by iteratively (a) merging and (b) ranking and selecting most viable candidates (Section 3.2). (3) we use the discovered slots to train an independent slot tagger (Section 3.3). 3.1 Figure 2 shows the overall data flow of our slot annotation pipeline. The data are first labeled with domain-generic linguistic annotation models, which we consider weak supervision. For our experiments, we use a frame semantic parser and NER, but other models, such as semantic role labeling (SRL; e.g., Palmer et al., 2010) or keyword extraction (e.g., Hulth, 2003) can be used in general. We use a simple union of labels provided by all annotation models.3 3.2 Our slot discovery method has three main stages: (1) We obtain weak supervision labels from autoDiscovering Slots: Merging and Ranking Subsequent steps identify domain-relevant slots based on candidates provided by the automatic annotation. The slot discovery process is iterative – in each iteration, it: (1) merges similar candidates, (2) ranks candidates’ relevance and eliminates irrelevant ones. Once no more frames are eliminated, the process stops and we obtain slot labels, which are used to tra"
2021.acl-long.189,N16-1030,0,0.0183214,"the original annotation models used as weak supervision are not adapted to our specific domain. Therefore, we use the obtained labels to train a new, domain-specific slot tagger to improve performance. The tagger has no access to better labels than those derived by our method; however, it has a simpler task, as the set of target labels is now much smaller and the domain is much narrower. We model the slot tagging task as sequence tagging, using a convolutional neural network that takes word- and character-based embeddings of the tokens as the input and produces a sequence of respective tags (Lample et al., 2016).7 The output layer of the tagger network gives softmax probability distributions over possible tags. To further increase recall, we add an inference-time rule – if slot candidate is split – it is just ranked for relevance multiple times (with respect to multiple contexts). 6 Usefulness of the individual metrics is confirmed in an ablation study in Section 6. 7 https://github.com/deepmipt/ner 2433 the most probable predicted tag is ‘O’ (i.e., no slot) and the second most probable tag has a probability higher than a preset threshold ?tag , the second tag is chosen as a prediction instead. As we"
2021.acl-long.189,P18-1133,0,0.0670244,"explicit dialogue state modeling (e.g., Serban et al., 2016; Li et al., 2016; Gao et al., 2019). They aim at a non-task-oriented setting, where state interpretability or response controllability are less of a concern. Other works in task-oriented dialogues use transfer learning for adapting to low-resourced target domains (Zhao and Eskenazi, 2018; Shalyminov et al., 2019), but also keep the dialogue state representation latent. In contrast, Jin et al. (2018) propose to model the dialogue state explicitly, in a semi-supervised way. They extend the end-to-end encoder-decoder Sequicity model of Lei et al. (2018, cf. Section 4) by introducing an additional decoder that has access to posterior information about the system response. This allows them to train a state representation with a reconstruction loss on unsupervised examples, using the state as a limited memory for essential concepts (roughly corresponding to slots). Their method can be applied in fully unsupervised way, but it still requires some amount of in-domain annotations to achieve good performance. Our work aims at explicit dialogue state modeling without the need for any in-domain supervision. 3 matic domain-generic annotation. (2) We"
2021.acl-long.189,N16-1014,0,0.036663,"sian” relate to the same slot). input sentence types). Yang et al. (2014) use semisupervised intent clustering, with manual annotation to seed and interpret the clusters. Chen et al. (2016) introduced a model for zero-shot intent embedding prediction based on similarity to known intents. Shi et al. (2018) proposed a fully unsupervised intent detection model with the use of sentence clustering based on sentence-level features. Most applications of unsupervised or semisupervised methods to end-to-end dialogue response generation avoid explicit dialogue state modeling (e.g., Serban et al., 2016; Li et al., 2016; Gao et al., 2019). They aim at a non-task-oriented setting, where state interpretability or response controllability are less of a concern. Other works in task-oriented dialogues use transfer learning for adapting to low-resourced target domains (Zhao and Eskenazi, 2018; Shalyminov et al., 2019), but also keep the dialogue state representation latent. In contrast, Jin et al. (2018) propose to model the dialogue state explicitly, in a semi-supervised way. They extend the end-to-end encoder-decoder Sequicity model of Lei et al. (2018, cf. Section 4) by introducing an additional decoder that ha"
2021.acl-long.189,2020.acl-main.3,0,0.0165374,"t al. (2020) focus on a few-shot setting and perform span extraction of slot values using pretrained models. Their approach, however, still requires some expert annotation. Another direction of research focuses on zero-shot slot filling. Bapna et al. (2017)’s recurrent-neuralnetwork-based slot tagger is pretrained on multiple domains and takes a textual description of the target slot on the input in addition to the user utterance. This way, adapting to a new domain only involves providing new slot descriptions. Further works extend this idea with more complex architectures (Shah et al., 2019; Liu et al., 2020). Unsupervised and semi-supervised methods were also investigated for predicting intents (user 2431 User input 1: I would like an expensive restaurant that serves Afghan food. Original annotation: Expensiveness Locale slot-0 slot-1 Our annotation: User input 2: How about Asian oriental food. Original annotation: Origin Food Our annotation: slot-1 Figure 3: A sample of a dialogue from CamRest676 data, with labels from a frame-semantic parser (middle) and our slot tagger (bottom). Although “Afghan” food is not in the frame parser output, our tagger was able to recognize it. The change in value f"
2021.acl-long.189,W04-3252,0,0.0206242,"end up in multiple clusters. This does not mean that the respective Candidate Ranking criteria We use the following metrics to compute the ranking score:6 • Frequency frq(?) is used since candidates that occur frequently in the data are likely important. • Coherence coh(?) is the average pairwise similarity of all fillers’ embeddings: Õ ?cos (?(?), ?(?)) coh(?) = (? ,?) ∈??2 |??2 | (1) where ??2 is a set of all pairs of fillers for the slot candidate s. We follow Chen et al. (2014)’s assumption that fillers with high coherence, i.e., focused on one topic, are good slot candidates. • TextRank (Mihalcea and Tarau, 2004) is a keyword extraction algorithm. It constructs a graph where nodes represent words and edges represent their co-occurrence. The dominant eigenvector of the adjacency matrix of this graph then gives the individual words’ scores. We replace fillers with candidate labels when computing the score, so we obtain results related to slots rather than to particular values. The final score is a simple sum of rankings with respect to all three scores. 3.3 Slot Tagger Model Training Our method described in Section 3.2 can give us a good set of dialogue slots. However, using the merged and filtered slot"
2021.acl-long.189,P17-1163,0,0.0610602,"Missing"
2021.acl-long.189,P19-1547,0,0.0258758,"omatically. Coope et al. (2020) focus on a few-shot setting and perform span extraction of slot values using pretrained models. Their approach, however, still requires some expert annotation. Another direction of research focuses on zero-shot slot filling. Bapna et al. (2017)’s recurrent-neuralnetwork-based slot tagger is pretrained on multiple domains and takes a textual description of the target slot on the input in addition to the user utterance. This way, adapting to a new domain only involves providing new slot descriptions. Further works extend this idea with more complex architectures (Shah et al., 2019; Liu et al., 2020). Unsupervised and semi-supervised methods were also investigated for predicting intents (user 2431 User input 1: I would like an expensive restaurant that serves Afghan food. Original annotation: Expensiveness Locale slot-0 slot-1 Our annotation: User input 2: How about Asian oriental food. Original annotation: Origin Food Our annotation: slot-1 Figure 3: A sample of a dialogue from CamRest676 data, with labels from a frame-semantic parser (middle) and our slot tagger (bottom). Although “Afghan” food is not in the frame parser output, our tagger was able to recognize it. Th"
2021.acl-long.189,W19-5904,0,0.0222927,"Shi et al. (2018) proposed a fully unsupervised intent detection model with the use of sentence clustering based on sentence-level features. Most applications of unsupervised or semisupervised methods to end-to-end dialogue response generation avoid explicit dialogue state modeling (e.g., Serban et al., 2016; Li et al., 2016; Gao et al., 2019). They aim at a non-task-oriented setting, where state interpretability or response controllability are less of a concern. Other works in task-oriented dialogues use transfer learning for adapting to low-resourced target domains (Zhao and Eskenazi, 2018; Shalyminov et al., 2019), but also keep the dialogue state representation latent. In contrast, Jin et al. (2018) propose to model the dialogue state explicitly, in a semi-supervised way. They extend the end-to-end encoder-decoder Sequicity model of Lei et al. (2018, cf. Section 4) by introducing an additional decoder that has access to posterior information about the system response. This allows them to train a state representation with a reconstruction loss on unsupervised examples, using the state as a limited memory for essential concepts (roughly corresponding to slots). Their method can be applied in fully unsup"
2021.acl-long.189,D18-1072,0,0.0200804,"dle) and our slot tagger (bottom). Although “Afghan” food is not in the frame parser output, our tagger was able to recognize it. The change in value for slot-1 (corresponding to food type) is successfully captured in the second utterance. This shows that our model can categorize entities (both “Afghan” and “Asian” relate to the same slot). input sentence types). Yang et al. (2014) use semisupervised intent clustering, with manual annotation to seed and interpret the clusters. Chen et al. (2016) introduced a model for zero-shot intent embedding prediction based on similarity to known intents. Shi et al. (2018) proposed a fully unsupervised intent detection model with the use of sentence clustering based on sentence-level features. Most applications of unsupervised or semisupervised methods to end-to-end dialogue response generation avoid explicit dialogue state modeling (e.g., Serban et al., 2016; Li et al., 2016; Gao et al., 2019). They aim at a non-task-oriented setting, where state interpretability or response controllability are less of a concern. Other works in task-oriented dialogues use transfer learning for adapting to low-resourced target domains (Zhao and Eskenazi, 2018; Shalyminov et al."
2021.acl-long.189,E17-1042,0,0.0697728,"Missing"
2021.acl-long.189,W13-4065,0,0.0177137,"formance of an end-to-end dialogue response generation model, compared to using no slot annotation at all. 1 Introduction Task-oriented dialogue systems typically use annotation based on slots to represent the meaning of user utterances (Young et al., 2013). Slots are attributes relevant to completing the task (e.g., price, food type, area). The sets of slots and their values typically need to be designed in advance by domain experts. Slots and their values are tracked over the course of the dialogue, forming dialogue state, which allows a dialogue system to plan the next actions effectively (Williams et al., 2013). Getting raw data for dialogue system training is not difficult, especially if we restrict the target domain. A requirement for dialogue state labels makes this process much more costly. However, both traditional pipeline systems (Young et al., 2013) and end-to-end task-oriented architectures (Wen et al., 2017) typically require such annotation. While some systems use implicit, latent state representation and do not require annotation (Serban et al., 2016), the behavior of such systems is hard to interpret or control. There are several works aiming at keeping interpretability and reducing the"
2021.acl-long.189,W18-5001,0,0.13204,"omain. A requirement for dialogue state labels makes this process much more costly. However, both traditional pipeline systems (Young et al., 2013) and end-to-end task-oriented architectures (Wen et al., 2017) typically require such annotation. While some systems use implicit, latent state representation and do not require annotation (Serban et al., 2016), the behavior of such systems is hard to interpret or control. There are several works aiming at keeping interpretability and reducing the annotation needs by automating it (Chen et al., 2014, 2015) or transferring annotation across domains (Zhao and Eskenazi, 2018; Coope et al., 2020), but they still require significant manual effort. In this paper, we present a novel approach to discovering a set of domain-relevant dialogue slots and their values given a set of dialogues in the target domain (such as transcripts from a call center). Our approach requires no manual annotation at all in order to tag slots in dialogue data. This substantially simplifies dialogue system design and training process, as the developer no longer needs to design a set of slots and annotate their occurrences in training data. We discover slots by using unsupervised clustering o"
2021.acl-long.269,I17-1099,0,0.0176651,"s shows the Joint model can mimic human supporters’ behaviors in strategy utilization. We believe our work will facilitate research on more data-driven approaches to build dialog systems capable of providing effective emotional support. 2 2.1 Related Work Emotional & Empathetic Conversation Figure 2 intuitively shows the relationships among In this paper, we define the task of Emotional ESC, emotional conversation, and empathetic conSupport Conversation (ESC), aiming to provide versation. Emotion has been shown to be impor3470 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020). As a notable work of emotional conversation, Zhou et al. (2018) propose Emotional Chatting Machine (ECM) to generate emotional responses given a pre-specified emotion. This task is required to accurately express (designated or not) emotions in generated responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely"
2021.acl-long.269,W04-1013,0,0.0229567,"Missing"
2021.acl-long.269,2020.acl-demos.30,0,0.167107,"en used to provide effective ES (Hill, 2009). Figure 2 illustrates the relationship between the three tasks and we provide further discussion in Section 2.1. Second, people are not naturally good at being supportive, so guidelines have been developed to train humans how to be more supportive. Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations. As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES. Empathetic Responding Emotional Chatting Accurately express emotions in responses Understand users&apos; feelings and reply accordingly Emotional Support Conversation Reduce users&apos; emotional distress and help them work through the challenges Figure 2: Emotional support conversations (our work) can include elements of emotional chatting (Zhou et al., 2018) and empathetic responding(Rashkin et al., 2019). support through social interactions (like the interactions betwee"
2021.acl-long.269,2021.findings-acl.72,1,0.739112,"responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely a basic quality of dialog systems, while ES is a more high-level and complex ability that dialog systems are expected to be equipped with. Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accordingly. For instance, Rashkin et al. (2019) argued that dialog models can generate more empathetic responses by recognizing the interlocutor’s feelings. Effective ES naturally requires expressing empathy according to the help-seeker’s experiences and feelings, as shown in our proposed Emotional Support Framework (Section 3.2, Figure 3). Hence, empathetic responding is only one of the necessary components of emotional support. In addition to empathetic responding, an emotional support conversation needs to explore the users’ p"
2021.acl-long.269,2020.emnlp-main.531,0,0.274036,"pathetic responding (Rashkin et al., 2019) return messages that are examples of emotion or empathy and are thus limited in functionality, as they are not capable of many other skills that are often used to provide effective ES (Hill, 2009). Figure 2 illustrates the relationship between the three tasks and we provide further discussion in Section 2.1. Second, people are not naturally good at being supportive, so guidelines have been developed to train humans how to be more supportive. Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations. As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES. Empathetic Responding Emotional Chatting Accurately express emotions in responses Understand users&apos; feelings and reply accordingly Emotional Support Conversation Reduce users&apos; emotional distress and help them work through the challenges Figure 2: Emotional support convers"
2021.acl-long.269,2020.cl-1.2,0,0.051659,"Missing"
2021.acl-long.269,P18-1104,0,0.0205011,"model can mimic human supporters’ behaviors in strategy utilization. We believe our work will facilitate research on more data-driven approaches to build dialog systems capable of providing effective emotional support. 2 2.1 Related Work Emotional & Empathetic Conversation Figure 2 intuitively shows the relationships among In this paper, we define the task of Emotional ESC, emotional conversation, and empathetic conSupport Conversation (ESC), aiming to provide versation. Emotion has been shown to be impor3470 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020). As a notable work of emotional conversation, Zhou et al. (2018) propose Emotional Chatting Machine (ECM) to generate emotional responses given a pre-specified emotion. This task is required to accurately express (designated or not) emotions in generated responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely a basic quality of d"
2021.acl-long.283,N19-1423,0,0.0538661,") x ∈ X, predicts the turn-level user engagement label y ∈ Y = {0, 1}, where label y = 1 means “disengaged” and y = 0 means “engaged”. We start from an unlabeled train set Dtrain = {xi }1Ntrain without any label yi . The test set Dtest = {(xi , yi )}1Ntest contains the ground-truth label yi . The development set Ddev has a similar structure as the test set Dtest but the development set can be much smaller than a train set (i.e., Ndev  Ntrain ), making it economical to obtain. Following the general architecture of neural classifiers, we formulate our model Mθ = M(φ, f ) = f (φ(x)): Here BERT (Devlin et al., 2019)-based φ is a text encoder that maps each dialog turn x to a feature space φ(x) ∈ Rd . f is the final linear layer with softmax activation. 4 Data To ensure our framework is generalized to various corpora, we investigate multiple open-domain dialog datasets ranging from ASR-based (Gunrock (Liang et al., 2020a)) to text-based (ConvAI2 (Dinan et al., 2019), Blender (Roller et al., 2020), and Meena (Adiwardana et al., 2020)) dialog systems. Gunrock Movie Dataset Gunrock Movie dataset consists of dialog data collected from Gunrock, an ASR-based open-domain social chatbot originally designed for Am"
2021.acl-long.283,W19-5944,0,0.0113137,"ed to annotate new dialog datasets. 2 2.1 Related Work Open-Domain Dialog System Evaluation Open-domain dialog system evaluation is a longlasting challenge. It has been shown that existing automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 2017). Mehri and Eskénazi (2020) simulate user response using DialogGPT and evaluate the probability of user complaint. Given the limitations above, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Venkatesh et a"
2021.acl-long.283,P19-1358,0,0.0267044,"obability of user complaint. Given the limitations above, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Venkatesh et al., 2018). Denoising human ratings is still an open research problem (Liang et al., 2020e; Li et al., 2019). 2.2 User Engagement in Dialogs User engagement is commonly defined as the user’s willingness to continue conversing with the dialog system (Yu et al., 2016, 2017). Existing work on measuring user engagement primarily resorts to human rating (Yi et al., 2019; Hancock et al., 2019), or proxy metrics. Example proxy metrics include conversation length like number of dialog turns (Venkatesh et al., 2018; Ram et al., 2018), and conversational breadth like topical diversity (Guo et al., 2018). Sporadic attempts have been made to detecting user disengagement in dialogs (Yu et al., 2004; Ghazarian et al., 2020; Choi et al., 2019). A major bottleneck of these methods is that they require hand-labeling many dialog samples for individual datasets. Although Liang et al. (2020e) denoise user self-reported ratings with the Shapley algorithm for dialog system evaluation, their method"
2021.acl-long.283,P18-1175,0,0.0229631,"to perform dialog evaluation. Our method could potentially generalize to other classification tasks if different weak labelers are provided. 2.3 Learning from Weak Supervision Learning from weak supervision reduces annotation costs by utilizing noisy but cost-efficient labels (Ratner et al., 2020, 2016; Liang et al., 2020e). One of the most popular forms of weak supervision is distant supervision, in which the records of an external knowledge base are heuristically aligned with data points to produce noisy labels for relationship extraction tasks (Bunescu and Mooney, 2007; Mintz et al., 2009; Hancock et al., 2018). Other applications of weak supervision to scene graph prediction (Krishna et al., 2019), intent classification (Mallinar et al., 2019), and medical imag3653 Figure 1: Schematic of the HERALD two-stage workflow. Stage 1: Auto-label training data with Heuristic Functions. We first design heuristics rules for detecting user disengagement by investigating multiple dialog corpora. The heuristics rules are implemented as heuristic functions based on regular expressions and dialog acts. Then, we use the heuristic function to label the training set automatically. Stage 2: Denoise weakly-labeled trai"
2021.acl-long.283,2021.maiworkshop-1.12,1,0.700263,"Missing"
2021.acl-long.283,2020.emnlp-main.355,1,0.913407,"l., 2016). Open-domain dialog system evaluation has long been one of the most difficult challenges in the dialog community for several reasons: (1) The goal of 1 Equal Contribution. dialog evaluation should be to evaluate users’ conversational experience. Existing automatic evaluation metrics such as BLEU are mostly constrained to a static corpus, and do not capture the user experience in a realistic interactive setting. (2) Currently, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Liang et al., 2020e). Although we could tell which dialog system is better by running statistical tests on a large number of noisy ratings, it is challenging to locate dialogs with bad performance reliably. Only by identifying these bad dialogs effectively can we correct errors in these samples to improve dialog system quality. User engagement has been recognized as one of the essential metrics for open-domain dialog evaluation (Ram et al., 2018). Previous research also confirms that incorporating user engagement as real-time feedback benefits dialog policy learning (Yu et al., 2016). One of the most costly bot"
2021.acl-long.283,2020.acl-main.126,1,0.739977,"l., 2016). Open-domain dialog system evaluation has long been one of the most difficult challenges in the dialog community for several reasons: (1) The goal of 1 Equal Contribution. dialog evaluation should be to evaluate users’ conversational experience. Existing automatic evaluation metrics such as BLEU are mostly constrained to a static corpus, and do not capture the user experience in a realistic interactive setting. (2) Currently, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Liang et al., 2020e). Although we could tell which dialog system is better by running statistical tests on a large number of noisy ratings, it is challenging to locate dialogs with bad performance reliably. Only by identifying these bad dialogs effectively can we correct errors in these samples to improve dialog system quality. User engagement has been recognized as one of the essential metrics for open-domain dialog evaluation (Ram et al., 2018). Previous research also confirms that incorporating user engagement as real-time feedback benefits dialog policy learning (Yu et al., 2016). One of the most costly bot"
2021.acl-long.283,W04-1013,0,0.0282192,"in dialog system evaluation is a longlasting challenge. It has been shown that existing automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 2017). Mehri and Eskénazi (2020) simulate user response using DialogGPT and evaluate the probability of user complaint. Given the limitations above, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Venkatesh et al., 2018). Denoising human ratings is still an open research problem (Liang et al., 2020e;"
2021.acl-long.283,D16-1230,0,0.162702,"user disengagement detection accuracy in two dialog corpora. Our implementation is available at https:// github.com/Weixin-Liang/HERALD/. 1 Introduction Evaluation metrics heavily influence a field’s research direction. The ultimate goal of open-domain dialog systems is to provide an enjoyable experience to users. Previous research mainly focuses on optimizing automatic dialog evaluation metrics such as BLEU, which models the distance between the system responses and a limited number of references available. However, it has been shown that these metrics correlate poorly with human judgments (Liu et al., 2016). Open-domain dialog system evaluation has long been one of the most difficult challenges in the dialog community for several reasons: (1) The goal of 1 Equal Contribution. dialog evaluation should be to evaluate users’ conversational experience. Existing automatic evaluation metrics such as BLEU are mostly constrained to a static corpus, and do not capture the user experience in a realistic interactive setting. (2) Currently, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Liang et"
2021.acl-long.283,D17-1238,0,0.0151526,"y to improve dialog system quality (Ghazarian et al., 2020; Choi et al., 2019). Third, user engagement is an essential objective of dialog systems, but few dialog datasets with user engagement ratings are available. Our heuristic functions, combined with the proposed workflow, can be readily deployed to annotate new dialog datasets. 2 2.1 Related Work Open-Domain Dialog System Evaluation Open-domain dialog system evaluation is a longlasting challenge. It has been shown that existing automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 2017). Mehri and Eskénazi ("
2021.acl-long.283,P02-1040,0,0.109143,"em Evaluation Open-domain dialog system evaluation is a longlasting challenge. It has been shown that existing automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 2017). Mehri and Eskénazi (2020) simulate user response using DialogGPT and evaluate the probability of user complaint. Given the limitations above, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Venkatesh et al., 2018). Denoising human ratings is still an open research problem (Liang et a"
2021.acl-long.283,P17-1103,0,0.0213481,"experience reliably to improve dialog system quality (Ghazarian et al., 2020; Choi et al., 2019). Third, user engagement is an essential objective of dialog systems, but few dialog datasets with user engagement ratings are available. Our heuristic functions, combined with the proposed workflow, can be readily deployed to annotate new dialog datasets. 2 2.1 Related Work Open-Domain Dialog System Evaluation Open-domain dialog system evaluation is a longlasting challenge. It has been shown that existing automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 201"
2021.acl-long.283,P18-1194,0,0.0179481,"as the segmentation tool. We then apply the heuristic functions on each segment to detect disengaged intents. For heuristic groups 1 to 3, if any segment contains a disengaged intent, the user response is auto-labeled as disengaged. For heuristic group 4 (“End with non-positive responses”), we assign disengaged labels only if the disengaged intents are detected in the last segment. We detect disengaged intents with Regexes. The benefit of using Regexes is that they have minimum dependencies and are easy to modify. We design Regexes for each intent. Following common Regexes complexity metrics (Luo et al., 2018), our Regexes for each intent contains 43.9 Regexes groups and 87.7 or clauses on average. Our framework also supports incorporating additional resources to improve the intent detection accuracy for automatic training data labeling. For example, we can enhance the recall of Regexes intent detection by incorporating existing deep learning-based NLU (Natural Language Understanding) models. Specifically, we re-purpose an open-sourced dialog act classification model (Yu and Yu, 2021) to enhance disengagement intent detection: we select 6 out of the 23 supported dialog act labels that are associate"
2021.acl-long.283,W12-2018,0,0.0288733,"It has been shown that existing automatic dialog evaluation metrics correlate poorly with human judgments (Liu et al., 2016; Lowe et al., 2017; Novikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 2017). Mehri and Eskénazi (2020) simulate user response using DialogGPT and evaluate the probability of user complaint. Given the limitations above, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Venkatesh et al., 2018). Denoising human ratings is still an open research problem (Liang et al., 2020e; Li et al., 2019). 2.2 User Engagement in Dialogs User engagement is"
2021.acl-long.283,2020.sigdial-1.28,0,0.02748,"vikova et al., 2017). A wellknown reason is that these automatic dialog evaluation metrics rely on modeling the distance between the generated response and a limited number of references available. The fundamental gap between the open-ended nature of the conversations and the limited references (Gupta et al., 2019) is not addressed in methods that are lexical-level based (Papineni et al., 2002; Lin, 2004; Banerjee and Lavie, 2005), embedding based (Rus and Lintean, 2012; Forgues et al., 2014), perplexity based (Adiwardana et al., 2020), or learning based (Tao et al., 2018; Lowe et al., 2017). Mehri and Eskénazi (2020) simulate user response using DialogGPT and evaluate the probability of user complaint. Given the limitations above, self-reported user ratings are widely used to evaluate open-domain dialogs. However, self-reported ratings suffer from bias and variance among different users (Venkatesh et al., 2018). Denoising human ratings is still an open research problem (Liang et al., 2020e; Li et al., 2019). 2.2 User Engagement in Dialogs User engagement is commonly defined as the user’s willingness to continue conversing with the dialog system (Yu et al., 2016, 2017). Existing work on measuring user enga"
2021.acl-long.283,P09-1113,0,0.0705622,"e Shapley algorithm to perform dialog evaluation. Our method could potentially generalize to other classification tasks if different weak labelers are provided. 2.3 Learning from Weak Supervision Learning from weak supervision reduces annotation costs by utilizing noisy but cost-efficient labels (Ratner et al., 2020, 2016; Liang et al., 2020e). One of the most popular forms of weak supervision is distant supervision, in which the records of an external knowledge base are heuristically aligned with data points to produce noisy labels for relationship extraction tasks (Bunescu and Mooney, 2007; Mintz et al., 2009; Hancock et al., 2018). Other applications of weak supervision to scene graph prediction (Krishna et al., 2019), intent classification (Mallinar et al., 2019), and medical imag3653 Figure 1: Schematic of the HERALD two-stage workflow. Stage 1: Auto-label training data with Heuristic Functions. We first design heuristics rules for detecting user disengagement by investigating multiple dialog corpora. The heuristics rules are implemented as heuristic functions based on regular expressions and dialog acts. Then, we use the heuristic function to label the training set automatically. Stage 2: Deno"
2021.acl-long.283,2021.eacl-main.94,1,0.718689,"pendencies and are easy to modify. We design Regexes for each intent. Following common Regexes complexity metrics (Luo et al., 2018), our Regexes for each intent contains 43.9 Regexes groups and 87.7 or clauses on average. Our framework also supports incorporating additional resources to improve the intent detection accuracy for automatic training data labeling. For example, we can enhance the recall of Regexes intent detection by incorporating existing deep learning-based NLU (Natural Language Understanding) models. Specifically, we re-purpose an open-sourced dialog act classification model (Yu and Yu, 2021) to enhance disengagement intent detection: we select 6 out of the 23 supported dialog act labels that are associated with disen3656 gaged intents, and map each selected dialog act label to the heuristic groups. The dialog act “complaint” is mapped to the heuristic group “complain system repetition”;“closing” is mapped to the disengaged intent “request termination”; “hold” to “hesitation”;“other_answers” to “unsure answer”; “back-channeling” to “back-channeling”, and “neg_answer“ to ‘negative answer‘”. If a user utterance is detected with disengaged intent by either Regexes or the deep learnin"
2021.acl-long.283,W16-3608,1,0.901613,"ce among different users (Liang et al., 2020e). Although we could tell which dialog system is better by running statistical tests on a large number of noisy ratings, it is challenging to locate dialogs with bad performance reliably. Only by identifying these bad dialogs effectively can we correct errors in these samples to improve dialog system quality. User engagement has been recognized as one of the essential metrics for open-domain dialog evaluation (Ram et al., 2018). Previous research also confirms that incorporating user engagement as real-time feedback benefits dialog policy learning (Yu et al., 2016). One of the most costly bottlenecks of learning to detect user disengagement is to annotate many turn-level user engagement labels (Ghazarian et al., 2020). In addition, the data annotation process becomes more expensive and challenging for privacy-sensitive dialog corpora, due to the privacy concerns in crowdsourcing (Xia and McKernan, 2020). To improve annotation efficiency, we reframe the training data annotation process as a denoising problem. Specifically, instead of manually labeling each training datum, we automatically label the training samples with a set of labeling heuristics. The"
2021.acl-long.54,N16-1180,0,0.0701565,"Missing"
2021.acl-long.54,D14-1200,0,0.0331951,"ic reasoning. 2 Related Work We review the related works on the social relation inference from documents, which is a well-studied task, and those from dialogues, which is the emerging task that our work is focused on. 2.1 Relation Inference from Documents Most of the existing literature focus on relation extraction from professional edited news reports or websites. They typically output a set of “subjectpredicate-object” triples after reading the entire document (Bach and Badaskar, 2007; Mintz et al., 2009; Kumar, 2017). While early works mostly utilize feature-based methods (Kambhatla, 2004; Miwa and Sasaki, 2014; Gormley et al., 2015) and kernel-based methods (Zelenko et al., 2003; Zhao and Grishman, 2005; Mooney and Bunescu, 2006), more recent studies use deep learning methods such as recurrent neural networks or transformers (Kumar, 2017). For example, Zhou et al. (2016) propose bidirectional LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to"
2021.acl-long.54,D19-6108,0,0.0177342,"Badaskar, 2007; Mintz et al., 2009; Kumar, 2017). While early works mostly utilize feature-based methods (Kambhatla, 2004; Miwa and Sasaki, 2014; Gormley et al., 2015) and kernel-based methods (Zelenko et al., 2003; Zhao and Grishman, 2005; Mooney and Bunescu, 2006), more recent studies use deep learning methods such as recurrent neural networks or transformers (Kumar, 2017). For example, Zhou et al. (2016) propose bidirectional LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to our method. Regarding social network modeling, while most works treat pairs of entities isolated (Yu et al., 659 2020; Xue et al., 2020b; Chen et al., 2020), Srivastava et al. (2016) formulate the interpersonal relation inference as structured prediction (Belanger and McCallum, 2016; Qiu et al., 2020; Zhao et al., 2020), inferring the collective assignment of relations among all entities from a document (Li et al., 2020; Jin et al., 2020). Regarding relation evolution, a few w"
2021.acl-long.54,N19-1067,0,0.0180783,"t pairs of entities isolated (Yu et al., 659 2020; Xue et al., 2020b; Chen et al., 2020), Srivastava et al. (2016) formulate the interpersonal relation inference as structured prediction (Belanger and McCallum, 2016; Qiu et al., 2020; Zhao et al., 2020), inferring the collective assignment of relations among all entities from a document (Li et al., 2020; Jin et al., 2020). Regarding relation evolution, a few works are aimed to learn the dynamics in social networks, i.e., the development of relations, from narratives by Hidden Markov Models (Chaturvedi et al., 2017), Recurrent Neural Networks (Kim and Klinger, 2019), deep recurrent autoencoders (Iyyer et al., 2016). Our method differs from the aforementioned works by modeling the structured social relations and their changes concurrently, which can be useful for the task of tracking social network evolution (Doreian and Stokman, 1997) and unveiling the reasoning process of relations. We achieve this by parsing the graph incrementally per utterance with the proposed α–β–γ strategy. 2.2 Relation Inference from Dialogues Recently, Yu et al. (2020) introduce the first human-annotated dialogue-based relation extraction dataset DialogRE, in which relations are"
2021.acl-long.54,W17-1601,0,0.0199297,"an essential step towards building emotionally intelligent agents. By jointly inferring individual attributes and social relations, our incremental parsing algorithm enables consistent and dynamic relational inference in dialogue systems, which can be remarkably useful for a wide range of applications such as a chatbot that constantly perceives new information and conducts social relation inference. However, we never forget the other side of the coin. We emphasize that an ethical design principle must be in place throughout all stages of the development and evaluation. First, as discussed in Larson (2017), we model the attributes as a social construct from a performative view. For example, “gender performativity is not merely performance, but rather performances that correspond to, or are constrained by, norms or conventions and simultaneously reinforce them. Second, our model relies upon the attribute-category ascription provided by MovieGraph (Vicol et al., 2018) and Friends Central in Fandom. However, we acknowledge that the annotation could be prone to a partial understanding of human relationships, and the real situation could be more complicated. Lastly, selfidentification should be the"
2021.acl-long.54,2020.findings-emnlp.102,0,0.0190101,"l position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to our method. Regarding social network modeling, while most works treat pairs of entities isolated (Yu et al., 659 2020; Xue et al., 2020b; Chen et al., 2020), Srivastava et al. (2016) formulate the interpersonal relation inference as structured prediction (Belanger and McCallum, 2016; Qiu et al., 2020; Zhao et al., 2020), inferring the collective assignment of relations among all entities from a document (Li et al., 2020; Jin et al., 2020). Regarding relation evolution, a few works are aimed to learn the dynamics in social networks, i.e., the development of relations, from narratives by Hidden Markov Models (Chaturvedi et al., 2017), Recurrent Neural Networks (Kim and Klinger, 2019), deep recurrent autoencoders (Iyyer et al., 2016). Our method differs from the aforementioned works by modeling the structured social relations and their changes concurrently, which can be useful for the task of tracking social network evolution (Doreian and Stokman, 1997) and unveiling the reasoning process of relations. We achie"
2021.acl-long.54,P09-1113,0,0.101217,"o investigate the information contribution, and perform case studies to show the effectiveness of our dynamic reasoning. 2 Related Work We review the related works on the social relation inference from documents, which is a well-studied task, and those from dialogues, which is the emerging task that our work is focused on. 2.1 Relation Inference from Documents Most of the existing literature focus on relation extraction from professional edited news reports or websites. They typically output a set of “subjectpredicate-object” triples after reading the entire document (Bach and Badaskar, 2007; Mintz et al., 2009; Kumar, 2017). While early works mostly utilize feature-based methods (Kambhatla, 2004; Miwa and Sasaki, 2014; Gormley et al., 2015) and kernel-based methods (Zelenko et al., 2003; Zhao and Grishman, 2005; Mooney and Bunescu, 2006), more recent studies use deep learning methods such as recurrent neural networks or transformers (Kumar, 2017). For example, Zhou et al. (2016) propose bidirectional LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tun"
2021.acl-long.54,2020.emnlp-main.148,1,0.713229,"nal LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to our method. Regarding social network modeling, while most works treat pairs of entities isolated (Yu et al., 659 2020; Xue et al., 2020b; Chen et al., 2020), Srivastava et al. (2016) formulate the interpersonal relation inference as structured prediction (Belanger and McCallum, 2016; Qiu et al., 2020; Zhao et al., 2020), inferring the collective assignment of relations among all entities from a document (Li et al., 2020; Jin et al., 2020). Regarding relation evolution, a few works are aimed to learn the dynamics in social networks, i.e., the development of relations, from narratives by Hidden Markov Models (Chaturvedi et al., 2017), Recurrent Neural Networks (Kim and Klinger, 2019), deep recurrent autoencoders (Iyyer et al., 2016). Our method differs from the aforementioned works by modeling the structured social relations and their changes concurrently, which can be useful for the task o"
2021.acl-long.54,2020.acl-main.444,0,0.234948,"after tomorrow. Mom?! Dad?! What-what. . . what you guys doing here?! S2: Well you kids talk about this place so much, we thought we’d see what all the fuss is about. S3: I certainly see what the girls like coming here. S1: Why?! S3: The sexy blonde behind the counter. S1: Gunther?! S2: Your mother just added him to her list. S1: What? Your-your list? R1 R2 R3 R4 R5 Argument Pair (S2, S1) (S3, Gunther) (S3, S1) (S1, S3) (S1, S2) Trigger dad sexy blonde mom mom dad Relation Type per:children per:positive impression per:children per:parents per:parents Table 1: A dialogue example from DialogRE (Yu et al., 2020). Trigger word annotations are not used for training, but rather for illustrating purpose only. Introduction Social relations form the basic structure of our society, defining not only our self-images but also our relationships (Sztompka, 2002). Robots with a higher emotional quotient (EQ) have the potential to understand users’ social relations better and act appropriately. Given a dialogue as context and a set of entities, the task of Dialogue Relation Extraction (DRE) predicts the relation types between the entities from a predefined relation set. Table 5 shows such an example from the data"
2021.acl-long.54,D17-1004,0,0.0193551,"ally output a set of “subjectpredicate-object” triples after reading the entire document (Bach and Badaskar, 2007; Mintz et al., 2009; Kumar, 2017). While early works mostly utilize feature-based methods (Kambhatla, 2004; Miwa and Sasaki, 2014; Gormley et al., 2015) and kernel-based methods (Zelenko et al., 2003; Zhao and Grishman, 2005; Mooney and Bunescu, 2006), more recent studies use deep learning methods such as recurrent neural networks or transformers (Kumar, 2017). For example, Zhou et al. (2016) propose bidirectional LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to our method. Regarding social network modeling, while most works treat pairs of entities isolated (Yu et al., 659 2020; Xue et al., 2020b; Chen et al., 2020), Srivastava et al. (2016) formulate the interpersonal relation inference as structured prediction (Belanger and McCallum, 2016; Qiu et al., 2020; Zhao et al., 2020), inferring the collective assignment of relations amon"
2021.acl-long.54,P05-1052,0,0.0992136,"m documents, which is a well-studied task, and those from dialogues, which is the emerging task that our work is focused on. 2.1 Relation Inference from Documents Most of the existing literature focus on relation extraction from professional edited news reports or websites. They typically output a set of “subjectpredicate-object” triples after reading the entire document (Bach and Badaskar, 2007; Mintz et al., 2009; Kumar, 2017). While early works mostly utilize feature-based methods (Kambhatla, 2004; Miwa and Sasaki, 2014; Gormley et al., 2015) and kernel-based methods (Zelenko et al., 2003; Zhao and Grishman, 2005; Mooney and Bunescu, 2006), more recent studies use deep learning methods such as recurrent neural networks or transformers (Kumar, 2017). For example, Zhou et al. (2016) propose bidirectional LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to our method. Regarding social network modeling, while most works treat pairs of entities isolate"
2021.acl-long.54,P16-2034,0,0.0224946,"xisting literature focus on relation extraction from professional edited news reports or websites. They typically output a set of “subjectpredicate-object” triples after reading the entire document (Bach and Badaskar, 2007; Mintz et al., 2009; Kumar, 2017). While early works mostly utilize feature-based methods (Kambhatla, 2004; Miwa and Sasaki, 2014; Gormley et al., 2015) and kernel-based methods (Zelenko et al., 2003; Zhao and Grishman, 2005; Mooney and Bunescu, 2006), more recent studies use deep learning methods such as recurrent neural networks or transformers (Kumar, 2017). For example, Zhou et al. (2016) propose bidirectional LSTM model to capture the longterm dependency between entity pairs, Zhang et al. (2017) present PA-LSTM to encode global position information, and Alt et al. (2019); Papanikolaou et al. (2019) fine-tune pre-trained transformer language models for relation extraction. Two streams of work are closely related to our method. Regarding social network modeling, while most works treat pairs of entities isolated (Yu et al., 659 2020; Xue et al., 2020b; Chen et al., 2020), Srivastava et al. (2016) formulate the interpersonal relation inference as structured prediction (Belanger a"
2021.acl-long.544,2020.sigdial-1.8,0,0.0175296,"o improve the grammar. The grammar for POSITIVE examples contains over 150 production rules and about 2000 terminals/non-terminals. This could be used to recognize or sample over 100,000 unique strings2 . 3.3 Additional Data Sources While the handwritten utterances we collect from Turkers and convert into the grammar is good for POSITIVE examples and hard NEGATIVE , it might not represent real world dialogues. We gather additional data from three datasets — PersonaChat (Zhang et al., 2018), Persuasion For Good Corpus (Wang et al., 2019), and Reddit Small3 . Datasets are sourced from ConvoKit (Chang et al., 2020). We gather 680 NEGATIVE examples from randomly sampling these datasets. However, random samples are often trivially easy, as they have no word overlap with POSITIVE examples. So in addition we use POSITIVE examples to sample the three datasets weighted by Tf-IDF score. This gives NEG ATIVE utterances like “yes, I am a people person. Do you?"" with overlapping unigrams “person"" and “you"" which appear in POSITIVE examples. We gather 1360 NEGATIVE examples with this method. We manually checked examples from these sources to avoid false negatives4 . 1 often utterance were actually classified as AI"
2021.acl-long.544,E17-2068,0,0.0291478,"eighted by the training label distribution. 5 we sampled were actually POSITIVE or AIC examples 7002 bit.ly/ruarobot-codeguide BOW LR: We compute a bag of words (BOW) L2normed Tf-IDF vector, and perform logistic regression. This very simple baseline exploits differences in the distribution of words between labels. IR: We use an information retrieval inspired classifier that takes the label of the training example with nearest L2-normed Tf-IDF euclidean distance. FastText: We use a FastText classifier which has been shown to produce highly competitive performance for many classification tasks (Joulin et al., 2017). We use a n-gram size of 3, a vector size of 300, and train for 10 epochs. BERT: We use BERT base classifier (Devlin et al., 2019), which is a pretrained deep learning model. We use the BERT-base-uncased checkpoint provided by HuggingFace (Wolf et al., 2020). Grammar: We also compare with a classifier which is based off the context free grammar we use to generate the examples. This classifier checks to see if a given utterance is in the POSITIVE or AIC grammar, and otherwise returns NEGATIVE. This classifier also includes a few small heuristics, such as also checking the last sentence of the"
2021.acl-long.544,P19-1566,1,0.852391,"al 34 individuals were surveyed, resulting in approximately 390 utterances to improve the grammar. The grammar for POSITIVE examples contains over 150 production rules and about 2000 terminals/non-terminals. This could be used to recognize or sample over 100,000 unique strings2 . 3.3 Additional Data Sources While the handwritten utterances we collect from Turkers and convert into the grammar is good for POSITIVE examples and hard NEGATIVE , it might not represent real world dialogues. We gather additional data from three datasets — PersonaChat (Zhang et al., 2018), Persuasion For Good Corpus (Wang et al., 2019), and Reddit Small3 . Datasets are sourced from ConvoKit (Chang et al., 2020). We gather 680 NEGATIVE examples from randomly sampling these datasets. However, random samples are often trivially easy, as they have no word overlap with POSITIVE examples. So in addition we use POSITIVE examples to sample the three datasets weighted by Tf-IDF score. This gives NEG ATIVE utterances like “yes, I am a people person. Do you?"" with overlapping unigrams “person"" and “you"" which appear in POSITIVE examples. We gather 1360 NEGATIVE examples with this method. We manually checked examples from these sources"
2021.acl-long.544,2021.acl-demo.38,1,0.791429,"Missing"
2021.acl-long.544,2020.emnlp-demos.6,0,0.0589639,"Missing"
2021.acl-long.544,P18-1205,0,0.0298037,"e grammar to better build out the grammar. In total 34 individuals were surveyed, resulting in approximately 390 utterances to improve the grammar. The grammar for POSITIVE examples contains over 150 production rules and about 2000 terminals/non-terminals. This could be used to recognize or sample over 100,000 unique strings2 . 3.3 Additional Data Sources While the handwritten utterances we collect from Turkers and convert into the grammar is good for POSITIVE examples and hard NEGATIVE , it might not represent real world dialogues. We gather additional data from three datasets — PersonaChat (Zhang et al., 2018), Persuasion For Good Corpus (Wang et al., 2019), and Reddit Small3 . Datasets are sourced from ConvoKit (Chang et al., 2020). We gather 680 NEGATIVE examples from randomly sampling these datasets. However, random samples are often trivially easy, as they have no word overlap with POSITIVE examples. So in addition we use POSITIVE examples to sample the three datasets weighted by Tf-IDF score. This gives NEG ATIVE utterances like “yes, I am a people person. Do you?"" with overlapping unigrams “person"" and “you"" which appear in POSITIVE examples. We gather 1360 NEGATIVE examples with this method."
2021.acl-long.544,2020.acl-demos.30,0,0.0340144,", 2017), and millions of smart speakers in homes (Olson and Kemery, 2019). Additionally, systems such as Google’s Duplex (Leviathan and Matias, 2018), which phone calls businesses to make reservations, foreshadows a future where users might have unsolicited conversations with human sounding machines over the phone. This future creates many challenges (Følstad and Brandtzæg, 2017; Henderson et al., 2018). A class of these problems have to do with humans not reAdditionally, current trends suggests progress in dialog systems might come from training on massive amounts of human conversation data (Zhang et al., 2020; Roller et al., 2020; Adiwardana et al., 2020). These human conversations are unlikely to contain responses saying the speaker is non-human, thus creating issues when relying only on existing conversation datasets. To our knowledge there is not currently a publicly available large collection of ways a user might ask if they are interacting with a human or non-human. Creating such dataset can 6999 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6999–7013 August 1–6, 2021. ©"
2021.acl-short.112,2020.acl-main.740,0,0.04411,"Missing"
2021.acl-short.40,W17-5526,0,0.0581295,"Missing"
2021.acl-short.40,I17-1099,0,0.0578505,"Missing"
2021.eacl-main.110,D19-5602,0,0.0196661,"of BERT (Devlin et al., 2019) and GPT2 (Radford et al., 2019) suggests the possibility of applying large pre-trained language models to dialog systems. There are some studies of applying large pre-trained language model to dialog generation. TransferTransfo (Wolf et al., 2019) fine-tuned the pre-trained language model GPT (Radford et al., 2018) on Persona-Chat dataset (Zhang et al., 2018) and obtained significant improvements on chitchat response generation, suggesting the potential of fine-tuning large pre-trained language models on other dialog response generation tasks. A more recent work (Budzianowski and Vulic, 2019) adopted the framework of TransferTransfo. They made the first attempt to leverage large pre-trained language models GPT and GPT-2 on task-oriented dialog generation, but it included belief states modeling as the input and did not achieve better results than the baseline. We propose to model dialogs without any annotation but rely on pre-trained large-scale language models that alternate. 3 Alternating Recurrent Dialog Model We propose Alternating Recurrent Dialog Model (ARDM) by compositing two separate pre-trained language model in alternate order to learn the user and system utterance distr"
2021.eacl-main.110,D18-1547,0,0.0753881,"appear in the database to support our model. Such state tracker achieves 0.960 in Entity Match rate. It suggests that state tracking may be accomplished in more straightforward ways other than training a neural network model on a large set of annotated data. With a simple state tracker, our proposed method still performs better than Sequicity, which trains the belief state and the response generation task jointly. 4.2 MultiWOZ Here, we only use the ground truth database search result to be consistent with other methods. We perform delexicalization which is mentioned in the original MultiWOZ (Budzianowski et al., 2018). We prepend the database search results to the system response for as conditional input. Also, the database results now contain information about whether the booking is successful or not (i.e., succeed or fail). Again, we prefix the database results to the system response. Note that we do not use belief state or dialog act annotation provided by the dataset to train ARDM. We set the top-p to 0.2 and the temperature to 0.7. We normalize the time’s slot value in all dialogs into the 24-hour format and perform tokenization via spaCy2 . We found that different papers report results with different"
2021.eacl-main.110,P19-1360,0,0.0972569,"e 24-hour format and perform tokenization via spaCy2 . We found that different papers report results with different versions of the evaluator, which makes it difficult to compare different methods fairly. We explain the differences among all versions of the evaluator in Appendix. In this paper, we follow LaRL’s evaluator implementation, as it is more reasonable than others. We re-evaluate results for all methods with the same evaluator to ensure fairness. We compare our model to the attention-based seq2seq model which is proposed as the MultiWOZ Baseline (Budzianowski et al., 2018), the HDSA (Chen et al., 2019) model that incorporates dialog act supervision as an inductive prior for model architecture, and the LaRL (Zhao et al., 2019) model which leverages latent action modeling and reinforcement learning to improve performance. We do not compare with GPT-2-finetune with our model in MultiWOZ because GPT-2-finetune’s performance on CamRest676 is significantly worse than our model. Note that GPT-2-finetune is equivalent to ARDM without alternating parameterization. The results are evaluated on BLEU-4, Inform Rate, and Success Rate. Inform and Success Rate measure whether the system response provides"
2021.eacl-main.110,P19-1285,0,0.0307119,"avoid recomputing history information. Therefore, the final ht is computed as: i=1 Mt−1 = [K≤t−1 , V≤t−1 ] mst ps (st |u≤t , s<t ) = Y P (wi |w<i , u≤t , s<t ) (3) i=1 Finally, we train the dialog model by maximizing the likelihood over Equation 1. However, in order to model multi-turn dialog distributions efficiently, we need a memory mechanism to encode the history. In the next section, we introduce the memory mechanism in detail. 3.2 Memory Recurrence We apply a memory mechanism to grant the model the capability of memorizing conversation history. This method is similar to Transformer-XL (Dai et al., 2019), which enables the model to learn longer dependency. For an utterance at turn t, we reuse the hidden states h≤t−1 stored in the memory Mt−1 to obtain ht , and store the ht back to the memory as Mt . As for the pre-trained Transformer language model, we implement the memory mechanism using self-attention given the query/key/value (4) (5) K≤t , V≤t = [K≤t−1 ; Kt ], [V≤t−1 ; Vt ] (6) ht = Attention(Qt , K≤t , V≤t ) (7) One can use ht (consisting of vectors for each token) to get each token’s probability to calculate the language model cross entropy loss to maximize p(wi |w< i, u<t , s<t ), shown"
2021.eacl-main.110,N19-1423,0,0.214748,"cts are difficult to annotate such as persuasion and negotiation. Eric and Manning (2017) proposed a simple sequence-to-sequence architecture that requires no explicit annotations. The model learns to extract information from dialog history with attention and copy mechanism. However, due to the limited language modeling capability in the previous model, Sequicity (Lei et al., 2018), which uses belief states as inputs for supervision, outperforms Eric and Manning (2017)’s method significantly in the recent dialog datasets. But with the success of large pre-trained language models such as BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), we investigate how large-scale pre-trained language models can help dialog tasks. Previous sequence-to-sequence models are used to tackle documents with only one narrator. However, in dialogs, two speakers have different roles; therefore, their language model distributions are very different from each other. To address this issue, we propose ARDM, a dialog model that encodes and decodes different speaker utterances in alternating order. This structure makes the model more flexible and efficient than traditional sequence-to-sequence models in processing variou"
2021.eacl-main.110,W17-5506,0,0.0204806,"or training the sub-modules such as dialog state tracker or policy decision-maker. An alternative is to model dialog without explicitly modeling belief states. Specifically, Eric and Manning (2017) proposed a sequence-to-sequence model that utilizes copymechanism to copy history information directly from raw dialog history. This method achieved the state-of-the-art results on DSTC2 (Henderson et al., 2014), which is a simple dialog restaurant booking task with abundant data. However, such method did not perform well on more complex dialog task data sets CamRes676 (Wen et al., 2017) and KVRET (Eric et al., 2017). Sequicity (Lei et al., 2018) attributed the bad performance of Eric and Manning (2017)’s method to the omission of belief tracker. They introduced the concept of belief span and added belief tracker back to the model and achieved state-of-the-art performance. Compared to Sequicity, Eric and Manning (2017)’s method provides a more general framework that reduces manual dialog state, user intent, and dialog act labeling by bypassing any symbolic annotations. Such a model can apply to datasets with no or partial annotations of belief states. In a real-world setting, if the dialog task introduces"
2021.eacl-main.110,E17-2075,0,0.521806,"are more and more popular. However, most current state-of-the-art approaches still heavily rely on extensive human annotations such as belief states and dialog acts (Lei et al., 2018). However, dialog content can vary considerably in different dialog tasks. Having a different intent or dialog act annotation scheme for each task is costly and even impossible for tasks such as open-domain social chat. Thus, it 1 https://github.com/qywu/ARDM is difficult to utilize these methods on challenging dialog tasks where dialog states and acts are difficult to annotate such as persuasion and negotiation. Eric and Manning (2017) proposed a simple sequence-to-sequence architecture that requires no explicit annotations. The model learns to extract information from dialog history with attention and copy mechanism. However, due to the limited language modeling capability in the previous model, Sequicity (Lei et al., 2018), which uses belief states as inputs for supervision, outperforms Eric and Manning (2017)’s method significantly in the recent dialog datasets. But with the success of large pre-trained language models such as BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), we investigate how large-scale pre"
2021.eacl-main.110,W14-4337,0,0.0983819,"Missing"
2021.eacl-main.110,P18-1133,0,0.262967,"eover, we can generalize ARDM to more challenging, non-collaborative tasks such as persuasion. In the PersuasionForGood task, ARDM is capable of generating human-like responses to persuade people to donate to a charity. 1 Introduction It has been a long-standing ambition for artificial intelligence researchers to create an intelligent conversational agent that can generate human-like responses. Recently, data-driven dialog models are more and more popular. However, most current state-of-the-art approaches still heavily rely on extensive human annotations such as belief states and dialog acts (Lei et al., 2018). However, dialog content can vary considerably in different dialog tasks. Having a different intent or dialog act annotation scheme for each task is costly and even impossible for tasks such as open-domain social chat. Thus, it 1 https://github.com/qywu/ARDM is difficult to utilize these methods on challenging dialog tasks where dialog states and acts are difficult to annotate such as persuasion and negotiation. Eric and Manning (2017) proposed a simple sequence-to-sequence architecture that requires no explicit annotations. The model learns to extract information from dialog history with att"
2021.eacl-main.110,P16-1162,0,0.028023,"of vectors for each token) to get each token’s probability to calculate the language model cross entropy loss to maximize p(wi |w< i, u<t , s<t ), shown in Figure 1. 3.3 Training Details We initialize the user and the system language model with a large pre-trained language model GPT-2 small with 117M parameters (Radford et al., 2019). It is a Transformer (Vaswani et al., 2017) model with 12 heads, 768 hidden size, and 12 layers. The model is trained on a large scale corpus called WebText extracted from Reddit with at least three upvotes. The tokenizer is 50,257 size byte pair encoding (BPE) (Sennrich et al., 2016) that can encode and decode any text in a lossless manner to avoid out-of-vocabulary tokens. We follow a special format in GPT-2 as the “trigger” so that the model can zero-shot dialog response generation, by prefixing the user role token “A:” or “B:”, 1294 and suffixing the end of utterance token “


”. This “trigger” approach is similar in other zero-shot scenarios mentioned in GPT-2 paper (e.g., that a ”TL;DR” token can trigger GPT-2 to summarize the input text.) We further fine-tune ARDM on the specific task dataset. We apply AdamW optimizer (Loshchilov and Hutter, 2019), and the number"
2021.eacl-main.110,P19-1566,1,0.901307,"Missing"
2021.eacl-main.110,D18-1009,0,0.0221276,"arly, the system needs to do the same for the user model to improve its understanding. This alternative repeating process forces both the user and system models to preserve the dialog history effectively in the memory. One can interpret the memory as the implicit representation of belief states or dialog acts. Another benefit of ARDM is that we will obtain both user and system utterance generators. We can let the two models talk to each other to generate new self-play dialogs (Silver et al., 2017). With self-play, one can rapidly build a large scale dialog dataset using adversarial filtering (Zellers et al., 2018). Such models can also potentially be used in reinforcement learning as user simulator to study complex dialog strategies as well. We will explore those possibilities in the future work. Persuasion is a double-edged sword. Given the fast development of dialog systems, an ethical design principle must be in place throughout all stages of the development and evaluation. We choose the donation task is because it is a relatively simple task that benefits children. Second, when deploying the persuasive agents in real conversations, we need to keep the users informed of the nature of the system. By"
2021.eacl-main.110,P18-1205,0,0.0279749,"introduce extra information to the model. Therefore, a dialog model with powerful representation learning should learn a form of belief states information automatically without human annotations as the scaffold. Recent success of BERT (Devlin et al., 2019) and GPT2 (Radford et al., 2019) suggests the possibility of applying large pre-trained language models to dialog systems. There are some studies of applying large pre-trained language model to dialog generation. TransferTransfo (Wolf et al., 2019) fine-tuned the pre-trained language model GPT (Radford et al., 2018) on Persona-Chat dataset (Zhang et al., 2018) and obtained significant improvements on chitchat response generation, suggesting the potential of fine-tuning large pre-trained language models on other dialog response generation tasks. A more recent work (Budzianowski and Vulic, 2019) adopted the framework of TransferTransfo. They made the first attempt to leverage large pre-trained language models GPT and GPT-2 on task-oriented dialog generation, but it included belief states modeling as the input and did not achieve better results than the baseline. We propose to model dialogs without any annotation but rely on pre-trained large-scale la"
2021.eacl-main.110,N19-1123,0,0.052653,"Missing"
2021.eacl-main.177,D18-1547,0,0.026283,"Missing"
2021.eacl-main.177,D18-1241,0,0.0242575,"comes clearer over time. The applications mentioned above could benefit greatly from this type of multi-turn interaction, enabling conversational agents to accurately predict intent, request additional information, and better understand ambiguous followup questions and comments. In an applied setting, meaningful and natural conversations are important features of virtual entities as a means to establish trust and improve usability. Here, we are motivated by the challenging task of conversational question answering (CQA). Current open-source datasets such as CoQA (Reddy et al., 2019) and QuAC (Choi et al., 2018) provide strong baselines for this task. However, these datasets have limited applicability in practical settings, because 1) they are created from domainagnostic source material, and 2) they do not necessarily consider the full diversity of question types and vernacular that may be encountered in natural dialogue. Creating realistic, domain-specific datasets to train CQA models is notoriously costly and time-consuming. As such, we focus on the related task of question generation as a means to generate synthetic conversational questions and subsequently, create new datasets or augment existing"
2021.eacl-main.177,D17-1219,0,0.0154334,"explore previous approaches to question generation and then discuss outstanding research challenges in conversational question generation. 2.1 Single-turn Question Generation Single-turn question generation has been the focus of extensive research. Two of the main categories in QG are answer-unaware and answeraware. The former category generates the question without knowledge of the answer and solely based on the passage; whereas, the latter takes both passage and answer as inputs. Traditional approaches for answer-unaware QG include two main steps: content selection and question generation (Du and Cardie, 2017; Subramanian et al., 2018). Some of the more recent approaches utilize sequence-to-sequence (seq2seq) models for end-toend question generation using Transformer-based architectures (Scialom et al., 2019). Various techniques have been used for improving the generated questions, including contextualized word embeddings (Scialom et al., 2019), question type usage and copying mechanism (Wu et al., 2020), and typed decoders (Wang et al., 2018). To enable answer-aware question generation, the input passage is augmented with information describing the answer. For example, the passage can be concaten"
2021.eacl-main.177,2020.acl-main.703,0,0.0282054,"9.41 50.83 53.15 49.26 B2 7.81 22.60 30.57 32.64 35.31 31.06 B3 2.83 16.11 19.40 20.81 23.31 20.24 B4 1.35 12.23 12.34 13.84 15.78 12.11 M 12.15 25.75 35.78 37.08 40.15 33.26 RL 34.05 43.25 46.88 48.67 50.98 46.23 BS 87.14 91.25 92.55 92.86 93.14 92.53 MS 7.62 25.92 31.89 33.91 36.40 32.82 Table 1: Automated Metric Evaluation Results. These scores seek to evaluate the lexical overlap, and to some degree, the semantic similarity, between generated and ground truth questions within each dialogue turn. We also train two QG models based on pretrained Transformer seq2seq architectures (BART-large (Lewis et al., 2020), T5large (Raffel et al., 2020)) using all elements of the ChainCQG methodology except the questionanswer representation sharing mechanism used in ChainCQG model. Instead, the target answer is the direct input to the model, concatenated with the passage and dialogue history. 4.4.1 Automated Metrics Results Results of all models and baselines are shown in Table 1. In the top row of this Table, P is the perplexity, B1-4 are BLEU 1 through BLEU 4, M is METEOR, RL is ROUGE-L, BS is the BERTScore, and MS is MoverScore. In the first column, ChainCQG-M and ChainCQG-S refer to two version of our appro"
2021.eacl-main.177,P18-1177,0,0.040228,"Missing"
2021.eacl-main.177,D19-1317,0,0.0133614,"alom et al., 2019), question type usage and copying mechanism (Wu et al., 2020), and typed decoders (Wang et al., 2018). To enable answer-aware question generation, the input passage is augmented with information describing the answer. For example, the passage can be concatenated with the answer positions and 2062 lexical features (e.g., part-of-speech (POS) and named entity (NER)) to form the encoder input of a seq2seq model (Zhou et al., 2017). Jointly modelling the unstructured passage and the structured answer-relevant relation has been suggested for improving question generation as well (Li et al., 2019). Additional techniques have been proposed to solve various answer-aware QG challenges, including poor performance on long passages (Zhao et al., 2018) and the bias of repeating the terms in the target answer within the generated question (Kim et al., 2019). 2.2 Conversational Question Generation Compared to single-turn QG, conversational (i.e., multi-turn) QG is less frequently explored in the literature. Further, it is more difficult as it requires a deeper understanding of the context and the dialogue history. Previous work mostly focused on answer-unaware CQG (Pan et al., 2019; Qi et al.,"
2021.eacl-main.177,P17-1123,0,0.0147206,"nerated questions in relation to the context. We have used Mechanical Turk for this evaluation. In the context of answer-aware question generation, Answer Consistency describes whether the generated questions result in the correct answers (Celikyilmaz et al., 2020). To measure this metric, we provide the passage and the answer, and ask the evaluators whether the generated question is consistent with the answer (i.e., 1 for consistent and 0 for inconsistent). Fluency measures the quality of the generated questions and accounts for criteria such as grammar, spelling, choice of words, and style (Du et al., 2017). To measure this metric, we provide the generated question and ask the human evaluator whether the language in the generated question is fluent. We consider three categories of errors: grammar/spelling mistakes, missing entity names, and mismatched pronouns. Based on these categories, we assign 2 for cases with no mistake in any of the categories, 1 for cases with maximum of one mistake in any of the mentioned categories, and 0 for cases with one or more mistakes in each one of the categories. We scale the fluency score to (0,1) by maximum evaluation scores. Implementation Details We use both"
2021.eacl-main.177,W17-5526,0,0.0281001,"Missing"
2021.eacl-main.177,P19-1480,0,0.0932831,"task. Our ChainCQG model is trained end-to-end, resulting in high-quality questions, while reducing computational cost by using shared parameters across both models. Using an answer-aware strategy grounds each turn of QG by jointly encoding the passage with the target answer rationale, increasing accuracy of the generated question types and further aligning coreferences between dialogue turns. We evaluate our approach using the inverted CoQA dataset (Reddy et al., 2019), which is a large-scale CQA dataset that we re-purposed for question generation. Our model outperforms existing SOTA CFNet (Gao et al., 2019) and ReDR (Pan et al., 2019) by a large margin on automatic evaluation metrics, and shows improved results on human evaluation metrics as well. More information about the baselines will be discussed in Section 2. In summary, the main contributions of this paper are threefold 1 : • The ChainCQG two-stage architecture is introduced with answer-aware input encoding, and it is an end-to-end model which is able to 1 Code available at https://github.com/ searchableai/ChainCQG. fluently generate different types of questions and achieve high consistency with the target answers. • We demonstrate a flow"
2021.eacl-main.177,D19-5809,0,0.144144,"ion (CQG) 2061 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 2061–2070 April 19 - 23, 2021. ©2021 Association for Computational Linguistics proves more challenging than single-turn QG as the questions are often highly ambiguous on their own, forcing the model to learn a deeper understanding of the context surrounding the passage text and dialogue history (Pan et al., 2019). Most CQG studies have generated questions using only the passage and dialogue history as inputs (i.e., answerunaware) (Pan et al., 2019; Qi et al., 2020; Nakanishi et al., 2019; Wang et al., 2018). Answer-aware CQG models, on the other hand, generate questions based on the target answer, as well as dialogue history and passage. Although answer-aware CQG models seek to improve the generated conversation flow, current answer-aware QG models suffer from issues including inaccurate coreference alignment, dialogue inconsistencies, incorrect grammar and the inability to generate many different types of questions (e.g. yes/no, factoid, explanation). In this paper, we introduce ChainCQG, a Conversational QG model that achieves improved performance by jointly learning the re"
2021.eacl-main.177,W19-4102,0,0.0147602,"ealistic, domain-specific datasets to train CQA models is notoriously costly and time-consuming. As such, we focus on the related task of question generation as a means to generate synthetic conversational questions and subsequently, create new datasets or augment existing ones. This will ultimately enable training CQA models in closed-loop, simulation environments, as well as allow machines to initiate dialogue and engage in information-seeking behavior. While QA models have been studied previously (Zhu et al., 2018; Huang et al., 2019; Yeh and Chen, 2019; Chen et al., 2020; Ju et al., 2019; Ohsugi et al., 2019)), the QG task, which is the focus of this paper, has received less attention. QG models in the answer-unaware setting aim to predict a question given the source passage, while in the answer-aware setting, the target answer and rationale are included as inputs as well. Most QG-related literature has focused on single-turn question generation using question-answer datasets such as SQuAD (Rajpurkar et al., 2016), and other textual sources like Wikipedia articles (Du and Cardie, 2018). Conversational Question Generation (CQG) 2061 Proceedings of the 16th Conference of the European Chapter of the"
2021.eacl-main.177,P19-1203,0,0.189825,"ing question-answer datasets such as SQuAD (Rajpurkar et al., 2016), and other textual sources like Wikipedia articles (Du and Cardie, 2018). Conversational Question Generation (CQG) 2061 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 2061–2070 April 19 - 23, 2021. ©2021 Association for Computational Linguistics proves more challenging than single-turn QG as the questions are often highly ambiguous on their own, forcing the model to learn a deeper understanding of the context surrounding the passage text and dialogue history (Pan et al., 2019). Most CQG studies have generated questions using only the passage and dialogue history as inputs (i.e., answerunaware) (Pan et al., 2019; Qi et al., 2020; Nakanishi et al., 2019; Wang et al., 2018). Answer-aware CQG models, on the other hand, generate questions based on the target answer, as well as dialogue history and passage. Although answer-aware CQG models seek to improve the generated conversation flow, current answer-aware QG models suffer from issues including inaccurate coreference alignment, dialogue inconsistencies, incorrect grammar and the inability to generate many different typ"
2021.eacl-main.177,P02-1040,0,0.109184,"ing conversational questions that are consistent with the target answers). To this end, we first examine a set of automated metrics. Then, to ensure robustness, we evaluate and discuss a set of human-based metrics. 4.3.1 4.3.2 Human Evaluation Metrics and Procedure Automated Metrics To evaluate our question generation approach, we aim to show that it is 1) grammatically and semantically correct and 2) able to achieve the task objectives. To achieve the first goal, we compute automatic metrics with respect to the ground truth questions. We report multiple commonly used metrics, including BLEU (Papineni et al., 2002), 4.4 Main Results The ChainCQG model architecture is evaluated alongside two SOTA baselines (ReDR, CFNet) on a number of automatic metrics, including BLEU (1-4), METEOR, ROUGE-L, MoverScore, and BERTScore. More information about these metrics and baselines was presented in Section 4.3. 2065 Model ReDR CFNet BART-large T5-large ChainCQG-M ChainCQG-S B1 27.58 38.24 49.41 50.83 53.15 49.26 B2 7.81 22.60 30.57 32.64 35.31 31.06 B3 2.83 16.11 19.40 20.81 23.31 20.24 B4 1.35 12.23 12.34 13.84 15.78 12.11 M 12.15 25.75 35.78 37.08 40.15 33.26 RL 34.05 43.25 46.88 48.67 50.98 46.23 BS 87.14 91.25 92."
2021.eacl-main.177,2020.findings-emnlp.3,0,0.0711425,"Question Generation (CQG) 2061 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 2061–2070 April 19 - 23, 2021. ©2021 Association for Computational Linguistics proves more challenging than single-turn QG as the questions are often highly ambiguous on their own, forcing the model to learn a deeper understanding of the context surrounding the passage text and dialogue history (Pan et al., 2019). Most CQG studies have generated questions using only the passage and dialogue history as inputs (i.e., answerunaware) (Pan et al., 2019; Qi et al., 2020; Nakanishi et al., 2019; Wang et al., 2018). Answer-aware CQG models, on the other hand, generate questions based on the target answer, as well as dialogue history and passage. Although answer-aware CQG models seek to improve the generated conversation flow, current answer-aware QG models suffer from issues including inaccurate coreference alignment, dialogue inconsistencies, incorrect grammar and the inability to generate many different types of questions (e.g. yes/no, factoid, explanation). In this paper, we introduce ChainCQG, a Conversational QG model that achieves improved performance by"
2021.eacl-main.177,D16-1264,0,0.0474654,"logue and engage in information-seeking behavior. While QA models have been studied previously (Zhu et al., 2018; Huang et al., 2019; Yeh and Chen, 2019; Chen et al., 2020; Ju et al., 2019; Ohsugi et al., 2019)), the QG task, which is the focus of this paper, has received less attention. QG models in the answer-unaware setting aim to predict a question given the source passage, while in the answer-aware setting, the target answer and rationale are included as inputs as well. Most QG-related literature has focused on single-turn question generation using question-answer datasets such as SQuAD (Rajpurkar et al., 2016), and other textual sources like Wikipedia articles (Du and Cardie, 2018). Conversational Question Generation (CQG) 2061 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 2061–2070 April 19 - 23, 2021. ©2021 Association for Computational Linguistics proves more challenging than single-turn QG as the questions are often highly ambiguous on their own, forcing the model to learn a deeper understanding of the context surrounding the passage text and dialogue history (Pan et al., 2019). Most CQG studies have generated questions using"
2021.eacl-main.177,Q19-1016,0,0.220039,"which the search objective becomes clearer over time. The applications mentioned above could benefit greatly from this type of multi-turn interaction, enabling conversational agents to accurately predict intent, request additional information, and better understand ambiguous followup questions and comments. In an applied setting, meaningful and natural conversations are important features of virtual entities as a means to establish trust and improve usability. Here, we are motivated by the challenging task of conversational question answering (CQA). Current open-source datasets such as CoQA (Reddy et al., 2019) and QuAC (Choi et al., 2018) provide strong baselines for this task. However, these datasets have limited applicability in practical settings, because 1) they are created from domainagnostic source material, and 2) they do not necessarily consider the full diversity of question types and vernacular that may be encountered in natural dialogue. Creating realistic, domain-specific datasets to train CQA models is notoriously costly and time-consuming. As such, we focus on the related task of question generation as a means to generate synthetic conversational questions and subsequently, create new"
2021.eacl-main.177,P19-1604,0,0.0132324,"ation has been the focus of extensive research. Two of the main categories in QG are answer-unaware and answeraware. The former category generates the question without knowledge of the answer and solely based on the passage; whereas, the latter takes both passage and answer as inputs. Traditional approaches for answer-unaware QG include two main steps: content selection and question generation (Du and Cardie, 2017; Subramanian et al., 2018). Some of the more recent approaches utilize sequence-to-sequence (seq2seq) models for end-toend question generation using Transformer-based architectures (Scialom et al., 2019). Various techniques have been used for improving the generated questions, including contextualized word embeddings (Scialom et al., 2019), question type usage and copying mechanism (Wu et al., 2020), and typed decoders (Wang et al., 2018). To enable answer-aware question generation, the input passage is augmented with information describing the answer. For example, the passage can be concatenated with the answer positions and 2062 lexical features (e.g., part-of-speech (POS) and named entity (NER)) to form the encoder input of a seq2seq model (Zhou et al., 2017). Jointly modelling the unstruc"
2021.eacl-main.177,W18-2609,0,0.0219714,"roaches to question generation and then discuss outstanding research challenges in conversational question generation. 2.1 Single-turn Question Generation Single-turn question generation has been the focus of extensive research. Two of the main categories in QG are answer-unaware and answeraware. The former category generates the question without knowledge of the answer and solely based on the passage; whereas, the latter takes both passage and answer as inputs. Traditional approaches for answer-unaware QG include two main steps: content selection and question generation (Du and Cardie, 2017; Subramanian et al., 2018). Some of the more recent approaches utilize sequence-to-sequence (seq2seq) models for end-toend question generation using Transformer-based architectures (Scialom et al., 2019). Various techniques have been used for improving the generated questions, including contextualized word embeddings (Scialom et al., 2019), question type usage and copying mechanism (Wu et al., 2020), and typed decoders (Wang et al., 2018). To enable answer-aware question generation, the input passage is augmented with information describing the answer. For example, the passage can be concatenated with the answer positi"
2021.eacl-main.177,P18-1204,0,0.119394,"gs of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 2061–2070 April 19 - 23, 2021. ©2021 Association for Computational Linguistics proves more challenging than single-turn QG as the questions are often highly ambiguous on their own, forcing the model to learn a deeper understanding of the context surrounding the passage text and dialogue history (Pan et al., 2019). Most CQG studies have generated questions using only the passage and dialogue history as inputs (i.e., answerunaware) (Pan et al., 2019; Qi et al., 2020; Nakanishi et al., 2019; Wang et al., 2018). Answer-aware CQG models, on the other hand, generate questions based on the target answer, as well as dialogue history and passage. Although answer-aware CQG models seek to improve the generated conversation flow, current answer-aware QG models suffer from issues including inaccurate coreference alignment, dialogue inconsistencies, incorrect grammar and the inability to generate many different types of questions (e.g. yes/no, factoid, explanation). In this paper, we introduce ChainCQG, a Conversational QG model that achieves improved performance by jointly learning the representations of que"
2021.eacl-main.177,2021.eacl-main.110,1,0.819728,"Missing"
2021.eacl-main.177,2020.ngt-1.8,0,0.0134388,"ased on the passage; whereas, the latter takes both passage and answer as inputs. Traditional approaches for answer-unaware QG include two main steps: content selection and question generation (Du and Cardie, 2017; Subramanian et al., 2018). Some of the more recent approaches utilize sequence-to-sequence (seq2seq) models for end-toend question generation using Transformer-based architectures (Scialom et al., 2019). Various techniques have been used for improving the generated questions, including contextualized word embeddings (Scialom et al., 2019), question type usage and copying mechanism (Wu et al., 2020), and typed decoders (Wang et al., 2018). To enable answer-aware question generation, the input passage is augmented with information describing the answer. For example, the passage can be concatenated with the answer positions and 2062 lexical features (e.g., part-of-speech (POS) and named entity (NER)) to form the encoder input of a seq2seq model (Zhou et al., 2017). Jointly modelling the unstructured passage and the structured answer-relevant relation has been suggested for improving question generation as well (Li et al., 2019). Additional techniques have been proposed to solve various ans"
2021.eacl-main.177,D19-5812,0,0.0212988,"that may be encountered in natural dialogue. Creating realistic, domain-specific datasets to train CQA models is notoriously costly and time-consuming. As such, we focus on the related task of question generation as a means to generate synthetic conversational questions and subsequently, create new datasets or augment existing ones. This will ultimately enable training CQA models in closed-loop, simulation environments, as well as allow machines to initiate dialogue and engage in information-seeking behavior. While QA models have been studied previously (Zhu et al., 2018; Huang et al., 2019; Yeh and Chen, 2019; Chen et al., 2020; Ju et al., 2019; Ohsugi et al., 2019)), the QG task, which is the focus of this paper, has received less attention. QG models in the answer-unaware setting aim to predict a question given the source passage, while in the answer-aware setting, the target answer and rationale are included as inputs as well. Most QG-related literature has focused on single-turn question generation using question-answer datasets such as SQuAD (Rajpurkar et al., 2016), and other textual sources like Wikipedia articles (Du and Cardie, 2018). Conversational Question Generation (CQG) 2061 Proceedi"
2021.eacl-main.177,D19-1053,0,0.0333956,"Missing"
2021.eacl-main.177,D18-1424,0,0.0178722,"ion generation, the input passage is augmented with information describing the answer. For example, the passage can be concatenated with the answer positions and 2062 lexical features (e.g., part-of-speech (POS) and named entity (NER)) to form the encoder input of a seq2seq model (Zhou et al., 2017). Jointly modelling the unstructured passage and the structured answer-relevant relation has been suggested for improving question generation as well (Li et al., 2019). Additional techniques have been proposed to solve various answer-aware QG challenges, including poor performance on long passages (Zhao et al., 2018) and the bias of repeating the terms in the target answer within the generated question (Kim et al., 2019). 2.2 Conversational Question Generation Compared to single-turn QG, conversational (i.e., multi-turn) QG is less frequently explored in the literature. Further, it is more difficult as it requires a deeper understanding of the context and the dialogue history. Previous work mostly focused on answer-unaware CQG (Pan et al., 2019; Qi et al., 2020; Nakanishi et al., 2019; Wang et al., 2018). Specifically, Pan et al. (2019) proposed an encoderdecoder framework, ReDR, for answer-agnostic CQG,"
2021.eacl-main.94,D17-1231,0,0.0194904,"el uses a 2-layer Bi-LSTM to encode the context representation and a multi-layer perceptron (MLP) to decode the output. For multilabel prediction, we use a binary cross-entropy objective function to learn co-occurring tags independently. This training objective also helps with transfer learning from other single label dialog act datasets. During testing, we choose the labels with the highest values predicted from the MLP as the potential output and filter them with an empirical threshold (0.5). 5.2 Context representation Contextual information plays an important role in dialog act prediction (Liu et al., 2017; Khatri et al., 2018). We consider two methods to represent previous turns: the actual utterance (text), and the dialog act of the utterance (DA). For each method, the most recent segmented sentence unit from each speaking party is considered as the history suggested by the length of context from Khatri et al. (2018). We append the last segmented system unit (sys_unit), the previous segmented user unit (user_prev), and the current segmented user unit (user_cur) as sys_unit <u_p> user_prev <u_c> user_cur where <u_p> and <u_c> are special tokens to separate utterances. For instance, to predict"
2021.eacl-main.94,D15-1166,0,0.0693862,"Missing"
2021.eacl-main.94,C18-1300,0,0.117905,"litates both annotation and the training of automatic dialog act predictors. MIDAS focuses on helping dialog systems understand their human users, while previous schemes mainly focus on analyzing human-human dialog with not fully open-domain data (SWBD-DAMSL), mutually-exclusive tags (DAMSL), or lack of contextual information (DIT++ and ISO). Therefore, MIDAS provides a unique hierarchical structure and proposes a set of new labels for the humanmachine setting while inheriting labels from previous schemes. A complete description of MIDAS is in Appendix A.2. Similar to Chowdhury et al. (2016); Mezza et al. (2018), we also show a potential mapping from SWBD, SWBD-DAMSL, and ISO to MIDAS in Appendix A.4. We discuss the three main features of MIDAS: hierarchical structure, multi-label format, and context consideration respectively. 3.1 Hierarchical structure Previous schemes such as ISO design their hierarchical structure as multiple dimensions and define dialog acts as dimension-specific functions. Such a turn-by-turn specific taxonomy mixes in-depth analysis into the discourse level, thereby requiring a distinguished definition in each dimension and creating a complex hierarchy. For instance, “accept”"
2021.eacl-main.94,L18-1008,0,0.0831063,"Missing"
2021.eacl-main.94,2011.iwslt-papers.7,0,0.0703149,"Missing"
2021.eacl-main.94,C16-1025,0,0.0273029,"Missing"
2021.eacl-main.94,J00-3003,0,0.791839,"Missing"
2021.eacl-main.94,H93-1005,0,0.389016,"Missing"
2021.eacl-main.94,H01-1015,0,0.4316,"Missing"
2021.emnlp-main.35,N19-1423,0,0.107342,"ing inference. Critically, the supporting model Pψ (yj |xi ) has never encountered out-of-scope utterances during training. 3.2 Baselines Prior methods for approaching indirect prediction generally fall into three categories: probability Data Augmentation for Dialogue Methods for threshold, outlier distance and Bayesian ensemble. augmenting data to train dialogue systems are most In all cases, the supporting model trained on the closely related to our work. Previous research has used data augmentation to improve natural lan- intent classification task uses a pretrained BERT model as its base (Devlin et al., 2019). guage understanding (NLU) and intent detection in Starting with Probability Threshold baselines, dialogue (Niu and Bansal, 2019; Hou et al., 2018). Other methods augment the in-scope sample repre- (1) MaxProb declares an example as OOS if the maximum value of the supporting model’s sentations to support out-of-scope robustness (Ryu et al., 2018; Ng et al., 2020a; Lee and Shalymi- output probability distribution falls below some nov, 2019). Recently, generative adversarial net- threshold τ (Hendrycks and Gimpel, 2017). (2) works (GANs) have been used to create out-of- ODIN enhances this by ad"
2021.emnlp-main.35,P17-2090,0,0.0264856,"odels (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope dialogues. The input context xi = {(S1 , U1 ), ..., (St , Ut )} is a series of system and user utterances within t turns of a conversation. The desired output yi ∈ [0, 1] is a binary label representing whether that cont"
2021.emnlp-main.35,D19-1456,0,0.0220839,"nd Liu, 2016). Alternative methods have also been explored which train a supporting model using in-scope data rather 1 than directly training a core model to detect OOS All code and data for major experiments are available at https://github.com/asappresearch/gold instances (Gangal et al., 2020). As a result, they 429 Detecting out-of-scope scenarios is an essential skill of dialogue systems deployed into the real world. While an ideal system would behave appropriately in all conversational settings, such perfection is not possible given that training data is finite, while user inputs are not (Geiger et al., 2019). Out-of-distribution issues occur when the model encounters situations not covered during training, including novel user intents, domain shifts or custom entities (Kamath et al., 2020; Cavalin et al., 2020). Unique to conversations, dialogue breakdowns represent cases where the user cannot continue the interaction with the system, perhaps Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 429–442 c November 7–11, 2021. 2021 Association for Computational Linguistics suffer from a mismatch where the objective during training does not line up with the e"
2021.emnlp-main.35,L16-1502,0,0.0217278,"out-ofscope scenarios is to train directly on OOS examples (Fumera et al., 2003). These situations are encountered more broadly by the insertion of any out-of-distribution response or more specifically when a particular utterance does not make sense in the current context. 2019; Mohseni et al., 2020) or assume access to an impractically large number of OOS examples in relation to INS examples (Tan et al., 2019; Kamath et al., 2020; Larson et al., 2019) Dialogue Breakdown In comparison to out-ofdistribution cases, dialogue breakdowns are unique to conversations because they depend on context (Higashinaka et al., 2016). In other words, the utterances fall within the distribution of reasonable responses but are out-of-scope due to the state of the particular dialogue. Such breakdowns occur when the conversation can no longer proceed smoothly due to an ambiguous statement from the user or some misunderstanding made by the agent (Ng et al., 2020b). GOLD also focuses on dialogue, but additionally operates under the setting of limited access to OOS data during training (Hendriksen et al., 2019). 2.2 Indirect Prediction An alternative set of methods for OOS detection assume access to a supporting model trained so"
2021.emnlp-main.35,C18-1105,0,0.0192181,"for approaching indirect prediction generally fall into three categories: probability Data Augmentation for Dialogue Methods for threshold, outlier distance and Bayesian ensemble. augmenting data to train dialogue systems are most In all cases, the supporting model trained on the closely related to our work. Previous research has used data augmentation to improve natural lan- intent classification task uses a pretrained BERT model as its base (Devlin et al., 2019). guage understanding (NLU) and intent detection in Starting with Probability Threshold baselines, dialogue (Niu and Bansal, 2019; Hou et al., 2018). Other methods augment the in-scope sample repre- (1) MaxProb declares an example as OOS if the maximum value of the supporting model’s sentations to support out-of-scope robustness (Ryu et al., 2018; Ng et al., 2020a; Lee and Shalymi- output probability distribution falls below some nov, 2019). Recently, generative adversarial net- threshold τ (Hendrycks and Gimpel, 2017). (2) works (GANs) have been used to create out-of- ODIN enhances this by adding temperature scaldomain examples that mimic known in-scope ex- ing and small perturbations to the input which help to increase the gap between I"
2021.emnlp-main.35,P16-1002,0,0.0228564,"dels to make decisions. When the variance of the predictions is high, then the input is supposedly difficult to recognize and thus out-of-distribution. Such ensembles can be formed explicitly through a collection of models (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope di"
2021.emnlp-main.35,2020.acl-main.503,0,0.202687,"a for major experiments are available at https://github.com/asappresearch/gold instances (Gangal et al., 2020). As a result, they 429 Detecting out-of-scope scenarios is an essential skill of dialogue systems deployed into the real world. While an ideal system would behave appropriately in all conversational settings, such perfection is not possible given that training data is finite, while user inputs are not (Geiger et al., 2019). Out-of-distribution issues occur when the model encounters situations not covered during training, including novel user intents, domain shifts or custom entities (Kamath et al., 2020; Cavalin et al., 2020). Unique to conversations, dialogue breakdowns represent cases where the user cannot continue the interaction with the system, perhaps Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 429–442 c November 7–11, 2021. 2021 Association for Computational Linguistics suffer from a mismatch where the objective during training does not line up with the eventual inference task, likely leading to suboptimal performance. More recently, data augmentation techniques have been applied to in-scope (INS) data to improve out-of-domain robustne"
2021.emnlp-main.35,N18-2072,0,0.0120998,"mentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope dialogues. The input context xi = {(S1 , U1 ), ..., (St , Ut )} is a series of system and user utterances within t turns of a conversation. The desired output yi ∈ [0, 1] is a binary label representing whether that context is out-of-scope. We define OOS to encompass both out-of-distribution utterances, such as out-of-domain intents or gibberish speech, as well as in-distribution utterances spoken in an ambiguous manner. A model given acce"
2021.emnlp-main.35,D19-1131,0,0.0348215,"Missing"
2021.emnlp-main.35,P19-1548,0,0.0155687,"function may be out-of-scope because it was not included in or distance function used for determining the dethe distribution the dialogue model was trained on. gree of separation. (Cavalin et al., 2020; Oh et al., Distribution shifts may occur due to unknown user 2018; Yilmaz and Toraman, 2020). For example, intents, different domains or incoherent speech. We Local Outlier Factor (LOF) defines an outlier as a differ from such methods since they either operate point whose density is lower than that of its nearest on images (Kim and Kim, 2018; Hendrycks et al., neighbors (Breunig et al., 2000; Lin and Xu, 2019). 430 Bayesian Ensembles The final class of methods utilize the variance of supporting models to make decisions. When the variance of the predictions is high, then the input is supposedly difficult to recognize and thus out-of-distribution. Such ensembles can be formed explicitly through a collection of models (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings."
2021.emnlp-main.35,2020.emnlp-main.726,0,0.0155892,"018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope dialogues. The input context xi = {(S1 , U1 ), ..., (St , Ut )} is a series of system and user utterances within t turns of a conversation. The desired output yi ∈ [0, 1] is a binary label representing whether that context is out-of-scope"
2021.emnlp-main.35,2021.ccl-1.108,0,0.0527108,"Missing"
2021.emnlp-main.35,2021.naacl-industry.30,0,0.0328456,"mple repre- (1) MaxProb declares an example as OOS if the maximum value of the supporting model’s sentations to support out-of-scope robustness (Ryu et al., 2018; Ng et al., 2020a; Lee and Shalymi- output probability distribution falls below some nov, 2019). Recently, generative adversarial net- threshold τ (Hendrycks and Gimpel, 2017). (2) works (GANs) have been used to create out-of- ODIN enhances this by adding temperature scaldomain examples that mimic known in-scope ex- ing and small perturbations to the input which help to increase the gap between INS and OOS amples (Zheng et al., 2020; Marek et al., 2021). In instances (Liang et al., 2018). (3) Entropy considcontrast, we operate directly on OOS samples and ers an example to be OOS if the supporting model consciously generate data far away from anything is uncertain, as determined by the entropy level seen during pre-training, a decision which our later rising above a threshold τ (Lewis and Gale, 1994). analysis reveals to be quite important. Outlier Distance baselines find OOS examples by casting the problem as detecting outliers. Inputs 3 Background and Baselines are considered outliers when their embeddings are In this section we formally de"
2021.emnlp-main.35,2020.emnlp-main.97,0,0.452983,"valin et al., 2020). Unique to conversations, dialogue breakdowns represent cases where the user cannot continue the interaction with the system, perhaps Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 429–442 c November 7–11, 2021. 2021 Association for Computational Linguistics suffer from a mismatch where the objective during training does not line up with the eventual inference task, likely leading to suboptimal performance. More recently, data augmentation techniques have been applied to in-scope (INS) data to improve out-of-domain robustness (Ng et al., 2020a; Zheng et al., 2020). However, we hypothesize that since INS data comes from a different distribution as OOS data, augmentation on the former will not perform as well as augmentation on the latter. In this paper, we propose a method of Generating Out-of-scope Labels with Data augmentation (GOLD) to improve OOS detection in dialogue. To create new pseudo-labeled examples, we start with a small seed set of known OOS examples. Next, we find utterances that are similar to the known OOS examples within an auxiliary dataset. We then generate candidate labels by replacing text from the known OOS ex"
2021.emnlp-main.35,D19-1132,0,0.0151748,"aselines Prior methods for approaching indirect prediction generally fall into three categories: probability Data Augmentation for Dialogue Methods for threshold, outlier distance and Bayesian ensemble. augmenting data to train dialogue systems are most In all cases, the supporting model trained on the closely related to our work. Previous research has used data augmentation to improve natural lan- intent classification task uses a pretrained BERT model as its base (Devlin et al., 2019). guage understanding (NLU) and intent detection in Starting with Probability Threshold baselines, dialogue (Niu and Bansal, 2019; Hou et al., 2018). Other methods augment the in-scope sample repre- (1) MaxProb declares an example as OOS if the maximum value of the supporting model’s sentations to support out-of-scope robustness (Ryu et al., 2018; Ng et al., 2020a; Lee and Shalymi- output probability distribution falls below some nov, 2019). Recently, generative adversarial net- threshold τ (Hendrycks and Gimpel, 2017). (2) works (GANs) have been used to create out-of- ODIN enhances this by adding temperature scaldomain examples that mimic known in-scope ex- ing and small perturbations to the input which help to increas"
2021.emnlp-main.35,D14-1162,0,0.0845441,"Missing"
2021.emnlp-main.35,D19-1410,0,0.0128214,"gainst baseline methods, we also run experiments to study the impact of varying the auxiliary dataset and the extraction options. 5.3.1 Source Datasets Figure 3: AUROC performance across source datasets 2017). Finally, we consider mixing all four datasets together into a single collection (MIX). 5.3.2 Extraction Techniques To optimize the procedure of extracting matches from the source data, we try four different mechanisms for embedding utterances. (1) We feed each OOS instance into a SentenceRoBERTa model pretrained for paraphrase retrieval to find similar utterances within the source data (Reimers and Gurevych, 2019). (2) As a second option, we encode source data using a static BERT Transformer model (Devlin et al., 2019). Then for each OOS example encoded in the same manner, we extract the nearest source utterances. (3) We embed OOS and source data as a bag-of-words where each token is a 300-dim GloVe embedding (Pennington et al., 2014). (4) As a final variation, we embed all utterances with TF-IDF embeddings of 7000 dimensions. The spectrum of extraction techniques aim to progress from methods that capture strong semantic connections to the OOS seed data towards options with weaker relation to original"
2021.emnlp-main.35,D18-1077,0,0.0273963,"rain dialogue systems are most In all cases, the supporting model trained on the closely related to our work. Previous research has used data augmentation to improve natural lan- intent classification task uses a pretrained BERT model as its base (Devlin et al., 2019). guage understanding (NLU) and intent detection in Starting with Probability Threshold baselines, dialogue (Niu and Bansal, 2019; Hou et al., 2018). Other methods augment the in-scope sample repre- (1) MaxProb declares an example as OOS if the maximum value of the supporting model’s sentations to support out-of-scope robustness (Ryu et al., 2018; Ng et al., 2020a; Lee and Shalymi- output probability distribution falls below some nov, 2019). Recently, generative adversarial net- threshold τ (Hendrycks and Gimpel, 2017). (2) works (GANs) have been used to create out-of- ODIN enhances this by adding temperature scaldomain examples that mimic known in-scope ex- ing and small perturbations to the input which help to increase the gap between INS and OOS amples (Zheng et al., 2020; Marek et al., 2021). In instances (Liang et al., 2018). (3) Entropy considcontrast, we operate directly on OOS samples and ers an example to be OOS if the suppor"
2021.emnlp-main.35,N19-1380,0,0.027361,"on utterances associated with a clear intent, once again dropping turns representing greetings and other pleasantries, which results in 71,551 examples spanning 44 total intents. The test set is hidden behind a leaderboard, so we divide the development set in half, resulting in an approximate 90/5/5 split for train, dev and test, respectively. Real Out-of-Domain Sentences From Taskoriented Dialog ROSTD is a dataset explicitly designed for out-of-distribution recognition (Gangal et al., 2020). The authors constructed sentences to be OOS examples with respect to a separate dataset collected by Schuster et al. (2019). The dialogues found in the original dataset then represent 433 the INS examples. ROSTD contains 47,913 total utterances spanning 13 intent classes and comes with a pre-defined 70/10/20 split which we leave unaltered. The dataset is less conversational since each example consists of a single turn command, while its labels are higher precision since each OOS instance is human-curated. 5.2 Evaluation Metrics Following prior work on out-of-distribution detection (Hendrycks and Gimpel, 2017; Ren et al., 2019), we evaluate our method on three primary metrics. (1) Area under the receiver operating"
2021.emnlp-main.35,D17-1314,0,0.0119321,"nt speech. We Local Outlier Factor (LOF) defines an outlier as a differ from such methods since they either operate point whose density is lower than that of its nearest on images (Kim and Kim, 2018; Hendrycks et al., neighbors (Breunig et al., 2000; Lin and Xu, 2019). 430 Bayesian Ensembles The final class of methods utilize the variance of supporting models to make decisions. When the variance of the predictions is high, then the input is supposedly difficult to recognize and thus out-of-distribution. Such ensembles can be formed explicitly through a collection of models (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as"
2021.emnlp-main.35,K17-2010,0,0.0228475,"s. When the variance of the predictions is high, then the input is supposedly difficult to recognize and thus out-of-distribution. Such ensembles can be formed explicitly through a collection of models (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope dialogues. The input context"
2021.emnlp-main.35,D19-1364,0,0.0194134,"ness of our best performing model. Finally, we provide analysis and insights on augmenting OOS data for other dialogue systems. 2 2.1 Related Work Direct Prediction A straightforward method of detecting out-ofscope scenarios is to train directly on OOS examples (Fumera et al., 2003). These situations are encountered more broadly by the insertion of any out-of-distribution response or more specifically when a particular utterance does not make sense in the current context. 2019; Mohseni et al., 2020) or assume access to an impractically large number of OOS examples in relation to INS examples (Tan et al., 2019; Kamath et al., 2020; Larson et al., 2019) Dialogue Breakdown In comparison to out-ofdistribution cases, dialogue breakdowns are unique to conversations because they depend on context (Higashinaka et al., 2016). In other words, the utterances fall within the distribution of reasonable responses but are out-of-scope due to the state of the particular dialogue. Such breakdowns occur when the conversation can no longer proceed smoothly due to an ambiguous statement from the user or some misunderstanding made by the agent (Ng et al., 2020b). GOLD also focuses on dialogue, but additionally operate"
2021.emnlp-main.35,D15-1306,0,0.0185877,"ugh a collection of models (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope dialogues. The input context xi = {(S1 , U1 ), ..., (St , Ut )} is a series of system and user utterances within t turns of a conversation. The desired output yi ∈ [0, 1] is a binary label represent"
2021.emnlp-main.35,D19-1670,0,0.0118642,"stribution. Such ensembles can be formed explicitly through a collection of models (Vyas et al., 2018; Shu et al., 2017; Lakshminarayanan et al., 2017) or implicitly through multiple applications of dropout (Gal and Ghahramani, 2016). 2.3 Data Augmentation Our method also pertains to the use of data augmentation to improve model performance under low resource settings. Augmentation in NLP Data augmentation for NLP has been studied extensively in the past (Jia and Liang, 2016; Silfverberg et al., 2017; F¨urstenau and Lapata, 2009). Common methods include those that alter the surface form text (Wei and Zou, 2019) or perturb a latent embedding space (Wang and Yang, 2015; Fadaee et al., 2017; Liu et al., 2020), as well as those that perform paraphrasing (Zhang et al., 2019). Alternatively, masked language models generate new examples by proposing context-aware replacements for the masked token (Kobayashi, 2018; Wu et al., 2019). 3.1 Problem Formulation Let Ddirect = {(x1 , y1 ), ..., (xn , yn )} be a target dataset containing a mixture of in-scope and out-of-scope dialogues. The input context xi = {(S1 , U1 ), ..., (St , Ut )} is a series of system and user utterances within t turns of a conversation. T"
2021.emnlp-main.35,P18-1205,0,0.0443771,"Missing"
2021.emnlp-main.35,N19-1131,0,0.0591037,"Missing"
2021.emnlp-main.590,2020.acl-main.573,0,0.0378034,"observe that by storing only a few samples per task (10-50) the model still greatly suffers from catastrophic forgetting, where with around 500 samples, which is equivalent to a total of 18,500 samples in our setting, the performance is closer to that of the multitask baseline (i.e., a possible upper bound). Similar observations are shown for the other two tasks in Figure 8, 9, and 10 in the Appendix. a fine-tuning step) during inference. Finally, continual learning has been used for sentence encoding (Liu et al., 2019), composition language learning (Li et al., 2019c) and relation learning (Han et al., 2020). However, these methods are specific to particular applications not generalizable to ToDs. 6 Related Work Continual learning methods are usually developed and benchmarked on computer visions tasks. Interested readers may refer to Mundt et al. (2020); Parisi et al. (2019); De Lange et al. (2019) for an overview of the existing approaches, and to Section 2.2 for more details on the three main CL approaches studied in this paper. Continual learning has also been studied in the Long Life Learning (LLL) scenario, where a learner continuously accumulates knowledge and makes use of it in the future"
2021.emnlp-main.622,D18-1547,0,0.416429,"of a list of slot-value pairs. Training a tion model for non-categorical slots and a classifiDST model often requires extensive annotated di- cation model for categorical slots, which hinders alogue data. These data are often collected via a the knowledge sharing from the different types of Wizard-of-Oz (Woz) (Kelley, 1984) setting, where QA datasets. Furthermore, unanswerable questions two workers converse with each other and anno- are not considered during their QA training phase. tate the dialogue states of each utterance (Wen Therefore, in a zero-shot DST setting, the model et al., 2017; Budzianowski et al., 2018; Moon et al., proposed by Gao et al. (2020) is not able to han2020), or with a Machines Talking To Machines dle “none” value slots (e.g., unmentioned slots) ∗ Work done during internship at Facebook that present in the dialogue state. 7890 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7890–7900 c November 7–11, 2021. 2021 Association for Computational Linguistics Figure 1: A high-level representation of the cross-task transfer for zero-shot DST (best viewed in color). During the QA training phase (top figure), the unified generative model (T5) i"
2021.emnlp-main.622,2020.acl-main.12,0,0.0330909,"Missing"
2021.emnlp-main.622,N19-1423,0,0.062187,"Missing"
2021.emnlp-main.622,Q19-1026,0,0.012715,"uncating the context passage from the first sentence that contains the answer span. As illustrated in Figure 3, given a question and a passage from a QA training set, we first truncate the passage according to the answer span annotation, then we pair the question and the truncated passage as an unanswerable sample. 3 Experiments 3.1 Datasets QA datasets. For the QA training, we use six extractive QA datasets such as SQuAD2.0 (Rajpurkar et al., 2018) 1 , NewsQA (Trischler et al., 2017), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), Natural Question (Kwiatkowski et al., 2019) from MRQA-2019 (Fisch et al., 2019), and two multichoice datasets such as RACE (Lai et al., 2017) and DREAM (Sun et al., 2019). The main train/dev statistics are reported in Table 1. DST datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level annotations of dialogue states. In MultiWoz, we follow the pre-processing and evaluation setup from Wu et al. (2019), where restaurant, train, attraction, hotel, and taxi dom"
2021.emnlp-main.622,D17-1082,0,0.0876989,"re 3, given a question and a passage from a QA training set, we first truncate the passage according to the answer span annotation, then we pair the question and the truncated passage as an unanswerable sample. 3 Experiments 3.1 Datasets QA datasets. For the QA training, we use six extractive QA datasets such as SQuAD2.0 (Rajpurkar et al., 2018) 1 , NewsQA (Trischler et al., 2017), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), Natural Question (Kwiatkowski et al., 2019) from MRQA-2019 (Fisch et al., 2019), and two multichoice datasets such as RACE (Lai et al., 2017) and DREAM (Sun et al., 2019). The main train/dev statistics are reported in Table 1. DST datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level annotations of dialogue states. In MultiWoz, we follow the pre-processing and evaluation setup from Wu et al. (2019), where restaurant, train, attraction, hotel, and taxi domains are used for training and testing. In SGD, the test set has 18 domains, and 5 of the domains"
2021.emnlp-main.622,P19-1546,0,0.0155263,"no “none” values are considered as active slots. Then the model gener2 https://github.com/jasonwu0731/ trade-dst 3 https://github.com/google-research/ google-research/tree/master/schema_ guided_dst 4 Source code is available in https://github.com/ facebookresearch/Zero-Shot-DST 7893 Model Joint Goal Accuracy Hotel Restaurant Taxi Train Average 20.06 22.46 22.60 31.25 14.20 16.28 19.80 22.72 12.59 13.56 16.50 26.28 59.21 59.27 59.50 61.87 22.39 22.76 22.50 36.72 25.69 26.87 28.18 35.77 56.81 53.90 56.81 63.22 49.57 56.06 Attraction TRADE† (Wu et al., 2019) MA-DST† (Kumar et al., 2020) SUMBT‡ (Lee et al., 2019) TransferQA (Ours) w/ Oracle Slot Gate SGD-baseline JGA AGA TransferQA JGA AGA Unseen Buses* Messaging* Payment* Trains* Alarm* 9.7 10.2 11.5 13.6 57.7 50.9 20.0 34.8 63.5 1.8 15.9 13.3 24.7 17.4 58.3 63.6 37.9 60.7 64.9 81.7 Seen Table 2: Zero-shot results on MultiWoz 2.1 (Eric et al., 2020). Results marked with † and ‡ are from Kumar et al. (2020) and Campagna et al. (2020). We also report the averaged zero shot joint goal accuracy among five domains. Note that this averaged per-domain accuracy is not comparable to the JGA in full shot setting. RentalCars Music RideSharing Media Homes Restau"
2021.emnlp-main.622,P18-1133,0,0.024592,"Predicted Values hotel-area hotel-pricerange what is the area of the hotel that the user wants? what is the price range of the hotel or guesthouse that the user wants? east cheap none none Table 6: Two typical errors of TransferQA zeroshot in MultiWoz 2.1. The first (top example) is predicting the values that not confirmed by the user yet, and the second (bottom example) is missing the values of implicit mentioned domain. Dialogue State Tracking is an essential yet challenging task in conversational AI research (Williams and Young, 2007; Williams et al., 2014). Recent state-of-the-art models (Lei et al., 2018; Zhang et al., 2020; Wu et al., 2020; Peng et al., 2020; Zhang et al., 2019; Kim et al., 2019; Lin et al., 2020; Chen et al., 2020; Heck et al., 2020; Mehri et al., 2020; Hosseini-Asl et al., 2020; Yu et al., 2020; Li et al., 2020; Madotto et al., 2020) trained with extensive annotated dialogue data have shown promising performance in complex multi-domain conversations (Budzianowski et al., 2018; Eric et al., 2020). However, collecting large amounts of data for every dialogue domain is often costly and inefficient. To reduce the expense of data acquisition, zero-shot (few-shot) transfer learn"
2021.emnlp-main.622,2021.acl-long.353,0,0.0363165,"Missing"
2021.emnlp-main.622,2021.naacl-main.448,1,0.866589,"Missing"
2021.emnlp-main.622,2020.emnlp-main.273,1,0.761706,"e range of the hotel or guesthouse that the user wants? east cheap none none Table 6: Two typical errors of TransferQA zeroshot in MultiWoz 2.1. The first (top example) is predicting the values that not confirmed by the user yet, and the second (bottom example) is missing the values of implicit mentioned domain. Dialogue State Tracking is an essential yet challenging task in conversational AI research (Williams and Young, 2007; Williams et al., 2014). Recent state-of-the-art models (Lei et al., 2018; Zhang et al., 2020; Wu et al., 2020; Peng et al., 2020; Zhang et al., 2019; Kim et al., 2019; Lin et al., 2020; Chen et al., 2020; Heck et al., 2020; Mehri et al., 2020; Hosseini-Asl et al., 2020; Yu et al., 2020; Li et al., 2020; Madotto et al., 2020) trained with extensive annotated dialogue data have shown promising performance in complex multi-domain conversations (Budzianowski et al., 2018; Eric et al., 2020). However, collecting large amounts of data for every dialogue domain is often costly and inefficient. To reduce the expense of data acquisition, zero-shot (few-shot) transfer learning has been proposed as an effective solution. Wu et al. (2019) adapt a copy mechanism for transferring prior k"
2021.emnlp-main.622,2021.ccl-1.108,0,0.0535518,"Missing"
2021.emnlp-main.622,P18-2124,0,0.020354,"omain unmentioned slots often appear in the middle of conversations, where some of the in-domain slots have not yet mentioned by the user. We simulate such scenario by truncating the context passage from the first sentence that contains the answer span. As illustrated in Figure 3, given a question and a passage from a QA training set, we first truncate the passage according to the answer span annotation, then we pair the question and the truncated passage as an unanswerable sample. 3 Experiments 3.1 Datasets QA datasets. For the QA training, we use six extractive QA datasets such as SQuAD2.0 (Rajpurkar et al., 2018) 1 , NewsQA (Trischler et al., 2017), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), Natural Question (Kwiatkowski et al., 2019) from MRQA-2019 (Fisch et al., 2019), and two multichoice datasets such as RACE (Lai et al., 2017) and DREAM (Sun et al., 2019). The main train/dev statistics are reported in Table 1. DST datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level an"
2021.emnlp-main.622,D16-1264,0,0.0515644,"datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level annotations of dialogue states. In MultiWoz, we follow the pre-processing and evaluation setup from Wu et al. (2019), where restaurant, train, attraction, hotel, and taxi domains are used for training and testing. In SGD, the test set has 18 domains, and 5 of the domains are not presented in the training set. 1 Note that original MRQA-2019 dataset use SQuAD (Rajpurkar et al., 2016), here we also add the unanswerable questions from SQuAD2.0. Dataset Type Train Dev SQuAD2.0 NewsQA TriviaQA SearchQA HotpotQA NaturalQA extractive extractive extractive extractive extractive extractive 130,319 74,160 61,688 117,384 72,928 104,071 11,873 4,212 7,785 16,980 5,904 12,836 multiple-choice multiple-choice 87,866 6,116 4,887 2,040 RACE DREAM Table 1: Datasets used in the QA pre-training. Statistics of extractive datasets (except SQuAD2.0) are taken from MRQA-2019 (Fisch et al., 2019), and that of multiple-choice datasets are from RACE (Lai et al., 2017) and DREAM (Sun et al., 2019)."
2021.emnlp-main.622,N18-2074,0,0.0549602,"Missing"
2021.emnlp-main.622,Q19-1014,0,0.141767,"passage from a QA training set, we first truncate the passage according to the answer span annotation, then we pair the question and the truncated passage as an unanswerable sample. 3 Experiments 3.1 Datasets QA datasets. For the QA training, we use six extractive QA datasets such as SQuAD2.0 (Rajpurkar et al., 2018) 1 , NewsQA (Trischler et al., 2017), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), Natural Question (Kwiatkowski et al., 2019) from MRQA-2019 (Fisch et al., 2019), and two multichoice datasets such as RACE (Lai et al., 2017) and DREAM (Sun et al., 2019). The main train/dev statistics are reported in Table 1. DST datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level annotations of dialogue states. In MultiWoz, we follow the pre-processing and evaluation setup from Wu et al. (2019), where restaurant, train, attraction, hotel, and taxi domains are used for training and testing. In SGD, the test set has 18 domains, and 5 of the domains are not presented in the trai"
2021.emnlp-main.622,W17-2623,0,0.0269985,"in the middle of conversations, where some of the in-domain slots have not yet mentioned by the user. We simulate such scenario by truncating the context passage from the first sentence that contains the answer span. As illustrated in Figure 3, given a question and a passage from a QA training set, we first truncate the passage according to the answer span annotation, then we pair the question and the truncated passage as an unanswerable sample. 3 Experiments 3.1 Datasets QA datasets. For the QA training, we use six extractive QA datasets such as SQuAD2.0 (Rajpurkar et al., 2018) 1 , NewsQA (Trischler et al., 2017), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), Natural Question (Kwiatkowski et al., 2019) from MRQA-2019 (Fisch et al., 2019), and two multichoice datasets such as RACE (Lai et al., 2017) and DREAM (Sun et al., 2019). The main train/dev statistics are reported in Table 1. DST datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level annotations of dialogue states. In Mul"
2021.emnlp-main.622,D19-1221,0,0.0383259,"Missing"
2021.emnlp-main.622,E17-1042,0,0.0744009,"Missing"
2021.emnlp-main.622,2020.emnlp-main.66,0,0.0179673,"erange what is the area of the hotel that the user wants? what is the price range of the hotel or guesthouse that the user wants? east cheap none none Table 6: Two typical errors of TransferQA zeroshot in MultiWoz 2.1. The first (top example) is predicting the values that not confirmed by the user yet, and the second (bottom example) is missing the values of implicit mentioned domain. Dialogue State Tracking is an essential yet challenging task in conversational AI research (Williams and Young, 2007; Williams et al., 2014). Recent state-of-the-art models (Lei et al., 2018; Zhang et al., 2020; Wu et al., 2020; Peng et al., 2020; Zhang et al., 2019; Kim et al., 2019; Lin et al., 2020; Chen et al., 2020; Heck et al., 2020; Mehri et al., 2020; Hosseini-Asl et al., 2020; Yu et al., 2020; Li et al., 2020; Madotto et al., 2020) trained with extensive annotated dialogue data have shown promising performance in complex multi-domain conversations (Budzianowski et al., 2018; Eric et al., 2020). However, collecting large amounts of data for every dialogue domain is often costly and inefficient. To reduce the expense of data acquisition, zero-shot (few-shot) transfer learning has been proposed as an effective"
2021.emnlp-main.622,P19-1078,1,0.83341,"nsuming manual annotations, while M2M requires exhaustive hand-crafted rules for covering various dialogue scenarios. In industrial applications, virtual assistants are required to add new services (domains) frequently based on user’s needs, but collecting extensive data for every new domain is costly and inefficient. Therefore, performing zero-shot prediction of dialogue states is becoming increasingly important since it does not require the expense of data acquisition. There are mainly two lines of work in the zero-shot transfer learning problem. The first is cross-domain transfer learning (Wu et al., 2019; Kumar et al., 2020; Rastogi et al., 2020; Lin et al., 2021a), where the models are first trained on several domains, then zero-shot to new domains. However, these methods rely on a considerable amount 1 Introduction of DST data to cover a broad range of slot types, Virtual assistants are designed to help users per- and it is still challenging for the models to handle form daily activities, such as travel planning, on- new slot types in the unseen domain. The second line shopping and restaurant booking. Dialogue line of work leverages machine reading question state tracking (DST), as an essen"
2021.emnlp-main.622,D18-1259,0,0.0255177,"user. We simulate such scenario by truncating the context passage from the first sentence that contains the answer span. As illustrated in Figure 3, given a question and a passage from a QA training set, we first truncate the passage according to the answer span annotation, then we pair the question and the truncated passage as an unanswerable sample. 3 Experiments 3.1 Datasets QA datasets. For the QA training, we use six extractive QA datasets such as SQuAD2.0 (Rajpurkar et al., 2018) 1 , NewsQA (Trischler et al., 2017), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), Natural Question (Kwiatkowski et al., 2019) from MRQA-2019 (Fisch et al., 2019), and two multichoice datasets such as RACE (Lai et al., 2017) and DREAM (Sun et al., 2019). The main train/dev statistics are reported in Table 1. DST datasets. The evaluation is conducted on two multi-domain task-oriented dialogue benchmark, MultiWoz (Budzianowski et al., 2018; Eric et al., 2020) and Schema-Guided-Dialogue (SGD) (Rastogi et al., 2020). Both datasets provide turn-level annotations of dialogue states. In MultiWoz, we follow the pre-processing and evaluation setup from Wu et al. (2019), where resta"
2021.emnlp-main.622,2020.nlp4convai-1.13,0,0.0601404,"Missing"
2021.findings-emnlp.194,K16-1002,0,0.0457387,"he generation process can be controlled using arbitrary attributes expressed as words or phrases. Table 1 shows text generated using the prompt The issue focused on with various control attributes. We evaluate our proposed method on sentiment and topic control and show better performance than previous state-of-the-art methods in controlling effectiveness and language quality 1 . pre-training (e.g. 55 control codes in CTRL). Another approach is to concatenate the attribute representation to the hidden states using linear transformation (Hoang et al., 2016; Fu et al., 2018) or latent variables (Bowman et al., 2016; Wang et al., 2019). These approaches require training from scratch or fine-tuning the entire pre-trained model to incorporate the external target attributes and model conditional probability (Ficler and Goldberg, 2017; Ziegler et al., 2019a; Smith et al., 2020). In addition, they always require carefully designed Kullback-Leibler (KL)-Divergence and adversarial training to generate out-of training domain text with the desirable attribute only (Romanov et al., 2019). In comparison, our proposed method does not require fine-tuning the original LM so that we can make use of the high quality pre"
2021.findings-emnlp.194,N19-1423,0,0.0329788,"Missing"
2021.findings-emnlp.194,W17-4912,0,0.0951595,"proposed method on sentiment and topic control and show better performance than previous state-of-the-art methods in controlling effectiveness and language quality 1 . pre-training (e.g. 55 control codes in CTRL). Another approach is to concatenate the attribute representation to the hidden states using linear transformation (Hoang et al., 2016; Fu et al., 2018) or latent variables (Bowman et al., 2016; Wang et al., 2019). These approaches require training from scratch or fine-tuning the entire pre-trained model to incorporate the external target attributes and model conditional probability (Ficler and Goldberg, 2017; Ziegler et al., 2019a; Smith et al., 2020). In addition, they always require carefully designed Kullback-Leibler (KL)-Divergence and adversarial training to generate out-of training domain text with the desirable attribute only (Romanov et al., 2019). In comparison, our proposed method does not require fine-tuning the original LM so that we can make use of the high quality pre-trained LM while controlling the target attributes. 2 Related Work Instead of fine-tuning the whole model, Houlsby et al. (2019) proposes to add residual adapters, Controlled text generation To interpolate a conwhich a"
2021.findings-emnlp.194,N16-1149,0,0.0243577,"e way the attributes are encoded, the end result is that the generation process can be controlled using arbitrary attributes expressed as words or phrases. Table 1 shows text generated using the prompt The issue focused on with various control attributes. We evaluate our proposed method on sentiment and topic control and show better performance than previous state-of-the-art methods in controlling effectiveness and language quality 1 . pre-training (e.g. 55 control codes in CTRL). Another approach is to concatenate the attribute representation to the hidden states using linear transformation (Hoang et al., 2016; Fu et al., 2018) or latent variables (Bowman et al., 2016; Wang et al., 2019). These approaches require training from scratch or fine-tuning the entire pre-trained model to incorporate the external target attributes and model conditional probability (Ficler and Goldberg, 2017; Ziegler et al., 2019a; Smith et al., 2020). In addition, they always require carefully designed Kullback-Leibler (KL)-Divergence and adversarial training to generate out-of training domain text with the desirable attribute only (Romanov et al., 2019). In comparison, our proposed method does not require fine-tuning the"
2021.findings-emnlp.194,Q18-1005,0,0.0260477,"he sentiment attribute representation. Thus, the target attribute representation may be diluted. To solve this problem, we propose three disentanglement methods. 3.2.1 Attribute representation with corpus representation disentanglement (AC) We propose to add a corpus domain representation d along with the attribute representation a during training. For a training corpus (such as movie reviews) with multiple attributes (such as positive and negative sentiment), d is used in all the training data while a is only used in a subset of the training data labeled with the target attribute. Similar to Liu and Lapata (2018), this can encourage the model to encode target attribute and other features separately into different representations. Specifically, the key-value pairs can be represented as K:t00 , V:t00 = [F(Ka ); Fd (Kd ); K:t ], [F(Va ); Fd (Vd ); V:t ] (3) where Fd is a separate alignment function for corpus domain representation, and Kd , Vd are from the LM encoding of corpus domain names. Compared to attributes, corpus domain names might be more abstract so we use special tokens for d (such as <movie review&gt;) and the original texts for attributes (such as athlete). At inference time, we want to genera"
2021.findings-emnlp.194,P11-1015,0,0.275395,"Missing"
2021.findings-emnlp.194,2020.findings-emnlp.219,0,0.313529,"ch ferent from adding adapters for each individual and has been commonly used in grounded generaattribute (Bapna and Firat, 2019; Ziegler et al., tion (Dinan et al., 2019; Prabhumoye et al., 2020). 2019b), our method only requires learning one Keskar et al. (2019) proposes to pre-train a large attribute alignment function for all attributes to conditional language model with available labels do controlled generation, and is more flexible at such as URLs for large LM control. This method inference time without degrading quality such as can be effective in conditional modeling, but rediversity (Madotto et al., 2020). Recently, Chan quires a substantial amount of resources for preet al. (2021) proposes to use self-supervised learntraining and is limited by the labels used during ing with hand-crafted phrases (e.g. “is perfect” to 1 represent positive sentiment), but suffers from high Our code is available at https://github.com/ DianDYu/attribute_alignment variance, low coherence and diversity in order to 2252 Attribute Representation E<movie&gt; Epositive Alignment Function director is great , EThe Edirector Eis Egreat … Eactor E’<movie&gt; E’positive great … actor Pre-trained LM Pre-trained LM <movie&gt; Wt+1 Ali"
2021.findings-emnlp.194,2020.coling-main.1,0,0.0118722,"high quality pre-trained LM while controlling the target attributes. 2 Related Work Instead of fine-tuning the whole model, Houlsby et al. (2019) proposes to add residual adapters, Controlled text generation To interpolate a conwhich are task-specific parameters to transformer trolling factor, concatenating the attribute to the inlayers for each language understanding task. Difput sequence is the most straightforward approach ferent from adding adapters for each individual and has been commonly used in grounded generaattribute (Bapna and Firat, 2019; Ziegler et al., tion (Dinan et al., 2019; Prabhumoye et al., 2020). 2019b), our method only requires learning one Keskar et al. (2019) proposes to pre-train a large attribute alignment function for all attributes to conditional language model with available labels do controlled generation, and is more flexible at such as URLs for large LM control. This method inference time without degrading quality such as can be effective in conditional modeling, but rediversity (Madotto et al., 2020). Recently, Chan quires a substantial amount of resources for preet al. (2021) proposes to use self-supervised learntraining and is limited by the labels used during ing with"
2021.findings-emnlp.194,N19-1088,0,0.120143,"tribute representation to the hidden states using linear transformation (Hoang et al., 2016; Fu et al., 2018) or latent variables (Bowman et al., 2016; Wang et al., 2019). These approaches require training from scratch or fine-tuning the entire pre-trained model to incorporate the external target attributes and model conditional probability (Ficler and Goldberg, 2017; Ziegler et al., 2019a; Smith et al., 2020). In addition, they always require carefully designed Kullback-Leibler (KL)-Divergence and adversarial training to generate out-of training domain text with the desirable attribute only (Romanov et al., 2019). In comparison, our proposed method does not require fine-tuning the original LM so that we can make use of the high quality pre-trained LM while controlling the target attributes. 2 Related Work Instead of fine-tuning the whole model, Houlsby et al. (2019) proposes to add residual adapters, Controlled text generation To interpolate a conwhich are task-specific parameters to transformer trolling factor, concatenating the attribute to the inlayers for each language understanding task. Difput sequence is the most straightforward approach ferent from adding adapters for each individual and has b"
2021.findings-emnlp.194,D13-1170,0,0.0044698,"n the training corpus and generate text conditioned on a new topic as a zero-shot setting. 4 Experiments We evaluate our proposed methods A: using attribute representation only; AC: Model A with corpus representation for disentanglement; ACK: AC with KL disentanglement; and lastly ACB: AC with Bayes disentanglement. We evaluate these models on sentiment control for thorough comparisons. We use nucleus sampling (Holtzman et al., 2020) for all the methods at inference time. Refer to Appendix A.4 for implementation details. 4.1 Sentiment control Data. We use the Stanford Sentiment Treebank (SST, Socher et al., 2013) as our training data. We choose the sentences with positive and negative sentiment to train our alignment function. We select the same 15 prompts such as “Once upon a time” that were used in prior work, which were originally randomly selected, and are listed in Appendix A.2 (Dathathri et al., 2020). log p(x|a) ∼ log p(x|a, d) − log p(x|d) (5) Baselines. We compare with five baselines. During training, we train the attribute and do- GPT2 generates unconditioned sentences given the prompts from pre-trained GPT2-medium. The genmain alignment functions (F, Fd ) by running the erated sentences are"
2021.findings-emnlp.194,N19-1015,0,0.0217332,"can be controlled using arbitrary attributes expressed as words or phrases. Table 1 shows text generated using the prompt The issue focused on with various control attributes. We evaluate our proposed method on sentiment and topic control and show better performance than previous state-of-the-art methods in controlling effectiveness and language quality 1 . pre-training (e.g. 55 control codes in CTRL). Another approach is to concatenate the attribute representation to the hidden states using linear transformation (Hoang et al., 2016; Fu et al., 2018) or latent variables (Bowman et al., 2016; Wang et al., 2019). These approaches require training from scratch or fine-tuning the entire pre-trained model to incorporate the external target attributes and model conditional probability (Ficler and Goldberg, 2017; Ziegler et al., 2019a; Smith et al., 2020). In addition, they always require carefully designed Kullback-Leibler (KL)-Divergence and adversarial training to generate out-of training domain text with the desirable attribute only (Romanov et al., 2019). In comparison, our proposed method does not require fine-tuning the original LM so that we can make use of the high quality pre-trained LM while co"
2021.findings-emnlp.194,2021.acl-long.560,1,0.71687,"sentiment classification dataset and finds that one neuron is responsible for the sentiment value in generation. Our proposed disentanglement methods, on the other hand, encourages the alignment function to encode different attributes to different representations and we leverage Bayes’ Rule to further separate attributes. In machine translation, a language representation is learned by appending a language code to the source sentence (Johnson et al., 2016) or summing with word embeddings (Conneau and Lample, 2019) to guide the translation towards the target language. Inspired by these methods (Yu et al., 2021), Attribute Alignment appends the attribute to the beginning of a sentence and learns an attribute alignment function to transform attribute representations while freezing the LM parameters, without fine-tuning the whole model in previous methods. 3 Methodology Unconditional language models are trained to optimize the probability of p(xi |x0:i−1 ) where xi is the next token and x0:i−1 are already generated tokens. For controlled generation, we need to model the conditional distribution p(xi |x0:i−1 , a) where a is the attribute for the model to condition on. Attribute representation learning L"
2021.findings-emnlp.295,P19-1536,0,0.0545812,"Missing"
2021.findings-emnlp.295,D17-1259,0,0.0185357,"etrained a response selection model with large conversational corpora, and finetuned it on new domains in task-oriented settings for a better context representation. Instead of retrieving candidates from human dialogues, we adopt the imitation learning approach, and leverage language models’ ability to generate coherent responses, and build a selector to imitate human selection process and choose among the generated candidates. Strategic dialogue tasks such as persuasion and negotiation have emerged and attracted more attention recently, given its wide applications in industry and daily life (Lewis et al., 2017; He et al., 2018; Wang et al., 2019; Li et al., 2020b; Shi et al., 2020). These tasks are close to human-human conversations and often contain both a specific task goal and social components to build rapport for better task completion. Previously, Mazzotta et al. (2007) proposed an agenda-based user-adapted persuasion system to build relationship with users and change their eating habit. Yuan et al. (2008) developed a dialogue system for educational debate with strategic heuristics. More recently, Li et al. (2020b) utilized large-scale language models to build a donation persuasion system by"
2021.findings-emnlp.295,D16-1127,0,0.276586,"esponse generation and could substantially impact user exand hence highly intellectual and strategic. perience and impede the persuasion outcome. Previous studies have attempted to address the Besides, although reinforcement learning (RL) first challenge, the dialogue repetition and inconapproaches have achieved big success in stratesistency problems, by changing the object function gic tasks such as games, it requires a soin supervised learning (Li et al., 2020a) or applyphisticated user simulator to provide real-time feedback to the dialogue system, which liming reinforcement learning (RL) (Li et al., 2016; its the application of RL on persuasion diaLiu et al., 2018). But these methods either may logues. To address these issues towards a betlead to uninterpretable behaviors, or rely on handter persuasion dialogue system, we apply RL crafted user simulators that are hard to design for to refine a language model baseline without persuasion dialogues. To tackle these challenges, user simulators, and distill sentence-level inwe propose to extract a policy directly from the formation about repetition, inconsistency, and data and let the models learn from its own mistakes task relevance through rewar"
2021.findings-emnlp.295,2020.acl-main.428,0,0.484978,"ion systems in order to be persuaded (Shi Persuasion dialogue system reflects the maet al., 2020). So the long-standing problems of diachine’s ability to make strategic moves beyond logue repetition and inconsistency can be especially verbal communication, and therefore differensalient in persuasion dialogue systems. Secondly, tiates itself from task-oriented or open-domain different from traditional dialogue tasks, the persuadialogues and has its own unique values. Howsion task is non-collaborative where the user and ever, the repetition and inconsistency probthe system have different goals (Li et al., 2020b), lems still persist in dialogue response generation and could substantially impact user exand hence highly intellectual and strategic. perience and impede the persuasion outcome. Previous studies have attempted to address the Besides, although reinforcement learning (RL) first challenge, the dialogue repetition and inconapproaches have achieved big success in stratesistency problems, by changing the object function gic tasks such as games, it requires a soin supervised learning (Li et al., 2020a) or applyphisticated user simulator to provide real-time feedback to the dialogue system, which"
2021.findings-emnlp.295,N18-1187,0,0.0809793,"hence highly intellectual and strategic. perience and impede the persuasion outcome. Previous studies have attempted to address the Besides, although reinforcement learning (RL) first challenge, the dialogue repetition and inconapproaches have achieved big success in stratesistency problems, by changing the object function gic tasks such as games, it requires a soin supervised learning (Li et al., 2020a) or applyphisticated user simulator to provide real-time feedback to the dialogue system, which liming reinforcement learning (RL) (Li et al., 2016; its the application of RL on persuasion diaLiu et al., 2018). But these methods either may logues. To address these issues towards a betlead to uninterpretable behaviors, or rely on handter persuasion dialogue system, we apply RL crafted user simulators that are hard to design for to refine a language model baseline without persuasion dialogues. To tackle these challenges, user simulators, and distill sentence-level inwe propose to extract a policy directly from the formation about repetition, inconsistency, and data and let the models learn from its own mistakes task relevance through rewards. Moreover, without the use of simulators. Leveraging decodt"
2021.findings-emnlp.295,D17-2014,0,0.0736195,"Missing"
2021.findings-emnlp.295,P19-1253,1,0.872382,"Missing"
2021.findings-emnlp.295,D19-1410,0,0.0239395,"Missing"
2021.findings-emnlp.295,D19-1206,1,0.851621,"2021b; Li et al., 2020a; Song et al., 2020). For example, Li et al. (2020a) proposed to detect the inconsistency with natural language inference data, and penalize it with unlikelihood loss to achieve more consistent personality in open-domain dialogues. Song et al. (2020) detected and rewrote the contradicting responses to achieve a more consistent personality. Our work tackles these problems with RL to reduce exposure bias in supervised learning and improve the interpretability. Previous work has also explored RL-based methods in dialogue system building (Li et al., 2016; Liu et al., 2018; Shi et al., 2019a,b). For instance, Li et al. (2016) integrated the goal of coherent into the reward design towards more diverse dialogue generation. Liu et al. (2018) presented a hybrid reinforcement and imitation learning approach to enable the agent to learn from interactions with users in task-oriented dialogues. However, such methods not only rely on hand-crafted user simulators that are inherently hard to build (Shi et al., 2019a) for persuasion systems, but also require meaningful rewards that are difficult to design. In this work, we propose to let the model learn from its own mistakes by generating m"
2021.findings-emnlp.94,D19-1189,0,0.0970445,"d multiple periments show that our method obtains statesubgoals. Both the question answering and the recof-the-art results on DuRecDial dataset in both ommendation processes require assistance from acautomatic and human evaluation. curate knowledge information. Therefore, having 1 Introduction rich and accurate knowledge is essential in generating engaging conversations. Since taking all Recommendation dialog systems recently attract possible knowledge as input will lead to more noise much attention due to their significant commercial and high computation, how to select useful knowlpotential (Chen et al., 2019; Jannach et al., 2020). edge in different subgoals is important. Such systems first elicit user preferences through We propose KERS to use knowledge effectively conversations and then provide high-quality recomin multi-subgoal conversational recommendation mendations based on elicited preferences. tasks. In order to control the flow of the converMany real-world recommendation applications sation, we develop a dialog guidance module that usually involve chitchat, question answering, and predicts a sequence of subgoals and selects userecommendation dialogs working together (Wang ful external kn"
2021.findings-emnlp.94,2020.emnlp-main.654,1,0.7994,"ation and red arrows indicate selected knowledge triple. and the knowledge enhancement module increases the importance of the selected knowledge in response generation. Both automatic and manual evaluations suggest that KERS has a better performance compared to state-of-the-art methods. 2 Related Work et al., 2019; Zhou et al., 2020b) also introduced topic transition approaches similar to the subgoal transition to improve the quality of open-domain dialogs. They built the topic path by either traversing on a knowledge graph or predicting knowledge items directly. Similar to Liu et al. (2020), Hayati et al. (2020) utilized sentence-level sociable recommendation strategy labels in the INSPIRED dataset to improve the recommendation success rate. However, the INSPIRED dataset was not annotated with specific dialog subgoals. Some relevant works for our project focused on obtaining knowledge information from all the related knowledge triples (Liu et al., 2020; Chen et al., 2019), or enhancing the semantic representations by incorporating both word-oriented and entity-oriented knowledge graphs (Zhou et al., 2020a). However, our work differs because it has fine-grained knowledge planning and accurate knowledg"
2021.findings-emnlp.94,D19-1203,0,0.0179828,"ex knowledge graphs, including both sentences and entities. Most previous work in recommendation dialog systems focused on slot-filling methods to collect user preferences and recommend items (Reschke et al., 2013; Christakopoulou et al., 2016; Sun and Zhang, 2018; Christakopoulou et al., 2018; Zhang et al., 2018; Lee et al., 2018; Lei et al., 2020). To study more sociable and informative recommendation conversations, Li et al. (2018); Moon et al. (2019); Zhou et al. (2020b) proposed new recommendation dialog datasets with knowledge graphs, and incorporated knowledge into response generation. Kang et al. (2019) created a dialog dataset with clear goals. Chen et al. (2019) captured knowledgegrounded information and used recommendationaware vocabulary bias to improve the quality of language generation. 3 Method Recently, Liu et al. (2020) proposed utilizing subgoal sequences to plan dialog paths and KERS consists of three modules: a dialog guidance presented a new recommendation dialog dataset module (section 3.1), an encoder (section 3.2), and DuRecDial. They demonstrated that establishing a a decoder (section 3.3), as shown in Figure 2. The subgoal sequence is crucial for natural transitions decoder"
2021.findings-emnlp.94,D14-1181,0,0.00474209,"Missing"
2021.findings-emnlp.94,N16-1014,0,0.0891065,"Missing"
2021.findings-emnlp.94,2020.acl-main.98,0,0.206499,"ubgoal. Subgoals can be seen as different dialog chance of a successful recommendation. It phases. Figure 1 shows an example dialog with is beneficial to divide up, such conversations multiple subgoals. All the subgoals are designed to with multiple subgoals (such as social chat, complete the final recommendation. question answering, recommendation, etc.), so that the system can retrieve appropriate An RNN-based multi-goal driven conversation knowledge with better accuracy under differgeneration framework (MGCG) was proposed to ent subgoals. In this paper, we propose a uniaddress this task by Liu et al. (2020). MGCG first fied framework for common knowledge-based models the subgoals separately to plan appropriate multi-subgoal dialog: knowledge-enhanced subgoal sequences for topic transitions and final multi-subgoal driven recommender system recommendations. Then MGCG extracts knowl(KERS). We first predict a sequence of subgoals and use them to guide the dialog model edge features from the whole knowledge graph to select knowledge from a sub-set of existing and produces responses to complete each subgoal. knowledge graph. We then propose three new However, MGCG did not investigate how to efmechanis"
2021.findings-emnlp.94,P19-1081,0,0.0265346,". However, our work differs because it has fine-grained knowledge planning and accurate knowledge incorporation in generation. Moreover, we deal with more complex knowledge graphs, including both sentences and entities. Most previous work in recommendation dialog systems focused on slot-filling methods to collect user preferences and recommend items (Reschke et al., 2013; Christakopoulou et al., 2016; Sun and Zhang, 2018; Christakopoulou et al., 2018; Zhang et al., 2018; Lee et al., 2018; Lei et al., 2020). To study more sociable and informative recommendation conversations, Li et al. (2018); Moon et al. (2019); Zhou et al. (2020b) proposed new recommendation dialog datasets with knowledge graphs, and incorporated knowledge into response generation. Kang et al. (2019) created a dialog dataset with clear goals. Chen et al. (2019) captured knowledgegrounded information and used recommendationaware vocabulary bias to improve the quality of language generation. 3 Method Recently, Liu et al. (2020) proposed utilizing subgoal sequences to plan dialog paths and KERS consists of three modules: a dialog guidance presented a new recommendation dialog dataset module (section 3.1), an encoder (section 3.2), and"
2021.findings-emnlp.94,P19-1369,0,0.0278836,"ion of the predicted subgoal Gnext and the final recommendation subgoal GT ) and Kc for next stage processing. where ginext denotes the token in Gnext . Then we input the predicted subgoal into another Transformer to get the candidate knowledge Kc . Because there is no labeled knowledge in ground-truth responses, we obtain pseudo labels in an unsuper- 3.2 Encoder vised manner. We first concatenate the knowledge To incorporate different types of information, we items in the tuple (head, relation, tail). Then we use a vanilla Transformer block as our encoder. We compute the char-based F1 score (Wu et al., 2019) encode context, candidate knowledge selected and 1094 the subgoals predicted by the dialog guidance module independently, since they have different structures. In addition, the input embedding includes word embedding, type embedding, and positional embedding, as shown in Figure 3. The multi-type embeddings help the encoder distinguish different parts of the context better (Wolf et al., 2018). Formally, the outputs of the encoder are computed as follows: EC = Transformer(X) (2) EK = Transformer(Kc ) (3) EG = Transformer(G′next ) (4) 3.3 Decoder We propose three new mechanisms to incorporate in"
2021.findings-emnlp.94,P02-1040,0,0.110972,"Missing"
2021.findings-emnlp.94,2020.coling-main.365,0,0.0898119,"ularly wonderful 犯罪 悬疑 crime suspense Figure 1: An example of rich knowledge in multi-subgoal recommendation dialog. The conversation is grounded on a knowledge graph. The task can be viewed as completing multiple subgoals sequentially. Text in red indicates knowledge related information and red arrows indicate selected knowledge triple. and the knowledge enhancement module increases the importance of the selected knowledge in response generation. Both automatic and manual evaluations suggest that KERS has a better performance compared to state-of-the-art methods. 2 Related Work et al., 2019; Zhou et al., 2020b) also introduced topic transition approaches similar to the subgoal transition to improve the quality of open-domain dialogs. They built the topic path by either traversing on a knowledge graph or predicting knowledge items directly. Similar to Liu et al. (2020), Hayati et al. (2020) utilized sentence-level sociable recommendation strategy labels in the INSPIRED dataset to improve the recommendation success rate. However, the INSPIRED dataset was not annotated with specific dialog subgoals. Some relevant works for our project focused on obtaining knowledge information from all the related kn"
2021.findings-emnlp.94,P13-2089,0,0.0340814,"n obtaining knowledge information from all the related knowledge triples (Liu et al., 2020; Chen et al., 2019), or enhancing the semantic representations by incorporating both word-oriented and entity-oriented knowledge graphs (Zhou et al., 2020a). However, our work differs because it has fine-grained knowledge planning and accurate knowledge incorporation in generation. Moreover, we deal with more complex knowledge graphs, including both sentences and entities. Most previous work in recommendation dialog systems focused on slot-filling methods to collect user preferences and recommend items (Reschke et al., 2013; Christakopoulou et al., 2016; Sun and Zhang, 2018; Christakopoulou et al., 2018; Zhang et al., 2018; Lee et al., 2018; Lei et al., 2020). To study more sociable and informative recommendation conversations, Li et al. (2018); Moon et al. (2019); Zhou et al. (2020b) proposed new recommendation dialog datasets with knowledge graphs, and incorporated knowledge into response generation. Kang et al. (2019) created a dialog dataset with clear goals. Chen et al. (2019) captured knowledgegrounded information and used recommendationaware vocabulary bias to improve the quality of language generation. 3"
2021.findings-emnlp.94,D14-1007,0,0.0236183,"Missing"
2021.naacl-main.239,D18-1547,0,0.39184,"age understanding cise procedural requirements. These actions difof user needs (Wu et al., 2019; Rastogi et al., fer from typical dialogue acts because tracking 2020b; Liang et al., 2020). However, selecting them necessitates striking a balance between exactions in real life requires not only obeying user ternal user requests and internally-imposed guiderequests, but also following practical policy limilines. Thus, the major difference between tations which may be at odds with those requests. ABCD and other dialogue datasets, such as MulFor example, while a user may ask for a refund on tiWOZ (Budzianowski et al., 2018), is that it asks their purchase, an agent should only honor such a the agent to adhere to a set of policies while simulrequest if it is valid with regards to the store’s retaneously dealing with customer requests. turn policy. Described in actions, before an agent While the prevalent data collection paradigm 1 All code and data will be available at this location. involves Wizard-of-Oz techniques, our situation 3002 1 Introduction Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3002–3017 June"
2021.naacl-main.239,D19-1459,0,0.104972,"d dialogue systems trained on such datasets are intended for solving user issues. The resolution of these issues implicitly requires taking actions, where an action is a non-utterance decision that depends on both user and system inputs. Despite the tremendous number of dialogues, examples in previous benchmarks fixate on the single knowledge base (KB) lookup action where the agent searches for an item that matches the user’s desires and is available in the KB. By sticking to this sole interaction, conversations can be generated through rules (Weston et al., 2016), paraphrased from templates (Byrne et al., 2019) or taken from static text scenarios (Zhang et al., 2018), leading to dialogues that are predominantly homogeneous in nature. Many datasets have scaled to more domains as well (Eric et al., 2017; Budzianowski et al., 2018; Peskov et al., 2019) Since each new domain introduces a KB lookup requiring different slotvalues, the number of unique actions grows as a linear function of the number of domains covered. Rather than expanding wider, ABCD instead focuses deeper by increasing the count and diversity of actions within a single domain. Exploring Other Avenues Multiple aspects are explored by co"
2021.naacl-main.239,P19-1455,0,0.0576183,"Missing"
2021.naacl-main.239,N19-1423,0,0.0254529,"Missing"
2021.naacl-main.239,W17-5506,0,0.0237083,"t depends on both user and system inputs. Despite the tremendous number of dialogues, examples in previous benchmarks fixate on the single knowledge base (KB) lookup action where the agent searches for an item that matches the user’s desires and is available in the KB. By sticking to this sole interaction, conversations can be generated through rules (Weston et al., 2016), paraphrased from templates (Byrne et al., 2019) or taken from static text scenarios (Zhang et al., 2018), leading to dialogues that are predominantly homogeneous in nature. Many datasets have scaled to more domains as well (Eric et al., 2017; Budzianowski et al., 2018; Peskov et al., 2019) Since each new domain introduces a KB lookup requiring different slotvalues, the number of unique actions grows as a linear function of the number of domains covered. Rather than expanding wider, ABCD instead focuses deeper by increasing the count and diversity of actions within a single domain. Exploring Other Avenues Multiple aspects are explored by conversational datasets attempting to mimic reality. Rashkin et al. (2019) studies the ability of a dialogue model to handle empathy, while Zhou et al. (2018) focuses on commonsense reasoning. Ano"
2021.naacl-main.239,2020.acl-main.54,0,0.0159319,"step selection, utterance ranking, ample, workers would be presented with 55 difand intent classification. For both tasks, we experferent classes for Intent Classification and asked imented with two types of frameworks, a pipeline to choose the right one. Since humans typically version and an end-to-end version. The pipeline struggle when choosing from large collections of version trains each subtask separately while the items, fine-tuned models performed roughly on end-to-end optimizes all tasks jointly (Liang et al., par or better compared to humans in this unnat2020; Rastogi et al., 2020a; Ham et al., 2020). ural setting. On the other hand, human evaluation for the overall CDS task was judged by measuring The pipeline model uses a BERT model trained the success rate in a standard conversational scewith the RAdam optimizer (Liu et al., 2020). narios where behavioral instincts are activated, so To test the performance of different pretrained humans were able to excel on this environment. models under the end-to-end framework, we 3009 f (xi , dj ) = h&gt; ctx hcand exp(f (xi , dj )) Pjrank = Σd0j exp f (xi , d0j ) Model Human Pipeline BERT-base AlBERT RoBERTa RoBERTa-Large BERT-base w/o Action Info BE"
2021.naacl-main.239,P17-1162,0,0.0286639,"al datasets attempting to mimic reality. Rashkin et al. (2019) studies the ability of a dialogue model to handle empathy, while Zhou et al. (2018) focuses on commonsense reasoning. Another approach is to augment dialogues with multi-modality including audio (Castro et al., 2019) or visual (Das et al., 2017a) components. Other researchers have explored grounding conversations with external data sources such as personas (Zhang et al., 2018), online reviews (Ghazvininejad et al., 2018) or large knowledge bases (Dinan et al., 2019). Intricate dialogues can also appear when studying collaboration (He et al., 2017; Kim et al., 2019) or negotiation (Lewis et al., 2017; He et al., 2018) which strongly encourage interaction with the other participant. In comparison, ABCD aims to make dialogue more realistic by considering distinct constraints from policies. Traditional Dialogue Datasets In recent years, Dialogues with Policies Procedural actions foldialogue datasets have grown in size from hunlowing strict guidelines naturally emerge in diadreds of conversations to the tens of thoulogue research geared towards real-world applisands (Henderson et al., 2014; Budzianowski 3003 Subflows Actions recover-userna"
2021.naacl-main.239,D18-1256,1,0.849231,"the ability of a dialogue model to handle empathy, while Zhou et al. (2018) focuses on commonsense reasoning. Another approach is to augment dialogues with multi-modality including audio (Castro et al., 2019) or visual (Das et al., 2017a) components. Other researchers have explored grounding conversations with external data sources such as personas (Zhang et al., 2018), online reviews (Ghazvininejad et al., 2018) or large knowledge bases (Dinan et al., 2019). Intricate dialogues can also appear when studying collaboration (He et al., 2017; Kim et al., 2019) or negotiation (Lewis et al., 2017; He et al., 2018) which strongly encourage interaction with the other participant. In comparison, ABCD aims to make dialogue more realistic by considering distinct constraints from policies. Traditional Dialogue Datasets In recent years, Dialogues with Policies Procedural actions foldialogue datasets have grown in size from hunlowing strict guidelines naturally emerge in diadreds of conversations to the tens of thoulogue research geared towards real-world applisands (Henderson et al., 2014; Budzianowski 3003 Subflows Actions recover-username,1 recover-password,1 reset-2fa,1 status-service-added,2 status-servic"
2021.naacl-main.239,W14-4337,0,0.0997016,"Missing"
2021.naacl-main.239,P19-1651,0,0.0141288,"pting to mimic reality. Rashkin et al. (2019) studies the ability of a dialogue model to handle empathy, while Zhou et al. (2018) focuses on commonsense reasoning. Another approach is to augment dialogues with multi-modality including audio (Castro et al., 2019) or visual (Das et al., 2017a) components. Other researchers have explored grounding conversations with external data sources such as personas (Zhang et al., 2018), online reviews (Ghazvininejad et al., 2018) or large knowledge bases (Dinan et al., 2019). Intricate dialogues can also appear when studying collaboration (He et al., 2017; Kim et al., 2019) or negotiation (Lewis et al., 2017; He et al., 2018) which strongly encourage interaction with the other participant. In comparison, ABCD aims to make dialogue more realistic by considering distinct constraints from policies. Traditional Dialogue Datasets In recent years, Dialogues with Policies Procedural actions foldialogue datasets have grown in size from hunlowing strict guidelines naturally emerge in diadreds of conversations to the tens of thoulogue research geared towards real-world applisands (Henderson et al., 2014; Budzianowski 3003 Subflows Actions recover-username,1 recover-passwo"
2021.naacl-main.239,D17-1259,0,0.108614,"al. (2019) studies the ability of a dialogue model to handle empathy, while Zhou et al. (2018) focuses on commonsense reasoning. Another approach is to augment dialogues with multi-modality including audio (Castro et al., 2019) or visual (Das et al., 2017a) components. Other researchers have explored grounding conversations with external data sources such as personas (Zhang et al., 2018), online reviews (Ghazvininejad et al., 2018) or large knowledge bases (Dinan et al., 2019). Intricate dialogues can also appear when studying collaboration (He et al., 2017; Kim et al., 2019) or negotiation (Lewis et al., 2017; He et al., 2018) which strongly encourage interaction with the other participant. In comparison, ABCD aims to make dialogue more realistic by considering distinct constraints from policies. Traditional Dialogue Datasets In recent years, Dialogues with Policies Procedural actions foldialogue datasets have grown in size from hunlowing strict guidelines naturally emerge in diadreds of conversations to the tens of thoulogue research geared towards real-world applisands (Henderson et al., 2014; Budzianowski 3003 Subflows Actions recover-username,1 recover-password,1 reset-2fa,1 status-service-add"
2021.naacl-main.239,P19-1534,0,0.0185817,"2018), leading to dialogues that are predominantly homogeneous in nature. Many datasets have scaled to more domains as well (Eric et al., 2017; Budzianowski et al., 2018; Peskov et al., 2019) Since each new domain introduces a KB lookup requiring different slotvalues, the number of unique actions grows as a linear function of the number of domains covered. Rather than expanding wider, ABCD instead focuses deeper by increasing the count and diversity of actions within a single domain. Exploring Other Avenues Multiple aspects are explored by conversational datasets attempting to mimic reality. Rashkin et al. (2019) studies the ability of a dialogue model to handle empathy, while Zhou et al. (2018) focuses on commonsense reasoning. Another approach is to augment dialogues with multi-modality including audio (Castro et al., 2019) or visual (Das et al., 2017a) components. Other researchers have explored grounding conversations with external data sources such as personas (Zhang et al., 2018), online reviews (Ghazvininejad et al., 2018) or large knowledge bases (Dinan et al., 2019). Intricate dialogues can also appear when studying collaboration (He et al., 2017; Kim et al., 2019) or negotiation (Lewis et al"
2021.naacl-main.239,D19-1218,0,0.0166738,"to take an action, respond with text or end the task. When the next step is an action xbt+1 , the model should predict the button with its slots and values as in AST. If the agent speaks in the next step xat+1 , the model should rank the true utterance highest, as measured by recall metrics.1 Finally, the model should recognize when to end the conversation. Rewarding the model only when it predicts every step correctly is counter-productive because minor variations in sentence order do not alter overall customer satisfaction. Therefore, CDS is scored using a variation on Cascading Evaluation (Suhr et al., 2019). Rather than receiving a single score for each conversation, cascaded evaluation allows the model to receive “partial credit” whenever it successfully predicts each successive step in the chat. This score is calculated on every turn, and the model is evaluated based on the percent of remaining steps correctly predicted, averaged across all available turns. (See Appendix C for more details.) 6.3 the task into predicting enumerable and nonenumerable values. The ontology lists out all |E| enumerable values, so the prediction head penum simply maps the hidden state henc into the appropriate dimen"
2021.naacl-main.239,P19-1078,0,0.121315,"er since prior steps may driven in no small part by the usefulness of these influence future decision states. (See Figure 1) tools, whereby actions are taken on behalf of the To more closely model real customer service user to accomplish their desired targets (Amaagents, we present the Action-Based Conversazon, 2019; Google, 2019). Research into tasktions Dataset (ABCD) consisting of 10,042 conoriented dialogue has concurrently made tremenversations containing numerous actions with predous progress on natural language understanding cise procedural requirements. These actions difof user needs (Wu et al., 2019; Rastogi et al., fer from typical dialogue acts because tracking 2020b; Liang et al., 2020). However, selecting them necessitates striking a balance between exactions in real life requires not only obeying user ternal user requests and internally-imposed guiderequests, but also following practical policy limilines. Thus, the major difference between tations which may be at odds with those requests. ABCD and other dialogue datasets, such as MulFor example, while a user may ask for a refund on tiWOZ (Budzianowski et al., 2018), is that it asks their purchase, an agent should only honor such a t"
2021.naacl-main.239,2020.emnlp-main.409,0,0.0240744,"Missing"
2021.naacl-main.239,P18-1205,0,0.130971,"for solving user issues. The resolution of these issues implicitly requires taking actions, where an action is a non-utterance decision that depends on both user and system inputs. Despite the tremendous number of dialogues, examples in previous benchmarks fixate on the single knowledge base (KB) lookup action where the agent searches for an item that matches the user’s desires and is available in the KB. By sticking to this sole interaction, conversations can be generated through rules (Weston et al., 2016), paraphrased from templates (Byrne et al., 2019) or taken from static text scenarios (Zhang et al., 2018), leading to dialogues that are predominantly homogeneous in nature. Many datasets have scaled to more domains as well (Eric et al., 2017; Budzianowski et al., 2018; Peskov et al., 2019) Since each new domain introduces a KB lookup requiring different slotvalues, the number of unique actions grows as a linear function of the number of domains covered. Rather than expanding wider, ABCD instead focuses deeper by increasing the count and diversity of actions within a single domain. Exploring Other Avenues Multiple aspects are explored by conversational datasets attempting to mimic reality. Rashki"
2021.naacl-main.239,2020.acl-demos.30,0,0.0763094,"Missing"
2021.naacl-main.448,D18-1547,0,0.438485,"y incorporate a pre-trained 5640 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5640–5648 June 6–11, 2021. ©2021 Association for Computational Linguistics Slot Type Figure 2: Slot description examples. seq2seq model (e.g., T5 (Raffel et al., 2020)) without any task-specific modification. To further enhance the model’s cross-domain transferability, we propose Slot Type Informed Descriptions that capture the shared information of different slots. Experimental results on the MultiWOZ benchmark (Budzianowski et al., 2018) suggest that 1) our model achieves significantly higher joint goal accuracy compared to existing results in zero-shot cross domain DST; 2) models using the proposed slot description formulation substantially outperform those using other slot description variants. Our contributions are summarized as the following: • We propose a simple yet novel generative DST model based on T5 that significantly improves existing zero-shot cross-domain DST results; • We investigate the effectiveness of different slot description formulations. To the best of our knowledge, this is the first work that comprehen"
2021.naacl-main.448,N18-2074,0,0.036191,"wledge transfer among different slots. We construct a template for each slot type that follows &quot;[slot type] of [slot] of the [domain]&quot;. We denote such a slot description as Slot Type. More details are available in Appendix A.1. 4 4.1 vi = Seq2seq(Ct , si ). (1) The learning objective of this generation process is minimizing the negative log-likelihood of vi given Ct and si , that is, L=− n X log p(vi |Ct , si ), (2) i where n is the number of slots to be tracked. We initialize the model parameters with T5 (Raffel et al., 2020), an encoder-decoder Transformer with relative position embeddings (Shaw et al., 2018) pre-trained on a massive amount of English text. We denote our model as T5DST. To incorporate slot descriptions into T5DST, we replace the slot name with its corresponding slot description as the model input. 3.2 Slot Type Informed Descriptions Experiments Dataset and Evaluation We evaluate the proposed method on the MultiWOZ 2.0 dataset (Budzianowski et al., 2018), which has 7 domains. We use the pre-processing and evaluation setup from Wu et al. (2019), where restaurant, train, attraction, hotel, and taxi domains are used for training, as the test set only contains these 5 domains. In the z"
2021.naacl-main.448,2020.emnlp-main.66,0,0.0402704,"et al. (2019, 2020) formulated DST as a question answering problem by casting a slot name into questions. However, these works did not show the effectiveness of slot descriptions, by comparing the performance of models with and without them. There is no study on how to construct slot descriptions. In this paper, we aim to fill this research gap by providing an empirical study on the different slot description formulations. Dialogue State Tracking has been of broad interest to the dialogue research community (Williams and Young, 2007; Williams et al., 2014; Heck et al., 2020; Liu et al., 2020; Wu et al., 2020; Madotto et al., 2020). Current 3 Methodology state-of-the-art models (Chen et al., 2020; Lin et al., 2020; Heck et al., 2020; Hosseini-Asl et al., 3.1 T5DST 2020; Ye et al., 2021; Li et al., 2020) trained with extensive annotated data have been shown The design of our model follows the basis of genpromising performance in complex multi-domain erative question answering models. As illustrated conversations (Budzianowski et al., 2018). How- in Figure 1, given a dialogue history which conever, collecting large amounts of data for every sists of an alternating set of utterances from two 5641 Mod"
2021.naacl-main.448,P19-1078,1,0.899837,"tate tracking (DST) is an essential component of task-oriented dialogue systems that tracks users’ requirements over multi-turn conversations. A popular formulation of the dialogue state is in the form of a list of slot-value pairs. In DST, tracking unseen slots in a new domain, a.k.a. zeroshot domain adaptation, is a significant challenge, ∗ Work done during internship at Facebook since the model has never seen in-domain training samples. There are two main lines of work to tackle this problem. The first proposes domain transferable models using copy mechanisms or ontology graph information (Wu et al., 2019; Zhou and Small, 2019). A limitation of such models is that they may not fully leverage pre-trained language models due to the specialized model architecture. The second line of work uses slot-descriptions as input to the model to facilitate the slot understanding (Rastogi et al., 2020). However, the provided slot descriptions are collected by crowd sourced human annotators and might be inconsistent among different domains. In general, the optimal approach for constructing slot descriptions in zero-shot settings remains unexplored. In this work, we tackle the challenge of zeroshot cross-domai"
2021.naacl-main.448,2020.nlp4convai-1.13,0,0.263341,"Missing"
2021.sigdial-1.3,N19-1058,1,0.939559,"h turn Tij = (uji , sji ) containing a user and a system utterance respectively. Each dialog can also have a turn-independent2 multimodal context Mi , for example, an image in which the dialog is grounded. As shown in Fig. 1, DialogStitch interleaves di3 2 Our framework readily extends to turn-dependent multimodal context Mij . For brevity, we only discuss the simpler scenario here. Stitching Multimodal Dialogs We showcase the ability of DialogStitch to handle and stitch dialogs with complex multi-round 22 reasoning spanning across different multimodal contexts using the CLEVR-Dialog dataset (Kottur et al., 2019). CLEVR-Dialog is a visuallysimple yet reasoning-wise complex visual dialog (Das et al., 2017) dataset, which contains a series of related question-answers pairs as dialog turns. These questions are grounded in an image, set in the abstract CLEVR world (Johnson et al., 2017), and is made of spatially arranged objects (with shape, size, material, color attributes) against a plain background (see Fig. 2a). By design, dialogs in CLEVR-Dialog have strong multi-turn dependencies. In addition, these dialogs also come with complete state annotations like type of question, objects/attributes of intere"
2021.sigdial-1.3,2020.acl-main.183,0,0.0107967,"book a flight), these datasets do not support modeling task-oriented agents that need to go beyond and handle longer conversations (also argued by Roller et al. (2020)). For instance, a real world customer service task might require conversations that last for hours, thus requiring more than 20 turns. As a step to bridge these gaps, we propose DialogStitch, a novel framework that takes existing dialog dataset and creates dialogs that comparatively are longer, contain longer-term dependencies, and span multiple contexts. Unlike existing works that either combine dialogs using human annotators (Smith et al., 2020; Moirangthem and Lee, 2018), our framework imparts these desirable traits to task-oriented dialogs by using the available human annotations without collecting any additional ones and thus free of cost, due to its synthetic Introduction Task-oriented dialog agents have become increasingly popular in the recent years due to their ready deployment to several real-world applications. For such agents to be effective, they need to carryout long conversations spanning multiple contexts, interspersed with social chit-chat, and potentially grounded in multimodal settings. Though prior works propose se"
2021.sigdial-1.3,I17-1099,0,0.0279874,"itch task-oriented and open-domain dialogs. Datasets. We adopt the ParlAI framework (Miller et al., 2017) as a testbed for DialogStitch, since it grants a unified access to a vast repository of both open-domain and task-oriented dialog datasets. Though DialogStitch is easily extendable to all these datasets within ParlAI, we consider the following datasets (see supp. for dataset statistics): • Task-Oriented: MultiWOZ 2.2 (Zang et al., 2020) and Schema Guided (Rastogi et al., 2020) • Open-Dialog: Wizard Of Wikipedia (WoW) (Dinan et al., 2019), PersonaChat (Zhang et al., 2018), and DailyDialog (Li et al., 2017) Stitched Datasets. Similar to multimodal Stitched datasets described in Sec. 3, we divide the dialogs into multiple chunks (2-5) at randomly selected pivot turns and take the following precautions while fusing them into a single conversation. • The context switch at the pivot turns is always initiated by the user utterance. • For coherency, we use conversational cues to indicate a context-switch turn (e.g., ‘getting back to the restaurant booking’) from task-oriented to open-domain, and vice-versa. • Additionally, we re-sample a pivot if the opendomain assistant turn preceding asks a question"
2021.sigdial-1.3,2020.nlp4convai-1.13,0,0.0365604,"ates a wider adoption in everyday applications. To achieve this, agents must additionally handle chit-chit about social topics. We emulate these scenarios to synthetically stitch task-oriented and open-domain dialogs. Datasets. We adopt the ParlAI framework (Miller et al., 2017) as a testbed for DialogStitch, since it grants a unified access to a vast repository of both open-domain and task-oriented dialog datasets. Though DialogStitch is easily extendable to all these datasets within ParlAI, we consider the following datasets (see supp. for dataset statistics): • Task-Oriented: MultiWOZ 2.2 (Zang et al., 2020) and Schema Guided (Rastogi et al., 2020) • Open-Dialog: Wizard Of Wikipedia (WoW) (Dinan et al., 2019), PersonaChat (Zhang et al., 2018), and DailyDialog (Li et al., 2017) Stitched Datasets. Similar to multimodal Stitched datasets described in Sec. 3, we divide the dialogs into multiple chunks (2-5) at randomly selected pivot turns and take the following precautions while fusing them into a single conversation. • The context switch at the pivot turns is always initiated by the user utterance. • For coherency, we use conversational cues to indicate a context-switch turn (e.g., ‘getting back to"
2021.sigdial-1.3,D17-2014,0,0.0296158,"le contexts, and contain longer term dependencies compared to prior work. Performance of state-of-the-art models drops when benchmarked on our datasets, thus suggesting a need to better model multiple-contexts and longerStitching Open-Domain Dialogs Being socially engaging is a desirable trait for task-orientated dialog agent as it facilitates a wider adoption in everyday applications. To achieve this, agents must additionally handle chit-chit about social topics. We emulate these scenarios to synthetically stitch task-oriented and open-domain dialogs. Datasets. We adopt the ParlAI framework (Miller et al., 2017) as a testbed for DialogStitch, since it grants a unified access to a vast repository of both open-domain and task-oriented dialog datasets. Though DialogStitch is easily extendable to all these datasets within ParlAI, we consider the following datasets (see supp. for dataset statistics): • Task-Oriented: MultiWOZ 2.2 (Zang et al., 2020) and Schema Guided (Rastogi et al., 2020) • Open-Dialog: Wizard Of Wikipedia (WoW) (Dinan et al., 2019), PersonaChat (Zhang et al., 2018), and DailyDialog (Li et al., 2017) Stitched Datasets. Similar to multimodal Stitched datasets described in Sec. 3, we divid"
2021.sigdial-1.3,P18-1205,0,0.0280855,"te these scenarios to synthetically stitch task-oriented and open-domain dialogs. Datasets. We adopt the ParlAI framework (Miller et al., 2017) as a testbed for DialogStitch, since it grants a unified access to a vast repository of both open-domain and task-oriented dialog datasets. Though DialogStitch is easily extendable to all these datasets within ParlAI, we consider the following datasets (see supp. for dataset statistics): • Task-Oriented: MultiWOZ 2.2 (Zang et al., 2020) and Schema Guided (Rastogi et al., 2020) • Open-Dialog: Wizard Of Wikipedia (WoW) (Dinan et al., 2019), PersonaChat (Zhang et al., 2018), and DailyDialog (Li et al., 2017) Stitched Datasets. Similar to multimodal Stitched datasets described in Sec. 3, we divide the dialogs into multiple chunks (2-5) at randomly selected pivot turns and take the following precautions while fusing them into a single conversation. • The context switch at the pivot turns is always initiated by the user utterance. • For coherency, we use conversational cues to indicate a context-switch turn (e.g., ‘getting back to the restaurant booking’) from task-oriented to open-domain, and vice-versa. • Additionally, we re-sample a pivot if the opendomain assis"
2021.sigdial-1.35,D18-1547,0,0.0611077,"Missing"
2021.sigdial-1.35,D19-1459,1,0.85342,"Missing"
2021.sigdial-1.35,W14-4012,0,0.0331343,"Missing"
2021.sigdial-1.35,2020.sigdial-1.4,0,0.0298148,"Missing"
2021.sigdial-1.35,2020.acl-main.703,0,0.0789154,"enchmarking State-of-the-Art Models To verify our corrections of the dialog state annotations, we benchmark state-of-the-art dialog state tracking (DST) models on our modified dataset. Traditionally, for DST task, the slot value is predicted by selecting from pre-defined candidates or extracting from dialog context. We adopt TRADE (Wu et al., 2019) as a representative of the mixture of these two methods. More recent works focus more on fine-tuning pre-trained model, which purely generates slot values based on dialog history. We choose SimpleTOD (Hosseini-Asl et al., 2020) and fine-tuned BART (Lewis et al., 2020) as benchmark models for DST as well. 331 Models TRADE (Wu et al., 2019) SimpleTOD (Hosseini-Asl et al., 2020) DST-BART (Lewis et al., 2020) Standard Results 2.1 2.2 Ours 44.4±0.3 45.6±0.5 55.2±0.2 54.7± 0.5 53.6±1.0 62.1±0.2 57.9±0.5 56.0±0.7 67.4±0.5 2.1 45.1±0.3 55.2± 0.5 58.7±0.2 Fuzzy Results 2.2 Ours 46.9±0.2 58.2±0.4 54.4±1.2 64.7±0.2 57.5±0.2 72.3±0.4 Table 4: The performance of TRADE, SimpleTOD and DST-BART in terms of joint goal accuracy on MultiWOZ 2.1, 2.2 and our modified version. Fuzzy Results considers model-predicted slot value is correct if it is very similar with the ground t"
2021.sigdial-1.35,P19-1253,1,0.813569,"h respect to the entity bias. Strictly speaking, bias cannot be considered as a source of error in the dataset, and it needs to be tackled via better modeling efforts. Although the entity bias hurts the prediction accuracy of low-frequency slots and reFigure 6: Example of dialog with new entities by replacing “bridge guest house” with “best western of long beach” sults in generating extra high-frequency slots, it also reflects certain real-world facts/biases as the dialogs are conducted by humans. This usually helps the learning task with limited training data, e.g., dialog domain adaptation (Qian and Yu, 2019; Lu et al., 2020). While we keep the bias in the original dataset intact, we propose a new test set with all entities replaced with new ones unseen in the training data to facilitate the identification of whether models capitalize on such biases. For each slot type from each domain in the MultiWOZ, we find a similar slot type in the Schema-Guided dataset (Rastogi et al., 2019). For the slot values belonging to those slot type, we replace them with unseen values from the Schema-Guided dataset. Examples of dialog with replaced entities, along with predicted slots by our benchmark model is shown"
2021.sigdial-1.35,N19-1126,0,0.0505891,"Missing"
2021.sigdial-1.35,E17-1042,0,0.0524054,"Missing"
2021.sigdial-1.35,P17-1099,0,0.0330157,"Missing"
2021.sigdial-1.35,2020.acl-main.638,0,0.0222005,"Missing"
2021.sigdial-1.35,P19-1078,0,0.0837757,"in the recent years. Among task-oriented dialog datasets, MultiWOZ (Budzianowski et al., 2018) has gained the most popularity. The dataset contains 10k+ dialogs and covers eight domains: Attraction, Bus, Hospital, Hotel, Restaurant, Taxi, Train and Police. Each dialog can cover one or multiple domains. The inclusion of detailed annotations, e.g., task goal, dialog state, and dialog acts for both user side and system side, renders MultiWOZ a universal benchmark for many dialog tasks, such as dialog state tracking (Zhang et al., 2019, 2020a; Heck et al., 2020), dialog policy optimization (yang Wu et al., 2019; Wang et al., 2020a,b) and end-to-end dialog modeling (Zhang et al., 2020b; Hosseini-Asl et al., 2020; Peng et al., 2020). Several recent papers, such as SimpleTOD (Hosseini-Asl et al., 2020), TRADE (Wu et al., 2019), MarCo (Wang et al., 2020b), evaluate their models solely on the MultiWOZ dataset, which makes their findings highly dependent on the quality of this dataset. Over the last couple of years, several sources of errors have been identified and corrected on MultiWOZ. Wu et al. (2019) pre-processed the dataset by normalizing the text and annotations. Eric et al. (2019) further correct"
2021.sigdial-1.35,2020.nlp4convai-1.13,0,0.0996837,"Missing"
2021.sigdial-1.35,2020.emnlp-main.740,0,0.0716135,"Missing"
2021.sigdial-1.6,N19-1078,0,0.016594,"ogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings: a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training. 1 Introduction Named entity recognition (NER) is the task of extracting proper names of people, locations, and so on from text or speech (Grishman and Sundheim, 1996). There has been a lot of work on NER from written text with many systems achieving impressive results (Devlin et al., 2019; Akbik et al., 2019). Although, NER from speech has been around for the same time as NER from text (starting with work by Kubala et al. (1998)), accuracy of NER from speech still lags behind the accuracy of NER from text. The rise in popularity of spoken dialog systems such as Siri or Alexa 45 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 45–55 July 29–31, 2021. ©2021 Association for Computational Linguistics We propose two models that exploit dialog context and speech patterns which are available in open-domain dialogs from spoken dialog systems to achieve"
2021.sigdial-1.6,C02-1130,0,0.142338,"ttle named entity overlap). Table 2 illustrates the difference in term of named entity overlap measured using vocabulary transfer rate (Palmer and Day, 1997). VoAlthough named entities are typically classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity"
2021.sigdial-1.6,galibert-etal-2014-etape,0,0.0409569,"Missing"
2021.sigdial-1.6,2020.lrec-1.797,0,0.0281511,"tures other than what were used in this paper. However, many previous studies have shown the usefulness of these additional features in other tasks so there are reasons to believe that the findings should translate to other datasets and settings. Figure 6: Speech pattern helps locating named entities. Without speech pattern, models predicted the wrong entity spans (e.g. “jonas brothers once” and “with mclovin”). SP: speech patterns 5.2 Future work Towards robust NER in dialog system Current ASR systems still perform poorly in domains that require special vocabulary and under noisy conditions (Georgila et al., 2020). Unfamiliar words or recording noise may lead to ASR errors that affect downstream tasks such as NER. Although continuously retraining the ASR and NER models can reduce these errors, such effort may be costly. Integrating features such as speech pattern features, which are less affected by changing vocabulary and recording conditions, could make NER models more robust and reduce the frequency of having to retrain the models. Speech pattern features have been used for NER in spoken broadcast news although this did not lead to improvement in performance (Hakkani-T¨ur et al., 1999). This could b"
2021.sigdial-1.6,2020.lrec-1.211,0,0.0397973,"Missing"
2021.sigdial-1.6,bick-2004-named,0,0.0598518,"y classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the a"
2021.sigdial-1.6,C96-1079,0,0.357568,"h challenging. We propose two models that exploit dialog context and speech pattern clues to extract named entities more accurately from open-domain dialogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings: a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training. 1 Introduction Named entity recognition (NER) is the task of extracting proper names of people, locations, and so on from text or speech (Grishman and Sundheim, 1996). There has been a lot of work on NER from written text with many systems achieving impressive results (Devlin et al., 2019; Akbik et al., 2019). Although, NER from speech has been around for the same time as NER from text (starting with work by Kubala et al. (1998)), accuracy of NER from speech still lags behind the accuracy of NER from text. The rise in popularity of spoken dialog systems such as Siri or Alexa 45 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 45–55 July 29–31, 2021. ©2021 Association for Computational Linguistics We prop"
2021.sigdial-1.6,2020.lrec-1.556,0,0.0381628,"Missing"
2021.sigdial-1.6,N06-2015,0,0.0144524,"Missing"
2021.sigdial-1.6,W17-4418,0,0.0599053,"Missing"
2021.sigdial-1.6,D17-1215,0,0.0271203,"t Hard split 51,362 147,724 15,733 46,435 152,728 23,394 146,858 146,858 19,585 19,984 19,279 20,583 23,499 81,829 1,975 5,942 11,066 836 5,648 11,257 1,079 7,402 7,402 934 1,254 952 1,391 cabulary transfer is the proportion of unique named entities appearing in both training and test set, and as expected, the development and test sets of the hard split have much lower vocabulary transfer than that of the standard split. Although standard split is a common practice in machine learning, deep learning models can perform well on the standard split by exploiting the spurious patterns in the data (Jia and Liang, 2017). Thus, the hard split is necessary for measuring how well the models can generalize, since NER models relying heavily on surface patterns will underperform when there are a lot of unseen named entities (Augenstein et al., 2017). Furthermore, the test set of the hard split more closely resembles the test data during deployment because the data the models see during deployment usually differ from the data collected during training (little overlap of named entities). Thus, the performance on the hard split is a more realistic reflection of the models performance during deployment. A comparison b"
2021.sigdial-1.6,N19-1423,0,0.0350581,"from open-domain dialogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings: a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training. 1 Introduction Named entity recognition (NER) is the task of extracting proper names of people, locations, and so on from text or speech (Grishman and Sundheim, 1996). There has been a lot of work on NER from written text with many systems achieving impressive results (Devlin et al., 2019; Akbik et al., 2019). Although, NER from speech has been around for the same time as NER from text (starting with work by Kubala et al. (1998)), accuracy of NER from speech still lags behind the accuracy of NER from text. The rise in popularity of spoken dialog systems such as Siri or Alexa 45 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 45–55 July 29–31, 2021. ©2021 Association for Computational Linguistics We propose two models that exploit dialog context and speech patterns which are available in open-domain dialogs from spoken dialo"
2021.sigdial-1.6,H01-1034,0,0.413136,"h because NER is a core component for understanding what users said in dialogs. In spoken dialog systems, humans interact with the systems using natural speech to accomplish certain tasks (task-oriented dialog) or just to be entertained (chitchat or open-domain dialog) (Jurafsky and Martin, 2009). These systems require speech transcripts as input in real-time and the transcripts are obtained using automatic speech recognition (ASR) components (Turmo et al., 2009). Much previous work on NER from speech data, such as broadcast news, applied text-based NER systems to the output of an ASR system (Palmer and Ostendorf, 2001). However, NER performance degraded significantly (20 points drop in F1 score) when applying a NER trained on written data to transcribed speech (Kubala et al., 1998). This could be because applying text-based NER system to ASR output ignores the differences in styles and conventions in written and spoken language (Palmer and Ostendorf, 2001). For example, spoken utterances in spontaneous speech are usually much shorter than written prose so the utterances could be ambiguous when taken out of context. In addition, speech also contains disfluencies, repetitions, restarts and corrections (Turmo"
2021.sigdial-1.6,W14-1609,0,0.0118097,"he notebook”, while BERT misclassified it as Book. In contrast, speech pattern features may help locating the named entities. Figure 6 shows that NER models without speech pattern features might predict the wrong text spans as named entities (e.g. “jonas brothers once” instead of “jonas brothers”). Interestingly, although the predicted type is not correct, the type of “mclovin” predicted by BERT is more plausible than BiLSTM-CRF. This might be because BERT gained some world knowledge after pre-training, and NER models usually benefit from external sources of knowledge (Ratinov and Roth, 2009; Passos et al., 2014). study by removing the features one by one. In particular, starting with a model that uses all 4 features (denoted as 4F): namely token ASR confidence, token duration, the pauses preceding and succeeding the token, we first remove the ASR confidence from the model input (denoted as 3F) and then remove the token duration from the model input (denoted as 2F). We trained all the models with ablated features from scratch with hyperparameter search similar to what was done in Section 4.2. For the hard split, the BERT 4F model did better than the BERT 3F model, showing that the ASR confidence is pr"
2021.sigdial-1.6,N16-1030,0,0.027565,"). The user’s utterance includes lexical features (i.e. word tokens or word pieces) and speech pattern features which are pauses’ duration, words’ duration, and tokens’ ASR confidence. Both models have three components: (1) a context encoder, (2) a speech pattern encoder, and (3) a sequence tagger. The context encoder and speech pattern encoder are the same in both models and the encoders provide additional clues for the sequence tagger to accurately label named entities. The first model’s sequence tagger is a widely used model for NER from written text based on BiLSTM-CRF (Ma and Hovy, 2016; Lample et al., 2016), which combines bidirectional LSTM (Graves and Schmidhuber, 2005) with conditional random field (Lafferty et al., 2001). The second model’s sequence tagger is based on BERT (Devlin et al., 2019), which achieved stateof-the-art result for the CoNLL dataset. Figure 2 shows the models’ structure. The context encoder is a bag-of-embedding model (Fig47 Tokens Turns Train Bot 22,908 User 624,168 146,858 Avg. Len. Train Bot User Number of Tokens 27.2 6.4 26.9 27.2 6.5 6.4 27.1 27.3 6.6 6.8 CoNLL OntoNotes WNUT Standard Split Dev Test 3,000 3,000 80,749 81,668 19,585 19,279 Standard split Hard split"
2021.sigdial-1.6,D14-1162,0,0.0820089,"Missing"
2021.sigdial-1.6,I05-1058,0,0.0563849,"of the hard split are created such that they have more named entities that are not seen in the training set (i.e. little named entity overlap). Table 2 illustrates the difference in term of named entity overlap measured using vocabulary transfer rate (Palmer and Day, 1997). VoAlthough named entities are typically classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving informati"
2021.sigdial-1.6,W09-1119,0,0.144513,"CRF missed the entity “the notebook”, while BERT misclassified it as Book. In contrast, speech pattern features may help locating the named entities. Figure 6 shows that NER models without speech pattern features might predict the wrong text spans as named entities (e.g. “jonas brothers once” instead of “jonas brothers”). Interestingly, although the predicted type is not correct, the type of “mclovin” predicted by BERT is more plausible than BiLSTM-CRF. This might be because BERT gained some world knowledge after pre-training, and NER models usually benefit from external sources of knowledge (Ratinov and Roth, 2009; Passos et al., 2014). study by removing the features one by one. In particular, starting with a model that uses all 4 features (denoted as 4F): namely token ASR confidence, token duration, the pauses preceding and succeeding the token, we first remove the ASR confidence from the model input (denoted as 3F) and then remove the token duration from the model input (denoted as 2F). We trained all the models with ablated features from scratch with hyperparameter search similar to what was done in Section 4.2. For the hard split, the BERT 4F model did better than the BERT 3F model, showing that th"
2021.sigdial-1.6,W04-1221,0,0.0256859,"n (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the average entity length by types respectively. The Movie, Book, and Song t"
2021.sigdial-1.6,P16-1101,0,0.0224917,"the bot’s utterance). The user’s utterance includes lexical features (i.e. word tokens or word pieces) and speech pattern features which are pauses’ duration, words’ duration, and tokens’ ASR confidence. Both models have three components: (1) a context encoder, (2) a speech pattern encoder, and (3) a sequence tagger. The context encoder and speech pattern encoder are the same in both models and the encoders provide additional clues for the sequence tagger to accurately label named entities. The first model’s sequence tagger is a widely used model for NER from written text based on BiLSTM-CRF (Ma and Hovy, 2016; Lample et al., 2016), which combines bidirectional LSTM (Graves and Schmidhuber, 2005) with conditional random field (Lafferty et al., 2001). The second model’s sequence tagger is based on BERT (Devlin et al., 2019), which achieved stateof-the-art result for the CoNLL dataset. Figure 2 shows the models’ structure. The context encoder is a bag-of-embedding model (Fig47 Tokens Turns Train Bot 22,908 User 624,168 146,858 Avg. Len. Train Bot User Number of Tokens 27.2 6.4 26.9 27.2 6.5 6.4 27.1 27.3 6.6 6.8 CoNLL OntoNotes WNUT Standard Split Dev Test 3,000 3,000 80,749 81,668 19,585 19,279 Stan"
2021.sigdial-1.6,W03-1307,0,0.1056,"e big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the average entity length by type"
2021.sigdial-1.6,A97-1028,0,0.361283,"utterances are output from an ASR system and are in lower case. The data are divided into two different splits: a standard split and a hard split, and the two splits share the same training set (Table 1). While the training, development, and test set of the standard split are formed by randomly partitioning the data, the development and test set of the hard split are created such that they have more named entities that are not seen in the training set (i.e. little named entity overlap). Table 2 illustrates the difference in term of named entity overlap measured using vocabulary transfer rate (Palmer and Day, 1997). VoAlthough named entities are typically classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (B"
2021.sigdial-1.6,P06-1078,0,0.125913,"1995; Lenzi et al., 2012). Although, joint decoding of ASR transcript and NER output (Caubri`ere et al., 2020) partly lessens the impact of ASR errors on NER, detecting named entities in ASR transcripts remains a challenging problem (Galibert et al., 2014). Prior work on NER from ASR transcripts focus on reducing ASR errors (Palmer and Ostendorf, 2001), exploiting multiple ASR hypotheses (Horlock and King, 2003; B´echet et al., 2004), or exploiting additional information such as speech pattern features (Katerenchuk and Rosenberg, 2014). Examples of speech pattern features are ASR confidence (Sudoh et al., 2006), pauses, and word durations (Hakkani-T¨ur et al., 1999). Recently, Cervantes and Ward (2020) used solely prosidic speech features to spot location mentions. Our work is similar to Katerenchuk and Rosenberg (2014) in that we also utilize speech pattern features. However, while Katerenchuk and Rosenberg (2014) focused on broadcast news speech, our work focuses on spoken dialogs. Thus, besides speech pattern features, our models also exploit dialog context for more accurate NER. In addition, Katerenchuk and Rosenberg (2014) used a separate classifier trained on Figure 1: Dialog context and speec"
2021.sigdial-1.6,M95-1002,0,0.426072,"Missing"
2021.sigdial-1.6,W03-0419,0,0.0713989,"Missing"
2021.sigdial-1.6,N18-1007,0,0.0284586,"ting data are significantly different, demonstrating that it is possible to combine lexical and speech pattern features to achieve more robust NER system. Figure 5: Without context, both models either predicted the wrong entity type or missed the named entity. 5.3 We show that short context and minimal speech pattern features can improve NER performance. Better performance might be achieved by modeling longer context and more features (e.g. prosodies, parts of speech, punctuation) from a SOTA ASR system. Prosodic features can also be extracted automatically to better align to sub-word tokens (Tran et al., 2018). It would also be interesting to see how robust NER would improve entity linking especially when entity mentions contain ASR errors. Since our work only explored open-domain conversations between humans and a chatbot, it is important to validate the benefits of modeling context and speech pattern features in other settings. Examples of other settings include open-domain conversations between humans or task-oriented conversations between humans or between humans and chatbots. For these different settings, NER models might need longer context or speech pattern features other than what were used"
2021.sigdial-1.6,W03-1306,0,0.179035,", Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the average entity length by types respectively. The Movie,"
D18-1385,S17-2082,0,0.508248,"Missing"
D18-1385,D11-1147,0,0.216088,"from another real event and usually their content corresponds to the text of the rumors. In this case, the image itself is real but not real in 1 https://github.com/WeimingWen/CCRV the context of the fake news. We thus propose to leverage the multimedia information by finding the agreement and disagreement among posts that are from different social media platforms but share similar visual contents. The agreement between rumors and their comments is used heavily in automatic verification. Mendoza et al. (2010) declared that fake rumors tended to have more people question their validity. Later, Qazvinian et al. (2011) first annotated comments on tweets as supporting, denying or querying, and then used such stance information in the classification to leverage the “wisdom of crowds”. Recently, the best performing system (Enayet and El-Beltagy, 2017) in RumourEval shared task at SemEval 2017 (Derczynski et al., 2017) also used such information. However, the crowd is not always wise. For example, Starbird et al. (2014) suspected the correctness of public opinions in rumors, pointing out some certain fake news received more support than questions. In our work, instead of using the “wisdom of crowds”, we used th"
D18-1385,tian-etal-2014-um,0,0.0430555,"Missing"
D18-1400,W17-4746,0,0.0850759,"Missing"
D18-1400,P17-1175,0,0.0989818,"Missing"
D18-1400,D17-1105,0,0.463548,"model outperforms other methods by a large margin. 1 Introduction Multimodal machine translation is the problem of translating sentences paired with images into a different target language (Elliott et al., 2016). In this setting, translation is expected to be more accurate compared to purely text-based translation, as the visual context could help resolve ambiguous multi-sense words. Examples of real-world applications of multimodal (vision plus text) translation include translating multimedia news, web product information, and movie subtitles. Several previous endeavours (Huang et al., 2016; Calixto et al., 2017a; Elliott and Kádár, 2017) have demonstrated improved translation quality when utilizing images. However, how to effectively integrate the visual information still remains a challenging problem. For instance, in the WMT 2017 multimodal machine translation challenge (Elliott et al., 2017), methods that incorporated visual information did not outperform pure text-based approaches with a big margin. In this paper, we propose a new model called Visual Attention Grounding Neural Machine Translation (VAG-NMT) to leverage visual information more effectively. We train VAG-NMT with a multitask learnin"
D18-1400,J75-4040,0,0.647776,"Missing"
D18-1400,W14-3348,0,0.0849975,"sing, and tokenizing with the Moses toolkit. A Byte-Pair-Encoding (BPE) (Sennrich et al., 2015) operation with 10K merge operations is learned from the pre-processed data and then applied to segment words. We restore the original words by concatenating the subwords segmented by BPE in post-processing. During training, we apply early stopping if there is no improvement in BLEU score on validation data for 10 validation steps. We apply beam search decoding to generate translation with beam size equal to 12. We evaluate the performance of all models using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014). The setting used in IKEA dataset is the same as Multi30K, except that we lower the default batch size from 32 to 12; since IKEA dataset has long sentences and large variance in sentence length, we use smaller batches to make the training more stable. Full details of our hyperparameter choices can be found in Appendix B. We run all models five times with different random seeds and report the mean and standard deviation. 5.3 Results We compare the performance of our model against the state-of-the-art multimodal machine translation approaches and the text-only baseline. The idea of our model is"
D18-1400,W17-4718,0,0.363324,"rely text-based translation, as the visual context could help resolve ambiguous multi-sense words. Examples of real-world applications of multimodal (vision plus text) translation include translating multimedia news, web product information, and movie subtitles. Several previous endeavours (Huang et al., 2016; Calixto et al., 2017a; Elliott and Kádár, 2017) have demonstrated improved translation quality when utilizing images. However, how to effectively integrate the visual information still remains a challenging problem. For instance, in the WMT 2017 multimodal machine translation challenge (Elliott et al., 2017), methods that incorporated visual information did not outperform pure text-based approaches with a big margin. In this paper, we propose a new model called Visual Attention Grounding Neural Machine Translation (VAG-NMT) to leverage visual information more effectively. We train VAG-NMT with a multitask learning mechanism that simultaneously optimizes two objectives: (1) learning a translation model, and (2) constructing a vision-language joint semantic embedding. In this model, we develop a visual attention mechanism to learn an attention vector that values the words that have closer semantic"
D18-1400,D17-1303,0,0.0286519,"ate image captions. (Karpathy and Li, 2014) densely align different objects in the image with their corresponding text captions in the shared space, which further improves the quality of the generated caption. In later work, multimodal shared space learning was extended to multimodal multilingual shared space learning. (Calixto et al., 2017c) learn a multi-modal multilingual shared space through optimization of a modified pairwise contrastive function, where the extra multilingual signal in the shared space leads to improvements in image-sentence ranking and semantic textual similarity task. (Gella et al., 2017) extend the work from (Calixto et al., 2017c) by using the image as the pivot point to learn the multilingual multimodal shared space, which does not require large parallel corpora during training. Finally, (Elliott and Kádár, 2017) is the first to integrate the idea of multimodal shared space learning to help multimodal machine translation. Their multi-task architecture called “imagination” shares an encoder between a primary task of the classical encoder-decoder NMT and an auxiliary task of visual feature reconstruction. Our VAG-NMT mechanism is inspired by (Elliott and Kádár, 2017), but has"
D18-1400,W17-4749,0,0.014522,"Association for Computational Linguistics 2 Related Work In the machine translation literature, there are two major streams for integrating visual information: approaches that (1) employ separate attention for different (text and vision) modalities, and (2) fuse visual information into the NMT model as part of the input. The first line of work learns independent context vectors from a sequence of text encoder hidden states and a set of location-preserving visual features extracted from a pre-trained convnet, and both sets of attentions affect the decoder’s translation (Calixto et al., 2017a; Helcl and Libovický, 2017). The second line of work instead extracts a global semantic feature and initializes either the NMT encoder or decoder to fuse the visual context (Calixto et al., 2017b; Ma et al., 2017). While both approaches demonstrate significant improvement over their Text-Only NMT baselines, they still perform worse than the best monomodal machine translation system from the WMT 2017 shared task (Zhang et al., 2017). The model that performs best in the multimodal machine translation task employed image context in a different way. (Huang et al., 2016) combine region features extracted from a region-propos"
D18-1400,W16-2360,0,0.10118,"attention grounding model outperforms other methods by a large margin. 1 Introduction Multimodal machine translation is the problem of translating sentences paired with images into a different target language (Elliott et al., 2016). In this setting, translation is expected to be more accurate compared to purely text-based translation, as the visual context could help resolve ambiguous multi-sense words. Examples of real-world applications of multimodal (vision plus text) translation include translating multimedia news, web product information, and movie subtitles. Several previous endeavours (Huang et al., 2016; Calixto et al., 2017a; Elliott and Kádár, 2017) have demonstrated improved translation quality when utilizing images. However, how to effectively integrate the visual information still remains a challenging problem. For instance, in the WMT 2017 multimodal machine translation challenge (Elliott et al., 2017), methods that incorporated visual information did not outperform pure text-based approaches with a big margin. In this paper, we propose a new model called Visual Attention Grounding Neural Machine Translation (VAG-NMT) to leverage visual information more effectively. We train VAG-NMT wi"
D18-1400,W17-4751,0,0.0206047,"attention for different (text and vision) modalities, and (2) fuse visual information into the NMT model as part of the input. The first line of work learns independent context vectors from a sequence of text encoder hidden states and a set of location-preserving visual features extracted from a pre-trained convnet, and both sets of attentions affect the decoder’s translation (Calixto et al., 2017a; Helcl and Libovický, 2017). The second line of work instead extracts a global semantic feature and initializes either the NMT encoder or decoder to fuse the visual context (Calixto et al., 2017b; Ma et al., 2017). While both approaches demonstrate significant improvement over their Text-Only NMT baselines, they still perform worse than the best monomodal machine translation system from the WMT 2017 shared task (Zhang et al., 2017). The model that performs best in the multimodal machine translation task employed image context in a different way. (Huang et al., 2016) combine region features extracted from a region-proposal network (Ren et al., 2015) with the word sequence feature as the input to the encoder, which leads to significant improvement over their NMT baseline. The best multimodal machine tran"
D18-1400,P02-1040,0,0.100962,"rmalizing the punctuation, lower casing, and tokenizing with the Moses toolkit. A Byte-Pair-Encoding (BPE) (Sennrich et al., 2015) operation with 10K merge operations is learned from the pre-processed data and then applied to segment words. We restore the original words by concatenating the subwords segmented by BPE in post-processing. During training, we apply early stopping if there is no improvement in BLEU score on validation data for 10 validation steps. We apply beam search decoding to generate translation with beam size equal to 12. We evaluate the performance of all models using BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014). The setting used in IKEA dataset is the same as Multi30K, except that we lower the default batch size from 32 to 12; since IKEA dataset has long sentences and large variance in sentence length, we use smaller batches to make the training more stable. Full details of our hyperparameter choices can be found in Appendix B. We run all models five times with different random seeds and report the mean and standard deviation. 5.3 Results We compare the performance of our model against the state-of-the-art multimodal machine translation approaches and the text-"
D18-1400,E17-3017,0,0.0321812,"e impact during the decoding (translation) stage. However, we may not want to solely rely on only a few most important words. Thus, to produce the initial hidden state of the decoder, we take a weighted average of the attention vector t and the mean of encoder hidden states: s0 = tanh(Winit (λt + (1 − λ) N 1 X hi )), (4) N i where λ determines the contribution from each vector. Through our experiments, we find the best value for λ is 0.5. 3.3 (6) p Translation objective During the decoding stage, at each time step j, the decoder generates a decoder hidden state sj from a conditional GRU cell (Sennrich et al., 2017) whose input is the previously generated translation token yj−1 , the previous decoder hidden state sj−1 , and the context vector cj at the current time step: sj = cGRU(sj−1 , yj−1 , cj ) (5) The context vector cj is a weighted sum of the encoder hidden state vectors, and captures the relevant source words that the decoder should focus on when generating the current translated token yj . The weight associated with each encoder hidden state is determined by a feed-forward network. where ot = tanh(We ej−1 + Wd dj + Wc cj ). The three inputs are transformed with We , Wd , and Wc , respectively an"
D18-1400,Q14-1006,0,0.124801,"ion decoder such that the source sentence words that are more related to the visual semantics have more influence during the decoding stage. When evaluated on the benchmark Multi30K and the Ambiguous COCO datasets, our VAG-NMT model demonstrates competitive performance compared to existing state-of-the-art multimodal machine translation systems. Another important challenge for multimodal machine translation is the lack of a large-scale, realistic dataset. To our knowledge, the only existing benchmark is Multi30K (Elliott et al., 2016), which is based on an image captioning dataset, Flickr30K (Young et al., 2014) with manual German and French translations. There are roughly 30K parallel sentences, which is relatively small compared to text-only machine translation datasets that have millions of sentences such as WMT14 EN→DE. Therefore, we propose a new multimodal machine translation dataset called IKEA to simulate the real-world problem of translating product descriptions from one language to another. Our IKEA dataset is a collection of parallel English, French, and German product descriptions and images from IKEA’s and UNIQLO’s websites. We have included a total of 3,600 products so far and will incl"
D18-1400,W17-4753,0,0.0206811,"idden states and a set of location-preserving visual features extracted from a pre-trained convnet, and both sets of attentions affect the decoder’s translation (Calixto et al., 2017a; Helcl and Libovický, 2017). The second line of work instead extracts a global semantic feature and initializes either the NMT encoder or decoder to fuse the visual context (Calixto et al., 2017b; Ma et al., 2017). While both approaches demonstrate significant improvement over their Text-Only NMT baselines, they still perform worse than the best monomodal machine translation system from the WMT 2017 shared task (Zhang et al., 2017). The model that performs best in the multimodal machine translation task employed image context in a different way. (Huang et al., 2016) combine region features extracted from a region-proposal network (Ren et al., 2015) with the word sequence feature as the input to the encoder, which leads to significant improvement over their NMT baseline. The best multimodal machine translation system in WMT 2017 (Caglayan et al., 2017) performs element-wise multiplication of the target language embedding with an affine transformation of the convnet image feature vector as the mixed input to the decoder."
D19-1014,D16-1127,0,0.020657,"c representations over time to track the dialog state. Finally they apply RL to learn an optimized dialog policy given the dialog state (Raux et al., 2005; Shi and Yu, 2018). Such modular-based dialog systems are effective in narrow task domains, such as searching a bus route schedule and reserving a restaurant through natural language, but they fail to generalize to complex settings where the size of the action space increases. Owing to the development of deep learning, RL on neural sequence-to-sequence models has been explored in more complex dialog domains such as open-domain conversation (Li et al., 2016) and negotiation (Lewis et al., 2017). However, due to the difficulty of assigning appropriate rewards when operating in a large action space, these frameworks cannot generate fluent dialog utterances. Zhao et al. (2019) proposed a novel latent action RL framework to marry the advantage of a module based approach and sequence-to-sequence approach. They learned the optimal dialog policy in a complex task-oriented dialog domain while achieving decent conversation quality. We study the similar issue in a multimodal task-oriented dialog scenario. We propose an iterative approach to optimize dialog"
D19-1014,P18-1140,1,0.801165,"atural language. Zhang et al. (2018), proposed an approach involving hierarchical reinforcement RL on Task-oriented Dialog System Various RL-based models have been proposed to train task-oriented dialog systems (Williams and Young, 2007). In order to build a traditional modular-based dialog system, researchers first identify the semantic representation, such as the dialog acts and slots in user utterances. Then they accumulate these semantic representations over time to track the dialog state. Finally they apply RL to learn an optimized dialog policy given the dialog state (Raux et al., 2005; Shi and Yu, 2018). Such modular-based dialog systems are effective in narrow task domains, such as searching a bus route schedule and reserving a restaurant through natural language, but they fail to generalize to complex settings where the size of the action space increases. Owing to the development of deep learning, RL on neural sequence-to-sequence models has been explored in more complex dialog domains such as open-domain conversation (Li et al., 2016) and negotiation (Lewis et al., 2017). However, due to the difficulty of assigning appropriate rewards when operating in a large action space, these framewor"
D19-1014,W18-5015,1,0.583333,"sational data, the neural end-to-end system can effectively learn to generate coherent and natural language. While much success has been achieved by applying neural sequence to sequence models to 143 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 143–153, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics learning and state-adaptation techniques that enable the agent to learn an optimal and efficient multi-modal policy. The bottleneck of (Zhang et al., 2018)’s method, however, is that the system response is retrieved from a predefined humanwritten or system-generated utterance. The number of predefined responses are limited, therefore, this method does not easily generalize to other tasks in real-world settings. We address these limitations by applying RL on a reduced, yet more relevant action space, while optimizing the dialog generator in a supervised fashion. We alternatively optimize policy learning to language generation to combine the two tasks together. trieval policy from dialog generation by applying RL, with the goal of achieving an opt"
D19-1014,N19-1123,0,0.0426158,"Missing"
D19-1162,W17-4604,0,0.0371689,"Missing"
D19-1162,D18-1217,0,0.0237575,"Missing"
D19-1162,P81-1022,0,0.646662,"Missing"
D19-1162,D18-1300,0,0.0660091,"Missing"
D19-1162,D08-1008,0,0.0795869,"Missing"
D19-1162,N18-3022,0,0.0672671,"Missing"
D19-1162,N18-1088,0,0.337418,"differences in relation distribution, such as the higher relative frequencies of root and nsubj can be explained by the shorter sentences in ConvBank compared to UD-EWT. Since each sentence must have a root, and most have a subject, the fewer other words in each sentence, the higher the frequencies of these two tags will tend to be. 5 Parsing Experiments To demonstrate the utility of the ConvBank dataset, we use the data to train a dependency 1 Training Data We use three datasets in training our dependency parser. We use the publicly available UD-EWT (Silveira et al., 2014) and Tweebank v.2 (Liu et al., 2018) to train baseline models. We also combine UD-EWT and Tweebank to create a larger UD dataset for pre-training. Finally, we use our own ConvBank dataset to fine-tune our bestperforming baseline model. We hold out 500 annotated ConvBank sentences for testing. We considered using the constituency parsed Switchboard corpus (Godfrey et al., 1992), which is a human-human telephone corpus, due to its similarity to our domain. However, no fully UDcompliant version of the dependency parsed corpus is publicly available. Although conversion from constituency to dependency graphs is possible, we found the"
D19-1162,P14-5010,0,0.0043368,"Missing"
D19-1162,nasr-etal-2014-automatically,0,0.0601793,"Missing"
D19-1162,silveira-etal-2014-gold,0,0.0375993,"Missing"
D19-1162,P18-2098,0,0.132982,"Missing"
D19-1162,W18-4918,0,0.0120848,"UD dataset for pre-training. Finally, we use our own ConvBank dataset to fine-tune our bestperforming baseline model. We hold out 500 annotated ConvBank sentences for testing. We considered using the constituency parsed Switchboard corpus (Godfrey et al., 1992), which is a human-human telephone corpus, due to its similarity to our domain. However, no fully UDcompliant version of the dependency parsed corpus is publicly available. Although conversion from constituency to dependency graphs is possible, we found the resulting dependency graphs unusable due to the error-prone conversion process. Peng and Zeldes (2018) point out that conversion systems particularly struggle with attaching nominal modifiers and oblique arguments. 5.2 Methods We build all models using the biaffine parser as described in Dozat and Manning (2016) and Qi et al. (2019). We use the open-source implementations of Dozat’s biaffine parser code2 for training our models. We use Glove (Pennington et al., 2014) for pre-trained word embeddings. We train three baseline models to compare how models trained on text data compare with our model, which leverages both annotated text and automated speech transcripts. First, we train a parsing mod"
D19-1162,D14-1162,0,0.0856723,"iant version of the dependency parsed corpus is publicly available. Although conversion from constituency to dependency graphs is possible, we found the resulting dependency graphs unusable due to the error-prone conversion process. Peng and Zeldes (2018) point out that conversion systems particularly struggle with attaching nominal modifiers and oblique arguments. 5.2 Methods We build all models using the biaffine parser as described in Dozat and Manning (2016) and Qi et al. (2019). We use the open-source implementations of Dozat’s biaffine parser code2 for training our models. We use Glove (Pennington et al., 2014) for pre-trained word embeddings. We train three baseline models to compare how models trained on text data compare with our model, which leverages both annotated text and automated speech transcripts. First, we train a parsing model on UDEWT (Silveira et al., 2014) alone. We also train a separate model on Tweebank v.2 (Liu et al., 2018) alone to determine how a parser trained on tweets, which are arguably more similar to conversational speech, will perform. We also train a model on combined UD-EWT and Tweebank data. Our final baseline is a model trained on a 1,000 utterance subset of ConvBank"
D19-1206,D18-1547,0,0.15578,"Missing"
D19-1206,P16-2008,0,0.0438131,"Missing"
D19-1206,N19-1169,0,0.0155055,"both user and system agents with dialog self-play. Liu and Lane (2017) presented a method for iterative dialog policy training and address the problem of building reliable simulators by optimizing the system and the user jointly. But such iterative approach requires extra effort in setting up RL and designing reward for the user simulator, which may result in the two agents exploiting the task, and leads to numerical instability. Another challenging research question is how user simulator performance can be evaluated (Schatztnann et al., 2005; Ai and Litman, 2011a,b; Engelbrecht et al., 2009; Hashimoto et al., 2019). Pietquin and Hastie (2013) conducted a comprehensive survey over metrics that have been used to assess user simulators, such as perplexity and BLEU score (Papineni et al., 2002). However, some of the metrics are designed specifically for language generation evaluation, and as Liu et al. (2016) pointed out, these automatic metrics barely correlate with human evaluation. Therefore, Ai and Litman (2011a) involved human judges to directly rate the simulated dialog. Schatzmann and Young (2009) asked humans to interact with the trained systems to perform indirect human evaluation. Schatztnann et a"
D19-1206,D18-1256,0,0.318734,"uperior result in automatic metrics does not guarantee a better result in the real situation. Li et al. (2016) proposed an agenda-based user simulator in the movie domain and published a generic user simulator building framework. In this work, we build a similar agenda-based user simulator in the restaurant domain, and focus more on analyzing the effects of using different user simulators. However, it’s not feasible to build agenda-based user simulators for more complex tasks without an explicit agenda. Therefore, people have also studied how to build user simulators in a data-driven fashion. He et al. (2018) fit a supervised-learningbased user simulator to perform RL training on a negotiation task. Asri et al. (2016) developed a seq2seq model for user simulation in the restaurant search domain, which took the dialog context into consideration without the help of external data structure. Kreyssig et al. (2018) introduced the Neural User Simulator (NUS) which learned user behaviour from a corpus and generates natural language directly instead of semantic output such as dialog acts. However, unlike in ABUS, how to infuse the agenda into the dialog planning and assure consistency in data-driven user"
D19-1206,W18-5007,0,0.064592,"taurant domain, and focus more on analyzing the effects of using different user simulators. However, it’s not feasible to build agenda-based user simulators for more complex tasks without an explicit agenda. Therefore, people have also studied how to build user simulators in a data-driven fashion. He et al. (2018) fit a supervised-learningbased user simulator to perform RL training on a negotiation task. Asri et al. (2016) developed a seq2seq model for user simulation in the restaurant search domain, which took the dialog context into consideration without the help of external data structure. Kreyssig et al. (2018) introduced the Neural User Simulator (NUS) which learned user behaviour from a corpus and generates natural language directly instead of semantic output such as dialog acts. However, unlike in ABUS, how to infuse the agenda into the dialog planning and assure consistency in data-driven user simulators has been an enduring challenge. In this paper, we present a supervised-learning-based user simulator and integrate the agenda into the policy learning. Furthermore, we compare such a data-driven method with its agenda-based counterpart. Another line of user simulator work treats the user simulat"
D19-1206,P18-1133,0,0.0174322,"notated dialogs. Model-based It requires specific human expertise to design rules for agenda-based user simulators (compared to more easily accessible annotation), and the process is both labor-intensive and errorprone. Moreover, for complicated tasks such as negotiation, it is not practical to design rules in the policy (He et al., 2018). Therefore, we explore the possibility of building dialog manager with supervised learning methods. Compared to agenda-based simulators which require special expert knowledge, supervised learning methods require less expert involvement. We utilize Sequicity (Lei et al., 2018) to construct model-based user simulator. Sequicity is a simple seq2seq dialog system model with copy and attention mechanism. It also used belief span to track the dialog states. For example, inform:{Name:“Caffee Uno”; Phone:“01223448620”} records the information that the system offers and this would be kept in belief span throughout the dialog, while request:{“food”, “price range”} means the system is asking for more information from user to locate a restaurant, which would be removed from belief span once the request is fulfilled. There are 13 types of system dialog acts. To focus on the va"
D19-1206,D16-1230,0,0.0275181,"esigning reward for the user simulator, which may result in the two agents exploiting the task, and leads to numerical instability. Another challenging research question is how user simulator performance can be evaluated (Schatztnann et al., 2005; Ai and Litman, 2011a,b; Engelbrecht et al., 2009; Hashimoto et al., 2019). Pietquin and Hastie (2013) conducted a comprehensive survey over metrics that have been used to assess user simulators, such as perplexity and BLEU score (Papineni et al., 2002). However, some of the metrics are designed specifically for language generation evaluation, and as Liu et al. (2016) pointed out, these automatic metrics barely correlate with human evaluation. Therefore, Ai and Litman (2011a) involved human judges to directly rate the simulated dialog. Schatzmann and Young (2009) asked humans to interact with the trained systems to perform indirect human evaluation. Schatztnann et al. (2005) proposed crossmodel evaluation to compare user simulators since human involvement is expensive. We combine the existing evaluation methods and conduct comprehensive assessments to measure the gap between automatic metrics and human satisfaction. 1991 3 Dataset We choose the restaurant"
D19-1206,D17-2014,0,0.0355762,"man over agendabased methods. Agenda-Template is comparable to SL-based simulators because of its fluent responses and carefully-designed policy. 6.3 Human Indirect Evaluation on AMT The ultimate goal of user simulator building is to train better system policies. Automatic metrics such as success rate can give us a sense on the system’s performance, but the ultimate evaluation should be conducted on human so that we can know the real performance of the system policy when deployed. Motivated by this, we tested the RL systems trained with various user simulators on Amazon Mechanical Turk (AMT) (Miller et al., 2017), and asked Turkers to interact with the system and obtained their opinions. Each system is tested on 100 Turkers. The results are shown in Table 2. The AMT interface is in the Appendix. We also listed two common automatic metrics in Table 2 to compare. The “Dialog Length” column shows the average dialog length of the Turker-Machine dialogs, which reflects the system’s efficiency to some extent. The “Auto Success” column represents the automatic success rate. It’s the convergent success rate from Fig. 3, measured by freezing the policy and testing against the user simulator for 100 episodes. P"
D19-1206,P02-1040,0,0.10367,"rs by optimizing the system and the user jointly. But such iterative approach requires extra effort in setting up RL and designing reward for the user simulator, which may result in the two agents exploiting the task, and leads to numerical instability. Another challenging research question is how user simulator performance can be evaluated (Schatztnann et al., 2005; Ai and Litman, 2011a,b; Engelbrecht et al., 2009; Hashimoto et al., 2019). Pietquin and Hastie (2013) conducted a comprehensive survey over metrics that have been used to assess user simulators, such as perplexity and BLEU score (Papineni et al., 2002). However, some of the metrics are designed specifically for language generation evaluation, and as Liu et al. (2016) pointed out, these automatic metrics barely correlate with human evaluation. Therefore, Ai and Litman (2011a) involved human judges to directly rate the simulated dialog. Schatzmann and Young (2009) asked humans to interact with the trained systems to perform indirect human evaluation. Schatztnann et al. (2005) proposed crossmodel evaluation to compare user simulators since human involvement is expensive. We combine the existing evaluation methods and conduct comprehensive asse"
D19-1206,P19-1253,1,0.859605,"fore, the RL model will experience the “anything else” scenario more in Agenda-based simulators than in SL-based simulators. When real users ask about “anything else”, RL systems trained with Agenda-based simulators will have more experiences in handling such a case, compared to systems trained with SL-based simulators. In this paper, we perform in-depth studies on the restaurant domain as it’s the most well-studied domain in task-oriented dialog systems, yet there’s still no standard user simulator available. In the future we plan to include more domain using various domain-adaptive methods (Qian and Yu, 2019; Tran and Nguyen, 2018; Gaˇsi´c et al., 2017) to support multi-domain dialog system research, and incorporate our work into more and more standardized dialog system platforms (Lee et al., 2019). 8 Conclusions User simulators are essential components in training RL-based dialog systems. However, building user simulators is not a trivial task. In this paper, we surveyed through different ways to build user simulators at the levels of dialog manager and NLG, and analyzed the pros and cons of each method. Further, we evaluated each simulator with automatic metrics and human evaluations both direc"
D19-1206,N07-2038,0,0.760876,"Missing"
D19-1206,P18-1140,1,0.84677,"a direct impact on the trained RL policy. * Equal contribution. The code and data are released at https://github. com/wyshi/user-simulator. 1 Such an intertwined relation between user simulator and dialog system makes the whole process a “chicken and egg” problem. This naturally leads to the question of how different user simulators impact the system performance, and how to build appropriate user simulators for different tasks. In previous RL-based dialog system literature, people reported their system’s performance, such as success rate, on their specific user simulators (Liu and Lane, 2017; Shi and Yu, 2018), but the details of the user simulators are not sufficient to reproduce the results. User simulators’ quality can vary in multiple aspects, which could lead to unfair comparison between different trained systems. For instance, RL systems built with more complicated user simulators will have lower scores on the automatic metrics, compared to those built using simpler user simulators. However, the good performance may not necessarily transfer when the system is tested by real users. In fact, models that have a low score but are trained on better simulators may actually perform better in real si"
D19-1206,N19-1178,1,0.755918,"own in Table 2. The AMT interface is in the Appendix. We also listed two common automatic metrics in Table 2 to compare. The “Dialog Length” column shows the average dialog length of the Turker-Machine dialogs, which reflects the system’s efficiency to some extent. The “Auto Success” column represents the automatic success rate. It’s the convergent success rate from Fig. 3, measured by freezing the policy and testing against the user simulator for 100 episodes. Previous approaches have utilized these two automatic metrics to evaluate the system’s efficiency and success (Williams et al., 2017; Shi et al., 2019), but we find that due to user individual difference, such automatic metrics have relatively big variances and don’t always correlate with efficiency perceived by human. For example, some users tend to provide all slots in one turn, while others provide slots only when necessary; some users would even go off-the-script and ask about restaurants not mentioned in the goal. Therefore, we should caution against relying solely on the automatic metrics to represent user opinion and the best way is to ask the users directly for their thoughts on the system’s performance from multiple aspects as follo"
D19-1206,C18-1103,0,0.0179164,"will experience the “anything else” scenario more in Agenda-based simulators than in SL-based simulators. When real users ask about “anything else”, RL systems trained with Agenda-based simulators will have more experiences in handling such a case, compared to systems trained with SL-based simulators. In this paper, we perform in-depth studies on the restaurant domain as it’s the most well-studied domain in task-oriented dialog systems, yet there’s still no standard user simulator available. In the future we plan to include more domain using various domain-adaptive methods (Qian and Yu, 2019; Tran and Nguyen, 2018; Gaˇsi´c et al., 2017) to support multi-domain dialog system research, and incorporate our work into more and more standardized dialog system platforms (Lee et al., 2019). 8 Conclusions User simulators are essential components in training RL-based dialog systems. However, building user simulators is not a trivial task. In this paper, we surveyed through different ways to build user simulators at the levels of dialog manager and NLG, and analyzed the pros and cons of each method. Further, we evaluated each simulator with automatic metrics and human evaluations both directly and indirectly, and"
D19-1206,W15-4639,0,0.0269341,"nto human-readable utterances. The quality of the templates have direct impact on the NLG quality. Retrieval Template method suffers from limited vocabulary size and language diversity. An alternative method is Retrieval-based NLG (Wu et al., 2016; Hu et al., 2014). The model retrieves user utterances with At as their dialog act in the training dataset. Following He et al. (2018), we represent the context by a TF-IDF weighted bag-ofwords vector and compute the similarity score between the candidate’s context vector and the current context vector to retrieval Ut . Generation Generation method (Wen et al., 2015a,b) does not need expert involvement to rewrite templates, but requires dialog act annotation similar to retrieval method. We build a vanilla seq2seq (Sutskever et al., 2014) model using the annotated data adding At in the input. 5 Dialog System Training Setting Traditionally, hand-crafted dialog acts plus slot values are used as the discrete action space in RL training (Raux et al., 2005). Dialog action space can also be on the word-level. However, previous study shows degenerate behavior when using word-level action space (Zhao et al., 2019), as it is difficult to design a reward. We choose"
D19-1206,D15-1199,0,0.0229993,"nto human-readable utterances. The quality of the templates have direct impact on the NLG quality. Retrieval Template method suffers from limited vocabulary size and language diversity. An alternative method is Retrieval-based NLG (Wu et al., 2016; Hu et al., 2014). The model retrieves user utterances with At as their dialog act in the training dataset. Following He et al. (2018), we represent the context by a TF-IDF weighted bag-ofwords vector and compute the similarity score between the candidate’s context vector and the current context vector to retrieval Ut . Generation Generation method (Wen et al., 2015a,b) does not need expert involvement to rewrite templates, but requires dialog act annotation similar to retrieval method. We build a vanilla seq2seq (Sutskever et al., 2014) model using the annotated data adding At in the input. 5 Dialog System Training Setting Traditionally, hand-crafted dialog acts plus slot values are used as the discrete action space in RL training (Raux et al., 2005). Dialog action space can also be on the word-level. However, previous study shows degenerate behavior when using word-level action space (Zhao et al., 2019), as it is difficult to design a reward. We choose"
D19-1206,P17-1062,0,0.19299,"ros and cons of different user simulators, as well as their impacts on the trained systems. 1 1 Introduction Reinforcement Learning has gained more and more attention in dialog system training because it treats the dialog planning as a sequential decision problem and focuses on long-term rewards (Su et al., 2017). However, RL requires interaction with the environment, and obtaining real human users to interact with the system is both time-consuming and labor-intensive. Therefore, building user simulators to interact with the system before deployment to real users becomes an economical choice (Williams et al., 2017; Li et al., 2016). But the performance of the user simulator has a direct impact on the trained RL policy. * Equal contribution. The code and data are released at https://github. com/wyshi/user-simulator. 1 Such an intertwined relation between user simulator and dialog system makes the whole process a “chicken and egg” problem. This naturally leads to the question of how different user simulators impact the system performance, and how to build appropriate user simulators for different tasks. In previous RL-based dialog system literature, people reported their system’s performance, such as suc"
D19-1206,N19-1123,0,0.0300369,"tor to retrieval Ut . Generation Generation method (Wen et al., 2015a,b) does not need expert involvement to rewrite templates, but requires dialog act annotation similar to retrieval method. We build a vanilla seq2seq (Sutskever et al., 2014) model using the annotated data adding At in the input. 5 Dialog System Training Setting Traditionally, hand-crafted dialog acts plus slot values are used as the discrete action space in RL training (Raux et al., 2005). Dialog action space can also be on the word-level. However, previous study shows degenerate behavior when using word-level action space (Zhao et al., 2019), as it is difficult to design a reward. We choose the first approach and use the discrete action space with six system dialog acts: “ask restaurant type”, “present restaurant search result”, “provide restaurant info”, “ask reservation info”, “inform reservation result”, “goodbye”. Simple action masks are applied to avoid impossible actions such as making reservation before presenting a restaurant. We use a 2-layer bidirectional-GRU with 200 hidden units to train a NLU module. For simplicity, we use the template-based method in the system’s NLG module. We used policy gradient method to train d"
D19-1206,W17-5518,0,0.0505332,"oth directly and indirectly. We also ask human users to assess the simulators directly and indirectly by rating the simulated dialogs and interacting with the trained systems. This paper presents a comprehensive evaluation framework for user simulator study and provides a better understanding of the pros and cons of different user simulators, as well as their impacts on the trained systems. 1 1 Introduction Reinforcement Learning has gained more and more attention in dialog system training because it treats the dialog planning as a sequential decision problem and focuses on long-term rewards (Su et al., 2017). However, RL requires interaction with the environment, and obtaining real human users to interact with the system is both time-consuming and labor-intensive. Therefore, building user simulators to interact with the system before deployment to real users becomes an economical choice (Williams et al., 2017; Li et al., 2016). But the performance of the user simulator has a direct impact on the trained RL policy. * Equal contribution. The code and data are released at https://github. com/wyshi/user-simulator. 1 Such an intertwined relation between user simulator and dialog system makes the whole"
D19-3014,W06-1323,0,0.106194,"f the interaction, and the user’s per-utterance word count (averaged across all utterances). We modeled the relationship between word count and the two metrics of user engagement (overall rating, mean number of turns) in separate linear regressions. Text To Speech After NLG, we adjust the TTS of the system to improve the expressiveness of the voice to convey that the system is an engaged and active participant in the conversation. We use a rule-based system to systematically add interjections, specifically Alexa Speechcons, and fillers to approximate human-like cognitive-emotional expression (Tokuhisa and Terashima, 2006). For more on the framework and analysis of the TTS modifications, see (Cohn et al., 2019). 3 Response Depth: Mean Word Count Analysis From January 5, 2019 to March 5, 2019, we collected conversational data for Gunrock. During this time, no other code updates occurred. We analyzed conversations for Gunrock with at least 3 user turns to avoid conversations triggered by accident. Overall, this resulted in a total of 34,432 user conversations. Together, these users gave Gunrock an average rating of 3.65 (median: 4.0), which was elicited at the end of the conversation (“On a scale from 1 to 5 star"
D19-3014,W19-5935,1,0.809868,"ed the relationship between word count and the two metrics of user engagement (overall rating, mean number of turns) in separate linear regressions. Text To Speech After NLG, we adjust the TTS of the system to improve the expressiveness of the voice to convey that the system is an engaged and active participant in the conversation. We use a rule-based system to systematically add interjections, specifically Alexa Speechcons, and fillers to approximate human-like cognitive-emotional expression (Tokuhisa and Terashima, 2006). For more on the framework and analysis of the TTS modifications, see (Cohn et al., 2019). 3 Response Depth: Mean Word Count Analysis From January 5, 2019 to March 5, 2019, we collected conversational data for Gunrock. During this time, no other code updates occurred. We analyzed conversations for Gunrock with at least 3 user turns to avoid conversations triggered by accident. Overall, this resulted in a total of 34,432 user conversations. Together, these users gave Gunrock an average rating of 3.65 (median: 4.0), which was elicited at the end of the conversation (“On a scale from 1 to 5 stars, how do you feel about talking to this socialbot again?”). Users engaged with Gunrock fo"
D19-3014,2021.eacl-main.94,1,0.845122,"Missing"
D19-3014,N18-5020,0,0.253208,"Ashwin Bhandare, Zhou Yu University of California, Davis {dianyu, mdcohn, yimyang, abtchen, wmwen, jpzhang, minzhou, krjesse}@ucdavis.edu {amchau, abhowmick, shriyer, s.giritheja, ssdavidson, asbhandar, joyu}@ucdavis.edu Abstract strategy to interleave task- and non-task functions in chatbots has been proposed (Rudnicky, 2019), no chatbots to our knowledge have employed a fact/opinion interleaving strategy. Finally, we use an extensive persona database to provide coherent profile information, a critical challenge in building social chatbots (Zhang et al., 2018). Compared to previous systems (Fang et al., 2018), Gunrock generates more balanced conversations between human and machine by encouraging and understanding more human inputs (see Table 1 for an example). Gunrock is the winner of the 2018 Amazon Alexa Prize, as evaluated by coherence and engagement from both real users and Amazonselected expert conversationalists. We focus on understanding complex sentences and having in-depth conversations in open domains. In this paper, we introduce some innovative system designs and related validation analysis. Overall, we found that users produce longer sentences to Gunrock, which are directly related to"
D19-3014,P18-1205,0,0.211022,"reenath Iyer, Giritheja Sreenivasulu, Sam Davidson, Ashwin Bhandare, Zhou Yu University of California, Davis {dianyu, mdcohn, yimyang, abtchen, wmwen, jpzhang, minzhou, krjesse}@ucdavis.edu {amchau, abhowmick, shriyer, s.giritheja, ssdavidson, asbhandar, joyu}@ucdavis.edu Abstract strategy to interleave task- and non-task functions in chatbots has been proposed (Rudnicky, 2019), no chatbots to our knowledge have employed a fact/opinion interleaving strategy. Finally, we use an extensive persona database to provide coherent profile information, a critical challenge in building social chatbots (Zhang et al., 2018). Compared to previous systems (Fang et al., 2018), Gunrock generates more balanced conversations between human and machine by encouraging and understanding more human inputs (see Table 1 for an example). Gunrock is the winner of the 2018 Amazon Alexa Prize, as evaluated by coherence and engagement from both real users and Amazonselected expert conversationalists. We focus on understanding complex sentences and having in-depth conversations in open domains. In this paper, we introduce some innovative system designs and related validation analysis. Overall, we found that users produce longer se"
N19-1178,N10-1008,0,0.423356,"Missing"
N19-1178,D16-1031,0,0.0301488,"omatic dialog system can mimic the behaviour in human-human dialogs, it can interact with users in a more natural and user-friendly way. Therefore, we propose to integrate the dialog structure information into the reward design of the reinforcement learning (RL). Experiments show that the model with the proposed reward functions converges faster to a better success rate. 2 Related Work Variational Autoencoders (VAEs) (Kingma and Welling, 2013; Doersch, 2016; Kingma et al., 2014) have gained popularity in many computational linguistics tasks due to its interpretable generative model structure (Miao and Blunsom, 2016; Miao et al., 2017). Zhao et al. (2018) applied VAE to learn discrete sentence representations and achieved good results. This is similar to our work, but we focus more on modeling the dialog structure and using the learned structure to improve the dialog system training. Serban et al. (2017) presented a VHRED model which combines the VRNN and encoder-decoder structure for direct dialog response generation. While also similar, our model uses discrete latent vectors instead of continuous ones, and re-constructs the utterances to recover the latent dialog structure, instead of modeling the resp"
N19-1178,J86-3001,0,0.613142,"tiveness in a downstream task, the dialog system building task. Experiments show that, by integrating the learned dialog structure into the reward function design, the model converges faster and to a better outcome in a reinforcement learning setting. 1 Introduction Human dialogs are like well-structured buildings, with words as the bricks, sentences as the floors, and topic transitions as the stairs connecting the whole building. Therefore, discovering dialog structure is crucial for various areas in computational linguistics, such as dialog system building (Young, 2006), discourse analysis (Grosz and Sidner, 1986), and dialog summarization (Murray et al., 2005; Liu et al., 2010). In domain specific tasks such as restaurant booking, it’s common for people to follow a typical conversation flow. Current dialog systems require human experts to design the dialog structure, which is time consuming and sometimes insufficient to satisfy various customer needs. Therefore, it’s of great importance to automatically discover dialog structure from existing human-human conversations and incorporate it into the dialog system design. However, modeling human conversation is not easy for machines. Some previous work rel"
N19-1178,N10-1020,0,0.505631,"of training examples, and by the limited number of application domains (Zhai and Williams, 2014). Moreover, structure annotations on human conversation can be subjective, which makes it hard to reach inter-rater agreements. Therefore, we propose an unsupervised method to infer the latent dialog structure since unsupervised methods do not require annotated dialog corpus. Limited previous work has studied unsupervised methods to model the latent dialog structure. Most of the previous methods use the hidden Markov model to capture the temporal dependency within human dialogs (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014). We propose to adopt a new type of models, the variational recurrent neural network (VRNN, a recurrent version of the VAE) (Chung et al., 2015), and infer the latent dialog structure with variational inference. VRNN is suitable for modeling sequential information. Compared to the simpler HMM models, VRNN also has the flexibility to model highly non-linear dynamics (Chung et al., 2015) in human dialogs. Our basic approach assumes that the dialog structure is composed of a sequence of latent states. Each conversational exchange (a pair of user and system utterances at"
N19-1178,P18-1140,1,0.865892,"the information on what action is more likely to follow another action, the model can learn to follow real-data distributions and make better predictions. We encode the transition information through KL-divergence, a measurement of the distance between two distributions, in the reward function. We design four types of reward functions and describe each of them in Algorithm 1 and Eq. 10 in the Appendix. The traditional delayed reward is the baseline. The second reward function, Repreward, uses constant penalty for repeated questions, as penalizing repetition yields better results, according to Shi and Yu (2018). The third reward function, KL-reward, incorporates the transition table information. From the RL model, we get the predicted probability ppred for different actions; from the D-VRNN model, we get the transition probability ptrans between states and each state is translated to an action. We calculate the negation of the KL-divergence between ptrans and ppred and use it as the immediate reward for every turn. This immediate reward links the predicted distribution with the real-data distribution by calculating the distance between them. The fourth reward function (KL+Rep) gives an additional -2"
N19-1178,P17-1062,0,0.0626824,"Figure 5: Negative log likelihood on weather data. 6.1 5.3 Application on RL VRNN Model Variants Comparison Even though the three proposed VRNN-based models have similar structures, they perform differently and are able to compensate each other. Reward Function Design We use policy gradient method (Williams, 1992) to train the dialog policy. Traditional reward functions give a positive reward (e.g. 20) after the successful completion of the task, 0 or a negative re1803 ward to penalize a failed task and -1 at each extra turn to encourage the system to finish the task sooner rather than later (Williams et al., 2017). But this type of delayed reward functions doesn’t have immediate rewards at each turn, which makes the model converge slowly. Therefore, we propose to incorporate the learned conversational exchange transition information as an immediate reward. The intuition is that in order to complete a task sooner, most users will follow a certain pattern when interacting with the system, for example, a typical flow is that users first give the entities information such as location, then ask for the restaurant information and finally, end the conversation. If we can provide the RL model with the informat"
N19-1178,P14-1004,0,0.708285,"onsuming and sometimes insufficient to satisfy various customer needs. Therefore, it’s of great importance to automatically discover dialog structure from existing human-human conversations and incorporate it into the dialog system design. However, modeling human conversation is not easy for machines. Some previous work rely on human annotations to learn dialog structures in supervised learning settings (Jurafsky, 1997). But since human labeling is expensive and hard to obtain, such method is constrained by the small size of training examples, and by the limited number of application domains (Zhai and Williams, 2014). Moreover, structure annotations on human conversation can be subjective, which makes it hard to reach inter-rater agreements. Therefore, we propose an unsupervised method to infer the latent dialog structure since unsupervised methods do not require annotated dialog corpus. Limited previous work has studied unsupervised methods to model the latent dialog structure. Most of the previous methods use the hidden Markov model to capture the temporal dependency within human dialogs (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014). We propose to adopt a new type of models, the var"
N19-1178,W18-5001,1,0.68242,"5.1 Datasets We test the proposed method on the CamRest676 corpus, which was released and collected by Wen et al. (2016). The task is to help users find restaurants in Cambridge, UK. While this task is highly similar to DSTC2, we choose this dataset instead of DSTC2 because it is relatively clean and comes with good entity extraction methods. There are a total of 676 dialogs in this dataset with three information slots (food, price range and area) and three request table slots (address, phone and postcode). We also evaluate our model on another dataset of simulated conversations, proposed in Zhao and Eskenazi (2018). The task is to help users get the weather report in a certain place at a specific time. The dialog system is controlled by a fixed structure and hand-set probabilities. Therefore, learning the dialog structure of this dataset might be easier. We assume each latent vector in the VAE emits one conversational exchange, including one user utterance and the corresponding system response at time t, and each conversational exchange corresponds to one latent vector, following Zhai and Williams (2014). 5 Experiments We use LSTM (Hochreiter and Schmidhuber, 1997) with 200-400 units for the RNNs, and a"
N19-1178,P18-1101,1,0.831826,"in human-human dialogs, it can interact with users in a more natural and user-friendly way. Therefore, we propose to integrate the dialog structure information into the reward design of the reinforcement learning (RL). Experiments show that the model with the proposed reward functions converges faster to a better success rate. 2 Related Work Variational Autoencoders (VAEs) (Kingma and Welling, 2013; Doersch, 2016; Kingma et al., 2014) have gained popularity in many computational linguistics tasks due to its interpretable generative model structure (Miao and Blunsom, 2016; Miao et al., 2017). Zhao et al. (2018) applied VAE to learn discrete sentence representations and achieved good results. This is similar to our work, but we focus more on modeling the dialog structure and using the learned structure to improve the dialog system training. Serban et al. (2017) presented a VHRED model which combines the VRNN and encoder-decoder structure for direct dialog response generation. While also similar, our model uses discrete latent vectors instead of continuous ones, and re-constructs the utterances to recover the latent dialog structure, instead of modeling the responses directly. There are some previous"
N19-1178,P17-1061,1,0.828496,"on of zt by another softmax, shown in Eq. (7). Once we have the posterior distribution, we apply Gumbel-Softmax to take samples of zt . D-VRNN and DD-VRNN differ in their priors but not in their inference, because we assume the direct transitions between zt in the prior instead of in the inference. x zt |xt ∼ softmax([ϕenc τ (ht−1 ), ϕτ (xt )]) (7) Loss function. The objective function of VRNN is a timestep-wise variational lower bound, shown in Eq. (8) (Chung et al., 2015). To mitigate the vanishing latent variable problem in VAE, we incorporate bow-loss and Batch Prior Regularization (BPR) (Zhao et al., 2017, 2018) with tunable weights, λ to the final loss function, shown in Eq. (9). -KL(q(zt |x≤t , z<t ) k p(zt |x<t , z<t ))] t=1 (8) LD-VRNN = LVRNN-BPR + λ ∗ Lbow (9) Transition Probability Calculation A good way to represent a dialog structure both numerically and visually is to construct a transition probability table among latent states. Such transition probability can also be used to design reward function in the RL training process. We calculate transition table differently for D-VRNN and DD-VRNN due to their different priors. D-VRNN. From Eq. (6), we know that ht is a function of x≤t and z"
P18-1140,N09-3009,0,0.165747,", adding sentiment information reduced the dialog length and improved the task success rate on a bus information search task. This work is the first attempt to incorporate multimodal user information in the adaptive end-toend dialog system training framework and attained state-of-the-art performance. 1 Introduction Most of us have had frustrating experience and even expressed anger towards automated customer service systems. Unfortunately, none of the current commercial systems can detect user sentiment and let alone act upon it. Researchers have included user sentiment in rule-based systems (Acosta, 2009; Pittermann et al., 2010), where there are strictly-written rules that guide the system to react to user sentiment. Because traditional modular-based systems are harder to train, to update with new data and to debug errors, end-to-end trainable systems are more popular. However, no work has tried to incorporate sentiment information in the end-to-end trainable systems so far to 2 Related Work Many studies in emotion recognition (Schuller et al., 2003; Nwe et al., 2003; Bertero et al., 2016) have used only acoustic features. But there has been work on emotion detection in spoken dialog systems"
P18-1140,E17-2075,0,0.0301502,"7 0.001 0.010 0.011 0.019 0.025 0.028 Max of F-1 0.686 0.596 0.685 0.700 0.707 0.686 0.756 Table 4: Results of sentiment detectors using different features. The best result is highlighted in bold and * indicates statistical significance compared to the baseline, which is using acoustic features only. (p &lt; 0.0001) 6 Supervised Learning (SL) We incorporated the detected user sentiment from the previous section into a supervised learning framework for training end-to-end dialog systems. There are many studies on building a dialog system in a supervised learning setting (Bordes and Weston (2016); Eric and Manning (2017); Seo et al. (2016); Liu and Lane (2017a); Li et al. (2017); Williams et al. (2017)). Following these approaches, we treated the problem of dialog policy learning as a classification problem, which is to select actions among system action templates given conversation history. Specifically, we decided to adopt the framework of Hybrid Code Network (HCN) introduced in Williams et al. (2017), because it is the current state-of-the-art model. We reimplemented HCN and used it as the baseline system, given the absence of direct comparison on DSTC1 data. One caveat is that HCN used action masks (bit v"
P18-1140,I17-1074,0,0.15921,"ational Linguistics (Long Papers), pages 1509–1519 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics alogic features, such as total number of interruptions, to predict user sentiment along with acoustic and textual features. The traditional method to build dialog system is to train modules such as language understanding component, dialog manager and language generator separately (Levin et al., 2000; Williams and Young, 2007; Singh et al., 2002). Recently, more and more work combines all the modules in an end-to-end training framework (Wen et al., 2016; Li et al., 2017; Dhingra et al., 2016; Williams et al., 2017; Liu and Lane, 2017a). Specifically related to our work, Williams et al. (2017) built a model, which combined the traditional rule-based system and the modern deep-learning-based system, with experts designing actions masks to regulate the neural model. Action masks are bit vectors indicating allowed system actions at certain dialog state. The end-to-end framework made dialog system training simpler and model updating easier. Reinforcement learning (RL) is also popular in dialog system building (Zhao and Eskenazi, 2016; Liu and Lane, 2017b; Li et a"
P18-1140,P17-1062,0,0.311159,"s 1509–1519 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics alogic features, such as total number of interruptions, to predict user sentiment along with acoustic and textual features. The traditional method to build dialog system is to train modules such as language understanding component, dialog manager and language generator separately (Levin et al., 2000; Williams and Young, 2007; Singh et al., 2002). Recently, more and more work combines all the modules in an end-to-end training framework (Wen et al., 2016; Li et al., 2017; Dhingra et al., 2016; Williams et al., 2017; Liu and Lane, 2017a). Specifically related to our work, Williams et al. (2017) built a model, which combined the traditional rule-based system and the modern deep-learning-based system, with experts designing actions masks to regulate the neural model. Action masks are bit vectors indicating allowed system actions at certain dialog state. The end-to-end framework made dialog system training simpler and model updating easier. Reinforcement learning (RL) is also popular in dialog system building (Zhao and Eskenazi, 2016; Liu and Lane, 2017b; Li et al., 2016). A common practice is to simulate u"
P18-1140,W16-3601,0,0.0327166,"training framework (Wen et al., 2016; Li et al., 2017; Dhingra et al., 2016; Williams et al., 2017; Liu and Lane, 2017a). Specifically related to our work, Williams et al. (2017) built a model, which combined the traditional rule-based system and the modern deep-learning-based system, with experts designing actions masks to regulate the neural model. Action masks are bit vectors indicating allowed system actions at certain dialog state. The end-to-end framework made dialog system training simpler and model updating easier. Reinforcement learning (RL) is also popular in dialog system building (Zhao and Eskenazi, 2016; Liu and Lane, 2017b; Li et al., 2016). A common practice is to simulate users. However, building a user simulator is not a trivial task. Zhao and Eskenazi (2016) combines the strengths of reinforcement learning and supervised learning to accelerate the learning of a conversational game simulator. Li et al. (2016) provides a standard framework for building user simulators, which can be modified and generalized to different domains. Liu and Lane (2017b) describes a more advanced way to build simulators for both the user and the agent, and train both sides jointly for better performance. We sim"
P18-1140,D16-1110,0,\N,Missing
P18-1140,P17-1045,0,\N,Missing
P19-1253,P17-1045,0,0.0188301,"sfer learning methods (Caruana, 1997b). We publish the code on the github1 . 2 Related Works Task-oriented dialog systems are developed to assist users to complete specific tasks, such as booking restaurant or querying weather information. The traditional method to build a dialog system is to train modules separately (Chen et al., 2017) such as: natural language understanding (NLU) (Deng et al., 2012; Dauphin et al., 2014; Hashemi et al.), dialog state tracker (Henderson et al., 2014), dialog policy learning (Cuay´ahuitl et al., 2015; Young et al., 2013) and natural language generation (NLG) (Dhingra et al., 2017; Wen et al., 2015). Henderson et al. (2013) introduces the concept of belief tracker that tracks users’ requirements and constraints in the dialog across turns. Recently, more and more works combine all the modules into a seq2seq model for the reason of easier model update. Lei et al. (2018) has introduced a new end-to-end dialog system, sequicity, constructed on a two-stage CopyNet (Gu et al., 2016): one for the belief tracker and another one for the response generation. This model has fewer number of parameters and trains faster than the state-of-the-art baselines while outperforming baseli"
P19-1253,P16-1154,0,0.520984,". We use the simulated data generated by SimDial (Zhao and Esk´enazi, 2018). Specifically, we use three domains: restaurant, weather, and bus information search, as source data and test the meta-learned parameter initialization against 2639 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2639–2649 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics the target domain, movie information search. By modifying Sequicity (Lei et al., 2018), a seq2seq encoder-decoder network, improving it with a two-stage CopyNet (Gu et al., 2016), we implement the MAML algorithm to achieve an optimal initialization using dialog data from source domains. Then, we fine-tune the initialization towards the target domain with a minimal portion of dialog data using normal gradient descent. Finally, we evaluate the adapted model with testing data also from the target domain. We outperform the state-of-the-art zero-shot baseline, ZSDG (Zhao and Esk´enazi, 2018), as well as other transfer learning methods (Caruana, 1997b). We publish the code on the github1 . 2 Related Works Task-oriented dialog systems are developed to assist users to complet"
P19-1253,D18-1398,0,0.103226,"ning new tasks with few steps and little data based on well-known tasks. One way to realize meta-learning is to learn an optimal initialization that could be adapted to new task accurately and quickly with little data (Vinyals et al., 2016; Snell et al., 2017). Another way to learn the learning progress is to train a meta-learner to optimize the optimizer of original network for updating parameters (Andrychowicz et al., 2016; Grant et al., 2018). Meta-learning has been applied in various circumstances such as image classification (Santoro et al., 2016; Finn et al., 2017), machine translation (Gu et al., 2018), robot manipulation (Duan et al., 2016; Wang et al., 2016), etc. We propose to apply meta-learning algorithm on top of the sequicity model to achieve dialog domain adaptation. Specifically, we chose the recently introduced algorithm, model-agnostic meta-learning(MAML) (Finn et al., 2017), because it generalizes across different models. This algorithm is compatible with any model optimized with gradient descent, such as regression, classification and even policy gradient reinforcement learning. Moreover, this algorithm outperforms other state-of-the-art one-shot algorithms for image classifica"
P19-1253,W13-4073,0,0.0371342,"e publish the code on the github1 . 2 Related Works Task-oriented dialog systems are developed to assist users to complete specific tasks, such as booking restaurant or querying weather information. The traditional method to build a dialog system is to train modules separately (Chen et al., 2017) such as: natural language understanding (NLU) (Deng et al., 2012; Dauphin et al., 2014; Hashemi et al.), dialog state tracker (Henderson et al., 2014), dialog policy learning (Cuay´ahuitl et al., 2015; Young et al., 2013) and natural language generation (NLG) (Dhingra et al., 2017; Wen et al., 2015). Henderson et al. (2013) introduces the concept of belief tracker that tracks users’ requirements and constraints in the dialog across turns. Recently, more and more works combine all the modules into a seq2seq model for the reason of easier model update. Lei et al. (2018) has introduced a new end-to-end dialog system, sequicity, constructed on a two-stage CopyNet (Gu et al., 2016): one for the belief tracker and another one for the response generation. This model has fewer number of parameters and trains faster than the state-of-the-art baselines while outperforming baselines on two large-scale datasets. The traditi"
P19-1253,P18-1133,0,0.0895479,"zation that could be accurately and quickly adapted to an unknown new domain with little data. We use the simulated data generated by SimDial (Zhao and Esk´enazi, 2018). Specifically, we use three domains: restaurant, weather, and bus information search, as source data and test the meta-learned parameter initialization against 2639 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2639–2649 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics the target domain, movie information search. By modifying Sequicity (Lei et al., 2018), a seq2seq encoder-decoder network, improving it with a two-stage CopyNet (Gu et al., 2016), we implement the MAML algorithm to achieve an optimal initialization using dialog data from source domains. Then, we fine-tune the initialization towards the target domain with a minimal portion of dialog data using normal gradient descent. Finally, we evaluate the adapted model with testing data also from the target domain. We outperform the state-of-the-art zero-shot baseline, ZSDG (Zhao and Esk´enazi, 2018), as well as other transfer learning methods (Caruana, 1997b). We publish the code on the git"
P19-1253,C18-1103,0,0.0364846,"ll required to train a model from scratch if we already have models for similar tasks. Instead, we want to quickly adapt a trained model to a new task with a small amount of new data. Dialog adaptation 1 https://github.com/qbetterk/sequicity.git has been explored in various dimensions. Shi and Yu (2018) introduces an end-to-end dialog system that adapts to user sentiment. Mo et al. (2018) and Genevay and Laroche (2016) also trains a user adaptive dialog systems using transfer learning. Recently, effective domain adaptation has been introduced for natural language generation in dialog systems (Tran and Nguyen, 2018; Wen et al., 2016). Some domain adaptation work has been done on dialog states tracking (Mrkˇsi´c et al., 2015) and dialog policy learning (Vlasov et al., 2018) as well. However, there is no recent work about domain adaptation for a seq2seq dialog system, except ZSDG Zhao and Esk´enazi (2018). ZSDG is a zero-shot learning method that adapts action matching to adapt models learned from multiple source domains to a new target domain only using its domain description. Different from ZSDG, we propose to adapt meta-learning to achieve similar domain adaption ability. Meta-learning aims at learning"
P19-1253,P15-2130,0,0.0404029,"Missing"
P19-1253,W15-4639,0,0.030843,"(Caruana, 1997b). We publish the code on the github1 . 2 Related Works Task-oriented dialog systems are developed to assist users to complete specific tasks, such as booking restaurant or querying weather information. The traditional method to build a dialog system is to train modules separately (Chen et al., 2017) such as: natural language understanding (NLU) (Deng et al., 2012; Dauphin et al., 2014; Hashemi et al.), dialog state tracker (Henderson et al., 2014), dialog policy learning (Cuay´ahuitl et al., 2015; Young et al., 2013) and natural language generation (NLG) (Dhingra et al., 2017; Wen et al., 2015). Henderson et al. (2013) introduces the concept of belief tracker that tracks users’ requirements and constraints in the dialog across turns. Recently, more and more works combine all the modules into a seq2seq model for the reason of easier model update. Lei et al. (2018) has introduced a new end-to-end dialog system, sequicity, constructed on a two-stage CopyNet (Gu et al., 2016): one for the belief tracker and another one for the response generation. This model has fewer number of parameters and trains faster than the state-of-the-art baselines while outperforming baselines on two large-sc"
P19-1253,P02-1040,0,0.10365,"tion efficiency of our methods. 5.2 Metrics There are three main metrics in our experiments: BLEU score, entity F1 score and adapting time. The first two are the most important and persuasive metrics used in Finn et al. (2017) has exhaustively demonstrated the MAML’s fast adaptation speed to new tasks. It could even achieve amazing performance with one step of gradient update incorporating with halfcheetah and ant. We would also like to count the number of epochs for adaptation to compare the adaptation speed between our methods and the baseline of transfer learning. • BLEU We use BLEU score (Papineni et al., 2002) to evaluate the quality of generated response sentences since generating natural language is also part of the task. • Entity F1 Score For each dialog, we compare the generated belief span and the Oracle one. Since belief span contains all the slots that constraints the response, this score also checks the completeness of tasks. • Adapting Time We count the number of epochs during the adaptation training. We only compare the adaptation with the data of the same size. 5.3 Baseline Models To evaluate the effectiveness of our model, we compare DAML with the following two baselines: • ZSDG (Zhao a"
P19-1253,D14-1162,0,0.0873139,"ces as domain description seeds for domain adaptation. • Transfer learning is applied on the sequicity model as the second baseline. We train the basic model by simply mixing all the data from source domains and then following Figure 1 (a) to update the model. We also enlarge the vocabulary with the training data in target domain. Besides, we implement one-shot learning version of this model by only using one target domain dialog for adaptation, as a comparison with the one-shot learning case of DAML. 5.4 Implementation details For all experiments, we use the pre-trained GloVe word embedding (Pennington et al., 2014) with a dimension of 50. We choose the one-layer GRU networks with a hidden size of 50 to construct the encoder and decoder. The model is optimized using Adam (Kingma and Ba, 2014) with a learning rate of 0.003. We reduce the learning rate to half if the validation loss increases. We set the batch (Ioffe and Szegedy, 2015) size to 32 and the dropout (Zaremba et al., 2014) rate to 0.5. 6 Results and Analysis Table 1 describes all the model performance. We denote testing data from the combination of 2644 In Domain BLEU Entity F1 Epoch Unseen Slot BLEU Entity F1 Epoch Unseen NLG BLEU Entity F1 Ep"
P19-1253,N16-1015,0,0.0247955,"model from scratch if we already have models for similar tasks. Instead, we want to quickly adapt a trained model to a new task with a small amount of new data. Dialog adaptation 1 https://github.com/qbetterk/sequicity.git has been explored in various dimensions. Shi and Yu (2018) introduces an end-to-end dialog system that adapts to user sentiment. Mo et al. (2018) and Genevay and Laroche (2016) also trains a user adaptive dialog systems using transfer learning. Recently, effective domain adaptation has been introduced for natural language generation in dialog systems (Tran and Nguyen, 2018; Wen et al., 2016). Some domain adaptation work has been done on dialog states tracking (Mrkˇsi´c et al., 2015) and dialog policy learning (Vlasov et al., 2018) as well. However, there is no recent work about domain adaptation for a seq2seq dialog system, except ZSDG Zhao and Esk´enazi (2018). ZSDG is a zero-shot learning method that adapts action matching to adapt models learned from multiple source domains to a new target domain only using its domain description. Different from ZSDG, we propose to adapt meta-learning to achieve similar domain adaption ability. Meta-learning aims at learning new tasks with few"
P19-1253,W18-5001,0,0.0560422,"Missing"
P19-1253,P18-1140,1,0.846473,"parameters and trains faster than the state-of-the-art baselines while outperforming baselines on two large-scale datasets. The traditional paradigm in machine learning research is to train a model for a specific task with plenty of annotated data. Obviously, it is not reasonable that large amount of data is still required to train a model from scratch if we already have models for similar tasks. Instead, we want to quickly adapt a trained model to a new task with a small amount of new data. Dialog adaptation 1 https://github.com/qbetterk/sequicity.git has been explored in various dimensions. Shi and Yu (2018) introduces an end-to-end dialog system that adapts to user sentiment. Mo et al. (2018) and Genevay and Laroche (2016) also trains a user adaptive dialog systems using transfer learning. Recently, effective domain adaptation has been introduced for natural language generation in dialog systems (Tran and Nguyen, 2018; Wen et al., 2016). Some domain adaptation work has been done on dialog states tracking (Mrkˇsi´c et al., 2015) and dialog policy learning (Vlasov et al., 2018) as well. However, there is no recent work about domain adaptation for a seq2seq dialog system, except ZSDG Zhao and Esk´e"
P19-1566,E17-1070,0,0.0383091,"ion strategies. In order to achieve different negotiation goals, He et al. (2018) decoupled the dialogue act and language generation which helped control the strategy with more flexibility. Our work is different in that we focus on the domain of persuasion and personalized persuasion procedure. Traditional persuasive dialogue systems have been applied in different fields, such as law (Gordon, 1993), car sales (Andr´e et al., 2000), intelligent tutoring (Yuan et al., 2008). However, most of them overlooked the power of personalized design and didn’t leverage deep learning techniques. Recently, Lukin et al. (2017) considered personality traits in single-turn persuasion dialogues on social and political issues. They found that personality factors can affect belief change, with conscientious, open and agreeable people being more convinced by emotional arguments. However, it’s difficult to utilize such a single-turn dataset in the design of multi-turn dialogue systems. 3 Data Collection We designed an online persuasion task to collect emerging persuasion strategies from humanhuman conversations on the Amazon Mechanical Turk platform (AMT). We utilized ParlAI (Miller et al., 2017), a python-based platform"
P19-1566,D17-2014,0,0.0429568,"ning techniques. Recently, Lukin et al. (2017) considered personality traits in single-turn persuasion dialogues on social and political issues. They found that personality factors can affect belief change, with conscientious, open and agreeable people being more convinced by emotional arguments. However, it’s difficult to utilize such a single-turn dataset in the design of multi-turn dialogue systems. 3 Data Collection We designed an online persuasion task to collect emerging persuasion strategies from humanhuman conversations on the Amazon Mechanical Turk platform (AMT). We utilized ParlAI (Miller et al., 2017), a python-based platform that enables dialogue AI research, to assist the data collection. We picked Save the Children2 as the charity to donate to, because it is one of the most well-known charity organizations around the world. Our task consisted of four parts, a pre-task survey, a persuasion dialogue, a donation confirmation and a post-task survey. Before the conversation began, we asked the participants to com5636 2 https://www.savethechildren.org/ Role ER EE ER EE ER EE ER EE ER EE ER EE ER EE ER EE ER EE Utterance Hello, are you interested in protection of rights of children? Yes, defin"
P19-1566,W16-3649,1,0.932748,"making the information personally relevant and appealing. However, two questions about personalized persuasion still remain unexplored. First, we concern about how personal information would affect persuasion outcomes. Second, we question about what strategies are more effective considering different user backgrounds and personalities. The past few years have witnessed the rapid development of conversational agents. The primary goal of these agents is to facilitate taskcompletion and human-engagement in practical contexts (Luger and Sellen, 2016; Bickmore et al., 2016; Graesser et al., 2014; Yu et al., 2016b). While persuasive technologies for behavior change have successfully leveraged other system features such as providing simulated experiences and behavior reminders (Orji and Moffatt, 2018; Fogg, 2002), the development of automated persuasive agents remains lagged due to the lack of synergy between the social scientific research on persuasion and the computational development of conversational systems. In this work, we introduced the foundation work on building an automatic personalized persuasive dialogue system. We first collected 1,017 humanhuman persuasion conversations (P ERSUASION F OR"
P19-1566,P18-1205,0,0.0611184,"forums, we present a persuasion dialogue dataset with user demographic and psychological attributes, and study personalized persuasion in a conversational setting. In the past few years, personalized dialogue systems have come to people’s attention because usertargeted personalized dialogue system is able to achieve better user engagement (Yu et al., 2016a). For instance, Shi and Yu (2018) exploited user sentiment information to make dialogue agent more user-adaptive and effective. But how to get access to user personal information is a limiting factor in personalized dialogue system design. Zhang et al. (2018) introduced a human-human chit-chat dataset with a set of 1K+ personas. In this dataset, each participant was randomly assigned a persona that consists of a few descriptive sentences. However, the brief description of user persona lacks quantitative analysis of users’ sociodemographic backgrounds and psychological characteristics, and therefore is not sufficient for interaction effect analysis between personalities and dialogue policy preference. Recent research has advanced the dialogue system design on certain negotiation tasks such as bargain on goods (He et al., 2018; Lewis et al., 2017)."
P19-1566,P18-1140,1,0.804703,"nt sequence in social media and showed promising results. Yang et al. (2019) proposed a hierarchical neural network model to identify persuasion strategies in a semi-supervised fashion. Inspired by these prior work in online forums, we present a persuasion dialogue dataset with user demographic and psychological attributes, and study personalized persuasion in a conversational setting. In the past few years, personalized dialogue systems have come to people’s attention because usertargeted personalized dialogue system is able to achieve better user engagement (Yu et al., 2016a). For instance, Shi and Yu (2018) exploited user sentiment information to make dialogue agent more user-adaptive and effective. But how to get access to user personal information is a limiting factor in personalized dialogue system design. Zhang et al. (2018) introduced a human-human chit-chat dataset with a set of 1K+ personas. In this dataset, each participant was randomly assigned a persona that consists of a few descriptive sentences. However, the brief description of user persona lacks quantitative analysis of users’ sociodemographic backgrounds and psychological characteristics, and therefore is not sufficient for inter"
P19-1566,Q17-1010,0,\N,Missing
P19-1566,W17-5102,0,\N,Missing
P19-1566,D17-1259,0,\N,Missing
P19-1566,D18-1256,0,\N,Missing
P19-1566,N19-1364,0,\N,Missing
W13-4007,W08-0105,1,0.712529,"extracted for each of the split channel recordings. The “INTERSPEECH 2010 Paralinguistic Challenge Feature Set” in the openSMILE toolkit (Schuller et al., 2012) was used as our basic acoustic feature set. For spectral features, Mel Spectrum and LSP were excluded due to the possible overlap with 3.3 Dyadic Features (DF) All of the features discussed above are low-level acoustic and visual features, extracted with 53 respect to individual participants. While individual behavior may index friendship state, we posit that patterns of interaction will be more effective. For example, prior research (Baker et al., 2008) suggests that the number and length of conversational turns (Cassell et al., 2007), presence of mutual smiles and non-mutual smiles (Prepin et al., 2012), mutual gaze and nonmutual gaze (Nakano et al., 2010), as well as posture shifting (Cassell, et al., 2001; TickleDegnen & Rosenthal, 1990), are important features to investigate in dyadic data. While other features such as gestures and mutual pitch shift may also play a role in indexing relationship state, these are not yet a part of the dyadic features we address here. 3.3.1 Number and Average Conversational Turns Length OKAO vision toolkit"
W13-4007,W07-1906,1,0.911717,"ases. In fact, Ogan et al. (2012) gave evidence that the use of playful rudeness between friends during peer tutoring correlates to greater learning. This leads to an associated challenge of spoken dialogue system development: creating systems that can develop social ties, and increase rapport with the user over repeated interactions to maximize beneficial outcomes. While little work has addressed automatic detection, some prior work has addressed the problem of emitting signals to build rapport in dialogue and agent systems (Stronks et al., 2002; Bickmore & Picard, 2005; Gratch et al., 2006; Cassell et al., 2007; Bickmore et al., 2011), and we turn to this research for what cues might be important in rapport. The majority of this prior work, however, has addressed harmony – or instant rapport – rather than rapport over time. For those systems that have addressed friendship or the growth of rapport, most commonly the number of interactions has been used as a meter of relationship progression, instigating changes in the dialogue system as the social odometer scrolls onward (Cassell & Bickmore, 2003; Vardoulakis et al., 2012). Counting the times a dyad has interacted is a crude approximation of a relati"
W13-4007,P03-1070,1,0.490091,"described above were all significantly different between friends and strangers (although gaze down was simply a trend, at p<.08). The following features were also important to the model, but did not show significance in the ANOVA, perhaps because of their sparse nature in our data. MFCC (Mel-Frequency Cepstral Coefficients) was associated with strangers and the similar audio feature of voicing was associated with friends. Both of these features have been described as approximating speech style – voicing, for example, may indicate more backchannels, such as “uh huh” and “hmm” (Ward, 2006). In Nakano et al. (2003), listener gaze at the speaker is interpreted as evidence of nonunderstanding. We found similar results whereby non-friends were more likely to engage in nonmutual gaze – looking at one another when the other person was not looking back. Mutual smile did not distinguish between friends and nonfriends, while non-mutual smile, on the other hand, provided indicative strength, in spite of its sparse nature, for friendship. This may relate to our prior work (Ogan et al., 2012) which found significant teasing and other behavior whereby friends appear comfortable enjoying themselves at the expense of"
W13-4007,W12-1603,1,0.83419,"Missing"
W15-4652,W10-4301,0,0.0240034,"ctions-giving robot. 2 Related work The critical role of gaze in coordinating turns in dialog is well known and has been previously studied (i.a., Duncan, 1972; Goodwin, 1981). Kendon (1967) found that speakers signal their wish to release the turn by gazing to the interlocutor. Vertegaal et al. (2003) found evidence that lack of eye contact decreases the efficiency of turn-taking in video conferencing. Most previous work on incremental processing in dialog has focused on the acoustic channel, including efforts on recognizing, generating, and synthesizing language incrementally. For instance, Skantze and Hjalmarsson (2010) showed that an incremental generator using filled pauses and self-corrections achieved (in a wizard of Oz experiment) shorter response times and was perceived as more efficient than a non-incremental generator. Guhe and Schilder (2002) have also used incremental generation for self-corrections. Situated and multiparty systems often incorporate attention and gaze in their models for turn taking and interaction planning (Traum and Rickel, 2002; Bohus and Horvitz, 2011). Sciutti et al. (2015) used gaze as an implicit signal for turn taking in a robotic teaching context. In an in-car navigation s"
W15-4652,W11-2013,1,\N,Missing
W16-3608,W15-4652,1,0.642075,"t al., 2014)) and asking the user to explain missing words. (Schmidt et al., 2015). In this paper, we propose a set of strategies that actively deal with both user engagement and system response appropriateness. 2 3 Related Work Many experiments have shown that an agent reacting to a user’s behavior or internal state leads to better user experience. In an in-car navigation setting, a system that reacts to the user’s cognitive load was shown to have better user experience (Kousidis et al., 2014). In a direction giving setting, a system that reacts to user’s attention was shown to be preferred (Yu et al., 2015a). In a tutoring setting, a system that reacts to the user’s disengagement resulted in better learning gain (ForbesRiley and Litman, 2012). In task-oriented systems users have a concrete reason to interact with the system. However, in a non-task-oriented setting, user engagement is the sole reason for the user to stay in the conversation, making it an ideal situation for engagement study. In this paper, we focus on making the system reactive to user engagement in real time in an everyday chatting setting. In human-human conversations, engagement has been studied extensively. Engagement is con"
W16-3608,P12-3007,0,0.019759,"Missing"
W16-3608,W12-1630,0,0.0338049,"Missing"
W16-3608,C14-1088,0,0.0189675,"xpert in a Wizard-of-Oz setting, it is the first step towards a fully automated engagement reactive system. Previously very little research addressed reactive systems due to the difficulty of modeling the users and the lack of audiovisual data. We also make the audiovisual data along with the annotations available. ily, making users have the interest to continue is critical. A lot of conversational strategies have been proposed in previous work to avoid generating incoherent utterances in non-task-oriented conversations, such as introducing topics, (e.g. “Let’s talk about favorite foods!” in (Higashinaka et al., 2014)) and asking the user to explain missing words. (Schmidt et al., 2015). In this paper, we propose a set of strategies that actively deal with both user engagement and system response appropriateness. 2 3 Related Work Many experiments have shown that an agent reacting to a user’s behavior or internal state leads to better user experience. In an in-car navigation setting, a system that reacts to the user’s cognitive load was shown to have better user experience (Kousidis et al., 2014). In a direction giving setting, a system that reacts to user’s attention was shown to be preferred (Yu et al., 2"
W16-3608,D11-1054,0,0.116176,"Missing"
W16-3649,P12-3007,0,0.00946686,"ction Non-task-oriented conversational systems do not have a stated goal to work towards. Nevertheless, they are useful for many purposes, such as keeping elderly people company and helping second language learners improve conversation and communication skills. More importantly, they can be combined with task-oriented systems to act as a transition smoother or a rapport builder for complex tasks that require user cooperation. There are a variety of methods to generate responses for nontask-oriented systems, such as machine translation (Ritter et al., 2011), retrieval-based response selection (Banchs and Li, 2012), and sequence-tosequence recurrent neural network (Vinyals and Le, 2015). However, these systems still produce utterances that are incoherent or inappropriate from time to time. To tackle this problem, we propose a set of conversational strategies, such as switching topics, to avoid possible inappropriate responses (breakdowns). After we have a set of strategies, which strategy to perform according to Reinforcement learning was introduced to the dialog community two decades ago (Biermann and Long, 1996) and has mainly been used in task-oriented systems (Singh et al., 1999). Researchers have p"
W16-3649,C14-1088,0,0.0167215,"omputable. Perplexity of the language model is an automatically computable metric but is hard to interpret (Vinyals and Le, 2015). In this paper, we propose three metrics: turn-level appropriateness, conversational depth and information gain, which access both the local and the global conversation quality of a non-task-oriented conversation. Information Related Work Many generic conversational strategies have been proposed in previous work to avoid generating incoherent utterances in non-task-oriented conversations, such as introducing new topics (e.g. “Let’s talk about favorite foods!” ) in (Higashinaka et al., 2014), asking the user to explain missing words (e.g. “What is SIGDIAL?”) (Maria Schmidt and Waibel, 2015). In this paper, we propose a set of generic strategies that are inspired by previous work, and test their usability on human users. No researcher has investigated thoroughly on which strategy to use in different conversational contexts. Compared to task-oriented dialog systems, non1 www.cmuticktock.org 405 when the posterior probability of the generated response is higher than a certain threshold. gain is automatically quantifiable. We use supervised machine learning methods to built automatic"
W16-3649,P98-2219,0,0.189651,"ign a dialog system that takes actions to maximize some measure of system reward, such as task completion rate or dialog length. The difficulty of such modeling lies in the state representation. Representing the dialog by the entire history is often neither feasible nor 404 Proceedings of the SIGDIAL 2016 Conference, pages 404–412, c Los Angeles, USA, 13-15 September 2016. 2016 Association for Computational Linguistics conceptually useful, and the so-called belief state approach is not possible, since we do not even know what features are required to represent the belief state. Previous work (Walker et al., 1998) has largely dealt with this issue by imposing prior limitations on the features used to represent the approximate state. In this paper, instead of focusing on task-oriented systems, we apply reinforcement learning to design a policy to select designed conversation strategies in a non-task-oriented dialog systems. Unlike task-oriented dialog systems, non-task-oriented systems have no specific goal that guides the interaction. Consequently, evaluation metrics that are traditionally used for reward design, such as task completion rate, are no longer appropriate. The state design in reinforcement"
W16-3649,W10-4339,0,0.0220514,"e more varied conversation history, which are thus harder to formulate as a mathematical problem. In this work, we propose a method to use statistical findings in conversational study to constrain the dialog history space and to use reinforcement learning for statistical policy learning in a non-task-oriented conversation setting. To date, reinforcement learning is mainly used for learning dialogue policies for slot-filling taskoriented applications such as bus information search (Lee and Eskenazi, 2012), restaurant recommendations (Jurˇc´ıcˇ ek et al., 2012), and sightseeing recommendations (Misu et al., 2010). Reinforcement learning is also used for some more complex systems, such as learning negotiation policies (Georgila and Traum, 2011) and tutoring (Chi et al., 2011). Reinforcement learning is also used in question-answering systems (Misu et al., 2012). Question-answering systems are very similar to non-task-oriented systems except that they do not consider dialog context in generating responses. They have pre-existing questions that the user is expected to go through, which limits the content space of the dialog. Reinforcement learning has also been applied to a non-task-oriented system for d"
W16-3649,W12-1611,0,0.0134265,"ing for statistical policy learning in a non-task-oriented conversation setting. To date, reinforcement learning is mainly used for learning dialogue policies for slot-filling taskoriented applications such as bus information search (Lee and Eskenazi, 2012), restaurant recommendations (Jurˇc´ıcˇ ek et al., 2012), and sightseeing recommendations (Misu et al., 2010). Reinforcement learning is also used for some more complex systems, such as learning negotiation policies (Georgila and Traum, 2011) and tutoring (Chi et al., 2011). Reinforcement learning is also used in question-answering systems (Misu et al., 2012). Question-answering systems are very similar to non-task-oriented systems except that they do not consider dialog context in generating responses. They have pre-existing questions that the user is expected to go through, which limits the content space of the dialog. Reinforcement learning has also been applied to a non-task-oriented system for deciding which sub-system to choose to generate a system utterance (Shibata et al., 2014). In this paper, we used reinforcement learning to learn a policy to sequentially decide which conversational strategy to use to avoid possible system breakdowns. T"
W16-3649,D11-1054,0,0.00767479,"he local and global quality of the conversation. 1 Introduction Non-task-oriented conversational systems do not have a stated goal to work towards. Nevertheless, they are useful for many purposes, such as keeping elderly people company and helping second language learners improve conversation and communication skills. More importantly, they can be combined with task-oriented systems to act as a transition smoother or a rapport builder for complex tasks that require user cooperation. There are a variety of methods to generate responses for nontask-oriented systems, such as machine translation (Ritter et al., 2011), retrieval-based response selection (Banchs and Li, 2012), and sequence-tosequence recurrent neural network (Vinyals and Le, 2015). However, these systems still produce utterances that are incoherent or inappropriate from time to time. To tackle this problem, we propose a set of conversational strategies, such as switching topics, to avoid possible inappropriate responses (breakdowns). After we have a set of strategies, which strategy to perform according to Reinforcement learning was introduced to the dialog community two decades ago (Biermann and Long, 1996) and has mainly been used in task"
W18-5015,W17-5512,0,0.148758,"ace. Specifically, the DRRN takes both the state and natural language actions as inputs and computes a Q-value for each state action pair. Thus, we use a DRRN as our question selection policy to approximate the value function for any question candidate. Our work is also related to hierarchical reinforcement learning (HRL) which often decomposes the problem into several sub-problems and achieves better learning convergence rate and generalization compared to flat RL (Sutton et al., 1999; Dietterich, 2000). HRL has been applied to dialog management (Lemon et al., 2006; Cuay´ahuitl et al., 2010; Budzianowski et al., 2017) which decomposes the dialog policy with respect to system goals or domains. When the system enters a sub-task, the selected dialog policy will be used and continue to operate until the subproblem is solved, however the terminate condition for a subproblem has to be predefined. Different from prior work, our proposed architecture uses hierarchical dialog policy to combine two RL architectures within a control flow, i.e., DQN and DRRN, in order to jointly learn multimodal dialog state representation and dialog policy. Note that our HRL framework resembles the FRL hierarchy (Dayan and Hinton, 19"
W18-5015,W17-5539,0,0.119633,"sDial (Das et al., 2017a) situates an answer-bot (A-Bot) to answer questions from a question-bot (Q-Bot) about an image. Das et al. (2017b) applied reinforcement learning (RL) to the VisDial task to learn the policies for the Q/A-Bots to collaboratively rank the correct image among a set of candidates. However, their Q-Bot can only ask questions and cannot make guesses. Chattopadhyay et al. (2017) further evaluated the pre-trained A-bot in a similar setting to answer human generated questions. Since humans are tasked to ask questions, the policy learning of QBot is not investigated. Finally, (Manuvinakurike et al., 2017) proposed a incremental dialogue policy learning method for image guessing. However, their dialog state only used language information and did not include visual information. We build upon prior works and propose a framework that learns an optimal dialog policy for the Q-Bot to perform both question selection and image guessing through exploiting multimodal information. 2.2 Reinforcement Learning RL is a popular approach to learn an optimal dialog policy for task-oriented dialog systems (Singh et al., 2002; Williams and Young, 2007; Georgila and Traum, 2011; Lee and Eskenazi, 2012; Yu et al.,"
W18-5015,I17-1047,0,0.0322048,"discrete action space and has been shown to be effective in dialog systems, especially for large domain dialog management(Casanueva et al., 2018). Besides, we propose a new technique called state adaptation in order to make the multimodal dialog state more aware of the constantly changing visual context. We demonstrate the efficacy of this technique through ablation analysis. 2 2.1 Related Work Visual Dialog Visual dialog requires the agent to hold a multiturn conversation about visual content. Several visual dialog tasks have been developed, including image grounded conversation generation (Mostafazadeh et al., 2017). Guess What?! (De Vries et al., 2017) involves locating visual objects using dialogs. VisDial (Das et al., 2017a) situates an answer-bot (A-Bot) to answer questions from a question-bot (Q-Bot) about an image. Das et al. (2017b) applied reinforcement learning (RL) to the VisDial task to learn the policies for the Q/A-Bots to collaboratively rank the correct image among a set of candidates. However, their Q-Bot can only ask questions and cannot make guesses. Chattopadhyay et al. (2017) further evaluated the pre-trained A-bot in a similar setting to answer human generated questions. Since humans"
W18-5015,P16-1170,0,0.0279487,"The framework jointly learns the multimodal dialog state representation and the hierarchical dialog policy to improve both dialog task success and efficiency. We also propose a new technique, state adaptation, to integrate context awareness in the dialog state representation. We evaluate the proposed framework and the state adaptation technique in an image guessing game and achieve promising results. 1 Introduction The interplay between vision and language has created a range of interesting applications, including image captioning (Karpathy and FeiFei, 2015), visual question generation (VQG) (Mostafazadeh et al., 2016), visual question answering (VQA) (Antol et al., 2015), and reference expressions (Hu et al., 2016). Visual dialog (Das et al., 2017b) extends the VQA problem to multi-turn visual-grounded conversations without specific goals. In this paper, we study the task-oriented visual dialog setting that requires the agent to learn the multimodal representation and dialog policy for decision making. We argue that a task-oriented visual intelligent conversational sys140 Proceedings of the SIGDIAL 2018 Conference, pages 140–150, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational L"
W18-5015,P17-2036,0,0.0271684,"lized as the average of image vectors and updated as follows: αr,t,i = sigmoid(VBr,t · Ir,i ) P20 αr,t,i Ir,i VCr,t = i=1 P20 i=1 αi Hierarchical Policy Learning (3) (4) where r, t and i refer to episode, dialog turn and image index. The V C is then adjusted based on the attention scores (see equation 4). The attention scores calculated by dot product in the equation 3 represent the affinity between the current vision belief state and each image vector. In the case of wrong guesses (informed by the simulator), we set the attention score for that wrong image to zero. This method is inspired by Tian et al. (2017) who explicitly weights context vectors by context-query relevance for encoding dialog context. The question selection sub-task also takes the 143 4.1 within this flat RL framework. We suspect this is due to the sample efficiency problem with large multimodal action space for which the question action or guess action typically results in different reward signals. Therefore, we did not compare our proposed method against a flat RL model. Rewards: The reward function is decomposed as R = RG + RQ + RI where RG means the final game reward(win/loss= ±10), RI refers to wrong guess penalty (-3). We d"
W18-5015,H89-1033,0,0.686097,"asks efficiently. The framework we propose takes inspiration from feudal reinforcement learning (FRL) (Dayan and Hinton, 1993), where levels of hierarchy within an agent communicate via explicit goals in a topdown fashion. In our case, it decomposes the decision into two steps: a first step where a master policy selects between verbal task (information query) and vision task (image retrieval), and a second step where a primitive action (question or imCreating an intelligent conversational system that understands vision and language is one of the ultimate goals in Artificial Intelligence (AI) (Winograd, 1972). Extensive research has focused on vision-tolanguage generation, however, limited research has touched on combining these two modalities in a goal-driven dialog context. We propose a multimodal hierarchical reinforcement learning framework that dynamically integrates vision and language for task-oriented visual dialog. The framework jointly learns the multimodal dialog state representation and the hierarchical dialog policy to improve both dialog task success and efficiency. We also propose a new technique, state adaptation, to integrate context awareness in the dialog state representation. W"
W18-5015,W16-3601,1,0.840483,", 2016). Visual dialog (Das et al., 2017b) extends the VQA problem to multi-turn visual-grounded conversations without specific goals. In this paper, we study the task-oriented visual dialog setting that requires the agent to learn the multimodal representation and dialog policy for decision making. We argue that a task-oriented visual intelligent conversational sys140 Proceedings of the SIGDIAL 2018 Conference, pages 140–150, c Melbourne, Australia, 12-14 July 2018. 2018 Association for Computational Linguistics learn the dialog state tracking and policy optimization in an end-to-end manner (Zhao and Eskenazi, 2016). In our framework, we use a DQN to learn the higher level policy for question selection or image guessing. Van Hasselt et al. (2016) proposed a double DQN to overcome the overestimation problem in the Q-Learning and Schaul et al. (2015) suggested prioritized experience replay to improve the data sampling efficiency for training DQN. We apply both techniques in our implementation. One limitation of DQNs is that they cannot handle unbounded action space, which is often the case for natural language interaction. He et al. (2015) proposed Deep Reinforcement Relevance Network (DRRN) that can handl"
W19-5935,P17-1120,0,0.027183,"rater in the conversation—as active participant or external listener—is an important factor in assessing social dialogs. 1 Introduction Dialog systems, despite recent improvements, still face a fundamental issue of how to convey interest and emotion via text to speech (TTS) synthesis. Many TTS voices have been described as “robotic” or “monotonous” by human listeners (Baker, 2015), an issue further exacerbated for generation of longer utterances (Németh et al., 2007). This is particularly relevant for non-taskoriented dialog systems, such as those that aim to engage users in social chitchat (Akasaki & Kaji, 2017; Liu et al., 2017); for example, Tokuhisa & Terashima (2009) found that affective (i.e., emotion conveying) productions relate to 293 Proceedings of the SIGDial 2019 Conference, pages 293–306 c Stockholm, Sweden, 11-13 September 2019. 2019 Association for Computational Linguistics 2016); that is, users may not be interacting with real intents. For one, the presence of an experimenter could impact the way users interact with the system (cf. Orne, 1962). This is also true for dialog systems; users may be less comfortable to engage in more naturalistic conversation, or may be more willing to acc"
W19-5935,W10-4318,0,0.114083,"ller words, both in terms of their context as well as their acoustic adjustments using Speech Synthesis Markup Language (SSML). Furthermore, no prior experiments have parametrically tested the presence of these two elements in controlled studies; doing so allows us to test whether there is a cumulative effect of these cognitive-emotional insertions. Finally, conducting an experiment directly through the Alexa system is an innovative approach that builds on past work that has largely relied on naturalness ratings of synthetic voices with no interactive component for the rater themselves (e.g., Marge et al., 2010; Gálvez et al., 2017; Hennig & Chellali, 2012; Schmitz et al., 2007). This study can serve as a test to the ‘Computers are Social Actors’ theoretical framework (CASA: Nass et al., 1994; Nass & Moon, 2000) that proposes that humans apply social norms from human-human interaction to computers when they detect a cue of humanity in the system. One empirical question for the CASA framework is what cues can trigger computer personification and to what extent this personification graded; that is, do we see cumulative effects of introducing multiple human-like features in a dialog system, or do liste"
W19-5935,W16-3608,1,0.897012,"Missing"
