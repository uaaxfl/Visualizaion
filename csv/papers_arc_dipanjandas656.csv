2021.gem-1.10,"The {GEM} Benchmark: Natural Language Generation, its Evaluation and Metrics",2021,-1,-1,9,0.888889,6246,sebastian gehrmann,"Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",0,"We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics. This disconnect makes it challenging to identify the limitations of current models and opportunities for progress. Addressing this limitation, GEM provides an environment in which models can easily be applied to a wide set of tasks and in which evaluation strategies can be tested. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop."
2021.acl-long.58,Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features,2021,-1,-1,4,0,12776,hannah rashkin,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Knowledge-grounded dialogue systems are intended to convey information that is based on evidence provided in a given source text. We discuss the challenges of training a generative neural dialogue model for such systems that is controlled to stay faithful to the evidence. Existing datasets contain a mix of conversational responses that are faithful to selected evidence as well as more subjective or chit-chat style responses. We propose different evaluation measures to disentangle these different styles of responses by quantifying the informativeness and objectivity. At training time, additional inputs based on these evaluation measures are given to the dialogue model. At generation time, these additional inputs act as stylistic controls that encourage the model to generate responses that are faithful to the provided evidence. We also investigate the usage of additional controls at decoding time using resampling techniques. In addition to automatic metrics, we perform a human evaluation study where raters judge the output of these controlled generation models to be generally more objective and faithful to the evidence compared to baseline dialogue systems."
2020.wmt-1.102,Learning to Evaluate Translation Beyond {E}nglish: {BLEURT} Submissions to the {WMT} Metrics 2020 Shared Task,2020,-1,-1,7,0,6268,thibault sellam,Proceedings of the Fifth Conference on Machine Translation,0,"The quality of machine translation systems has dramatically improved over the last decade, and as a result, evaluation has become an increasingly challenging problem. This paper describes our contribution to the WMT 2020 Metrics Shared Task, the main benchmark for automatic evaluation of translation. We make several submissions based on BLEURT, a previously published which uses transfer learning. We extend the metric beyond English and evaluate it on 14 language pairs for which fine-tuning data is available, as well as 4 {``}zero-shot{''} language pairs, for which we have no labelled examples. Additionally, we focus on English to German and demonstrate how to combine BLEURT{'}s predictions with those of YiSi and use alternative reference translations to enhance the performance. Empirical results show that the models achieve competitive results on the WMT Metrics 2019 Shared Task, indicating their promise for the 2020 edition."
2020.emnlp-main.89,{ToTTo}: A Controlled Table-To-Text Generation Dataset,2020,45,1,7,1,3512,ankur parikh,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"We present ToTTo, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description. To obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from Wikipedia. We present systematic analyses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation."
2020.acl-main.212,Syntactic Data Augmentation Increases Robustness to Inference Heuristics,2020,29,2,3,0,22221,junghyun min,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Pretrained neural models such as BERT, when fine-tuned to perform natural language inference (NLI), often show high accuracy on standard datasets, but display a surprising lack of sensitivity to word order on controlled challenge sets. We hypothesize that this issue is not primarily caused by the pretrained model{'}s limitations, but rather by the paucity of crowdsourced NLI examples that might convey the importance of syntactic structure at the fine-tuning stage. We explore several methods to augment standard training sets with syntactically informative examples, generated by applying syntactic transformations to sentences from the MNLI corpus. The best-performing augmentation method, subject/object inversion, improved BERT{'}s accuracy on controlled examples that diagnose sensitivity to word order from 0.28 to 0.73, without affecting performance on the MNLI test set. This improvement generalized beyond the particular construction used for data augmentation, suggesting that augmentation causes BERT to recruit abstract syntactic representations."
2020.acl-main.704,{BLEURT}: Learning Robust Metrics for Text Generation,2020,48,1,2,0,6268,thibault sellam,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgment. We propose BLEURT, a learned evaluation metric for English based on BERT. BLEURT can model human judgment with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG data set. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution."
P19-1452,{BERT} Rediscovers the Classical {NLP} Pipeline,2019,0,81,2,0.666667,19975,ian tenney,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations."
P19-1483,Handling Divergent Reference Texts when Evaluating Table-to-Text Generation,2019,40,1,5,0,3309,bhuwan dhingra,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Automatically constructed datasets for generating text from semi-structured data (tables), such as WikiBio, often contain reference texts that diverge from the information in the corresponding semi-structured data. We show that metrics which rely solely on the reference texts, such as BLEU and ROUGE, show poor correlation with human judgments when those references diverge. We propose a new metric, PARENT, which aligns n-grams from the reference and generated texts to the semi-structured data before computing their precision and recall. Through a large scale human evaluation study of table-to-text models for WikiBio, we show that PARENT correlates with human judgments better than existing text generation metrics. We also adapt and evaluate the information extraction based evaluation proposed by Wiseman et al (2017), and show that PARENT has comparable correlation to it, while being easier to use. We show that PARENT is also applicable when the reference texts are elicited from humans using the data from the WebNLG challenge."
N19-1263,Text Generation with Exemplar-based Adaptive Decoding,2019,0,5,5,0,4025,hao peng,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We propose a novel conditioned text generation model. It draws inspiration from traditional template-based text generation techniques, where the source provides the content (i.e., what to say), and the template influences how to say it. Building on the successful encoder-decoder paradigm, it first encodes the content representation from the given input text; to produce the output, it retrieves exemplar text from the training data as {``}soft templates,{''} which are then used to construct an exemplar-specific decoder. We evaluate the proposed model on abstractive text summarization and data-to-text generation. Empirical results show that this model achieves strong performance and outperforms comparable baselines."
D18-1028,{W}iki{A}tomic{E}dits: A Multilingual Corpus of {W}ikipedia Edits for Modeling Language and Discourse,2018,36,4,4,0.457299,8204,manaal faruqui,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We release a corpus of 43 million atomic edits across 8 languages. These edits are mined from Wikipedia edit history and consist of instances in which a human editor has inserted a single contiguous phrase into, or deleted a single contiguous phrase from, an existing sentence. We use the collected data to show that the language generated during editing differs from the language that we observe in standard corpora, and that models trained on edits encode different aspects of semantics and discourse than models trained on raw text. We release the full corpus as a resource to aid ongoing research in semantics, discourse, and representation learning."
D18-1080,Learning To Split and Rephrase From {W}ikipedia Edit History,2018,14,1,5,0,10226,jan botha,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Split and rephrase is the task of breaking down a sentence into shorter ones that together convey the same meaning. We extract a rich new dataset for this task by mining Wikipedia{'}s edit history: WikiSplit contains one million naturally occurring sentence rewrites, providing sixty times more distinct split examples and a ninety times larger vocabulary than the WebSplit corpus introduced by Narayan et al. (2017) as a benchmark for this task. Incorporating WikiSplit as training data produces a model with qualitatively better predictions that score 32 BLEU points above the prior best result on the WebSplit benchmark."
D18-1091,Identifying Well-formed Natural Language Questions,2018,0,4,2,0.457299,8204,manaal faruqui,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Understanding search queries is a hard problem as it involves dealing with {``}word salad{''} text ubiquitously issued by users. However, if a query resembles a well-formed question, a natural language processing pipeline is able to perform more accurate interpretation, thus reducing downstream compounding errors. Hence, identifying whether or not a query is well formed can enhance query understanding. Here, we introduce a new task of identifying a well-formed natural language question. We construct and release a dataset of 25,100 publicly available questions classified into well-formed and non-wellformed categories and report an accuracy of 70.7{\%} on the test set. We also show that our classifier can be used to improve the performance of neural sequence-to-sequence models for generating questions for reading comprehension."
W17-4121,Neural Paraphrase Identification of Questions with Noisy Pretraining,2017,0,15,5,0,12777,gaurav tomar,Proceedings of the First Workshop on Subword and Character Level Models in {NLP},0,"We present a solution to the problem of paraphrase identification of questions. We focus on a recent dataset of question pairs annotated with binary paraphrase labels and show that a variant of the decomposable attention model (replacing the word embeddings of the decomposable attention model of Parikh et al. 2016 with character n-gram representations) results in accurate performance on this task, while being far simpler than many competing neural architectures. Furthermore, when the model is pretrained on a noisy dataset of automatically collected question paraphrases, it obtains the best reported performance on the dataset."
Q16-1010,Transforming Dependency Structures to Logical Forms for Semantic Parsing,2016,68,58,5,0,3549,siva reddy,Transactions of the Association for Computational Linguistics,0,"The strongly typed syntax of grammar formalisms such as CCG, TAG, LFG and HPSG offers a synchronous framework for deriving syntactic structures and semantic logical forms. In contrast{---}partly due to the lack of a strong type system{---}dependency structures are easy to annotate and have become a widely used form of syntactic analysis for many languages. However, the lack of a type system makes a formal mechanism for deriving logical forms from dependency structures challenging. We address this by introducing a robust system based on the lambda calculus for deriving neo-Davidsonian logical forms from dependency trees. These logical forms are then used for semantic parsing of natural language to Freebase. Experiments on the Free917 and Web-Questions datasets show that our representation is superior to the original dependency trees and that it outperforms a CCG-based representation on this task. Compared to prior work, we obtain the strongest result to date on Free917 and competitive results on WebQuestions."
D16-1244,A Decomposable Attention Model for Natural Language Inference,2016,23,403,3,1,3512,ankur parikh,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
Q15-1003,Efficient Inference and Structured Learning for Semantic Role Labeling,2015,35,41,3,1,31725,oscar tackstrom,Transactions of the Association for Computational Linguistics,0,"We present a dynamic programming algorithm for efficient constrained inference in semantic role labeling. The algorithm tractably captures a majority of the structural constraints examined by prior work in this area, which has resorted to either approximate methods or off-the-shelf integer linear programming solvers. In addition, it allows training a globally-normalized log-linear model with respect to constrained conditional likelihood. We show that the dynamic program is several times faster than an off-the-shelf integer linear programming solver, while reaching the same solution. Furthermore, we show that our structured model results in significant improvements over its local counterpart, achieving state-of-the-art results on both PropBank- and FrameNet-annotated corpora."
D15-1112,Semantic Role Labeling with Neural Network Factors,2015,42,48,4,0,12526,nicholas fitzgerald,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We present a new method for semantic role labeling in which arguments and semantic roles are jointly embedded in a shared vector space for a given predicate. These embeddings belong to a neural network, whose output represents the potential functions of a graphical model designed for the SRL task. We consider both local and structured learning methods and obtain strong results on standard PropBank and FrameNet corpora with a straightforward product-of-experts model. We further show how the model can learn jointly from PropBank and FrameNet annotations to obtain additional improvements on the smaller FrameNet dataset."
W14-3007,Statistical Models for Frame-Semantic Parsing,2014,26,2,1,1,6251,dipanjan das,Proceedings of Frame Semantics in {NLP}: A Workshop in Honor of Chuck {F}illmore (1929-2014),0,"We present a brief history and overview of statistical methods in frame-semantic parsing xe2x80x93 the automatic analysis of text using the theory of frame semantics. We discuss how the FrameNet lexicon and frameannotated datasets have been used by statistical NLP researchers to build usable, state-of-the-art systems. We also focus on future directions in frame-semantic parsing research, and discuss NLP applications that could benefit from this line of work. 1 Frame-Semantic Parsing Frame-semantic parsing has been considered as the task of automatically finding semantically salient targets in text, disambiguating their semantic frame representing an event and scenario in discourse, and annotating arguments consisting of words or phrases in text with various frame elements (or roles). The FrameNet lexicon (Baker et al., 1998), an ontology inspired by the theory of frame semantics (Fillmore, 1982), serves as a repository of semantic frames and their roles. Figure 1 depicts a sentence with three evoked frames for the targets xe2x80x9cmillionxe2x80x9d, xe2x80x9ccreatedxe2x80x9d and xe2x80x9cpushedxe2x80x9d with FrameNet frames and roles. Automatic analysis of text using framesemantic structures can be traced back to the pioneering work of Gildea and Jurafsky (2002). Although their experimental setup relied on a primitive version of FrameNet and only made use of xe2x80x9cexemplarsxe2x80x9d or example usages of semantic frames (containing one target per sentence) as opposed to a xe2x80x9ccorpusxe2x80x9d of sentences, it resulted in a flurry of work in the area of automatic semantic role labeling (Marquez et al., 2008). However, the focus of semantic role labeling (SRL) research has mostly been on PropBank (Palmer et al., 2005) conventions, where verbal targets could evoke a xe2x80x9csensexe2x80x9d frame, which is not shared across targets, making the frame disambiguation setup different from the representation in FrameNet. Furthermore, it is fair to say that early research on PropBank focused primarily on argument structure prediction, and the interaction between frame and argument structure analysis has mostly been unaddressed (Marquez et al., 2008). There are exceptions, where the verb frame has been taken into account during SRL (Meza-Ruiz and Riedel, 2009; Watanabe et al., 2010). Moreoever, the CoNLL 2008 and 2009 shared tasks also include the verb and noun frame identification task in their evaluations, although the overall goal was to predict semantic dependencies based on PropBank, and not full argument spans (Surdeanu et al., 2008; Hajic et al., 2009). The SemEval 2007 shared task (Baker et al., 2007) attempted to revisit the frame-semantic analysis task based on FrameNet. It introduced a larger FrameNet lexicon (version 1.3), and also a larger corpus with full-text annotations compared to prior work, with multiple targets annotated per sentence. The corpus allowed words and phrases with noun, verb, adjective, adverb, number, determiner, conjunction and preposition syntactic categories to serve as targets and evoke frames, unlike any other single dataset; it also allowed targets from different syntactic categories share frames, and therefore roles. The repository of semantic role types was also much richer than PropBankstyle lexicons, numbering in several hundreds. Most systems participating in the task resorted to a cascade of classifiers and rule-based modules: identifying targets (a non-trivial subtask), disambiguating frames, identifying potential arguments, and then labeling them with roles. The system described by Johansson and Nugues (2007) performed the best in this shared task. Next, we focus on its performance, and subsequent improvements made by the research community on this task."
P14-5020,Enhanced Search with Wildcards and Morphological Inflections in the {G}oogle {B}ooks Ngram Viewer,2014,8,7,4,0,39113,jason mann,Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We present a new version of the Google Books Ngram Viewer, which plots the frequency of words and phrases over the last five centuries; its data encompasses 6% of the worldxe2x80x99s published books. The new Viewer adds three features for more powerful search: wildcards, morphological inflections, and capitalization. These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text."
P14-1136,Semantic Frame Identification with Distributed Word Representations,2014,30,55,2,0,28945,karl hermann,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"A computer-implemented technique can include receiving, at a server, labeled training data including a plurality of groups of words, each group of words having a predicate word, each word having generic word embeddings. The technique can include extracting, at the server, the plurality of groups of words in a syntactic context of their predicate words. The technique can include concatenating, at the server, the generic word embeddings to create a high dimensional vector space representing features for each word. The technique can include obtaining, at the server, a model having a learned mapping from the high dimensional vector space to a low dimensional vector space and learned embeddings for each possible semantic frame in the low dimensional vector space. The technique can also include outputting, by the server, the model for storage, the model being configured to identify a specific semantic frame for an input."
J14-1002,Frame-Semantic Parsing,2014,101,152,1,1,6251,dipanjan das,Computational Linguistics,0,"Frame semantics is a linguistic theory that has been instantiated for English in the FrameNet lexicon. We solve the problem of frame-semantic parsing using a two-stage statistical model that takes lexical targets i.e., content words and phrases in their sentential contexts and predicts frame-semantic structures. Given a target in context, the first stage disambiguates it to a semantic frame. This model uses latent variables and semi-supervised learning to improve frame disambiguation for targets unseen at training time. The second stage finds the target's locally expressed semantic arguments. At inference time, a fast exact dual decomposition algorithm collectively predicts all the arguments of a frame at once in order to respect declaratively stated linguistic constraints, resulting in qualitatively better structures than nave local predictors. Both components are feature-based and discriminatively trained on a small set of annotated frame-semantic parses. On the SemEval 2007 benchmark data set, the approach, along with a heuristic identifier of frame-evoking targets, outperforms the prior state of the art by significant margins. Additionally, we present experiments on the much larger FrameNet 1.5 data set. We have released our frame-semantic parser as open-source software."
D14-1134,Learning Compact Lexicons for {CCG} Semantic Parsing,2014,31,33,2,0,6799,yoav artzi,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser. Existing methods incrementally expand the lexicon by greedily adding entries, considering a single training datapoint at a time. We propose using corpus-level statistics for lexicon learning decisions. We introduce voting to globally consider adding entries to the lexicon, and pruning to remove entries no longer required to explain the training data. Our methods result in state-of-the-art performance on the task of executing sequences of natural language instructions, achieving up to 25% error reduction, with lexicons that are up to 70% smaller and are qualitatively less noisy."
Q13-1001,Token and Type Constraints for Cross-Lingual Part-of-Speech Tagging,2013,28,114,2,1,31725,oscar tackstrom,Transactions of the Association for Computational Linguistics,0,"We consider the construction of part-of-speech taggers for resource-poor languages. Recently, manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext have been used as type constraints to overcome the scarcity of annotated data in this setting. In this paper, we show that additional token constraints can be projected from a resource-rich source language to a resource-poor target language via word-aligned bitext. We present several models to this end; in particular a partially observed conditional random field model, where coupled token and type constraints provide a partial signal for training. Averaged across eight previously studied Indo-European languages, our model achieves a 25{\%} relative error reduction over the prior state of the art. We further present successful results on seven additional languages from different families, empirically demonstrating the applicability of coupled token and type constraints across a diverse set of languages."
P13-2017,{U}niversal {D}ependency Annotation for Multilingual Parsing,2013,31,151,5,0,10634,ryan mcdonald,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages: German, English, Swedish, Spanish, French and Korean. To show the usefulness of such a resource, we present a case study of crosslingual transfer parsing with more reliable evaluation than has been possible before. This xe2x80x98universalxe2x80x99 treebank is made freely available in order to facilitate research on multilingual dependency parsing. 1"
D13-1205,Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization,2013,63,21,2,0.864548,30689,kuzman ganchev,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"A computer-implemented method can include obtaining (i) an aligned bi-text for a source language and a target language, and (ii) a supervised sequence model for the source language. The method can include labeling a source side of the aligned bi-text using the supervised sequence model and projecting labels from the labeled source side to a target side of the aligned bi-text to obtain a labeled target side of the aligned bi-text. The method can include filtering the labeled target side based on a task of a natural language processing (NLP) system configured to utilize a sequence model for the target language to obtain a filtered target side of the aligned bi-text. The method can also include training the sequence model for the target language using posterior regularization with soft constraints on the filtered target side to obtain a trained sequence model for the target language."
S12-1029,An Exact Dual Decomposition Algorithm for Shallow Semantic Parsing with Constraints,2012,28,47,1,1,6251,dipanjan das,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We present a novel technique for jointly predicting semantic arguments for lexical predicates. The task is to find the best matching between semantic roles and sentential spans, subject to structural constraints that come from expert linguistic knowledge (e.g., in the FrameNet lexicon). We formulate this task as an integer linear program (ILP); instead of using an off-the-shelf tool to solve the ILP, we employ a dual decomposition algorithm, which we adapt for exact decoding via a branch-and-bound technique. Compared to a baseline that makes local predictions, we achieve better argument identification scores and avoid all structural violations. Runtime is nine times faster than a proprietary ILP solver."
N12-1086,Graph-Based Lexicon Expansion with Sparsity-Inducing Penalties,2012,38,36,1,1,6251,dipanjan das,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present novel methods to construct compact natural language lexicons within a graph-based semi-supervised learning framework, an attractive platform suited for propagating soft labels onto new natural language types from seed data. To achieve compactness, we induce sparse measures at graph vertices by incorporating sparsity-inducing penalties in Gaussian and entropic pairwise Markov networks constructed from labeled and unlabeled data. Sparse measures are desirable for high-dimensional multi-class learning problems such as the induction of labels on natural language types, which typically associate with only a few labels. Compared to standard graph-based learning methods, for two lexicon expansion problems, our approach produces significantly smaller lexicons and obtains better predictive performance."
petrov-etal-2012-universal,A Universal Part-of-Speech Tagset,2012,46,418,2,0,25419,slav petrov,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-of-speech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts-of-speech for 22 different languages. We highlight the use of this resource via three experiments, that (1) compare tagging accuracies across languages, (2) present an unsupervised grammar induction approach that does not use gold standard part-of-speech tags, and (3) use the universal tags to transfer dependency parsers between languages, achieving state-of-the-art results."
P11-2008,"Part-of-Speech Tagging for {T}witter: Annotation, Features, and Experiments",2011,15,673,4,0.571429,4023,kevin gimpel,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"We address the problem of part-of-speech tagging for English data from the popular micro-blogging service Twitter. We develop a tagset, annotate data, develop features, and report tagging results nearing 90% accuracy. The data and tools have been made available to the research community with the goal of enabling richer text analysis of Twitter and related social media data sets."
P11-1061,Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections,2011,26,187,1,1,6251,dipanjan das,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg-Kirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm."
P11-1144,Semi-Supervised Frame-Semantic Parsing for Unknown Predicates,2011,34,54,1,1,6251,dipanjan das,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We describe a new approach to disambiguating semantic frames evoked by lexical predicates previously unseen in a lexicon or annotated data. Our approach makes use of large amounts of unlabeled data in a graph-based semi-supervised learning framework. We construct a large graph where vertices correspond to potential predicates and use label propagation to learn possible semantic frames for new ones. The label-propagated graph is used within a frame-semantic parser and, for unknown predicates, results in over 15% absolute improvement in frame identification accuracy and over 13% absolute improvement in full frame-semantic parsing F1 score on a blind test set, over a state-of-the-art supervised baseline."
D11-1005,Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance,2011,34,53,2,0,3318,shay cohen,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages. Our approach is based on a model that locally mixes between supervised models from the helper languages. Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable. We obtain state-of-the-art performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing."
W10-2925,Distributed Asynchronous Online Learning for Natural Language Processing,2010,31,31,2,0.571429,4023,kevin gimpel,Proceedings of the Fourteenth Conference on Computational Natural Language Learning,0,"Recent speed-ups for training large-scale models like those found in statistical NLP exploit distributed computing (either on multicore or cloud architectures) and rapidly converging online learning algorithms. Here we aim to combine the two. We focus on distributed, mini-batch learners that make frequent updates asynchronously (Nedic et al., 2001; Langford et al., 2009). We generalize existing asynchronous algorithms and experiment extensively with structured prediction problems from NLP, including discriminative, unsupervised, and non-convex learning scenarios. Our results show asynchronous learning can provide substantial speedups compared to distributed and single-processor mini-batch algorithms with no signs of error arising from the approximate nature of the technique."
S10-1059,{SEMAFOR}: Frame Argument Resolution with Log-Linear Models,2010,7,40,3,0,39978,desai chen,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This paper describes the SEMAFOR system's performance in the SemEval 2010 task on linking events and their participants in discourse. Our entry is based upon SEMAFOR 1.0 (Das et al., 2010a), a frame-semantic probabilistic parser built from log-linear models. The extended system models null instantiations, including non-local argument reference. Performance is evaluated on the task data with and without gold-standard overt arguments. In both settings, it fares the best of the submitted systems with respect to recall and F1."
N10-1038,Movie Reviews and Revenues: An Experiment in Text Regression,2010,10,128,2,0,37044,mahesh joshi,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We consider the problem of predicting a movie's opening weekend revenue. Previous work on this problem has used metadata about a movie---e.g., its genre, MPAA rating, and cast---with very limited work making use of text about the movie. In this paper, we use the text of film critics' reviews from several sources to predict opening weekend revenue. We describe a new dataset pairing movie reviews with metadata and revenue data, and show that review text can substitute for metadata, and even improve over it, for prediction."
N10-1138,Probabilistic Frame-Semantic Parsing,2010,32,118,1,1,6251,dipanjan das,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper contributes a formalization of frame-semantic parsing as a structure prediction problem and describes an implemented parser that transforms an English sentence into a frame-semantic representation. It finds words that evoke FrameNet frames, selects frames for them, and locates the arguments for each frame. The system uses two feature-based, discriminative probabilistic (log-linear) models, one with latent variables to permit disambiguation of new predicate words. The parser is demonstrated to significantly outperform previously published results."
W09-2813,Non-textual Event Summarization by Applying Machine Learning to Template-based Language Generation,2009,28,7,2,0,46946,mohit kumar,Proceedings of the 2009 Workshop on Language Generation and Summarisation ({UCNLG}+{S}um 2009),0,"We describe a learning-based system that creates draft reports based on observation of people preparing such reports in a target domain (conference replanning). The reports (or briefings) are based on a mix of text and event data. The latter consist of task creation and completion actions, collected from a wide variety of sources within the target environment. The report drafting system is part of a larger learning-based cognitive assistant system that improves the quality of its assistance based on an opportunity to learn from observation. The system can learn to accurately predict the briefing assembly behavior and shows significant performance improvements relative to a non-learning system, demonstrating that it's possible to create meaningful verbal descriptions of activity from event streams."
P09-1053,Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition,2009,31,161,1,1,6251,dipanjan das,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"We present a novel approach to deciding whether two sentences hold a paraphrase relationship. We employ a generative model that generates a paraphrase of a given sentence, and we use probabilistic inference to reason about whether two sentences share the paraphrase relationship. The model cleanly incorporates both syntax and lexical semantics using quasi-synchronous dependency grammars (Smith and Eisner, 2006). Furthermore, using a product of experts (Hinton, 2002), we combine the model with a complementary logistic regression model based on state-of-the-art lexical overlap features. We evaluate our models on the task of distinguishing true paraphrase pairs from false ones on a standard corpus, giving competitive state-of-the-art performance."
I08-1035,Automatic Extraction of Briefing Templates,2008,16,2,1,1,6251,dipanjan das,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"An approach to solving the problem of automatic briefing generation from non-textual events can be segmenting the task into two major steps, namely, extraction of briefing templates and learning aggregators that collate information from events and automatically fill up the templates. In this paper, we describe two novel unsupervised approaches for extracting briefing templates from human written reports. Since the problem is non-standard, we define our own criteria for evaluating the approaches and demonstrate that both approaches are effective in extracting domain relevant templates with promising accuracies."
D08-1017,Stacking Dependency Parsers,2008,31,86,2,0,3896,andre martins,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"We explore a stacked framework for learning to predict dependency structures for natural language sentences. A typical approach in graph-based dependency parsing has been to assume a factorized model, where local features are used but a global function is optimized (McDonald et al., 2005b). Recently Nivre and McDonald (2008) used the output of one dependency parser to provide features for another. We show that this is an example of stacked learning, in which a second predictor is trained to improve the performance of the first. Further, we argue that this technique is a novel way of approximating rich non-local features in the second parser, without sacrificing efficient, model-optimal prediction. Experiments on twelve languages show that stacking transition-based and graph-based parsers improves performance over existing state-of-the-art dependency parsers."
