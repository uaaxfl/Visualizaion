2001.jeptalnrecital-long.22,C96-1030,0,0.121126,"Missing"
2001.jeptalnrecital-long.22,1993.tmi-1.17,0,0.0293361,"ies is often limited by the nature of the text segments that they connect, generally whole sentences. This article examines the potential of a type of system that would be able to recuperate the translation of arbitrary sequences of words. Mots cl´es : m´emoire de traduction sous-phrastique, traduction assist´ee par ordinateur, traduction automatique a` base d’exemples. 1 Introduction L’ensemble des nombres r´eels contient plus de solutions a` plus de probl`emes d’arithm´etique que toute autre ressource... Le lecteur averti aura reconnu, sous un d´eguisement grossier, la c´el`ebre citation de Isabelle et al. (1993): en remplac¸ant l’arithm´etique par la traduction et l’ensemble des nombres r´eels par celui des traductions existantes, on reconnaˆıt bien l’affirmation qui a servi de leitmotiv a` quantit´e de travaux sur les outils d’aide a` la traduction. La premi`ere question que cette boutade soul`eve est celle que se pose tout e´ colier aux prises avec un devoir de math´ematiques: comment aller chercher ces solutions ? Dans le cas de la traduction, toute une gamme d’approches ont e´ t´e propos´ees, allant de la simple consultation interactive (par exemple, avec le syst`eme TransSearch (Macklovitch et a"
2001.jeptalnrecital-long.22,macklovitch-russell-2000-whats,0,0.674436,"Missing"
2001.jeptalnrecital-long.22,macklovitch-etal-2000-transsearch,1,0.771304,"Missing"
2001.jeptalnrecital-long.22,niessen-etal-2000-evaluation,0,0.140903,"Missing"
2001.jeptalnrecital-long.22,1999.mtsummit-1.48,0,0.475518,"Missing"
2001.jeptalnrecital-long.22,W00-0726,0,0.0973981,"Missing"
2001.jeptalnrecital-long.22,1992.tmi-1.7,1,0.860661,"en italique identifient les parties des propositions que l’utilisateur s´electionne. 4 Exp´eriences 4.1 M´emoire de traduction La m´emoire de traduction que nous avons utilis´ee ici est constitu´ee de textes des d´ebats parlementaires canadiens ; textes commun´ement regroup´es sous le nom Hansard. Notre corpus couvre environ 15 ans de d´ebats (de 1986 a` 2000 inclusivement) et totalise pr`es de 100 millions de mots de chaque langue. Le tout a e´ t´e automatiquement segment´e en phrases, lesquelles ont ensuite e´ t´e align´ees avec le programme SFIAL (une version am´elior´ee de la m´ethode de Simard et al. (1992)), produisant ainsi plus de 5 millions de paires de segments. 4.2 Corpus de test Nous avons isol´e deux bitextes assez diff´erents de nature pour mesurer les taux de pr´ecision et de rappel obtenus. Chaque bitexte est constitu´e de 100 paires de phrases extraites al´eatoirement 3 La pertinence d’un copi´e/coll´e est dans cette e´ tude d´efinie par: une brique traductionnelle contient au moins deux mots de la traduction oracle. Philippe Langlais et Michel Simard de l’un des corpus suivants: Hansard, constitu´e de textes du Hansard non rencontr´es dans la m´emoire de traduction et Verne, le roma"
2001.jeptalnrecital-long.22,J97-3002,0,0.0704067,"de r´eduire la quantit´e de mat´eriel cible propos´e a` l’utilisateur consiste a` apparier les couples traductionnels a` un niveau sousphrastique (mots ou autres). Plusieurs m´ethodes ont e´ t´e propos´ees pour localiser a` l’int´erieur de traductions la sous-s´equence cible en relation de traduction avec une s´equence source donn´ee. Certaines ont fait l’objet d’une e´ valuation comparative, dans le cadre de l’ARC-A2 (V´eronis and Langlais2000). Dans ce travail nous avons implant´e une m´ethode d’alignement de mots bas´ee sur les transducteurs grammaticaux invers´es (ITG) propos´es par Dekai Wu (1997). En bref, cette proc´edure prend en entr´ee une paire de segments et une grammaire sp´ecialis´ee (sp´ecifi´ee sous formes de r`egles probabilistes). Elle tente alors de segmenter de mani`ere r´ecursive et parall`ele la paire de segments en identifiant a` chaque e´ tape l’alignement le plus probable entre deux sous-s´equences. La figure 4 illustre le r´esultat d’un alignement produit par cette m´ethode pour un couple traductionnel et une requˆete donn´es. S´equence source: the recommendations made by Couple traductionnel: source: What we find in this bill are things that are directly from the"
2001.mtsummit-papers.36,J93-2003,0,0.0436816,"we clean up the resulting model by filtering out dubious associations. The motivation behind this process is essentially practical. We do not believe that separating the identification of salient units from their bilingual mapping is a promising approach. It would be much better to look for a translation model which allows ;=<?&gt; associations. Of course, the problem for such an approach is to find a way to cope with the well known malediction of multidimensionality (any group of source words being potentially associated to any target group one). More advanced models such as IBM models 3 to 5 (Brown et al., 1993) which permit * <@; associations may be seen as a step in this direction. More recently, the 2-stage model described by Och (Och and Weber, 98; Och et al., 99) seems to be another alternative — at least in a task comparable to the Verbmobil one — as it allows certain hidden structural information to be captured. best results. An exemple of the output of this process is reported in Table 1 for a pair of sentences from the Hansard corpus. H K L O MNN 9QKRSKTU9 NNP VXW Y[ZV^] Gb c bdfee g[h E_a` ` _Xi jk c qr AaB  D & cl E H Km,nIo,p*&apos; (2) Identifying monolingual salient sequences"
2001.mtsummit-papers.36,langlais-etal-2000-evaluation,1,0.898765,"rtion point. Evaluation An implementation of T RANS T YPE which allows the completion of words was evaluated in two ways. In a theoretical evaluation, a simulated user generates character by character the target part of a test corpus, accepting as soon as it is helpful the first completion provided by T RANS T YPE. It was shown that under this scenario, a user could save about two thirds of the keystrokes needed to produce a translation (Foster et al., 1997). An in-situ evaluation involving ten translators who were asked to translate the same text using T RANS T YPE has also been carried out (Langlais et al., 2000b). Some interesting observations emerged which motivate the present study. Only one translator actually managed to translate faster using T RANS T YPE; this suggests that even in a very simple scenario, target-text mediated interactive translation is at least viable. Lack of training time is probably one reason for these otherwise disappointing results. The fact that real users do not systematically watch the screen when typing may also account for part of the problem. A qualitative survey revealed that most users (actually nine out of ten) liked T RANS T YPE and would be eager to try it in t"
2001.mtsummit-papers.36,W97-0311,0,0.0227295,"nslation (e.g. bill/facture vs bill/projet de loi), lexicons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units"
2001.mtsummit-papers.36,1999.tmi-1.9,0,0.0455546,"bill/facture vs bill/projet de loi), lexicons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units hereafter) are linked across"
2001.mtsummit-papers.36,P99-1067,0,0.0120337,"e loi), lexicons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units hereafter) are linked across languages."
2001.mtsummit-papers.36,P97-1061,0,0.0170624,"emple of the output of this process is reported in Table 1 for a pair of sentences from the Hansard corpus. H K L O MNN 9QKRSKTU9 NNP VXW Y[ZV^] Gb c bdfee g[h E_a` ` _Xi jk c qr AaB  D & cl E H Km,nIo,p*&apos; (2) Identifying monolingual salient sequences Distributional filters The literature abounds in measures that help to decide whether words that happen to co-occur are linguistically significant or not. In this study, we rated the coherence of any sequence of words seen in a training corpus by means of two measures: a likelihood-based one (Dunning, 93) and an entropy-based one (Shimohata et al., 1997). Observing the output produced by these methods, it is immediatly apparent that neither metric guarantees that the best ranked units are those that we would ourselves manually select as salient. In particular, it is clear that many sequences overlap; which further complicating the selection process. For this reason, we applied a cascade filter to remove well-rated but non-salient units. Below, we report on the results of a filtering process (called DIST) which removes any sequence seen only once or having a likelihood ratio lower than 5.0; DIST also removes some sequences that overlap with ot"
2001.mtsummit-papers.36,1999.tmi-1.11,0,0.021485,"cons are often the only means for a user to influence the translation engine. As T RANS T YPE is deeply useroriented, we feel it would be a desirable extension to the system if users were allowed to introduce specific lexicons. This extension can be seen as a first step toward an adaptative version of T RANS T YPE, which is a very challenging issue that we hope to study further. Automatic acquisition of lexicons from bilingual corpora Many studies have addressed the problem of automatically acquiring bilingual lexicons (see for instance (Melamed, 1997; Ohomori and Higashida, 1999; Rapp, 1999; Tanaka and Matsuo, 1999; Jacquemin, 99) for recent ones). These studies are by nature difficult if not impossible to compare. Therefore, we investigate a simpler version of the approach described in (Langlais et al., 2000a) that basically involves three steps. First, we identify monolingually salient units using various statistical metrics and/or filters. Second, we group together in our training corpus words which belong to the units selected in the previous step in order to train a new translation model where both words and sequences of words (units hereafter) are linked across languages. Last but not least, we cl"
2001.mtsummit-papers.36,W99-0604,0,\N,Missing
2001.mtsummit-papers.36,A00-1019,1,\N,Missing
2001.mtsummit-papers.36,P98-2162,0,\N,Missing
2001.mtsummit-papers.36,C98-2157,0,\N,Missing
2001.mtsummit-papers.60,C96-1030,0,0.206884,"Missing"
2001.mtsummit-papers.60,1997.mtsummit-papers.1,0,0.0284968,"her a new translation can be a laborious activity, and whether users would find it easier just to type the text instead is not clear. To evaluate this, we measured the performance of a GTMS under 2 alternative scenarios. In the first of these, the user picks only those TL proposals that he can use “as is” in his new translation, without cutting. In the second scenario, the user also considers proposals whose prefix is usable as is. The intention of this last scenario is to evaluate the potential of a “typing completion” mechanism, such as that proposed in the TransType interactive MT project (Foster et al., 1997). The results of these experiments on the Hansard bitext appear in Table 3 below. Scenario Precision Recall cut and paste 37.14 28.09 prefix 26.01 19.66 as is 17.96 13.58 Table 3: GTMS performance under different user-editing scenarios What this shows is that, within our current GTMS implementation, a lot of cutting and pasting would be required to take full advantage of the TM’s content. Nevertheless, using only those proposals that fit “as is” is still viable. Multiple Translation Evaluation Using “oracle translations” to evaluate usability does not necessarily reflect the full potential of"
2001.mtsummit-papers.60,2001.jeptalnrecital-long.22,1,0.741808,"the Pangloss constitutes an acceptable translation for the sourcemulti-engine machine-translation system comprises an language (SL) sentence. As for the query, it is constructed automatically by the TMS, from the SL sentence to be 1 http://www.google.com translated. The retrieval operation is carried out by 2 Note that even for large segments of text such as sentences and matching this query as closely as possible. paragraphs, the general re-usability of past translations is being In this perspective, the default strategy of existing TMS's seriously questioned by some translators; see Bédard (2001), for is an extreme form of high-precision, low-recall search: example. return only the best matching document, and only if it 3 http://www-rali.iro.umontreal.ca/TransSearch EBMT component based on a very simple mechanism (Brown, 1996). The system’s database of examples consists in a large collection of aligned sentences (in other words, a standard translation memory). Given a new sentence to translate, the system looks up all possible subsequences of words of this sentence in the database. It then relies on a simple word-alignment mechanism to locate the translation of each matching sequence"
2001.mtsummit-papers.60,macklovitch-russell-2000-whats,0,0.0616014,"l usually look for does not contain smaller segments that could be useful to couples whose source-language sentence matches the new the translator. sentence in its entirety. This match need not be exact (all The TransSearch system (Macklovitch et al. 2000) is one the above systems feature some sort of “fuzzy” matching), radically different type of TMS based on this idea. It but obviously, better-matching couples stand a better allows translators to interactively query a large database chance of being re-usable. of past translations for specific terms, expressions, or any It is instructive, as Macklovitch and Russell (2000) sequence of words. If current usage statistics are an suggest, to view TM applications in an information argument in favor of exploiting TM’s at a sub-sentential retrieval (IR) perspective: when using a TMS, the level, the system has been online3 for almost 5 years, and translator is actually just searching for documents that currently processes over 50 000 queries per month (March might help in translating a given sentence. In this case, 2001). these “documents” happen to be pairs of mutually Another argument in support of this idea comes in the translated sentences, and the translator is li"
2001.mtsummit-papers.60,macklovitch-etal-2000-transsearch,1,0.726713,"slation Manager/2), Atril (Déja Vu) and Star-AG Nevertheless, this state of affairs is somewhat frustrating: (Transit). In all these systems, the couples in the intuitively, just because a sentence has never been translation memory are normally pairs of sentences. Given translated before does not necessarily mean that the TM a new sentence to be translated, they will usually look for does not contain smaller segments that could be useful to couples whose source-language sentence matches the new the translator. sentence in its entirety. This match need not be exact (all The TransSearch system (Macklovitch et al. 2000) is one the above systems feature some sort of “fuzzy” matching), radically different type of TMS based on this idea. It but obviously, better-matching couples stand a better allows translators to interactively query a large database chance of being re-usable. of past translations for specific terms, expressions, or any It is instructive, as Macklovitch and Russell (2000) sequence of words. If current usage statistics are an suggest, to view TM applications in an information argument in favor of exploiting TM’s at a sub-sentential retrieval (IR) perspective: when using a TMS, the level, the sy"
2001.mtsummit-papers.60,niessen-etal-2000-evaluation,0,0.0554197,"Missing"
2001.mtsummit-papers.60,1999.mtsummit-1.48,0,0.399588,"Missing"
2001.mtsummit-papers.60,1992.tmi-1.7,1,0.677229,"osera-t-il] les [recommandations faites par] les deux agences? Figure 5: Proposed TL sub-sequences and optimal cover of the oracle translation. Test Material The translation memory we used for the tests was constructed from a corpus of proceedings of the Canadian parliamentary debates (Hansard). This corpus covers 15 years of debates (from 1986 to 2000 inclusively) and totals over 100 million words of each language. All pairs of documents were automatically segmented into sentences, which were then aligned using the SFIAL program (an improved implementation of the alignment method proposed by Simard et al., 1992), thus producing over 5 million pairs of segments. Two different test bitexts were used for our experiments, each consisting in 100 pairs of sentences, randomly selected from two quite different documents: The Hansard bitext comes from a parliamentary debate outside our translation memory corpus, while the Verne bitext was extracted from Jules Verne's novel “De la terre à la lune”. In both bitexts, the alignments were verified by hand. Basic Results The initial objective of our work was to determine to what extent it was possible to improve the performance of existing TMS's in terms of recall."
2001.mtsummit-papers.60,J97-3002,0,0.0202272,"sing the selected couples, the system must produce the TL text to be proposed to the user. Since each selected couple (s,t) may correspond to only a fraction of the source sentence e, large segments of the TL sentences t will usually not be relevant to the translation of e. Limiting the amount of information presented to the user requires identifying some specific portion in t that best corresponds to the common sub-sequence sij between e and s. To perform this operation, we have experimented with a word-alignment procedure adapted from Wu’s statistical inversion transduction grammars (SITG − Wu, 1997). Briefly, this procedure takes as input the pair of sentences s and t, and recursively segments both texts in parallel, identifying at each step the most probable alignment between sub-sequences. By forcing this procedure to “stop” around the matching sub-sequence sij in s, we can locate the sub-sequence tkl of t to which it most likely corresponds in this “parallel derivation” of s and t. Figure 4 below shows an example. SL sub-sequence : <the recommendations made by&gt; Matching couple : SL : “ What we find in this bill are things that are directly from the recommendations made by these groups"
2002.jeptalnrecital-long.2,J93-2003,0,0.0050473,"Missing"
2002.jeptalnrecital-long.2,A00-1019,1,0.8849,"Missing"
2002.jeptalnrecital-long.2,2001.mtsummit-papers.36,1,0.870686,"Missing"
2002.jeptalnrecital-long.2,P01-1050,0,0.0620755,"Missing"
2002.jeptalnrecital-long.2,P98-2158,0,0.149826,"Missing"
2002.jeptalnrecital-long.2,C00-2163,0,0.0417606,"Missing"
2002.jeptalnrecital-long.2,W01-1408,0,0.0218376,"Missing"
2003.jeptalnrecital-long.18,J93-2003,0,0.00472084,"Missing"
2003.jeptalnrecital-long.18,C96-1030,0,0.0322551,"Missing"
2003.jeptalnrecital-long.18,1994.amta-1.10,0,0.0994015,"Missing"
2003.jeptalnrecital-long.18,P01-1030,0,0.0608848,"Missing"
2003.jeptalnrecital-long.18,2002.jeptalnrecital-long.2,1,0.863824,"Missing"
2003.jeptalnrecital-long.18,P01-1050,0,0.0318827,"Missing"
2003.jeptalnrecital-long.18,P98-2158,0,0.0542169,"Missing"
2003.jeptalnrecital-long.18,P00-1056,0,0.119625,"Missing"
2003.jeptalnrecital-long.18,W00-0731,0,0.0611225,"Missing"
2003.jeptalnrecital-long.18,P02-1040,0,0.0807418,"Missing"
2003.jeptalnrecital-long.18,J97-3002,0,0.0334788,"Missing"
2003.jeptalnrecital-long.18,C98-2153,0,\N,Missing
2003.mtsummit-papers.15,J93-2003,0,0.00571176,"isted, sentences were split at an arbitrary token boundary. For the take2 experiments, however, we decided to simplify this process by discarding segment pairs for which the source sentence was longer than 40 words. 4 Translation Engines The problem of statistical translation can be viewed as an optimization problem where, given a source string F = hf1 , . . . , fj i, a translation model Ptm (·) and a language model Plm (·), we try to find a target string E = he1 , . . . , ei i that maximizes the joint probability Plm (E) ∗ Ptm (F |E). As such, it is an instance of the noisy channel approach (Brown et al., 1993), in which an output signal is ‘decoded’ in order to recover the original input; algorithms which perform this task are known as decoders. The probabilities Plm (·) and Ptm (·) are derived by training on monolingual and bilingual corpora. The language model used in this work was a trigram model trained by an existing in-house package, and the translation models considered were the IBM model 2, also trained using an in-house tool, and IBM model 4, trained using the GIZA++ package (Och and Ney, 2000).4 One important choice for rescoring is how to represent the sets of translations that are outpu"
2003.mtsummit-papers.15,1994.amta-1.10,0,0.0296286,"Missing"
2003.mtsummit-papers.15,P01-1030,0,0.497158,"gov/ speech/tests/mt/resources/. As time quickly passed we rapidly learned the second lesson of this exercise: building a statistical MT engine, even largely from pre-existing components, is by no means straightforward. Several unexpected problems arose which in retrospect are quite interesting. First, training very large models with publicly available packages is feasible only to the extent that the corresponding memory demands can be met (see section 4.1). Second, dealing with multiple decoders inevitably complicates development. However, thanks to the multiple decoder strategy suggested by Germann et al. (2001) we managed to get a decent IBM 4 decoder. Third, we observed that decoding in itself involves a compromise between quality of results and the length of the delay before results are emitted: tuning for performance is a delicate and time-consuming process. The immediate aim of the NIST exercise we participated in was to translate 919 Chinese sentences (length varying from 5 to 101 words, with an average of 29) into English. Additionally, the rescoring strategy required the translation of some 20,000 sentences for the purpose of training the rescoring layer. In the event, slower than expected pr"
2003.mtsummit-papers.15,P98-2158,0,0.279627,"de approximation to the joint probability of those words). This last heuristic was introduced as a normalization in order to moderate the strong influence that frequent words in the training corpus tend to have at translation time. This means that we only compare paths using the same number of source and target words, and whose source words have similar a priori probabilities. 4.2.3 Inverted Alignment Decoder In an attempt to gauge the influence of both decoders and models on the overall translation quality, we also implemented a version of the inverted alignment search algorithm described by Nießen et al. (1998) for IBM 2 models. The basic idea of this method is to expand hypotheses along the positions of the target string while progressively covering the source. The algorithm allows any target word to be aligned to none, one or several consecutive source words (up to a maximum that was set to 3 in the reported experiments); thus, this search accounts for the notion of fertility which is not explicitly captured by IBM 2 models. A hypothesis is fully determined by four parameters: the source and target positions, the source coverage in words and the target word found at the target position. Therefore,"
2003.mtsummit-papers.15,E99-1010,0,0.0211525,"tures. Establishing the limits of the package (maximum input size, etc.) took at least another week of monitoring, excluding computation time. We soon found that using GIZA++ to train a translation model on a corpus of more than one million sentence pairs was impractical. Beyond this point, memory is saturated and the system is forced to swap, drastically increasing the time required. IBM model 4 conditions the distortion probabilities on the class of the centroid source and target words. To acquire these classes, we used the program mkcls.5 In contrast to the bilingual procedure described by Och (1999), for which no ready-made solution was immediately available, this permits only the creation of monolingual classes. Using this program, source and target vocabulary were processed into 50 classes; this required around ten hours of computation. In total, the full training of an IBM model 4 on a corpus of around one million sentence pairs requires two to three days of computation on a 1GB memory Pentium 4 desk computer. 4.2 Multiple Decoders Three different decoders, all previously described in the statistical MT literature, were implemented. One advantage of having several decoders at one’s di"
2003.mtsummit-papers.15,P00-1056,0,0.115271,"int probability Plm (E) ∗ Ptm (F |E). As such, it is an instance of the noisy channel approach (Brown et al., 1993), in which an output signal is ‘decoded’ in order to recover the original input; algorithms which perform this task are known as decoders. The probabilities Plm (·) and Ptm (·) are derived by training on monolingual and bilingual corpora. The language model used in this work was a trigram model trained by an existing in-house package, and the translation models considered were the IBM model 2, also trained using an in-house tool, and IBM model 4, trained using the GIZA++ package (Och and Ney, 2000).4 One important choice for rescoring is how to represent the sets of translations that are output from the base model. There are at least two possibilities: n-best lists— explicit enumerations of the candidate translations—and word graphs (Ueffing et al., 2002), which are capable of storing much larger sets of translations implicitly. Word graphs are potentially more powerful than n-best lists, but they are also more complex to implement. Furthermore, they constrain the rescoring layer to respect the factorization inherent in the graph. Because of these problems, we chose a simple n-best list"
2003.mtsummit-papers.15,P02-1038,0,0.0861279,"in the NIST evaluation was a desire to learn what was really involved in putting together a working statistical MT system. Deadlines appeared reassuringly distant and we had a plan to achieve good performance despite the limitations mentioned in the previous section. We put our hope into a rescoring approach built on top of a roughly state-of-the-art translation model such as IBM Model 4. Rescoring has been extensively used in automatic speech recognition (ASR) on n-best lists or word-graphs (Ortmanns et al., 1997; Rose and Riccardi, 1999), and has more recently been proposed for use in SMT (Och and Ney, 2002; Soricut et al., 2002; Ueffing et al., 2002). The first step was to install the necessary packages, train translation and language models, and begin work on decoders for IBM Model 4. We also designed a rescoring infrastructure that could host any component able to return a score on a source-target sentence pair. Up to this point we were on familiar territory, since the work was based on a clean and well aligned bitext derived in-house from the Canadian Hansard. By the time the training corpora were made available, a good deal of code had been written, if not fully tested. We were confronted b"
2003.mtsummit-papers.15,soricut-etal-2002-using,0,0.0119268,"tion was a desire to learn what was really involved in putting together a working statistical MT system. Deadlines appeared reassuringly distant and we had a plan to achieve good performance despite the limitations mentioned in the previous section. We put our hope into a rescoring approach built on top of a roughly state-of-the-art translation model such as IBM Model 4. Rescoring has been extensively used in automatic speech recognition (ASR) on n-best lists or word-graphs (Ortmanns et al., 1997; Rose and Riccardi, 1999), and has more recently been proposed for use in SMT (Och and Ney, 2002; Soricut et al., 2002; Ueffing et al., 2002). The first step was to install the necessary packages, train translation and language models, and begin work on decoders for IBM Model 4. We also designed a rescoring infrastructure that could host any component able to return a score on a source-target sentence pair. Up to this point we were on familiar territory, since the work was based on a clean and well aligned bitext derived in-house from the Canadian Hansard. By the time the training corpora were made available, a good deal of code had been written, if not fully tested. We were confronted by an obvious corollary"
2003.mtsummit-papers.15,W02-1021,0,0.0431082,"earn what was really involved in putting together a working statistical MT system. Deadlines appeared reassuringly distant and we had a plan to achieve good performance despite the limitations mentioned in the previous section. We put our hope into a rescoring approach built on top of a roughly state-of-the-art translation model such as IBM Model 4. Rescoring has been extensively used in automatic speech recognition (ASR) on n-best lists or word-graphs (Ortmanns et al., 1997; Rose and Riccardi, 1999), and has more recently been proposed for use in SMT (Och and Ney, 2002; Soricut et al., 2002; Ueffing et al., 2002). The first step was to install the necessary packages, train translation and language models, and begin work on decoders for IBM Model 4. We also designed a rescoring infrastructure that could host any component able to return a score on a source-target sentence pair. Up to this point we were on familiar territory, since the work was based on a clean and well aligned bitext derived in-house from the Canadian Hansard. By the time the training corpora were made available, a good deal of code had been written, if not fully tested. We were confronted by an obvious corollary of the statistical MT"
2004.iwslt-evaluation.5,P00-1056,0,0.0649659,"Missing"
2004.iwslt-evaluation.5,J93-2003,0,0.00553426,"Missing"
2004.iwslt-evaluation.5,W04-3227,0,\N,Missing
2004.iwslt-evaluation.5,2003.mtsummit-papers.53,0,\N,Missing
2004.iwslt-evaluation.5,koen-2004-pharaoh,0,\N,Missing
2004.iwslt-evaluation.5,W99-0604,0,\N,Missing
2004.iwslt-evaluation.5,W03-1001,0,\N,Missing
2004.iwslt-evaluation.5,P98-2158,0,\N,Missing
2004.iwslt-evaluation.5,C98-2153,0,\N,Missing
2004.iwslt-evaluation.5,A00-1019,1,\N,Missing
2004.iwslt-evaluation.5,N03-1017,0,\N,Missing
2004.iwslt-evaluation.5,W03-0303,0,\N,Missing
2004.iwslt-evaluation.5,N04-1033,0,\N,Missing
2004.jeptalnrecital-long.20,2003.jeptalnrecital-long.7,0,0.0428533,"épend ce modèle sont décrites à même le texte. 2.1 Définition du contexte La première des fonctions dont dépend le modèle de la figure 1 — Contexte(t) — définit l’ensemble des mots qui vont servir à la désambiguïsation de t. Nous avons testé deux implémentations de cette fonction. La première — celle utilisée par défaut — consiste à retourner l’ensemble des mots pleins centrés autour du mot t. Nous rapportons les résultats de nos variantes en section 4 pour des longueurs de contexte de ±2 (les deux mots pleins directement à gauche et à droite de t), ±3, ±8, ±10 et ±25 mots. Notons qu’Audibert (2003) suggère que choisir un contexte symétrique n’est pas optimal dans le cas des verbes. Il montre en effet que l’information servant à les désambiguïser a tendance à se trouver dans les compléments d’objets, et donc plutôt à droite des verbes. L’auteur suggère pour cela d’utiliser un contexte &lt; −2, +4 &gt;. Dans les mêmes actes, Crestan et al. (2003) montrent qu’il est bénéfique — du moins pour certaines classes syntaxiques de mots — de mettre en œuvre une procédure automatique de sélection du contexte. La seconde implémentation de cette fonction, dénotée CL, consiste à extraire du contexte d’ocFlo"
2004.jeptalnrecital-long.20,W02-0807,0,0.0620956,"Missing"
2004.jeptalnrecital-long.20,J98-1004,0,0.181814,"Missing"
2004.jeptalnrecital-long.20,J01-3001,0,0.0264256,"Missing"
2004.jeptalnrecital-long.20,P95-1026,0,0.128197,"Missing"
2005.eamt-1.23,2004.iwslt-evaluation.1,0,0.0542013,"hine Translation is a field nowadays strongly anchored in a paradigm of performance. Evaluation exercises such as those conducted within the TIDES project are pushing system designers to constantly improve their systems. The shared task usually consists in translating news articles excerpts from a foreign language into English. While this is certainly a challenging issue, real life applications of machine translation in a production setting (i.e. without human revision) will likely be more targeted than newspaper articles. More focused evaluation exercises do exist. Within the IWSLT workshop (Akiba et al., 2004), the main objective was to provide an evaluation framework for spoken language translation technologies. The shared task consisted in translating sentences from the Basic Travel Expression Corpus (BTEC) which gathers sentences believed to be useful for a tourist in a foreign country. In the Verbmobil project (Wahlster, 2000), transcriptions of spontaneous speech from several narrow domains such as ap166 pointment scheduling were translated from German into English. In this study, we focus on an even more concrete task and one of the greatest successes of machine translation: the English to Fr"
2005.eamt-1.23,C02-1134,0,0.222759,"Missing"
2005.eamt-1.23,C04-1046,1,0.822277,"of Figure 2. The weights on the arcs are the frequency of a given transition. A non-smoothed local bigram language model is obtained by simply normalizing each node by the sum of the weights of the arcs leaving this node. provement. memory + consensus WER SER NIST BLEU 18.69 18.97 94.82 85.53 9.7853 9.9314 66.56 68.86 Table 4: Results of the consensus approach on the output of the memory, for the 13 010 sentences of BLANC not seen verbatim in the TRAIN corpus. 6 The rescoring approach Several papers recently described rescoring approaches for improving the accuracy of a base MT system (e.g. (Blatz et al., 2004)). Rescoring is based on the hope that with the help of additional information (or different ways of using it), we can change the ranks of translations in a nbest list. One motivation for such an approach is that the best translation among alternatives is often not the first one proposed by the base system. P HARAOH, used in section 4, can output its search graph for which the C ARMEL package (Knight and Al-Onaizan, 1999) used in the preceding section, can produce n-best lists. For each source sentence s we built a n-best list of up to 10 different translation alternatives {tj }j∈[1,n≤10] usin"
2005.eamt-1.23,J93-2003,0,0.00649038,"C TEST WER SER NIST BLEU 8.17 7.46 32.46 32.01 10.4081 10.8725 83.52 84.03 Table 3: Results of the phrase-based statistical engine on the BLANC and TEST corpora. longest sequence in a pair was at most twice the length of its counterpart5 . Doing so, we acquired a model of 3 199 163 parameters. We considered two ways of scoring each parameter. The first one is by relative frequency, that is, simply by counting the number of times a given pair (f, e) was seen aligned in the bitext, normalized by the number of times f was seen. The second score we used is the IBM model 1 conditional probability (Brown et al., 1993): p(eji |fab ) −j+i−1 = (b − a) j  b  y=i x=a p(ey |fx ) (1) Since we had only a few parameters to tune, we sought the best setting by uniformly sampling each parameter range with a small enough step size (0.1 for weighting coefficients, and 0.2 for the word penalty). Indeed, we did not find the tuning to bring much gain. In particular, a contrario to the observation we made on other translation tasks, we did not observe a huge difference in performance between the relative frequency score and the IBM one. This might be due to the fact that each parameter is seen often enough that relative f"
2005.eamt-1.23,W98-1435,0,0.230837,"this task. Some alternatives to Machine Translation (MT) have been proposed for weather reports, namely multilingual text generation directly from raw weather data: temperatures, winds, pressures etc. In these generation systems, humans still make selections on templates in order to organize the report. Generating text in many languages from one source is quite appealing from a conceptual point of view and has been cited as one of the potential applications for natural language generation (Reiter and Dale, 2000); some systems have been developed (Kittredge et al., 1986; Goldberg et al., 1994; Coch, 1998) and tested in operational contexts. A recent experiment (Reiter, 2005) even suggests that in some ways automatically generated reports are judged better by humans than human written forecasts! But to our knowledge, no automatic generation has yet been put to daily use on the same level as the one attained by MT, one of the reasons being that meteorologists prefer to write their reports in natural language rather than selecting text structure templates. So we are confident that there is still a need (and a market ?) for a the automatic translation of manually written weather reports. 9 Acknowl"
2005.eamt-1.23,C86-1132,0,0.206006,"Missing"
2005.eamt-1.23,2005.eamt-1.23,1,0.124992,"n the very short life of a weather report. Weather reports are issued every 6 hours. We specifically chose this task because there already exists a fully operational rule-based translation system designed for it, who’s performance was carefully measured (Macklovitch (1985)), and because a very large bitext corpus of previously published weather forcasts is available. Thus, we were able to build a variety of corpus-based MT systems targeted on this specific task and compare their respective performances. 1 The current reports are available at http://meteo. ec.gc.ca/forecast/textforecast_f.html EAMT 2005 Conference Proceedings From the real world to real Words: the METEO case Langlais, Leplus, Grandrabur, Lapalme In the mid seventies, a group of linguists and computer scientists of Universit´e de Montr´eal (TAUM group) developed an English to French weather report machine translation system which became known as the TAUM -M ETEO system. Spin-offs of that research system, namely METEO-1 and METEO-2 (Grimaila and Chandioux, 1992), have been in continuous use since 1984 translating up to 45,000 words a day. A description of the system is presented in (Hutchins and Somers, 1992, chap12). Roughly,"
2005.eamt-1.23,N03-1017,0,0.00999102,"sing the SRILM package (Stolcke, 2002). The perplexity of this model on BLANC and TEST is respectively 4.94 and 3.83, which is very low compared to standard benchmarks (Zens and Ney, 2004). To build our translation table, we first aligned our bitext at the word level. Following a common practice, we used the GIZA++ package (Och and Ney, 2000) to word-align our bitext in both directions (English-to-French and FrenchTo-English)4 . We extended the set of word links that were present in both alignments by some links belonging to only one alignment direction, following the heuristics described in (Koehn et al., 2003). From the resulting alignment A, we collected the set of pairs of source and target sequences (fab , eji ) from all regions (a, b) × (i, j) in the alignment matrix where none of the source words in fab is aligned to a word not belonging to eji and vice-versa: ∀x ∈ [a, b], ∀y : (x, y) ∈ A, y ∈ [i, j] ∀y ∈ [i, j], ∀x : (x, y) ∈ A, x ∈ [a, b] We did apply a few length-based heuristics to filter the parameters acquired in this way: (source or target) sequences of at most 8 words were considered and we imposed that the length of the 4 We used the alignments produced by IBM model 2. EAMT 2005 Confe"
2005.eamt-1.23,leplus-etal-2004-weather,1,0.749326,"d seventies, a group of linguists and computer scientists of Universit´e de Montr´eal (TAUM group) developed an English to French weather report machine translation system which became known as the TAUM -M ETEO system. Spin-offs of that research system, namely METEO-1 and METEO-2 (Grimaila and Chandioux, 1992), have been in continuous use since 1984 translating up to 45,000 words a day. A description of the system is presented in (Hutchins and Somers, 1992, chap12). Roughly, it involves three major steps: dictionary look-up, syntactic analysis and light syntactic and morphological generation. Leplus et al. (2004) described experiments they conducted on a bitext of forecasts in both French and English produced during 2002 and 2003 by Environment Canada. They report fairly good translation results by applying a straightforward memory-based approach to the task. The authors mentioned that this approach is warranted by the particularly high rate of sentence repetitions. Indeed, Grimaila and Chandioux (1992) argued that the repetitiveness of the task was one of the reasons for the success of the METEO system. In the current work, we explore how well stateof-the-art corpus-based approaches can do for the sa"
2005.eamt-1.23,P00-1056,0,0.0227071,"We split the TRAIN corpus in two subparts, TRAIN - T (4 180 000 pairs of sentences) for training the translation and the language models, and TRAIN - H (8 100 pairs) for tuning the different parameters of the engine. We trained a KneserNey smoothed trigram language model using the SRILM package (Stolcke, 2002). The perplexity of this model on BLANC and TEST is respectively 4.94 and 3.83, which is very low compared to standard benchmarks (Zens and Ney, 2004). To build our translation table, we first aligned our bitext at the word level. Following a common practice, we used the GIZA++ package (Och and Ney, 2000) to word-align our bitext in both directions (English-to-French and FrenchTo-English)4 . We extended the set of word links that were present in both alignments by some links belonging to only one alignment direction, following the heuristics described in (Koehn et al., 2003). From the resulting alignment A, we collected the set of pairs of source and target sequences (fab , eji ) from all regions (a, b) × (i, j) in the alignment matrix where none of the source words in fab is aligned to a word not belonging to eji and vice-versa: ∀x ∈ [a, b], ∀y : (x, y) ∈ A, y ∈ [i, j] ∀y ∈ [i, j], ∀x : (x, y"
2005.eamt-1.23,N04-1021,0,0.177775,"group of linguists and computer scientists of Universit´e de Montr´eal (TAUM group) developed an English to French weather report machine translation system which became known as the TAUM -M ETEO system. Spin-offs of that research system, namely METEO-1 and METEO-2 (Grimaila and Chandioux, 1992), have been in continuous use since 1984 translating up to 45,000 words a day. A description of the system is presented in (Hutchins and Somers, 1992, chap12). Roughly, it involves three major steps: dictionary look-up, syntactic analysis and light syntactic and morphological generation. Leplus et al. (2004) described experiments they conducted on a bitext of forecasts in both French and English produced during 2002 and 2003 by Environment Canada. They report fairly good translation results by applying a straightforward memory-based approach to the task. The authors mentioned that this approach is warranted by the particularly high rate of sentence repetitions. Indeed, Grimaila and Chandioux (1992) argued that the repetitiveness of the task was one of the reasons for the success of the METEO system. In the current work, we explore how well stateof-the-art corpus-based approaches can do for the sa"
2005.eamt-1.23,N04-1033,0,0.0892427,"quiring a language model and a translation table; if desired, weighting coefficients as well as a few pruning options can control the behavior of the engine. We split the TRAIN corpus in two subparts, TRAIN - T (4 180 000 pairs of sentences) for training the translation and the language models, and TRAIN - H (8 100 pairs) for tuning the different parameters of the engine. We trained a KneserNey smoothed trigram language model using the SRILM package (Stolcke, 2002). The perplexity of this model on BLANC and TEST is respectively 4.94 and 3.83, which is very low compared to standard benchmarks (Zens and Ney, 2004). To build our translation table, we first aligned our bitext at the word level. Following a common practice, we used the GIZA++ package (Och and Ney, 2000) to word-align our bitext in both directions (English-to-French and FrenchTo-English)4 . We extended the set of word links that were present in both alignments by some links belonging to only one alignment direction, following the heuristics described in (Koehn et al., 2003). From the resulting alignment A, we collected the set of pairs of source and target sequences (fab , eji ) from all regions (a, b) × (i, j) in the alignment matrix wher"
2005.eamt-1.23,koen-2004-pharaoh,0,\N,Missing
2005.jeptalnrecital-court.14,2004.iwslt-evaluation.1,0,0.0399483,"Missing"
2005.jeptalnrecital-court.14,C02-1134,0,0.0434285,"Missing"
2005.jeptalnrecital-court.14,C04-1046,1,0.887609,"Missing"
2005.jeptalnrecital-court.14,J93-2003,0,0.005862,"Missing"
2005.jeptalnrecital-court.14,N03-1017,0,0.0127935,"Missing"
2005.jeptalnrecital-court.14,2005.eamt-1.23,1,0.800055,"Missing"
2005.jeptalnrecital-court.14,leplus-etal-2004-weather,1,0.891043,"Missing"
2005.jeptalnrecital-court.14,N04-1033,0,0.0276551,"Missing"
2005.jeptalnrecital-court.14,koen-2004-pharaoh,0,\N,Missing
2005.jeptalnrecital-court.14,P00-1056,0,\N,Missing
2005.jeptalnrecital-long.23,J93-2003,0,0.00659945,"Missing"
2005.jeptalnrecital-long.23,2004.iwslt-papers.5,0,0.0595807,"Missing"
2005.jeptalnrecital-long.23,N03-1017,0,0.00839204,"Missing"
2005.jeptalnrecital-long.23,J03-3003,0,0.0406139,"Missing"
2005.jeptalnrecital-long.23,P98-1117,1,0.857953,"Missing"
2005.jeptalnrecital-long.23,macklovitch-etal-2000-transsearch,1,0.838024,"Missing"
2005.jeptalnrecital-long.23,N04-1034,0,0.0645264,"Missing"
2005.jeptalnrecital-long.23,P99-1067,0,0.115806,"Missing"
2005.jeptalnrecital-long.23,J03-3002,0,0.106345,"Missing"
2005.jeptalnrecital-long.24,J93-2003,0,0.0126525,"Missing"
2005.jeptalnrecital-long.24,P01-1030,1,0.892376,"Missing"
2005.jeptalnrecital-long.24,P04-1064,1,0.882028,"Missing"
2005.jeptalnrecital-long.24,P99-1041,0,0.0877922,"Missing"
2005.jeptalnrecital-long.24,W02-1018,0,0.0264918,"Missing"
2005.jeptalnrecital-long.24,P00-1056,0,0.327309,"Missing"
2005.jeptalnrecital-long.24,J04-4002,0,0.0723566,"Missing"
2005.jeptalnrecital-long.24,W99-0604,0,0.111557,"Missing"
2005.jeptalnrecital-long.24,P03-1021,0,0.0362064,"Missing"
2005.jeptalnrecital-long.24,P02-1040,0,0.072645,"Missing"
2005.jeptalnrecital-long.24,N03-2036,0,0.0275543,"Missing"
2005.mtsummit-ebmt.10,J93-2003,0,0.00419524,"alignment (the first part of the source sentence is aligned to the first part of the target sentence, the second parts are aligned together), or an inverted one (the first source part is aligned to the second target one and vice-versa). The best split found at each step is kept and we further split the two parts until we cannot split anymore (that is, when there is at most one token in one side). The computation of the quality of a split is done using a linear combination of two word models (one for each direction) that have been trained on the same training material. We used an IBM model 2 (Brown et al., 1993) for that purpose, whose parameters were trained with the Giza package (Och and Ney, 2000). An illustration of the output of this alignment procedure is provided for the running example in Figure 3. Once both the word alignment and the treelets are computed, populating the memory with tree-phrases is just a matter of collecting them, and keeping their count over the total training corpus. The format we use to represent the treelets (see Figure 3) is similar to the one proposed in (Quirk et al., 2005): the left and right dependents of a given governor word are listed in order in two separate li"
2005.mtsummit-ebmt.10,P03-1011,0,0.0199845,"(2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better generalise the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. In this work, we consider a new kind of unit: a Tree-Phrase (TP), a combination of a treelet (TL) and a elastic phrase (EP), the tokens of which may be in non-contiguous positions. Several authors have used treelets as a prime unit to do translation (Gildea, 2003; Ding and Palmer, 2004; Quirk et al., 2005), but mostly with the 71 www.linguatechnologies.com idea of projecting a source treelet into its target counterpart. In this study, we do not address the issue of projecting a treelet into a target one, but take the bet that collecting (without structure) the target words associated with the words encoded in the nodes of a treelet will suffice to handle translation. This set of target words is what we call an elastic phrase (EP). An elastic phrase is not only possibly a non-contiguous sequence of words, but also has the characteristic of having “gaps"
2005.mtsummit-ebmt.10,2005.eamt-1.19,0,0.014378,"e-based machine translation is nowadays a popular paradigm. It has the advantage of naturally capturing local reordering and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to generalise well upon the training corpus. Several alternatives have been proposed to tackle some of these weaknesses. Matusov et al. (2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. Hildebrand et al. (2005) show that it is possible to adapt the transfer table of a phrase-based model to the specificity of the text being translated. Simard et al. (2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better generalise the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. In this work, we consider a new kind of unit: a Tree-Phrase (TP), a combination of a treelet (TL) and a elasti"
2005.mtsummit-ebmt.10,N03-1017,0,0.00895538,"tract We present a study we conducted to build a repository storing associations between simple dependency treelets in a source language and their corresponding phrases in a target language. To assess the impact of this resource in EBMT, we used the repository to compute coverage statistics on a test bitext and on a nbest list of translation candidates produced by a standard phrase-based decoder. 1 Introduction Phrase-based machine translation is nowadays a popular paradigm. It has the advantage of naturally capturing local reordering and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to generalise well upon the training corpus. Several alternatives have been proposed to tackle some of these weaknesses. Matusov et al. (2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. Hildebrand et al. (2005) show that it is possible to adapt the transfer table of a phrase-based model to the specificity of the text being translated. Simard et al. (2005) detail an approach where th"
2005.mtsummit-ebmt.10,2005.eamt-1.25,0,0.0398724,"ompute coverage statistics on a test bitext and on a nbest list of translation candidates produced by a standard phrase-based decoder. 1 Introduction Phrase-based machine translation is nowadays a popular paradigm. It has the advantage of naturally capturing local reordering and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to generalise well upon the training corpus. Several alternatives have been proposed to tackle some of these weaknesses. Matusov et al. (2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. Hildebrand et al. (2005) show that it is possible to adapt the transfer table of a phrase-based model to the specificity of the text being translated. Simard et al. (2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better generalise the training corpus and to nicely handle differences such as negations in French and English that are"
2005.mtsummit-ebmt.10,P00-1056,0,0.0607392,"t sentence, the second parts are aligned together), or an inverted one (the first source part is aligned to the second target one and vice-versa). The best split found at each step is kept and we further split the two parts until we cannot split anymore (that is, when there is at most one token in one side). The computation of the quality of a split is done using a linear combination of two word models (one for each direction) that have been trained on the same training material. We used an IBM model 2 (Brown et al., 1993) for that purpose, whose parameters were trained with the Giza package (Och and Ney, 2000). An illustration of the output of this alignment procedure is provided for the running example in Figure 3. Once both the word alignment and the treelets are computed, populating the memory with tree-phrases is just a matter of collecting them, and keeping their count over the total training corpus. The format we use to represent the treelets (see Figure 3) is similar to the one proposed in (Quirk et al., 2005): the left and right dependents of a given governor word are listed in order in two separate lists along with their respective offset (the governor/root token always has the offset 0)."
2005.mtsummit-ebmt.10,P05-1034,0,0.122765,"tandard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better generalise the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. In this work, we consider a new kind of unit: a Tree-Phrase (TP), a combination of a treelet (TL) and a elastic phrase (EP), the tokens of which may be in non-contiguous positions. Several authors have used treelets as a prime unit to do translation (Gildea, 2003; Ding and Palmer, 2004; Quirk et al., 2005), but mostly with the 71 www.linguatechnologies.com idea of projecting a source treelet into its target counterpart. In this study, we do not address the issue of projecting a treelet into a target one, but take the bet that collecting (without structure) the target words associated with the words encoded in the nodes of a treelet will suffice to handle translation. This set of target words is what we call an elastic phrase (EP). An elastic phrase is not only possibly a non-contiguous sequence of words, but also has the characteristic of having “gaps” of arbitrary size, which is not the case f"
2005.mtsummit-ebmt.10,W03-0304,1,0.844085,"Syntex Figure 2: An example of output from Syntex. Each line corresponds to a single Syntex token. Some tags have been translated in English to facilitate reading. 3 The Memory We parsed with Syntex the source (French) part of our training bitext, that is, about 1.7 million sentences. From this material, we extracted all dependency subtrees of depth 1 from the complete dependency trees found by Syntex. For instance, the two treelets in Figure 3 will be collected out of the parse tree in Figure 1. Prior to that, the full training corpus was aligned at the word level by the method described in (Simard and Langlais, 2003) which recursively splits in two parts both the source and target sentences and allows either a left-to-right alignment (the first part of the source sentence is aligned to the first part of the target sentence, the second parts are aligned together), or an inverted one (the first source part is aligned to the second target one and vice-versa). The best split found at each step is kept and we further split the two parts until we cannot split anymore (that is, when there is at most one token in one side). The computation of the quality of a split is done using a linear combination of two word m"
2005.mtsummit-ebmt.10,2005.jeptalnrecital-long.24,1,0.792769,"d-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to generalise well upon the training corpus. Several alternatives have been proposed to tackle some of these weaknesses. Matusov et al. (2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. Hildebrand et al. (2005) show that it is possible to adapt the transfer table of a phrase-based model to the specificity of the text being translated. Simard et al. (2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better generalise the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. In this work, we consider a new kind of unit: a Tree-Phrase (TP), a combination of a treelet (TL) and a elastic phrase (EP), the tokens of which may be in non-contiguous positions. Several authors have used treelets as a prime unit to do translation (Gildea"
2006.jeptalnrecital-long.19,P00-1056,0,0.174597,"Missing"
2006.jeptalnrecital-long.19,2005.mtsummit-papers.19,0,0.0993079,"Missing"
2006.jeptalnrecital-long.19,patry-etal-2006-mood,1,0.872419,"Missing"
2006.jeptalnrecital-poster.12,2005.mtsummit-ebmt.2,0,0.0550984,"Missing"
2006.jeptalnrecital-poster.12,2005.mtsummit-papers.11,0,0.0176345,"Missing"
2006.jeptalnrecital-poster.12,2003.jeptalnrecital-long.18,1,0.845536,"Missing"
2006.jeptalnrecital-poster.12,P00-1056,0,0.174075,"Missing"
2006.jeptalnrecital-poster.12,C00-2090,0,0.0255085,"Missing"
2006.jeptalnrecital-poster.12,W03-0313,0,0.0604973,"Missing"
2006.jeptalnrecital-poster.12,2001.mtsummit-papers.60,1,0.880093,"Missing"
2007.iwslt-1.22,C04-1168,0,0.0955926,"e known for sure, in spoken language translation they must be reconstructed from an audio signal. Instead of translating the raw audio signal, spoken language translation systems usually start from the output of an automatic speech recognition system, which usually takes the form of a word lattice. A straightforward way to translate a word lattice is to feed a textual translation system with the most probable sentence. To overcome some recognition errors, one can instead translate a set of n top ranked sentences extracted from the lattice and select the best translation among the one returned [1, 2]. Finally, a third approach is to translate directly the lattice with a specialized decoder tightly coupled with the speech recognition system [3, 4, 5, 6, 7]. In this paper, we present MISTRAL (Monotone yet Imperfect Statistical TRAnslation of Lattices), a discriminative phrase-based system that translates lattices in two passes. The first pass uses a beam-search decoder to extract a N-Best list of source sentences and their translations from the lattice and the second pass rescores this list with more complex feature functions. Different word-based lattice translation systems are presented i"
2007.iwslt-1.22,2005.iwslt-1.2,0,0.0620097,"language translation systems usually start from the output of an automatic speech recognition system, which usually takes the form of a word lattice. A straightforward way to translate a word lattice is to feed a textual translation system with the most probable sentence. To overcome some recognition errors, one can instead translate a set of n top ranked sentences extracted from the lattice and select the best translation among the one returned [1, 2]. Finally, a third approach is to translate directly the lattice with a specialized decoder tightly coupled with the speech recognition system [3, 4, 5, 6, 7]. In this paper, we present MISTRAL (Monotone yet Imperfect Statistical TRAnslation of Lattices), a discriminative phrase-based system that translates lattices in two passes. The first pass uses a beam-search decoder to extract a N-Best list of source sentences and their translations from the lattice and the second pass rescores this list with more complex feature functions. Different word-based lattice translation systems are presented in [3, 4, 5]. A generative phrase-based system is described in [6]. This system translates the lattice with a sequence of weighted finite state machines applie"
2007.iwslt-1.22,2005.mtsummit-papers.11,0,0.0221687,"on corpus are kept. The first pass is then used to extract the 500 best translations from a new corpus. Rescoring is optimised on this list with the downhill simplex algorithm. 4. Experiments 4.1. Data The corpus used for the shared task is composed of transcriptions of spontaneous conversations in the travel domain. It is divided in train (TRAIN) and development (DEV) sections containing respectively 19,722 and 996 sentence pairs. We also trained our models on the Italian-English section of the proceedings of the European Parliament (EUROPARL), which contains more than 928,000 sentence pairs [9]. The two corpora were converted to lower case and their punctuation marks were removed. The lattices of DEV, which were originally scored with a language model and an acoustic model, were augmented with posterior probabilities using the lattice-tool utility [10]. 1 Recombination is done after pruning because it is slower to execute. did not observe a degradation in translation quality by doing so. We System First Pass Rescoring We then trained a translation table on TRAIN and another on EUROPARL. To do so, we used a script that was provided for the shared task of the NAACL 2006 Workshop on St"
2007.iwslt-1.22,W06-3114,0,0.0343558,"ed to lower case and their punctuation marks were removed. The lattices of DEV, which were originally scored with a language model and an acoustic model, were augmented with posterior probabilities using the lattice-tool utility [10]. 1 Recombination is done after pruning because it is slower to execute. did not observe a degradation in translation quality by doing so. We System First Pass Rescoring We then trained a translation table on TRAIN and another on EUROPARL. To do so, we used a script that was provided for the shared task of the NAACL 2006 Workshop on Statistical Machine Translation [11]. This script uses the heuristics described in [12] to extract phrase pairs from a word alignment that was first produced by GIZA ++ [13]. It then computes five scores for each phrase pair: the posterior probability in each translation direction, the lexical probability in each translation direction and a constant phrase penalty. Knowing that the corpora contain many dates and numbers, we manually created a third translation table containing 122 entries translating days, months and numbers2 . The first 300 sentences of DEV were used to tune the coefficients of the first pass (200 for tuning an"
2007.iwslt-1.22,N03-1017,0,0.0233113,"emoved. The lattices of DEV, which were originally scored with a language model and an acoustic model, were augmented with posterior probabilities using the lattice-tool utility [10]. 1 Recombination is done after pruning because it is slower to execute. did not observe a degradation in translation quality by doing so. We System First Pass Rescoring We then trained a translation table on TRAIN and another on EUROPARL. To do so, we used a script that was provided for the shared task of the NAACL 2006 Workshop on Statistical Machine Translation [11]. This script uses the heuristics described in [12] to extract phrase pairs from a word alignment that was first produced by GIZA ++ [13]. It then computes five scores for each phrase pair: the posterior probability in each translation direction, the lexical probability in each translation direction and a constant phrase penalty. Knowing that the corpora contain many dates and numbers, we manually created a third translation table containing 122 entries translating days, months and numbers2 . The first 300 sentences of DEV were used to tune the coefficients of the first pass (200 for tuning and 100 for validation, see section 3.4) and the 300"
2007.iwslt-1.22,P00-1056,0,0.132471,"acoustic model, were augmented with posterior probabilities using the lattice-tool utility [10]. 1 Recombination is done after pruning because it is slower to execute. did not observe a degradation in translation quality by doing so. We System First Pass Rescoring We then trained a translation table on TRAIN and another on EUROPARL. To do so, we used a script that was provided for the shared task of the NAACL 2006 Workshop on Statistical Machine Translation [11]. This script uses the heuristics described in [12] to extract phrase pairs from a word alignment that was first produced by GIZA ++ [13]. It then computes five scores for each phrase pair: the posterior probability in each translation direction, the lexical probability in each translation direction and a constant phrase penalty. Knowing that the corpora contain many dates and numbers, we manually created a third translation table containing 122 entries translating days, months and numbers2 . The first 300 sentences of DEV were used to tune the coefficients of the first pass (200 for tuning and 100 for validation, see section 3.4) and the 300 following sentences to tune the coefficients of the rescoring pass. The remaining 396"
2007.iwslt-1.22,2001.mtsummit-papers.68,0,0.0698729,"Missing"
2007.iwslt-1.22,P07-2045,0,0.0104834,"Missing"
2007.iwslt-1.22,N03-1031,0,\N,Missing
2007.iwslt-1.22,P02-1040,0,\N,Missing
2007.jeptalnrecital-long.9,P98-1069,0,0.13711,"Missing"
2007.jeptalnrecital-long.9,W06-3114,0,0.0687981,"Missing"
2007.jeptalnrecital-long.9,P98-1120,0,0.0948234,"Missing"
2007.jeptalnrecital-long.9,2005.iwslt-1.4,0,0.0406729,"Missing"
2007.jeptalnrecital-long.9,2004.jeptalnrecital-long.13,0,0.0606337,"Missing"
2007.jeptalnrecital-long.9,P00-1056,0,0.182461,"Missing"
2007.jeptalnrecital-long.9,P99-1067,0,0.147667,"Missing"
2007.jeptalnrecital-long.9,W05-0616,0,0.0421487,"Missing"
2007.jeptalnrecital-long.9,1999.tmi-1.11,0,0.128228,"Missing"
2007.tmi-papers.13,H94-1028,0,0.298621,"Missing"
2007.tmi-papers.13,J95-4004,0,0.0254826,"programming algorithm embedded in decoders such as Pharaoh or Ramses. Perhaps the main contribution of this study is to point out the potential such an easy search algorithm has over more demanding decoders. Until now, this was an idea that had not received much attention in the phrase-based SMT community. We plan to extend this work in several directions. Actually, one initial motivation for this 112 study was to explore post-processing operations that could apply to the output of a translation engine, in order to recover systematic errors, in a way inspired by transformation-based learning (Brill, 1995). On step toward accomplishing this consists in increasing the number of operations that our greedy search can perform, associating with each of them a coefficient that we can adjust on a development corpus. This is the idea we want to explore further. We also want to cast our greedy decoder within the open-source framework called Mood, whose principle is to offer decoders that are easy to modify and extend. Therefore, our goal will be to release a reengineered version of feGreedy. 6 Acknowledgements This study has been partially funded by a NSERC grant. We are grateful to Pierre Poulin for hi"
2007.tmi-papers.13,W06-3114,0,0.0336372,"ll system. The cascading strategy received a more dedicated treatment in Marcu (2001) and Watanabe and Sumita (2003). In their work, the authors were seeding a word-based greedy search algorithm with examples extracted from a translation memory hoping to bias the search toward a better solution. Our motivation is slightly different however: we simply want to know whether the greedy strategy can overcome some search errors made by a phrase-based DP-search. 3 Experimental setup 3.1 Corpora We concentrated our efforts on the shared task of last year’s workshop on Statistical Machine Translation (Koehn and Monz, 2006) which consisted in translating Spanish, German and French texts into English and the reverse direction. The training material available is coming from the Europarl corpus. Four disjoint corpora were released during this exercise, namely train, a portion of 688,031, 730,740 and 751,088 pairs of sentences for French, Spanish and German respectively; dev, a development corpus that we used for tuning; devtest, a corpus of 2,000 pairs of 5 (4) We used the --trace option of Pharaoh to access the phrasal alignment corresponding to the best translation found. 107 F E S0 T0 S1 T1 S2 T2 S3 T3 S4 T4 de"
2007.tmi-papers.13,N03-1017,0,0.0842749,"eriments we conducted with a simple, yet effective greedy search engine. In particular, we show that when seeded with the translations produced by a stateof-the-art beam search decoder, it produces an output of significantly higher quality than the latter taken alone, as measured by automatic metrics. 1 Introduction At the beginning of Statistical Machine Translation (SMT), efforts were made to design efficient machine decoders for word-based models (Tillmann et al., 1997; Wang and Waibel, 1997; Niessen et al., 1998; Garc´ıa and Casacuberta, 2001). As phrase-based models gained in popularity (Koehn et al., 2003), specific phrasebased decoders were released, such as Pharaoh1 1 Moses, available at http://www.statmt.org/ moses/ gracefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming (DP). For the kind of models we typically consider in SMT (word- or phrase-based), this is just fine, but one can easily think of models for whi"
2007.tmi-papers.13,P01-1050,0,0.0657843,"th Pharaoh It is likely that a DP-search will outperform our greedy implementation, hereafter named feGreedy. Therefore, it is natural to investigate whether any benefit would result from seeding feGreedy with the best translation produced by Pharaoh.5 The idea of cascading two translation engines has been pioneered within the wordbased Candide translation system (Berger et al., 1994). Unfortunately, the authors did not describe their local search engine, neither did they provide an evaluation of its benefits to the overall system. The cascading strategy received a more dedicated treatment in Marcu (2001) and Watanabe and Sumita (2003). In their work, the authors were seeding a word-based greedy search algorithm with examples extracted from a translation memory hoping to bias the search toward a better solution. Our motivation is slightly different however: we simply want to know whether the greedy strategy can overcome some search errors made by a phrase-based DP-search. 3 Experimental setup 3.1 Corpora We concentrated our efforts on the shared task of last year’s workshop on Statistical Machine Translation (Koehn and Monz, 2006) which consisted in translating Spanish, German and French texts"
2007.tmi-papers.13,P98-2158,0,0.0424761,"ion a search engine using a complete-state formulation does not have. In this paper, we present experiments we conducted with a simple, yet effective greedy search engine. In particular, we show that when seeded with the translations produced by a stateof-the-art beam search decoder, it produces an output of significantly higher quality than the latter taken alone, as measured by automatic metrics. 1 Introduction At the beginning of Statistical Machine Translation (SMT), efforts were made to design efficient machine decoders for word-based models (Tillmann et al., 1997; Wang and Waibel, 1997; Niessen et al., 1998; Garc´ıa and Casacuberta, 2001). As phrase-based models gained in popularity (Koehn et al., 2003), specific phrasebased decoders were released, such as Pharaoh1 1 Moses, available at http://www.statmt.org/ moses/ gracefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming (DP). For the kind of models we typically cons"
2007.tmi-papers.13,W06-3121,0,0.026838,"e, as measured by automatic metrics. 1 Introduction At the beginning of Statistical Machine Translation (SMT), efforts were made to design efficient machine decoders for word-based models (Tillmann et al., 1997; Wang and Waibel, 1997; Niessen et al., 1998; Garc´ıa and Casacuberta, 2001). As phrase-based models gained in popularity (Koehn et al., 2003), specific phrasebased decoders were released, such as Pharaoh1 1 Moses, available at http://www.statmt.org/ moses/ gracefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming (DP). For the kind of models we typically consider in SMT (word- or phrase-based), this is just fine, but one can easily think of models for which such a property is inappropriate. One notable exception to the dynamic programming approach is the ReWrite decoder (Germann et al., 2001). It is a greedy decoder that iteratively tries to improve a current translation by modifying some of its elements according to"
2007.tmi-papers.13,patry-etal-2006-mood,1,0.848964,"uality than the latter taken alone, as measured by automatic metrics. 1 Introduction At the beginning of Statistical Machine Translation (SMT), efforts were made to design efficient machine decoders for word-based models (Tillmann et al., 1997; Wang and Waibel, 1997; Niessen et al., 1998; Garc´ıa and Casacuberta, 2001). As phrase-based models gained in popularity (Koehn et al., 2003), specific phrasebased decoders were released, such as Pharaoh1 1 Moses, available at http://www.statmt.org/ moses/ gracefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming (DP). For the kind of models we typically consider in SMT (word- or phrase-based), this is just fine, but one can easily think of models for which such a property is inappropriate. One notable exception to the dynamic programming approach is the ReWrite decoder (Germann et al., 2001). It is a greedy decoder that iteratively tries to improve a current translation by modifying"
2007.tmi-papers.13,2003.mtsummit-papers.15,1,0.903308,"easily think of models for which such a property is inappropriate. One notable exception to the dynamic programming approach is the ReWrite decoder (Germann et al., 2001). It is a greedy decoder that iteratively tries to improve a current translation by modifying some of its elements according to some predefined operations. At each iteration, the best hypothesis found up to that point is kept and used for the next iteration, until convergence is obtained, which typically happens after a few iterations. A time-efficient refinement of this decoder has been described in (Germann, 2003). However, Foster et al. (2003) did report that this decoder produces translations of lower quality than those produced by a DP-decoder. To our knowledge, there has been no investigation on a greedy decoder designed to maximize the log-linear combination of models traditionally embedded in a phrase-based SMT system. This paper aims at filling this gap. We show that our implementation, although not as good as a state-of-the-art beam search DP-engine, is not far off. More interestingly, we report experiments on the Europarl corpus where the greedy search algorithm significantly 104 improves the best translation produced by a"
2007.tmi-papers.13,P97-1037,0,0.281192,"rementally on partial translations, a restriction a search engine using a complete-state formulation does not have. In this paper, we present experiments we conducted with a simple, yet effective greedy search engine. In particular, we show that when seeded with the translations produced by a stateof-the-art beam search decoder, it produces an output of significantly higher quality than the latter taken alone, as measured by automatic metrics. 1 Introduction At the beginning of Statistical Machine Translation (SMT), efforts were made to design efficient machine decoders for word-based models (Tillmann et al., 1997; Wang and Waibel, 1997; Niessen et al., 1998; Garc´ıa and Casacuberta, 2001). As phrase-based models gained in popularity (Koehn et al., 2003), specific phrasebased decoders were released, such as Pharaoh1 1 Moses, available at http://www.statmt.org/ moses/ gracefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming ("
2007.tmi-papers.13,2001.mtsummit-papers.22,0,0.33232,"Missing"
2007.tmi-papers.13,P97-1047,0,0.101854,"ranslations, a restriction a search engine using a complete-state formulation does not have. In this paper, we present experiments we conducted with a simple, yet effective greedy search engine. In particular, we show that when seeded with the translations produced by a stateof-the-art beam search decoder, it produces an output of significantly higher quality than the latter taken alone, as measured by automatic metrics. 1 Introduction At the beginning of Statistical Machine Translation (SMT), efforts were made to design efficient machine decoders for word-based models (Tillmann et al., 1997; Wang and Waibel, 1997; Niessen et al., 1998; Garc´ıa and Casacuberta, 2001). As phrase-based models gained in popularity (Koehn et al., 2003), specific phrasebased decoders were released, such as Pharaoh1 1 Moses, available at http://www.statmt.org/ moses/ gracefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming (DP). For the kind of mo"
2007.tmi-papers.13,P01-1030,0,0.579004,"cefully replaces Pharaoh. (Koehn, 2004) and some open-source alternatives, among which Ramses (Patry et al., 2006) and Phramer (Olteanu et al., 2006). All these decoders share one common property: they rely on a scoring function that is incremental, in order to allow an efficient organization of the computations by dynamic programming (DP). For the kind of models we typically consider in SMT (word- or phrase-based), this is just fine, but one can easily think of models for which such a property is inappropriate. One notable exception to the dynamic programming approach is the ReWrite decoder (Germann et al., 2001). It is a greedy decoder that iteratively tries to improve a current translation by modifying some of its elements according to some predefined operations. At each iteration, the best hypothesis found up to that point is kept and used for the next iteration, until convergence is obtained, which typically happens after a few iterations. A time-efficient refinement of this decoder has been described in (Germann, 2003). However, Foster et al. (2003) did report that this decoder produces translations of lower quality than those produced by a DP-decoder. To our knowledge, there has been no investig"
2007.tmi-papers.13,N03-1010,0,0.132259,"s just fine, but one can easily think of models for which such a property is inappropriate. One notable exception to the dynamic programming approach is the ReWrite decoder (Germann et al., 2001). It is a greedy decoder that iteratively tries to improve a current translation by modifying some of its elements according to some predefined operations. At each iteration, the best hypothesis found up to that point is kept and used for the next iteration, until convergence is obtained, which typically happens after a few iterations. A time-efficient refinement of this decoder has been described in (Germann, 2003). However, Foster et al. (2003) did report that this decoder produces translations of lower quality than those produced by a DP-decoder. To our knowledge, there has been no investigation on a greedy decoder designed to maximize the log-linear combination of models traditionally embedded in a phrase-based SMT system. This paper aims at filling this gap. We show that our implementation, although not as good as a state-of-the-art beam search DP-engine, is not far off. More interestingly, we report experiments on the Europarl corpus where the greedy search algorithm significantly 104 improves the"
2007.tmi-papers.13,2003.mtsummit-papers.54,0,0.111692,"likely that a DP-search will outperform our greedy implementation, hereafter named feGreedy. Therefore, it is natural to investigate whether any benefit would result from seeding feGreedy with the best translation produced by Pharaoh.5 The idea of cascading two translation engines has been pioneered within the wordbased Candide translation system (Berger et al., 1994). Unfortunately, the authors did not describe their local search engine, neither did they provide an evaluation of its benefits to the overall system. The cascading strategy received a more dedicated treatment in Marcu (2001) and Watanabe and Sumita (2003). In their work, the authors were seeding a word-based greedy search algorithm with examples extracted from a translation memory hoping to bias the search toward a better solution. Our motivation is slightly different however: we simply want to know whether the greedy strategy can overcome some search errors made by a phrase-based DP-search. 3 Experimental setup 3.1 Corpora We concentrated our efforts on the shared task of last year’s workshop on Statistical Machine Translation (Koehn and Monz, 2006) which consisted in translating Spanish, German and French texts into English and the reverse d"
2007.tmi-papers.13,2004.tmi-1.9,0,0.0853735,"Missing"
2008.eamt-1.17,N03-1017,0,0.0120284,"pendency does not occur in the phrase under consideration. The ordering of the features according to Information Gain values were consistent with that obtained for the Italian → English system of [6]. As expected, the source phrase as well as its concatenated POS tags are the most discriminative features for predicting the translation of the phrase. Immediate context words and POS tags are the next promising features, the right context being 6 7 8 It does perform slightly better than the IGTree algorithm used in [6]. We relied on an in-house version of the standard phrase extraction procedure [1] for collecting the context information required for each source phrase. Using POS instead of words as dependency targets slightly decreases performance. 116 12th EAMT conference, 22-23 September 2008, Hamburg, Germany more discriminative than the left one. Dependency-based features were found less informative, which can be explained by the fact that often, the immediate context already captures the discriminative information. In an attempt to boost the selection of the most probable target phrase according to context disambiguation, we added to the log-linear combination a binary feature prop"
2008.eamt-1.17,vilar-etal-2006-error,0,0.108912,"Missing"
2008.eamt-1.17,P07-1005,0,0.0616928,"lity P (e|f, C(f )) by simply normalizing those weights. We used the Tribl hybrid algorithm6 of the TiMBL software package [8] as a classifier. Building such a classifier is mainly a matter of collecting training examples {(hf, C(f )i, e)} for all the phrases f seen in context C(f ) and translated as e.7 This classification implicitly performs smoothing by returning the example in the tree matching on most features. In case of an exact match, the actual class (i.e. target phrase) seen in the training material is returned. In case of a mismatch, a majority vote is performed. Approaches such as [5, 6, 4] relied on information extracted from the immediate context of a source phrase. To begin with, we considered this information as well, and represented an example by a fixed-length vector encoding the words of the source phrase f , their POS tags, the POS tags of two words on the left and the two words on the right of f , as well as the associated words. This is illustrated in Figure 1. source our1 /prp [declaration2 /nn of3 /prp] rights4 /nns is5 /vbz unique6 /jj target notre1 d´eclaration2 des3 droits4 est5 unique6 example (hdeclaration of, nn prp,nil,prp,nns,vbz,nil,our,rights,isi,d´eclarati"
2008.eamt-1.17,2007.tmi-papers.28,0,0.228672,"rce phrase, and e is a target phrase. 114 12th EAMT conference, 22-23 September 2008, Hamburg, Germany existing word-sense disambiguation systems into a phrase-based SMT system. Both systems use local collocations and word and POS from the immediate context. In [3], bag-of-word context and basic dependency features are used. [5] trained Support Vector Machine classifiers for every possible candidate translation of a source phrase. They considered words of the immediate context (5 tokens to the left and to the right), n-grams (up to size 3) of words, POS and lemmas, as well as chunking labels. [6] trained a global memory-based classifier that performs implicit smoothing of the probability estimates. The classifier makes use of words and POS information of the immediate context of the phrase (2 tokens to the left and to the right). The experimental conditions and the gains reported in the aforementioned studies differ significantly. However, it is interesting to note that all but one attempts are considering English as the target language. Given the fact that this type of integration only requires linguistic analysis for the source language, we may interpret this as a particular difficu"
2008.eamt-1.17,2005.mtsummit-papers.11,0,0.0108207,"n the left one. Dependency-based features were found less informative, which can be explained by the fact that often, the immediate context already captures the discriminative information. In an attempt to boost the selection of the most probable target phrase according to context disambiguation, we added to the log-linear combination a binary feature proposed by [6] which equals 1 for the target phrase that obtains the highest probability P (e|f, C(f )), and 0 otherwise. 3 Experiments and evaluation 3.1 Baseline and context-aware systems We used the French-English Europarl bitext compiled by [9]. To keep the data to a manageable size, we considered a subset of 95,734 sentences that the Stanford parser [10] could parse,9 for training our global classifier. Following the standard practice, we performed phrase extraction for at most 7 word-long phrases using Giza++ and the grow-diag-final-and heuristics [1]. We obtained approximately 11,5M phrases; 3,7M of which are potentially useful for translating the dev and test corpora gathering 475 and 472 bisentences respectively. We built a baseline system from the set of contextless extracted biphrases. We investigated two context-aware system"
2008.eamt-1.17,de-marneffe-etal-2006-generating,0,0.00595076,"ften, the immediate context already captures the discriminative information. In an attempt to boost the selection of the most probable target phrase according to context disambiguation, we added to the log-linear combination a binary feature proposed by [6] which equals 1 for the target phrase that obtains the highest probability P (e|f, C(f )), and 0 otherwise. 3 Experiments and evaluation 3.1 Baseline and context-aware systems We used the French-English Europarl bitext compiled by [9]. To keep the data to a manageable size, we considered a subset of 95,734 sentences that the Stanford parser [10] could parse,9 for training our global classifier. Following the standard practice, we performed phrase extraction for at most 7 word-long phrases using Giza++ and the grow-diag-final-and heuristics [1]. We obtained approximately 11,5M phrases; 3,7M of which are potentially useful for translating the dev and test corpora gathering 475 and 472 bisentences respectively. We built a baseline system from the set of contextless extracted biphrases. We investigated two context-aware systems as well. System S1 uses the features from the immediate context only and is a replication of the system describ"
2008.eamt-1.17,P03-1021,0,0.00497162,"We investigated two context-aware systems as well. System S1 uses the features from the immediate context only and is a replication of the system described in [6]. System S2 uses the same features plus the 16 most informative dependency features found empirically. Following a practical note in [7], we filtered out from the phrase tables of S1 and S2 entries for which p(e|f ) &lt; 0.0002. This reduces experimentation time dramatically without impacting translation results very much. No such filtering was done for the baseline system. Models weights were optimized using Minimum Error Rate Training [11], and decoding was performed using the Moses10 open source PBSMT decoder. All of our translation engines share the same target language model: a Kneser-Ney smoothed trigram model we trained on the French part of the whole Europarl corpus thanks to the SRILM toolkit [12]. For running S1 and S2 systems, we proceeded sentence by sentence. We first classified each sequence of words of a given sentence offline, thus producing a context-aware phrase-table. This table was merged to the main one. Since Moses is not designed to handle context-dependent phrases, we had to serialize each token in the sou"
2008.eamt-1.17,2007.mtsummit-papers.11,0,\N,Missing
2008.eamt-1.17,D08-1076,0,\N,Missing
2008.jeptalnrecital-long.12,H94-1028,0,0.151709,"Missing"
2008.jeptalnrecital-long.12,J93-2003,0,0.0147127,"Missing"
2008.jeptalnrecital-long.12,W07-0726,0,0.0612865,"Missing"
2008.jeptalnrecital-long.12,P07-2054,0,0.062094,"Missing"
2008.jeptalnrecital-long.12,2007.mtsummit-papers.18,0,0.0699354,"Missing"
2008.jeptalnrecital-long.12,2003.mtsummit-papers.15,1,0.796034,"Missing"
2008.jeptalnrecital-long.12,2001.mtsummit-papers.22,0,0.0532891,"Missing"
2008.jeptalnrecital-long.12,N03-1010,0,0.604819,"Missing"
2008.jeptalnrecital-long.12,P01-1030,0,0.443592,"Missing"
2008.jeptalnrecital-long.12,W06-3114,0,0.0688186,"Missing"
2008.jeptalnrecital-long.12,N03-1017,0,0.0447604,"Missing"
2008.jeptalnrecital-long.12,2007.tmi-papers.13,1,0.559678,"Missing"
2008.jeptalnrecital-long.12,P01-1050,0,0.0630531,"Missing"
2008.jeptalnrecital-long.12,P98-2158,0,0.0710151,"Missing"
2008.jeptalnrecital-long.12,W06-3121,0,0.041521,"Missing"
2008.jeptalnrecital-long.12,P02-1040,0,0.0754856,"Missing"
2008.jeptalnrecital-long.12,patry-etal-2006-mood,1,0.892826,"Missing"
2008.jeptalnrecital-long.12,W07-0728,0,0.0680424,"Missing"
2008.jeptalnrecital-long.12,P97-1037,0,0.76071,"Missing"
2008.jeptalnrecital-long.12,P97-1047,0,0.115509,"Missing"
2008.jeptalnrecital-long.12,2003.mtsummit-papers.54,0,0.0638362,"Missing"
2008.jeptalnrecital-long.12,2004.tmi-1.9,0,0.0638784,"Missing"
2009.eamt-1.4,J93-2003,0,0.0157262,"Missing"
2009.eamt-1.4,2008.amta-govandcom.17,0,0.352256,"Missing"
2009.eamt-1.4,2005.eamt-1.9,0,0.0405673,"Missing"
2009.eamt-1.4,J03-1002,0,0.00690451,"Missing"
2009.eamt-1.4,W03-0313,0,0.661906,"Missing"
2009.eamt-1.4,W02-1001,0,0.031492,"Missing"
2009.eamt-1.4,P03-1041,0,0.658384,"Missing"
2009.eamt-1.4,C96-2141,0,0.637512,"Missing"
2009.jeptalnrecital-long.11,2005.eamt-1.9,0,0.0574485,"Missing"
2009.jeptalnrecital-long.11,W02-1001,0,0.0203214,"Missing"
2009.jeptalnrecital-long.11,2008.amta-govandcom.17,0,0.0842464,"Missing"
2009.jeptalnrecital-long.11,1999.mtsummit-1.48,0,0.0468347,"Missing"
2009.jeptalnrecital-long.11,W03-0313,0,0.557513,"Missing"
2009.jeptalnrecital-long.11,C96-2141,0,0.46216,"Missing"
2009.jeptalnrecital-long.11,J93-2003,0,\N,Missing
2009.jeptalnrecital-long.16,2007.mtsummit-tutorials.1,0,0.260788,"ystème standard de traduction statistique basé sur les segments, le score attribué aux différentes traductions d’un segment ne dépend pas du contexte dans lequel il apparaît. Plusieurs travaux récents tendent à montrer l’intérêt de prendre en compte le contexte source lors de la traduction, mais ces études portent sur des systèmes traduisant vers l’anglais, une langue faiblement fléchie. Dans cet article, nous décrivons nos expériences sur la prise en compte du contexte source dans un système statistique traduisant de l’anglais vers le français, basé sur l’approche proposée par Stroppa et al. (2007). Nous étudions l’impact de différents types d’indices capturant l’information contextuelle, dont des dépendances syntaxiques typées. Si les mesures automatiques d’évaluation de la qualité d’une traduction ne révèlent pas de gains significatifs de notre système par rapport à un système à l’état de l’art ne faisant pas usage du contexte, une évaluation manuelle conduite sur 100 phrases choisies aléatoirement est en faveur de notre système. Cette évaluation fait également ressortir que la prise en compte de certaines dépendances syntaxiques est bénéfique à notre système. Abstract. In standard ph"
2009.jeptalnrecital-long.16,de-marneffe-etal-2006-generating,0,0.0327867,"Missing"
2009.jeptalnrecital-long.16,W07-0719,0,0.0348446,"Missing"
2009.jeptalnrecital-long.16,W08-0302,0,0.0273901,"Missing"
2009.jeptalnrecital-long.16,2005.mtsummit-papers.11,0,0.0727143,"Missing"
2009.jeptalnrecital-long.16,N03-1017,0,0.0224914,"Missing"
2009.jeptalnrecital-long.16,2006.jeptalnrecital-long.19,1,0.712081,"Missing"
2009.jeptalnrecital-long.16,2008.jeptalnrecital-long.22,0,0.0905881,"Missing"
2009.jeptalnrecital-long.16,P03-1021,0,0.0092088,"Missing"
2009.jeptalnrecital-long.16,2007.tmi-papers.28,0,0.0472749,"Missing"
2009.jeptalnrecital-long.16,vilar-etal-2006-error,0,0.0501421,"Missing"
2009.jeptalnrecital-long.8,2007.mtsummit-papers.19,0,0.609742,"Missing"
2009.jeptalnrecital-long.8,hathout-2002-wordnet,0,0.835346,"Missing"
2009.jeptalnrecital-long.8,W08-2001,0,0.637212,"Missing"
2009.jeptalnrecital-long.8,C08-2013,1,0.723522,"Missing"
2009.jeptalnrecital-long.8,E09-1056,1,0.825294,"Missing"
2009.jeptalnrecital-long.8,P98-1120,0,0.104361,"Missing"
2009.jeptalnrecital-long.8,W05-0616,0,0.459528,"Missing"
2009.jeptalnrecital-long.8,C98-1116,0,\N,Missing
2009.mtsummit-papers.12,P07-1020,0,0.482147,"min de la Tour Montr´eal (Qu´ebec), Canada H3T 1J4 felipe@iro.umontreal.ca tures observed outside of the alignment. This technique has improved word alignments (Zhao and Xing, 2006), phrase-based translation (Carpuat and Wu, 2007; Stroppa et al., 2007) and hierarchical translation (Chan et al., 2007). Another alternative explored is to select (Hildebrand et al., 2005) or weight (L¨u et al., 2007) the training material according to the source sentence. In this setting, the context of an alignment is captured by giving a greater importance to translations occurring in similar contexts. Finally, Bangalore et al. (2007) presented a global lexical selection model that gets rid of alignments altogether and conditions the probability of each target word on the whole source sentence. They used logistic regression models representing a source sentence with a set of ngrams and classifying each target word as present or absent in the translation. The selected words are then passed to a second module, which searches for their best ordering. Our work is in line with their idea and introduces a global lexical selection model which uses a multilayer perceptron taking as input a bag-of-words. The differences between the"
2009.mtsummit-papers.12,J93-2003,0,0.0192258,"concepts. Experiments Data We evaluated our system on a subset of the English and French parts of EUROPARL (Koehn, 2005), a corpus extracted from the proceedings of the European Parliament. We used 100, 000 sentence pairs to train our models (TRAIN), 10, 000 to compare them at different training stages (DEV) and 2, 000 other sentence pairs (TEST) to evaluate the models that performed best on DEV . 4.2 Baselines The first baseline against which we compared our model is an IBM 1 model computed by GIZA ++ (Och and Ney, 2003) with its default configuration1 , the only alignment model presented by Brown et al. (1993) which does not account for the order of source words. We evaluated IBM 1 as: ! X 1 Pr(t|s) = Pr(t|) + Pr(t|s) (7) 1 + |s| s∈s where  is a special null word.2 When Och et al. (2004) evaluated different rescoring features to enhance statistical machine translation, they got one of their best improvement with IBM 1. Our second baseline is a perceptron (Equation 2) where each source word is linked to its 10 best translations according to IBM 1.3 4.3 Multilayer Perceptrons The results reported in this section were obtained from a MLP with 500 hidden units (henceforth MLP). MLP has no links betwe"
2009.mtsummit-papers.12,D07-1007,0,0.102013,"are de cette (of this). It is easy to imagine a sentence where the translation should be plante the botanical term (“The leaves of this plant are red.”) and another where it should be usine the building (“The walls of this plant are red.”). To overcome this limitation, Vickrey et al. (2005) proposed to condition the alignment score on feaPhilippe Langlais Universit´e de Montr´eal 2920 chemin de la Tour Montr´eal (Qu´ebec), Canada H3T 1J4 felipe@iro.umontreal.ca tures observed outside of the alignment. This technique has improved word alignments (Zhao and Xing, 2006), phrase-based translation (Carpuat and Wu, 2007; Stroppa et al., 2007) and hierarchical translation (Chan et al., 2007). Another alternative explored is to select (Hildebrand et al., 2005) or weight (L¨u et al., 2007) the training material according to the source sentence. In this setting, the context of an alignment is captured by giving a greater importance to translations occurring in similar contexts. Finally, Bangalore et al. (2007) presented a global lexical selection model that gets rid of alignments altogether and conditions the probability of each target word on the whole source sentence. They used logistic regression models repre"
2009.mtsummit-papers.12,P07-1005,0,0.108897,"tion should be plante the botanical term (“The leaves of this plant are red.”) and another where it should be usine the building (“The walls of this plant are red.”). To overcome this limitation, Vickrey et al. (2005) proposed to condition the alignment score on feaPhilippe Langlais Universit´e de Montr´eal 2920 chemin de la Tour Montr´eal (Qu´ebec), Canada H3T 1J4 felipe@iro.umontreal.ca tures observed outside of the alignment. This technique has improved word alignments (Zhao and Xing, 2006), phrase-based translation (Carpuat and Wu, 2007; Stroppa et al., 2007) and hierarchical translation (Chan et al., 2007). Another alternative explored is to select (Hildebrand et al., 2005) or weight (L¨u et al., 2007) the training material according to the source sentence. In this setting, the context of an alignment is captured by giving a greater importance to translations occurring in similar contexts. Finally, Bangalore et al. (2007) presented a global lexical selection model that gets rid of alignments altogether and conditions the probability of each target word on the whole source sentence. They used logistic regression models representing a source sentence with a set of ngrams and classifying each targ"
2009.mtsummit-papers.12,2005.eamt-1.19,0,0.0642071,"lant are red.”) and another where it should be usine the building (“The walls of this plant are red.”). To overcome this limitation, Vickrey et al. (2005) proposed to condition the alignment score on feaPhilippe Langlais Universit´e de Montr´eal 2920 chemin de la Tour Montr´eal (Qu´ebec), Canada H3T 1J4 felipe@iro.umontreal.ca tures observed outside of the alignment. This technique has improved word alignments (Zhao and Xing, 2006), phrase-based translation (Carpuat and Wu, 2007; Stroppa et al., 2007) and hierarchical translation (Chan et al., 2007). Another alternative explored is to select (Hildebrand et al., 2005) or weight (L¨u et al., 2007) the training material according to the source sentence. In this setting, the context of an alignment is captured by giving a greater importance to translations occurring in similar contexts. Finally, Bangalore et al. (2007) presented a global lexical selection model that gets rid of alignments altogether and conditions the probability of each target word on the whole source sentence. They used logistic regression models representing a source sentence with a set of ngrams and classifying each target word as present or absent in the translation. The selected words a"
2009.mtsummit-papers.12,N03-1017,0,0.0213015,"e using a multilayer perceptron. At the expense of ignoring word order and repetition, our model does not assume word alignments and consider all source words jointly when evaluating the probability of a target word. We compared our model against IBM 1 which does not consider word order either. Our model was comparable with IBM 1 when predicting the target words that should appear in the translation of a source sentence. When our model was extended to include alignment information, it surpassed IBM 1 on all the metrics we used. 1 Introduction When translating a sentence, a phrase-based model (Koehn et al., 2003) divides it in phrases that are translated individually and then reunited using a language model (usually a trigram) and a reordering model. A side effect of this strategy is that the dependencies between a target phrase and the words outside of its aligned source phrase are only captured by the language model. For example, such a system could be asked to translate plant in French knowing only that the last two words produced are de cette (of this). It is easy to imagine a sentence where the translation should be plante the botanical term (“The leaves of this plant are red.”) and another where"
2009.mtsummit-papers.12,2005.mtsummit-papers.11,0,0.0323655,"The hidden layer of our MLPs acts as a continuous space where the source words are projected. Even though this is not obvious to control, we hope the hidden units will capture concepts or topics. Translating a source bag-of-words is thus a two-step operation. It is first projected in a concept space that is then projected in the space of target words. This way, the probability of a target word can be increased by source words that never co-occurred with it as long as they express common concepts. Experiments Data We evaluated our system on a subset of the English and French parts of EUROPARL (Koehn, 2005), a corpus extracted from the proceedings of the European Parliament. We used 100, 000 sentence pairs to train our models (TRAIN), 10, 000 to compare them at different training stages (DEV) and 2, 000 other sentence pairs (TEST) to evaluate the models that performed best on DEV . 4.2 Baselines The first baseline against which we compared our model is an IBM 1 model computed by GIZA ++ (Och and Ney, 2003) with its default configuration1 , the only alignment model presented by Brown et al. (1993) which does not account for the order of source words. We evaluated IBM 1 as: ! X 1 Pr(t|s) = Pr(t|)"
2009.mtsummit-papers.12,D07-1036,0,0.0964773,"Missing"
2009.mtsummit-papers.12,J03-1002,0,0.00367842,"be increased by source words that never co-occurred with it as long as they express common concepts. Experiments Data We evaluated our system on a subset of the English and French parts of EUROPARL (Koehn, 2005), a corpus extracted from the proceedings of the European Parliament. We used 100, 000 sentence pairs to train our models (TRAIN), 10, 000 to compare them at different training stages (DEV) and 2, 000 other sentence pairs (TEST) to evaluate the models that performed best on DEV . 4.2 Baselines The first baseline against which we compared our model is an IBM 1 model computed by GIZA ++ (Och and Ney, 2003) with its default configuration1 , the only alignment model presented by Brown et al. (1993) which does not account for the order of source words. We evaluated IBM 1 as: ! X 1 Pr(t|s) = Pr(t|) + Pr(t|s) (7) 1 + |s| s∈s where  is a special null word.2 When Och et al. (2004) evaluated different rescoring features to enhance statistical machine translation, they got one of their best improvement with IBM 1. Our second baseline is a perceptron (Equation 2) where each source word is linked to its 10 best translations according to IBM 1.3 4.3 Multilayer Perceptrons The results reported in this sec"
2009.mtsummit-papers.12,2007.tmi-papers.28,0,0.3768,"Missing"
2009.mtsummit-papers.12,H05-1097,0,0.137446,"ually a trigram) and a reordering model. A side effect of this strategy is that the dependencies between a target phrase and the words outside of its aligned source phrase are only captured by the language model. For example, such a system could be asked to translate plant in French knowing only that the last two words produced are de cette (of this). It is easy to imagine a sentence where the translation should be plante the botanical term (“The leaves of this plant are red.”) and another where it should be usine the building (“The walls of this plant are red.”). To overcome this limitation, Vickrey et al. (2005) proposed to condition the alignment score on feaPhilippe Langlais Universit´e de Montr´eal 2920 chemin de la Tour Montr´eal (Qu´ebec), Canada H3T 1J4 felipe@iro.umontreal.ca tures observed outside of the alignment. This technique has improved word alignments (Zhao and Xing, 2006), phrase-based translation (Carpuat and Wu, 2007; Stroppa et al., 2007) and hierarchical translation (Chan et al., 2007). Another alternative explored is to select (Hildebrand et al., 2005) or weight (L¨u et al., 2007) the training material according to the source sentence. In this setting, the context of an alignment"
2009.mtsummit-papers.12,P06-2124,0,0.0132681,"h knowing only that the last two words produced are de cette (of this). It is easy to imagine a sentence where the translation should be plante the botanical term (“The leaves of this plant are red.”) and another where it should be usine the building (“The walls of this plant are red.”). To overcome this limitation, Vickrey et al. (2005) proposed to condition the alignment score on feaPhilippe Langlais Universit´e de Montr´eal 2920 chemin de la Tour Montr´eal (Qu´ebec), Canada H3T 1J4 felipe@iro.umontreal.ca tures observed outside of the alignment. This technique has improved word alignments (Zhao and Xing, 2006), phrase-based translation (Carpuat and Wu, 2007; Stroppa et al., 2007) and hierarchical translation (Chan et al., 2007). Another alternative explored is to select (Hildebrand et al., 2005) or weight (L¨u et al., 2007) the training material according to the source sentence. In this setting, the context of an alignment is captured by giving a greater importance to translations occurring in similar contexts. Finally, Bangalore et al. (2007) presented a global lexical selection model that gets rid of alignments altogether and conditions the probability of each target word on the whole source sent"
2009.mtsummit-papers.12,N04-1021,0,\N,Missing
2009.mtsummit-posters.9,J93-2003,0,0.00920608,"n Figure 1(b), conforme ` a and respecte are 2 of the 103 transpots displayed to the user for the query in keeping with. 2.1 Word Alignment Word alignment is a key component of the transpotting task. Given a source sentence S = s1 ...sn and a target sentence T = t1 ...tm in translation relation, an IBM-style alignment a = a1 ...am connects each target token to a source one (aj ∈ {1, ..., n}) or to the so-called NULL token which accounts for untranslated target tokens, and which is arbitrarily set to the source position 0 (aj = 0). Several word-alignment models are introduced and discussed in (Brown et al., 1993). They differ by the expression of the joint probability of a target sentence and its alignment, given the source sentence. As we do not want to keep the precomputed alignments of each sentence pairs, we decided to use the IBM model 2 which allows our system to quickly manage on-line hundreds of pairs of sentences retrieved for a given query. This model is expressed by: m n p(tm 1 , a1 |s1 ) = m Y Figure 2: Example of word alignment generated by an IBM model 2 that leads to an erroneous transpot for the query in keeping with. 2.2 Transpotting Algorithm In this work, we implemented a variant o"
2009.mtsummit-posters.9,2009.eamt-1.4,1,0.789456,"the French sentence is much harder to identify. Professional translators are quick to locate the matches but they must often go through many sentences to find different translations. Currently, the system displays the sentences in reverse chronological order of dates of the documents. Identifying the matching substring in the other language enables a better display of the results by grouping them as shown in Figure 1(b). To do so, we collect all these substrings for a given query and merge close variants, such as the inflected forms of the same lemmas, according to the procedure described in (Huet et al., 2009). In the displayed example, the user can easily browse the 103 different French translations identified for in keeping with among 371 sentence pairs. The most frequent translations are conforme ` a, conform´ ement ` a, respecte, correspondant ` a, etc. Clicking on a translation shows the two most recent occurrences and clicking on the number below the second translation displays all of them. (a) Current system. (b) Development version. Figure 1: Results to the query in keeping with with the current version (a) and the future version (b) of T RANS S EARCH. This last version groups the translati"
2009.mtsummit-posters.9,2008.amta-govandcom.17,1,0.720278,"ory (TM) systems and bilingual concordancers. Both tools exploit a TM composed of a bitext: a set of pairs of units (typically sentences) that are in translation relation. Whereas a TM system is a translation device, a bilingual concordancer is conceptually simpler, since its main purpose is to retrieve from a bitext, the pairs of units that contain a query (typically a phrase) that a user manually submits. It is then left to the user to locate the relevant material in the retrieved target units. As simple as it may appear, a bilingual concordancer is nevertheless a very popular CAT tool. In (Macklovitch et al., 2008), the authors report that T RANS S EARCH,1 the commercial 1 www.tsrali.com web-based concordancer we focus on in this study, received an average of 177 000 queries a month over a one-year period (2006–2007). Figure 1(a) shows the first three search results found by the current version of T RANS S EARCH for the English phrase in keeping with in a bitext composed of sentences from the Canadian Hansards. Once the system has identified English sentences containing the query, it displays them with the corresponding French sentence. Although the substring of the English sentence can be highlighted e"
2009.mtsummit-posters.9,W03-0313,0,0.815193,"the number below the second translation displays all of them. (a) Current system. (b) Development version. Figure 1: Results to the query in keeping with with the current version (a) and the future version (b) of T RANS S EARCH. This last version groups the translations before the display; the user can thus know right away the whole gamut of translations that were found in the bitext. For the first suggested translation, the two substrings highlighted in the targer parts were considered as variants of conforme ` a, according to the merging process described in (Huet et al., 2009). Following (Simard, 2003), we call translation spotting or transpotting the process of identifying the different translations of a user query in a bitext. The first idea that comes to mind is using word alignment, a common task in Statistical Machine Translation (SMT). Unfortunately, merely relying on maximal word alignment scores does not give satisfactory results. While in SMT, word alignment is one component of a complete pipeline, in our application, its results are directly visible by the user. In many cases, they are a a bit off : the spotted translation may be incomplete, too long or completely miss the right t"
2009.mtsummit-posters.9,P03-1041,0,0.0181874,"eep the precomputed alignments of each sentence pairs, we decided to use the IBM model 2 which allows our system to quickly manage on-line hundreds of pairs of sentences retrieved for a given query. This model is expressed by: m n p(tm 1 , a1 |s1 ) = m Y Figure 2: Example of word alignment generated by an IBM model 2 that leads to an erroneous transpot for the query in keeping with. 2.2 Transpotting Algorithm In this work, we implemented a variant of the transpotting algorithm initially proposed by Simard (2003), which shares some similarity with the phrase extraction technique described in (Venugopal et al., 2003). For each pair hj1 , j2 i ∈ [1, m] × [1, m], two Viterbi alignments are computed: one between the phrase tjj21 and the query sii21 , and one between the remaining material in the sentences s¯ii21 ≡ si11 −1 sni2 +1 and t¯jj21 ≡ t1j1 −1 tm j2 +1 . This method finds the translation of the query according to:   maxaj2 p(ajj21 |sii21 , tjj21 )   j1 ˆ × tˆˆjj2 = argmax 1 (j1 ,j2 )    max j2 p(¯ ajj21 |¯ sii21 , t¯jj21 ) a ¯ j1 p(tj |saj ) × p(aj |j, m, n) j=1 where  is the length distribution, the first term inside the product is the transfer or lexical distribution and the second one is th"
2009.mtsummit-posters.9,C96-2141,0,0.121935,"rly improves precision scores for the transpotting and the translation tasks, two metrics we consider as important in our application. More specifically, the SRF method has a better ability to spot a translation in a given pair of sentences, while the PRF method tends to reduce the number of suggested translations to a query. Albeit these results are encouraging, we are facing an evaluation problem inherent to interactive applications. Ultimately, this will involve the development of test cases with real users of the application. We are currently experimenting the use of HMM alignment models (Vogel et al., 1996) in our transpotting algorithms as alternative to the IBM model 2. Finally, our approach might be applied to the more general task of acquiring a phrase table in SMT. As a matter of fact, a phrase in such a system plays a similar role to a query in our setting. Therefore, apλ 0 0.01 0.06 0.5 1 score rec prec rec prec rec prec rec prec rec prec transpotting 72.6 85.6 77.6 85.7 80.5 84.8 83.9 81.3 83.7 78.7 translation 61.9 18.0 74.9 18.5 79.9 18.2 82.6 16.2 82.6 14.7 Table 1: Scores of the SRF method for the transpotting and translation tasks according to the parameter λ on the TEST corpus. λ ="
2010.jeptalnrecital-court.21,2002.jeptalnrecital-long.5,0,0.144701,"Missing"
2010.jeptalnrecital-court.21,2009.jeptalnrecital-long.21,0,0.0613976,"Missing"
2010.jeptalnrecital-court.21,P98-2127,0,0.645278,"Missing"
2010.jeptalnrecital-court.21,C94-1049,0,0.861462,"Missing"
2010.jeptalnrecital-court.21,P06-2111,0,0.261634,"Missing"
2010.jeptalnrecital-demonstration.14,2008.amta-govandcom.17,1,0.800507,"Missing"
2010.jeptalnrecital-long.2,2009.jeptalnrecital-long.11,1,0.882278,"Missing"
2010.jeptalnrecital-long.2,2009.mtsummit-posters.9,1,0.859649,"Missing"
2010.jeptalnrecital-long.2,P07-2045,0,0.0039257,"Missing"
2010.jeptalnrecital-long.2,P04-1066,0,0.0595949,"Missing"
2010.jeptalnrecital-long.2,W03-0313,0,0.0723615,"Missing"
2010.jeptalnrecital-long.2,C96-2141,0,0.402202,"Missing"
2010.jeptalnrecital-long.38,2007.mtsummit-papers.19,0,0.0865049,"Missing"
2010.jeptalnrecital-long.38,J01-2001,0,0.0263226,"Missing"
2010.jeptalnrecital-long.38,hathout-2002-wordnet,0,0.061967,"Missing"
2010.jeptalnrecital-long.38,W08-2001,0,0.0237089,"Missing"
2010.jeptalnrecital-long.38,2009.jeptalnrecital-long.8,1,0.840647,"Missing"
2010.jeptalnrecital-long.38,D07-1092,1,0.892158,"Missing"
2010.jeptalnrecital-long.38,W07-1315,0,0.0346781,"Missing"
2010.jeptalnrecital-long.38,W05-0616,0,0.0764238,"Missing"
2010.jeptalnrecital-long.38,P00-1027,0,0.0277649,"Missing"
2011.jeptalnrecital-long.15,apidianaki-2008-translation,0,0.0369232,"Missing"
2011.jeptalnrecital-long.15,P05-1074,0,0.0589816,"Missing"
2011.jeptalnrecital-long.15,P01-1008,0,0.0646748,"Missing"
2011.jeptalnrecital-long.15,W02-0908,0,0.155683,"action de synonymes à partir d’un corpus en français. Nous présentons ici une analyse plus fine des relations extraites automatiquement en nous intéressant cette fois-ci à la langue anglaise pour laquelle de plus amples ressources sont disponibles. Différentes façons d’évaluer notre approche corroborent le fait que l’approche miroir se comporte globalement mieux que l’approche distributionnelle décrite dans (Lin, 1998), une approche de référence dans le domaine. Abstract. In (Muller & Langlais, 2010), we compared a distributional approach to a variant of the mirror approach described by Dyvik (2002) on a task of synonym extraction. This was conducted on a corpus of the French language. In the present work, we propose a more precise and systematic evaluation of the relations extracted by a mirror and a distributional approaches. This evaluation is conducted on the English language for which widespread resources are available. All the evaluations we conducted in this study concur to the observation that our mirror approach globally outperforms the distributional one described by Lin (1998), which we believe to be a fair reference in the domain. Mots-clés : Sémantique lexicale, similarité d"
2011.jeptalnrecital-long.15,J02-2001,0,0.0557527,"Missing"
2011.jeptalnrecital-long.15,ferret-2010-testing,0,0.0209747,"Missing"
2011.jeptalnrecital-long.15,W05-0604,0,0.0331901,"Missing"
2011.jeptalnrecital-long.15,heylen-etal-2008-modelling,0,0.0556461,"Missing"
2011.jeptalnrecital-long.15,E93-1028,0,0.333377,"Missing"
2011.jeptalnrecital-long.15,P98-2127,0,0.192429,"Missing"
2011.jeptalnrecital-long.15,W08-1911,0,0.0380589,"Missing"
2011.jeptalnrecital-long.15,C82-1036,0,0.700615,"Missing"
2011.jeptalnrecital-long.15,P04-1066,0,0.0820315,"Missing"
2011.jeptalnrecital-long.15,2010.jeptalnrecital-court.21,1,0.852559,"Missing"
2011.jeptalnrecital-long.15,C94-1049,0,0.18905,"Missing"
2011.jeptalnrecital-long.15,C08-1114,0,0.0558635,"Missing"
2011.jeptalnrecital-long.15,P06-2111,0,0.0388452,"Missing"
2011.jeptalnrecital-long.15,J09-3004,0,0.0374471,"Missing"
2012.amta-papers.2,E09-1003,0,0.0210514,"E which are wrong or partial when aligned with C-HMM-bi only, but correct when aligned with our 2stage approach using the same alignment algorithm. ing, while the ones identified after the second stage are typically more faithful to the reference translation. This is the case even if the transpots proposed by the two methods often differ in their boundaries only. 6 Related Works Improving word-alignment by exploiting more data has been the focus of some studies. In particular, it was shown that acquiring comparable data from external resources is a fruitful strategy (Munteanu and Marcu, 2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al."
2012.amta-papers.2,P05-1074,0,0.0449043,"l of Vogel et al. (1996). Moore (2004) proposed to smooth IBM model 1 translation model, especially the count of rare events. Foster et al. (2006) proposed to smooth a phrase-based translation model. These works correct the estimated probabilities of rare events by smoothing lexical distributions. While they attempt to smooth the whole lexical model once for all, we propose a smoothing local to each rare event and dependent of the translation process. In paraphrase extraction, approaches have been proposed to extract paraphrases from bilingual data by relying on phrase-based alignment models (Bannard and Callison-Burch, 2005; Callison-Burch, 2008; Max, 2010). Although our approach is different, identifying a query’s rare translation can been seen as recognizing that this translation is a paraphrase of a query’s frequent translation. 7 Conclusion and Future Work We proposed an original method that improves the transpotting of infrequent translations. To overcome the lack of additional data, this method uses non parallel sentences sampled from the training material in order to adapt the lexical distribution used to transpot a given query. The experiments we conducted exhibit significant gains in identifying rare tr"
2012.amta-papers.2,W09-0432,0,0.0183576,"s, making the approach very tractable. - X X X X X X - X X Figure 2: Transpot distribution for the query wait and see. For each transpot, we mention: its frequency; whether it is a frequency-1 transpot; and whether it is a wrong, partial or good transpot. For our approach to work, we need to specify two elements: how to gather the material used to adapt the lexical distributions of the alignment model, and how to adapt the model. 2.1 Gathering Non Parallel Sentence Pairs Adapting lexical models usually involves more or dedicated parallel data (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Bertoldi and Federico, 2009). In this paper, we exploit an already large training set and we do not seek for external data. Indeed, since we are dealing with infrequent translations, there is no extra parallel data on top of the seed sentences that we can exploit. Rather, we propose an empirical way to better exploit the training data. For each seed sentence pair, we randomly sample from the training data source sentences where the query occurs. We artificially associate them to the target seed sentence which contains the frequency-1 suspicious transpot. This gives a set of non parallel sentence pairs to which we add the"
2012.amta-papers.2,P06-1009,0,0.0177598,"2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need such manual training data. Comparing our approach to this one would be interesting. In the eventuality that it outperforms our approach, embedding it into our 2-stage framework could be attempted, as planned in future work. Some works have been proposed to smooth translation models. Toutanova et al. (2002) used POS tags for smoothing translation di"
2012.amta-papers.2,J93-2003,0,0.0582667,"using Eq. (1). Since there is no reason why the local distribution would improve the alignment of words outside the query, the combination in Eq. (1) is only applied when transporting words of the query. For the other words, the global distribution is used, as in the first transpotting stage. In the end, the result of this second transpotting stage is returned to the user with the hope that it is more accurate than the transpot identified in the first place for the query in the seed sentence pair. 3 Transpotting Algorithms IBM models are natural contenders for tackling the transpotting task (Brown et al., 1993). Formally, given a source language sentence S = s1 ...sn and its target language translation T = t1 ...tm , an IBMstyle alignment a = a1 ...am links each word of T to a word of S (aj ∈ {1, ..., n}) or to the empty word (aj = 0) which is arbitrarily associated to untranslated words. For the IBM model 2, the joint probability of a target sentence and its alignment given the source sentence is expressed by: m n p(tm 1 , a1 |s1 ) = p(m|n) m Y p(tj |saj )×p(aj |j, m, n) tained by maximizing:     j2 i2 ¯j2 j2 i2 j2 aj1 |¯ s i1 , t j1 ) argmax max p(aj1 |si1 , tj1 ) × max p(¯ j  j1 ,j2  aj2 a"
2012.amta-papers.2,2005.eamt-1.9,0,0.131613,"show that using only a few pairs of non parallel sentences allows to improve significantly the alignment of infrequent translations. 1 Introduction The task of transpotting consists in identifying the translation of a given sequence of words, hereafter called the query, in a pair of parallel sentences (Simard, 2003). While transpotting may be seen as a special case of word aligning pairs of parallel sentences, which is the bread and butter of Machine Translation (MT), this task deserves to be evaluated as such. Indeed, transpotting is at the heart of bilingual concordancers (Wu et al., 2003; Callison-Burch et al., 2005; Bourdaillet et al., 2010; D´esilets et al., 2010), and professional translators in the translation industry rely heavily on such Computer Assisted Translation (CAT) tools (Bowker and Barlow, 2008; Macklovitch et al., 2008; Koehn, 2009; Paulsen Christensen and Schjoldager, 2010; Karamanis et al., 2011). Figure 1 illustrates the answer provided by the bilingual concordancer Tradooit1 for the English 1 http://www.tradooit.com Philippe Langlais DIRO/RALI Universit´e de Montr´eal Montr´eal, Canada H3C 3J7 felipe@iro.umontreal.ca query meanwhile. Typically, a concordancer returns pairs of sentence"
2012.amta-papers.2,D08-1021,0,0.0243087,"004) proposed to smooth IBM model 1 translation model, especially the count of rare events. Foster et al. (2006) proposed to smooth a phrase-based translation model. These works correct the estimated probabilities of rare events by smoothing lexical distributions. While they attempt to smooth the whole lexical model once for all, we propose a smoothing local to each rare event and dependent of the translation process. In paraphrase extraction, approaches have been proposed to extract paraphrases from bilingual data by relying on phrase-based alignment models (Bannard and Callison-Burch, 2005; Callison-Burch, 2008; Max, 2010). Although our approach is different, identifying a query’s rare translation can been seen as recognizing that this translation is a paraphrase of a query’s frequent translation. 7 Conclusion and Future Work We proposed an original method that improves the transpotting of infrequent translations. To overcome the lack of additional data, this method uses non parallel sentences sampled from the training material in order to adapt the lexical distribution used to transpot a given query. The experiments we conducted exhibit significant gains in identifying rare translations by making u"
2012.amta-papers.2,2010.iwslt-papers.3,0,0.0146261,"hen aligned with C-HMM-bi only, but correct when aligned with our 2stage approach using the same alignment algorithm. ing, while the ones identified after the second stage are typically more faithful to the reference translation. This is the case even if the transpots proposed by the two methods often differ in their boundaries only. 6 Related Works Improving word-alignment by exploiting more data has been the focus of some studies. In particular, it was shown that acquiring comparable data from external resources is a fruitful strategy (Munteanu and Marcu, 2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al"
2012.amta-papers.2,2009.mtsummit-btm.5,0,0.060556,"Missing"
2012.amta-papers.2,P11-1042,0,0.0178695,"ng data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need such manual training data. Comparing our approach to this one would be interesting. In the eventuality that it outperforms our approach, embedding it into our 2-stage framework could be attempted, as planned in future work. Some works have been proposed to smooth translation models. Toutanova et al. (2002) used POS tags for smoothing translation distributions in the HMM alignment model of Vogel et al. (1996). Moore (2004) proposed to smooth IBM model 1 translation model, especially the count of rare events. Foster et al. (2006) proposed t"
2012.amta-papers.2,W07-0717,0,0.0302474,"e Freq using only a few non parallel sentence pairs, making the approach very tractable. - X X X X X X - X X Figure 2: Transpot distribution for the query wait and see. For each transpot, we mention: its frequency; whether it is a frequency-1 transpot; and whether it is a wrong, partial or good transpot. For our approach to work, we need to specify two elements: how to gather the material used to adapt the lexical distributions of the alignment model, and how to adapt the model. 2.1 Gathering Non Parallel Sentence Pairs Adapting lexical models usually involves more or dedicated parallel data (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Bertoldi and Federico, 2009). In this paper, we exploit an already large training set and we do not seek for external data. Indeed, since we are dealing with infrequent translations, there is no extra parallel data on top of the seed sentences that we can exploit. Rather, we propose an empirical way to better exploit the training data. For each seed sentence pair, we randomly sample from the training data source sentences where the query occurs. We artificially associate them to the target seed sentence which contains the frequency-1 suspicious transpot. This gives"
2012.amta-papers.2,W06-1607,0,0.173561,"e that the scores of all algorithms drop significantly. This shows that identifying rare translations of a query is harder than identifying frequent ones, and this, even if rare translations in our test set are composed of frequent words (see Section 4.1). The large drop of the PBM algorithm might seem surprising. It is explained by the fact that often, a query/rare translation pair is not kept by the grow-diag-final heuristic of MOSES, due to a failure of the word alignment models being used. This highlights a shortcoming of phrase-based models when dealing with rare events, as described in (Foster et al., 2006). Note that some kind of SMT decoder could be used to enhance the PBM algorithm. Nevertheless, it seemed more rational to us to focus on pure word-alignment based techniques. 5.3 2-stage Translation Spotting The third experiment evaluates the performance of the 2-stage method described in Section 2. We considered the three best transpotting algorithms for identifying rare translations, as identified in the previous section. Results are presented in Table 3 when using 200 non parallel sentence pairs for building the artificial bitext of each sentence pair. In Figure 5, the results are plotted a"
2012.amta-papers.2,W11-1207,0,0.0160232,"-bi only, but correct when aligned with our 2stage approach using the same alignment algorithm. ing, while the ones identified after the second stage are typically more faithful to the reference translation. This is the case even if the transpots proposed by the two methods often differ in their boundaries only. 6 Related Works Improving word-alignment by exploiting more data has been the focus of some studies. In particular, it was shown that acquiring comparable data from external resources is a fruitful strategy (Munteanu and Marcu, 2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually"
2012.amta-papers.2,W07-0733,0,0.0238822,"non parallel sentence pairs, making the approach very tractable. - X X X X X X - X X Figure 2: Transpot distribution for the query wait and see. For each transpot, we mention: its frequency; whether it is a frequency-1 transpot; and whether it is a wrong, partial or good transpot. For our approach to work, we need to specify two elements: how to gather the material used to adapt the lexical distributions of the alignment model, and how to adapt the model. 2.1 Gathering Non Parallel Sentence Pairs Adapting lexical models usually involves more or dedicated parallel data (Foster and Kuhn, 2007; Koehn and Schroeder, 2007; Bertoldi and Federico, 2009). In this paper, we exploit an already large training set and we do not seek for external data. Indeed, since we are dealing with infrequent translations, there is no extra parallel data on top of the seed sentences that we can exploit. Rather, we propose an empirical way to better exploit the training data. For each seed sentence pair, we randomly sample from the training data source sentences where the query occurs. We artificially associate them to the target seed sentence which contains the frequency-1 suspicious transpot. This gives a set of non parallel sent"
2012.amta-papers.2,P07-2045,0,0.00973461,"nspotted after adapting online the lexical distribution, leading to significant improvements in terms of alignment. On top of improving the state-of-the art of transpotting, a task of practical importance for the translation industry, there are several contributions we would like to underline: • We show that a smart processing of non parallel sentence pairs from the training data can help statistical word alignment, a somehow surprising result. Our two-stage approach significantly outperforms the standard bidirectional IBM word-alignment combined with the mainstream grow-dial-final heuristic (Koehn et al., 2007) when aligning rare translations. • We demonstrate that our approach works while • We show that it is possible to enhance word alignment for infrequent events in the setting of a bilingual concordancer, which is an important concern for professional translators. The reminder of this paper is organized as follows. In Section 2, we describe our approach to enhance the alignment of infrequent translations. In Section 3, we present several state-of-the-art transpotting algorithms we compared. In Section 4, we present our experimental setup, and analyze our results in Section 5. We discuss related"
2012.amta-papers.2,J10-3002,0,0.0190638,"wenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need such manual training data. Comparing our approach to this one would be interesting. In the eventuality that it outperforms our approach, embedding it into our 2-stage framework could be attempted, as planned in future work. Some works have been proposed to smooth translation models. Toutanova et al. (2002) used POS tags for smoothing translation distributions in the"
2012.amta-papers.2,C08-1064,0,0.278816,"Missing"
2012.amta-papers.2,2008.amta-govandcom.17,0,0.023907,"equence of words, hereafter called the query, in a pair of parallel sentences (Simard, 2003). While transpotting may be seen as a special case of word aligning pairs of parallel sentences, which is the bread and butter of Machine Translation (MT), this task deserves to be evaluated as such. Indeed, transpotting is at the heart of bilingual concordancers (Wu et al., 2003; Callison-Burch et al., 2005; Bourdaillet et al., 2010; D´esilets et al., 2010), and professional translators in the translation industry rely heavily on such Computer Assisted Translation (CAT) tools (Bowker and Barlow, 2008; Macklovitch et al., 2008; Koehn, 2009; Paulsen Christensen and Schjoldager, 2010; Karamanis et al., 2011). Figure 1 illustrates the answer provided by the bilingual concordancer Tradooit1 for the English 1 http://www.tradooit.com Philippe Langlais DIRO/RALI Universit´e de Montr´eal Montr´eal, Canada H3C 3J7 felipe@iro.umontreal.ca query meanwhile. Typically, a concordancer returns pairs of sentences where the query and one of its translations are identified using word alignment. Based on these alignments, a distribution of translations, hereafter called transpots, is returned as well for the query. This gives a user"
2012.amta-papers.2,D10-1064,0,0.0135744,"h IBM model 1 translation model, especially the count of rare events. Foster et al. (2006) proposed to smooth a phrase-based translation model. These works correct the estimated probabilities of rare events by smoothing lexical distributions. While they attempt to smooth the whole lexical model once for all, we propose a smoothing local to each rare event and dependent of the translation process. In paraphrase extraction, approaches have been proposed to extract paraphrases from bilingual data by relying on phrase-based alignment models (Bannard and Callison-Burch, 2005; Callison-Burch, 2008; Max, 2010). Although our approach is different, identifying a query’s rare translation can been seen as recognizing that this translation is a paraphrase of a query’s frequent translation. 7 Conclusion and Future Work We proposed an original method that improves the transpotting of infrequent translations. To overcome the lack of additional data, this method uses non parallel sentences sampled from the training material in order to adapt the lexical distribution used to transpot a given query. The experiments we conducted exhibit significant gains in identifying rare translations by making use of only a"
2012.amta-papers.2,P06-1065,0,0.0258975,"Munteanu and Marcu, 2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need such manual training data. Comparing our approach to this one would be interesting. In the eventuality that it outperforms our approach, embedding it into our 2-stage framework could be attempted, as planned in future work. Some works have been proposed to smooth translation models. Toutanova et al. (2002) used POS tags for"
2012.amta-papers.2,P04-1066,0,0.0160593,"ly word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need such manual training data. Comparing our approach to this one would be interesting. In the eventuality that it outperforms our approach, embedding it into our 2-stage framework could be attempted, as planned in future work. Some works have been proposed to smooth translation models. Toutanova et al. (2002) used POS tags for smoothing translation distributions in the HMM alignment model of Vogel et al. (1996). Moore (2004) proposed to smooth IBM model 1 translation model, especially the count of rare events. Foster et al. (2006) proposed to smooth a phrase-based translation model. These works correct the estimated probabilities of rare events by smoothing lexical distributions. While they attempt to smooth the whole lexical model once for all, we propose a smoothing local to each rare event and dependent of the translation process. In paraphrase extraction, approaches have been proposed to extract paraphrases from bilingual data by relying on phrase-based alignment models (Bannard and Callison-Burch, 2005; Call"
2012.amta-papers.2,P06-1011,0,0.0221977,"ranslations from TEST R ARE which are wrong or partial when aligned with C-HMM-bi only, but correct when aligned with our 2stage approach using the same alignment algorithm. ing, while the ones identified after the second stage are typically more faithful to the reference translation. This is the case even if the transpots proposed by the two methods often differ in their boundaries only. 6 Related Works Improving word-alignment by exploiting more data has been the focus of some studies. In particular, it was shown that acquiring comparable data from external resources is a fruitful strategy (Munteanu and Marcu, 2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blun"
2012.amta-papers.2,J03-1002,0,0.0227114,"translation of a query. Therefore, we computed a second metric where we give a point to a transpot with at least one word correct. For example, when the translation is qui vivra verra, the transpot verra is considered correct with this metric. Since the transpotting algorithms always return a transpot, the number of returned transpots is the same as the number of reference translations; so for these tasks precision equals recall. 4.3 Training and Tuning The distributions required by the word-based transpotting algorithms described in Section 3 were obtained by running GIZA ++ on the Hansards (Och and Ney, 2003). IBM model 4 lexical distributions were used in this work, while the alignment distributions were coming from IBM2 or HMM models. The phrase table required by the phrase-based transpotting algorithm has been computed by MOSES in its default configuration. Equation (4) which combines lexical distributions obtained by training models in both translation directions requires a combination operator. We obtained the best results on DEV R ARE using the geometric mean. Equation (1) which combines global and local lexical distributions requires the optimization of the λ parameter that controls the lin"
2012.amta-papers.2,D10-1052,0,0.0207239,"o et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need such manual training data. Comparing our approach to this one would be interesting. In the eventuality that it outperforms our approach, embedding it into our 2-stage framework could be attempted, as planned in future work. Some works have been proposed to smooth translation models. Toutanova et al. (2002) used POS tags for smoothing translation distributions in the HMM alignment model of"
2012.amta-papers.2,W03-0313,0,0.443431,"ations is a difficult task. We propose a simple and original solution to this problem that yields to significant gains over a state-of-the-art transpotting task. Our approach consists in aligning non parallel sentences from the training data in order to reinforce online the alignment models. We show that using only a few pairs of non parallel sentences allows to improve significantly the alignment of infrequent translations. 1 Introduction The task of transpotting consists in identifying the translation of a given sequence of words, hereafter called the query, in a pair of parallel sentences (Simard, 2003). While transpotting may be seen as a special case of word aligning pairs of parallel sentences, which is the bread and butter of Machine Translation (MT), this task deserves to be evaluated as such. Indeed, transpotting is at the heart of bilingual concordancers (Wu et al., 2003; Callison-Burch et al., 2005; Bourdaillet et al., 2010; D´esilets et al., 2010), and professional translators in the translation industry rely heavily on such Computer Assisted Translation (CAT) tools (Bowker and Barlow, 2008; Macklovitch et al., 2008; Koehn, 2009; Paulsen Christensen and Schjoldager, 2010; Karamanis"
2012.amta-papers.2,W02-1012,0,0.0899498,"Missing"
2012.amta-papers.2,C96-2141,0,0.523262,"ion directions (IBM models are not symmetrical). For this, the lexical probability of a target word t given a source word s is reformulated as: j=1 (2) where p(m|n) is the sentence length probability, the first term of the product is the lexical probability, and the second term is the alignment probability. According to this formulation, the most probable alignm n ment of two sentences, argmaxam p(am 1 |t1 , s1 ), 1 can be efficiently computed in O(mn) time; we call it (by abuse of language) the Viterbi alignment. The hidden Markov alignment model (HMM) is a generalization of the IBM model 2 (Vogel et al., 1996). In this case, the alignment probability in Equation (2) is expressed by p(aj |aj−1 , n), where the alignment probability is designed by a first-order dependency: the alignment of a target word depends of the alignment of the preceding one. The Viterbi alignment is obtained by dynamic programming in O(mn2 ) time. A simple transpotting algorithm consists in computing the Viterbi alignment of a sentence pair using either an IBM model 2 or an HMM, then the target words which are aligned to the (source) query words correspond to the transpot. We call those algorithms IBM2 and HMM respectively. Un"
2012.amta-papers.2,2005.mtsummit-papers.33,0,0.0364087,"tion. This is the case even if the transpots proposed by the two methods often differ in their boundaries only. 6 Related Works Improving word-alignment by exploiting more data has been the focus of some studies. In particular, it was shown that acquiring comparable data from external resources is a fruitful strategy (Munteanu and Marcu, 2006; Abdul-Rauf and Schwenk, 2009; Cettolo et al., 2010; Gahbiche-Braham et al., 2011). Exploiting external data is mainly a batch procedure, while our approach better exploits the available training data, and this is done online. The works of (Simard, 2003; Vogel, 2005) are closely related to the constrained alignment approaches described in Section 3. Both allow to extract phrase pairs from bilingual data. Our work attempts to extend this family of methods with the adaptive online method described above. Other works proposed discriminative approaches for word alignment (Moore et al., 2006; Blunsom and Cohn, 2006; Liu et al., 2010; Setiawan et al., 2010). They rely on manually word-aligned training data which render them hard to generalize and questionable for industrial applications. Dyer et al. (2011) proposed a discriminative framework that does not need"
2012.amta-papers.2,P03-2040,0,0.0833634,"Missing"
2013.mtsummit-papers.10,C10-2010,0,0.412901,"Missing"
2013.mtsummit-papers.10,P91-1022,0,0.850243,"Missing"
2013.mtsummit-papers.10,J93-2003,0,0.0542928,"go. This aligner is simple but it performs surprisingly well and often better than more elaborated ones, and do so very fast, allowing to align very large corpora. We analyze the robustness of our aligner across different text genres and level of noise. We also revisit the alignment procedure with which the Europarl corpus has been prepared and show that better SMT performance can be obtained by simply using our aligner. 1 Introduction Sentence alignment has received a lot of attention in the late eighties and early nineties. Based on the excellent results reported (Kay and R¨oscheisen, 1993; Brown et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moor"
2013.mtsummit-papers.10,P97-1038,0,0.0546827,"prone to errors committed during this step. Those approaches end up making hard decisions, which we found problematic. Melamed (1997) proposed an “expanding rectangle search strategy” that shares properties with the dynamic programming approach we proposed, while requiring more meta-parameters and heuristics to work. Chen (1993) controls the search space by making use of thresholds, and taking care of large deletions in one language by some heuristics. Our word-level dynamic programming has been shown efficient at identifying large deletions and is conceptually simpler to implement. See also (Chang and Chen, 1997) for an image processing inspired approach. A few approaches are relaxing the non monotonicity YASA and many other aligners are assuming. The generative model of (Deng et al., 2007) includes a divide clustering phase that accounts for local non monotonicity. Perhaps the most flexible approach we know of is the one of (Bisson and Fluhr, 2000) that proposes to tackle sentence alignment as a cross-lingual information retrieval task. The problem with the approach is that it does not enforce the cohesion a sentence-alignment typically exhibits, thus delivering poor performance when the alignment is"
2013.mtsummit-papers.10,P93-1002,0,0.631101,"surprisingly well and often better than more elaborated ones, and do so very fast, allowing to align very large corpora. We analyze the robustness of our aligner across different text genres and level of noise. We also revisit the alignment procedure with which the Europarl corpus has been prepared and show that better SMT performance can be obtained by simply using our aligner. 1 Introduction Sentence alignment has received a lot of attention in the late eighties and early nineties. Based on the excellent results reported (Kay and R¨oscheisen, 1993; Brown et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moore, 2002). Lexical Philippe Langlais"
2013.mtsummit-papers.10,P93-1001,0,0.429324,"t it performs surprisingly well and often better than more elaborated ones, and do so very fast, allowing to align very large corpora. We analyze the robustness of our aligner across different text genres and level of noise. We also revisit the alignment procedure with which the Europarl corpus has been prepared and show that better SMT performance can be obtained by simply using our aligner. 1 Introduction Sentence alignment has received a lot of attention in the late eighties and early nineties. Based on the excellent results reported (Kay and R¨oscheisen, 1993; Brown et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moore, 2002). Lexical Phili"
2013.mtsummit-papers.10,J93-1004,0,0.966648,"simple but it performs surprisingly well and often better than more elaborated ones, and do so very fast, allowing to align very large corpora. We analyze the robustness of our aligner across different text genres and level of noise. We also revisit the alignment procedure with which the Europarl corpus has been prepared and show that better SMT performance can be obtained by simply using our aligner. 1 Introduction Sentence alignment has received a lot of attention in the late eighties and early nineties. Based on the excellent results reported (Kay and R¨oscheisen, 1993; Brown et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moore, 2002). Lexical Phili"
2013.mtsummit-papers.10,2012.amta-papers.7,0,0.0719247,"Missing"
2013.mtsummit-papers.10,2005.mtsummit-papers.11,0,0.109352,"ertainly contributes to increase the alignment precision, we observed on the French-English E UROPARL bitext that the “number of paragraphs heuristic” concerns 6 484 speaker turns, for a total of 64 441 French and 63 097 English paragraphs. This observation triggered a number of alternative alignment procedures we investigated: where we replace G & C by YASA in the alignment procedure we just described. YASA PK ++ where we remove the “number of paragraphs” heuristic. Therefore, speaker turns are aligned by the G & C aligner, whatever their number of paragraphs. E UROPARL The E UROPARL corpus (Koehn, 2005) is a large parallel corpus often used for training SMT en8 Both aligners were run on a similar computer. 9 In our experiments, aligning 100k sentences per language requires 700Mb of memory for YASA and 2.3Gb for B MA. 81 YASA ++ is similar to PK++ with the exception that YASA is used instead of G & C. 10 http://www.statmt.org/europarl/ where we do not use explicitly the markup available. The markup is kept, but YASA considers it as ordinary sentences. In the end, bisegments associating sentences to markup are removed. de-en DAILY We trained 5 SMT systems, one on each bitext we obtained thanks"
2013.mtsummit-papers.10,N01-1014,0,0.0282252,"cognates (dynamically detected) and the entries of the bilingual lexicon (if provided) are counted for c in equation 1. We used the same definition of a cognate proposed by Simard et al. (1992): two tokens that either do not contain digits and share a prefix of 4 characters (diacritics are being removed before the comparison), or alphanumerical tokens that are identical. Obviously, this definition brings false alarms (e.g., library/librairie (lit. bookshop)), and fails in a number of cases (e.g., night/nuit). It is undoubtedly interesting to use a more sensible definition, such as the one of (Kondrak, 2001). This scoring function is inherited from the practices in use at the time we developed this system (nearly 2 decades ago) and must be revisited. A natural way to proceed would be to implement each score (and possibly others) as features of a discriminative model that would be adjusted either on a held out corpus (similarly to (Munteanu and Marcu, 2005)) or online after a first accurate pass of sentence alignment, as in (Yu et al., 2012). 3 Experiments We conducted experiments on two known testbeds, BAF, a small-scaled multi-genre English-French parallel corpus, and E UROPARL, a large-scaled m"
2013.mtsummit-papers.10,P98-1117,1,0.876632,"Missing"
2013.mtsummit-papers.10,C10-2081,0,0.292183,"red and show that better SMT performance can be obtained by simply using our aligner. 1 Introduction Sentence alignment has received a lot of attention in the late eighties and early nineties. Based on the excellent results reported (Kay and R¨oscheisen, 1993; Brown et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moore, 2002). Lexical Philippe Langlais RALI / DIRO Universit´e de Montr´eal CP. 6128 Suc. Centre-ville H3C 3J7 Montr´eal, Qu´ebec, Canada felipe@iro.umontreal.ca features have been repeatedly reported to improve upon length-based features when noisy corpora are aligned (Chen, 1993; Wu, 1994). Lexical-based systems differ in the way lexica"
2013.mtsummit-papers.10,P97-1039,0,0.0890207,"been proposed, and many share with YASA a two-stage approach that first determines a plausible search space, then applies a more informed alignment procedure. 82 Simard and Plamondon (1998) for instance proposed a method for recursively identifying anchor points (basically, isolated cognate pairs) that serve to reduce the search space. Li et al. (2010) developed a bitext splitter in order to reduce the search space, based on an initial length-based alignment, and therefore is prone to errors committed during this step. Those approaches end up making hard decisions, which we found problematic. Melamed (1997) proposed an “expanding rectangle search strategy” that shares properties with the dynamic programming approach we proposed, while requiring more meta-parameters and heuristics to work. Chen (1993) controls the search space by making use of thresholds, and taking care of large deletions in one language by some heuristics. Our word-level dynamic programming has been shown efficient at identifying large deletions and is conceptually simpler to implement. See also (Chang and Chen, 1997) for an image processing inspired approach. A few approaches are relaxing the non monotonicity YASA and many oth"
2013.mtsummit-papers.10,moore-2002-fast,0,0.563191,"as been prepared and show that better SMT performance can be obtained by simply using our aligner. 1 Introduction Sentence alignment has received a lot of attention in the late eighties and early nineties. Based on the excellent results reported (Kay and R¨oscheisen, 1993; Brown et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moore, 2002). Lexical Philippe Langlais RALI / DIRO Universit´e de Montr´eal CP. 6128 Suc. Centre-ville H3C 3J7 Montr´eal, Qu´ebec, Canada felipe@iro.umontreal.ca features have been repeatedly reported to improve upon length-based features when noisy corpora are aligned (Chen, 1993; Wu, 1994). Lexical-based systems differ"
2013.mtsummit-papers.10,J05-4003,0,0.0472969,"al tokens that are identical. Obviously, this definition brings false alarms (e.g., library/librairie (lit. bookshop)), and fails in a number of cases (e.g., night/nuit). It is undoubtedly interesting to use a more sensible definition, such as the one of (Kondrak, 2001). This scoring function is inherited from the practices in use at the time we developed this system (nearly 2 decades ago) and must be revisited. A natural way to proceed would be to implement each score (and possibly others) as features of a discriminative model that would be adjusted either on a held out corpus (similarly to (Munteanu and Marcu, 2005)) or online after a first accurate pass of sentence alignment, as in (Yu et al., 2012). 3 Experiments We conducted experiments on two known testbeds, BAF, a small-scaled multi-genre English-French parallel corpus, and E UROPARL, a large-scaled multilingual corpus. We follow (Langlais et al., 1998) and evaluate the quality of a candidate alignment by precision and recall ratios — that we summarize into Fmeasure — at different levels of granularity. At the alignment level, a candidate receives a credit for each correctly identified bisegment. Precision and recall are computed accordingly. One pr"
2013.mtsummit-papers.10,P02-1040,0,0.0920252,"Summit (Nice, September 2–6, 2013), p. 77–84. c 2013 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. favorably in a number of settings — including noisy parallel texts — to two popular (and much better engineered) open-source aligners, namely B MA (Moore, 2002) and H UNALIGN (Varga et al., 2005). We also show that using our aligner within the procedure with which the E UROPARL bitext, as distributed on http://www.statmt.org/ europarl/, leads to gains in statistical machine translation (SMT) according to the B LEU metric (Papineni et al., 2002). In the remainder of this paper, we describe our system in Section 2. We report on the experiments we conducted in Section 3. We discuss related work in Section 4 and conclude in Section 5. 2 Description of the System YASA operates a two-step process through the parallel data. Cognates are first recognized in order to accomplish a first token-level alignment that (efficiently) delimits a fruitful search space (see Section 2.1). Then, sentence alignment is performed on this reduced search space (see Section 2.2). For efficiency reasons, both stages are accomplished by dynamic programming. As a"
2013.mtsummit-papers.10,W11-4624,0,0.0274212,"Missing"
2013.mtsummit-papers.10,1992.tmi-1.7,0,0.760615,"lle H3C 3J7 Montr´eal, Qu´ebec, Canada felipe@iro.umontreal.ca features have been repeatedly reported to improve upon length-based features when noisy corpora are aligned (Chen, 1993; Wu, 1994). Lexical-based systems differ in the way lexical features are acquired. Some systems require an initial bilingual dictionary (Li et al., 2010; Wu, 1994), while others induce such lexicons online (Kay and R¨oscheisen, 1993; Chen, 1993; Moore, 2002), often training IBM models (Brown et al., 1993) on the most promising sentence pairs identified by a length-based method. To alleviate the need of a lexicon, Simard et al. (1992) proposed to use cognates, a lightweight lexical feature that is suited for aligning Indo-European language pairs. Lexical-based systems that refine their lexicon online are typically slower, and somehow dependent on the language pair under consideration, and the quantity of material to align (word-alignment for some language pairs and with small corpora is challenging). On the contrary, length-based systems are mainly language independent and efficient to compute, explaining in great part the popularity of tools such as the G & C aligner (Gale and Church, 1993). For computation reasons, most"
2013.mtsummit-papers.10,C10-1124,0,0.0772135,"Missing"
2013.mtsummit-papers.10,P94-1012,0,0.119766,"n et al., 1993; Gale and Church, 1993; Chen, 1993) the community rapidly considered the sentence alignment problem solved, and the interest for it nowadays remains marginal. This matter of fact is further reinforced by the availability of good ready-to-use open source aligners (Gale and Church, 1993; Varga et al., 2005; Moore, 2002; Li et al., 2010). While many sentence alignment systems have been proposed, they basically make use of two types of features: length-based (Brown et al., 1991; Gale and Church, 1993) and lexical-based features (Kay and R¨oscheisen, 1993; Chen, 1993; Melamed, 1997; Wu, 1994; Moore, 2002). Lexical Philippe Langlais RALI / DIRO Universit´e de Montr´eal CP. 6128 Suc. Centre-ville H3C 3J7 Montr´eal, Qu´ebec, Canada felipe@iro.umontreal.ca features have been repeatedly reported to improve upon length-based features when noisy corpora are aligned (Chen, 1993; Wu, 1994). Lexical-based systems differ in the way lexical features are acquired. Some systems require an initial bilingual dictionary (Li et al., 2010; Wu, 1994), while others induce such lexicons online (Kay and R¨oscheisen, 1993; Chen, 1993; Moore, 2002), often training IBM models (Brown et al., 1993) on the m"
2013.mtsummit-papers.10,W12-4402,0,0.0214615,"Missing"
2013.mtsummit-papers.10,J93-1006,0,\N,Missing
2013.mtsummit-papers.10,C98-1113,1,\N,Missing
2021.findings-emnlp.270,N19-1249,1,0.823196,"ve that the majority of WLS weights are concentrated below 0.3 and that the best α values were around 0.5 for Vanilla KD. On the other hand, we observe that our meta-learner mostly produces weights with either very high or very low values, and less frequently weights around 0.5 (e.g. CoLA and RTE). Interestingly, this suggests that for many samples, either one of the hard or soft label loss is informative for the student. Consequently, a sample-wise loss weighting method seems a key component of KD. 5 Conclusion ing our reweighting method to Multi-task Learning (MTL) scenarios (Caruana, 1997; Lu et al., 2019; Stickland and Murray, 2019), where learning to balance losses from different tasks is critical to benefit all tasks involved. Rich Caruana. 1997. Multitask learning. Mach. Learn., 28(1):41–75. Ikhyun Cho and U Kang. 2020. Pea-kd: Parameterefficient and accurate knowledge distillation. CoRR, abs/2009.14822. Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D. Manning, and Quoc V. Le. 2019. Bam! born-again multi-task networks for natural language understanding. In Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 2"
2021.findings-emnlp.270,2020.acl-main.202,0,0.026913,"illation (Ba and Caruana, 2014; Hinton et al., 2015) has proven highly effective for compressing a large-scale NLP model (Devlin et al., 2019; Radford et al., 2019), called teacher in KD terms, into a smaller one, the student. A key factor behind KD’s success is the use of teacher output as soft labels for supervising the training of the student (Müller et al., 2019; Yuan et al., 2020). The latter model is trained by jointly minimizing the losses on both hard and soft labels. The contribution of each loss term is conventionally controlled by a balancing hyperparameter. KD (Clark et al., 2019; Mukherjee and Awadallah, 2020; Jafari et al., 2021). However, the contribution of loss terms is heuristically decayed by an annealing factor, yet another hyperparameter. We argue that using the same weights for all training samples, referred to in our work as singleweight, prevents exploiting the full advantage of KD, because each data sample might have different optimal weights for the loss terms. We propose a meta-learning approach to learn samplewise weights of loss terms. We revisit learning to weight approaches (Ren et al., 2018; Shu et al., 2019), initially proposed for noisy sample downweighting, and adapt it for l"
2021.findings-emnlp.270,2021.acl-long.86,1,0.874869,"loss weighting scheme consistently outperforms its counterparts on 7 tasks from the GLUE benchmark (Wang et al., 2019). A fine-grained analysis of the learned weights shows that, compared to the baselines, our meta-learner explores a greater range of KD weights to find the sample-wise optimal values. 2 Related Work In recent years, Knowledge Distillation for B ERTlike models (Devlin et al., 2019; Liu et al., 2019) has been extensively studied, leveraging intermediate layer matching (Ji et al., 2021; Wu et al., 2020; Passban et al., 2021), data augmentation (Fu et al., 2020; Jiao et al., 2020; Rashid et al., 2021; Kamalloo et al., 2021), adversarial training (Zaharia et al., 2021; Rashid et al., 2020, 2021), and lately loss terms re-weighting (Clark et al., 2019; Zhou et al., 2021; Jafari et al., 2021). In this work, we explore the latter direction with a meta learning approach (Li et al., 2019; Fan et al., 2020). However, recent studies suggested that hard and soft label importance is sample-wise (Tang et al., 2020; Zhou et al., 2021), and only a subset of training samples are crucial for distillation (Li et al., 2018; Zhang et al., 2021). For instance, teacher outputs may be of poor quality for some"
2021.findings-emnlp.270,2020.acl-main.195,0,0.0285231,"o teach with deep interand propose RW-KD a method which does this and actions. CoRR, abs/2007.04649. leads to better distillation performance on 7 GLUE Jie Fu, Xue Geng, Zhijian Duan, Bohan Zhuang, tasks. Future work involves combining RW-KD Xingdi Yuan, Adam Trischler, Jie Lin, Chris Pal, and with state of the art KD methods that use extra loss Hao Dong. 2020. Role-wise data augmentation for knowledge distillation. CoRR, abs/2004.08861. terms such as intermediate layer similarity (Sanh et al., 2019; Jiao et al., 2020), attention match- Abbas Ghaddar, Philippe Langlais, Ahmad Rashid, and ing (Sun et al., 2020; Wang et al., 2021), and adver- Mehdi Rezagholizadeh. 2021a. Context-aware adversarial training for name regularity bias in named entity sarial (Rashid et al., 2021) losses. We expect that these methods can take full advantage of RW-KD, recognition. Trans. Assoc. Comput. Linguistics, 9:586– 604. since they use single-weight loss terms weights. In 3 addition to KD training, we will investigate applyhttps://www.mindspore.cn/ 3149 Abbas Ghaddar, Philippe Langlais, Mehdi Rezagholizadeh, and Ahmad Rashid. 2021b. End-to-end self-debiasing framework for robust NLU training. In Findings of the Associ"
2021.findings-emnlp.270,2021.findings-acl.188,0,0.0179256,"interand propose RW-KD a method which does this and actions. CoRR, abs/2007.04649. leads to better distillation performance on 7 GLUE Jie Fu, Xue Geng, Zhijian Duan, Bohan Zhuang, tasks. Future work involves combining RW-KD Xingdi Yuan, Adam Trischler, Jie Lin, Chris Pal, and with state of the art KD methods that use extra loss Hao Dong. 2020. Role-wise data augmentation for knowledge distillation. CoRR, abs/2004.08861. terms such as intermediate layer similarity (Sanh et al., 2019; Jiao et al., 2020), attention match- Abbas Ghaddar, Philippe Langlais, Ahmad Rashid, and ing (Sun et al., 2020; Wang et al., 2021), and adver- Mehdi Rezagholizadeh. 2021a. Context-aware adversarial training for name regularity bias in named entity sarial (Rashid et al., 2021) losses. We expect that these methods can take full advantage of RW-KD, recognition. Trans. Assoc. Comput. Linguistics, 9:586– 604. since they use single-weight loss terms weights. In 3 addition to KD training, we will investigate applyhttps://www.mindspore.cn/ 3149 Abbas Ghaddar, Philippe Langlais, Mehdi Rezagholizadeh, and Ahmad Rashid. 2021b. End-to-end self-debiasing framework for robust NLU training. In Findings of the Association for Computatio"
2021.findings-emnlp.270,2020.emnlp-main.74,1,0.727533,"nweighting, and adapt it for loss terms weighting in KD. Experimental results show that our KD loss weighting scheme consistently outperforms its counterparts on 7 tasks from the GLUE benchmark (Wang et al., 2019). A fine-grained analysis of the learned weights shows that, compared to the baselines, our meta-learner explores a greater range of KD weights to find the sample-wise optimal values. 2 Related Work In recent years, Knowledge Distillation for B ERTlike models (Devlin et al., 2019; Liu et al., 2019) has been extensively studied, leveraging intermediate layer matching (Ji et al., 2021; Wu et al., 2020; Passban et al., 2021), data augmentation (Fu et al., 2020; Jiao et al., 2020; Rashid et al., 2021; Kamalloo et al., 2021), adversarial training (Zaharia et al., 2021; Rashid et al., 2020, 2021), and lately loss terms re-weighting (Clark et al., 2019; Zhou et al., 2021; Jafari et al., 2021). In this work, we explore the latter direction with a meta learning approach (Li et al., 2019; Fan et al., 2020). However, recent studies suggested that hard and soft label importance is sample-wise (Tang et al., 2020; Zhou et al., 2021), and only a subset of training samples are crucial for distillation ("
2021.findings-emnlp.270,2021.vardial-1.13,0,0.0318242,"45 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3145–3152 November 7–11, 2021. ©2021 Association for Computational Linguistics noisy samples thanks to an auxiliary meta-learner which re-weights training samples of the main model. Such approaches often train a meta-learner on a clean validation set, or on small-loss training samples if no clean data is available. The meta-learner architecture varies from a simple multi-layer perceptron (MLP) as in Meta-WeightNet (Shu et al., 2019) to LSTM-based encoder as in MentorNet (Jiang et al., 2018). The work of Jin et al. (2021) on multi-modal model compression with KD is the most similar to ours. The authors train a MLP meta learner (Shu et al., 2019), on the validation set, which assigns samplelevel weights for 3 loss terms that are calculated when text, image, and both modalities are given as input. In our work, we use a transformer-based meta learner to estimate the sample-wise optimal weights for KD with gradient similarity (see Section 3.2). 3 Normalization Function Estimate the weight with the negative gradient : Meta Student Stage 2 Update the meta student with a GD step: Student X Meta Student X + Teacher St"
A00-1019,J96-1002,0,0.00664237,"ere a(t', s) E [0, 1] are context-dependent interpolation coefficients. For example, the translation model could have a higher weight at the start of a sentence but the contribution of the language model might become more important in the middle or the end of the sentence• A study of the weightings for these two models is described elsewhere• In the work described here we did not use the contribution of the language model (that is, a(t', s) = O, V t', s). Techniques for weakening the independence assumptions made by the IBM models 1 and 2 have been proposed in recent work (Brown et al., 1993; Berger et al., 1996; Och and Weber, 98; Wang and Waibel, 98; Wu and Wong, 98). These studies report improvements on some specific tasks (task-oriented limited vocabulary) which by nature are very different from the task TRANSTYPE is devoted to. Furthermore, the underlying decoding strategies are too time consuming for our application• We therefore use a translation model based on the simple linear interpolation given in equation 2 which combines predictions of two translation models - - Ms and M~ - both based on IBM-like model 2(Brown et al., 1993). Ms was trained on single words and Mu, described 136 in section"
A00-1019,1997.mtsummit-papers.1,0,0.096049,"Missing"
A00-1019,P95-1032,0,0.0543477,"Missing"
A00-1019,P93-1003,0,0.027342,"Missing"
A00-1019,W97-0311,0,0.0428982,"Missing"
A00-1019,P97-1061,0,0.0366885,"ord model, A u the 10 best units according to the unit model. Modeling = et • a • premier disait 3 p(w~) Finding Monolingual Units Finding relevant units in a text has been explored in many areas of natural language processing. Our approach relies on distributional and frequency statistics computed on each sequence of words found in a training corpus. For sake of efficiency, we used the suffix array technique to get a compact representation of our training corpus. This method allows the efficient retrieval of arbitrary length n-grams (Nagao and Mori, 94; Haruno et al., 96; Ikehara et al., 96; Shimohata et al., 1997; Russell, 1998). The literature abounds in measures that can help to decide whether words that co-occur are linguistically significant or not. In this work, the strength of association of a sequence of words w [ = w l , . . . , w n is computed by two measures: a likelihood-based one p(w'~) (where g is the likelihood ratio given in (Dunning, 93)) and an entropy-based one e(w'~) (Shimohata et al., 1997). Letting T stand for the training text and m a token: 137 Intuitively, the first measurement accounts for the fact that parts of a sequence of words that should be considered as a whole should n"
A00-1019,P94-1033,0,0.046262,"Missing"
A00-1019,P98-2221,0,0.048473,"Missing"
A00-1019,P98-2230,0,0.027694,"Missing"
A00-1019,W99-0604,0,\N,Missing
A00-1019,C90-2045,0,\N,Missing
A00-1019,C96-1006,0,\N,Missing
A00-1019,J93-2003,0,\N,Missing
A00-1019,C94-1101,0,\N,Missing
A00-1019,C96-1070,0,\N,Missing
A00-1019,C90-3008,0,\N,Missing
A00-1019,C96-2098,0,\N,Missing
A00-1019,P99-1067,0,\N,Missing
A00-1019,P98-2158,0,\N,Missing
A00-1019,C98-2153,0,\N,Missing
A00-1019,P97-1037,0,\N,Missing
A00-1019,P96-1003,0,\N,Missing
A00-1019,P94-1032,0,\N,Missing
A00-1019,C86-1077,0,\N,Missing
A00-1019,C96-1089,0,\N,Missing
A00-1019,C98-2225,0,\N,Missing
A00-1019,P98-2162,0,\N,Missing
A00-1019,C98-2157,0,\N,Missing
A00-1019,C98-2216,0,\N,Missing
A00-1019,langlais-etal-2000-evaluation,1,\N,Missing
A00-1019,P99-1041,0,\N,Missing
A00-1019,C96-1097,0,\N,Missing
A00-1019,P97-1047,0,\N,Missing
C08-2013,2007.mtsummit-papers.19,0,0.304317,"y as z is to t”, in a sense to be specified. See (Lepage, 1998) or (Stroppa and Yvon, 2005) for possible interpretations. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. If the principle of analogical learning is quite simple, it does involve complex steps that seriously limit its applicability. As a matter of fact, we are only aware of studies where analogical learning is applied to restricted tasks, either because they arbitrarily concentrate on words (Stroppa and Yvon, 2005; Langlais and Patry, 2007; Denoual, 2007) or because they focus on limited data (Lepage and Denoual, 2005; Denoual, 2007). In this study, we investigate different strategies for making step 1 of analogical learning tractable. We propose a data"
C08-2013,D07-1092,1,0.893605,"ance yvon@limsi.fr where [x : y = z : t] denotes an analogical proportion, that is a relation between these four items, meaning that “x is to y as z is to t”, in a sense to be specified. See (Lepage, 1998) or (Stroppa and Yvon, 2005) for possible interpretations. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. If the principle of analogical learning is quite simple, it does involve complex steps that seriously limit its applicability. As a matter of fact, we are only aware of studies where analogical learning is applied to restricted tasks, either because they arbitrarily concentrate on words (Stroppa and Yvon, 2005; Langlais and Patry, 2007; Denoual, 2007) or because they focus on limited data (Lepage and Denoual, 2005; Denoua"
C08-2013,P98-1120,0,0.698271,"e diagonal terms share some n-grams reminiscent of the number (This/These) and tense (drink /drank ) commutations involved. We thus propose a sampling strategy (hereafter EV ) which selects x-forms that share with t some sequences of characters. To this end, input forms are represented in a vector space whose dimensions are frequent character n-grams, retaining the k-most frequent n-grams, where n ∈ [min; max]. A form is thus encoded as a binary vector of Exhaustive tree-count search The strategy we propose here exploits a property on character counts that an analogical relation must fulfill (Lepage, 1998): [x : y = z : t] ⇒ |x|c + |t|c = |y|c + |z|c ∀c ∈ A where A is the alphabet on which the forms are built, and |x|c stands for the number of occurrences of character c in x. In the sequel, we denote C(hx, ti) = {hy, zi ∈ I 2 : |x|c + |t|c = |y|c + |z|c ∀c ∈ A} the set of pairs that satisfy the count property with respect to hx, ti . The strategy we propose consists in first selecting an x-form in the input space. This enforces a set of necessary constraints on the counts of characters that any two forms y and z must satisfy for [x : y = z : t] to be true. By considering all forms x in turn,2 w"
C08-2013,W05-0616,1,0.845567,"6128, Qu´ebec, H3C3J7, Canada felipe@iro.umontreal.ca Franc¸ois Yvon Univ. Paris Sud 11 & LIMSI-CNRS F-91401 Orsay, France yvon@limsi.fr where [x : y = z : t] denotes an analogical proportion, that is a relation between these four items, meaning that “x is to y as z is to t”, in a sense to be specified. See (Lepage, 1998) or (Stroppa and Yvon, 2005) for possible interpretations. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. If the principle of analogical learning is quite simple, it does involve complex steps that seriously limit its applicability. As a matter of fact, we are only aware of studies where analogical learning is applied to restricted tasks, either because they arbitrarily concentrate on words (Stroppa and Yvon"
C08-2013,C98-1116,0,\N,Missing
C10-1070,C02-2020,0,0.754903,"ion scores have been investigated and compared, the likelihood score (Dunning, 1993) being among the most popular. Also, different similarity measures have been proposed for ranking target context vectors, among which the popular cosine measure. The goal of the different authors who investigate context-projection approaches also varies. Some studies are tackling the problem of identifying the translation of general words (Rapp, 1999; Otero, 2007; Yu and Tsujii, 2009) while others are addressing the translation of domain specific terms. Among the latter, many are translating single-word terms (Chiao and Zweigenbaum, 2002; D´ejean et al., 2005; Prochasson et 1 A stoplist is typically used in order to prevent function words from populating the context vectors. 617 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 617–625, Beijing, August 2010 al., 2009), while others are tackling the translation of multi-word terms (Daille and Morin, 2005). The type of discourse might as well be of concern in some of the studies dedicated to bilingual terminology mining. For instance, Morin et al. (2007) distinguish popular science versus scientific terms, while Saralegi et al. ("
C10-1070,I05-1062,0,0.87373,"of identifying the translation of general words (Rapp, 1999; Otero, 2007; Yu and Tsujii, 2009) while others are addressing the translation of domain specific terms. Among the latter, many are translating single-word terms (Chiao and Zweigenbaum, 2002; D´ejean et al., 2005; Prochasson et 1 A stoplist is typically used in order to prevent function words from populating the context vectors. 617 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 617–625, Beijing, August 2010 al., 2009), while others are tackling the translation of multi-word terms (Daille and Morin, 2005). The type of discourse might as well be of concern in some of the studies dedicated to bilingual terminology mining. For instance, Morin et al. (2007) distinguish popular science versus scientific terms, while Saralegi et al. (2008) target popular science terms only. The present discussion only focuses on a few number of representative studies. Still, it is already striking that a direct comparison of them is difficult, if not impossible. Differences in resources being used (in quantities, in domains, etc.), in technical choices made (similarity measures, context vector computation, etc.) and"
C10-1070,2009.mtsummit-posters.14,0,0.805692,"d generality, our implementation does not exploit interlanguage links nor structural elements specific to Wikipedia documents, as opposed to (Yu and Tsujii, 2009). Step 2 A context vector vs for the source term S is built (see Figure 1 for a made-up example). This vector contains the words that are in the context of the occurrences of S and are strongly correlated to S. The definition of “context” is one of the parameters whose best value we want to find. Context length can be based on a number of units, for instance 3 sentences (Daille and Morin, 2005), windows of 3 (Rapp, 1999) or 25 words (Prochasson et al., 2009), etc. It is an important parameter of the projection-based approach. Should the context length be too small, we would miss words that would be relevant in finding the translation. On the other hand, if the context is too large, it 618 2 We used a set of about 40 regular expressions to do this. might contain too much noise. At this step, a stoplist made of function words is applied in order to filter out context words and reduce noise in the context vector. Additionally, an association measure is used to score the strength of correlation between S and the words in its contexts; it serves to no"
C10-1070,P99-1067,0,0.842921,"his. As a testcase, we address the task of translating terms of the medical domain by exploiting pages mined from Wikipedia. One interesting outcome of this study is that significant gains can be obtained by using an association measure that is rarely used in practice. 1 Introduction Identifying translations of terms in comparable corpora is a challenge that has attracted many researchers. A popular idea that emerged for solving this problem is based on the assumption that the context of a term and its translation share similarities that can be used to rank translation candidates (Fung, 1998; Rapp, 1999). Many variants of this idea have been implemented. While a few studies have investigated pattern matching approaches to compare source and target contexts (Fung, 1995; Diab and Finch, 2000; Yu and Tsujii, 2009), most variants make use of a bilingual lexicon in order to translate the words of the context of a term (often called seed words). D´ejean et al. (2005) instead use a bilingual thesaurus for translating these. Another distinction between approaches lies in the way the context is defined. The most common practice, the so-called window-based approach, defines the context words as those c"
C10-1070,J93-1003,0,0.25405,"opose a resource-intensive strategy which requires both source and target dependency parsers, while Otero (2007) investigates a lighter approach where a few hand coded regular expressions based on POS tags simulate source parsing. The latter approach only requires a POS tagger of the source and the target languages as well as a small parallel corpus in order to project the source regular expressions. Naturally, studies differ in the way each cooccurrence (either window or syntax-based) is weighted, and a plethora of association scores have been investigated and compared, the likelihood score (Dunning, 1993) being among the most popular. Also, different similarity measures have been proposed for ranking target context vectors, among which the popular cosine measure. The goal of the different authors who investigate context-projection approaches also varies. Some studies are tackling the problem of identifying the translation of general words (Rapp, 1999; Otero, 2007; Yu and Tsujii, 2009) while others are addressing the translation of domain specific terms. Among the latter, many are translating single-word terms (Chiao and Zweigenbaum, 2002; D´ejean et al., 2005; Prochasson et 1 A stoplist is typ"
C10-1070,R09-2012,0,0.0238187,"2. 3.1 Resources Corpora The comparable corpora are made of the (at most) 50 French and English Wikipedia documents that are the most relevant to the source term and to its reference translation respectively. These documents are retrieved with the NLGbAse Information Retrieval tool.5 The average token count of all the 50-document corpora as well as the average frequency of the source and target terms in these corpora for our four series of experiments are listed in Table 1. 4 Our resources are available at http://olst.ling. umontreal.ca/˜audrey/coling2010/. They were acquired as described in (Rubino, 2009). 5 http://nlgbase.org/ 620 1 Tokenss Tokenst |S| |T | 89,431 52,002 296 542 Experiment 2 3 73,809 27,517 184 255 42,762 12,891 66 104 the number of correct translations (at most 1 per source term) divided by the number of terms for which our system gave at least one answer; recall is equal to the ratio of correct translations to the total number of terms. F-measure is the harmonic mean of precision and recall: 4 90,328 38,929 306 404 Table 1: 50-document corpora averages F-measure = The corpora are somewhat small (most corpora in previous studies are made of at least a million words). We beli"
C10-1070,P95-1032,0,0.115388,"at significant gains can be obtained by using an association measure that is rarely used in practice. 1 Introduction Identifying translations of terms in comparable corpora is a challenge that has attracted many researchers. A popular idea that emerged for solving this problem is based on the assumption that the context of a term and its translation share similarities that can be used to rank translation candidates (Fung, 1998; Rapp, 1999). Many variants of this idea have been implemented. While a few studies have investigated pattern matching approaches to compare source and target contexts (Fung, 1995; Diab and Finch, 2000; Yu and Tsujii, 2009), most variants make use of a bilingual lexicon in order to translate the words of the context of a term (often called seed words). D´ejean et al. (2005) instead use a bilingual thesaurus for translating these. Another distinction between approaches lies in the way the context is defined. The most common practice, the so-called window-based approach, defines the context words as those cooccuring significantly with the source term within windows centered around the term.1 Some studies have reported gains by considering syntactically motivated co-occur"
C10-1070,P08-1088,0,0.209783,"pose to integrate a reverse translation spotting strategy in order to improve precision. Prochasson et al. (2009) boost the strength of context words that happen to be transliterated in the other language. A somehow 3 For instance, O21 stands for the number of windows containing S but not s. generalized version of this heuristic has been described in (Shao and Ng, 2004). In this work, we examine the performance of the best configuration of parameters we found, combined with a simple heuristic based on graphic similarity between source and target terms, similar to the orthographic features in (Haghighi et al., 2008)’s generative model. This is very specific to our task where medical terms often (but not always) share Latin or Greek roots, such as microvillosit´es in French and microvilli in English. In this heuristic, translation candidates which are cognates of the source term are ranked first among the list of translation candidates. In our implementation, two words are cognates if their first four characters are identical (Simard et al., 1992). One interesting note concerns the wordorder mismatch typically observed in French and English complex terms, such as in ADN mitochondrial (French) and mitochon"
C10-1070,P07-1084,0,0.635474,"fic terms. Among the latter, many are translating single-word terms (Chiao and Zweigenbaum, 2002; D´ejean et al., 2005; Prochasson et 1 A stoplist is typically used in order to prevent function words from populating the context vectors. 617 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 617–625, Beijing, August 2010 al., 2009), while others are tackling the translation of multi-word terms (Daille and Morin, 2005). The type of discourse might as well be of concern in some of the studies dedicated to bilingual terminology mining. For instance, Morin et al. (2007) distinguish popular science versus scientific terms, while Saralegi et al. (2008) target popular science terms only. The present discussion only focuses on a few number of representative studies. Still, it is already striking that a direct comparison of them is difficult, if not impossible. Differences in resources being used (in quantities, in domains, etc.), in technical choices made (similarity measures, context vector computation, etc.) and in objectives (general versus terminological dictionary extraction) prevent one from establishing a clear landscape of the various approaches. Indeed,"
C10-1070,C04-1089,0,0.033046,"000 entries are related to the medical domain), as well as a 5,000-entry general language only lexicon. 2.3 Cognate heuristic Many authors are embedding heuristics in order to improve their approach. For instance, Chiao and Zweigenbaum (2002) propose to integrate a reverse translation spotting strategy in order to improve precision. Prochasson et al. (2009) boost the strength of context words that happen to be transliterated in the other language. A somehow 3 For instance, O21 stands for the number of windows containing S but not s. generalized version of this heuristic has been described in (Shao and Ng, 2004). In this work, we examine the performance of the best configuration of parameters we found, combined with a simple heuristic based on graphic similarity between source and target terms, similar to the orthographic features in (Haghighi et al., 2008)’s generative model. This is very specific to our task where medical terms often (but not always) share Latin or Greek roots, such as microvillosit´es in French and microvilli in English. In this heuristic, translation candidates which are cognates of the source term are ranked first among the list of translation candidates. In our implementation,"
C10-1070,1992.tmi-1.7,0,0.385624,"of parameters we found, combined with a simple heuristic based on graphic similarity between source and target terms, similar to the orthographic features in (Haghighi et al., 2008)’s generative model. This is very specific to our task where medical terms often (but not always) share Latin or Greek roots, such as microvillosit´es in French and microvilli in English. In this heuristic, translation candidates which are cognates of the source term are ranked first among the list of translation candidates. In our implementation, two words are cognates if their first four characters are identical (Simard et al., 1992). One interesting note concerns the wordorder mismatch typically observed in French and English complex terms, such as in ADN mitochondrial (French) and mitochondrial DNA (English). We do treat this case adequately. 3 Experimental protocol In order to pinpoint the best configuration of values for the parameters identified in Section 2.2, four series of experiments were carried out. In all of them, the task consists of spotting translation candidates for each source language term using the resources4 described below. The quality of the results is evaluated with the help of the metrics described"
C10-1070,N10-1063,0,0.0061571,"s (at most 1 per source term) divided by the number of terms for which our system gave at least one answer; recall is equal to the ratio of correct translations to the total number of terms. F-measure is the harmonic mean of precision and recall: 4 90,328 38,929 306 404 Table 1: 50-document corpora averages F-measure = The corpora are somewhat small (most corpora in previous studies are made of at least a million words). We believe this is more representative of a task where we try to translate domain specific terms. Some of the Wikipedia documents may contain a handful of parallel sentences (Smith et al., 2010), but this information is not used in our approach. The construction of the corpus involves a bias in that the reference translations are used to obtain the most relevant target language documents. However, since our objective is to compare the relative performance of different sets of parameters, this does not affect our results. In fact, as per (D´ejean et al., 2005) (whose comparable corpora are English and German abstracts), the use of such an “ideal” corpus is common (as in (Chiao and Zweigenbaum, 2002), where the corpus is built from a specific query). 2 × (precision × recall) (precision"
C10-1070,2009.mtsummit-posters.26,0,0.607433,"ed by using an association measure that is rarely used in practice. 1 Introduction Identifying translations of terms in comparable corpora is a challenge that has attracted many researchers. A popular idea that emerged for solving this problem is based on the assumption that the context of a term and its translation share similarities that can be used to rank translation candidates (Fung, 1998; Rapp, 1999). Many variants of this idea have been implemented. While a few studies have investigated pattern matching approaches to compare source and target contexts (Fung, 1995; Diab and Finch, 2000; Yu and Tsujii, 2009), most variants make use of a bilingual lexicon in order to translate the words of the context of a term (often called seed words). D´ejean et al. (2005) instead use a bilingual thesaurus for translating these. Another distinction between approaches lies in the way the context is defined. The most common practice, the so-called window-based approach, defines the context words as those cooccuring significantly with the source term within windows centered around the term.1 Some studies have reported gains by considering syntactically motivated co-occurrences. Yu and Tsujii (2009) propose a resou"
C18-1122,E09-1003,0,0.0296986,"systems. The overall structure of this approach is still considered state-of-the-art. Adafre and Rijke (2006) is the first work to observe that articles from Wikipedia are likely to generate parallel corpora useful for machine translation. These two approaches are extended by Smith et al. (2010) where the authors introduce several new features by exploiting the structure and metadata of Wikipedia article pairs. They use their augmented set of features in a conditional random field and obtain state-of-the-art results on a small set of 20 manually annotated Wikipedia article pairs. The work of Abdul-Rauf and Schwenk (2009) proposes a different approach, in which they use an SMT system built from a small parallel corpus. Instead of using a classifier, they translate the source language side of a comparable corpus to find candidate sentences on the target language side. They determine if a translated source sentence and a candidate target sentence are parallel by measuring the word error rate and the translation error rate. A simplification of these systems is proposed in (Azpeitia et al., 2017), where the similarity between two sentences is defined as the average of the Jaccard similarity coefficients obtained b"
C18-1122,W06-2810,0,0.124676,"Missing"
C18-1122,W17-2508,0,0.0128564,"and obtain state-of-the-art results on a small set of 20 manually annotated Wikipedia article pairs. The work of Abdul-Rauf and Schwenk (2009) proposes a different approach, in which they use an SMT system built from a small parallel corpus. Instead of using a classifier, they translate the source language side of a comparable corpus to find candidate sentences on the target language side. They determine if a translated source sentence and a candidate target sentence are parallel by measuring the word error rate and the translation error rate. A simplification of these systems is proposed in (Azpeitia et al., 2017), where the similarity between two sentences is defined as the average of the Jaccard similarity coefficients obtained between sentence token sets and lexical translations determined by IBM models (Brown et al., 1993). Their approach also combine various features, such as longest common prefix matching, numbers and capitalized truecased tokens. Chu et al. (2016) train a neural machine translation (NMT) system to generate sentence representations with the encoder, which are then used as additional features to the system of Munteanu and Marcu (2005). Similarly, Cristina et al. (2017) study sente"
C18-1122,J93-2003,0,0.0629808,"mall parallel corpus. Instead of using a classifier, they translate the source language side of a comparable corpus to find candidate sentences on the target language side. They determine if a translated source sentence and a candidate target sentence are parallel by measuring the word error rate and the translation error rate. A simplification of these systems is proposed in (Azpeitia et al., 2017), where the similarity between two sentences is defined as the average of the Jaccard similarity coefficients obtained between sentence token sets and lexical translations determined by IBM models (Brown et al., 1993). Their approach also combine various features, such as longest common prefix matching, numbers and capitalized truecased tokens. Chu et al. (2016) train a neural machine translation (NMT) system to generate sentence representations with the encoder, which are then used as additional features to the system of Munteanu and Marcu (2005). Similarly, Cristina et al. (2017) study sentence representations obtained from the encoder of an NMT system to detect new parallel sentence pairs. By comparing cosine similarities, they show that they can distinguish parallel and non-parallel sentences. A differ"
C18-1122,D14-1179,0,0.0481891,"Missing"
C18-1122,L16-1468,0,0.277435,"e target language side. They determine if a translated source sentence and a candidate target sentence are parallel by measuring the word error rate and the translation error rate. A simplification of these systems is proposed in (Azpeitia et al., 2017), where the similarity between two sentences is defined as the average of the Jaccard similarity coefficients obtained between sentence token sets and lexical translations determined by IBM models (Brown et al., 1993). Their approach also combine various features, such as longest common prefix matching, numbers and capitalized truecased tokens. Chu et al. (2016) train a neural machine translation (NMT) system to generate sentence representations with the encoder, which are then used as additional features to the system of Munteanu and Marcu (2005). Similarly, Cristina et al. (2017) study sentence representations obtained from the encoder of an NMT system to detect new parallel sentence pairs. By comparing cosine similarities, they show that they can distinguish parallel and non-parallel sentences. A different approach exploiting continuous vector representations is proposed in Grover and Mitra (2017). After learning word representations using the bil"
C18-1122,P17-3003,0,0.288538,"efix matching, numbers and capitalized truecased tokens. Chu et al. (2016) train a neural machine translation (NMT) system to generate sentence representations with the encoder, which are then used as additional features to the system of Munteanu and Marcu (2005). Similarly, Cristina et al. (2017) study sentence representations obtained from the encoder of an NMT system to detect new parallel sentence pairs. By comparing cosine similarities, they show that they can distinguish parallel and non-parallel sentences. A different approach exploiting continuous vector representations is proposed in Grover and Mitra (2017). After learning word representations using the bilingual word embeddings model of (Luong et al., 2015), they use a convolutional neural network on a similarity matrix to classify if a pair of sentences is aligned or not. These approaches are different from ours, where we use a single end-to-end model to estimate the conditional probability distribution that two sentences are parallel. 3 3.1 Approach Negative sampling n  As positive examples, we use a parallel corpus C consisting of n parallel sentence pairs (sSk , sTk ) k=1 , where S and T denote the source sentences and target sentences. Si"
C18-1122,W11-2123,0,0.026059,"ning set. All unknown words are replaced by the UNK token. 4.2.2 Evaluation metric To evaluate the translation performance of our systems we use the BLEU score (Papineni et al., 2002) using the multi-bleu script from Moses. 4.2.3 Training settings The SMT systems are phrase-based systems (Koehn et al., 2003) that are trained with Moses. We use the GIZA++ implementation (Och and Ney, 2003)10 to train word alignment models in both directions. The phrases and lexical reordering are extracted using the default values of Moses. The language models are 5-gram models learned using the KenLM toolkit (Heafield, 2011)11 on the monolingual parts of the same parallel corpus used for training the translation models. The parameters are optimized on the newstest2012 corpus. To train the NMT systems, we use the PyTorch implementation of OpenNMT (Klein et al., 2017).12 The NMT systems are one layer BiLSTMs with an attention mechanism (Bahdanau et al., 2014). The dimensions of the word embeddings and recurrent states for the encoder and decoder are all set to 256. The systems are trained for 10 epochs with minibatch of 64 sentence pairs using SGD with an initial learning rate of 1.0 and linear decay.13 The norm of"
C18-1122,P17-4012,0,0.0160825,"tings The SMT systems are phrase-based systems (Koehn et al., 2003) that are trained with Moses. We use the GIZA++ implementation (Och and Ney, 2003)10 to train word alignment models in both directions. The phrases and lexical reordering are extracted using the default values of Moses. The language models are 5-gram models learned using the KenLM toolkit (Heafield, 2011)11 on the monolingual parts of the same parallel corpus used for training the translation models. The parameters are optimized on the newstest2012 corpus. To train the NMT systems, we use the PyTorch implementation of OpenNMT (Klein et al., 2017).12 The NMT systems are one layer BiLSTMs with an attention mechanism (Bahdanau et al., 2014). The dimensions of the word embeddings and recurrent states for the encoder and decoder are all set to 256. The systems are trained for 10 epochs with minibatch of 64 sentence pairs using SGD with an initial learning rate of 1.0 and linear decay.13 The norm of the gradient is clipped such that it is not greater than 5. 4.2.4 Evaluation on machine translation systems For each of the SMT and NMT approaches, we trained 14 machine translation systems. The first two systems,14 which serve as reference syst"
C18-1122,N03-1017,0,0.0968745,"te the machine translation systems on the newstest2013 corpus. All datasets are tokenized using the scripts from Moses. The maximum length of each sentence is set to 80 tokens. For the NMT systems, the vocabulary size for both languages is limited to the 150,000 most frequent words of their corresponding training set. All unknown words are replaced by the UNK token. 4.2.2 Evaluation metric To evaluate the translation performance of our systems we use the BLEU score (Papineni et al., 2002) using the multi-bleu script from Moses. 4.2.3 Training settings The SMT systems are phrase-based systems (Koehn et al., 2003) that are trained with Moses. We use the GIZA++ implementation (Och and Ney, 2003)10 to train word alignment models in both directions. The phrases and lexical reordering are extracted using the default values of Moses. The language models are 5-gram models learned using the KenLM toolkit (Heafield, 2011)11 on the monolingual parts of the same parallel corpus used for training the translation models. The parameters are optimized on the newstest2012 corpus. To train the NMT systems, we use the PyTorch implementation of OpenNMT (Klein et al., 2017).12 The NMT systems are one layer BiLSTMs with a"
C18-1122,P07-2045,0,0.0244231,"Missing"
C18-1122,2005.mtsummit-papers.11,0,0.511153,"Missing"
C18-1122,W15-1521,0,0.0206872,"on (NMT) system to generate sentence representations with the encoder, which are then used as additional features to the system of Munteanu and Marcu (2005). Similarly, Cristina et al. (2017) study sentence representations obtained from the encoder of an NMT system to detect new parallel sentence pairs. By comparing cosine similarities, they show that they can distinguish parallel and non-parallel sentences. A different approach exploiting continuous vector representations is proposed in Grover and Mitra (2017). After learning word representations using the bilingual word embeddings model of (Luong et al., 2015), they use a convolutional neural network on a similarity matrix to classify if a pair of sentences is aligned or not. These approaches are different from ours, where we use a single end-to-end model to estimate the conditional probability distribution that two sentences are parallel. 3 3.1 Approach Negative sampling n  As positive examples, we use a parallel corpus C consisting of n parallel sentence pairs (sSk , sTk ) k=1 , where S and T denote the source sentences and target sentences. Since we want a model that learns differentiable vector representations to distinguish parallel from non-"
C18-1122,J05-4003,0,0.583844,"to believe that our system is a promising tool to create new aligned multilingual resources. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 1 http://alt.qcri.org/semeval2017/task2/ License details: http:// 1442 Proceedings of the 27th International Conference on Computational Linguistics, pages 1442–1453 Santa Fe, New Mexico, USA, August 20-26, 2018. 2 Related work Traditional systems developed to extract parallel sentences from comparable corpora typically rely on multiples models or metadata from articles structure. Munteanu and Marcu (2005) present a complete system based on statistical word alignment models and a maximum entropy classifier to automatically extract sentence pairs from newspaper collections. The authors evaluate the quality of the extracted sentences by showing that they improve the performance of statistical machine translation (SMT) systems. The overall structure of this approach is still considered state-of-the-art. Adafre and Rijke (2006) is the first work to observe that articles from Wikipedia are likely to generate parallel corpora useful for machine translation. These two approaches are extended by Smith"
C18-1122,J03-1002,0,0.0145046,"enized using the scripts from Moses. The maximum length of each sentence is set to 80 tokens. For the NMT systems, the vocabulary size for both languages is limited to the 150,000 most frequent words of their corresponding training set. All unknown words are replaced by the UNK token. 4.2.2 Evaluation metric To evaluate the translation performance of our systems we use the BLEU score (Papineni et al., 2002) using the multi-bleu script from Moses. 4.2.3 Training settings The SMT systems are phrase-based systems (Koehn et al., 2003) that are trained with Moses. We use the GIZA++ implementation (Och and Ney, 2003)10 to train word alignment models in both directions. The phrases and lexical reordering are extracted using the default values of Moses. The language models are 5-gram models learned using the KenLM toolkit (Heafield, 2011)11 on the monolingual parts of the same parallel corpus used for training the translation models. The parameters are optimized on the newstest2012 corpus. To train the NMT systems, we use the PyTorch implementation of OpenNMT (Klein et al., 2017).12 The NMT systems are one layer BiLSTMs with an attention mechanism (Bahdanau et al., 2014). The dimensions of the word embeddin"
C18-1122,P02-1040,0,0.101062,",000 pairs of English–French articles obtained from Wikipedia dumps.9 The newstest2012 corpus is our validation set and we evaluate the machine translation systems on the newstest2013 corpus. All datasets are tokenized using the scripts from Moses. The maximum length of each sentence is set to 80 tokens. For the NMT systems, the vocabulary size for both languages is limited to the 150,000 most frequent words of their corresponding training set. All unknown words are replaced by the UNK token. 4.2.2 Evaluation metric To evaluate the translation performance of our systems we use the BLEU score (Papineni et al., 2002) using the multi-bleu script from Moses. 4.2.3 Training settings The SMT systems are phrase-based systems (Koehn et al., 2003) that are trained with Moses. We use the GIZA++ implementation (Och and Ney, 2003)10 to train word alignment models in both directions. The phrases and lexical reordering are extracted using the default values of Moses. The language models are 5-gram models learned using the KenLM toolkit (Heafield, 2011)11 on the monolingual parts of the same parallel corpus used for training the translation models. The parameters are optimized on the newstest2012 corpus. To train the"
C18-1122,N10-1063,0,0.0273963,"(2005) present a complete system based on statistical word alignment models and a maximum entropy classifier to automatically extract sentence pairs from newspaper collections. The authors evaluate the quality of the extracted sentences by showing that they improve the performance of statistical machine translation (SMT) systems. The overall structure of this approach is still considered state-of-the-art. Adafre and Rijke (2006) is the first work to observe that articles from Wikipedia are likely to generate parallel corpora useful for machine translation. These two approaches are extended by Smith et al. (2010) where the authors introduce several new features by exploiting the structure and metadata of Wikipedia article pairs. They use their augmented set of features in a conditional random field and obtain state-of-the-art results on a small set of 20 manually annotated Wikipedia article pairs. The work of Abdul-Rauf and Schwenk (2009) proposes a different approach, in which they use an SMT system built from a small parallel corpus. Instead of using a classifier, they translate the source language side of a comparable corpus to find candidate sentences on the target language side. They determine if"
C18-1122,C96-2141,0,0.548313,"Missing"
C98-1113,1990.tc-1.1,0,0.0526616,"Missing"
C98-1113,C92-2079,0,0.0350145,"Missing"
C98-1113,P91-1023,0,0.0677609,"975 = 1515 + 36*20 = (excluding = 975 0.64 = 1 5 Systems tested Six systems were tested, two of which having been submitted by the RALI. 714 l : t A L I / J a c a l This system uses as a first step a program that reduces the search space only to those sentence pairs that axe potentially interesting (Simard and Plamondon, 1996). The underlying principle is the automatic detection of isolated cognates (i.e. for which no other similar word exists in a window of given size). Once the search space is reduced, the system aligns the sentences using the well-known sentence-length model described in (Gale and Church, 1991). RALI/Salign The second method proposed by RALI is based on a dynamic programming scheme which uses a score function derived from a translation model similar to that of (Brown et ai., 1990). The search space is reduced to a beam of fixed width around the diagonal (which would represent the alignment if the two texts were perfectly synchronized). L O R I A The strategy adopted in this system differs from that of the other systems since sentence alignment is performed after the preliminaxy alignment of larger units (whenever possible, using maxk-up), such as paragraphs and divisions, on the bas"
C98-1113,1996.amta-1.4,0,0.0386261,"last few years, there has been a growing interest in parallel text alignment techniques. These techniques a t t e m p t to map various textual units to their translation and have proven useful for a wide range of applications and tools. A simple example of such a tool is probably the TrunsSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also fbr bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans 711 Jean V6ronis LPL, Univ. de Provence 29, Av. R. Schuman F-13621 Aix-en-Provence Cedex 1 veronis@univ-aix.fr azld Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new"
C98-1113,1995.mtsummit-1.36,0,0.0486228,"Missing"
C98-1113,1996.amta-1.13,0,0.0481671,"d tools. A simple example of such a tool is probably the TrunsSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also fbr bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans 711 Jean V6ronis LPL, Univ. de Provence 29, Av. R. Schuman F-13621 Aix-en-Provence Cedex 1 veronis@univ-aix.fr azld Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent demonstration that very simple techniques could yield almost perfect results. For instance, to produce sentence alignments, Brown et al. (1991) and Gale and Church (1991) both propose"
C98-1113,P97-1039,0,0.144085,"Missing"
C98-1113,1996.amta-1.14,1,0.897358,"lt in a dramatic loss of efficiency. The truth is that, while text alignment is mostly an easy problem, especially when considered at the sentence level, there are situations where even humans have a hard time making the right decision. In fact, it could be argued that, ultimately, text alignment is no easier tha~l the more general problem of natural laalguage understanding. In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment (Brown et al., 1991; Gale and Church, 1991; Debili, 1992; Kay and RSscheisen, 1993; Simard et al., 1992; Simard and Plamondon, 1996). Alignment at the word and term level, which is extremely useful for applications such as lexical resource extraction, is still a largely unexplored research area(Melamed, 1997). In order to live up to the expectations of the various application fields, alignment technology will therefore have to improve substantially. As was the case with several other language processing techniques (such as information retrieval, document understanding or speech recognition), it is likely that a systematic evaluation will enable such improvements. However, before the ARCADE project started, no formal evalua"
C98-1113,1992.tmi-1.7,1,0.91092,"Missing"
C98-1113,1993.tmi-1.17,0,\N,Missing
C98-1113,A94-1006,0,\N,Missing
C98-1113,J90-2002,0,\N,Missing
C98-1113,P91-1022,0,\N,Missing
D07-1092,P02-1051,0,0.0750448,"Missing"
D07-1092,N06-1003,0,0.0229373,"mittedly, several unsupervised morphological induction methodologies have been proposed, e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage. Related Work We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entities (Chen et al., 1998; AlOnaizan and Knight, 2002). Our approach is complementary to those ones. Recently and more closely related to the approach we described, Callison-Burch et al. (2006) proposed to replace an unknown phrase in a source sentence by a paraphrase. Paraphrases in their work are acquired thanks to a word alignment computed over a large external set of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases from. Therefore we feel our approach is more suited for translating “low density” languages and languages with a rich morphology. Several authors considered as well the tr"
D07-1092,P98-1036,0,0.0776718,"ovic and Ney, 2004; Goldwater and McClosky, 2005). Our approach does not require any morphological knowledge of the source, the target, or both languages. Admittedly, several unsupervised morphological induction methodologies have been proposed, e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage. Related Work We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entities (Chen et al., 1998; AlOnaizan and Knight, 2002). Our approach is complementary to those ones. Recently and more closely related to the approach we described, Callison-Burch et al. (2006) proposed to replace an unknown phrase in a source sentence by a paraphrase. Paraphrases in their work are acquired thanks to a word alignment computed over a large external set of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases fro"
D07-1092,W05-0617,0,0.0119399,"equately rendered by the modal will in English. 5 The use of morphological analysis in (statistical) machine translation has been the focus of several studies, (Nießen, 2002) among the first. Depending on the pairs of languages considered, gains have been reported when the training material is of modest size (Lee, 2004; Popovic and Ney, 2004; Goldwater and McClosky, 2005). Our approach does not require any morphological knowledge of the source, the target, or both languages. Admittedly, several unsupervised morphological induction methodologies have been proposed, e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage. Related Work We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entities (Chen et al., 1998; AlOnaizan and Knight, 2002). Our approach is complementary to those ones. Recently and more closely related to the approach we described, Callison-Burch et al. (2006) proposed to replace an unknown phrase in a source sentence by a paraphrase. Paraphrases in their work a"
D07-1092,P98-1069,0,0.0959984,"d alignment computed over a large external set of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases from. Therefore we feel our approach is more suited for translating “low density” languages and languages with a rich morphology. Several authors considered as well the translation of new words by relying on distributional collocational properties computed from a huge non-parallel corpus (Rapp, 1999; Fung and Yee, 1998; Takaaki and Matsuo, 1999; Koehn and Knight, 2002). Even if admittedly non-parallel corpora are easier to acquire than bitexts, this line of work is still heavily dependent on huge external resources. Most of the analogies made at the word level in our study are capturing morphological information. 10 We do use a target vocabulary list to filter out spurious analogies, but we believe we could do without. The frequency with which we generate a string could serve to decide upon its legitimacy. 885 6 Discussion and Future Work In this paper, we have investigated the appropriateness of analogical"
D07-1092,H05-1085,0,0.021554,"ples of translations are reported in Figure 6. We observe that single words are not contrived anymore to be translated by a single word. This allows to capture 1:n relations such as d´epasseront↔will exceed, where the future tense of the French word is adequately rendered by the modal will in English. 5 The use of morphological analysis in (statistical) machine translation has been the focus of several studies, (Nießen, 2002) among the first. Depending on the pairs of languages considered, gains have been reported when the training material is of modest size (Lee, 2004; Popovic and Ney, 2004; Goldwater and McClosky, 2005). Our approach does not require any morphological knowledge of the source, the target, or both languages. Admittedly, several unsupervised morphological induction methodologies have been proposed, e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage. Related Work We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entities (Chen et al., 1998; AlOnaizan and Knight, 2002). O"
D07-1092,W02-0902,0,0.0536611,"of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases from. Therefore we feel our approach is more suited for translating “low density” languages and languages with a rich morphology. Several authors considered as well the translation of new words by relying on distributional collocational properties computed from a huge non-parallel corpus (Rapp, 1999; Fung and Yee, 1998; Takaaki and Matsuo, 1999; Koehn and Knight, 2002). Even if admittedly non-parallel corpora are easier to acquire than bitexts, this line of work is still heavily dependent on huge external resources. Most of the analogies made at the word level in our study are capturing morphological information. 10 We do use a target vocabulary list to filter out spurious analogies, but we believe we could do without. The frequency with which we generate a string could serve to decide upon its legitimacy. 885 6 Discussion and Future Work In this paper, we have investigated the appropriateness of analogical learning to handle unknown words in machine transl"
D07-1092,E03-1076,0,0.0673952,"Missing"
D07-1092,W06-3114,0,0.0167424,"the only words Si and Sj close enough to S. More precisely, we enforce that Si ∈ vδ (S) and that Sj ∈ vβ (Si ) for a neighborhood function vγ (A) of the form: vγ (A) = {B |f (B, A) ≤ γ} where f is a distance; we used the edit-distance in this study (Levenshtein, 1966). Note that the second strategy we apply is only a heuristic. 3 Resources In this work, we are concerned with one concrete problem a machine translation system must face: the one of translating unknown words. We are further focusing on the shared task of the workshop on Statistical Machine Translation, which took place last year (Koehn and Monz, 2006) and consisted in translating Spanish, German, and French texts from and to English. For some reasons, we restricted ourselves to translating only into English. The training material available is coming from the Europarl corpus. The test material was divided into two parts.5 The first one (hereafter called test-in) is composed of 2 000 sentences from European parliament debates. The second part (called test-out) gathers 1 064 sentences6 collected from editorials of the Project Syndicate website.7 The main statistics pertinent to our study are summarized in Table 1. A rough analysis of the 441"
D07-1092,N04-4015,0,0.0221474,"ured while translating words. Examples of translations are reported in Figure 6. We observe that single words are not contrived anymore to be translated by a single word. This allows to capture 1:n relations such as d´epasseront↔will exceed, where the future tense of the French word is adequately rendered by the modal will in English. 5 The use of morphological analysis in (statistical) machine translation has been the focus of several studies, (Nießen, 2002) among the first. Depending on the pairs of languages considered, gains have been reported when the training material is of modest size (Lee, 2004; Popovic and Ney, 2004; Goldwater and McClosky, 2005). Our approach does not require any morphological knowledge of the source, the target, or both languages. Admittedly, several unsupervised morphological induction methodologies have been proposed, e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage. Related Work We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entit"
D07-1092,2005.iwslt-1.4,0,0.317202,"Missing"
D07-1092,P98-1120,0,0.582834,"the inference procedure rely on the existence of an analogical solver, which we sketch in the next section. One important thing to note at this stage, is that an analogical equation may have several solutions, some being legitimate word-forms in a given language, others being not. Thus, it is important to select wisely the generated solutions, therefore Step 3. In practice, the inference procedure involves the computation of many analogical equations, and a statistic as simple as the frequency of a solution often suffices to separate good from spurious solutions. 2.2 Analogical Solver Lepage (1998) proposed an algorithm for computing the solutions of a formal analogical equation [A : B = C : ? ]. We implemented a variant of this algorithm which requires to compute two editdistance tables, one between A and B and one between A and C. Since we are looking for subsequences of B and C not present in A, insertion cost is null. Once this is done, the algorithm synchronizes the alignments defined by the paths of minimum cost in each table. Intuitively, the synchronization of two alignments (one between A and B, and one between A and C) consists in composing in the correct order subsequences of"
D07-1092,P02-1040,0,0.106119,"Missing"
D07-1092,W06-3116,1,0.846894,"Missing"
D07-1092,popovic-ney-2004-towards,0,0.0379203,"translating words. Examples of translations are reported in Figure 6. We observe that single words are not contrived anymore to be translated by a single word. This allows to capture 1:n relations such as d´epasseront↔will exceed, where the future tense of the French word is adequately rendered by the modal will in English. 5 The use of morphological analysis in (statistical) machine translation has been the focus of several studies, (Nießen, 2002) among the first. Depending on the pairs of languages considered, gains have been reported when the training material is of modest size (Lee, 2004; Popovic and Ney, 2004; Goldwater and McClosky, 2005). Our approach does not require any morphological knowledge of the source, the target, or both languages. Admittedly, several unsupervised morphological induction methodologies have been proposed, e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage. Related Work We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entities (Chen et al., 1998;"
D07-1092,P99-1067,0,0.032949,"nks to a word alignment computed over a large external set of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases from. Therefore we feel our approach is more suited for translating “low density” languages and languages with a rich morphology. Several authors considered as well the translation of new words by relying on distributional collocational properties computed from a huge non-parallel corpus (Rapp, 1999; Fung and Yee, 1998; Takaaki and Matsuo, 1999; Koehn and Knight, 2002). Even if admittedly non-parallel corpora are easier to acquire than bitexts, this line of work is still heavily dependent on huge external resources. Most of the analogies made at the word level in our study are capturing morphological information. 10 We do use a target vocabulary list to filter out spurious analogies, but we believe we could do without. The frequency with which we generate a string could serve to decide upon its legitimacy. 885 6 Discussion and Future Work In this paper, we have investigated the appropria"
D07-1092,W05-0616,0,0.644725,"ams. The interested reader can find in (Lepage, 2003) a particularly dense treatment of analogy, including a fascinating chapter on the history of the notion of analogy. The concept of proportional analogy, denoted [A : B = C : D ], is a relation between four entities which reads: “A is to B as C is to D ”. Among proportional analogies, we distinguish formal analogies, that is, ones that arise at the graphical level, such as [fournit : fleurit = fournie : fleurie] in French or [believer : unbelievable = doer : undoable] in English. Formal analogies are often good indices for deeper analogies (Stroppa and Yvon, 2005). Lepage and Denoual (2005) presented the system ALEPH, an intriguing example-based system entirely built on top of an automatic formal analogy solver. This system has achieved state-of-theart performance on the IWSLT task (Eck and Hori, 2005), despite its striking purity. As a matter of fact, ALEPH requires no distances between examples, nor any threshold.1 It does not even rely on a tokenization device. One reason for its success probably lies in the specificity of the BTEC corpus: short and simple sentences of a narrow domain. It is doubtful that ALEPH would still behave adequately on broad"
D07-1092,1999.tmi-1.11,0,0.0477083,"over a large external set of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases from. Therefore we feel our approach is more suited for translating “low density” languages and languages with a rich morphology. Several authors considered as well the translation of new words by relying on distributional collocational properties computed from a huge non-parallel corpus (Rapp, 1999; Fung and Yee, 1998; Takaaki and Matsuo, 1999; Koehn and Knight, 2002). Even if admittedly non-parallel corpora are easier to acquire than bitexts, this line of work is still heavily dependent on huge external resources. Most of the analogies made at the word level in our study are capturing morphological information. 10 We do use a target vocabulary list to filter out spurious analogies, but we believe we could do without. The frequency with which we generate a string could serve to decide upon its legitimacy. 885 6 Discussion and Future Work In this paper, we have investigated the appropriateness of analogical learning to handle unknow"
D07-1092,J06-3003,0,0.0150167,"ents of EO (X). This inference procedure shares similarities with the K-nearest-neighbor (k-NN) approach. In particular, since no model of the training material is being learned, the training corpus needs to be stored in order to be queried. On the contrary to k-NN, however, the search for closest neighbors does not require any distance, but instead relies on relational similarities. This purity has a cost: while in k-NN inference, neighbors can be found in time linear to the training size, in analogical learning, this operation requires a computation time cubic in N , the 2 In Turney’s work (Turney, 2006), a stem designates the first two words of a proportional analogy. 878 number of observations. In many applications of interest, including the one we tackle here, this is simply impractical and heuristics must be applied. The first and second steps of the inference procedure rely on the existence of an analogical solver, which we sketch in the next section. One important thing to note at this stage, is that an analogical equation may have several solutions, some being legitimate word-forms in a given language, others being not. Thus, it is important to select wisely the generated solutions, th"
D07-1092,C98-1066,0,\N,Missing
D07-1092,C98-1036,0,\N,Missing
D07-1092,2005.iwslt-1.1,0,\N,Missing
D07-1092,C98-1116,0,\N,Missing
D07-1092,P00-1056,0,\N,Missing
E09-1056,J93-2003,0,0.00944004,"If machine translation is to meet commercial needs, it must offer a sensible approach to translating terms. Currently, MT systems offer at best database management tools which allow a human (typically a translator, a terminologist or even the vendor of the system) to specify bilingual terminological entries. More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations (Itagaki et al., 2007). One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques (Brown et al., 1993) to mine new translations. Massive amounts of parallel data are certainly available in several pairs of languages for domains such as parliament debates or the like. However, having at our disposal a domain-specific (e.g. computer science) bitext Proceedings of the 12th Conference of the European Chapter of the ACL, pages 487–495, c Athens, Greece, 30 March – 3 April 2009. 2009 Association for Computational Linguistics 487 2.2 In the remainder of this paper, we first present in Section 2 the principle of analogical learning. Practical issues in analogical learning are discussed in Section 3 al"
E09-1056,W05-0616,1,0.948584,"ector techniques (Rapp, 1995; Fung and McKeown, 1997) can be used to identify the translation of terms. We certainly agree with that point of view to a certain extent, but as discussed by Morin et al. (2007), for many specific domains and pairs of languages, such resources simply do not exist. Furthermore, the task of translation identification is more difficult and error-prone. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. In this study, we improve the state-of-the-art of analogical learning by (i) proposing a simple yet effective implementation of an analogical solver; (ii) proposing an efficient solution to the search issue embedded in analogical learning, (iii) investigating whether a classifier can be trained to recogn"
E09-1056,W02-1001,0,0.0246147,"Missing"
E09-1056,P08-1059,0,0.0441301,"Missing"
E09-1056,2007.mtsummit-papers.19,0,0.512696,"such resources simply do not exist. Furthermore, the task of translation identification is more difficult and error-prone. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. In this study, we improve the state-of-the-art of analogical learning by (i) proposing a simple yet effective implementation of an analogical solver; (ii) proposing an efficient solution to the search issue embedded in analogical learning, (iii) investigating whether a classifier can be trained to recognize bad candidates produced by analogical learning. We evaluate our analogical engine on the task of translating terms of the medical domain; a domain well-known for its tendency to create new words, many of which being complex lexical constructions."
E09-1056,W07-0705,0,0.0544343,"Missing"
E09-1056,W97-0119,0,0.0759318,"Missing"
E09-1056,2007.mtsummit-papers.36,0,0.0122855,"nguage pairs written in different scripts. Combining it with a phrasebased statistical engine leads to significant improvements. 1 Introduction If machine translation is to meet commercial needs, it must offer a sensible approach to translating terms. Currently, MT systems offer at best database management tools which allow a human (typically a translator, a terminologist or even the vendor of the system) to specify bilingual terminological entries. More advanced tools are meant to identify inconsistencies in terminological translations and might prove useful in controlledlanguage situations (Itagaki et al., 2007). One approach to translate terms consists in using a domain-specific parallel corpus with standard alignment techniques (Brown et al., 1993) to mine new translations. Massive amounts of parallel data are certainly available in several pairs of languages for domains such as parliament debates or the like. However, having at our disposal a domain-specific (e.g. computer science) bitext Proceedings of the 12th Conference of the European Chapter of the ACL, pages 487–495, c Athens, Greece, 30 March – 3 April 2009. 2009 Association for Computational Linguistics 487 2.2 In the remainder of this pap"
E09-1056,koen-2004-pharaoh,0,0.0664297,"Missing"
E09-1056,D07-1092,1,0.880221,"gree with that point of view to a certain extent, but as discussed by Morin et al. (2007), for many specific domains and pairs of languages, such resources simply do not exist. Furthermore, the task of translation identification is more difficult and error-prone. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. In this study, we improve the state-of-the-art of analogical learning by (i) proposing a simple yet effective implementation of an analogical solver; (ii) proposing an efficient solution to the search issue embedded in analogical learning, (iii) investigating whether a classifier can be trained to recognize bad candidates produced by analogical learning. We evaluate our analogical engine on the task of translating terms o"
E09-1056,C08-2013,1,0.8318,"f I(u), denoted N (t). Those solutions that belong to the input space are the z-forms retained; EI (u) = { hx, y, zi : EI (u) = { hx, y, zi : x ∈ I, hy, zi ∈ C(hx, ti), [x : y = z : t] } where C(hx, ti) denotes the set of pairs hy, zi which satisfy the count property. This strategy will only work if (i) the number of quadruplets to check is much smaller than the number of triplets we can form in the input space (which happens to be the case in practice), and if (ii) we can efficiently identify the pairs hy, zi that satisfy a set of constraints on character counts. To this end, we proposed in (Langlais and Yvon, 2008) to organize the input space into a data structure which supports efficient runtime retrieval. x ∈ N (t) , y ∈ N (x), z ∈ [y : x = t : ? ] ∩ I } This strategy (hereafter named LP) directly follows from a symmetrical property of an analogy ([x : y = z : t] ⇔ [y : x = t : z]), and reduces the search procedure to the resolution of a number of analogical equations which is quadratic with the number of pairs hx, yi sampled. We found this strategy to be of little use for input spaces larger than a few tens of thousands forms. To solve this problem, we exploit a property on symbol counts that an anal"
E09-1056,2005.iwslt-1.4,0,0.0842875,"another issue. One might argue that domain-specific comparable (or perhaps unrelated) corpora are easier to acquire, in which case context-vector techniques (Rapp, 1995; Fung and McKeown, 1997) can be used to identify the translation of terms. We certainly agree with that point of view to a certain extent, but as discussed by Morin et al. (2007), for many specific domains and pairs of languages, such resources simply do not exist. Furthermore, the task of translation identification is more difficult and error-prone. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several European languages, an idea investigated as well by Denoual (2007) for a Japanese to English translation task. In this study, we improve the state-of-the-art of analogical learning by (i) proposing a simple yet effective implementation of an analogical solver; (ii) proposing an"
E09-1056,P98-1120,0,0.343527,"set. Our solver, depicted in Algorithm 2, is thus controlled by a sampling size s, the impact of which is illustrated in Table 1. By increasing s, the solver generates more (mostly spurious) solutions, but also increases the relative frequency with which the expected output is generated. In practice, provided a large enough sampling size,2 the expected form very often appears among the most frequent ones. selecting good candidates involves some practical issues. Since searching for input triplets might involve the need for solving (input) equations, we discuss the solver first. 3.1 The solver Lepage (1998) proposed an algorithm for solving an analogical equation [x : y = z : ? ]. An alignment between x and y and between x and z is first computed (by edit-distance) as illustrated in Figure 1. Then, the three strings are synchronized using x as a backbone of the synchronization. The algorithm can be seen as a deterministic finite-state machine where a state is defined by the two edit-operations being visited in the two tables. This is schematized by the two cursors in the figure. Two actions are allowed: copy one symbol from y or z into the solution and move one or both cursors. x: r e a d er y:"
E09-1056,P06-1096,0,0.0437426,"Missing"
E09-1056,P07-1084,0,0.0158288,"ing: Application to Translating multi-Terms of the Medical Domain Philippe Langlais DIRO Univ. of Montreal, Canada felipe@iro.umontreal.ca Franc¸ois Yvon and Pierre Zweigenbaum LIMSI-CNRS Univ. Paris-Sud XI, France {yvon,pz}@limsi.fr Abstract with an adequate coverage is another issue. One might argue that domain-specific comparable (or perhaps unrelated) corpora are easier to acquire, in which case context-vector techniques (Rapp, 1995; Fung and McKeown, 1997) can be used to identify the translation of terms. We certainly agree with that point of view to a certain extent, but as discussed by Morin et al. (2007), for many specific domains and pairs of languages, such resources simply do not exist. Furthermore, the task of translation identification is more difficult and error-prone. Analogical learning has recently regained some interest in the NLP community. Lepage and Denoual (2005) proposed a machine translation system entirely based on the concept of formal analogy, that is, analogy on forms. Stroppa and Yvon (2005) applied analogical learning to several morphological tasks also involving analogies on words. Langlais and Patry (2007) applied it to the task of translating unknown words in several"
E09-1056,C98-1116,0,\N,Missing
E09-1056,2007.iwslt-1.7,0,\N,Missing
F14-1004,J92-4003,0,0.586256,"Missing"
F14-1004,N10-1138,0,0.0354473,"Missing"
F14-1004,P11-1144,0,0.0334949,"Missing"
F14-1004,de-marneffe-etal-2006-generating,0,0.0108994,"Missing"
F14-1004,N03-2008,0,0.0859228,"Missing"
F14-1004,W03-1007,0,0.10453,"Missing"
F14-1004,P00-1065,0,0.113975,"Missing"
F14-1004,johansson-etal-2012-semantic,0,0.0315684,"Missing"
F14-1004,S07-1048,0,0.0742759,"Missing"
F14-1004,P98-2127,0,0.371072,"Missing"
F14-1004,J08-2005,0,0.0309939,"Missing"
F14-1004,P10-1040,0,0.0890209,"Missing"
foster-etal-2002-text,J99-4005,0,\N,Missing
foster-etal-2002-text,J93-2003,0,\N,Missing
foster-etal-2002-text,C00-2123,0,\N,Missing
foster-etal-2002-text,P98-2158,0,\N,Missing
foster-etal-2002-text,C98-2153,0,\N,Missing
foster-etal-2002-text,W00-0707,1,\N,Missing
foster-etal-2002-text,W02-1020,1,\N,Missing
foster-etal-2002-text,P00-1006,1,\N,Missing
H05-1095,J93-2003,0,0.00752012,"asured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequences of words? In doing so we expect to improve translation quality by better accounting for additional linguistic phenome"
H05-1095,P05-1033,0,0.0570595,"ned training corpus. Our approach is based on a direct approximation of the posterior probability Pr (tI1 |sJ1 ), using a loglinear model: Pr (tI1 |sJ1 ) M X Our model currently relies on seven feature functions, which we describe here. (1) 1 1 = exp ZsJ • The compositional bi-phrase feature function hcomp : this is introduced to compensate for ! λm hm (tI1 , sJ1 ) m=1 1 In such a model, the contribution of each feature function hm is determined by the corresponding model parameter λm ; ZsJ denotes a normalization 1 constant. This type of model is now quite widely 757 Recent work from Chiang (Chiang, 2005) addresses similar concerns to those motivating our work by introducing a Synchronous CFG for bi-phrases. If on one hand SCFGs allow to better control the order of the material inserted in the gaps, on the other gap size does not seem to be taken into account, and phrase dovetailing such as the one involving “do want” and “not anymore” in Fig. 2 is disallowed. hbp ’s strong tendency to overestimate the probability of rare bi-phrases; it is computed as in equation (2), except that bi-phrase probabilities are computed based on individual word translation probabilities, somewhat as in IBM mod"
H05-1095,P01-1030,1,0.79189,"uent source phrases, as most phrases have less than 20 translations. 6.3 Experiments The parameters of the model were optimized independantly for each bi-phrase library. In all cases, we performed only 2 iterations of the training procedure, then measured the performance of the system on the test set in terms of the NIST and BLEU scores against one reference translation. As a point of comparison, we also trained an IBM-4 translation model with the GIZA++ toolkit (Och and Ney, 2000), using the combined bi-phrase building and training sets, and translated the test set using the ReWrite decoder (Germann et al., 2001)5 . Table 2 describes the various libraries that were used for our experiments, and the results obtained for each. System/library ReWrite A1 A2 -g0 A2 -g3 B 1 -g0 B1 B 2 -g0 B 2 -g3 B 1 -g1 B 1 -g2 B 1 -g3 B 1 -g4 bi-phrases 238 K 642 K 4.1 M 193 K 267 K 499 K 3.3 M 206 K 213 K 218 K 222 K NIST 6.6838 6.6695 6.7675 6.7068 6.7898 6.9172 6.7290 6.9707 6.8979 6.9406 6.9546 6.9527 BLEU 0.3324 0.3310 0.3363 0.3283 0.3369 0.3407 0.3391 0.3552 0.3441 0.3454 0.3518 0.3423 Table 2: Bi-phrase libraries and results The top part of the table presents the results for the A libraries. As can be seen, librar"
H05-1095,P04-1064,1,0.936967,"iterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, such as the method described in (Goutte et al., 2004). By means of a matrix factorization, this method produces a parallel partition of the two texts, seen as sets of word tokens. Each token therefore belongs to one, and only one, subset within this partition, and corresponding subsets in the source and target make up what are called cepts. For example, in Figure 1, these cepts are represented by the circles numbered 1, 2 and 3; each cept thus connects word tokens in the source and the target, regardless of position or contiguity. These cepts naturally constitute bi-phrases, and can be used directly to produce a biphrase library. Obviously, the"
H05-1095,W02-1018,0,0.0165656,"lso presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequ"
H05-1095,P00-1056,0,0.0383638,"equivalents. While the first of these filters typically eliminates a large number of entries, the second only affects the most frequent source phrases, as most phrases have less than 20 translations. 6.3 Experiments The parameters of the model were optimized independantly for each bi-phrase library. In all cases, we performed only 2 iterations of the training procedure, then measured the performance of the system on the test set in terms of the NIST and BLEU scores against one reference translation. As a point of comparison, we also trained an IBM-4 translation model with the GIZA++ toolkit (Och and Ney, 2000), using the combined bi-phrase building and training sets, and translated the test set using the ReWrite decoder (Germann et al., 2001)5 . Table 2 describes the various libraries that were used for our experiments, and the results obtained for each. System/library ReWrite A1 A2 -g0 A2 -g3 B 1 -g0 B1 B 2 -g0 B 2 -g3 B 1 -g1 B 1 -g2 B 1 -g3 B 1 -g4 bi-phrases 238 K 642 K 4.1 M 193 K 267 K 499 K 3.3 M 206 K 213 K 218 K 222 K NIST 6.6838 6.6695 6.7675 6.7068 6.7898 6.9172 6.7290 6.9707 6.8979 6.9406 6.9546 6.9527 BLEU 0.3324 0.3310 0.3363 0.3283 0.3369 0.3407 0.3391 0.3552 0.3441 0.3454 0.3518 0.3"
H05-1095,J03-1002,0,0.00889681,"d on the first “free” position in the target language sentence, i.e. either the leftmost gap, or the right end of the sequence. Figure 2 illustrates this process with an example. To produce translations, our approach therefore relies on a collection of bi-phrases, what we call a bi-phrase library. Such a library is constructed from a corpus of existing translations, aligned at the word level. Two strategies come to mind to produce noncontiguous bi-phrases for these libraries. The first is to align the words using a “standard” word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, su"
H05-1095,J04-4002,0,0.0387242,"ting translations, aligned at the word level. Two strategies come to mind to produce noncontiguous bi-phrases for these libraries. The first is to align the words using a “standard” word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, such as the method described in (Goutte et al., 2004). By means of a matrix factorization, this method produces a parallel partition of the two texts, seen as sets of word tokens. Each token therefore belongs to one, and only one, subset within this partition, and corresponding subsets in the source and target make up what are called cepts. For examp"
H05-1095,W99-0604,0,0.0809757,"slation model is also presented that deals such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possib"
H05-1095,P03-1021,0,0.0338002,"guities they contain. 4 Say we have a set of source-language sentences S. For a given value of λ, we can compute the set of corresponding target-language translations T . Given a set of reference (“gold-standard”) translations R for S and a function E(T, R) which measures the “error” in T relative to R, then we can formulate the parameter estimation problem as2 : Parameter Estimation The values of the λ parameters of the log-linear model can be set so as to optimize a given criterion. For instance, one can maximize the likelyhood of some set of training sentences. Instead, and as suggested by Och (2003), we chose to maximize directly the quality of the translations produced by the system, as measured with a machine translation evaluation metric. 758 As pointed out by Och, one notable difficulty with this approach is that, because the computation of T is based on an argmax operation (see eq. 1), it is not continuous with regard to λ, and standard gradientdescent methods cannot be used to solve the optimization. Och proposes two workarounds to this problem: the first one relies on a direct optimization method derived from Powell’s algorithm; the second introduces a smoothed (continuous) versio"
H05-1095,P02-1040,0,0.111177,"to λ, and standard gradientdescent methods cannot be used to solve the optimization. Och proposes two workarounds to this problem: the first one relies on a direct optimization method derived from Powell’s algorithm; the second introduces a smoothed (continuous) version of the error function E(T, R) and then relies on a gradient-based optimization method. We have opted for this last approach. Och shows how to implement it when the error function can be computed as the sum of errors on individual sentences. Unfortunately, this is not the case for such widely used MT evaluation metrics as BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). We show here how it can be done for NIST; a similar derivation is possible for BLEU. The NIST evaluation metric computes a weighted n-gram precision between T and R, multiplied by a factor B(S, T, R) that penalizes short translations. It can be formulated as: B(S, T, R) × N X n=1 P s∈S In (ts , rs ) P s∈S Cn (ts ) (3) where N is the largest n-gram considered (usually N = 4), In (ts , rs ) is a weighted count of common n-grams between the target (ts ) and reference (rs ) translations of sentence s, and Cn (ts ) is the total number of n-grams in ts . To derive a ver"
H05-1095,N03-2036,0,0.095765,"as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequences of words? In doing so we expect to improve t"
H05-1095,P02-1039,1,0.503169,"ls such phrases, as well as a training method based on the maximization of translation accuracy, as measured with the NIST evaluation metric. Translations are produced by means of a beam-search decoder. Experimental results are presented, that demonstrate how the proposed method allows to better generalize from the training data. 1 Arne Mauser RWTH Aachen University arne.mauser@rwth-aachen.de 2 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al., 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003). While in traditional word-based statistical models (Brown et al., 1993) the atomic unit that translation operates on is the word, phrase-based methods acknowledge the significant role played in language by multiword expressions, thus incorporating in a statistical framework the insight behind Example-Based Machine Translation (Somers, 1999). However, Phrase-based models proposed so far only deal with multi-word units that are sequences Non-contiguous phrases Why should it be a good thing to use phrases composed of possibly non-contiguous sequences of words? In doing"
H05-1095,N03-1017,0,0.183385,"rom a corpus of existing translations, aligned at the word level. Two strategies come to mind to produce noncontiguous bi-phrases for these libraries. The first is to align the words using a “standard” word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences. This is the strategy that is usually adopted in other phrase-based MT approaches (Zens and Ney, 2003; Och and Ney, 2004). Here, the difference is that we are not restricted to combinations that produce strictly contiguous bi-phrases. The second strategy is to rely on a wordalignment method that naturally produces many-tomany alignments between non-contiguous words, such as the method described in (Goutte et al., 2004). By means of a matrix factorization, this method produces a parallel partition of the two texts, seen as sets of word tokens. Each token therefore belongs to one, and only one, subset within this partition, and corresponding subsets in the source and target make up what are cal"
H05-1095,N04-1033,0,\N,Missing
I11-1074,P07-1020,0,0.019786,"ead of source words like Venkatapathy and Bangalore (2009) suggested. This approach has its limitation because it only captures local structures and cannot consider grammatical or semantic relations. We are thus thinking about alternative ways to encode the source sentences and how these new representations could be included to our model. Previous Works To our knowledge, IBM 1 is the first target vocabulary prediction models that was used in SMT. It was one of the best model among many others in a rescoring module for a PBSMT (Och et al., 2004). The term global lexical selection was coined by Bangalore et al. (2007) who pushed the idea of target vocabulary prediction further than us. They devised a system that first predicted a set of target words and then reordered those words to produce a final translation. This system is particularly suited for languages that are not sensitive to word reordering like Hindi (Venkatapathy and Bangalore, 2009). Their system use a logistic regression model to predict the target words from the set of n-grams in the source sentence. Our pred score is a softer version of this idea. It encourages the decoder to select the predicted words without forcing it and it allows the r"
I11-1074,P07-2045,0,0.0100378,"absent from it. An interesting property of this score is that it is proportional to eq. 1 once the source sentence is known. We evaluated a second score that counts the number of target words with a probability higher than a given threshold α: pred(t |s) = {t ∈ t |yt|s > α} (11) Experiments We integrated our prediction models (see section 6.1) in an in house multi-stack phrase-based decoder which has performances similar to those of PHARAOH (Koehn, 2004a) when used in the same conditions. We trained our phrase-table using TRAIN FACTORED - MODEL . PERL, a script available with the MOSES PBSMT (Koehn et al., 2007). We optimized the weights of our log-linear model to maximize BLEU on our development set with the Nelder-Mead algorithm (Press et al., 1992) on nbest lists of 2000 sentences. To keep the decoding time reasonable, we limited the number of translations per source phrase to 30 and the number of hypotheses per stack to 50. We conducted our experiments with a trigram language model. We are aware that our system could be enhanced in several ways. The distortion models embedded in MOSES are known to improve quality upon the translations produced by PHARAOH, and larger ngram models, such as 5-gram m"
I11-1074,H94-1028,0,0.0771935,"Missing"
I11-1074,koen-2004-pharaoh,0,0.04792,"g the gradients. 6 Prediction scores An odd of x for a given word means that this word is x times more likely to be present in the translation than to be absent from it. An interesting property of this score is that it is proportional to eq. 1 once the source sentence is known. We evaluated a second score that counts the number of target words with a probability higher than a given threshold α: pred(t |s) = {t ∈ t |yt|s > α} (11) Experiments We integrated our prediction models (see section 6.1) in an in house multi-stack phrase-based decoder which has performances similar to those of PHARAOH (Koehn, 2004a) when used in the same conditions. We trained our phrase-table using TRAIN FACTORED - MODEL . PERL, a script available with the MOSES PBSMT (Koehn et al., 2007). We optimized the weights of our log-linear model to maximize BLEU on our development set with the Nelder-Mead algorithm (Press et al., 1992) on nbest lists of 2000 sentences. To keep the decoding time reasonable, we limited the number of translations per source phrase to 30 and the number of hypotheses per stack to 50. We conducted our experiments with a trigram language model. We are aware that our system could be enhanced in sever"
I11-1074,W04-3250,0,0.0195444,"g the gradients. 6 Prediction scores An odd of x for a given word means that this word is x times more likely to be present in the translation than to be absent from it. An interesting property of this score is that it is proportional to eq. 1 once the source sentence is known. We evaluated a second score that counts the number of target words with a probability higher than a given threshold α: pred(t |s) = {t ∈ t |yt|s > α} (11) Experiments We integrated our prediction models (see section 6.1) in an in house multi-stack phrase-based decoder which has performances similar to those of PHARAOH (Koehn, 2004a) when used in the same conditions. We trained our phrase-table using TRAIN FACTORED - MODEL . PERL, a script available with the MOSES PBSMT (Koehn et al., 2007). We optimized the weights of our log-linear model to maximize BLEU on our development set with the Nelder-Mead algorithm (Press et al., 1992) on nbest lists of 2000 sentences. To keep the decoding time reasonable, we limited the number of translations per source phrase to 30 and the number of hypotheses per stack to 50. We conducted our experiments with a trigram language model. We are aware that our system could be enhanced in sever"
I11-1074,D07-1036,0,0.0452525,"Missing"
I11-1074,D07-1007,0,0.0608064,"on the bias of the training corpus (words already translated are strike through). be similar to the source sentence (Hildebrand et al., 2005; L¨u et al., 2007). A second group of approaches cast the target phrase selection problem in a word sense disambiguation setting where source phrases are considered as ambiguous words and their translations as different meanings (Vickrey et al., 2005). This usually boils down to training one classifier per source phrase. These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008) use the same contextual scores for all the source phrases. The weights of those scores are then optimized with the other weights of the decoder. Finally a third group of approaches assign a probability to every words in the target vocabulary given a source sentence (Venkatapathy and Bangalore, 2009; Mauser et al., 2009; Patry and Langlais, 2009). This predicted vocabulary can guide the decoder at translation time. Our approach stands in this last group and we present its ge"
I11-1074,D09-1022,0,0.621659,"er per source phrase. These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008) use the same contextual scores for all the source phrases. The weights of those scores are then optimized with the other weights of the decoder. Finally a third group of approaches assign a probability to every words in the target vocabulary given a source sentence (Venkatapathy and Bangalore, 2009; Mauser et al., 2009; Patry and Langlais, 2009). This predicted vocabulary can guide the decoder at translation time. Our approach stands in this last group and we present its general idea in section 2. While previous approaches used linear or logistic regression models, we opted for the multilayer perceptron presented in section 3. Section 4 motivates this choice with a simple example. Section 5 details the algorithm to train our MLP. Experimental results, previous works and conclusion then follow in sections 6, 7 and 8 respectively. 2 Target vocabulary prediction Standard PBSMT systems condition their translati"
I11-1074,P07-1005,0,0.0599917,"lready translated are strike through). be similar to the source sentence (Hildebrand et al., 2005; L¨u et al., 2007). A second group of approaches cast the target phrase selection problem in a word sense disambiguation setting where source phrases are considered as ambiguous words and their translations as different meanings (Vickrey et al., 2005). This usually boils down to training one classifier per source phrase. These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008) use the same contextual scores for all the source phrases. The weights of those scores are then optimized with the other weights of the decoder. Finally a third group of approaches assign a probability to every words in the target vocabulary given a source sentence (Venkatapathy and Bangalore, 2009; Mauser et al., 2009; Patry and Langlais, 2009). This predicted vocabulary can guide the decoder at translation time. Our approach stands in this last group and we present its general idea in section 2. While previous ap"
I11-1074,J03-1002,0,0.0140627,"Missing"
I11-1074,W08-0302,0,0.0192937,"Hildebrand et al., 2005; L¨u et al., 2007). A second group of approaches cast the target phrase selection problem in a word sense disambiguation setting where source phrases are considered as ambiguous words and their translations as different meanings (Vickrey et al., 2005). This usually boils down to training one classifier per source phrase. These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008) use the same contextual scores for all the source phrases. The weights of those scores are then optimized with the other weights of the decoder. Finally a third group of approaches assign a probability to every words in the target vocabulary given a source sentence (Venkatapathy and Bangalore, 2009; Mauser et al., 2009; Patry and Langlais, 2009). This predicted vocabulary can guide the decoder at translation time. Our approach stands in this last group and we present its general idea in section 2. While previous approaches used linear or logistic regression models, we opted for the multilayer"
I11-1074,2005.eamt-1.19,0,0.0258398,"here n usually varies between 3 and 5. 658 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 658–666, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP Source Partial target the leaves of this plant les feuilles de cette Pair 1 Pair 2 plant → usine plant → plante a failure. The probability of a target sentence can thus be evaluated with: Present t∈t Figure 1: An example state where the selection of a target phrase depends mostly on the bias of the training corpus (words already translated are strike through). be similar to the source sentence (Hildebrand et al., 2005; L¨u et al., 2007). A second group of approaches cast the target phrase selection problem in a word sense disambiguation setting where source phrases are considered as ambiguous words and their translations as different meanings (Vickrey et al., 2005). This usually boils down to training one classifier per source phrase. These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008)"
I11-1074,2009.mtsummit-papers.12,1,0.722783,"These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008) use the same contextual scores for all the source phrases. The weights of those scores are then optimized with the other weights of the decoder. Finally a third group of approaches assign a probability to every words in the target vocabulary given a source sentence (Venkatapathy and Bangalore, 2009; Mauser et al., 2009; Patry and Langlais, 2009). This predicted vocabulary can guide the decoder at translation time. Our approach stands in this last group and we present its general idea in section 2. While previous approaches used linear or logistic regression models, we opted for the multilayer perceptron presented in section 3. Section 4 motivates this choice with a simple example. Section 5 details the algorithm to train our MLP. Experimental results, previous works and conclusion then follow in sections 6, 7 and 8 respectively. 2 Target vocabulary prediction Standard PBSMT systems condition their translation on one source phrase at"
I11-1074,N03-1017,0,0.010868,"on (MLP). Our interest in MLP lies in their hidden layer which encodes source sentences in a representation that is not directly tied to the notion of word. We evaluated our approach on an English to French translation task. Our MLP model was able to improve BLEU scores over a standard PBSMT system. 1 Philippe Langlais DIRO/RALI Universit´e de Montr´eal Montr´eal, Canada H3C 3J7 felipe@iro.umontreal.ca Introduction Phrase-based statistical machine translation systems translate source sentences step by step, starting with an empty sentence and ending when all source words have been translated (Koehn et al., 2003). At each step, an untranslated phrase is selected and one of its translation is appended at the end of the translation. In this work, we are interested in the selection of a target phrase to translate a given source phrase. This selection is usually guided by three families of models. Translation models evaluate the intrinsic quality of a given phrase pair using evidences such as cooccurrence statistics between 1 Sequences of n words where n usually varies between 3 and 5. 658 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 658–666, c Chiang Mai, Th"
I11-1074,2007.tmi-papers.28,0,0.0581615,"Missing"
I11-1074,H05-1097,0,0.0764465,"euilles de cette Pair 1 Pair 2 plant → usine plant → plante a failure. The probability of a target sentence can thus be evaluated with: Present t∈t Figure 1: An example state where the selection of a target phrase depends mostly on the bias of the training corpus (words already translated are strike through). be similar to the source sentence (Hildebrand et al., 2005; L¨u et al., 2007). A second group of approaches cast the target phrase selection problem in a word sense disambiguation setting where source phrases are considered as ambiguous words and their translations as different meanings (Vickrey et al., 2005). This usually boils down to training one classifier per source phrase. These classifiers use a variety of features like surrounding source words, target words, part-of-speech or lemmas(Berger et al., 1994; Carpuat and Wu, 2007; Stroppa et al., 2007; Chan et al., 2007). Instead of training one classifier per source phrase, Gimpel and Smith (2008) use the same contextual scores for all the source phrases. The weights of those scores are then optimized with the other weights of the decoder. Finally a third group of approaches assign a probability to every words in the target vocabulary given a s"
I11-1074,2007.mtsummit-papers.68,0,0.034847,"options considering only plant. Therefore, the word leaves is never considered and the final decision largely depends on whether the training corpus is more biased toward one translation or the other. This problem is not new and has even been addressed by the creators of CANDIDE (Berger et al., 1994), one of the first SMT system. We know of three groups of approaches for tackling it. A first group of approaches acknowledge the bias of the system and use it at its advantage by customizing the training corpus for each source sentence. This bias can be introduced with thematic training corpora (Xu et al., 2007; L¨u et al., 2007) or with custom corpora built dynamically to Phrase-based statistical machine translation (PBSMT) decoders translate source sentences one phrase at a time using strong independence assumptions over the source phrases. Translation table scores are typically independent of context, language model scores depend on a few words surrounding the target phrase and distortion models do not influence directly the choice of target phrases. In this work, we propose to condition the selection of each target word on the whole source sentence using a multilayer perceptron (MLP). Our intere"
I11-1074,N04-1021,0,\N,Missing
L18-1323,W13-3515,0,0.0946227,"st, it extends the coverage of the existing KB probabilistically to any query, greatly improving upon the closed-world assumption that facts not known to be true are false. Second, as the extraction of information in the open domain is a relatively noisy process, a confidence score helps detecting extraction errors, and makes for higher-quality automatically generated KBs. Last, adjusting the confidence threshold of extracted facts allows to tune as desired the trade-off between precision and recall of the extraction process. The task has attracted little attention since it was introduced in (Angeli and Manning, 2013), most that we know in (Li et al., 2016). The authors propose to assign high KB-membership probability to facts that have support facts existing in the KB, which are similar to them (based on 1 A &quot;fact&quot; is a relation phrase linking two or more argument phrases. The arguments need not be named entities. common phrases and word similarity). We propose a new baseline for this task, in the form of a language model. Whereas the method of (Angeli and Manning, 2013) is fairly complicated to implement, and requires indexing the KB in various ways for intermediate computations, a trained language model"
L18-1323,P15-1034,0,0.0135465,"action, Evaluation, Knowledge Base Completion 1. Introduction Much recent effort has been put into building Knowledge Bases (KBs), either manually curated (Freebase (Bollacker et al., 2008), Cyc (Lenat, 1995)) or automatically produced (YAGO (Suchanek et al., 2007), Knowledge Vault (Dong et al., 2014)), ranging from logically consistent linked-data in OWL (SUMO (Pease et al., 2002)) to little-structured sets of textual relations extracted from text (NELL (Mitchell et al., 2015)) with Open IE systems (Reverb, Ollie (Mausam et al., 2012), ClausIE (Del Corro and Gemulla, 2013), Stanford Open IE (Angeli et al., 2015), CSD-IE (Bast and Haussmann, 2013)). However large they may be, typical KBs are largely incomplete, and many relevant facts are missing (West et al., 2014). Because an exhaustive coverage of the information that ought to be part of the KB is a very desirable feature, KB completion (inference of missing facts from known ones) is a rapidly growing field (West et al., 2014; Nickel et al., 2015; Wang et al., 2015; Toutanova et al., 2016). In the context of Open Information Extraction (OIE), our aim is to assign a score to an arbitrary unseen query fact1 , judging its plausibility as a member of t"
L18-1323,D11-1142,0,0.0588818,"e phrases having at least the same head word. Stricter criteria are used as long as there is a sufficient number of candidates. • Compute the distances between the query fact and each of its supporting facts, using 11 distance metrics, based on both distributional similarity and the WordNet thesaurus - cosine, Jaccard, etc. • The highest similarities are used as weights in a linear classifier, whose job is to agreggate the similarity values across candidates and distance metrics. 2.3. OIE Systems Confidence Contrarily to most OIE systems in which the confidence score is often an afterthought, Fader et al. (2011) went to great lengths to develop Reverb’s confidence function (see their Section 4.2). They manually labeled the extractions from 1000 Web sentences as correct or incorrect, and trained a classifier using features about the original sentence to assign a confidence score to the extraction process. The confidence function of Ollie is based on the frequency of the syntactic pattern that was used to extract a given fact. ClausIE simply returns the confidence score of the underlying dependency parser, as its rules rely directly on it. In contrast to our work, the confidence scores produced by OIE"
L18-1323,C16-1062,0,0.0135704,"examples are automatically generated. We find that this procedure has a significant impact on the difficulty of the task. At last, we go back to the goal of improving existing extractions by picking out the noise. Instead of an automatically generated test set, we measure the ability of the models to identify the remaining wrong extractions in the RV-15M high-quality dataset (presented in section 4.1.). 2. 2.1. Related work Knowledge Base Completion Much work in Knowledge Base Completion (KBC) has been done in recent years (Bordes et al., 2013; Riedel et al., 2013; García-Durán et al., 2015; Feng et al., 2016; Trouillon et al., 2016), on tasks very similar to ours, mostly focusing on Freebase, and other such large manually curated KBs (WordNet, NCI-PID (Schaefer et al., 2008), etc.). The major difference between our approach and most KBC work is the predefined schema of the KB. The arguments of the relations curated in Freebase are mostly named entities, and the relations to be gathered were defined when building the KB. FB15k, a popular Freebase dataset, covers 1345 predicates, though only 401 have more than 100 occurences (Yang et al., 2014). NELL captures about 150 relations, and WordNet about"
L18-1323,W11-2123,0,0.0152837,"constructed, all three argument and relation spans are probable as they stand (since they come from genuine extractions). What makes the fact incorrect is that the parts do not fit together. Therefore, we use as a score the (log) probability of the whole fact minus that of each individual part. We call this model LMjunctions. With {a1 , r, a2 } the fact expressing that the relation r holds between the two arguments a1 and a2 , and p the language model probability function : score({a1 , r, a2 }) = log p(a1 .r.a2 ) − log p(a1 ) − log p(r) − log p(a2 ). We trained the language models with KenLM (Heafield, 2011), using the knowledge base itself as a corpus, each fact being considered as a sentence. We trained 5-gram models (the default), doing as little parameter tuning as possible. Further, we train a linear classifier based on linguistic modeling-based features (LM-SVM). We implemented the SVM with scikit-learn (Pedregosa et al., 2011)2 . It uses 20 features such as the individual log-probabilities of the various parts, the log-probabilities of various bigrams and trigrams focused on the argument-relation junctions, and arithmetic operations over those values. The classifier is trained on 10k genui"
L18-1323,P16-1137,0,0.0815816,"obabilistically to any query, greatly improving upon the closed-world assumption that facts not known to be true are false. Second, as the extraction of information in the open domain is a relatively noisy process, a confidence score helps detecting extraction errors, and makes for higher-quality automatically generated KBs. Last, adjusting the confidence threshold of extracted facts allows to tune as desired the trade-off between precision and recall of the extraction process. The task has attracted little attention since it was introduced in (Angeli and Manning, 2013), most that we know in (Li et al., 2016). The authors propose to assign high KB-membership probability to facts that have support facts existing in the KB, which are similar to them (based on 1 A &quot;fact&quot; is a relation phrase linking two or more argument phrases. The arguments need not be named entities. common phrases and word similarity). We propose a new baseline for this task, in the form of a language model. Whereas the method of (Angeli and Manning, 2013) is fairly complicated to implement, and requires indexing the KB in various ways for intermediate computations, a trained language model is very compact, straightforward to imp"
L18-1323,D12-1048,0,0.0233871,"col, and analyse the shortcomings of our model. Keywords: Open Information Extraction, Evaluation, Knowledge Base Completion 1. Introduction Much recent effort has been put into building Knowledge Bases (KBs), either manually curated (Freebase (Bollacker et al., 2008), Cyc (Lenat, 1995)) or automatically produced (YAGO (Suchanek et al., 2007), Knowledge Vault (Dong et al., 2014)), ranging from logically consistent linked-data in OWL (SUMO (Pease et al., 2002)) to little-structured sets of textual relations extracted from text (NELL (Mitchell et al., 2015)) with Open IE systems (Reverb, Ollie (Mausam et al., 2012), ClausIE (Del Corro and Gemulla, 2013), Stanford Open IE (Angeli et al., 2015), CSD-IE (Bast and Haussmann, 2013)). However large they may be, typical KBs are largely incomplete, and many relevant facts are missing (West et al., 2014). Because an exhaustive coverage of the information that ought to be part of the KB is a very desirable feature, KB completion (inference of missing facts from known ones) is a rapidly growing field (West et al., 2014; Nickel et al., 2015; Wang et al., 2015; Toutanova et al., 2016). In the context of Open Information Extraction (OIE), our aim is to assign a score"
L18-1323,N13-1008,0,0.0315058,"and Manning, 2013) and consider the way negative examples are automatically generated. We find that this procedure has a significant impact on the difficulty of the task. At last, we go back to the goal of improving existing extractions by picking out the noise. Instead of an automatically generated test set, we measure the ability of the models to identify the remaining wrong extractions in the RV-15M high-quality dataset (presented in section 4.1.). 2. 2.1. Related work Knowledge Base Completion Much work in Knowledge Base Completion (KBC) has been done in recent years (Bordes et al., 2013; Riedel et al., 2013; García-Durán et al., 2015; Feng et al., 2016; Trouillon et al., 2016), on tasks very similar to ours, mostly focusing on Freebase, and other such large manually curated KBs (WordNet, NCI-PID (Schaefer et al., 2008), etc.). The major difference between our approach and most KBC work is the predefined schema of the KB. The arguments of the relations curated in Freebase are mostly named entities, and the relations to be gathered were defined when building the KB. FB15k, a popular Freebase dataset, covers 1345 predicates, though only 401 have more than 100 occurences (Yang et al., 2014). NELL ca"
L18-1323,D16-1252,0,0.0261273,"Missing"
L18-1323,P15-2050,0,0.0133592,"presented by the average of their individual words’ embeddings. This performs well on ConceptNet, per (Li et al., 2016), but captures little information on OIE facts. This is both reported by Angeli and Manning (2013) and replicated in our experiments. The full algorithm of (Angeli and Manning, 2013), presented in Section 2.2., is denoted AM-system in Table 1. We reimplemented the count and cos methods used in their evaluation, which are both simplified versions of their approach (the former coarse, and the latter close in principle to the full-fledged scoring function). As has been noted by (Stanovsky et al., 2015), OIE output can be used as training material for other tasks such as text comprehension, word similarity and analogy. This is because OIE produces a distinctive intermediate representation of the sentence, from which complementary features (to that of dependency parse or lexical representations) can be extracted. Moreover, in the confidence scoring function of Reverb, several features capture how completely the extraction covers the sentence’s tokens. In short, the most typical correct extractions look like short declarative sentences, like (Hudson, was born in, Hampstead), or (Hampstead, is"
L18-1323,D15-1174,0,0.0319392,"e predefined schema of the KB. The arguments of the relations curated in Freebase are mostly named entities, and the relations to be gathered were defined when building the KB. FB15k, a popular Freebase dataset, covers 1345 predicates, though only 401 have more than 100 occurences (Yang et al., 2014). NELL captures about 150 relations, and WordNet about 20. By contrast OIE seeks to extract all the relations expressed in text, resulting in hundreds of 2052 thousands of relation predicates (even though many are synonyms). The RV-15M dataset used in this work has 660k distinct relation strings. (Toutanova et al., 2015) embed surface textual patterns in the same vector space as the KB relations, which is similar to the implicit embedding of all predicates in the same vector space as we do. Yet their work only predicts relations based on the 237 predicates of the FB15k-237 dataset, whereas we predict confidence scores for all relations, including predicates never seen during training. OIE evaluation would consider (ideas, sleep, furiously) to be a correct extractions, whereas the goal of our system is to reject any &quot;fact&quot; coming from that sentence on the grounds that they do not make sense. 2.2. 3.1. Angeli a"
L18-1323,P16-1136,0,0.0216537,"tracted from text (NELL (Mitchell et al., 2015)) with Open IE systems (Reverb, Ollie (Mausam et al., 2012), ClausIE (Del Corro and Gemulla, 2013), Stanford Open IE (Angeli et al., 2015), CSD-IE (Bast and Haussmann, 2013)). However large they may be, typical KBs are largely incomplete, and many relevant facts are missing (West et al., 2014). Because an exhaustive coverage of the information that ought to be part of the KB is a very desirable feature, KB completion (inference of missing facts from known ones) is a rapidly growing field (West et al., 2014; Nickel et al., 2015; Wang et al., 2015; Toutanova et al., 2016). In the context of Open Information Extraction (OIE), our aim is to assign a score to an arbitrary unseen query fact1 , judging its plausibility as a member of the KB. This task is important for three reasons : first, it extends the coverage of the existing KB probabilistically to any query, greatly improving upon the closed-world assumption that facts not known to be true are false. Second, as the extraction of information in the open domain is a relatively noisy process, a confidence score helps detecting extraction errors, and makes for higher-quality automatically generated KBs. Last, adj"
L18-1699,E17-1075,0,0.200067,"nominal and pronominal coreference mentions are necessary to finegrained entity tying performance. For each variant, we report the average score on 5 randomly generated subsets. To be comparable with previous works, we used training materiel up to 4 million mentions, and leave experiments on the usefulness of the full WiFiNE for future work. 4.3 Results on F IGER (GOLD) Previous works trained their models on 2.6 million mentions obtained by mapping hyperlinks in Wikipedia articles to Freebase5 . Models FIGER (Ling and Weld, 2012) FIGER+PLE (Ren et al., 2016) Attentive (Shimaoka et al., 2017) (Abhishek et al., 2017) Proper Nominal Pronominal (1) 1 0 0 (2) 2 0 0 (3) 3 0 0 (4) 1 1 0 (5) 1 0 1 (6) 1 1 1 (7) 2 1 1 Strict Macro Micro 52.30 69.90 69.30 59.90 76.30 74.90 59.68 78.97 75.36 65.80 81.20 77.40 This work 61.99 76.20 75.12 63.77 77.56 76.25 63.41 78.03 76.32 64.83 79.26 77.36 63.06 79.00 76.77 65.19 79.59 77.55 66.07 79.94 78.21 Table 5: Comparison of the distribution of the top 5 types present in F IGER (GOLD) test set to that of WiFiNE. Table 5 shows the 5 most frequent types the F IGER (GOLD) test set compared to those in WiFiNE. F IGER (GOLD) is a small dataset, it contains only 523 mentions anno"
L18-1699,K16-1023,1,0.67679,"Linking, Question Answering, etc. One issue in fine-grained typing is the absence of a wellestablished training corpus. The large number of types makes it difficult to manually annotate the amount of data needed for training. This bottleneck was addressed by using an automatic annotation procedure (Section 2), which follows two steps: 1. Identifying and linking entity mentions to a Knowledge Base (typically Freebase). 2. Assigning to each mention the set of types that apply in the context of the sentence. Step 1 suffers a number of issues: lack of coverage when Wikipedia is used as a source (Ghaddar and Langlais, 2016b), and entity linking which is error prone (Ren et al., 2016). Step 2 also has limitations: the type of a mention is often resolved with strict pruning heuristics (regardless of the context) as in (Gillick et al., 2014); or the type of a mention is kept ambiguous following (Shimaoka et al., 2017). For instance, in the sentence: “Gonzales embarked on a pop career as the leader of the alternative rock band Son.” The entity Chilly Gonzales has 3 labels in Freebase: musician, writer , actor but only musician applies here. In this paper, we revisit the idea of automatically extracting fine-grained"
L18-1699,L16-1021,1,0.856941,"Linking, Question Answering, etc. One issue in fine-grained typing is the absence of a wellestablished training corpus. The large number of types makes it difficult to manually annotate the amount of data needed for training. This bottleneck was addressed by using an automatic annotation procedure (Section 2), which follows two steps: 1. Identifying and linking entity mentions to a Knowledge Base (typically Freebase). 2. Assigning to each mention the set of types that apply in the context of the sentence. Step 1 suffers a number of issues: lack of coverage when Wikipedia is used as a source (Ghaddar and Langlais, 2016b), and entity linking which is error prone (Ren et al., 2016). Step 2 also has limitations: the type of a mention is often resolved with strict pruning heuristics (regardless of the context) as in (Gillick et al., 2014); or the type of a mention is kept ambiguous following (Shimaoka et al., 2017). For instance, in the sentence: “Gonzales embarked on a pop career as the leader of the alternative rock band Son.” The entity Chilly Gonzales has 3 labels in Freebase: musician, writer , actor but only musician applies here. In this paper, we revisit the idea of automatically extracting fine-grained"
L18-1699,I17-1042,1,0.824577,"a et al., 2017). For instance, in the sentence: “Gonzales embarked on a pop career as the leader of the alternative rock band Son.” The entity Chilly Gonzales has 3 labels in Freebase: musician, writer , actor but only musician applies here. In this paper, we revisit the idea of automatically extracting fine-grained entity annotations from Wikipedia. Similarly to previous works, we gather annotations from anchored texts in an article, as well as their associated types in Freebase (Bollacker et al., 2008). In addition, we also generate annotations for texts not anchored in Wikipedia following (Ghaddar and Langlais, 2017). We do this by considering coreference mentions of anchored texts as candidate annotations, and by exploiting the out-link structure of Wikipedia. We propose an easy-first annotation pipeline described in Section 3 which happens to reduce noise. Second, we define simple yet efficient heuristics in order to prune the set of candidate types of each entity mention found in the article. These heuristics are based on: Freebase tuples, the high density of entity mentions, and the paragraph and section structure of the article. We applied our methodology on a 2013 English Wikipedia dump, leading to"
L18-1699,D10-1048,0,0.0310669,"ns detection procedure. 2. We follow out-links of out-links, and search in the target article (by an exact string match) the titles of the articles reached. For instance, we search for the strings Europe, France, Napoleon, as well as other article titles from the out-link list of the article Paris. 3. For the titles matched during step 2, we also match their coreferent mentions. For instance, because France was matched in the previous step, we also search its coreferences as listed in the coreference table (CT of Figure 1). 4. Last, we adapt the multi-sieve rule-based coreference resolver of (Raghunathan et al., 2010) to the specificity of Wikipedia in order to find the antecedent referents of a pronominal mention. The rules link a pronoun to its best antecedent mention based on attributes agreement (gender, number, entity type,...). We apply the pronoun coreference rules on each article, then discard all pronouns that do not refer to a Wikipedia entity mention. During this process, some collisions may occur. We solve the issue of overlapping annotations by applying the steps exactly in the order presented above. Our steps have been ordered in such a way that the earlier the step, the more confidence we ha"
L18-1699,E17-1119,0,0.0887676,"Missing"
L18-1699,W03-0419,0,0.697929,"Missing"
L18-1699,P15-2048,0,0.465983,"raph structure), and CT represents the coreference table we gathered from the resource. 2. Related Works In previous works, the entity mention detection process is performed using one of two methods. The first one consists in using the internal links in Wikipedia as training data, where anchored strings (that have an equivalent page in Freebase) are treated as entity mentions (Ling and Weld, 2012; Ren et al., 2016). Another method is to directly use a Freebase entity resolver such as DB-pedia Spotligh (Daiber et al., 2013) to link textual mentions to their Freebase page (Gillick et al., 2014; Yogatama et al., 2015; Ren et al., 2016). In both cases, the Freebase object type attributes of the entity are mapped to a predefined set of types. In the last few years, two popular mapping schemes emerged: F IGER (Ling and Weld, 2012) (112 label) and G ILLICK (Gillick et al., 2014) (89 label). They are both organized in a hierarchical structure, where children labels also inherit the parent label. F IGER defines a 2-level hierarchy (e.g. /person and /person/musician); while G ILLICK uses 3 levels of types (e.g. /person and /person/artist, /person/artist/musician). Most resolved entities have multiple type labels"
langlais-etal-2000-evaluation,C90-2045,0,\N,Missing
langlais-etal-2000-evaluation,J93-2003,0,\N,Missing
langlais-etal-2000-evaluation,C90-3008,0,\N,Missing
langlais-etal-2000-evaluation,P98-2158,0,\N,Missing
langlais-etal-2000-evaluation,C98-2153,0,\N,Missing
langlais-etal-2000-evaluation,A00-1019,1,\N,Missing
langlais-etal-2000-evaluation,P97-1037,0,\N,Missing
langlais-etal-2000-evaluation,C86-1077,0,\N,Missing
langlais-etal-2000-evaluation,P97-1047,0,\N,Missing
langlais-etal-2002-translators,J93-2003,0,\N,Missing
langlais-etal-2002-translators,P01-1067,0,\N,Missing
langlais-etal-2002-translators,langlais-etal-2000-evaluation,1,\N,Missing
langlais-etal-2002-translators,2001.mtsummit-papers.36,1,\N,Missing
langlais-etal-2002-translators,P00-1006,0,\N,Missing
langlais-etal-2012-texto4science,fairon-paumier-2006-translated,0,\N,Missing
langlais-etal-2012-texto4science,2010.eamt-1.37,0,\N,Missing
langlais-etal-2012-texto4science,P10-2058,0,\N,Missing
langlais-etal-2012-texto4science,P10-1079,0,\N,Missing
langlais-etal-2012-texto4science,P06-2005,0,\N,Missing
langlais-simard-2002-merging,macklovitch-russell-2000-whats,0,\N,Missing
langlais-simard-2002-merging,C96-1030,0,\N,Missing
langlais-simard-2002-merging,J93-2003,0,\N,Missing
langlais-simard-2002-merging,W00-0731,0,\N,Missing
langlais-simard-2002-merging,P98-2158,0,\N,Missing
langlais-simard-2002-merging,C98-2153,0,\N,Missing
langlais-simard-2002-merging,1999.mtsummit-1.92,0,\N,Missing
langlais-simard-2002-merging,P01-1050,0,\N,Missing
langlais-simard-2002-merging,2001.mtsummit-papers.60,1,\N,Missing
langlais-simard-2002-merging,macklovitch-etal-2000-transsearch,1,\N,Missing
leplus-etal-2004-weather,J93-2003,0,\N,Missing
leplus-etal-2004-weather,C86-1132,0,\N,Missing
leplus-etal-2004-weather,P98-2158,0,\N,Missing
leplus-etal-2004-weather,C98-2153,0,\N,Missing
leplus-etal-2004-weather,N03-1017,0,\N,Missing
leplus-etal-2004-weather,P98-1117,1,\N,Missing
leplus-etal-2004-weather,C98-1113,1,\N,Missing
macklovitch-etal-2000-transsearch,J93-1004,0,\N,Missing
macklovitch-etal-2000-transsearch,1993.tmi-1.17,0,\N,Missing
macklovitch-etal-2000-transsearch,P91-1022,0,\N,Missing
macklovitch-etal-2000-transsearch,J93-1006,0,\N,Missing
N19-1249,C18-1139,0,0.0693011,"TM-d can boost the chunking task significantly, but both fail to improve NER and POS tasks. This is consistent with observations made in (Collobert et al., 2011; Søgaard and Goldberg, 2016). We also observe that our SC-LSTM model also benefits the chunking task the most. We will analyze this fur2400 NER Collobert et al. (2011) Chiu and Nichols (2015) ♣ Huang et al. (2015) Luo et al. (2015) Ma and Hovy (2016) Lample et al. (2016) Shen et al. (2017) Yang et al. (2017) Rei (2017) Liu et al. (2017) Peters et al. (2017) Zhang et al. (2018) Liu et al. (2018) Peters et al. (2018) Clark et al. (2018) Akbik et al. (2018) ♣ Devlin et al. (2018) SC-LSTM SC-LSTM-CNN-CRF SC-LSTM-LM-CNN ther in Section 6. LSTM (STL) LSTM-s LSTM-d SC-LSTM POS 95.46 95.45 95.44 95.51 chunking 94.44 95.12 95.24 96.04 NER 89.39 89.35 89.37 89.96 Table 3: Results of models being trained in STL or MTL mode. For all MTL models, we report the best performance via a small grid search over combinations of the hidden size [100, 200, 300, 400] and the number of layers [1, 2, 3]. The best performance of each MTL model was obtained with hidden size 300 and 3 layers. 5.2 SC-LSTM versus state-of-the-art To further demonstrate the effectiveness of"
N19-1249,E17-1005,0,0.0409994,"Missing"
N19-1249,C16-1333,0,0.0263042,"d LSTM-d, which is also consistent with the conclusion in (Changpinyo et al., 2018). In conclusion, all of the results show that our SC-LSTM model is effective at capturing the mutual benefits of all combined tasks. Since it performs consistently better in various settings, we believe our model to be more robust. 7 Related Work There are many works that use extra knowledge to improve the performance of sequence labeling tasks. Many works have focussed on jointly learning two tasks, often with one being considered as the main task, the other being the auxiliary one (Søgaard and Goldberg, 2016; Bjerva et al., 2016; Alonso and Plank, 2017). For instance, chunking, combinatory categorical grammar supertagging, NER, super senses (SemCor), or multiword expression + supersense will be taken as the main task, while POS is the auxiliary task in (Søgaard and Goldberg, 2016). Exceptions to this line of work include (Collobert et al., 2011) that evaluates four tasks: POS, chunking, NER and semantic role labeling; (Kiperwasser and Ballesteros, 2018) that considers a machine translation task with POS and dependency parsing. And Niehues and Cho (2017) considers machine translation with POS and NER tasks; Zhang and"
N19-1249,C18-1251,0,0.153132,"Missing"
N19-1249,D18-1217,0,0.0566735,"Missing"
N19-1249,W03-0425,0,0.267287,"Missing"
N19-1249,W18-2501,0,0.0153279,". In order to encode character sequences, we used a CNN. The character embedding look-up table is initialized by randomly sampling from 3 The embedding file glove6B are available https:// nlp.stanford.edu/projects/glove/ 2399 Layers Char-level Embedding the uniform distribution in the range [-0.1, 0.1]; • the third part of the input vector is contextual embedding. Most of the recent works found that contextualized features such as ELMo or BERT (Peters et al., 2018; Devlin et al., 2018) can greatly boost performance. We incorporate ELMo into our input vector by using the ELMo implementation of Gardner et al. (2018). Conditional random field (CRF) classifiers can consider the dependency of output tags and has been proven useful for tasks like NER or chunking. We consider CRF layers in our models. To compare the effectiveness of three MTL models, we first test our SC-LSTM and other vanilla LSTM based models without CNN based character-level information extractor and contextual embeddings. In this case, the input will be a concatenation of word embedding and capitalization features4 . To compare with the state-of-art models, we further implemented three more variants: SC-LSTM-CNN-CRF which makes use of CNN"
N19-1249,P18-1035,0,0.0224427,"Cell LSTM. Task-specific cells are each parametrized by an output gate okt which learns to select the useful information from the shared memory cell ct and outputs qkt . This is formally described in Equation 2, where Wk and Uk are two extra weight matrices that parametrize the kth task, and qkt has to be understood as a task-specific hidden representation since parameters of kth task-specific cell are only updated by supervision from task k. okt “ σpWk qkt´1 ` Uk xkt q qkt “ okt ˚ tanhpct q In order to make use of both shared and taskspecific information (Kim et al., 2016; Peng et al., 2017; Hershcovich et al., 2018), for the kth task, we concatenate the output of the shared cell ht and of the task-specific one qkt to generate the final latent representation, as noted in Equation 3, where ‘ is the concatenation operation. In practice, we stack SC-LSTM layers. The top-most layer uses skt as a representation of the current input, while cells in lower layers pass the current shared hidden state ht to the upper SC-LSTM cell. The use of s in the topmost layer only is arbitrary and should be investigated. skt “ qkt ‘ ht 3.3 Figure 2: Structure of an SC-LSTM cell. The dashed delimited box depicts the task-specif"
N19-1249,W03-0430,0,0.0563799,"parameters that can learn task specific information. We name it a Shared-Cell Long-Short Term Memory (SC-LSTM). Experimental results on three sequence labeling benchmarks (named-entity recognition, text chunking, and part-of-speech tagging) demonstrate the effectiveness of our SC-LSTM cell. 1 Introduction As one of the fundamental tasks in NLP, sequence labeling has been studied for years. Before the blooming of neural network methods, handcrafted features were widely used in traditional approaches like CRFs, HMMs, and maximum entropy classifiers (Lafferty et al., 2001; McCallum et al., 2000; McCallum and Li, 2003; Florian et al., 2003). However, applying them to different tasks or domains is hard. Recently, instead of using handcrafted features, end-to-end neural network based systems have been developed for sequence labeling tasks, such as LSTM-CNN (Chiu and Nichols, 2015), LSTM-CRF (Huang et al., 2015; Lample et al., 2016), and LSTM-CNN-CRF (Ma and Hovy, 2016). These models utilize LSTM to encode the global information of a sentence into a word-level representation of its tokens, which avoids manual feature engineering. Moreover, by incorporating a character-level representation of tokens, these mod"
N19-1249,C16-1038,0,0.0213757,"is new cell, which stands for Shared-Cell LSTM. Task-specific cells are each parametrized by an output gate okt which learns to select the useful information from the shared memory cell ct and outputs qkt . This is formally described in Equation 2, where Wk and Uk are two extra weight matrices that parametrize the kth task, and qkt has to be understood as a task-specific hidden representation since parameters of kth task-specific cell are only updated by supervision from task k. okt “ σpWk qkt´1 ` Uk xkt q qkt “ okt ˚ tanhpct q In order to make use of both shared and taskspecific information (Kim et al., 2016; Peng et al., 2017; Hershcovich et al., 2018), for the kth task, we concatenate the output of the shared cell ht and of the task-specific one qkt to generate the final latent representation, as noted in Equation 3, where ‘ is the concatenation operation. In practice, we stack SC-LSTM layers. The top-most layer uses skt as a representation of the current input, while cells in lower layers pass the current shared hidden state ht to the upper SC-LSTM cell. The use of s in the topmost layer only is arbitrary and should be investigated. skt “ qkt ‘ ht 3.3 Figure 2: Structure of an SC-LSTM cell. Th"
N19-1249,Q18-1017,0,0.131574,"Missing"
N19-1249,N16-1030,0,0.65622,"e fundamental tasks in NLP, sequence labeling has been studied for years. Before the blooming of neural network methods, handcrafted features were widely used in traditional approaches like CRFs, HMMs, and maximum entropy classifiers (Lafferty et al., 2001; McCallum et al., 2000; McCallum and Li, 2003; Florian et al., 2003). However, applying them to different tasks or domains is hard. Recently, instead of using handcrafted features, end-to-end neural network based systems have been developed for sequence labeling tasks, such as LSTM-CNN (Chiu and Nichols, 2015), LSTM-CRF (Huang et al., 2015; Lample et al., 2016), and LSTM-CNN-CRF (Ma and Hovy, 2016). These models utilize LSTM to encode the global information of a sentence into a word-level representation of its tokens, which avoids manual feature engineering. Moreover, by incorporating a character-level representation of tokens, these models further improve. ˚ Co-first author. In many such studies, though, neural network models are trained toward a single task in a supervised way by making use of relatively small annotated training material. Jointly learning multiple tasks can reduce the risk of over-fitting to one task, and many attempts have been m"
N19-1249,D18-1153,0,0.044843,"Missing"
N19-1249,D15-1104,0,0.185629,"ine 4). The results show that our SC-LSTM model improves the performance of the three tasks simultaneously compared with LSTM (STL), and outperforms the other two MTL methods. By joint learning three tasks, both LSTM-s and LSTM-d can boost the chunking task significantly, but both fail to improve NER and POS tasks. This is consistent with observations made in (Collobert et al., 2011; Søgaard and Goldberg, 2016). We also observe that our SC-LSTM model also benefits the chunking task the most. We will analyze this fur2400 NER Collobert et al. (2011) Chiu and Nichols (2015) ♣ Huang et al. (2015) Luo et al. (2015) Ma and Hovy (2016) Lample et al. (2016) Shen et al. (2017) Yang et al. (2017) Rei (2017) Liu et al. (2017) Peters et al. (2017) Zhang et al. (2018) Liu et al. (2018) Peters et al. (2018) Clark et al. (2018) Akbik et al. (2018) ♣ Devlin et al. (2018) SC-LSTM SC-LSTM-CNN-CRF SC-LSTM-LM-CNN ther in Section 6. LSTM (STL) LSTM-s LSTM-d SC-LSTM POS 95.46 95.45 95.44 95.51 chunking 94.44 95.12 95.24 96.04 NER 89.39 89.35 89.37 89.96 Table 3: Results of models being trained in STL or MTL mode. For all MTL models, we report the best performance via a small grid search over combinations of the hidden s"
N19-1249,P16-1101,0,0.649016,"eling has been studied for years. Before the blooming of neural network methods, handcrafted features were widely used in traditional approaches like CRFs, HMMs, and maximum entropy classifiers (Lafferty et al., 2001; McCallum et al., 2000; McCallum and Li, 2003; Florian et al., 2003). However, applying them to different tasks or domains is hard. Recently, instead of using handcrafted features, end-to-end neural network based systems have been developed for sequence labeling tasks, such as LSTM-CNN (Chiu and Nichols, 2015), LSTM-CRF (Huang et al., 2015; Lample et al., 2016), and LSTM-CNN-CRF (Ma and Hovy, 2016). These models utilize LSTM to encode the global information of a sentence into a word-level representation of its tokens, which avoids manual feature engineering. Moreover, by incorporating a character-level representation of tokens, these models further improve. ˚ Co-first author. In many such studies, though, neural network models are trained toward a single task in a supervised way by making use of relatively small annotated training material. Jointly learning multiple tasks can reduce the risk of over-fitting to one task, and many attempts have been made at doing so for sequence labeling"
N19-1249,P16-1105,0,0.0206303,"ging, NER, super senses (SemCor), or multiword expression + supersense will be taken as the main task, while POS is the auxiliary task in (Søgaard and Goldberg, 2016). Exceptions to this line of work include (Collobert et al., 2011) that evaluates four tasks: POS, chunking, NER and semantic role labeling; (Kiperwasser and Ballesteros, 2018) that considers a machine translation task with POS and dependency parsing. And Niehues and Cho (2017) considers machine translation with POS and NER tasks; Zhang and Weiss (2016) show that jointly learning a POS tagger and a dependency parser is effective. Miwa and Bansal (2016) jointly trained models for entity detection and relation extraction in the field of relation extraction. Other works are also trying to leverage language models to empower the performance of sequence labeling tasks. Notably, Liu et al. (2017) propose a model which uses a neural language model to learn character-level knowledge, and conducts sequence labeling to guide the language model towards specific tasks. Others (Peters et al., 2017, 2018; Devlin et al., 2018) use neural language models pre-trained on a large unlabeled corpus to learn context-sensitive representations of words, and levera"
N19-1249,W17-4708,0,0.0208095,"ask, the other being the auxiliary one (Søgaard and Goldberg, 2016; Bjerva et al., 2016; Alonso and Plank, 2017). For instance, chunking, combinatory categorical grammar supertagging, NER, super senses (SemCor), or multiword expression + supersense will be taken as the main task, while POS is the auxiliary task in (Søgaard and Goldberg, 2016). Exceptions to this line of work include (Collobert et al., 2011) that evaluates four tasks: POS, chunking, NER and semantic role labeling; (Kiperwasser and Ballesteros, 2018) that considers a machine translation task with POS and dependency parsing. And Niehues and Cho (2017) considers machine translation with POS and NER tasks; Zhang and Weiss (2016) show that jointly learning a POS tagger and a dependency parser is effective. Miwa and Bansal (2016) jointly trained models for entity detection and relation extraction in the field of relation extraction. Other works are also trying to leverage language models to empower the performance of sequence labeling tasks. Notably, Liu et al. (2017) propose a model which uses a neural language model to learn character-level knowledge, and conducts sequence labeling to guide the language model towards specific tasks. Others ("
N19-1249,P17-1186,0,0.0438032,"Missing"
N19-1249,D14-1162,0,0.101925,"ginal LSTM computations. 4 4.2 2 We used UD English POS v1.3. 12,543 204k Architectural Choices We used bidirectional LSTM or SC-LSTM as our encoders for the vector representation of words. Bidirectional LSTM can capture global information of the whole sentence, thanks to the encoding of a sequence in a recurrent way. The vector representation of words consists of three parts: word embedding, character-level representation and contextual representation: • previous works have proven that pre-trained word embeddings like Word2vec (Mikolov et al., 2013), SENNA (Collobert et al., 2011), or Glove (Pennington et al., 2014) have a positive impact on sequence labeling tasks. We used Glove embeddings3 of dimension 100, that are fine-tuned during training; Benchmarks We test several baseline systems and our SCLSTM model on three well-established sequence labeling benchmarks: CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) for namedentity recognition, CoNLL2000 (Tjong Kim Sang and Buchholz, 2000) for chunking, and the more recent Universal Dependency dataset (Nivre et al., 2016) for part-of-speech tagging,2 and on which recent MTL investigations have been conducted (Alonso and Plank, 2017; Changpinyo et al., 2018)."
N19-1249,P17-1161,0,0.240804,"ination of task-specific loss functions, where the weighting coefficients (λk in Equation 4) are hyper-parameters. SC-LSTM Cell The overall structure of our cell is depicted in Figure 2. On top of a standard LSTM cell, we add one 2398 “ K ÿ k“1 ˆkq λk Lpyk , y (4) Algorithm 1 Stochastic training procedure 1: 2: 3: 4: 5: 6: procedure T RAINING for each epoch do Randomly choose a task k. Randomly choose a training example not yet considered in the dataset Sk Update the parameters for this task by taking a gradient step based on this example. Go to step 3 until using all examples. recent works (Peters et al., 2017; Liu et al., 2017), sections 15-18 of the Wall Street Journal are used for training, and we randomly sampled 1000 sentences in the training set as the development set. Section 20 is used for tests. Table 1 presents the main characteristics of the training, development and test sets we used. Train NER #sentences #tokens #entities Chunking #sentencies #tokens #chunks POS #sentences #tokens We seek to minimize cross-entropy of the predicted and true distributions, therefore taskspecific loss functions are defined according to Equation 5. ˆkq “ ´ Lpyk , y nk ÿ mi ÿ k k ˆ i,j yi,j log y (5) i“1 j“"
N19-1249,N18-1202,0,0.632999,"d Zadrozny, 2014; Ma and Hovy, 2016; Lample et al., 2016) and Some works further show its effectiveness (Reimers and Gurevych, 2017; Yang et al., 2018). In order to encode character sequences, we used a CNN. The character embedding look-up table is initialized by randomly sampling from 3 The embedding file glove6B are available https:// nlp.stanford.edu/projects/glove/ 2399 Layers Char-level Embedding the uniform distribution in the range [-0.1, 0.1]; • the third part of the input vector is contextual embedding. Most of the recent works found that contextualized features such as ELMo or BERT (Peters et al., 2018; Devlin et al., 2018) can greatly boost performance. We incorporate ELMo into our input vector by using the ELMo implementation of Gardner et al. (2018). Conditional random field (CRF) classifiers can consider the dependency of output tags and has been proven useful for tasks like NER or chunking. We consider CRF layers in our models. To compare the effectiveness of three MTL models, we first test our SC-LSTM and other vanilla LSTM based models without CNN based character-level information extractor and contextual embeddings. In this case, the input will be a concatenation of word embedding a"
N19-1249,P17-1194,0,0.019925,"our results to the LSTM-CRF model of Lample et al. (2016) and the LSTM-CNN-CRF of Ma and Hovy (2016), since those are state-of-the-art singly tasked sequence labelers. • Multi-tasked sequence labelers where models leverage the supervision of other tasks. We compare our model with the representative approaches of Luo et al. (2015); Søgaard and Goldberg (2016); Collobert and Weston (2008); Collobert et al. (2011). • Models with language model. Recently, several studies in using contextualized word embeddings achieved great success in a number of tasks. Some recent studies (Peters et al., 2017; Rei, 2017; Peters et al., 2018; Devlin et al., 2018) are particularly considered. It is worth noting that we did not engineer tasks specific features or integrate external ressources such as gazetteers in our variants. 5.2.1 NER Results for the CoNLL 2003 dataset are reported in Table 4. We observe that our SC-LSTM-LMCNN model outperforms all approaches but Devlin et al. (2018) and Akbik et al. (2018). The latter work is using the development set as training F1-score 89.59 91.62 88.83 91.20 91.21 90.94 90.89 91.20 86.26 91.71 91.93 91.2 91.95 92.22 92.60 93.09 92.80 89.96 91.37 92.60 Table 4: F1-score"
N19-1249,P16-1147,0,0.0396818,"Missing"
N19-1249,P16-2038,0,0.446022,"of relatively small annotated training material. Jointly learning multiple tasks can reduce the risk of over-fitting to one task, and many attempts have been made at doing so for sequence labeling tasks (Caruana, 1997; Collobert and Weston, 2008; Collobert et al., 2011). Results so far are not conclusive. Some works have reported negative results overall. For instance in their pioneering work, Collobert et al. (2011) observed that training their model on NER, POS tagging and chunking altogether led to slight decrease in performance compared to a similar model trained on each task separately. Søgaard and Goldberg (2016) study chunking and CCG super tagging, coupled with an additional POS tagging task. They do report gains on both target tasks over single task models, but results varied depending where the additional task was taken care of in their architecture. The authors actually reported a failure to leverage other labelling tasks, and concluded that combined tasks should be sufficiently similar to the target one, for significant gains to be observed. Similarly, Alonso and Plank (2017) achieved significant improvements for only 1 out of 5 tasks considered. Also of interest is the work of (Changpinyo et al"
N19-1249,W00-0726,0,0.762414,"Missing"
N19-1249,W03-0419,0,0.782291,"Missing"
N19-1249,C18-1327,0,0.0701328,"18). We conformed to the pre-defined splits into train/dev/test except for chunking that does not contain a validation set. For this dataset, following 8,936 212k 107k Table 1: Main characteristics of the datasets used. Experimental Setting 4.1 14,987 205k 23,523 Dev Test #tags = 4 3,644 3,486 52k 47k 5,943 5,654 #tags = 10 2,012 47k 24k #tags = 17 2,002 2,077 25k 25 • character-level information has been proven useful for three sequence labeling tasks (Santos and Zadrozny, 2014; Ma and Hovy, 2016; Lample et al., 2016) and Some works further show its effectiveness (Reimers and Gurevych, 2017; Yang et al., 2018). In order to encode character sequences, we used a CNN. The character embedding look-up table is initialized by randomly sampling from 3 The embedding file glove6B are available https:// nlp.stanford.edu/projects/glove/ 2399 Layers Char-level Embedding the uniform distribution in the range [-0.1, 0.1]; • the third part of the input vector is contextual embedding. Most of the recent works found that contextualized features such as ELMo or BERT (Peters et al., 2018; Devlin et al., 2018) can greatly boost performance. We incorporate ELMo into our input vector by using the ELMo implementation of"
P98-1117,J90-2002,0,0.0991742,"a program that reduces the search space only to those sentence pairs that are potentially interesting (Simard and Plamondon, 1996). The underlying principle is the automatic detection of isolated cognates (i.e. for which no other similar word exists in a window of given size). Once the search space is reduced, the system aligns the sentences using the well-known sentence-length model described in (Gale and Church, 1991). RALI/Sallgn The second m e t h o d proposed by RALI is based on a dynamic programming scheme which uses a score function derived from a translation model similar to that of (Brown et al., 1990). T h e search space is reduced to a beam of fixed width around the diagonal (which would represent the alignment if the two texts were perfectly synchronized). L O R I A The strategy adopted in this system differs from that of the other systems since sentence alignment is performed after the preliminary alignment of larger units (whenever possible, using mark-up), such as paragraphs and divisions, on the basis of the SGML structure. A dynamic programming scheme is applied to all alignment levels in successive steps. IRMC This system involves a preliminary, rough word alignment step which uses"
P98-1117,P91-1022,0,0.559327,"Missing"
P98-1117,A94-1006,0,0.0164473,"growing interest in parallel text alignment techniques. These techniques attempt to m a p various textual units to their translation and have proven useful for a wide range of applicatious and tools. A simple example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans 711 J e a n Vdronis LPL, Univ. de Provence 29, Av. R. Schuman F-13621 Aix-en-Provence Cedex 1 veronis~univ-aix.fr and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively new field was sparked early on by the apparent"
P98-1117,C92-2079,0,0.034314,"Missing"
P98-1117,P91-1023,0,0.0852987,"36*20 = 975 recall = 975/1515 precision = 0.64 = 1 F=0.78 5 Systems tested Six systems were tested, two of which having been submitted by the I:tALI. 714 RALI/Jacal This system uses as a first step a program that reduces the search space only to those sentence pairs that are potentially interesting (Simard and Plamondon, 1996). The underlying principle is the automatic detection of isolated cognates (i.e. for which no other similar word exists in a window of given size). Once the search space is reduced, the system aligns the sentences using the well-known sentence-length model described in (Gale and Church, 1991). RALI/Sallgn The second m e t h o d proposed by RALI is based on a dynamic programming scheme which uses a score function derived from a translation model similar to that of (Brown et al., 1990). T h e search space is reduced to a beam of fixed width around the diagonal (which would represent the alignment if the two texts were perfectly synchronized). L O R I A The strategy adopted in this system differs from that of the other systems since sentence alignment is performed after the preliminary alignment of larger units (whenever possible, using mark-up), such as paragraphs and divisions, on"
P98-1117,1993.tmi-1.17,0,0.0122396,"e both on the evaluation protocols and metrics, and the algoritbm.q used by the different systems. For the second phase, which is now underway, A R C A D E has been opened to a larger number of teams who will tackle the problem of word-level alignment. 1 Introduction In the last few years, there has been a growing interest in parallel text alignment techniques. These techniques attempt to m a p various textual units to their translation and have proven useful for a wide range of applicatious and tools. A simple example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans 711 J e a n Vdronis LPL, Univ. de Provence 29, Av. R. Schuman F-13621 Aix-en-Provence Cedex 1 veroni"
P98-1117,1996.amta-1.4,0,0.038694,"the last few years, there has been a growing interest in parallel text alignment techniques. These techniques attempt to m a p various textual units to their translation and have proven useful for a wide range of applicatious and tools. A simple example of such a tool is probably the TransSearch bilingual concordancing system (Isabelle et al., 1993), which allows a user to query a large archive of existing translations in order to find ready-made solutions to specific translation problems. Such a tool has proved extremely useful not only for translators, but also for bilingual lexicographers (Langlois, 1996) and terminologists (Dagan and Church, 1994). More sophisticated applications based on alignment technology have also been the object of recent work, such as the automatic building of bilingual lexical resources (Melamed, 1996; Klavans 711 J e a n Vdronis LPL, Univ. de Provence 29, Av. R. Schuman F-13621 Aix-en-Provence Cedex 1 veronis~univ-aix.fr and Tzoukermann, 1995), the automatic verification of translations (Macklovitch, 1995), the automatic dictation of translations (Brousseau et al., 1995) and even interactive machine translation (Foster et al., 1997). Enthusiasm for this relatively ne"
P98-1117,1995.mtsummit-1.36,0,0.0477579,"Missing"
P98-1117,P97-1039,0,0.122178,"Missing"
P98-1117,1996.amta-1.14,1,0.888247,"sult in a dramatic loss of efficiency. The truth is that, while text alignment is mostly an easy problem, especially when considered at the sentence level, there are situations where even humans have a hard time making the right decision. In fact, it could be argued that, ultimately, text alignment is no easier than the more general problem of natural language understanding. In addition, most research efforts were directed towards the easiest problem, that of sentence-to-sentence alignment (Brown et al., 1991; Gale and Church, 1991; Debili, 1992; Kay and l~scheisen, 1993; Simard et al., 1992; Simard and Plamondon, 1996). Alignment at the word and term level, which is extremely useful for applications such as lexieal resource extraction, is still a largely unexplored research area(Melamed, 1997). In order to live up to the expectations of the various application fields, alignment technology will therefore have to improve substantially. As was the case with several other language processing techniques (such as information retrieval, document understanding or speech recognition), it is likely that a systematic evaluation will enable such improvements. However, before the ARCADE project started, no forreal evalu"
P98-1117,1992.tmi-1.7,1,0.897757,"Missing"
P98-1117,1996.amta-1.13,0,\N,Missing
patry-etal-2006-mood,koen-2004-pharaoh,0,\N,Missing
patry-etal-2006-mood,J99-4005,0,\N,Missing
patry-etal-2006-mood,J93-2003,0,\N,Missing
patry-etal-2006-mood,W02-1021,0,\N,Missing
patry-etal-2006-mood,P02-1040,0,\N,Missing
patry-etal-2006-mood,W05-0820,0,\N,Missing
patry-etal-2006-mood,P01-1067,0,\N,Missing
patry-etal-2006-mood,J04-4002,0,\N,Missing
patry-etal-2006-mood,N03-1017,0,\N,Missing
patry-etal-2006-mood,P05-1034,0,\N,Missing
patry-etal-2006-mood,P05-1066,0,\N,Missing
patry-etal-2006-mood,J03-1005,0,\N,Missing
patry-etal-2006-mood,P00-1056,0,\N,Missing
patry-etal-2006-mood,P01-1030,0,\N,Missing
patry-langlais-2008-mistral,patry-etal-2006-mood,1,\N,Missing
patry-langlais-2008-mistral,C04-1168,0,\N,Missing
patry-langlais-2008-mistral,2007.iwslt-1.1,0,\N,Missing
patry-langlais-2008-mistral,P02-1040,0,\N,Missing
patry-langlais-2008-mistral,P07-2045,0,\N,Missing
patry-langlais-2008-mistral,N03-1017,0,\N,Missing
patry-langlais-2008-mistral,2007.iwslt-1.22,1,\N,Missing
patry-langlais-2008-mistral,2005.mtsummit-papers.11,0,\N,Missing
patry-langlais-2008-mistral,N04-1021,0,\N,Missing
patry-langlais-2008-mistral,2005.iwslt-1.2,0,\N,Missing
patry-langlais-2008-mistral,P00-1056,0,\N,Missing
patry-langlais-2008-mistral,P07-2054,0,\N,Missing
vasilescu-etal-2004-evaluating,W02-0807,0,\N,Missing
W00-0507,C90-3008,0,0.247146,"Missing"
W00-0507,J93-2003,0,0.00567536,"xpensive to compute than p(t[s) when using IBM-style translation models. Since speed is crucial for our application, we chose to forego it in the work described here. Our linear combination model is fully described in (Langlais and Foster, 2000) but can be seen as follows: 2.2.1 T h e e v a l u a t o r The evaluator is a function p(t[t&apos;, s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t&apos; which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al., 1993), but it diflhrs in one significant aspect: whereas the IBM model involves a &quot;noisy channel&quot; decomposition, we 48 p(tlt&apos;,s ) = p(tlt&apos; ) A(O(t&apos;,s)), (1) language + p(tls)[1-~(O(t&apos;,s))! translation where .~(O(t&apos;,s)) e [0,1] are contextdependent interpolation coefficients. O(t~,s) stands for any function which maps t~,s into a set of equivalence classes. Intuitively, ),(O(t r, s)) should be high when s is more informative than t r and low otherwise. For example, the translation model could have a higher weight at the start of sentence but the contribution of the language model can become more imp"
W00-0507,langlais-etal-2000-evaluation,1,0.713413,"Missing"
W00-0507,A00-1018,0,0.0195985,"Missing"
W00-0507,A00-1019,1,0.86616,"Missing"
W00-0507,C90-2045,0,0.0899252,"eract with the user and how to find appropriate multi-word units for suggestions that can be computed in real time. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled trans][ators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from the meaning of the source text to the form of the target"
W00-0507,C86-1077,0,0.503703,"o find appropriate multi-word units for suggestions that can be computed in real time. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled trans][ators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from the meaning of the source text to the form of the target text. This would relieve"
W02-1020,J93-2003,0,0.00791075,"Missing"
W02-1020,W97-0504,0,0.109042,"Missing"
W02-1020,1997.mtsummit-papers.1,0,0.685544,"Missing"
W02-1020,W00-0707,1,0.889221,"Missing"
W02-1020,J99-4005,0,0.0733578,"Missing"
W02-1020,A00-1019,1,0.904482,"Missing"
W02-1020,P98-2158,0,0.0401272,"Missing"
W02-1020,C00-2123,0,0.0311209,"Missing"
W02-1020,C98-2153,0,\N,Missing
W02-1020,langlais-etal-2002-translators,1,\N,Missing
W02-1020,P00-1006,1,\N,Missing
W02-1402,C00-2163,0,\N,Missing
W02-1402,H93-1039,0,\N,Missing
W02-1405,H93-1039,0,0.59378,"SMT). However, accurate evaluation of its potential in real-life contexts is still a questionable issue. In this study, we investigate the behavior of an SMT engine faced with a corpus far different from the one it has been trained on. We show that terminological databases are obvious resources that should be used to boost the performance of a statistical engine. We propose and evaluate a way of integrating terminology into a SMT engine which yields a significant reduction in word error rate. 1 Introduction SMT mainly became known to the linguistic community as a result of the seminal work of Brown et al. (1993b). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem. For instance, Vogel et al. (1996) succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models. Och et al. (1999) described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and Nießen and Ney (2001) did the same for morphological information. Radically different statis"
W02-1405,J93-2003,0,0.0317046,"SMT). However, accurate evaluation of its potential in real-life contexts is still a questionable issue. In this study, we investigate the behavior of an SMT engine faced with a corpus far different from the one it has been trained on. We show that terminological databases are obvious resources that should be used to boost the performance of a statistical engine. We propose and evaluate a way of integrating terminology into a SMT engine which yields a significant reduction in word error rate. 1 Introduction SMT mainly became known to the linguistic community as a result of the seminal work of Brown et al. (1993b). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem. For instance, Vogel et al. (1996) succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models. Och et al. (1999) described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and Nießen and Ney (2001) did the same for morphological information. Radically different statis"
W02-1405,W02-1402,1,0.877787,"Missing"
W02-1405,A00-1019,1,0.818653,"ctually a collection of pairs of source and target word sequences that are in a translation relation according to the viterbi alignment run with an IBM4 model that was also trained on the Hansard corpus. This collection of phrases was then merged with a greedy statistical decoder to improve the overall performance of the system. What this study suggests is that translation memories collected from a given corpus can improve the performance of a statistical engine trained on the same corpus, which in itself is an interesting result. A very similar study but with weaker results is derscribed in (Langlais et al., 2000), in the framework of the TransType project. Besides the different metrics the authors used, the discrepancy in performance in these two studies may be explained by the nature of the test corpora used. The test corpus in the latter study was more representative of a real translation task, while the test corpus that Marcu used was a set of around 500 French sentences of no more than 10 words. Our present study is close in spirit to these last two, except that we do not attack the problem of automatically acquiring bilingual lexicons; instead, we consider it a part of the translator’s task to pr"
W02-1405,2001.mtsummit-papers.36,1,0.918174,"m model. However, the design of a truly adaptative translation model remains a more speculative enterprise. At the very least, it would require a fairly precise location of errors in previously translated sentences; and we know from the ARCADE campaign on bilingual alignments, that accurate word alignments are difficult to obtain (V´eronis and Langlais, 2000). This may be even more difficult in situations where errors will involve OOV words. We investigated a third option, which involves taking advantage – at run time – of existing terminological resources, such as Termium 4 . As mentioned by Langlais et al. (2001), one of a translator’s first tasks is often terminological research; and many translation companies employ specialized terminologists. Actually, aside from the infrequent cases where, in a given thematic context, a word is likely to have a clearly preferred translation (e.g. bill/facture vs bill/projet de loi ), lexicons are often the only means for a user to influence the translation engine. Merging such lexicons at run time offers a complementary solution to those mentioned above and it should be a fruitful strategy in situations where terminological resources are not available at training"
W02-1405,P01-1050,0,0.0209135,"ure, a systematic inspection of the outputs produced with TU reveals that the translations are still less faithful to the source text than the translations produced for the hansard text. OOV words remain a serious problem. 6 Discussion In this study, we have shown that translating texts in specific domains with a general[]purpose statistical engine is difficult. This suggests the need to implementing an adaptative strategy. Among the possible scenarios, we have shown that opening the engine to terminological resources is a natural and efficient way of softening the decoder. In a similar vein, Marcu (2001) investigated how to combine Example Based Machine Translation (EBMT) and SMT approaches. The author automatically derived from the Hansard corpus what he calls a translation memory: actually a collection of pairs of source and target word sequences that are in a translation relation according to the viterbi alignment run with an IBM4 model that was also trained on the Hansard corpus. This collection of phrases was then merged with a greedy statistical decoder to improve the overall performance of the system. What this study suggests is that translation memories collected from a given corpus c"
W02-1405,W01-1407,0,0.0143982,"came known to the linguistic community as a result of the seminal work of Brown et al. (1993b). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem. For instance, Vogel et al. (1996) succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models. Och et al. (1999) described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and Nießen and Ney (2001) did the same for morphological information. Radically different statistical models have also been proposed. (Foster, 2000) investigated maximum entropy models as an alternative to the so-called noisy-channel approach. Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words. While many of these studies include intensive evaluation sections, it is not always easy to determine exactly how well statistical translation can do on a given task. We know that on a specific task of spoken language translation, Wang ("
W02-1405,P98-2158,0,0.0126977,"ked with a model containing exactly the first gainranked million parameters. It is interesting to note that by doing this, we not only save memory, and therefore time, but also obtain improvments in terms of perplexity and overall performance1 . 1 On a translation task from French to English on 2.2 The search algorithm The maximum operation in equation 1, also called search or decoding, involves a length model. We assume that the length (counted in words) of French sentences that translate an English sentence of a given length follow a normal distribution. We extended the decoder described by Nießen et al. (1998) to a trigram language model. The basic idea of this search algorithm is to expand hypotheses along the positions of the target string while progressively covering the source ones. We refer the reader to the original paper for the recursion on which it relies, and instead give in Figure 1 a sketch of how a translation is built. An hypothesis h is fully determined by four parameters: its source (j) and target (i) positions of the last word (e), and its coverage (c). Therefore, the search space can be represented as a 4-dimension table, each item of which contains backtracking information (f for"
W02-1405,C00-2163,0,0.0128693,"ram we trained on the English sentences of our bitext. The perplexity of the resulting model is fairly low – 65 –, which actually reflects the fact that this corpus contains many fixed expressions (e.g pursuant to standing order). The inverted translation model we used is an IBM2-like model: 10 iterations of IBM1training were run (reducing the perplexity of the training corpus from 7776 to 90), followed by 10 iterations of IBM2-training (yielding a final perplexity of 54). We further reduced the number of transfer parameters (originally 34 969 331) by applying an algorithm described in Foster (2000); this algorithm basically filters in the pairs of words with the best gain, where gain is defined as the difference in perplexity — measured on a held-out corpus — of a model trained with this pair of words and a model trained without. In this experiment, we worked with a model containing exactly the first gainranked million parameters. It is interesting to note that by doing this, we not only save memory, and therefore time, but also obtain improvments in terms of perplexity and overall performance1 . 1 On a translation task from French to English on 2.2 The search algorithm The maximum oper"
W02-1405,W99-0604,0,0.019663,"te a way of integrating terminology into a SMT engine which yields a significant reduction in word error rate. 1 Introduction SMT mainly became known to the linguistic community as a result of the seminal work of Brown et al. (1993b). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem. For instance, Vogel et al. (1996) succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models. Och et al. (1999) described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and Nießen and Ney (2001) did the same for morphological information. Radically different statistical models have also been proposed. (Foster, 2000) investigated maximum entropy models as an alternative to the so-called noisy-channel approach. Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words. While many of these studies include intensive evaluation sections, it is not always easy to de"
W02-1405,C96-2141,0,0.016931,"ow that terminological databases are obvious resources that should be used to boost the performance of a statistical engine. We propose and evaluate a way of integrating terminology into a SMT engine which yields a significant reduction in word error rate. 1 Introduction SMT mainly became known to the linguistic community as a result of the seminal work of Brown et al. (1993b). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem. For instance, Vogel et al. (1996) succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models. Och et al. (1999) described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and Nießen and Ney (2001) did the same for morphological information. Radically different statistical models have also been proposed. (Foster, 2000) investigated maximum entropy models as an alternative to the so-called noisy-channel approach. Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as"
W02-1405,P01-1067,0,0.0350758,"ys have been suggested to attack the problem. For instance, Vogel et al. (1996) succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models. Och et al. (1999) described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and Nießen and Ney (2001) did the same for morphological information. Radically different statistical models have also been proposed. (Foster, 2000) investigated maximum entropy models as an alternative to the so-called noisy-channel approach. Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words. While many of these studies include intensive evaluation sections, it is not always easy to determine exactly how well statistical translation can do on a given task. We know that on a specific task of spoken language translation, Wang (1998) provided evidence that SMT compared favorably to a symbolic translation system; but as mentioned by the author, the comparison was not totally fair. We do not know of any studies that describe extensive experiments evaluating the adequacy of SMT in a r"
W02-1405,C98-2153,0,\N,Missing
W02-1405,P00-1006,0,\N,Missing
W03-0304,J90-2002,0,0.404222,"Missing"
W03-0304,J93-2003,0,0.035939,"Missing"
W03-0304,P00-1056,0,0.242079,"Missing"
W03-0304,W99-0604,0,0.0924544,"Missing"
W03-0304,J97-3002,0,0.220223,"Missing"
W04-1402,2001.mtsummit-eval.4,1,0.827354,"Missing"
W04-1402,dabbadie-etal-2002-terminological,1,0.892898,"Missing"
W04-1402,2001.mtsummit-eval.5,0,0.108291,"Missing"
W04-1402,2001.mtsummit-eval.6,1,0.896248,"Missing"
W04-1402,rajman-hartley-2002-automatic,1,0.847321,"Missing"
W04-1402,2001.mtsummit-eval.8,0,0.116552,"Missing"
W04-1402,besancon-rajman-2002-evaluation,1,\N,Missing
W04-3225,J96-1002,0,0.0140255,"ed within our IMT prototype. Section 3 describes the cache-based adaptation we performed on the target language model. In section 4, we present the different types of adaptations we performed on the translation model. Section 5 then puts the results in the context of our IMT application. Section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system. 2 Current IMT models The word-based translation model embedded within the IMT system has been designed by Foster (2000). It is a Maximum Entropy/Minimum Divergence (MEMD) translation model (Berger et al., 1996), which mimics the parameters of the IBM model 2 (Brown et al., 1993) within a log-linear setting. The resulting model (named MDI2B) is of the following form, where h is the current target text, s the source sentence being translated, s a particular word in s and w the next word to be predicted: P q(w|h) exp( s∈s αsw + βAB ) p(w|h, s) = (1) Z(h, s) The q distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study. The α coefficients are the familiar transfer or lexical parameters, and the β ones can be understood"
W04-3225,C88-1016,0,0.0304285,"as their position dependent correction. Z is a normalizing factor, the sum of the numerator for every w in the target vocabulary. Our baseline model used an interpolated trigram of the following form as the q distribution: p(w|h) = + + + λ1 (wi−2 wi−1 ) × ptri (wi |wi−2 wi−1 ) λ2 (wi−2 wi−1 ) × pbi (wi |wi−1 ) λ3 (wi−2 wi−1 ) × puni (wi ) λ4 (wi−2 wi−1 ) × |V 1|+1 where λ1 (wi−2 wi−1 ) + λ2 (wi−2 wi−1 ) + λ3 (wi−2 wi−1 ) + λ4 (wi−2 wi−1 ) = 1 and |V |+ 1 is the size of the event space (including a special unknown word). As mentioned above, the MDI2B model is closely related to the IBM2 model (Brown et al., 1988). It contains two classes of features: word pair features and positional features. The word pair feature functions are defined as follows:  1 if s ∈ s and t = w fst (w, h, s) = 0 otherwise This function is on if the predicted word is t and s is in the current source sentence. Each feature fst has a corresponding weight αst (for brevity, this is defined to be 0 in equation 1 if the pair s, t is not included in the model). The positional feature functions are defined as follows: fA,B (w, i, s) = J X δ[(i, j, J) ∈ A ∧ (sj , w) ∈ B ∧ j = ˆsj ] j=1 where δ[X] is 1 if X is true, otherwise 0; and"
W04-3225,J93-2003,0,0.00945756,"ation we performed on the target language model. In section 4, we present the different types of adaptations we performed on the translation model. Section 5 then puts the results in the context of our IMT application. Section 6 discusses the implications of our experiments and suggests some improvements that could be made to the system. 2 Current IMT models The word-based translation model embedded within the IMT system has been designed by Foster (2000). It is a Maximum Entropy/Minimum Divergence (MEMD) translation model (Berger et al., 1996), which mimics the parameters of the IBM model 2 (Brown et al., 1993) within a log-linear setting. The resulting model (named MDI2B) is of the following form, where h is the current target text, s the source sentence being translated, s a particular word in s and w the next word to be predicted: P q(w|h) exp( s∈s αsw + βAB ) p(w|h, s) = (1) Z(h, s) The q distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study. The α coefficients are the familiar transfer or lexical parameters, and the β ones can be understood as their position dependent correction. Z is a normalizing factor, th"
W04-3225,W02-1020,1,0.903063,"Missing"
W04-3225,W03-0302,0,0.0102562,"ith documents such as the sniper corpus, we believe that this could be a key improvement for a dynamic adaptive model. Better alignment As mentioned before, the ultimate goal for our cache is that it contains only the pairs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done for positional alignment"
W04-3225,W03-0301,0,0.0457849,"Missing"
W04-3225,W01-1411,0,0.0113039,"the sniper corpus, we believe that this could be a key improvement for a dynamic adaptive model. Better alignment As mentioned before, the ultimate goal for our cache is that it contains only the pairs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done for positional alignment features, wou"
W04-3225,P00-1056,0,0.0456813,"ition. Especially with documents such as the sniper corpus, we believe that this could be a key improvement for a dynamic adaptive model. Better alignment As mentioned before, the ultimate goal for our cache is that it contains only the pairs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done fo"
W04-3225,E03-1032,0,0.0244729,"Missing"
W04-3225,W03-0304,1,0.806705,"irs present in the perfect alignment. Better performance from the alignment would lead to pairs in the cache closer to this ideal. In this study we computed Viterbi alignments from an IBM model 2, because it is very efficient to compute and also because for training MDI2B, we do use the IBM model 2. We could consider also more advanced word alignment models (Och and Ney, 2000; Lin and Cherry, 2003; Moore, 2001). To keep the alignment model simple, we could still use an IBM model 2, but with the compositionality constraint that has been shown to give better word alignment than the Viterbi one (Simard and Langlais, 2003). Feature weights We implemented two versions of our model: one with only one feature weight and another with one feature weight for each word pair. The second model suffered from poor data representation and our training algorithm wasn’t able to estimate good cache feature weights. We think that creating classes of word pairs, such as it was done for positional alignment features, would lead to better results. It would enable the model to take into account the tendency that a pair has to repeat itself in a document. Relative weighting Another key improvement is that changes to word-pair weigh"
W04-3225,P00-1006,1,\N,Missing
W05-0810,J93-1003,0,0.0322939,"Missing"
W05-0810,J93-1004,0,0.504222,"niques strongly rely on the monotonic nature of the inherent alignment. Therefore, we conducted a first experiment using an in-house sentence alignment program called JAPA that we developed within the framework of the Arcade evaluation campaign (Langlais et al., 1998). The implementation details of this aligner can be found in (Langlais, 1997), but in a few words, JAPA aligns pairs of sentences by first grossly aligning their words (making use of either cognate-like tokens, or a specified bilingual dictionary). A second pass aligns the sentences in a way similar1 to the algorithm described by Gale and Church (1993), but where the search space is constrained to be close to the one delimited by the word alignment. This technique happened to be among the most accurate of the ones tested during the Arcade exercise. To adapt JAPA to our needs, we only did two things. First, we considered single sentences as documents, and tokens as sentences (we define a token as a sequence of characters delimited by Introduction Word alignment is an important step in exploiting parallel corpora. When efficient techniques have been proposed (Brown et al., 1993; Och and Ney, 2003), they have been mostly evaluated on ”safe” pa"
W05-0810,P98-1117,1,0.890027,"Missing"
W05-0810,J03-1002,0,0.00473577,"ay similar1 to the algorithm described by Gale and Church (1993), but where the search space is constrained to be close to the one delimited by the word alignment. This technique happened to be among the most accurate of the ones tested during the Arcade exercise. To adapt JAPA to our needs, we only did two things. First, we considered single sentences as documents, and tokens as sentences (we define a token as a sequence of characters delimited by Introduction Word alignment is an important step in exploiting parallel corpora. When efficient techniques have been proposed (Brown et al., 1993; Och and Ney, 2003), they have been mostly evaluated on ”safe” pairs of languages where the notion of word is rather clear. We devoted two weeks to the intriguing task of aligning at the word level pairs of sentences of English and Inuktitut. We experimented with two different approaches. For the first one, we relied on an in-house sentence alignment program (JAPA) where English and Inuktitut tokens were considered as sentences. The second approach we propose takes advantage of associations computed between any English word and roughly any subsequence of Inuktitut characters seen in the training corpus. We also"
W05-0810,1992.tmi-1.7,0,0.0783599,"nt approaches. For the first one, we relied on an in-house sentence alignment program (JAPA) where English and Inuktitut tokens were considered as sentences. The second approach we propose takes advantage of associations computed between any English word and roughly any subsequence of Inuktitut characters seen in the training corpus. We also investigated the combination of both approaches. 1 In our case, the score we seek to globally maximize by dynamic programming is not only taking into account the length criteria described in (Gale and Church, 1993) but also a cognate-based one similar to (Simard et al., 1992). 75 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 75–78, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 1-1 2-1 3-1 0.406 0.172 0.123 4-1 5-1 7-1 0.092 0.038 0.027 4-2 5-2 3-2 0.015 0.011 0.011 We extended this line of work in order to achieve word alignment. 3.1 Table 1: The 9 most frequent English-Inuktitut patterns observed on the development set. A total of 24 different patterns have been observed. As Martin et al. (2003) pointed out, the strong agglutinative nature of Inuktitut makes it necessary to consider subunits of Inuktitut tok"
W05-0810,J93-2003,0,\N,Missing
W05-0810,W03-0320,0,\N,Missing
W05-0810,C98-1113,1,\N,Missing
W05-0824,E03-1076,0,0.0371469,"rman words before training the translation models. Empirical methods for compound splitting applied to system baseline swap split swap+split WER SER NIST BLEU 60.70 60.73 60.67 60.57 98.40 98.60 98.60 98.40 5.8411 5.9643 5.7511 5.9685 21.11 22.58 21.99 23.10 where the moving of words ranked the best. This defined the configuration we submitted, whose results (as provided by the organizers) are reported in Table 3. pair fi-en de-en es-en fr-en Table 2: Performances of the swapping and the compound splitting approaches on the top 500 sentences of the development set. German have been studied by Koehn and Knight (2003). They found that a simple splitting strategy based on the frequency of German words was the most efficient method of the ones they tested, when embedded in a phrase-based translation engine. Therefore, we applied such a strategy to split German words in our corpora. The results of this approach are shown in Table 2. Note: Both the swapping strategy and the compound splitting yielded improvements in terms of BLEU score. Only after the deadline did we find time to train new models with a combination of both techniques; the results of which are reported in the last line of Table 2. 5 The Finnish"
W05-0824,N03-1017,0,0.0254431,"l Texts, pages 137–140, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 pair fi-en de-en fr-en es-en WER SER NIST BLEU 66.53 60.70 53.77 53.84 99.20 98.40 98.20 98.60 5.3353 5.8411 6.4717 6.5571 18.73 21.11 27.69 28.08 longing to the original model the following approximation: p(e ˙ i |fj ) ≈ pwn (ei |e) × pn (e|fj ) e∈E Table 1: Baseline performances measured on the 500 top sentences of the DEV corpus in terms of WER (word error rate), SER (sentence error rate), NIST and BLEU scores. which control the decoder. For acquiring a PBM, we followed the approach described by Koehn et al. (2003). In brief, we relied on a bi-directional word alignment of the training corpus to acquire the parameters of the model. We used the word alignment produced by Giza (Och and Ney, 2000) out of an IBM model 2. We did try to use the alignment produced with IBM model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of Koehn et al. (2003). Each parameter in a PBM can be scored in several ways. We considered its relative frequency as well as its IBM-model 1 score (where the transfer probabilities were taken from an IBM model 2 transfer ta"
W05-0824,P00-1056,0,0.0856452,"98.60 5.3353 5.8411 6.4717 6.5571 18.73 21.11 27.69 28.08 longing to the original model the following approximation: p(e ˙ i |fj ) ≈ pwn (ei |e) × pn (e|fj ) e∈E Table 1: Baseline performances measured on the 500 top sentences of the DEV corpus in terms of WER (word error rate), SER (sentence error rate), NIST and BLEU scores. which control the decoder. For acquiring a PBM, we followed the approach described by Koehn et al. (2003). In brief, we relied on a bi-directional word alignment of the training corpus to acquire the parameters of the model. We used the word alignment produced by Giza (Och and Ney, 2000) out of an IBM model 2. We did try to use the alignment produced with IBM model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of Koehn et al. (2003). Each parameter in a PBM can be scored in several ways. We considered its relative frequency as well as its IBM-model 1 score (where the transfer probabilities were taken from an IBM model 2 transfer table). The language model we used was the one provided within the shared task. We obtained baseline performances by tuning the engine on the top 500 sentences of the development corpus"
W05-0824,koen-2004-pharaoh,0,\N,Missing
W06-3106,2005.eamt-1.25,0,0.0250426,"s do not have to be adjacent. We show that the phrase-based translation engine we implemented benefits from Tree-Phrases. 1 Introduction Phrase-based machine translation is now a popular paradigm. It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to derive generalizations from the training corpus. Several alternatives have been recently proposed to tackle some of these weaknesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer,"
W06-3106,P04-1083,0,0.0151908,"knesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treele"
W06-3106,P00-1056,0,0.0669329,"Missing"
W06-3106,P02-1038,0,0.0291073,"´eraux” (request for federal funding). Note that the 2 words “a” and “demand´e” (literally “have” and “asked”) from the original sentence have been merged together by S YNTEX to form a single token. These tokens are the ones we use in this study. with the first pair of structures listed in the example. 3 The Translation Engine We built a translation engine very similar to the statistical phrase-based engine P HARAOH described in (Koehn, 2004) that we extended to use tree-phrases. Not only does our decoder differ from P HARAOH by using TPs, it also uses direct translation models. We know from (Och and Ney, 2002) that not using the noisy-channel approach does not impact the quality of the translation produced. 3.1 The maximization setting For a source sentence f , our engine incrementally generates a set of translation hypotheses H by combining tree-phrase (TP) units and phrase-phrase (PP) units.2 We define a hypothesis in this set as h = {Ui ≡ (Fi , Ei )}i∈[1,u] , a set of u pairs of source (Fi ) and target sequences (Ei ) of ni and mi words respectively: Fi ≡ {fjni : jni ∈ [1, |f |]}n∈[1,ni ] i Ei ≡ {elm i : lm ∈ [1, |e|]}m∈[1,m ] i under the constraints that for all i ∈ [1, u], jni &lt; i jn+1 , ∀n ∈"
W06-3106,J03-1002,0,0.00450563,"Missing"
W06-3106,2004.iwslt-evaluation.8,0,0.0143553,"he constraints that for all i ∈ [1, u], jni &lt; i jn+1 , ∀n ∈ [1, ni [ for a source treelet (similar coni straints apply on the target side), and jn+1 = jni + 1 , ∀n ∈ [1, ni [ for a source phrase. The way the hypotheses are built imposes additional constraints between units that will be described in Section 3.3. Note that, at decoding time, |e|, the number of words 2 What we call here a phrase-phrase unit is simply a pair of source/target sequences of words. 40 alignment: better understood as the numerator of a maximum entropy model popular in several statistical MT systems (Och and Ney, 2002; Bertoldi et al., 2004; Zens and Ney, 2004; Simard et al., 2005; Quirk et al., 2005). The components are the so-called feature functions (described below) and the weighting coefficients (λ) are the parameters of the model: a demand´e ≡ request for, f´ed´eraux ≡ federal, cr´edits ≡ funding treelets: a demand´ e M cr´ edits M qM qqq MMMMM qqq on qM qqq MMMMM qqq cr´ edits des s(h) = λpprf log ppprf (h) + λp |h|+ λtprf log ptprf (h) + λt |h|+ λppibm log pppibm (h)+ λtpibm log ptpibm (h)+ λlm log plm (projE (h))+ λd d(h) + λw |projE (h)| f´ ed´ eraux tree-phrases: TL? EP? {{on@-1} a_demand´ e {cr´ edits@2}} |request@0|"
W06-3106,P05-1033,0,0.0606934,"detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two languages and can easily be merged with stan"
W06-3106,2005.mtsummit-papers.19,0,0.0566838,"Missing"
W06-3106,P02-1040,0,0.0731677,"2005) could be used as well for that purpose. Language model We trained a Kneser-Ney trigram language model using the S RI L M toolkit (Stolcke, 2002). 4.3 Protocol We compared the performances of two versions of our engine: one which employs TPs ans PPs (TP ENGINE hereafter), and one which only uses PPs (PP - ENGINE). We translated the 16 disjoint subcorpora of the TEST corpus with and without TPs. We measure the quality of the translation produced with three automatic metrics. Two error rates: the sentence error rate (S ER) and the word error rate (W ER) that we seek to minimize, and B LEU (Papineni et al., 2002), that we seek to maximize. This last metric was computed with the multi-bleu.perl script available at www. statmt.org/wmt06/shared-task/. We separately tuned both systems on the DEV corpus by applying a brute force strategy, i.e. by sampling uniformly the range of each parameter (λ) and picking the configuration which led to the best B LEU score. This strategy is inelegant, but in early experiments we conducted, we found better configurations this way than by applying the Simplex method with multiple starting points. The tuning roughly takes 24 hours of computation on a cluster of 16 computer"
W06-3106,P05-1034,0,0.264609,"a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two languages and can easily be merged with standard phrase-based engines. A TP can be seen as a simplification of the treelet pairs manipulated in (Quirk et al., 2005). In particular, we do not address the issue of projecting a source treelet into a target one, but take the bet that collecting (without structure) the target words associated with the words encoded in the nodes of a treelet will suffice to allow translation. This set of target words is what we call an elastic phrase. We show that these units lead to (modest) improvements in translation quality as measured by automatic metrics. We conducted all our experiments 39 Proceedings of the Workshop on Statistical Machine Translation, pages 39–46, c New York City, June 2006. 2006 Association for Comput"
W06-3106,P05-1067,0,0.014147,"ov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic ph"
W06-3106,N04-1014,0,0.0210533,"model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two lang"
W06-3106,N03-1017,0,0.245171,"s, i.e. associations between simple syntactic dependency treelets in a source language and their corresponding phrases in a target language. The Tree-Phrases we use in this study are syntactically informed and present the advantage of gathering source and target material whose words do not have to be adjacent. We show that the phrase-based translation engine we implemented benefits from Tree-Phrases. 1 Introduction Phrase-based machine translation is now a popular paradigm. It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to derive generalizations from the training corpus. Several alternatives have been recently proposed to tackle some of these weaknesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the"
W06-3106,2003.mtsummit-papers.53,0,\N,Missing
W06-3106,koen-2004-pharaoh,0,\N,Missing
W06-3106,H05-1095,1,\N,Missing
W06-3106,J08-3004,0,\N,Missing
W06-3106,N04-1033,0,\N,Missing
W06-3116,W05-0824,1,0.837223,"Missing"
W06-3116,P00-1056,0,0.097092,", stateof-the-art decoders and providing an architecture to easily build these decoders. This effort is described in (Patry et al., 2006). Introduction Phrase-based (PB) machine translation (MT) is now a popular paradigm, partly because of the relative ease with which we can automatically create an acceptable translation engine from a bitext. As a matter of fact, deriving such an engine from a bitext consists in (more or less) gluing together dedicated software modules, often freely available. Word-based models, or the so-called IBM models, can be trained using the G IZA or G IZA ++ toolkits (Och and Ney, 2000). One can then train phrase-based models using the T HOT toolkit (Ortiz-Mart´ınez et al., 2005). For their part, language models currently in use in SMT systems can be trained using packages such as SRILM (Stolcke, 2002) and the CMU-SLM toolkit (Clarkson and Rosenfeld, 1997). 1 www.statmt.org/wmt06/shared-task/ baseline.html As a proof of concept that our framework (MOOD) is viable, we attempted to use its functionalities to implement a clone of P HARAOH, based on the comprehensive user manual of the latter. This clone, called R AMSES, is now part of the MOOD distribution, which can be downloa"
W06-3116,2005.mtsummit-papers.19,0,0.0647717,"Missing"
W06-3116,patry-etal-2006-mood,1,0.862047,"zers of the shared task1 to build the necessary models. We then carried out a pair-to-pair comparison of R AMSES with P HARAOH on the six different translation directions that we were asked to perform. We present this comparison in this paper. 1 For this reason, we undertook the design of a generic architecture called MOOD (Modular ObjectOriented Decoder), especially suited for instantiating SMT decoders. Two major goals directed our design of this package: offering open source, stateof-the-art decoders and providing an architecture to easily build these decoders. This effort is described in (Patry et al., 2006). Introduction Phrase-based (PB) machine translation (MT) is now a popular paradigm, partly because of the relative ease with which we can automatically create an acceptable translation engine from a bitext. As a matter of fact, deriving such an engine from a bitext consists in (more or less) gluing together dedicated software modules, often freely available. Word-based models, or the so-called IBM models, can be trained using the G IZA or G IZA ++ toolkits (Och and Ney, 2000). One can then train phrase-based models using the T HOT toolkit (Ortiz-Mart´ınez et al., 2005). For their part, langua"
W06-3116,2005.mtsummit-osmtw.1,0,0.0122472,"must implement a specific combination of two elements: a model representation and a search space exploration strategy. MOOD is a framework designed precisely to allow such a combination, by clearly separating its two elements. The design of the framework is described in (Patry et al., 2006). MOOD is implemented with the C++ programming language and is licensed under the Gnu General Public License (GPL)2 . This license grants the right to anybody to use, modify and distribute the program and its source code, provided that any modified version be licensed under the GPL as well. As explained in (Walker, 2005), this kind of license stimulates new ideas and research. 3 MOOD at work: R AMSES As we said above, in order to test our design, we reproduced the most popular phrase-based decoder, P HARAOH (Koehn, 2004), by following as faithfully as possible its detailed user manual. The commandline syntax R AMSES recognizes is compatible with that of P HARAOH. The output produced by both decoders are compatible as well and R AMSES can also output its n-best lists in the same format as P HARAOH does, i.e. in a format that the CARMEL toolkit can parse (Knight and Al-Onaizan, 1999). Switching decoders is ther"
W06-3116,2004.tmi-1.9,0,0.102446,"Missing"
W06-3116,koen-2004-pharaoh,0,\N,Missing
W06-3116,J93-2003,0,\N,Missing
W06-3116,N03-1017,0,\N,Missing
W06-3116,P05-1066,0,\N,Missing
W08-0310,allauzen-bonneau-maynard-2008-training,1,0.882861,"Missing"
W08-0310,D07-1091,0,0.12789,"ond pass, the use of the Neural Network LMs, if used with an appropriate (tuned) weight, yields a small, yet consistent improvement of B LEU for all pairs. Performance on the news task are harder to analyze, due to the lack of development data. Throwing in large set of in-domain data was obviously helpful, even though we are currently unable to adequately measure this effect. 4 Experiments with factored models Even though these models were not used in our submissions, we feel it useful to comment here our (negative) experiments with factored models. 4.1 Overview In this work, factored models (Koehn and Hoang, 2007) are experimented with three factors : the surface form, the lemma and the part of speech (POS). The translation process is composed of different mapping steps, which either translate input factors into output factors, or generate additional output factors from existing output factors. In this work, four mapping steps are used with two decoding paths. The first path corresponds to the standard and direct mapping of surface forms. The second decoding path consists in two translation steps for respectively POS tag and the lemmas, followed by a generation step which produces the surface form give"
W08-0310,W07-0733,0,0.0277945,"stical Machine Translation, pages 107–110, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics the news-commentary parallel data, as depicted on Figure 1. This setup was found to be more favorable than training on Europarl data only (for obvious mismatching domain reasons) and than training on news-commentary data only, most probably because of a lack of coverage. Another, alternative way of benefitting from the coverage of the Europarl corpus and the relevance of the news-commentary corpus is to use two phrase-tables in parallel, an interesting feature of Moses. (Koehn and Schroeder, 2007) found that this was the best way to “adapt” a translation system to the news-commentary task. These results are corroborated in (Déchelotte, 2007)1 , which adapts a “European Parliament” system using a “European and Spanish Parliaments” development set. However, we were not able to reproduce those findings for this evaluation. This might be caused by the increase of the number of feature functions, from 14 to 26, due to the duplication of the phrase table and the lexicalized reordering model. 2.2 2.2.1 Language Models Europarl language models The training of Europarl language models (LMs) was"
W08-0310,N03-1017,0,0.00383999,"data, translating French, German and Spanish from and to English, amounting a total of twelve evaluation conditions. Figure 1 presents the generic overall architecture of L IMSI’s translation systems. They are fairly standard phrase-based ∗ Univ. Montréal, felipe@iro.umontreal.ca Figure 1: Generic architecture of L IMSI’s SMT systems. Depending on the condition, the decoder generates either the final output or n-best lists. In the latter case, the rescoring incorporates the same translation features, except for a better target language model (see text). translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence. The search uses the following models: a phrase table, providing 4 scores and a phrase penalty, a lexicalized reordering model (7 scores), a language model score and a word penalty. These fourteen scores are weighted and linearly combined (Och and Ney, 2002; Och, 2003); their respective weights are learned on development data so as to maximize the B LEU score. In the following, we detail several aspects of our systems. 2.1 Translation models The translation models deployed in our systems for the europarl condition were"
W08-0310,P07-2045,0,0.0336357,"d Spanish from and to English, amounting a total of twelve evaluation conditions. Figure 1 presents the generic overall architecture of L IMSI’s translation systems. They are fairly standard phrase-based ∗ Univ. Montréal, felipe@iro.umontreal.ca Figure 1: Generic architecture of L IMSI’s SMT systems. Depending on the condition, the decoder generates either the final output or n-best lists. In the latter case, the rescoring incorporates the same translation features, except for a better target language model (see text). translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence. The search uses the following models: a phrase table, providing 4 scores and a phrase penalty, a lexicalized reordering model (7 scores), a language model score and a word penalty. These fourteen scores are weighted and linearly combined (Och and Ney, 2002; Och, 2003); their respective weights are learned on development data so as to maximize the B LEU score. In the following, we detail several aspects of our systems. 2.1 Translation models The translation models deployed in our systems for the europarl condition were trained on the provided Europarl pa"
W08-0310,P02-1038,0,0.0651661,"s. Depending on the condition, the decoder generates either the final output or n-best lists. In the latter case, the rescoring incorporates the same translation features, except for a better target language model (see text). translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence. The search uses the following models: a phrase table, providing 4 scores and a phrase penalty, a lexicalized reordering model (7 scores), a language model score and a word penalty. These fourteen scores are weighted and linearly combined (Och and Ney, 2002; Och, 2003); their respective weights are learned on development data so as to maximize the B LEU score. In the following, we detail several aspects of our systems. 2.1 Translation models The translation models deployed in our systems for the europarl condition were trained on the provided Europarl parallel data only. For the news condition, they were trained on the Europarl data merged with 107 Proceedings of the Third Workshop on Statistical Machine Translation, pages 107–110, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics the news-commentary parallel data,"
W08-0310,J04-4002,0,0.016144,"l data and on News data, translating French, German and Spanish from and to English, amounting a total of twelve evaluation conditions. Figure 1 presents the generic overall architecture of L IMSI’s translation systems. They are fairly standard phrase-based ∗ Univ. Montréal, felipe@iro.umontreal.ca Figure 1: Generic architecture of L IMSI’s SMT systems. Depending on the condition, the decoder generates either the final output or n-best lists. In the latter case, the rescoring incorporates the same translation features, except for a better target language model (see text). translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence. The search uses the following models: a phrase table, providing 4 scores and a phrase penalty, a lexicalized reordering model (7 scores), a language model score and a word penalty. These fourteen scores are weighted and linearly combined (Och and Ney, 2002; Och, 2003); their respective weights are learned on development data so as to maximize the B LEU score. In the following, we detail several aspects of our systems. 2.1 Translation models The translation models deployed in our systems for the eur"
W08-0310,P03-1021,0,0.0607674,"condition, the decoder generates either the final output or n-best lists. In the latter case, the rescoring incorporates the same translation features, except for a better target language model (see text). translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence. The search uses the following models: a phrase table, providing 4 scores and a phrase penalty, a lexicalized reordering model (7 scores), a language model score and a word penalty. These fourteen scores are weighted and linearly combined (Och and Ney, 2002; Och, 2003); their respective weights are learned on development data so as to maximize the B LEU score. In the following, we detail several aspects of our systems. 2.1 Translation models The translation models deployed in our systems for the europarl condition were trained on the provided Europarl parallel data only. For the news condition, they were trained on the Europarl data merged with 107 Proceedings of the Third Workshop on Statistical Machine Translation, pages 107–110, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics the news-commentary parallel data, as depicted"
W10-1713,W09-0432,0,0.0271007,"Missing"
W10-1713,W09-0401,0,0.103024,"Missing"
W10-1713,W07-0717,0,0.0428474,"Missing"
W10-1713,2005.eamt-1.19,0,0.114386,"adds a new sentence pair when it contains new n-grams (with 1 ≤ n ≤ 12) occurring less than 20 times in the current corpus, which led us to add 1.5 M pairs for English-French and 1.4 M for French-English. A significant improvement of BLEU is observed using this method (0.8 for English-French and 1.0 for French-English) w.r.t. the use of 1.7 M randomly selected pairs. However, this method has the major drawback of needing to build a new phrase table for each document to translate. Information retrieval Information retrieval (IR) methods have been used in the past to subsample parallel corpora (Hildebrand et al., 2005; L¨u et al., 2007). These studies use sentences belonging to the development and test corpora as queries to select the k most similar source sentences in an indexed parallel corpus. The retrieved sentence pairs constitute a training corpus for the translation models. In order to alleviate the fact that a new PBM has to be learned for each 1 106 www.lemurproject.org PBM +IR score +N-best list reranking +grammatical checker BLEU 27.5 27.7 27.9 28.0 En→Fr BLEU-cased 26.5 26.6 26.8 26.9 TER 62.2 62.1 62.1 62.0 BLEU 27.8 28.0 28.0 - Fr→En BLEU-cased 26.9 27.0 27.0 - TER 61.2 61.0 61.2 - Table 5: O"
W10-1713,P07-2045,0,0.0122228,"Missing"
W10-1713,2009.mtsummit-papers.9,0,0.0194333,"ement errors, like in the following example where the agreement between the subject nombre (number) is correctly made with the adjective coup´e (cut), thanks to the full syntactic parsing of the French sentence. Source: [...] the number of revaccinations could then be cut [...] Reranking: [...] le nombre de revaccinations pourrait 2 5 Effects of the Original Source Language of Articles on Translation During our experiments, we found that translation quality is highly variable depending on the original source language of the news sentences. This phenomenon is correlated to the previous work of Kurokawa et al. (2009) that showed that whether or not a piece of text is an original or a translation has an impact on translation performance. The main reason that explains our observations is probably that the topics and the vocabulary of news originally expressed in languages other than French and English tend to differ more from those of the training materials used to train PBM models for these two languages. In order to take into account this phenomenon, MERT tuning was repeated for each original source language, using the www.druide.com 107 References same PBM models trained on all parallel corpora and incor"
W10-1713,W09-0424,0,0.103928,"Missing"
W10-1713,D07-1036,0,0.0900439,"Missing"
W10-1713,J03-1002,0,0.00554702,"Missing"
W10-1713,P03-1021,0,0.0110142,"EU is computed using a serialized reference (line 3), which is equivalent to ignoring deserialization errors, a minor gain of BLEU is observed, which validates our recovering method. Since resorting to serialization/deserialization yields comparable performance to a system not using it, while reducing the model’s size, we chose to use it. • maximum sentence length of 80 words, • limit on the number of phrase translations loaded for each phrase fixed to 30. Weights of LM, phrase table and lexicalized reordering model scores were optimized on the development corpus thanks to the MERT algorithm (Och, 2003). 2.4 Experiments This section reports experiments done on the news-test2009 corpus for testing various configurations. In these first experiments, we trained LMs and translation models on the Europarl corpus. no serialization corpus serialization corpus and reference serialization Case We tested two methods to handle case. The first one lowercases all training data and documents to translate, while the second one normalizes all training data and documents into their natural case. These two methods require a postprocessing recapitalization but this last step is more basic for the truecase meth"
W11-1212,E09-1003,0,0.0466296,"fier designed to recognize parallel sentences. They applied their classifier on two monolingual news corpora in Arabic and English, covering similar periods, and showed that the parallel material extracted, when added to an in-domain parallel training corpus of United Nation texts, improved significantly an Arabic-to-English SMT system tested on news data. Still, they noted that the extracted material does not come close to the quality obtained by adding a small out-domain parallel corpus to the in-domain training material. Different variants of this approach have been tried afterwards, e.g. (Abdul-Rauf and Schwenk, 2009). To the best of our knowledge, Adafre and de Rijke (2006) where the first to look at the problem of extracting parallel sentences from Wikipedia. They compared two approaches for doing so that both search for parallel sentence pairs in cross-language linked articles. The first one uses an MT engine in order to translate sentences of one document into the language of the other article; then parallel sentences are selected based on a monolingual similarity measure. The second approach represents each sentence of a pair of documents in a space of hyperlink anchored texts. An initial lexicon is c"
W11-1212,W06-2810,0,0.312658,"Missing"
W11-1212,N07-2008,0,0.36612,"ection thanks to an indexing strategy φ that will be described shortly. Then, for a source document s, we first index it, that is, we compute φ(s), and query the retrieval engine with φ(s), which in turn returns the N most similar target documents found in the collection. In our experiments, we used the Lucene5 retrieval library. We tested two indexing strategies: one reduces a document to the sequence of hapax words it contains (φ ≡hap), the other one reduces it to its sequence of numerical entities (φ ≡num). Hapax words have been found very useful in identifying parallel pairs of documents (Enright and Kondrak, 2007) as well as for word-aligning bitexts (Lardilleux and Lepage, 2007). Following Enright and Kondrak (2007), we define hapax words as blank separated strings of more than 4 characters that appear only once in the document being indexed. Also, we define a numerical entity as a blank separated form containing at least one digit. It is clear from this description that our indexing strategies can easily be applied to many different languages. 2.2 Each candidate pair delivered by Lucene, is classified as parallel or not by a classifier trained in a supervised way to recognize parallel documents. Here"
W11-1212,erjavec-2004-multext,0,0.0129673,"ated the 1 http://www.statmt.org/wmt10 Philippe Langlais DIRO/RALI Universit´e de Montr´eal Montr´eal, Canada H3C3J7 felipe@iro.umontreal.ca Opus corpus,2 an open source parallel corpus gathering texts of various sources, in several languages pairs. This is an ongoing effort currently gathering more than 13 Gigabytes of compressed files. The Europarl corpus3 (Koehn, 2005) gathers no less than 2 Gigabytes of compressed documents in 20 language pairs. Some other bitexts are more marginal in nature. For instance, the novel 1984 of George Orwel has been organized into an English-Norvegian bitext (Erjavec, 2004) and Beyaz Kale of Orhan Pamuk as well as Sofies Verden of Jostein Gaardner are available for the Swedish-Turk language pair (Megyesi et al., 2006). A growing number of studies investigate the extraction of near parallel material (mostly sentences) from comparable data. Among them, Munteanu et al. (2004) demonstrate that a classifier can be trained to recognize parallel sentences in comparable corpora mined from news collections. A number of related studies (see section 5) have also been proposed; some of them seeking to extract parallel sentences from cross-language linked article pairs in Wi"
W11-1212,W09-1605,0,0.0606906,"other, while the English article [Decline of the Roman Empire] and the French one [D´eclin de l’empire romain d’Occident] are parallel.12 4.1 Resource During summer 2009, we collected all FrenchEnglish cross-language linked articles from Wikipedia. A very straightforward preprocessing stage involving simple regular expressions removed part of the markup specific to this resource. We ended up with 537 067 articles in each language. The average length of the English pages is 711 words, while the average for French is 445 words. The difference in length among linked articles has been studied by Filatova (2009) on a small excerpt of bibliographical articles describing 48 persons listed in the biography generation task (Task 5) of DUC 2004.13 12 13 At least they were at the time of redaction. http://duc.nist.gov/duc2004/tasks.html/ 91 Parallelness of cross-language linked article pairs in FR - EN Wikipedia. In this experiment, we wanted to measure the proportion of cross-language linked article pairs in Wikipedia that are in translation relation. In order to do so, we manually evaluated 200 pairs of articles in our French-English Wikipedia repository. A web interface was developed in order to annotat"
W11-1212,W04-3208,0,0.0670682,"ibing 48 persons listed in the biography generation task (Task 5) of DUC 2004.13 12 13 At least they were at the time of redaction. http://duc.nist.gov/duc2004/tasks.html/ 91 Parallelness of cross-language linked article pairs in FR - EN Wikipedia. In this experiment, we wanted to measure the proportion of cross-language linked article pairs in Wikipedia that are in translation relation. In order to do so, we manually evaluated 200 pairs of articles in our French-English Wikipedia repository. A web interface was developed in order to annotate each pair, following the distinction introduced by Fung and Cheung (2004): parallel indicates sentence-aligned texts that are in translation relation; noisy characterizes two documents that are nevertheless mostly bilingual translations of each other; topic corresponds to documents which share similar topics, but that are not translation of each others and very-non that stands for rather unrelated texts. The results of the manual evaluation are reported in the left column of table 1. We observe that a fourth of the pairs of articles are indeed parallel or noisy parallel. This figure quantifies the observation made by Adafre and de Rijke (2006) that while some artic"
W11-1212,1999.mtsummit-1.79,0,0.0604974,"nd S TRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. Since heuristics on URL names does not ensure parallelness, other cues, such as the ratio of the length of the documents paired or their HTML structure, are further being used. Others have proposed to use features computed after sentence aligning a candidate pair of documents (Shi et al., 2006), a very time consuming strategy (that we tried without success). Others have tried to use bilingual lexicons in order to compare document pairs; this is for instance the case of the B ITS system (Ma and Liberman, 1999). Also, Enright and Kondrak (2007) 93 propose a very lightweight content-based approach to pairing documents, capitalizing on the number of hapax words they share. We show in this study, that this approach can easily be outperformed. Zhao and Vogel (2002) were among the first to report experiments on harvesting comparable news collections in order to extract parallel sentences. With a similar goal, Munteanu et al. (2004) proposed to train in a supervised way (using some parallel data) a classifier designed to recognize parallel sentences. They applied their classifier on two monolingual news c"
W11-1212,megyesi-etal-2006-building,0,0.0296192,"Opus corpus,2 an open source parallel corpus gathering texts of various sources, in several languages pairs. This is an ongoing effort currently gathering more than 13 Gigabytes of compressed files. The Europarl corpus3 (Koehn, 2005) gathers no less than 2 Gigabytes of compressed documents in 20 language pairs. Some other bitexts are more marginal in nature. For instance, the novel 1984 of George Orwel has been organized into an English-Norvegian bitext (Erjavec, 2004) and Beyaz Kale of Orhan Pamuk as well as Sofies Verden of Jostein Gaardner are available for the Swedish-Turk language pair (Megyesi et al., 2006). A growing number of studies investigate the extraction of near parallel material (mostly sentences) from comparable data. Among them, Munteanu et al. (2004) demonstrate that a classifier can be trained to recognize parallel sentences in comparable corpora mined from news collections. A number of related studies (see section 5) have also been proposed; some of them seeking to extract parallel sentences from cross-language linked article pairs in Wikipedia4 (Adafre and de Rijke, 2006; Smith et al., 2010). None of these studies addresses specifically the issue of discovering parallel pairs of a"
W11-1212,N04-1034,0,0.572565,"ore than 13 Gigabytes of compressed files. The Europarl corpus3 (Koehn, 2005) gathers no less than 2 Gigabytes of compressed documents in 20 language pairs. Some other bitexts are more marginal in nature. For instance, the novel 1984 of George Orwel has been organized into an English-Norvegian bitext (Erjavec, 2004) and Beyaz Kale of Orhan Pamuk as well as Sofies Verden of Jostein Gaardner are available for the Swedish-Turk language pair (Megyesi et al., 2006). A growing number of studies investigate the extraction of near parallel material (mostly sentences) from comparable data. Among them, Munteanu et al. (2004) demonstrate that a classifier can be trained to recognize parallel sentences in comparable corpora mined from news collections. A number of related studies (see section 5) have also been proposed; some of them seeking to extract parallel sentences from cross-language linked article pairs in Wikipedia4 (Adafre and de Rijke, 2006; Smith et al., 2010). None of these studies addresses specifically the issue of discovering parallel pairs of articles in Wikipedia. In this paper, we describe PARADOCS, a system capable of mining parallel documents in a collection, based on lightweight content-based f"
W11-1212,J03-3002,0,0.703492,"dia. In this paper, we describe PARADOCS, a system capable of mining parallel documents in a collection, based on lightweight content-based features extracted from the documents. On the contrary to other systems designed to target parallel corpora (Chen 2 http://opus.lingfil.uu.se/ http://www.statmt.org/europarl/ 4 http://fr.wikipedia.org/ 3 87 Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 87–95, 49th Annual Meeting of the Association for Computational Linguistics, c Portland, Oregon, 24 June 2011. 2011 Association for Computational Linguistics and Nie, 2000; Resnik and Smith, 2003), we do not assume any specific naming conventions on filenames or URLs. The reminder of this article is organized as follows. In the next section, we describe our approach to mining parallel documents in a bilingual collection of texts. We test our approach on the Europarl corpus in section 3. We present in section 4 the application of our system to a subpart of the French-English articles of Wikipedia. We describe related work in section 5, summarize our work in section 6 and present future works in section 7. 2 PARADOCS In order to identify pairs of parallel documents in a bilingual collect"
W11-1212,P06-1062,0,0.0184194,"everal authors. Most of the previous approaches for tackling this problem capitalize on naming conventions (on file URL names) for pairing documents. This is for instance the case of PTM INER (Chen and Nie, 2000) and S TRAND (Resnik and Smith, 2003), two systems that are intended to mine parallel documents over the Web. Since heuristics on URL names does not ensure parallelness, other cues, such as the ratio of the length of the documents paired or their HTML structure, are further being used. Others have proposed to use features computed after sentence aligning a candidate pair of documents (Shi et al., 2006), a very time consuming strategy (that we tried without success). Others have tried to use bilingual lexicons in order to compare document pairs; this is for instance the case of the B ITS system (Ma and Liberman, 1999). Also, Enright and Kondrak (2007) 93 propose a very lightweight content-based approach to pairing documents, capitalizing on the number of hapax words they share. We show in this study, that this approach can easily be outperformed. Zhao and Vogel (2002) were among the first to report experiments on harvesting comparable news collections in order to extract parallel sentences."
W11-1212,N10-1063,0,0.22669,"l as Sofies Verden of Jostein Gaardner are available for the Swedish-Turk language pair (Megyesi et al., 2006). A growing number of studies investigate the extraction of near parallel material (mostly sentences) from comparable data. Among them, Munteanu et al. (2004) demonstrate that a classifier can be trained to recognize parallel sentences in comparable corpora mined from news collections. A number of related studies (see section 5) have also been proposed; some of them seeking to extract parallel sentences from cross-language linked article pairs in Wikipedia4 (Adafre and de Rijke, 2006; Smith et al., 2010). None of these studies addresses specifically the issue of discovering parallel pairs of articles in Wikipedia. In this paper, we describe PARADOCS, a system capable of mining parallel documents in a collection, based on lightweight content-based features extracted from the documents. On the contrary to other systems designed to target parallel corpora (Chen 2 http://opus.lingfil.uu.se/ http://www.statmt.org/europarl/ 4 http://fr.wikipedia.org/ 3 87 Proceedings of the 4th Workshop on Building and Using Comparable Corpora, pages 87–95, 49th Annual Meeting of the Association for Computational L"
W11-1212,erjavec-2010-multext,0,\N,Missing
W11-1212,W09-0401,0,\N,Missing
W13-1109,P11-2071,0,0.0365143,"Missing"
W13-1109,D10-1044,0,0.0411895,"Missing"
W13-1109,P11-2008,0,0.0615495,"Missing"
W13-1109,W12-3153,0,0.0343686,"Missing"
W13-1109,P07-2045,0,0.00886209,"ed (a posteriori) the parallelness of a random sample of 50 sentence pairs extracted for each feed. Quite fortunately, the extracted material was of excellent quality, with most samples containing all perfectly aligned sentences. Only canadabusiness , LibraryArchives and CanBorder counted a single mistranslated pair. Clearly, the websites of the Canadian institutions we mined are translated with great care and the tweets referring to them are meticulously translated in terms of content links. 3 3.1 Experiments Methodology All our translation experiments were conducted with Moses’ EMS toolkit (Koehn et al., 2007), which in turn uses gizapp (Och and Ney, 2003) and SRILM (Stolcke, 2002). As a test bed, we used the 200 bilingual tweets we acquired that were not used to follow urls, as described in Sections 2.1 and 2.3. We kept each feed separate in order to measure the performance of our system on each of them. Therefore we have 12 test sets. We tested two configurations: one in which an out-of-domain translation system is applied (without adaptation) to the translation of the tweets of our test material, another one where we allowed the system to look at in-domain data, either at training or at tuning t"
W13-1109,2010.eamt-1.37,0,0.0206028,"trate on the automated processing of messages exchanged on social networks. See (Gimpel et al., 2011) for a recent review of some of them. Some effort has been invested in translating short text messages (SMSs). Notably, Munro (2010) describes the service deployed by a consortium of volunteer organizations named “Mission 4636” during the earthquake that struck Haiti in January 2010. This service routed SMSs alerts reporting trapped people and other emergencies to a set of volunteers who translated Haitian Creole SMSs into English, so that primary emergency responders could understand them. In Lewis (2010), the authors describe how the Microsoft translation team developed a statistical translation engine (Haitian Creole into English) in as little as 5 days, during the same tragedy. 2 http://news.meedan.net/ http://www.aboutonlinetips.com/ twitter-translation-tools/ 3 80 Proceedings of the Workshop on Language in Social Media (LASM 2013), pages 80–89, c Atlanta, Georgia, June 13 2013. 2013 Association for Computational Linguistics Jehl (2010) addresses the task of translating English tweets into German. She concludes that the proper treatment of unknown words is of the utmost importance and high"
W13-1109,2010.amta-workshop.1,0,0.102277,"illing to translate tweets written in Arabic on Middle East issues. Another solution consists in using machine translation. Several portals are facilitating this,3 mainly by using Google’s machine translation API. Curiously enough, few studies have focused on the automatic translation of text produced within social networks, even though a growing number of these studies concentrate on the automated processing of messages exchanged on social networks. See (Gimpel et al., 2011) for a recent review of some of them. Some effort has been invested in translating short text messages (SMSs). Notably, Munro (2010) describes the service deployed by a consortium of volunteer organizations named “Mission 4636” during the earthquake that struck Haiti in January 2010. This service routed SMSs alerts reporting trapped people and other emergencies to a set of volunteers who translated Haitian Creole SMSs into English, so that primary emergency responders could understand them. In Lewis (2010), the authors describe how the Microsoft translation team developed a statistical translation engine (Haitian Creole into English) in as little as 5 days, during the same tragedy. 2 http://news.meedan.net/ http://www.abou"
W13-1109,J03-1002,0,0.00415281,"ample of 50 sentence pairs extracted for each feed. Quite fortunately, the extracted material was of excellent quality, with most samples containing all perfectly aligned sentences. Only canadabusiness , LibraryArchives and CanBorder counted a single mistranslated pair. Clearly, the websites of the Canadian institutions we mined are translated with great care and the tweets referring to them are meticulously translated in terms of content links. 3 3.1 Experiments Methodology All our translation experiments were conducted with Moses’ EMS toolkit (Koehn et al., 2007), which in turn uses gizapp (Och and Ney, 2003) and SRILM (Stolcke, 2002). As a test bed, we used the 200 bilingual tweets we acquired that were not used to follow urls, as described in Sections 2.1 and 2.3. We kept each feed separate in order to measure the performance of our system on each of them. Therefore we have 12 test sets. We tested two configurations: one in which an out-of-domain translation system is applied (without adaptation) to the translation of the tweets of our test material, another one where we allowed the system to look at in-domain data, either at training or at tuning time. The in-domain material we used for adaptin"
W13-1109,P02-1040,0,0.093778,". For adaptation experiments conducted at training time, all the URL material extracted from a specific feed (except for the sentences of the tuning sets) was used. The language model used in our experiments was a 5-gram language model with KneserNey smoothing. It must be emphasized that there is no tweet material in our training or tuning sets. One reason for this is that we did not have enough tweets to populate our training corpus. Also, this corresponds to a realistic scenario where we want to translate a Twitter feed without first collecting tweets from this feed. We use the BLEU metric (Papineni et al., 2002) as well as word-error rate (WER) to measure translation quality. A good translation system maximizes BLEU and minimizes WER. Due to initially poor results, we had to refine the tokenizer mentioned in Section 2.1 in order to replace urls with serialized placeholders, since those numerous entities typically require rule-based translations. The BLEU and WER scores we report henceforth were computed on such lowercased, tokenized and serialized texts, and did not incur penalties that would have 84 train tune fr→en hans hans hans in euro euro euro in en→fr hans hans hans in euro euro euro in canada"
W13-1109,P12-1099,0,0.0522131,"Missing"
W13-1109,C04-1059,0,0.0800329,"Missing"
W17-2509,J03-3002,0,0.432894,"Missing"
W17-2509,E09-1003,0,0.264575,"artesian product between sentence pairs in the corpora. This is not an issue for small comparable corpora, e.g. two Wikipedia articles. However, in our case we are given two monolingual corpora of approximately 370,000 and 270,000 sentences, for a potential of 9.99e10 pairs of sentences to evaluate. To reduce the size and the noise of the candidate sentence pairs, traditional approaches apply candidate filters such as sentence length ratio, bilingual dictionary word overlap, word alignment conditions from SMT and information retrieval systems (Resnik and Smith, 2003; Munteanu and Marcu, 2005; Abdul-Rauf and Schwenk, 2009). Following our idea to evaluate the feasibility of an approach using only distributional representations, for each sentence we learned its continuous vector representation and created our set of candidate sentence pairs by using the n-best cosine similarity score between each source sentence 3.2 Training settings We use TensorFlow3 (Abadi et al., 2016) to train our models. The dimension of the BiGRU recurrent state is 200 in each direction with word embeddings of dimension 300. We train our models using a mini-batch size of 128 and Adam optimizer (Kingma and Ba, 2014) with a learning rate of"
W17-2509,D14-1179,0,0.0113343,"Missing"
W17-2509,E17-2066,0,0.0480494,"Missing"
W17-2509,J05-4003,0,0.73428,"ted after submitting our results. This paper describes our participation in BUCC 2017 shared task: identifying parallel sentences in comparable corpora. Our goal is to leverage continuous vector representations and distributional semantics with a minimal use of external preprocessing and postprocessing tools. We report experiments that were conducted after transmitting our results. 1 Introduction Traditional approaches for parallel sentence identification from comparable corpora rely on machine learning models with the use of features measured by statistical machine translation (SMT) systems. Munteanu and Marcu (2005) present how to extract parallel sentences from newspaper articles using general and alignment features to train a binary maximum entropy classifier. AbdulRauf and Schwenk (2009) use an SMT-based system on comparable corpora to translate the source language side to detect corresponding parallel sentences on the target language side. While continuous vector representations of words and sentences estimated by neural language models and neural networks (Bengio et al., 2003; Collobert and Weston, 2008) have been successfully applied to a variety of natural language processing tasks, ranging from h"
W17-4812,D14-1224,0,0.0293316,"d et al., 2008), indicating that there are more implicit DCs in Chinese, correspondingly, discourse relations are usually implicit. 2 Related Work Discourse related issues have become increasingly popular in Natural Language Processing in recent 93 Proceedings of the Third Workshop on Discourse in Machine Translation, pages 93–98, c Copenhagen, Denmark, September 8, 2017. 2017 Association for Computational Linguistics. years, especially the release of some famous discourse treebanks including PDTB, CDTB and RST (Mann and Thompson, 1986) corpus has promoted the research greatly. Some research (Li et al. 2014, Rutherford and Xue, 2014) has done on monolingual annotation and analysis of Chinese DCs. Li et al. (2014a) and Yung et al. (2015a, 2015b) also present some cross-lingual discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Mey"
W17-4812,W12-0117,0,0.038831,"Missing"
W17-4812,W13-3303,0,0.0189758,"014, Rutherford and Xue, 2014) has done on monolingual annotation and analysis of Chinese DCs. Li et al. (2014a) and Yung et al. (2015a, 2015b) also present some cross-lingual discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Meyer and Webber, 2013). As for Chinese discourse relations and translation, Tu et al. (2013) employ a RST-based discourse parsing approaches in SMT, in their following work (Tu et al. 2014), they also present a tree-string model on Chinese complex sentences, integrating discourse relations into MT, gaining some improvement on translation performance. Li et al. (2014b) argues the influence of discourse factors in translation. 3 3.1 As mentioned above, we will analyze the DCs on both cross-sentence and within-sentence levels, we decide to annotate the corpus in a top-down way. That is, we first annotate DCs between c"
W17-4812,tiedemann-2012-parallel,0,0.0282037,"or of the paper alone, who is a PhD student majored in Linguistics and Computational Linguistics. As a result, unlike many previous works on corpus annotation, we don’t conduct consistency experiments between different annotators to justify the performance of annotation until now. But we try to guarantee the annotation quality as much as possible. In the future, we will expand the annotaCross-lingual Annotations of DCs In order to investigate the DCs in the translation, we first manually align DCs in Chinese and English in the bilingual corpus, News-commentary corpus 1 downloaded from OPUS 2 (Tiedemann, 2012), then further annotate them with essential information on both the source and target sides. The reasons why we choose news-commentary corpus lie in two sides: first, each line in the corpus usually includes several consecutive sentences, and each sentence is further composed of several sub-sentences(clauses), which provide rich cross-sentence and within-sentence discourselevel information. Second, sentences in each line are neither too long nor too short, which are suitable to train the MT models. In this part, we will describe the annotation scheme and some corresponding findings. 1 2 Annota"
W17-4812,P07-2045,0,0.0151478,"erent, thus the n-gram based BLEU evaluation will not able to capture the information, which support our guess. Preliminary Experiments & Analysis We conduct MT automatic evaluation experiments on the annotated Chinese sentences with inserted implicit DCs to testify the translation performance before and after representing implicit DCs with explicit ones. Evaluation metrics include BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) scores, calculated by the Asiya toolkit4 (Giménez and Màrquez, 2010). 4.1 Experimental Results and Analysis Experimental Setting With Moses decoder (Koehn et al., 2007), we train a phrase-based SMT model on another different version of News-Commentary corpus 5 provided respectively by OPUS (69,206 sentence pairs) and WMT2017 Shared Task 6 (235,724 pairs), and the model is tuned by MERT (Och, 2003) with the development sets (2002 pairs) provided by WMT2017. GIZA++ (Och and Ney, 2003) is used for automatic word alignment and a 5-gram language model is trained on English Gigaword (Parker et al., 2011). 1500 sentences randomly chosen from the annotated corpus in section3 are used as test sets. Source: 作为货币联盟，金融一体化在欧元区非常 牢固， [implicit = Causation, added DC = 因此]"
W17-4812,J03-1002,0,0.00704226,"ting implicit DCs with explicit ones. Evaluation metrics include BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) scores, calculated by the Asiya toolkit4 (Giménez and Màrquez, 2010). 4.1 Experimental Results and Analysis Experimental Setting With Moses decoder (Koehn et al., 2007), we train a phrase-based SMT model on another different version of News-Commentary corpus 5 provided respectively by OPUS (69,206 sentence pairs) and WMT2017 Shared Task 6 (235,724 pairs), and the model is tuned by MERT (Och, 2003) with the development sets (2002 pairs) provided by WMT2017. GIZA++ (Och and Ney, 2003) is used for automatic word alignment and a 5-gram language model is trained on English Gigaword (Parker et al., 2011). 1500 sentences randomly chosen from the annotated corpus in section3 are used as test sets. Source: 作为货币联盟，金融一体化在欧元区非常 牢固， [implicit = Causation, added DC = 因此] 这使 得欧洲央行成了不二之选。 Ref: Given that financial integration is particularly strong within the monetary union, putting the ECB in charge was an obvious choice. MT: As a monetary union, financial integration in the euro area is very strong, so it makes the ECB has become the best choice. Source: 这些国家需要采取措施助贫民摆脱贫困陷 阱， [Implici"
W17-4812,W07-0734,0,0.0525515,"e7, stating that our preprocessing for the implicit DCs can be identified by the decoder. But, if we compare the translated DCs with those in reference, some of them are different, thus the n-gram based BLEU evaluation will not able to capture the information, which support our guess. Preliminary Experiments & Analysis We conduct MT automatic evaluation experiments on the annotated Chinese sentences with inserted implicit DCs to testify the translation performance before and after representing implicit DCs with explicit ones. Evaluation metrics include BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) scores, calculated by the Asiya toolkit4 (Giménez and Màrquez, 2010). 4.1 Experimental Results and Analysis Experimental Setting With Moses decoder (Koehn et al., 2007), we train a phrase-based SMT model on another different version of News-Commentary corpus 5 provided respectively by OPUS (69,206 sentence pairs) and WMT2017 Shared Task 6 (235,724 pairs), and the model is tuned by MERT (Och, 2003) with the development sets (2002 pairs) provided by WMT2017. GIZA++ (Och and Ney, 2003) is used for automatic word alignment and a 5-gram language model is trained on English Gigaword (Parker et al.,"
W17-4812,P03-1021,0,0.0639931,"d implicit DCs to testify the translation performance before and after representing implicit DCs with explicit ones. Evaluation metrics include BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) scores, calculated by the Asiya toolkit4 (Giménez and Màrquez, 2010). 4.1 Experimental Results and Analysis Experimental Setting With Moses decoder (Koehn et al., 2007), we train a phrase-based SMT model on another different version of News-Commentary corpus 5 provided respectively by OPUS (69,206 sentence pairs) and WMT2017 Shared Task 6 (235,724 pairs), and the model is tuned by MERT (Och, 2003) with the development sets (2002 pairs) provided by WMT2017. GIZA++ (Och and Ney, 2003) is used for automatic word alignment and a 5-gram language model is trained on English Gigaword (Parker et al., 2011). 1500 sentences randomly chosen from the annotated corpus in section3 are used as test sets. Source: 作为货币联盟，金融一体化在欧元区非常 牢固， [implicit = Causation, added DC = 因此] 这使 得欧洲央行成了不二之选。 Ref: Given that financial integration is particularly strong within the monetary union, putting the ECB in charge was an obvious choice. MT: As a monetary union, financial integration in the euro area is very strong,"
W17-4812,C14-1055,0,0.0230306,"d et al., 2008), indicating that there are more implicit DCs in Chinese, correspondingly, discourse relations are usually implicit. 2 Related Work Discourse related issues have become increasingly popular in Natural Language Processing in recent 93 Proceedings of the Third Workshop on Discourse in Machine Translation, pages 93–98, c Copenhagen, Denmark, September 8, 2017. 2017 Association for Computational Linguistics. years, especially the release of some famous discourse treebanks including PDTB, CDTB and RST (Mann and Thompson, 1986) corpus has promoted the research greatly. Some research (Li et al. 2014, Rutherford and Xue, 2014) has done on monolingual annotation and analysis of Chinese DCs. Li et al. (2014a) and Yung et al. (2015a, 2015b) also present some cross-lingual discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Mey"
W17-4812,P02-1040,0,0.0983255,"he examples shown in following table7, stating that our preprocessing for the implicit DCs can be identified by the decoder. But, if we compare the translated DCs with those in reference, some of them are different, thus the n-gram based BLEU evaluation will not able to capture the information, which support our guess. Preliminary Experiments & Analysis We conduct MT automatic evaluation experiments on the annotated Chinese sentences with inserted implicit DCs to testify the translation performance before and after representing implicit DCs with explicit ones. Evaluation metrics include BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007) scores, calculated by the Asiya toolkit4 (Giménez and Màrquez, 2010). 4.1 Experimental Results and Analysis Experimental Setting With Moses decoder (Koehn et al., 2007), we train a phrase-based SMT model on another different version of News-Commentary corpus 5 provided respectively by OPUS (69,206 sentence pairs) and WMT2017 Shared Task 6 (235,724 pairs), and the model is tuned by MERT (Och, 2003) with the development sets (2002 pairs) provided by WMT2017. GIZA++ (Och and Ney, 2003) is used for automatic word alignment and a 5-gram language model is traine"
W17-4812,P13-2066,0,0.0295618,"s of Chinese DCs. Li et al. (2014a) and Yung et al. (2015a, 2015b) also present some cross-lingual discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Meyer and Webber, 2013). As for Chinese discourse relations and translation, Tu et al. (2013) employ a RST-based discourse parsing approaches in SMT, in their following work (Tu et al. 2014), they also present a tree-string model on Chinese complex sentences, integrating discourse relations into MT, gaining some improvement on translation performance. Li et al. (2014b) argues the influence of discourse factors in translation. 3 3.1 As mentioned above, we will analyze the DCs on both cross-sentence and within-sentence levels, we decide to annotate the corpus in a top-down way. That is, we first annotate DCs between crosssentences, and then within the sentences. Note that, if there exis"
W17-4812,P14-1080,0,0.0158396,"discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Meyer and Webber, 2013). As for Chinese discourse relations and translation, Tu et al. (2013) employ a RST-based discourse parsing approaches in SMT, in their following work (Tu et al. 2014), they also present a tree-string model on Chinese complex sentences, integrating discourse relations into MT, gaining some improvement on translation performance. Li et al. (2014b) argues the influence of discourse factors in translation. 3 3.1 As mentioned above, we will analyze the DCs on both cross-sentence and within-sentence levels, we decide to annotate the corpus in a top-down way. That is, we first annotate DCs between crosssentences, and then within the sentences. Note that, if there exist sentences end with only full stop marks and have no commas or other punctuations, these sentenc"
W17-4812,W15-3101,0,0.124263,"it. 2 Related Work Discourse related issues have become increasingly popular in Natural Language Processing in recent 93 Proceedings of the Third Workshop on Discourse in Machine Translation, pages 93–98, c Copenhagen, Denmark, September 8, 2017. 2017 Association for Computational Linguistics. years, especially the release of some famous discourse treebanks including PDTB, CDTB and RST (Mann and Thompson, 1986) corpus has promoted the research greatly. Some research (Li et al. 2014, Rutherford and Xue, 2014) has done on monolingual annotation and analysis of Chinese DCs. Li et al. (2014a) and Yung et al. (2015a, 2015b) also present some cross-lingual discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Meyer and Webber, 2013). As for Chinese discourse relations and translation, Tu et al. (2013) employ a RST-based discourse parsing app"
W17-4812,W15-2519,0,0.120254,"it. 2 Related Work Discourse related issues have become increasingly popular in Natural Language Processing in recent 93 Proceedings of the Third Workshop on Discourse in Machine Translation, pages 93–98, c Copenhagen, Denmark, September 8, 2017. 2017 Association for Computational Linguistics. years, especially the release of some famous discourse treebanks including PDTB, CDTB and RST (Mann and Thompson, 1986) corpus has promoted the research greatly. Some research (Li et al. 2014, Rutherford and Xue, 2014) has done on monolingual annotation and analysis of Chinese DCs. Li et al. (2014a) and Yung et al. (2015a, 2015b) also present some cross-lingual discourse relation analysis. But they just analyze within sentences instead of crosssentences. In the field of MT, some previous works have been mainly focus on DCs in European language pairs (Becher, 2011; Zufferey and Cartoni, 2014) such as English, French and German, including but not limited to disambiguating DCs in translation (Meyer et al., 2011; Meyer and PopescuBelis, 2012), labeled and implicit DCs translation (Meyer and Webber, 2013). As for Chinese discourse relations and translation, Tu et al. (2013) employ a RST-based discourse parsing app"
