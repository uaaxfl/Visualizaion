2021.rocling-1.35,What confuses {BERT}? Linguistic Evaluation of Sentiment Analysis on Telecom Customer Opinion,2021,-1,-1,9,0,2394,cingfang shih,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"Ever-expanding evaluative texts on online forums have become an important source of sentiment analysis. This paper proposes an aspect-based annotated dataset consisting of telecom reviews on social media. We introduce a category, implicit evaluative texts, impevals for short, to investigate how the deep learning model works on these implicit reviews. We first compare two models, BertSimple and BertImpvl, and find that while both models are competent to learn simple evaluative texts, they are confused when classifying impevals. To investigate the factors underlying the correctness of the model{'}s predictions, we conduct a series of analyses, including qualitative error analysis and quantitative analysis of linguistic features with logistic regressions. The results show that local features that affect the overall sentential sentiment confuse the model: multiple target entities, transitional words, sarcasm, and rhetorical questions. Crucially, these linguistic features are independent of the model{'}s confidence measured by the classifier{'}s softmax probabilities. Interestingly, the sentence complexity indicated by syntax-tree depth is not correlated with the model{'}s correctness. In sum, this paper sheds light on the characteristics of the modern deep learning model and when it might need more supervision through linguistic evaluations."
2021.rocling-1.40,Keyword-centered Collocating Topic Analysis,2021,-1,-1,5,0,2417,yulin chang,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),0,"The rapid flow of information and the abundance of text data on the Internet have brought about the urgent demand for the construction of monitoring resources and techniques used for various purposes. To extract facets of information useful for particular domains from such large and dynamically growing corpora requires an unsupervised yet transparent ways of analyzing the textual data. This paper proposed a hybrid collocation analysis as a potential method to retrieve and summarize Taiwan-related topics posted on Weibo and PTT. By grouping collocates of èºç£ {`}Taiwan{'} into clusters of topics via either word embeddings clustering or Latent Dirichlet allocation, lists of collocates can be converted to probability distributions such that distances and similarities can be defined and computed. With this method, we conduct a diachronic analysis of the similarity between Weibo and PTT, providing a way to pinpoint when and how the topic similarity between the two rises or falls. A fine-grained view on the grammatical behavior and political implications is attempted, too. This study thus sheds light on alternative explainable routes for future social media listening method on the understanding of cross-strait relationship."
2020.rocling-1.4,Mitigating Impacts of Word Segmentation Errors on Collocation Extraction in {C}hinese,2020,-1,-1,2,0,2418,yongfu liao,Proceedings of the 32nd Conference on Computational Linguistics and Speech Processing (ROCLING 2020),0,None
2020.rocling-1.18,Lectal Variation of the Two {C}hinese Causative Auxiliaries,2020,-1,-1,3,0,2394,cingfang shih,Proceedings of the 32nd Conference on Computational Linguistics and Speech Processing (ROCLING 2020),0,None
2020.rocling-1.20,An Analysis of Multimodal Document Intent in {I}nstagram Posts,2020,-1,-1,2,0,15601,yingyu chen,Proceedings of the 32nd Conference on Computational Linguistics and Speech Processing (ROCLING 2020),0,None
2020.paclic-1.13,From Sense to Action: A Word-Action Disambiguation Task in {NLP},2020,-1,-1,1,1,2402,shukai hsieh,"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation",0,None
2020.paclic-1.47,Exploring Discourse on Same-sex Marriage in {T}aiwan: A Case Study of Near-Synonym of {HOMOSEXUAL} in Opposing Stances,2020,-1,-1,2,0,15891,hantang hung,"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation",0,None
2020.lrec-1.33,Do You Believe It Happened? Assessing {C}hinese Readers{'} Veridicality Judgments,2020,-1,-1,2,1,2386,yuyun chang,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This work collects and studies Chinese readers{'} veridicality judgments to news events (whether an event is viewed as happening or not). For instance, in {``}The FBI alleged in court documents that Zazi had admitted having a handwritten recipe for explosives on his computer{''}, do people believe that Zazi had a handwritten recipe for explosives? The goal is to observe the pragmatic behaviors of linguistic features under context which affects readers in making veridicality judgments. Exploring from the datasets, it is found that features such as event-selecting predicates (ESP), modality markers, adverbs, temporal information, and statistics have an impact on readers{'} veridicality judgments. We further investigated that modality markers with high certainty do not necessarily trigger readers to have high confidence in believing an event happened. Additionally, the source of information introduced by an ESP presents low effects to veridicality judgments, even when an event is attributed to an authority (e.g. {``}The FBI{''}). A corpus annotated with Chinese readers{'} veridicality judgments is released as the Chinese PragBank for further analysis."
2020.coling-main.258,Computational Modeling of Affixoid Behavior in {C}hinese Morphology,2020,-1,-1,2,1,2395,yuhsiang tseng,Proceedings of the 28th International Conference on Computational Linguistics,0,"The morphological status of affixes in Chinese has long been a matter of debate. How one might apply the conventional criteria of free/bound and content/function features to distinguish word-forming affixes from bound roots in Chinese is still far from clear. Issues involving polysemy and diachronic dynamics further blur the boundaries. In this paper, we propose three quantitative features in a computational model of affixoid behavior in Mandarin Chinese. The results show that, except for in a very few cases, there are no clear criteria that can be used to identify an affix{'}s status in an isolating language like Chinese. A diachronic check using contextualized embeddings with the WordNet Sense Inventory also demonstrates the possible role of the polysemy of lexical roots across diachronic settings."
D19-6404,{E}igencharacter: An Embedding of {C}hinese Character Orthography,2019,0,0,2,1,2395,yuhsiang tseng,Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN),0,"Chinese characters are unique in its logographic nature, which inherently encodes world knowledge through thousands of years evolution. This paper proposes an embedding approach, namely eigencharacter (EC) space, which helps NLP application easily access the knowledge encoded in Chinese orthography. These EC representations are automatically extracted, encode both structural and radical information, and easily integrate with other computational models. We built EC representations of 5,000 Chinese characters, investigated orthography knowledge encoded in ECs, and demonstrated how these ECs identified visually similar characters with both structural and radical information."
2019.rocling-1.19,Extracting Semantic Representations of Sexual Biases from Word Vectors,2019,-1,-1,2,0,15601,yingyu chen,Proceedings of the 31st Conference on Computational Linguistics and Speech Processing (ROCLING 2019),0,None
2019.gwc-1.19,Augmenting {C}hinese {W}ord{N}et semantic relations with contextualized embeddings,2019,-1,-1,2,1,2395,yuhsiang tseng,Proceedings of the 10th Global Wordnet Conference,0,"Constructing semantic relations in WordNet has been a labour-intensive task, especially in a dynamic and fast-changing language environment. Combined with recent advancements of contextualized embeddings, this paper proposes the concept of morphology-guided sense vectors, which can be used to semi-automatically augment semantic relations in Chinese Wordnet (CWN). This paper (1) built sense vectors with pre-trained contextualized embedding models; (2) demonstrated the sense vectors computed were consistent with the sense distinctions made in CWN; and (3) predicted the potential semantically-related sense pairs with high accuracy by sense vectors model."
L18-1207,Fluid Annotation: A Granularity-aware Annotation Tool for {C}hinese Word Fluidity,2018,0,0,1,1,2402,shukai hsieh,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
2018.gwc-1.48,Sinitic {W}ordnet: Laying the Groundwork with {C}hinese Varieties Written in Traditional Characters,2018,-1,-1,2,1,29725,chihyao lee,Proceedings of the 9th Global Wordnet Conference,0,"The present work seeks to make the logographic nature of Chinese script a relevant research ground in wordnet studies. While wordnets are not so much about words as about the concepts represented in words, synset formation inevitably involves the use of orthographic and/or phonetic representations to serve as headword for a given concept. For wordnets of Chinese languages, if their synsets are mapped with each other, the connection from logographic forms to lexicalized concepts can be explored backwards to, for instance, help trace the development of cognates in different varieties of Chinese. The Sinitic Wordnet project is an attempt to construct such an integrated wordnet that aggregates three Chinese varieties that are widely spoken in Taiwan and all written in traditional Chinese characters."
O17-1007,Exploring Lavender Tongue from Social Media Texts[In {C}hinese],2017,-1,-1,2,0,32699,hsiaohan wu,Proceedings of the 29th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2017),0,None
I17-3011,{C}lassifier{G}uesser: A Context-based Classifier Prediction System for {C}hinese Language Learners,2017,0,0,3,0,6925,nicole peinelt,"Proceedings of the {IJCNLP} 2017, System Demonstrations",0,"Classifiers are function words that are used to express quantities in Chinese and are especially difficult for language learners. In contrast to previous studies, we argue that the choice of classifiers is highly contextual and train context-aware machine learning models based on a novel publicly available dataset, outperforming previous baselines. We further present use cases for our database and models in an interactive demo system."
W16-6617,Evaluative Pattern Extraction for Automated Text Generation,2016,3,0,2,0,33324,chiachen lee,Proceedings of the 9th International Natural Language Generation conference,0,None
W16-5315,{C}og{AL}ex-{V} Shared Task: {LOPE},2016,0,0,3,0,33497,kanan luce,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"Automatic discovery of semantically-related words is one of the most important NLP tasks, and has great impact on the theoretical psycholinguistic modeling of the mental lexicon. In this shared task, we employ the word embeddings model to testify two thoughts explicitly or implicitly assumed by the NLP community: (1). Word embedding models can reflect syntagmatic similarities in usage between words to distances in projected vector space. (2). Word embedding models can reflect paradigmatic relationships between words."
O16-1009,Crowdsourcing Experiment Designs for {C}hinese Word Sense Annotation,2016,10,0,6,0,34576,tzuyun huang,Proceedings of the 28th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2016),0,None
O16-1027,Sarcasm Detection in {C}hinese Using a Crowdsourced Corpus,2016,4,0,2,0,34599,shihkai lin,Proceedings of the 28th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2016),0,None
Y15-2004,An Arguing Lexicon for Stance Classification on Short Text Comments in {C}hinese,2015,-1,-1,2,0,36259,juhan chuang,"Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation: Posters",0,None
W15-4209,Linguistic Linked Data in {C}hinese: The Case of {C}hinese {W}ordnet,2015,17,2,2,1,29725,chihyao lee,Proceedings of the 4th Workshop on Linked Data in Linguistics: Resources and Applications,0,"The present study describes recent developments of Chinese Wordnet, which has been reformatted using the lemon model and published as part of the Linguistic Linked Open Data Cloud. While lemon suffices for modeling most of the structures in Chinese Wordnet at the lexical level, the model does not allow for finergrained distinction of a word sense, or meaning facets, a linguistic feature also attended to in Chinese Wordnet. As for the representation of synsets, we use the WordNet RDF ontology for integrationxe2x80x99s sake. Also, we use another ontology proposed by the Global WordNet Association to show how Chinese Wordnet as Linked Data can be integrated into the Global WordNet Grid."
W14-0139,Leveraging Morpho-semantics for the Discovery of Relations in {C}hinese {W}ordnet,2014,13,0,1,1,2402,shukai hsieh,Proceedings of the Seventh Global {W}ordnet Conference,0,"Semantic relations of different types have played an important role in wordnet, and have been widely recognized in various fields. In recent years, with the growing interests of constructing semantic network in support of intelligent systems, automatic semantic relation discovery has become an urgent task. This paper aims to extract semantic relations relying on the in situ morpho-semantic structure in Chinese which can dispense of an outside source such as corpus or web data. Manual evaluation of thousands of word pairs shows that most relations can be successful predicted. We believe that it can serve as a valuable starting point in complementing with other approaches, which will hold promise for the robust lexical relations acquisition."
O14-5002,Public Opinion Toward {CSSTA}: A Text Mining Approach,2014,-1,-1,2,0,39215,yian wu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 19, Number 4, {D}ecember 2014 - Special Issue on Selected Papers from {ROCLING} {XXVI}",0,None
O14-1010,Public Opinion Toward {CSSTA}: A Text Mining Approach,2014,-1,-1,2,0,39215,yian wu,Proceedings of the 26th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2014),0,None
O14-1014,Sketching the Dependency Relations of Words in {C}hinese,2014,15,0,2,0,15618,menghsien shih,Proceedings of the 26th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2014),0,"We proposes a language resource by automatically sketching grammatical relations of words based on dependency parses from untagged texts. The advantage of word sketch based on parsed corpora is, compared to Sketch Engine (Kilgarriff, Rychly, Smrz, & Tugwell, 2004), to provide more details about the different usage of each word such as various types of modification, which is also important in language pedagogy. Although some language resources of other languages have attempted to sketch words based on parsed data, in Chinese we have not seen a resource for dependency sketch of words in customized texts. Therefore, we propose such a resource and evaluate with Chinese Sketch Engine (Huang et al., 2005) in terms of corresponding thesaurus function."
hsieh-2014-chinese,Why {C}hinese Web-as-Corpus is Wacky? Or: How Big Data is Killing {C}hinese Corpus Linguistics,2014,5,0,1,1,2402,shukai hsieh,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,This paper aims to examine and evaluate the current development of using Web-as-Corpus (WaC) paradigm in Chinese corpus linguistics. I will argue that the unstable notion of wordhood in Chinese and the resulting diverse ideas of implementing word segmentation systems have posed great challenges for those who are keen on building web-scaled corpus data. Two lexical measures are proposed to illustrate the issues and methodological discussions are provided.
W13-5403,To Coerce or Not to Coerce: A Corpus-based Exploration of Some Complement Coercion Verbs in {C}hinese,2013,-1,-1,2,0,38373,chanchia hsu,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
W13-5415,Features of Verb Complements in Co-composition: A case study of {C}hinese baking verb using {W}eibo corpus,2013,7,0,2,1,2386,yuyun chang,Proceedings of the 6th International Conference on Generative Approaches to the Lexicon ({GL}2013),0,None
O13-3004,Back to the Basic: Exploring Base Concepts from the {W}ordnet Glosses,2013,30,1,2,0,38373,chanchia hsu,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 18, Number 2, June 2013-Special Issue on {C}hinese Lexical Resources: Theories and Applications",0,"There has been no consensus as to what constitutes a set of base concepts in the mental landscape. With the aim of exploring base concepts in Chinese, this paper proposes that frequently-occurring words in the glosses of a lexical resource such as the Chinese Wordnet can be seen as a candidate set of base concepts because the glosses use basic words. The present study identified 130 base concepts in Chinese. The Base Concepts in EuroWordNet were adopted as a reference for comparison. While only 44.6% of the base concepts identified in the present study have an equivalent in the set of Base Concepts of EuroWordNet, the other base concepts extracted by our gloss-based approach also reflect a certain degree of basicness. It is hoped that both the overlap and the difference between different sets of base concepts identified in different languages and by different approaches can deepen our understanding of the basic core in the mind. Additionally, it is also hoped that the set of base concepts identified in the present study can have computational as well as pedagogical applications in the future."
O13-1024,Causing Emotion in Collocation:An Exploratory Data Analysis,2013,24,0,3,0,41568,peiyu lu,Proceedings of the 25th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2013),0,"This paper aims to seek approaches in investigating the relationships within emotion words under linguistic aspect, rather than figuring out new algorithms or so in processing emotion detection. It is noted that emotion words could be categorized into two groups: emotion-inducing words and emotion-describing words, and emotion-inducing words would be able to trigger emotions expressed via emotion-describing words. Hence, this paper takes the social network Plurk, the emotion words are from the study on Standard Stimuli and Normative Responses of Emotions (SSNRE) in Taiwan and the National Taiwan University Sentiment Dictionary (NTUSD) as corpus, combining with Principle Component Analysis (PCA) and followed collocation approach, in order to make a preliminary exploration in observing the interactions between emotion-inducing and emotion-describing words. From the results, it is found that though the retrieved Plurk posts containing emotion-inducing words, polarities of the induced emotion-describing words contained within the posts are not consistent. In addition, the polarities of posts would not only be influenced by emotion words, but negation words, modal words and certain content words within context."
O13-1025,Observing Features of {PTT} Neologisms: A Corpus-driven Study with N-gram Model,2013,5,3,2,0,41569,tsunjui liu,Proceedings of the 25th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2013),0,"PTT (xe6x89xb9xe8xb8xa2xe8xb8xa2) is one of the largest web forums in Taiwan. In the last few years, its importance has been growing rapidly because it has been widely mentioned by most of the mainstream media. It is observed that its influence reflects not only on the society but also on the language novel use in Taiwan. In this research, a pipeline processing system in Python was developed to collect the data from PTT, and the n-gram model with proposed linguistic filter are adopted with the attempt to capture two-character neologisms emerged in PTT. Evaluation task with 25 subjects was conducted against the system's performance with the calculation of Fleissxe2x80x99 kappa measure. Linguistic discussion as well as the comparison with time series analysis of frequency data are provided. It is hoped that the detection of neologisms in PTT can be improved by observing the features, which may even facilitate the prediction of the neologisms in the future."
Y12-1053,{C}hinese Sentiments on the Clouds: A Preliminary Experiment on Corpus Processing and Exploration on Cloud Service,2012,16,0,1,1,2402,shukai hsieh,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"This study aims to propose a novel pipeline architecture in building and analyzing largescaled linguistic data on the cloud-based environment, an experimental survey on Chinese Polarity Lexicon will be taken as an example. In this experiment, data are evaluated and tagged by applying crowd sourcing approach using online Google Form. All the data processing and analyzing procedures are completed on-the-fly with free cloud services automatically and dynamically.The paper shows the advantages of using cloud-based environment in collecting and processing linguistic data which can be easily scaled up and efficiently computed. In addition, the proposed pipeline architecture also brings out the potentials of merging with mashups from the web for representing and exploring corpus data of various types."
O12-3003,"Frequency, Collocation, and Statistical Modeling of Lexical Items: A Case Study of Temporal Expressions in Two Conversational Corpora",2012,-1,-1,5,1,14417,shengfu wang,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 17, Number 2, June 2012-Specia Issue on Selected Papers from {ROCLING} {XXIII}",0,None
O12-1007,Measuring Individual Differences in Word Recognition: The Role of Individual Lexical Behaviors,2012,17,0,2,0,42753,hsinni lin,Proceedings of the 24th Conference on Computational Linguistics and Speech Processing ({ROCLING} 2012),0,"This study adopts a corpus-based computational linguistic approach to measure individual differences (IDs) in visual word recognition. Word recognition has been a cardinal issue in the field of psycholinguistics. Previous studies examined the IDs by resorting to test-based or questionnaire-based measures. Those measures, however, confined the research within the scope where they can evaluate. To extend the research to approximate to IDs in real life, the present study undertakes the issue from the observations of experiment participantsxe2x80x99 daily-life lexical behaviors. Based on participantsxe2x80x99 Facebook posts, two types of personal lexical behaviors are computed, including the frequency index of personal word usage and personal word frequency. It is investigated that to what extent each of them accounts for participantsxe2x80x99 variances in Chinese word recognition. The data analyses are carried out by mixed-effects models, which can precisely estimate by-subject differences. Results showed that the effects of personal word frequency reached significance; participants responded themselves more rapidly when encountering more frequently used words. People with lower frequency indices of personal word usage had a lower accuracy rates than others, which was contrary to our prediction. Comparison and discussion of the results also reveal methodology issues that can provide noteworthy suggestions for future research on measuring personal lexical behaviors. Proceedings of the Twenty-Fourth Conference on Computational Linguistics and Speech Processing (ROCLING 2012)"
O11-1012,"Frequency, Collocation, and Statistical Modeling of Lexical Items: A Case Study of Temporal Expressions in an Elderly Speaker Corpus",2011,16,0,5,1,14417,shengfu wang,Proceedings of the 23rd Conference on Computational Linguistics and Speech Processing ({ROCLING} 2011),0,"This study examines how different dimensions of corpus frequency data may affect the outcome of statistical modeling of lexical items. The corpus used in our analysis is an elderly speaker corpus in its early development, and the target words are temporal expressions, which might reveal how the speech produced by the elderly is organized. We conduct divisive hierarchical clustering based on two different dimensions of corpus data, namely raw frequency distribution and collocation-based vectors. Results show when different dimensions of data were used as the input, the target terms were indeed clustered in different ways. Analyses based on frequency distributions and collocational patterns are distinct from each other. Specifically, statistically-based collocational analysis produces more distinct clustering results that differentiate temporal terms more delicately than do the ones based on raw frequency."
Y10-1093,Towards an Automatic Measurement of Verbal Lexicon Acquisition: The Case for a Young Children-versus-Adults Classification in {F}rench and {M}andarin,2010,15,2,2,0,38144,yann desalle,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,In this paper we define a lexical metrology in graphs of verbal synonymy to com- pute the flexsemic score of speakers from their verbal productions in action denomination tasks. This flexsemic score is used to automatically categorize young children versus young adults. We show that this score is effective in French and in Mandarin.
Y10-1094,Graph Representation of Synonymy and Translation Resources for Crosslinguistic Modelisation of Meaning,2010,23,2,4,0,38145,benoit gaillard,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,"In this paper we describe the data that will be used to compare the semantic struc- tures that emerge from synonymy in French and in Mandarin. We aim at studying these semantic structures at both a global, lexicographic level, using lexicons, synonymy and trans- lation dictionaries and at a more localised, experimental level, using data collected in parallel psycholinguistic experiments in French and Mandarin. After presenting our research project, the data we need to carry it out and the available resources, we analyse several linguistic issues arising from the structural differences between the French and Mandarin lexicons. We then explain the construction of the synonymy and translation networks from the available resources and detail specific choices that will enable us to produce meaningful experimental results based on this prepared data. Two kinds of networks are built: lexicographic networks and smaller movie-based networks extracted from experimental recordings. We conclude by describing how we intend to use this data."
S10-1013,{S}em{E}val-2010 Task 17: All-Words Word Sense Disambiguation on a Specific Domain,2010,17,46,4,0,8824,eneko agirre,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Domain portability and adaptation of NLP components and Word Sense Disambiguation systems present new challenges. The difficulties found by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledge-based WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. This task presented all-words datasets on the environment domain for WSD in four languages (Chinese, Dutch, English, Italian). 11 teams participated, with supervised and knowledge-based systems, mainly in the English dataset. The results show that in all languages the participants where able to beat the most frequent sense heuristic as estimated from general corpora. The most successful approaches used some sort of supervision in the form of hand-tagged examples from the domain."
S10-1093,{K}yoto: An Integrated System for Specific Domain {WSD},2010,10,2,8,0,13429,aitor soroa,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"This document describes the preliminary release of the integrated Kyoto system for specific domain WSD. The system uses concept miners (Tybots) to extract domain-related terms and produces a domain-related thesaurus, followed by knowledge-based WSD based on wordnet graphs (UKB). The resulting system can be applied to any language with a lexical knowledge base, and is based on publicly available software and resources. Our participation in Semeval task #17 focused on producing running systems for all languages in the task, and we attained good results in all except Chinese. Due to the pressure of the time-constraints in the competition, the system is still under development, and we expect results to improve in the near future."
O10-2010,Qualia Modification in Noun-Noun Compounds: A Cross-Language Survey,2010,5,6,4,1,29725,chihyao lee,{ROCLING} 2010 Poster Papers,0,"In analyzing the formation of a given compound, both its internal syntactic structure and semantic relations need to be considered. The Generative Lexicon Theory (GL Theory) provides us with an explanatory model of compounds that captures the qualia modification relations in the semantic composition within a compound, which can be applied to natural language processing tasks. In this paper, we primarily discuss the qualia structure of noun-noun compounds found in Chinese as well as a couple of other languages like German, Spanish, Japanese and Italian. We briefly review the construction of compounds and focus on the noun-noun construction. While analyzing the semantic relationship between the words that compose a compound, we use the GL Theory to demonstrate that the proposed qualia structure enables compositional interpretation within the compound. Besides, we attempt to examine whether or not for each semantic head, its modifier can fit in one of the four quales. Finally, our analysis reveals the potentials and limits of qualia-based treatment of composition of nominal compounds and suggests a path for future work."
O10-1012,Classifying mood in plurks,2010,4,6,6,0,45757,meiyu chen,Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing ({ROCLING} 2010),0,"In this paper, we present a simple but efficient approach for the automatic mood classification of microblogging messages from Plurk platform. In contrast with Twitter, Plurk has become the most popular microblogging service in Taiwan and other countries 1 ; however, no previous research has been done for the emotion and mood recognition, nor the Chinese affective terms or corpus available. Following the line of mashup programming, we thus construct a dynamic plurk corpus by pipelining Plurk APIs, Yahoo! Chinese segmentation APIs, etc to preprocess and annotate the corpus data. Based on the corpus, we conduct experiments by way of combining textual statistics and emoticons data, and our method yield the results with high performance. This work can be further extended to combine with affective ontology designed with emotion theory of appraisal. Keyword: mood classification, plurks, keyness, emotion paradox 1 According to Alvin, the cofounder of Plurk website, the number of the plurkers in Taiwan had reached approximately 1 million, which was one-third of the total plurkers in October, 2009. Another statistic data is collected from Google trend for website, manifesting that Taiwan is the rank one region of visiting Plurk website (August,2010)."
C10-3002,{P}y{CWN}: a Python Module for {C}hinese {W}ordnet,2010,4,3,2,0,46422,yuehcheng wu,Coling 2010: Demonstrations,0,"This presentation introduces a Python module (PyCWN) for accessing and processing Chinese lexical resources. In particular, our focus is put on the Chinese Wordnet (CWN) that has been developed and released by CWN group at Academia Sinica. PyCWN provides the access to Chinese Wordnet (sense and relation data) under the Python environment. The presenation further demonstrates how this module applies to a variety of lexical processing tasks as well as the potentials for multilingual lexical processing."
C10-2108,Word Space Modeling for Measuring Semantic Specificity in {C}hinese,2010,15,1,2,0,45060,chingfen pan,Coling 2010: Posters,0,"The aim of this study is to use the word-space model to measure the semantic loads of single verbs, profile verbal lexicon acquisition, and explore the semantic information on Chinese resultative verb compounds (RVCs). A distributional model based on Academia Sinica Balanced Corpus (ASBC) with Latent Semantic Analysis (LSA) is built to investigate the semantic space variation depending on the semantic loads/specificity. The between group comparison of age-related changes in verb style is then conducted to suggest the influence of semantic space on verbal acquisition. Finally, it demonstrates how meaning exploring on RVCs is done with semantic space."
Y09-2029,Bridging the Gap between Graph Modeling and Developmental Psycholinguistics: An Experiment on Measuring Lexical Proximity in {C}hinese Semantic Space,2009,6,2,1,1,2402,shukai hsieh,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 2",0,"Modeling of semantic space is a new and challenging research topic both in cog- nitive science and linguistics. Existing approaches can be classified into two different types according to how the calculation are done: either a word-by-word co-occurrence matrix or a word-by-context matrix (Riordan 2007). In this paper, we argue that the existing popular distributional semantic model (vector space model), does not adequately explain the age-of- acquisition data in Chinese. An alternatively measure of semantic proximity called PROX (Gaume et al, 2006) is applied instead. The application or PROX has interesting psycholin- guistic implications. Unlike previous semantic space models, PROX can be trained with children's data as well as adult data. This allows us to test the hypothesis that children's se- mantic space approximates the target of acquisition: adult's semantic space. It also allows us to compare our Chinese experiment results with French results to see to attest the universality of the approximation model."
W09-3418,{CWN}-{LMF}: {C}hinese {W}ord{N}et in the {L}exical {M}arkup {F}ramework,2009,17,8,2,0,1205,lunghao lee,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"Lexical Markup Framework (LMF, ISO-24613) is the ISO standard which provides a common standardized framework for the construction of natural language processing lexicons. LMF facilitates data exchange among computational linguistic resources, and also promises a convenient uniformity for future application. This study describes the design and implementation of the WordNet-LMF used to represent lexical semantics in Chinese WordNet. The compiled CWN-LMF will be released to the community for linguistic researches."
W09-3421,Query Expansion using {LMF}-Compliant Lexical Resources,2009,8,4,10,0,301,takenobu tokunaga,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper reports prototype multilingual query expansion system relying on LMF compliant lexical resources. The system is one of the deliverables of a three-year project aiming at establishing an international standard for language resources which is applicable to Asian languages. Our important contributions to ISO 24613, standard Lexical Markup Framework (LMF) include its robustness to deal with Asian languages, and its applicability to cross-lingual query tasks, as illustrated by the prototype introduced in this paper."
W09-3303,{W}iktionary for Natural Language Processing: Methodology and Limitations,2009,0,2,5,0,38143,emmanuel navarro,Proceedings of the 2009 Workshop on The People{'}s Web Meets {NLP}: Collaboratively Constructed Semantic Resources (People{'}s Web),0,None
O09-3003,Assessing Text Readability Using Hierarchical Lexical Relations Retrieved from {W}ord{N}et,2009,31,9,5,1,40039,shuyen lin,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 14, Number 1, March 2009",0,"Although some traditional readability formulas have shown high predictive validity in the r=0.8 range and above (Chall & Dale, 1995), they are generally not based on genuine linguistic processing factors, but on statistical correlations (Crossley et al., 2008). Improvement of readability assessment should focus on finding variables that truly represent the comprehensibility of text as well as the indices that accurately measure the correlations. In this study, we explore the hierarchical relations between lexical items based on the conceptual categories advanced from Prototype Theory (Rosch et al., 1976). According to this theory and its development, basic level words like guitar represent the objects humans interact with most readily. They are acquired by children earlier than their superordinate words like stringed instrument and their subordinate words like acoustic guitar. Accordingly, the readability of a text is presumably associated with the ratio of basic level words it contains. WordNet (Fellbaum, 1998), a network of meaningfully related words, provides the best online open source database for studying such lexical relations. Our study shows that a basic level noun can be identified by its ratio of forming compounds (e.g. chairxe2x86x92armchair) and the length difference in relation to its hyponyms. We compared graded readings for American children and high school English readings for Taiwanese students by several readability formulas and in terms of basic level noun ratios (i.e. the number of basic level noun types divided by the number of noun types in a text). It is suggested that basic level noun ratios provide a robust and meaningful index of lexical complexity, which is directly associated with text readability."
O08-2004,Automatic labeling of troponymy for {C}hinese verbs,2008,6,1,4,0,47953,chiaoshan lo,{ROCLING} 2008 Poster Papers,0,"xe4xbbxa5xe5x90x8cxe7xbexa9xe8xa9x9exe9x9bx86xe8x88x87xe8xa9x9exe5xbdx99xe8xaax9exe6x84x8fxe9x97x9cxe4xbfx82xe6x9exb6xe6xa7x8bxe8x80x8cxe6x88x90xe7x9ax84xe8xa9x9exe5xbdx99xe7x9fxa5xe8xadx98xe5xbaxab,xe5xa6x82xe8x8bxb1xe8xaax9exe8xa9x9exe7xb6xb2 (Wordnet)xe3x80x81xe6xadx90xe8xaax9exe8xa9x9e xe7xb6xb2 (EuroWordnet)xe7xadx89,xe5xb7xb2xe6x9cx89xe5x85x85xe5x88x86xe7x9ax84xe7xa0x94xe7xa9xb6,xe8xa9x9exe7xb6xb2xe7x9ax84xe5xbbxbaxe6xa7x8bxe4xb9x9fxe5xb7xb2xe7x9bxb8xe7x95xb6xe5xaex8cxe5x96x84xe3x80x82xe5x9fxbaxe6x96xbcxe7x9bxb8xe5x90x8cxe7x9ax84xe7x9bxaexe7x9ax84,xe4xb8xad xe7xa0x94xe9x99xa2xe8xaax9exe8xa8x80xe6x89x80xe4xbaxa6xe5xb7xb2xe5xbbxbaxe7xabx8bxe5xa4xa7xe8xa6x8fxe6xa8xa1xe4xb9x8bxe4xb8xadxe6x96x87xe8xa9x9exe5xbdx99xe7xb6xb2xe8xb7xaf (Chinese Wordnet,CWN),xe6x97xa8xe5x9cxa8xe6x8fx90xe4xbex9bxe5xaex8cxe6x95xb4xe7x9ax84 xe4xb8xadxe6x96x87xe8xbexadxe5xbdx99xe4xb9x8bxe8xa9x9exe7xbexa9xe5x8dx80xe5x88x86xe3x80x82xe7x84xb6xe8x80x8c,xe5x9cxa8xe7x9bxaexe5x89x8dxe4xb9x8bxe4xb8xadxe6x96x87xe8xa9x9exe5xbdx99xe7xb6xb2xe8xb7xafxe7xb3xbbxe7xb5xb1xe4xb8xad,xe7x94xb1xe6x96xbcxe7x9bxaexe5x89x8dxe4xb8xbbxe8xa6x81xe6x98xafxe6x8exa1xe7x94xa8xe4xbaxbaxe7x82xbaxe5x88xa4 xe5xaex9axe4xbex86xe6xa8x99xe8xa8x98xe5x90x8cxe7xbexa9xe8xa9x9exe9x9bx86xe4xb9x8bxe9x96x93xe7x9ax84xe8xaax9exe6x84x8fxe9x97x9cxe4xbfx82,xe5x9bxa0xe6xadxa4xe9x80x99xe4xbax9bxe6xa8x99xe8xa8x98xe4xb9x8bxe6x95xb8xe9x87x8fxe5xb0x9axe6x9cxaaxe9x81x94xe6x88x90xe5x8fxafxe8xa1x8cxe6x87x89xe7x94xa8xe4xb9x8bxe4xb8x80xe5xaex9axe8xa6x8fxe6xa8xa1xe3x80x82 xe5x9bxa0xe6xadxa4,xe6x9cxacxe7xafx87xe6x96x87xe7xabxa0xe7x89xb9xe5x88xa5xe9x87x9dxe5xb0x8dxe5x8bx95xe8xa9x9exe4xb9x8bxe9x96x93xe7x9ax84xe4xb8x8axe4xb8x8bxe4xbdx8dxe8xa9x9exe5xbdx99xe8xaax9exe6x84x8fxe9x97x9cxe4xbfx82 (Troponymy),xe6x8fx90xe5x87xbaxe4xb8x80xe7xa8xaexe8x87xaaxe5x8bx95xe6xa8x99 xe8xa8x98xe7x9ax84xe6x96xb9xe6xb3x95xe3x80x82xe6x88x91xe5x80x91xe5xb8x8cxe6x9cx9bxe8x97x89xe7x94xb1xe5x8fxa5xe6xb3x95xe4xb8x8axe7x89xb9xe5xaex9axe7x9ax84xe5x8fxa5xe5x9ex8b (lexical syntactic pattern),xe5xbbxbaxe7xabx8bxe4xb8x80xe5x80x8bxe8x83xbdxe5xa4xa0xe8x87xaa xe5x8bx95xe6x8axbdxe5x8fx96xe5x87xbaxe5x8bx95xe8xa9x9exe4xb8x8axe4xb8x8bxe4xbdx8dxe7x9ax84xe7xb3xbbxe7xb5xb1xe3x80x82xe9x80x8fxe9x81x8exe8xa9x9exe7xbexa9xe6x84x8fxe5x88xa4xe5xaex9axe5x8ex9fxe5x89x87xe7x9ax84xe8xa9x95xe4xbcxb0,xe7xb5x90xe6x9ex9cxe9xa1xafxe7xa4xba,xe6xadxa4xe7xb3xbbxe7xb5xb1xe8x87xaaxe5x8bx95xe6x8axbdxe5x8fx96xe5x87xba xe7x9ax84xe5x8bx95xe8xa9x9exe4xb8x8axe4xbdx8dxe8xa9x9e,xe6xadxa3xe7xa2xbaxe7x8ex87xe5xb0x87xe8xbfx91xe7x99xbexe5x88x86xe4xb9x8bxe4xb8x83xe5x8dx81xe3x80x82xe6x9cxacxe7xa0x94xe7xa9xb6xe7x9bxbcxe8x83xbdxe5xb0x87xe6x9cxacxe6x96xb9xe6xb3x95xe6x87x89xe7x94xa8xe6x96xbcxe6xadxa3xe5x9cxa8xe7x99xbcxe5xb1x95xe4xb8xadxe7x9ax84xe4xb8xadxe6x96x87xe8xa9x9e xe7xb6xb2xe8x87xaaxe5x8bx95xe8xaax9exe6x84x8fxe9x97x9cxe4xbfx82xe6xa8x99xe8xa8x98,xe4xbbxa5xe5x8fx8axe7x9fxa5xe8xadx98xe6x9cxacxe9xabx94xe4xb9x8bxe8x87xaaxe5x8bx95xe5xbbxbaxe6xa7x8b,xe9x80xb2xe8x80x8cxe8x83xbdxe6x9cx89xe6x95x88xe7x8ex87xe7x9ax84xe5xbbxbaxe6xa7x8bxe5xaex8cxe5x96x84xe7x9ax84xe4xb8xadxe6x96x87xe8xa9x9exe5xbdx99xe7x9fxa5"
O08-1001,Measuring Text Readability by Lexical Relations Retrieved from {W}ordnet,2008,101,0,5,1,40039,shuyen lin,Proceedings of the 20th Conference on Computational Linguistics and Speech Processing,0,"Current readability formulae have often been criticized for being unstable or not valid. They are mostly computed in regression analysis based on intuitively-chosen variables and graded readings. This study explores the relation between text readability and the conceptual categories proposed in Prototype Theory. These categories form a hierarchy: Basic level words like guitar represent the objects humans interact with most readily. They are acquired by children earlier than their superordinate words (or hypernyms) like stringed instrument and their subordinate words (or hyponyms) like acoustic guitar. Therefore, the readability of a text is presumably associated with the ratio of basic level words it contains. WordNet, a network of meaningfully related words, provides the best online open source database for studying such lexical relations. Our preliminary studies show that a basic level word can be identified by its frequency to form compounds (e.g. chair armchair) and the length difference from its hyponyms in average. We compared selected high school English textbook readings in terms of their basic level word ratios and their values calculated in several readability formulae. Basic level word ratios turned out to be the only one positively correlated with the text levels."
O08-1009,A Realistic and Robust Model for {C}hinese Word Segmentation,2008,13,2,4,0,1504,churen huang,Proceedings of the 20th Conference on Computational Linguistics and Speech Processing,0,"A realistic Chinese word segmentation tool must adapt to textual variations with minimal training input and yet robust enough to yield reliable segmentation result for all variants. Various lexicon-driven approaches to Chinese segmentation, e.g. [1,16], achieve high f-scores yet require massive training for any variation. Text-driven approach, e.g. [12], can be easily adapted for domain and genre changes yet has difficulty matching the high f-scores of the lexicon-driven approaches. In this paper, we refine and implement an innovative text-driven word boundary decision (WBD) segmentation model proposed in [15]. The WBD model treats word segmentation simply and efficiently as a binary decision on whether to realize the natural textual break between two adjacent characters as a word boundary. The WBD model allows simple and quick training data preparation converting characters as contextual vectors for learning the word boundary decision. Machine learning experiments with four different classifiers show that training with 1,000 vectors and 1 million vectors achieve comparable and reliable results. In addition, when applied to SigHAN Bakeoff 3 competition data, the WBD model produces OOV recall rates that are higher than all published results. Unlike all previous work, our OOV recall rate is comparable to our own F-score. Both experiments support the claim that the WBD model is a realistic model for Chinese word segmentation as it can be easily adapted for new variants with robust result. In conclusion, we will discuss linguistic ramifications as well as future implications for the WBD approach."
vossen-etal-2008-kyoto,"{KYOTO}: a System for Mining, Structuring and Distributing Knowledge across Languages and Cultures",2008,32,44,5,0,5469,piek vossen,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We outline work performed within the framework of a current EC project. The goal is to construct a language-independent information system for a specific domain (environment/ecology/biodiversity) anchored in a language-independent ontology that is linked to wordnets in seven languages. For each language, information extraction and identification of lexicalized concepts with ontological entries is carried out by text miners (ÂKybotsÂ). The mapping of language-specific lexemes to the ontology allows for crosslinguistic identification and translation of equivalent terms. The infrastructure developed within this project enables long-range knowledge sharing and transfer across many languages and cultures, addressing the need for global and uniform transition of knowledge beyond the specific domains addressed here."
chung-etal-2008-extracting,Extracting Concrete Senses of Lexicon through Measurement of Conceptual Similarity in Ontologies,2008,5,0,5,0,15600,siawfong chung,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The measurement of conceptual similarity in a hierarchical structure has been proposed by studies such as Wu and Palmer (1994) which have been summarized and evaluated in Budanisky and Hirst (2006). The present study applies the measurement of conceptual similarity to conceptual metaphor research by comparing concreteness of ontological resource nodes to several prototypical concrete nodes selected by human subjects. Here, the purpose of comparing conceptual similarity between nodes is to select a concrete sense for a word which is used metaphorically. Through using WordNet-SUMO interface such as SinicaBow (Huang, Chang and Lee, 2004), concrete senses of a lexicon will be selected once its SUMO nodes have been compared in terms of conceptual similarity with the prototypical concrete nodes. This study has strong implications for the interaction of psycholinguistic and computational linguistic fields in conceptual metaphor research."
tokunaga-etal-2008-adapting,Adapting International Standard for {A}sian Language Technologies,2008,8,6,4,0,301,takenobu tokunaga,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Corpus-based approaches and statistical approaches have been the main stream of natural language processing research for the past two decades. Language resources play a key role in such approaches, but there is an insufficient amount of language resources in many Asian languages. In this situation, standardisation of language resources would be of great help in developing resources in new languages. This paper presents the latest development efforts of our project which aims at creating a common standard for Asian language resources that is compatible with an international standard. In particular, the paper focuses on i) lexical specification and data categories relevant for building multilingual lexical resources for Asian languages; ii) a core upper-layer ontology needed for ensuring multilingual interoperability and iii) the evaluation platform used to test the entire architectural framework."
I08-1052,Constructing Taxonomy of Numerative Classifiers for {A}sian Languages,2008,5,9,4,0,29633,kiyoaki shirai,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"Numerative classifiers are ubiquitous in many Asian languages. This paper proposes a method to construct a taxonomy of numerative classifiers based on a nounclassifier agreement database. The taxonomy defines superordinate-subordinate relation among numerative classifiers and represents the relations in tree structures. The experiments to construct taxonomies were conducted for evaluation by using data from three different languages: Chinese, Japanese and Thai. We found that our method was promising for Chinese and Japanese, but inappropriate for Thai. It confirms that there really is no hierarchy among Thai classifiers."
P07-2018,"Rethinking {C}hinese Word Segmentation: Tokenization, Character Classification, or Wordbreak Identification",2007,6,27,3,0,1504,churen huang,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"This paper addresses two remaining challenges in Chinese word segmentation. The challenge in HLT is to find a robust segmentation method that requires no prior lexical knowledge and no extensive training to adapt to new types of data. The challenge in modelling human cognition and acquisition it to segment words efficiently without using knowledge of wordhood. We propose a radical method of word segmentation to meet both challenges. The most critical concept that we introduce is that Chinese word segmentation is the classification of a string of character-boundaries (CB's) into either word-boundaries (WB's) and non-word-boundaries. In Chinese, CB's are delimited and distributed in between two characters. Hence we can use the distributional properties of CB among the background character strings to predict which CB's are WB's."
P07-2039,Automatic Discovery of Named Entity Variants: Grammar-driven Approaches to Non-Alphabetical Transliterations,2007,16,2,3,0,1504,churen huang,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"Identification of transliterated names is a particularly difficult task of Named Entity Recognition (NER), especially in the Chinese context. Of all possible variations of transliterated named entities, the difference between PRC and Taiwan is the most prevalent and most challenging. In this paper, we introduce a novel approach to the automatic extraction of diverging transliterations of foreign named entities by bootstrapping co-occurrence statistics from tagged and segmented Chinese corpus. Preliminary experiment yields promising results and shows its potential in NLP applications."
P06-2050,When Conset Meets Synset: A Preliminary Survey of an Ontological Lexical Resource Based on {C}hinese Characters,2006,9,3,1,1,2402,shukai hsieh,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"This paper describes an on-going project concerning with an ontological lexical resource based on the abundant conceptual information grounded on Chinese characters. The ultimate goal of this project is set to construct a cognitively sound and computationally effective character-grounded machine-understandable resource.n n Philosophically, Chinese ideogram has its ontological status, but its applicability to the NLP task has not been expressed explicitly in terms of language resource. We thus propose the first attempt to locate Chinese characters within the context of ontology. Having the primary success in applying it to some NLP tasks, we believe that the construction of this knowledge resource will shed new light on theoretical setting as well as the construction of Chinese lexical semantic resources."
O06-1003,å¤§è¦æ¨¡è©å½èªæéä¿èªåæ¨ç¤ºä¹åæ­¥ç ç©¶: ä»¥ä¸­æè©ç¶²({C}hinese {W}ordnet)çºä¾ (A Preliminary Study on Large-scale Automatic Labeling of Lexical Semantic Relations: A Case study of {C}hinese {W}ordnet) [In {C}hinese],2006,3,0,1,1,2402,shukai hsieh,Proceedings of the 18th Conference on Computational Linguistics and Speech Processing,0,None
I05-3008,Word Meaning Inducing via Character Ontology: A Survey on the Semantic Prediction of {C}hinese Two-Character Words,2005,7,2,1,1,2402,shukai hsieh,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper presents a semantic class prediction model of Chinese twocharacter compound words based on a character ontology, which is set to be a feasible conceptual knowledge resource grounded in Chinese characters. The experiment we conduct yields satisfactory results which turn out to be that the task of semantic prediction of two-character words could be greatly facilitated using Chinese characters as a knowledge resource."
