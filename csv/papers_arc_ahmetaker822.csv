S19-2147,"{S}em{E}val-2019 Task 7: {R}umour{E}val, Determining Rumour Veracity and Support for Rumours",2019,0,13,4,0,25115,genevieve gorrell,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"Since the first RumourEval shared task in 2017, interest in automated claim validation has greatly increased, as the danger of {``}fake news{''} has become a mainstream concern. However automated support for rumour verification remains in its infancy. It is therefore important that a shared task in this area continues to provide a focus for effort, which is likely to increase. Rumour verification is characterised by the need to consider evolving conversations and news updates to reach a verdict on a rumour{'}s veracity. As in RumourEval 2017 we provided a dataset of dubious posts and ensuing conversations in social media, annotated both for stance and veracity. The social media rumours stem from a variety of breaking news stories and the dataset is expanded to include Reddit as well as new Twitter posts. There were two concrete tasks; rumour stance prediction and rumour verification, which we present in detail along with results achieved by participants. We received 22 system submissions (a 70{\%} increase from RumourEval 2017) many of which used state-of-the-art methodology to tackle the challenges involved."
R19-1002,Identification of Good and Bad News on {T}witter,2019,0,0,2,0,93,piush aggarwal,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Social media plays a great role in news dissemination which includes good and bad news. However, studies show that news, in general, has a significant impact on our mental stature and that this influence is more in bad news. An ideal situation would be that we have a tool that can help to filter out the type of news we do not want to consume. In this paper, we provide the basis for such a tool. In our work, we focus on Twitter. We release a manually annotated dataset containing 6,853 tweets from 5 different topical categories. Each tweet is annotated with good and bad labels. We also investigate various machine learning systems and features and evaluate their performance on the newly generated dataset. We also perform a comparative analysis with sentiments showing that sentiment alone is not enough to distinguish between good and bad news."
W18-5505,Information Nutrition Labels: A Plugin for Online News Evaluation,2018,0,0,9,0,27930,vincentius kevin,Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER}),0,"In this paper we present a browser plugin \textit{NewsScan} that assists online news readers in evaluating the quality of online content they read by providing \textit{information nutrition labels} for online news articles. In analogy to groceries, where nutrition labels help consumers make choices that they consider best for themselves, information nutrition labels tag online news articles with data that help readers judge the articles they engage with. This paper discusses the choice of the labels, their implementation and visualization."
W18-5518,Uni-{DUE} Student Team: Tackling fact checking through decomposable attention neural network,2018,0,0,2,0,27944,jan kowollik,Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER}),0,In this paper we present our system for the FEVER Challenge. The task of this challenge is to verify claims by extracting information from Wikipedia. Our system has two parts. In the first part it performs a search for candidate sentences by treating the claims as query. In the second part it filters out noise from these candidates and uses the remaining ones to decide whether they support or refute or entail not enough information to verify the claim. We show that this system achieves a FEVER score of 0.3927 on the FEVER shared task development data set which is a 25.5{\%} improvement over the baseline score.
L18-1617,"Multi-lingual Argumentative Corpora in {E}nglish, {T}urkish, {G}reek, {A}lbanian, {C}roatian, {S}erbian, {M}acedonian, {B}ulgarian, {R}omanian and {A}rabic",2018,0,2,8,0,30169,alfred sliwa,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1284,Can Rumour Stance Alone Predict Veracity?,2018,0,18,2,0,30913,sebastian dungs,Proceedings of the 27th International Conference on Computational Linguistics,0,"Prior manual studies of rumours suggested that crowd stance can give insights into the actual rumour veracity. Even though numerous studies of automatic veracity classification of social media rumours have been carried out, none explored the effectiveness of leveraging crowd stance to determine veracity. We use stance as an additional feature to those commonly used in earlier studies. We also model the veracity of a rumour using variants of Hidden Markov Models (HMM) and the collective stance information. This paper demonstrates that HMMs that use stance and tweets{'} times as the only features for modelling true and false rumours achieve F1 scores in the range of 80{\%}, outperforming those approaches where stance is used jointly with content and user based features."
sanchan-etal-2017-automatic,Automatic Summarization of Online Debates,2017,8,0,2,0,31166,nattapong sanchan,Proceedings of the 1st Workshop on Natural Language Processing and Information Retrieval associated with {RANLP} 2017,0,"Debate summarization is one of the novel and challenging research areas in automatic text summarization which has been largely unexplored. In this paper, we develop a debate summarization pipeline to summarize key topics which are discussed or argued in the two opposing sides of online debates. We view that the generation of debate summaries can be achieved by clustering, cluster labeling, and visualization. In our work, we investigate two different clustering approaches for the generation of the summaries. In the first approach, we generate the summaries by applying purely term-based clustering and cluster labeling. The second approach makes use of X-means for clustering and Mutual Information for labeling the clusters. Both approaches are driven by ontologies. We visualize the results using bar charts. We think that our results are a smooth entry for users aiming to receive the first impression about what is discussed within a debate topic containing waste number of argumentations."
W17-5108,Projection of Argumentative Corpora from Source to Target Languages,2017,12,3,1,1,25116,ahmet aker,Proceedings of the 4th Workshop on Argument Mining,0,"Argumentative corpora are costly to create and are available in only few languages with English dominating the area. In this paper we release the first publicly available Mandarin argumentative corpus. The corpus is created by exploiting the idea of comparable corpora from Statistical Machine Translation. We use existing corpora in English and manually map the claims and premises to comparable corpora in Mandarin. We also implement a simple solution to automate this approach with the view of creating argumentative corpora in other less-resourced languages. In this way we introduce a new task of multi-lingual argument mapping that can be evaluated using our English-Mandarin argumentative corpus. The preliminary results of our automatic argument mapper mirror the simplicity of our approach, but provide a baseline for further improvements."
W17-5112,What works and what does not: Classifier and feature analysis for argument mining,2017,0,11,1,1,25116,ahmet aker,Proceedings of the 4th Workshop on Argument Mining,0,"This paper offers a comparative analysis of the performance of different supervised machine learning methods and feature sets on argument mining tasks. Specifically, we address the tasks of extracting argumentative segments from texts and predicting the structure between those segments. Eight classifiers and different combinations of six feature types reported in previous work are evaluated. The results indicate that overall best performing features are the structural ones. Although the performance of classifiers varies depending on the feature combinations and corpora used for training and testing, Random Forest seems to be among the best performing classifiers. These results build a basis for further development of argument mining techniques and can guide an implementation of argument mining into different applications such as argument based search."
aker-etal-2017-simple,Simple Open Stance Classification for Rumour Analysis,2017,22,5,1,1,25116,ahmet aker,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Stance classification determines the attitude, or stance, in a (typically short) text. The task has powerful applications, such as the detection of fake news or the automatic extraction of attitudes toward entities or events in the media. This paper describes a surprisingly simple and efficient classification approach to open stance classification in Twitter, for rumour and veracity classification. The approach profits from a novel set of automatically identifiable problem-specific features, which significantly boost classifier accuracy and achieve above state-of-the-art results on recent benchmark datasets. This calls into question the value of using complex sophisticated models for stance classification without first doing informed feature extraction."
aker-etal-2017-extensible,An Extensible Multilingual Open Source Lemmatizer,2017,1,2,1,1,25116,ahmet aker,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"We present GATE DictLemmatizer, a multilingual open source lemmatizer for the GATE NLP framework that currently supports English, German, Italian, French, Dutch, and Spanish, and is easily extensible to other languages. The software is freely available under the LGPL license. The lemmatization is based on the Helsinki Finite-State Transducer Technology (HFST) and lemma dictionaries automatically created from Wiktionary. We evaluate the performance of the lemmatizers against TreeTagger, which is only freely available for research purposes. Our evaluation shows that DictLemmatizer achieves similar or even better results than TreeTagger for languages where there is support from HFST. The performance drops when there is no support from HFST and the entire lemmatization process is based on lemma dictionaries. However, the results are still satisfactory given the fact that DictLemmatizer isopen-source and can be easily extended to other languages. The software for extending the lemmatizer by creating word lists from Wiktionary dictionaries is also freely available as open-source software."
W16-6610,Automatic label generation for news comment clusters,2016,15,7,1,1,25116,ahmet aker,Proceedings of the 9th International Natural Language Generation conference,0,"We present a supervised approach to automat-n ically labelling topic clusters of reader com-n ments to online news. We use a feature setn that includes both features capturing proper-n ties local to the cluster and features that cap-n ture aspects from the news article and fromn comments outside the cluster. We evaluaten the approach in an automatic and a manual,n task-based setting. Both evaluations show then approach to outperform a baseline method,n which uses tf*idf to select comment-internaln terms for use as topic labels. We illustrate hown cluster labels can be used to generate clustern summaries and present two alternative sum-n mary formats: a pie chart summary and an ab-n stractive summary."
W16-3605,The {SENSEI} Annotated Corpus: Human Summaries of Reader Comment Conversations in On-line News,2016,15,9,3,1,33318,emma barker,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Researchers are beginning to explore hown to generate summaries of extended argumentativen conversations in social media,n such as those found in reader comments inn on-line news. To date, however, there hasn been little discussion of what these summariesn should be like and a lack of humanauthoredn exemplars, quite likely becausen writing summaries of this kind of interchangen is so difficult. In this paper wen propose one type of reader comment summaryn xe2x80x93 the conversation overview summaryn xe2x80x93 that aims to capture the key argumentativen content of a reader commentn conversation. We describe a method wen have developed to support humans in authoringn conversation overview summariesn and present a publicly available corpus xe2x80x93n the first of its kind xe2x80x93 of news articles plusn comment sets, each multiply annotated,n according to our method, with conversationn overview summaries."
S16-1092,{USFD} at {S}em{E}val-2016 Task 1: Putting different State-of-the-Arts into a Box,2016,11,0,1,1,25116,ahmet aker,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,In this paper we describe our participation in the STS Core subtask which is the determination of the monolingual semantic similarity between pair of sentences. In our participation we adapted state-ofthe-art approaches from related work applied on previous STS Core subtasks and run them on the 2016 data. We investigated the performance of single methods but also the combination of them. Our results show that Convolutional Neural Networks (CNN) are superior to both the Monolingual Word Alignment and the Word2Vec approaches. The combination of all the three methods performs slightly better than using CNN only. Our results also show that the performance of our systems varies between the datasets.
L16-1494,What{'}s the Issue Here?: Task-based Evaluation of Reader Comment Summarization Systems,2016,9,4,5,1,33318,emma barker,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Automatic summarization of reader comments in on-line news is an extremely challenging task and a capability for which there is a clear need. Work to date has focussed on producing extractive summaries using well-known techniques imported from other areas of language processing. But are extractive summaries of comments what users really want? Do they support users in performing the sorts of tasks they are likely to want to perform with reader comments? In this paper we address these questions by doing three things. First, we offer a specification of one possible summary type for reader comment, based on an analysis of reader comment in terms of issues and viewpoints. Second, we define a task-based evaluation framework for reader comment summarization that allows summarization systems to be assessed in terms of how well they support users in a time-limited task of identifying issues and characterising opinion on issues in comments. Third, we describe a pilot evaluation in which we used the task-based evaluation framework to evaluate a prototype reader comment clustering and summarization system, demonstrating the viability of the evaluation framework and illustrating the sorts of insight such an evaluation affords."
L16-1663,"Creation of comparable corpora for {E}nglish-{Urdu, Arabic, Persian}",2016,0,0,3,0,35373,murad abouammoh,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Statistical Machine Translation (SMT) relies on the availability of rich parallel corpora. However, in the case of under-resourced languages or some specific domains, parallel corpora are not readily available. This leads to under-performing machine translation systems in those sparse data settings. To overcome the low availability of parallel resources the machine translation community has recognized the potential of using comparable resources as training data. However, most efforts have been related to European languages and less in middle-east languages. In this study, we report comparable corpora created from news articles for the pair English â{Arabic, Persian, Urdu} languages. The data has been collected over a period of a year, entails Arabic, Persian and Urdu languages. Furthermore using the English as a pivot language, comparable corpora that involve more than one language can be created, e.g. English- Arabic - Persian, English - Arabic - Urdu, English â Urdu - Persian, etc. Upon request the data can be provided for research purposes."
W15-4635,Comment-to-Article Linking in the Online News Domain,2015,15,5,1,1,25116,ahmet aker,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Online commenting to news articles provides a communication channel between media professionals and readers offering a crucial tool for opinion exchange and freedom of expression. Currently, comments are detached from the news article and thus removed from the context that they were written for. In this work, we propose a method to connect readersxe2x80x99 comments to the news article segments they refer to. We use similarity features to link comments to relevant article segments and evaluate both word-based and term-based vector spaces. Our results are comparable to state-of-theart topic modeling techniques when used for linking tasks. We demonstrate that article segments and comments representation are relevant to linking accuracy since we achieve better performances when similarity features are computed using similarity between terms rather than words."
W14-5406,A Poodle or a Dog? Evaluating Automatic Image Annotation Using Human Descriptions at Different Levels of Granularity,2014,27,7,3,0,25940,josiah wang,Proceedings of the Third Workshop on Vision and Language,0,"Different people may describe the same object in different ways, and at varied levels of granularity (xe2x80x9cpoodlexe2x80x9d, xe2x80x9cdogxe2x80x9d, xe2x80x9cpetxe2x80x9d or xe2x80x9canimalxe2x80x9d?) In this paper, we propose the idea of xe2x80x98granularityawarexe2x80x99 groupings where semantically related concepts are grouped across different levels of granularity to capture the variation in how different people describe the same image content. The idea is demonstrated in the task of automatic image annotation, where these semantic groupings are used to alter the results of image annotation in a manner that affords different insights from its initial, category-independent rankings. The semantic groupings are also incorporated during evaluation against image descriptions written by humans. Our experiments show that semantic groupings result in image annotations that are more informative and flexible than without groupings, although being too flexible may result in image annotations that are less informative."
W14-4802,Assigning Terms to Domains by Document Classification,2014,20,3,4,0,33330,robert gaizauskas,Proceedings of the 4th International Workshop on Computational Terminology (Computerm),0,In this paper we investigate a number of questions relating to the identification of the domain of a term by domain classification of the document in which the term occurs. We propose and evaluate a straightforward method for domain classification of documents in 24 languages that exploits a multilingual thesaurus and Wikipedia. We investigate and provide quantitative results about the extent to which humans agree about the domain classification of documents and terms also the extent to which terms are likely to xe2x80x9cinheritxe2x80x9d the domain of their parent document.
aker-etal-2014-bootstrapping,Bootstrapping Term Extractors for Multiple Languages,2014,13,4,1,1,25116,ahmet aker,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Terminology extraction resources are needed for a wide range of human language technology applications, including knowledge management, information extraction, semantic search, cross-language information retrieval and automatic and assisted translation. We create a low cost method for creating terminology extraction resources for 21 non-English EU languages. Using parallel corpora and a projection method, we create a General POS Tagger for these languages. We also investigate the use of EuroVoc terms and Wikipedia corpus to automatically create term grammar for each language. Our results show that these automatically generated resources can assist term extraction process with similar performance to manually generated resources. All resources resulted in this experiment are freely available for download."
aker-etal-2014-bilingual,Bilingual dictionaries for all {EU} languages,2014,17,7,1,1,25116,ahmet aker,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Bilingual dictionaries can be automatically generated using the GIZA++ tool. However, these dictionaries contain a lot of noise, because of which the quality of outputs of tools relying on the dictionaries are negatively affected. In this work we present three different methods for cleaning noise from automatically generated bilingual dictionaries: LLR, pivot and translation based approach. We have applied these approaches on the GIZA++ dictionaries -- dictionaries covering official EU languages -- in order to remove noise. Our evaluation showed that all methods help to reduce noise. However, the best performance is achieved using the transliteration based approach. We provide all bilingual dictionaries (the original GIZA++ dictionaries and the cleaned ones) free for download. We also provide the cleaning tools and scripts for free download."
P13-1040,Extracting bilingual terminologies from comparable corpora,2013,24,26,1,1,25116,ahmet aker,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper we present a method for extracting bilingual terminologies from comparable corpora. In our approach we treat bilingual term extraction as a classification problem. For classification we use an SVM binary classifier and training data taken from the EUROVOC thesaurus. We test our approach on a held-out test set from EUROVOC and perform precision, recall and f-measure evaluations for 20 European language pairs. The performance of our classifier reaches the 100% precision level for many language pairs. We also perform manual evaluation on bilingual terms extracted from English-German term-tagged comparable corpora. The results of this manual evaluation showed 60-83% of the term pairs generated are exact translations and over 90% exact or partial translations."
paramita-etal-2012-correlation,Correlation between Similarity Measures for Inter-Language Linked {W}ikipedia Articles,2012,12,12,3,0.897436,33315,monica paramita,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Wikipedia articles in different languages have been mined to support various tasks, such as Cross-Language Information Retrieval (CLIR) and Statistical Machine Translation (SMT). Articles on the same topic in different languages are often connected by inter-language links, which can be used to identify similar or comparable content. In this work, we investigate the correlation between similarity measures utilising language-independent and language-dependent features and respective human judgments. A collection of 800 Wikipedia pairs from 8 different language pairs were collected and judged for similarity by two assessors. We report the development of this corpus and inter-assessor agreement between judges across the languages. Results show that similarity measured using language independent features is comparable to using an approach based on translating non-English documents. In both cases the correlation with human judgments is low but also dependent upon the language pair. The results and corpus generated from this work also provide insights into the measurement of cross-language similarity."
kurtic-etal-2012-corpus,A Corpus of Spontaneous Multi-party Conversation in {B}osnian {S}erbo-{C}roatian and {B}ritish {E}nglish,2012,22,6,5,0,33316,emina kurtic,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we present a corpus of audio and video recordings of spontaneous, face-to-face multi-party conversation in two languages. Freely available high quality recordings of mundane, non-institutional, multi-party talk are still sparse, and this corpus aims to contribute valuable data suitable for study of multiple aspects of spoken interaction. In particular, it constitutes a unique resource for spoken Bosnian Serbo-Croatian (BSC), an under-resourced language with no spoken resources available at present. The corpus consists of just over 3 hours of free conversation in each of the target languages, BSC and British English (BE). The audio recordings have been made on separate channels using head-set microphones, as well as using a microphone array, containing 8 omni-directional microphones. The data has been segmented and transcribed using segmentation notions and transcription conventions developed from those of the conversation analysis research tradition. Furthermore, the transcriptions have been automatically aligned with the audio at the word and phone level, using the method of forced alignment. In this paper we describe the procedures behind the corpus creation and present the main features of the corpus for the study of conversation."
aker-etal-2012-assessing,Assessing Crowdsourcing Quality through Objective Tasks,2012,22,29,1,1,25116,ahmet aker,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The emergence of crowdsourcing as a commonly used approach to collect vast quantities of human assessments on a variety of tasks represents nothing less than a paradigm shift. This is particularly true in academic research where it has suddenly become possible to collect (high-quality) annotations rapidly without the need of an expert. In this paper we investigate factors which can influence the quality of the results obtained through Amazon's Mechanical Turk crowdsourcing platform. We investigated the impact of different presentation methods (free text versus radio buttons), workers' base (USA versus India as the main bases of MTurk workers) and payment scale (about {\$}4, {\$}8 and {\$}10 per hour) on the quality of the results. For each run we assessed the results provided by 25 workers on a set of 10 tasks. We run two different experiments using objective tasks: maths and general text questions. In both tasks the answers are unique, which eliminates the uncertainty usually present in subjective tasks, where it is not clear whether the unexpected answer is caused by a lack of worker's motivation, the worker's interpretation of the task or genuine ambiguity. In this work we present our results comparing the influence of the different factors used. One of the interesting findings is that our results do not confirm previous studies which concluded that an increase in payment attracts more noise. We also find that the country of origin only has an impact in some of the categories and only in general text questions but there is no significant difference at the top pay."
aker-etal-2012-light,A light way to collect comparable corpora from the Web,2012,19,21,1,1,25116,ahmet aker,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Statistical Machine Translation (SMT) relies on the availability of rich parallel corpora. However, in the case of under-resourced languages, parallel corpora are not readily available. To overcome this problem previous work has recognized the potential of using comparable corpora as training data. The process of obtaining such data usually involves (1) downloading a separate list of documents for each language, (2) matching the documents between two languages usually by comparing the document contents, and finally (3) extracting useful data for SMT from the matched document pairs. This process requires a large amount of time and resources since a huge volume of documents needs to be downloaded to increase the chances of finding good document pairs. In this work we aim to reduce the amount of time and resources spent for tasks 1 and 2. Instead of obtaining full documents we first obtain just titles along with some meta-data such as time and date of publication. Titles can be obtained through Web Search and RSS News feed collections so that download of the full documents is not needed. We show experimentally that titles can be used to approximate the comparison between documents using full document contents."
skadina-etal-2012-collecting,Collecting and Using Comparable Corpora for Statistical Machine Translation,2012,32,25,2,0,17522,inguna skadicna,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Lack of sufficient parallel data for many languages and domains is currently one of the major obstacles to further advancement of automated translation. The ACCURAT project is addressing this issue by researching methods how to improve machine translation systems by using comparable corpora. In this paper we present tools and techniques developed in the ACCURAT project that allow additional data needed for statistical machine translation to be extracted from comparable corpora. We present methods and tools for acquisition of comparable corpora from the Web and other sources, for evaluation of the comparability of collected corpora, for multi-level alignment of comparable corpora and for extraction of lexical and terminological data for machine translation. Finally, we present initial evaluation results on the utility of collected corpora in domain-adapted machine translation and real-life applications."
C12-2003,Automatic Bilingual Phrase Extraction from Comparable Corpora,2012,22,14,1,1,25116,ahmet aker,Proceedings of {COLING} 2012: Posters,0,"In this work we present an approach for extracting parallel phrases from comparable news articles to improve statistical machine translation. This is particularly useful for under-resourced languages where parallel corpora are not readily available. Our approach consists of a phrase pair generator that automatically generates candidate parallel phrases and a binary SVM classifier that classifies the candidate phrase pairs as parallel or non-parallel. The phrase pair generator is also used to automatically create training and testing data for the SVM classifier from parallel corpora. We evaluate our approach using English-German, English-Greek and English-Latvian language pairs. The performance of our classifier on the test sets is above 80% precision and 97% accuracy for all language pairs. We also perform an SMT evaluation by measuring the impact of phrases extracted from comparable corpora on SMT quality using BLEU. For all language pairs we obtain significantly better results compared to the baselines."
R11-1011,Multi-Document Summarization by Capturing the Information Users are Interested in,2011,18,3,3,0,25381,elena lloret,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"This paper proposes a method for automatically generating summaries taking into account the information in which users may be interested. Our approach relies on existing model summaries from tourist sites and captures from them the type of information humans use to describe places around the world. Relational patterns are first extracted and categorized by the type of information they encode. Then, we apply them to the collection of input documents to automatically extract the most relevant sentences and build the summaries. In order to evaluate the performance of our approach, we conduct two types of evaluation. On the one hand, we use ROUGE to assess the information contained in our summaries against existing human written summaries, whereas on the other hand, we carry out a human readability evaluation. Our results indicate that our approach achieves high performance both in ROUGE and manual evaluation."
P10-1127,Generating Image Descriptions Using Dependency Relational Patterns,2010,25,61,1,1,25116,ahmet aker,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple web-documents that contain information related to an image's location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns."
aker-gaizauskas-2010-model,Model Summaries for Location-related Images,2010,16,17,1,1,25116,ahmet aker,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"At present there is no publicly available data set to evaluate the performance of different summarization systems on the task of generating location-related extended image captions. In this paper we describe a corpus of human generated model captions in English and German. We have collected 932 model summaries in English from existing image descriptions and machine translated these summaries into German. We also performed post-editing on the translated German summaries to ensure high quality. Both English and German summaries are evaluated using a readability assessment as in DUC and TAC to assess their quality. Our model summaries performed similar to the ones reported in Dang (2005) and thus are suitable for evaluating automatic summarization systems on the task of generating image descriptions for location related images. In addition, we also investigated whether post-editing of machine-translated model summaries is necessary for automated ROUGE evaluations. We found a high correlation in ROUGE scores between post-edited and non-post-edited model summaries which indicates that the expensive process of post-editing is not necessary."
D10-1047,Multi-Document Summarization Using {A}* Search and Discriminative Learning,2010,16,31,1,1,25116,ahmet aker,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we address two key challenges for extractive multi-document summarization: the search problem of finding the best scoring summary and the training problem of learning the best model parameters. We propose an A* search algorithm to find the best extractive summary up to a given length, which is both optimal and efficient to run. Further, we propose a discriminative training algorithm which directly maximises the quality of the best summary, rather than assuming a sentence-level decomposition as in earlier work. Our approach leads to significantly better results than earlier techniques across a number of evaluation metrics."
R09-1002,Summary Generation for Toponym-referenced Images using Object Type Language Models,2009,20,14,1,1,25116,ahmet aker,Proceedings of the International Conference {RANLP}-2009,0,This paper presents a novel approach to automatic captioning of toponym-referenced images. The automatic captioning procedure works by summarizing multiple web-documents that contain information related to an imagexe2x80x99s location. Our summarizer can generate both query-based and language model-biased multidocument summaries. The models are created from large numbers of existing articles pertaining to places of the same xe2x80x9cobject typexe2x80x9d. Evaluation relative to human written captions shows that when language models are used to bias the summarizer the summaries score more highly than the non-biased ones.
W08-1407,Evaluating automatically generated user-focused multi-document summaries for geo-referenced images,2008,16,4,1,1,25116,ahmet aker,Coling 2008: Proceedings of the workshop Multi-source Multilingual Information Extraction and Summarization,0,"This paper reports an initial study that aims to assess the viability of a state-of-the-art multi-document summarizer for automatic captioning of geo-referenced images. The automatic captioning procedure requires summarizing multiple web documents that contain information related to images' location. We use SUMMA (Saggion and Gaizauskas, 2005) to generate generic and query-based multi-document summaries and evaluate them using ROUGE evaluation metrics (Lin, 2004) relative to human generated summaries. Results show that, even though query-based summaries perform better than generic ones, they are still not selecting the information that human participants do. In particular, the areas of interest that human summaries display (history, travel information, etc.) are not contained in the query-based summaries. For our future work in automatic image captioning this result suggests that developing the query-based summarizer further and biasing it to account for user-specific requirements will prove worthwhile."
