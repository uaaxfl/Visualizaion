2020.aacl-srw.15,2020.acl-main.705,0,0.0667083,"pan Advanced Institute of Science and Technology nguyenml@jaist.ac.jp Abstract ALBERT (Lan et al., 2019), have been widely used in many natural language understanding tasks. Among them, BERT is one of the most effective representations that has inspired many other representations such as RoBERTa, ALBERT. It significantly boosts the performance of many natural language understanding tasks, including text classification, question answering, etc (Devlin et al., 2019). There have been few recent attempts to incorporate BERT into NMT models (Xiong et al., 2019; Zhu et al., 2020; Weng et al., 2019; Chen et al., 2020). Large-scale pre-trained representations such as BERT have been widely used in many natural language understanding tasks. The methods of incorporating BERT into documentlevel machine translation are still being explored. BERT is able to understand sentence relationships (Devlin et al., 2019) since BERT is pre-trained using the next sentence prediction task. In our work, we leverage this property to improve document-level machine translation. In our proposed model, BERT performs as a context encoder to achieve documentlevel contextual information, which is then integrated into both the encoder"
2020.aacl-srw.15,N19-1423,0,0.173132,"al Machine Translation Using BERT as Context Encoder Zhiyu Guo Japan Advanced Institute of Science and Technology guozhiyu@jaist.ac.jp Minh Le Nguyen Japan Advanced Institute of Science and Technology nguyenml@jaist.ac.jp Abstract ALBERT (Lan et al., 2019), have been widely used in many natural language understanding tasks. Among them, BERT is one of the most effective representations that has inspired many other representations such as RoBERTa, ALBERT. It significantly boosts the performance of many natural language understanding tasks, including text classification, question answering, etc (Devlin et al., 2019). There have been few recent attempts to incorporate BERT into NMT models (Xiong et al., 2019; Zhu et al., 2020; Weng et al., 2019; Chen et al., 2020). Large-scale pre-trained representations such as BERT have been widely used in many natural language understanding tasks. The methods of incorporating BERT into documentlevel machine translation are still being explored. BERT is able to understand sentence relationships (Devlin et al., 2019) since BERT is pre-trained using the next sentence prediction task. In our work, we leverage this property to improve document-level machine translation. In"
2020.aacl-srw.15,2020.acl-main.322,0,0.0488477,"ng corpus, BERT can better encode context information on News dataset. 3.4 Ablation study Effect of Context Integration Table 3 shows the effect of integrating BERT context representation into the encoder and the decoder. We can find that integrating BERT context representation into the encoder brings more improvements, it is also beneficial to integrate representation into the decoder. The results indicate that the BERT context representation should be integrated into both encoder and decoder to achieve better performance. Does the BERT encoder really capture the contextual information? Yes. Li et al. (2020) claims that the improvements of the multi-encoder 104 As shown in Table 4, the performance of Random and Fixed decrease due to the incorrect context, which is different from the result in Li et al. (2020). This indicates that our proposed model can really capture the contextual information. Although the performance of Random and Fixed decreases, they can still outperform the standard Transformer model significantly. This is because current sentence usually plays a more important role in target sentence generation, and our proposed model can leverage the representation of current sentence obta"
2020.aacl-srw.15,2021.ccl-1.108,0,0.109191,"Missing"
2020.aacl-srw.15,2020.acl-main.321,0,0.259231,"2014; Vaswani et al., 2017). NMT systems have even achieved human parity on resource-rich language pairs (Hassan et al., 2018). However, standard NMT systems perform translation only at the sentence level, which ignores the dependencies among sentences when translating entire documents. To address the above challenges, various document-level NMT models, have been proposed to extract contextual information from surrounding sentences and have achieved substantial improvements in generating consistent translations (Voita et al., 2018; Zhang et al., 2018; Werlen et al., 2018; Maruf et al., 2019; Ma et al., 2020). Large-scale pre-trained text representations like GPT-2 (Radford et al., 2018, 2019), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), In this work, we propose to extend the Transformer model to take advantage of BERT document-level contextual representation. We use the pre-trained BERT as a context encoder to achieve document-level representation, which is then integrated into both the encoder and the decoder of Transformer NMT model. We use a multihead attention mechanism and context gate to control how each layer interacts with BERT context representations adaptively. We conducted"
2020.aacl-srw.15,N19-1313,0,0.354071,"14; Bahdanau et al., 2014; Vaswani et al., 2017). NMT systems have even achieved human parity on resource-rich language pairs (Hassan et al., 2018). However, standard NMT systems perform translation only at the sentence level, which ignores the dependencies among sentences when translating entire documents. To address the above challenges, various document-level NMT models, have been proposed to extract contextual information from surrounding sentences and have achieved substantial improvements in generating consistent translations (Voita et al., 2018; Zhang et al., 2018; Werlen et al., 2018; Maruf et al., 2019; Ma et al., 2020). Large-scale pre-trained text representations like GPT-2 (Radford et al., 2018, 2019), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), In this work, we propose to extend the Transformer model to take advantage of BERT document-level contextual representation. We use the pre-trained BERT as a context encoder to achieve document-level representation, which is then integrated into both the encoder and the decoder of Transformer NMT model. We use a multihead attention mechanism and context gate to control how each layer interacts with BERT context representations adaptiv"
2020.aacl-srw.15,N19-4009,0,0.0182198,"24.01 23.28 24.87 26.61 25.59 23.99 26.23 25.03 24.84 22.37 22.42 22.78 23.55 24.52 25.05 22.50 26.55 Table 2: BLEU scores on the two document-level machine translation benchmarks dropout (Srivastava et al., 2014) is 0.1 for sentence model and 0.2 for document-level model. We use the Adam (Kingma and Ba, 2014) optimizer and the same learning rate schedule strategy as (Vaswani et al., 2017) with 4000 warmup steps. The batch size is limited to 4000 tokens. We also apply label smoothing to the cross-entropy loss, and the smoothing rate is 0.1. Our Transformer implementation is based on Fairseq (Ott et al., 2019). 3.3 BLEU none encoder decoder both 22.50 25.65 25.55 26.55 Table 3: Effect of context integration. ”none” means no BERT context representation is integrated, ”encoder” means BERT context representation is only integrated into the encoder, ”decoder” means BERT context representation is only integrated into the decoder, ”both” means BERT context representation is integrated into both the encoder and the decoder. Experimental results We list the results of our experiments in Table 2, comparing six context-aware NMT models. For Document-aware Transformer (Zhang et al., 2018), Hierarchical Attent"
2020.aacl-srw.15,P02-1040,0,0.106497,"he BERT document-level context representation into standard Transformer decoder. In the l-th layer,  E(l) = M ultiHead T(l−1) , T(l−1) , T(l−1)  F(l) = M ultiHead E(l) , CB , CB   h i dl = σ Wdl F(l) , G(l) + bld  We obtain the processed datasets from Maruf et al. (2019)2 . We use the same train/valid/test datasets with Maruf et al. (2019), so that our results can be compared with previous work. We use the script of Moses toolkit3 to tokenize the sentence. We use byte pair encoding (Sennrich et al., 2016) to segment all sentences with 30K merge operations. The evaluation metrics is BLEU (Papineni et al., 2002).   G(l) = M ultiHead E(l) , S(L) , S(L)    H(l) = dl F(l) + 1 − dl G(l) T(l) = F F N (H(l) ) (6) After achieving the final representations of the last decoder layer T(L) , the output probability of the current target sentence yi are computed as: p (yi |xi , x<i , x>i ) Q = t p (yi,t |yi,≤t , xi , x<i , x>i ) = Q t sof tmax  E [yi,t ]> TL i,t Dataset We use two English-German datasets as the benchmark datasets, which are TED and News. The corpora statistics are shown in Table 1.  A(l) = g l B(l) + 1 − g l D(l) Experiments 3.2 Firstly, we train a Transformer sentence-level NMT model unti"
2020.aacl-srw.15,P16-1162,0,0.0480366,"n into the decoder Similar to the encoder layer, we use context gate and attention mechanism to integrate the BERT document-level context representation into standard Transformer decoder. In the l-th layer,  E(l) = M ultiHead T(l−1) , T(l−1) , T(l−1)  F(l) = M ultiHead E(l) , CB , CB   h i dl = σ Wdl F(l) , G(l) + bld  We obtain the processed datasets from Maruf et al. (2019)2 . We use the same train/valid/test datasets with Maruf et al. (2019), so that our results can be compared with previous work. We use the script of Moses toolkit3 to tokenize the sentence. We use byte pair encoding (Sennrich et al., 2016) to segment all sentences with 30K merge operations. The evaluation metrics is BLEU (Papineni et al., 2002).   G(l) = M ultiHead E(l) , S(L) , S(L)    H(l) = dl F(l) + 1 − dl G(l) T(l) = F F N (H(l) ) (6) After achieving the final representations of the last decoder layer T(L) , the output probability of the current target sentence yi are computed as: p (yi |xi , x<i , x>i ) Q = t p (yi,t |yi,≤t , xi , x<i , x>i ) = Q t sof tmax  E [yi,t ]> TL i,t Dataset We use two English-German datasets as the benchmark datasets, which are TED and News. The corpora statistics are shown in Table 1.  A"
2020.aacl-srw.15,W17-4811,0,0.0824169,"performance of Random and Fixed decrease due to the incorrect context, which is different from the result in Li et al. (2020). This indicates that our proposed model can really capture the contextual information. Although the performance of Random and Fixed decreases, they can still outperform the standard Transformer model significantly. This is because current sentence usually plays a more important role in target sentence generation, and our proposed model can leverage the representation of current sentence obtained by BERT as extra representation. Yang et al., 2019b). Uni-encoder models (Tiedemann and Scherrer, 2017; Li et al., 2019; Ma et al., 2020) take the concatenation of contexts and source sentences as the input. Dual-encoder (Voita et al., 2018; Zhang et al., 2018; Werlen et al., 2018; Maruf et al., 2019; Yang et al., 2019b) models integrate an additional encoder to incorporate the contextual information into standard NMT models. Our proposed model can be categorised as a dual-encoder model. More recently, Li et al. (2020) indicates that in dual-encoder document-level NMT models, the BLEU score improvement is not attributed to the use of contextual information. We have shown that our model can rea"
2020.aacl-srw.15,P18-1117,0,0.203447,"ess of neural machine translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2014; Vaswani et al., 2017). NMT systems have even achieved human parity on resource-rich language pairs (Hassan et al., 2018). However, standard NMT systems perform translation only at the sentence level, which ignores the dependencies among sentences when translating entire documents. To address the above challenges, various document-level NMT models, have been proposed to extract contextual information from surrounding sentences and have achieved substantial improvements in generating consistent translations (Voita et al., 2018; Zhang et al., 2018; Werlen et al., 2018; Maruf et al., 2019; Ma et al., 2020). Large-scale pre-trained text representations like GPT-2 (Radford et al., 2018, 2019), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), In this work, we propose to extend the Transformer model to take advantage of BERT document-level contextual representation. We use the pre-trained BERT as a context encoder to achieve document-level representation, which is then integrated into both the encoder and the decoder of Transformer NMT model. We use a multihead attention mechanism and context gate to control how e"
2020.aacl-srw.15,D18-1325,0,0.328718,"(Sutskever et al., 2014; Bahdanau et al., 2014; Vaswani et al., 2017). NMT systems have even achieved human parity on resource-rich language pairs (Hassan et al., 2018). However, standard NMT systems perform translation only at the sentence level, which ignores the dependencies among sentences when translating entire documents. To address the above challenges, various document-level NMT models, have been proposed to extract contextual information from surrounding sentences and have achieved substantial improvements in generating consistent translations (Voita et al., 2018; Zhang et al., 2018; Werlen et al., 2018; Maruf et al., 2019; Ma et al., 2020). Large-scale pre-trained text representations like GPT-2 (Radford et al., 2018, 2019), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), In this work, we propose to extend the Transformer model to take advantage of BERT document-level contextual representation. We use the pre-trained BERT as a context encoder to achieve document-level representation, which is then integrated into both the encoder and the decoder of Transformer NMT model. We use a multihead attention mechanism and context gate to control how each layer interacts with BERT context rep"
2020.aacl-srw.15,D19-1164,0,0.132827,"trainable. To balance the accuracy and the computation cost, we only use one previous sentence as the context. We use the same model configuration with the setting of the Maruf et al. (2019). For the Transformer NMT model, the hidden size is 512, and the FFN layer dimension is 2048. The number of layers is 4; the number of attention head is 8. The 1 (7) Implementation Details http://www.casmacat.eu/corpus/news-commentary.html https://github.com/sameenmaruf/selective-attn 3 https://github.com/moses-smt/mosesdecoder 2  103 Model TED News HAN (Werlen et al., 2018) SAN (Maruf et al., 2019) QCN (Yang et al., 2019b) Doc-Transformer (Zhang et al., 2018) Transformer (Vaswani et al., 2017) Flat-Transformer (Ma et al., 2020) +BERT BERT-fused (Zhu et al., 2020) Our Reproduced Transformer Our Proposed Model 24.58 24.62 25.19 24.01 23.28 24.87 26.61 25.59 23.99 26.23 25.03 24.84 22.37 22.42 22.78 23.55 24.52 25.05 22.50 26.55 Table 2: BLEU scores on the two document-level machine translation benchmarks dropout (Srivastava et al., 2014) is 0.1 for sentence model and 0.2 for document-level model. We use the Adam (Kingma and Ba, 2014) optimizer and the same learning rate schedule strategy as (Vaswani et al., 201"
2020.aacl-srw.15,D18-1049,0,0.056943,"Missing"
2020.coling-main.86,P17-1152,0,0.0254415,"and be able to select appropriate information to align them in the matching step. Recently, many successful text representation methods have been proposed thanks to the advancement of deep neural network models. The most popular deep neural architectures for text representation include convolutional neural networks (CNNs) (Kim, 2014; Shen et al., 2014; Severyn and Moschitti, 2015; Vaswani et al., 2017), recurrent neural networks (RNNs) (Mikolov et al., 2011), and their variations such as long short-term memories (LSTMs) (Wang et al., 2016; Palangi et al., 2016; Mueller and Thyagarajan, 2016; Chen et al., 2017; Bach et al., 2019a; Bach et al., 2019b) and gated recurrent units (GRUs) (Tang et al., 2015), attention mechanisms (Vaswani et al., 2017), and pre-trained models like BERT (Devlin et al., 2019), among the others. The main advantage of deep neural networks for text This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. ∗ The first two authors have equal contribution. 1 In this paper, “question” and “query” are used interchangeably. License details: http:// 988 Proceedings of the 28th International Conference on Computational"
2020.coling-main.86,N19-1423,0,0.0131241,"ural network models. The most popular deep neural architectures for text representation include convolutional neural networks (CNNs) (Kim, 2014; Shen et al., 2014; Severyn and Moschitti, 2015; Vaswani et al., 2017), recurrent neural networks (RNNs) (Mikolov et al., 2011), and their variations such as long short-term memories (LSTMs) (Wang et al., 2016; Palangi et al., 2016; Mueller and Thyagarajan, 2016; Chen et al., 2017; Bach et al., 2019a; Bach et al., 2019b) and gated recurrent units (GRUs) (Tang et al., 2015), attention mechanisms (Vaswani et al., 2017), and pre-trained models like BERT (Devlin et al., 2019), among the others. The main advantage of deep neural networks for text This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. ∗ The first two authors have equal contribution. 1 In this paper, “question” and “query” are used interchangeably. License details: http:// 988 Proceedings of the 28th International Conference on Computational Linguistics, pages 988–998 Barcelona, Spain (Online), December 8-13, 2020 representation, as well as for other tasks, is that they can capture various types of information at different levels by"
2020.coling-main.86,D14-1181,0,0.00664129,"nts (Jurafsky and Martin, 2009). Text representation, i.e., question and document representation, therefore, plays a crucial role in such systems. Good text representation methods are expected to be able to extract important information from the input question and documents and be able to select appropriate information to align them in the matching step. Recently, many successful text representation methods have been proposed thanks to the advancement of deep neural network models. The most popular deep neural architectures for text representation include convolutional neural networks (CNNs) (Kim, 2014; Shen et al., 2014; Severyn and Moschitti, 2015; Vaswani et al., 2017), recurrent neural networks (RNNs) (Mikolov et al., 2011), and their variations such as long short-term memories (LSTMs) (Wang et al., 2016; Palangi et al., 2016; Mueller and Thyagarajan, 2016; Chen et al., 2017; Bach et al., 2019a; Bach et al., 2019b) and gated recurrent units (GRUs) (Tang et al., 2015), attention mechanisms (Vaswani et al., 2017), and pre-trained models like BERT (Devlin et al., 2019), among the others. The main advantage of deep neural networks for text This work is licensed under a Creative Commons Attr"
2020.coling-main.86,D14-1162,0,0.0863432,"ismatching and ambiguity because of the richness of natural language challenge the non-neural approaches to achieve state-of-the-art results in retrieval tasks. Systems, therefore, need to better understand semantics. Instead of labor features, authors propose effective neural architectures as well as training methods, and let models extract features of different abstraction levels of semantics from data by itself, which expands system capability by data availability. Before BERT, most of systems are built based on feeding word embeddings pretrained (Word2Vec (Mikolov et al., 2013), or GloVe (Pennington et al., 2014)) or randomized to a neural network (CNN, LSTM, etc.). Palangi et al. (2016) used an LSTM network to construct the semantic vector of a sentence via sentence-pair similarity modeling. Shen et al. (2014) proposed a contextual semantic model based on CNN using both local and global contexts to compresses a word sequence into a lowdimensional vector. Pang et al. (2017) claimed that neural retrieval systems like DSSM (Huang et al., 2013) don’t truly understand relevance. The authors, then, proposed DeepRank to mimic the process of humans in assessing relevance. Adopting BERT, a heavy text-encoding"
2020.coling-main.86,D15-1167,0,0.0419149,"many successful text representation methods have been proposed thanks to the advancement of deep neural network models. The most popular deep neural architectures for text representation include convolutional neural networks (CNNs) (Kim, 2014; Shen et al., 2014; Severyn and Moschitti, 2015; Vaswani et al., 2017), recurrent neural networks (RNNs) (Mikolov et al., 2011), and their variations such as long short-term memories (LSTMs) (Wang et al., 2016; Palangi et al., 2016; Mueller and Thyagarajan, 2016; Chen et al., 2017; Bach et al., 2019a; Bach et al., 2019b) and gated recurrent units (GRUs) (Tang et al., 2015), attention mechanisms (Vaswani et al., 2017), and pre-trained models like BERT (Devlin et al., 2019), among the others. The main advantage of deep neural networks for text This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. ∗ The first two authors have equal contribution. 1 In this paper, “question” and “query” are used interchangeably. License details: http:// 988 Proceedings of the 28th International Conference on Computational Linguistics, pages 988–998 Barcelona, Spain (Online), December 8-13, 2020 representation, as"
2020.coling-main.86,D16-1058,0,0.0286979,"e to extract important information from the input question and documents and be able to select appropriate information to align them in the matching step. Recently, many successful text representation methods have been proposed thanks to the advancement of deep neural network models. The most popular deep neural architectures for text representation include convolutional neural networks (CNNs) (Kim, 2014; Shen et al., 2014; Severyn and Moschitti, 2015; Vaswani et al., 2017), recurrent neural networks (RNNs) (Mikolov et al., 2011), and their variations such as long short-term memories (LSTMs) (Wang et al., 2016; Palangi et al., 2016; Mueller and Thyagarajan, 2016; Chen et al., 2017; Bach et al., 2019a; Bach et al., 2019b) and gated recurrent units (GRUs) (Tang et al., 2015), attention mechanisms (Vaswani et al., 2017), and pre-trained models like BERT (Devlin et al., 2019), among the others. The main advantage of deep neural networks for text This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. ∗ The first two authors have equal contribution. 1 In this paper, “question” and “query” are used interchangeably. License details: http:"
2020.coling-main.86,D19-3004,0,0.0580001,"M, etc.). Palangi et al. (2016) used an LSTM network to construct the semantic vector of a sentence via sentence-pair similarity modeling. Shen et al. (2014) proposed a contextual semantic model based on CNN using both local and global contexts to compresses a word sequence into a lowdimensional vector. Pang et al. (2017) claimed that neural retrieval systems like DSSM (Huang et al., 2013) don’t truly understand relevance. The authors, then, proposed DeepRank to mimic the process of humans in assessing relevance. Adopting BERT, a heavy text-encoding model pretrained on a huge amount of texts, Yilmaz et al. (2019) proposed an ad-hoc retrieval system that can handle document-level retrieval. The system, also, combines lexical matching and BERT scores for better performance. The system, however, requires costly computation resource. Legal Text Ad-hoc Retrieval Digitization of legal documents has created the need for the invention of a more efficient search system. For legal text, using a keyphrase-based search system is a challenge because of contingent on the end-users’ expertise in the subject area, such as being aware of complex legal terms, the classification of case laws and statutes. In order to re"
2020.findings-emnlp.409,W16-2922,0,0.0180225,"CDR (Chemical-Disease Reactions) dataset is manually annotated for the binary interactions between Chemical and Disease concepts (Li et al., 2016a) while GDA (Gene-Disease Associations) (Ye et al., 2019) provides the annotations for the binary interactions between Gene and Disease concepts using distant supervision. For both datasets, we follow the same data preprocessing and spits (i.e., for training/development/test data) as the prior work (Christopoulou et al., 2019) to achieve a fair comparison. Also, similar to (Christopoulou et al., 2019), we use the PubMed pre-trained word embeddings (Chiu et al., 2016) 4563 Model (Gu et al., 2017) (Verga et al., 2018) (Nguyen and Verspoor, 2018) EoG (Christopoulou et al., 2019) EoGANE (our system) (Zhou et al., 2016)* (Peng et al., 2016)* (Li et al., 2016b)* (Chandrasekarasastry et al., 2018)* (Zheng et al., 2018)* for the models on CDR while randomly initialized word embeddings are employed for GDA. These word embeddings are optimized during the training process of the models in this work. We implement the EoGANE model in this work by extending the code for the EoG model that is provided in its original paper (Christopoulou et al., 2019). As such, we inher"
2020.findings-emnlp.409,D19-1498,0,0.388496,"siders relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determined by the coreferences of the entity mentions and the appearance of the entity mentions"
2020.findings-emnlp.409,N19-1370,0,0.0203949,"k RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) i"
2020.findings-emnlp.409,C16-1139,0,0.0167383,"he similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopo"
2020.findings-emnlp.409,P16-1200,0,0.0261951,"r DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented"
2020.findings-emnlp.409,P09-1113,0,0.0739897,"regularization techniques to improve the representations for DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches"
2020.findings-emnlp.409,W18-2314,0,0.0921693,"eyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE is to predict the semantic relationships between each pair of entities in E (i.e., including the type NONE for the entity pairs with no relations). In this se"
2020.findings-emnlp.409,P14-2012,1,0.742077,"puting the representations for the nodes in the graphs. Based on such node representations, we introduce two novel regularization techniques to improve the representations for DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al"
2020.findings-emnlp.409,W15-1506,1,0.826948,"odel for DRE. These node representations allow us to introduce two novel representation regularization mechanisms to improve the representation vectors for DRE. The experiments show that our model achieves state-of-the-art performance on two benchmark datasets. 1 Introduction An important task of Information Extraction is Relation Extraction (RE) that seeks to identify the semantic relationships between entities mentioned in text. The prior works have mainly focused on the intra-sentence scenario where the two entity mentions appear in the same sentences (Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2015). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Pen"
2020.findings-emnlp.409,Q17-1008,0,0.0897077,"15). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determin"
2020.findings-emnlp.409,E17-1110,0,0.150604,"we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determined by the coreferences"
2020.findings-emnlp.409,P19-1423,0,0.113527,"nsively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE"
2020.findings-emnlp.409,N19-1147,0,0.0210858,"ision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE is to predict the semantic relationships between each pair of entities in E (i.e., including the type NONE for the entity pairs with no relations). In this section, we will first describe the graph-ba"
2020.findings-emnlp.409,D18-1246,0,0.0217721,"n two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity m"
2020.findings-emnlp.409,N18-1080,0,0.0725814,"hang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE is to predict the semantic relationships between each pair of entities in E (i.e., including the type NONE for the entity pairs wit"
2020.findings-emnlp.409,2020.acl-main.715,1,0.876087,"Missing"
2020.findings-emnlp.409,D15-1203,0,0.0297258,"representations for DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-"
2020.findings-emnlp.409,C14-1220,0,0.253627,"sed edge-oriented model for DRE. These node representations allow us to introduce two novel representation regularization mechanisms to improve the representation vectors for DRE. The experiments show that our model achieves state-of-the-art performance on two benchmark datasets. 1 Introduction An important task of Information Extraction is Relation Extraction (RE) that seeks to identify the semantic relationships between entities mentioned in text. The prior works have mainly focused on the intra-sentence scenario where the two entity mentions appear in the same sentences (Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2015). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentent"
2020.findings-emnlp.409,D17-1186,0,0.0180602,"een the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019)"
2020.findings-emnlp.409,D18-1244,0,0.125622,"their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determined by the coreferences of the entity mentions and the appearance of the entity mentions in the sentences. The representation vectors for the edges of the graph (thus called edge-oriented) are then computed via several inference layers, serving as the features to predict the relations between the pairs of entities in the documents. In this way, the model can leverage the interactions between the nodes and edges of different types to obtain richer representation vectors for the edges between the entity nodes (Christo"
2020.findings-emnlp.409,P05-1053,0,0.294916,"des in the graph-based edge-oriented model for DRE. These node representations allow us to introduce two novel representation regularization mechanisms to improve the representation vectors for DRE. The experiments show that our model achieves state-of-the-art performance on two benchmark datasets. 1 Introduction An important task of Information Extraction is Relation Extraction (RE) that seeks to identify the semantic relationships between entities mentioned in text. The prior works have mainly focused on the intra-sentence scenario where the two entity mentions appear in the same sentences (Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2015). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distan"
2020.findings-emnlp.411,D17-1321,0,0.0243344,"in the images are not necessarily covered in their full details. Consequently, in this work, we seek to fill in this gap for IC by exploring personality image captioning (PIC) where the models need to further consider a personality/trait in the captioning process. In particular, we leverage PERSONALITY-CAPTIONS (PC) (Shuster et al., 2019), the first dataset for PIC, to evaluate the models in this work. Which characteristics should a caption have to adequately describe an image in PIC? Motivated by the functional and structural decomposition for language learning (Lazaridou et al., 2016, 2020; Kottur et al., 2017), we argue that an effective caption for PIC should posses two important properties. On the one hand, the captions in PIC should follow the natural language structures to induce effective communication with human (i.e., the structural view or naturalness of the captions). On the other hand, for the functional view, the generated captions from a model should involve sufficient information to enable another system or human to uniquely identify the input images and traits. In this paper, we propose to achieve these two goals by recasting PIC as a multi-agent communication framework that involves"
2020.findings-emnlp.411,P16-1162,0,0.00957698,"del with 20 epochs for the pre-training step and 3 epochs for the main training step using early stopping on the development data. In addition, we use the distilled version of GPT2 in (Sanh et al., 2019) for the GPT2 model in this work. The size of the transformer model in GPT2 follows (Sanh et al., 2019) where the number of layers is L = 6, the number of attention heads is 8, the dimensionality of the hidden vectors is d = 1024, and the dimension of the input embeddings (i.e., the segmentation embeddings, positional embeddings, and word embeddings) is 768. Finally, we use Byte Pair Encoding (Sennrich et al., 2016) to tokenize the captions in the dataset. 3.2 Comparing to the State of the Art We compare our proposed model (called GPTSpeaker) with the state-of-the-art models on the PC test data. In particular, we consider the following baselines (reported in Shuster et al. (2019)): (1) ShowTell: the encoder-decoder architecture (Vinyals et al., 2014), (2) ShowAttTell: a similar model to ShowTell where the visual feature vector is computed via attention (Xu et al., 2015), and (3) UpDown: an encoder-decoder model with two LSTM layers for the decoder (Shuster et al., 2019). UpDown, which is adapted from (An"
2020.findings-emnlp.411,2020.acl-main.685,0,0.0310499,"Missing"
2020.findings-emnlp.411,Q14-1006,0,0.0357364,"nerated captions from GPT-Speaker and UpDown are selected by the annotators (i.e., the win percentages). Table 3 shows the win percentages of GPT-Speaker and UpDown for the three tests. It is clear from the table that GPT-Speaker substantially outperforms UpDown in this human evaluation. This is significant with p < 0.005 (using a binomial two-tailed test), thus highlighting the advantage of GPT-Speaker to generate more engaging and relevant captions for PIC. Related Work The main approach for IC so far involves deep learning models where several datasets have been created (Chen et al., 2015; Young et al., 2014) and different variants of the encoder-decoder architectures have been proposed (Xu et al., 2015; Herdade et al., 2019; Su et al., 2019). PIC is a way to encourage more engaging captions for which several features are considered, i.e., location and age (Denton et al., 2015), reader’s active vocabulary (Park et al., 2017), humour (Yoshida et al., 2018), sentiment (Mathews et al., 2016), dialog/conversation (Zhang et al., 2018), and caption styles (Gan et al., 2017; Mathews et al., 2018). The closest work to ours is (Shuster et al., 2019) that examines a different feature of diverse personality"
2020.findings-emnlp.411,P18-1205,0,0.0222038,"ing and relevant captions for PIC. Related Work The main approach for IC so far involves deep learning models where several datasets have been created (Chen et al., 2015; Young et al., 2014) and different variants of the encoder-decoder architectures have been proposed (Xu et al., 2015; Herdade et al., 2019; Su et al., 2019). PIC is a way to encourage more engaging captions for which several features are considered, i.e., location and age (Denton et al., 2015), reader’s active vocabulary (Park et al., 2017), humour (Yoshida et al., 2018), sentiment (Mathews et al., 2016), dialog/conversation (Zhang et al., 2018), and caption styles (Gan et al., 2017; Mathews et al., 2018). The closest work to ours is (Shuster et al., 2019) that examines a different feature of diverse personality traits. Our work also bears some similarity with the previous IC models that attempts to improve the ability to discriminate images for the generated captions (Liu et al., 2018; Luo et al., 2018; Vered et al., 2019). However, these IC models do not capture personality traits for PIC as we do. We also note the stylized IC model in (Guo et al., 2019) that applies a style classification loss. However, this work does not consider"
2020.paclic-1.24,W14-4012,0,0.0471095,"Missing"
2020.paclic-1.24,D19-5610,0,0.195418,"irect source-target parallel corpus, but the approaches focus on generating pseudo-parallel corpus by using back-translation to translate sentences in the pivot language of the pivot-target parallel corpus to the source language (Lakew et al., 2017; Gu et al., 2019). One of the main limitations of these approaches is that the source between training and testing scenarios are different since the source in training is synthetic. However, the approaches still outperform pivot language and zero-shot NMT approaches because they can potentially utilize all available parallel and monolingual corpus (Currey and Heafield, 2019). In this work, our main contributions are (1) improving the quality of zero-resource NMT by introducing a simple iterative training-generatingfiltering-training process and (2) proposing a noise filtering method. Especially, we evaluate our approach on less-common and low-resource language pairs such as Khmer-Vietnamese. In this scenario, source-pivot (Khmer-English) and pivottarget (English-Vietnamese) pairs are also lowresource (pivot is often English). Our approach starts from a multilingual NMT system that is trained on source-pivot and pivot-language pairs, the system then generates sour"
2020.paclic-1.24,P19-1121,0,0.0188763,"lel data between the source and target languages during training. However, the performance of these approaches is still poor when the source and target languages are unrelated or the observed language pairs are not enough to capture the relation of unseen language pairs. Similar to the above approaches, zero-resource NMT approaches do not use any direct source-target parallel corpus, but the approaches focus on generating pseudo-parallel corpus by using back-translation to translate sentences in the pivot language of the pivot-target parallel corpus to the source language (Lakew et al., 2017; Gu et al., 2019). One of the main limitations of these approaches is that the source between training and testing scenarios are different since the source in training is synthetic. However, the approaches still outperform pivot language and zero-shot NMT approaches because they can potentially utilize all available parallel and monolingual corpus (Currey and Heafield, 2019). In this work, our main contributions are (1) improving the quality of zero-resource NMT by introducing a simple iterative training-generatingfiltering-training process and (2) proposing a noise filtering method. Especially, we evaluate ou"
2020.paclic-1.24,N03-1017,0,0.0411728,"then calculate the sentence similarity based on word alignment scores and the longest parallel phrase of the candidate sentence pairs. In order to acquire word alignments of a sentence pair (x, y), we iterate sentence x from left to right and greedily align each word in x to the most similar word in y which was not already aligned. For measuring the similarity of words we use cosine similarity of word embeddings. Afterward, given a set of word alignments A, we can easily extract parallel phrases of (x, y) by using the phrase extraction algorithm in the Statistical Machine Translation System (Koehn et al., 2003). Finally, the semantic similarity score of the sentence pair (x, y) is computed by averaging word alignment scores and weighting it with the ratio of the length of the longest parallel phrase p and the length of the sentence x as follows: P score(a) |p| sim(x, y) = × a⊂A (10) |x| |A| where |p |and |x |are the length of longest parallel phrase and sentence x respectively, |A |is the number of word alignments, a is a word alignment candidate and score(a) is word alignment score that is computed by using cosine similarity of two words in the alignment a. 5 Experiments 5.1 Dataset In this work, w"
2020.paclic-1.24,D18-2012,0,0.0143219,"Table 2: Experiment results on BLEU score to choose the right real:synthetic ratios for Khmer→English (km→en) and Indonesian→English (id→en) using back-translation (BT) and self-training (ST). final augmented data by combining the original data with back-translated and self-trained data as shown in Table 1. Note that, to prevent imbalances between language pairs in the multilingual training data, we did not augment for the English-Vietnamese pair since the size of this pair is much larger other pairs. 5.2 Preprocessing To learn a shared vocabulary for training multiNMT, we used SentencePiece (Kudo and Richardson, 2018) with size 32,000 over the combined English, Vietnamese, Khmer, and Indonesian monolingual data. Besides, we added target language tags at both the beginning and end of the source sentences in the multilingual training data. The multilingual word embedding model used in our filtering method was acquired by using the unsupervised method in MUSE library3 . The word embeddings for English, Vietnamese, Khmer, and Indonesian are trained with fastText toolkit4 on corresponding monolingual data. 3 4 https://github.com/facebookresearch/MUSE https://fasttext.cc/ All translation results shown in our wor"
2020.paclic-1.24,D15-1166,0,0.0800275,"Missing"
2020.paclic-1.24,W15-1521,0,0.0306685,"lating zi in (Z ↔ Y ) data to xi . We consider that (xi , yi ) is good synthetic sentence pair if xi is both semantically similar to yi and zi . A semantic score for each synthetic sentence xi is computed as below: score(xi ) = sim(xi , yi ) + sim(xi , zi ) 2 (9) where sim(xi , yi ) and sim(xi , zi ) are the semantic similarity of (xi , yi ) and (xi , zi ) sentence pair respectively. To compute the semantic similarity of two sentences in different languages, (Xu et al., 2019) relies on cosine similarities of sentence embedding vectors in a common vector space such as bilingual word embedding (Luong et al., 2015b). Our method first also embeds words in different languages into a common vector space as work in (Conneau et al., 2017), then calculate the sentence similarity based on word alignment scores and the longest parallel phrase of the candidate sentence pairs. In order to acquire word alignments of a sentence pair (x, y), we iterate sentence x from left to right and greedily align each word in x to the most similar word in y which was not already aligned. For measuring the similarity of words we use cosine similarity of word embeddings. Afterward, given a set of word alignments A, we can easily"
2020.paclic-1.24,P02-1040,0,0.114495,"Missing"
2020.paclic-1.24,P16-1009,0,0.0351937,"a better multi-NMT system with the synthetic data. Use this better system in order to generate new synthetic data, then use this data with the original training data to build an even better system. Finally, this cycle continues until the model converges. 4.1 Data Augmentation As mentioned above, if the amount of multilingual training data is too small, the multi-NMT system is unable to learn to translate between zero-shot directions. Hence, in our work, to augment the parallel data for (X ↔ Z) and (Z ↔ Y ), we leverage monolingual data in both target and source side by using back-translation (Sennrich et al., 2016) and self-training (Zhang and Zong, 2016). Given a parallel data (X ↔ Z) and monolingual data MX , MZ in → − − language X, Z respectively, we denote by f and ← g the forward (from X to Z) and the backward (from Z to X) NMT systems. Back-translation is a popular data augmentation method utilizing target side monolingual data. To perform back-translation, given the parallel data − (X ↔ Z), a base backward NMT system ← g is trained and use it to translate MZ to language X, de− noted by ← g (MZ ). The original parallel data (X ↔ Z) is then concatenated with the back-translated − data (← g (MZ ) ↔"
2020.paclic-1.24,I13-1143,0,0.0147362,"pectively, |A |is the number of word alignments, a is a word alignment candidate and score(a) is word alignment score that is computed by using cosine similarity of two words in the alignment a. 5 Experiments 5.1 Dataset In this work, we evaluate our approach on zero-resource Khmer-Vietnamese (km-vi) and Indonesian-Vietnamese (id-vi) language pairs with English is the pivot language. The parallel datasets for Khmer-English (km-en) and Indonesian-English (id-en) are from the Asian Language Treebank (ALT) Parallel Corpus (Riza et al., 2016) and for English-Vietnamese is from the UET dataset (Vu Huy et al., 2013) (see Table 1 for details). All testing datasets are from the ALT corpus with size of 1,018 sentences. In addition, we used monolingual data released in Wikipedia1 for Vietnamese, English and Indonesia and data from WMT20202 for Khmer. After de-duplication and removing too short (&lt;5 tokens) or too long (&gt;100 tokens) sentences, we obtained approximately 11 million, 5 million, 2 million and 3 million unique sentences for English, Vietnamese, Khmer, and Indonesian respectively. Moreover, as mentioned in Section 4.1, before training models, we augmented the multilingual training data by using back"
2020.paclic-1.24,D16-1160,0,0.0221935,"ic data. Use this better system in order to generate new synthetic data, then use this data with the original training data to build an even better system. Finally, this cycle continues until the model converges. 4.1 Data Augmentation As mentioned above, if the amount of multilingual training data is too small, the multi-NMT system is unable to learn to translate between zero-shot directions. Hence, in our work, to augment the parallel data for (X ↔ Z) and (Z ↔ Y ), we leverage monolingual data in both target and source side by using back-translation (Sennrich et al., 2016) and self-training (Zhang and Zong, 2016). Given a parallel data (X ↔ Z) and monolingual data MX , MZ in → − − language X, Z respectively, we denote by f and ← g the forward (from X to Z) and the backward (from Z to X) NMT systems. Back-translation is a popular data augmentation method utilizing target side monolingual data. To perform back-translation, given the parallel data − (X ↔ Z), a base backward NMT system ← g is trained and use it to translate MZ to language X, de− noted by ← g (MZ ). The original parallel data (X ↔ Z) is then concatenated with the back-translated − data (← g (MZ ) ↔ MZ ) to obtain a new training data. Self-"
2021.eacl-demos.10,N19-1388,0,0.0237634,"ll efficient in memory usage and speed. This is achieved by our novel plugand-play mechanism with Adapters where a multilingual pretrained transformer is shared across pipelines for different languages. Our toolkit along with pretrained models and code are publicly available at: https: //github.com/nlp-uoregon/trankit. A demo website for our toolkit is also available at: http://nlp.uoregon.edu/trankit. Finally, we create a demo video for Trankit at: https://youtu.be/q0KGP3zGjGc. 1 Introduction Many efforts have been devoted to developing multilingual NLP systems to overcome language barriers (Aharoni et al., 2019; Liu et al., 2019a; Taghizadeh and Faili, 2020; Zhu, 2020; Kanayama and Iwamoto, 2020; Nguyen and Nguyen, 2021). A large portion of existing multilingual systems has focused on downstream NLP tasks that critically depend on upstream linguistic features, ranging from basic information such as token and sentence boundaries for raw text to more sophisticated structures such as part-of-speech tags, morphological 1 https://spacy.io/ 80 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, pages 80–90 April 19 - 23, 2021."
2021.eacl-demos.10,2020.lrec-1.500,0,0.0398918,"ay mechanism with Adapters where a multilingual pretrained transformer is shared across pipelines for different languages. Our toolkit along with pretrained models and code are publicly available at: https: //github.com/nlp-uoregon/trankit. A demo website for our toolkit is also available at: http://nlp.uoregon.edu/trankit. Finally, we create a demo video for Trankit at: https://youtu.be/q0KGP3zGjGc. 1 Introduction Many efforts have been devoted to developing multilingual NLP systems to overcome language barriers (Aharoni et al., 2019; Liu et al., 2019a; Taghizadeh and Faili, 2020; Zhu, 2020; Kanayama and Iwamoto, 2020; Nguyen and Nguyen, 2021). A large portion of existing multilingual systems has focused on downstream NLP tasks that critically depend on upstream linguistic features, ranging from basic information such as token and sentence boundaries for raw text to more sophisticated structures such as part-of-speech tags, morphological 1 https://spacy.io/ 80 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, pages 80–90 April 19 - 23, 2021. ©2021 Association for Computational Linguistics Input: Raw Sentence/Document String J"
2021.eacl-demos.10,N19-4010,0,0.0647179,"Missing"
2021.eacl-demos.10,benikova-etal-2014-nosta,0,0.0157028,"h', gpu=True, cache_dir='./cache') doc = '''Hello! This is Trankit.''' # perform all tasks on the input all = p(doc) Figure 4: A function performing all tasks on the input. the XLM-Roberta encoder which is pretrained on those languages. Figure 6 illustrates how to train a token and sentence splitter with TPipeline. Demo Website. A demo website for Trankit to support 90 pretrained pipelines is hosted at: http: //nlp.uoregon.edu/trankit. Figure 7 shows its interface. 5 5.1 Figure 5: Output from Trankit. Some parts are collapsed to improve visualization. System Evaluation der, 2003), GermEval14 (Benikova et al., 2014), OntoNotes (Weischedel et al., 2013), and WikiNER (Nothman et al., 2012). Hyper-parameters for all models and datasets are selected based on the development data in this work. Datasets & Hyper-parameters To achieve a fair comparison, we follow Stanza (Qi et al., 2020) to train and evaluate all the models on the same canonical data splits of 90 Universal Dependencies treebanks v2.5 (UD2.5)3 (Zeman et al., 2019), and 11 public NER datasets provided in the following corpora: AQMAR (Mohit et al., 2012), CoNLL02 (Tjong Kim Sang, 2002), CoNLL03 (Tjong Kim Sang and De Meul5.2 Universal Dependencies"
2021.eacl-demos.10,D19-1279,0,0.125567,"ssing Minh Van Nguyen, Viet Lai, Amir Pouran Ben Veyseh, Thien Huu Nguyen Department of Computer and Information Science University of Oregon, Eugene, Oregon, USA {minhnv,vietl,apouranb,thien}@cs.uoregon.edu Abstract features, and dependency trees of sentences (called fundamental NLP tasks). As such, building effective multilingual systems/pipelines for fundamental upstream NLP tasks to produce such information has the potentials to transform multilingual downstream systems. There have been several NLP toolkits that concerns multilingualism for fundamental NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performan"
2021.eacl-demos.10,Q17-1010,0,0.037994,"ntal NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performance for many languages. However, Stanza and UDPipe’s pipelines for different languages are trained separately and do not share any component, especially the embedding layers that account for most of the model size. This makes their memory usage grow aggressively as pipelines for more languages are simultaneously needed and loaded into the memory (e.g., for language learning apps). Most importantly, none of such toolkits have explored contextualized embeddings from pretrained transformer-based language models that have the potentials to significantly"
2021.eacl-demos.10,P18-1007,0,0.0228726,"ork architecture of an adapter. boxes) are fixed and only the adapter weights of two projection layers and the task-specific weights outside the transformer (for final predictions) are updated. As demonstrated in Figure 1, Trankit involves six components described as follows. Multilingual Encoder with Adapters. This is our core component that is shared across different transformer-based components for different languages of the system. Given an input raw text s, we first split it into substrings by spaces. Afterward, Sentence Piece, a multilingual subword tokenizer (Kudo and Richardson, 2018; Kudo, 2018), is used to further split each substring into wordpieces. By concatenating wordpiece sequences for substrings, we obtain an overall sequence of wordpieces w = [w1 , w2 , . . . , wK ] for s. In the next step, w is fed into the pretrained transformer, which is already integrated with adapters, to obtain the wordpiece representations: l,m xl,m 1:K = Transformer(w1:K ; θAD ) Design and Architecture (2) l,m Here, θAD represents the adapter weights for language l and component m of the system. As such, we have specific adapters in all transformer layers for each component m and language l. Note tha"
2021.eacl-demos.10,D18-2012,0,0.0264541,"rmer layer. Right: the network architecture of an adapter. boxes) are fixed and only the adapter weights of two projection layers and the task-specific weights outside the transformer (for final predictions) are updated. As demonstrated in Figure 1, Trankit involves six components described as follows. Multilingual Encoder with Adapters. This is our core component that is shared across different transformer-based components for different languages of the system. Given an input raw text s, we first split it into substrings by spaces. Afterward, Sentence Piece, a multilingual subword tokenizer (Kudo and Richardson, 2018; Kudo, 2018), is used to further split each substring into wordpieces. By concatenating wordpiece sequences for substrings, we obtain an overall sequence of wordpieces w = [w1 , w2 , . . . , wK ] for s. In the next step, w is fed into the pretrained transformer, which is already integrated with adapters, to obtain the wordpiece representations: l,m xl,m 1:K = Transformer(w1:K ; θAD ) Design and Architecture (2) l,m Here, θAD represents the adapter weights for language l and component m of the system. As such, we have specific adapters in all transformer layers for each component m and languag"
2021.eacl-demos.10,2020.acl-main.747,0,0.432414,"t languages are trained separately and do not share any component, especially the embedding layers that account for most of the model size. This makes their memory usage grow aggressively as pipelines for more languages are simultaneously needed and loaded into the memory (e.g., for language learning apps). Most importantly, none of such toolkits have explored contextualized embeddings from pretrained transformer-based language models that have the potentials to significantly improve the performance of the NLP tasks, as demonstrated in many prior works (Devlin et al., 2019; Liu et al., 2019b; Conneau et al., 2020). In this paper, we introduce Trankit, a multilingual Transformer-based NLP Toolkit that overWe introduce Trankit, a light-weight Transformer-based Toolkit for multilingual Natural Language Processing (NLP). It provides a trainable pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained pipelines for 56 languages. Built on a state-of-the-art pretrained language model, Trankit significantly outperforms prior multilingual NLP pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsing while maintaining competitive performan"
2021.eacl-demos.10,D19-1068,0,0.143853,"Missing"
2021.eacl-demos.10,N19-1423,0,0.0559401,"anza and UDPipe’s pipelines for different languages are trained separately and do not share any component, especially the embedding layers that account for most of the model size. This makes their memory usage grow aggressively as pipelines for more languages are simultaneously needed and loaded into the memory (e.g., for language learning apps). Most importantly, none of such toolkits have explored contextualized embeddings from pretrained transformer-based language models that have the potentials to significantly improve the performance of the NLP tasks, as demonstrated in many prior works (Devlin et al., 2019; Liu et al., 2019b; Conneau et al., 2020). In this paper, we introduce Trankit, a multilingual Transformer-based NLP Toolkit that overWe introduce Trankit, a light-weight Transformer-based Toolkit for multilingual Natural Language Processing (NLP). It provides a trainable pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained pipelines for 56 languages. Built on a state-of-the-art pretrained language model, Trankit significantly outperforms prior multilingual NLP pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsi"
2021.eacl-demos.10,2021.ccl-1.108,0,0.0638997,"Missing"
2021.eacl-demos.10,P14-5010,0,0.00479643,"Nguyen Department of Computer and Information Science University of Oregon, Eugene, Oregon, USA {minhnv,vietl,apouranb,thien}@cs.uoregon.edu Abstract features, and dependency trees of sentences (called fundamental NLP tasks). As such, building effective multilingual systems/pipelines for fundamental upstream NLP tasks to produce such information has the potentials to transform multilingual downstream systems. There have been several NLP toolkits that concerns multilingualism for fundamental NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performance for many languages. However, Stanza and UDPipe’s pipeline"
2021.eacl-demos.10,2020.emnlp-demos.7,0,0.200879,"Missing"
2021.eacl-demos.10,2020.emnlp-main.617,0,0.0701328,"Missing"
2021.eacl-demos.10,E12-1017,0,0.0185113,"Some parts are collapsed to improve visualization. System Evaluation der, 2003), GermEval14 (Benikova et al., 2014), OntoNotes (Weischedel et al., 2013), and WikiNER (Nothman et al., 2012). Hyper-parameters for all models and datasets are selected based on the development data in this work. Datasets & Hyper-parameters To achieve a fair comparison, we follow Stanza (Qi et al., 2020) to train and evaluate all the models on the same canonical data splits of 90 Universal Dependencies treebanks v2.5 (UD2.5)3 (Zeman et al., 2019), and 11 public NER datasets provided in the following corpora: AQMAR (Mohit et al., 2012), CoNLL02 (Tjong Kim Sang, 2002), CoNLL03 (Tjong Kim Sang and De Meul5.2 Universal Dependencies performance Table 1 compares the performance of Trankit and the latest available versions of other popular toolkits, including Stanza (v1.1.1) with current stateof-the-art performance, UDPipe (v1.2), and spaCy (v2.3) on the UD2.5 test sets. The performance for all systems is obtained using the official scorer 3 We skip 10 treebanks whose languages are not supported by XLM-Roberta. 84 System Trankit (plug-and-play with adapters) Multilingual No-adapters Tokens 99.05 96.69 95.06 Sents. 95.12 88.95 89."
2021.eacl-demos.10,2020.acl-demos.14,0,0.28296,"ersity of Oregon, Eugene, Oregon, USA {minhnv,vietl,apouranb,thien}@cs.uoregon.edu Abstract features, and dependency trees of sentences (called fundamental NLP tasks). As such, building effective multilingual systems/pipelines for fundamental upstream NLP tasks to produce such information has the potentials to transform multilingual downstream systems. There have been several NLP toolkits that concerns multilingualism for fundamental NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performance for many languages. However, Stanza and UDPipe’s pipelines for different languages are trained separately and"
2021.eacl-demos.10,2019.nsurl-1.4,0,0.0901258,"Missing"
2021.eacl-demos.10,2020.findings-emnlp.92,0,0.0355468,"Missing"
2021.eacl-demos.10,2021.wanlp-1.27,1,0.682957,"Missing"
2021.eacl-demos.10,P19-1452,0,0.0317287,"component, the corresponding trained adapter and task-specific weights are activated and plugged into the pipeline to process the input. This mechanism not only solves the memory problem but also substantially reduces the training time. Add & Norm Adapter FF Up Add & Norm Feed-forward FF Down Adapter 2 Add & Norm Related Work Multi-Head Attention There have been works using pre-trained transformers to build models for character-based word segmentation for Chinese (Yang, 2019; Tian et al., 2020; Che et al., 2020); POS tagging for Dutch, English, Chinese, and Vietnamese (de Vries et al., 2019; Tenney et al., 2019; Tian et al., 2020; Che et al., 2020; Nguyen and Nguyen, 2020); morphological feature tagging for Estonian and Persian (Kittask et al., 2020; Mohseni and Tebbifakhr, 2019); and dependency parsing for English and Chinese (Tenney et al., 2019; Che et al., 2020). However, all of these works are only developed for some specific language, thus potentially unable to support and scale to the multilingual setting. Some works have designed multilingual transformer-based systems via multilingual training on the combined data of different languages (Tsai et al., 2019; Kondratyuk and Straka, 2019; ¨ un e"
2021.eacl-demos.10,2020.lrec-1.497,0,0.0620223,"Missing"
2021.eacl-demos.10,2020.acl-main.735,0,0.0134215,"rks well for 56 languages. Figure 1 presents the overall architecture of Trankit pipeline that features three novel 81 component, the corresponding trained adapter and task-specific weights are activated and plugged into the pipeline to process the input. This mechanism not only solves the memory problem but also substantially reduces the training time. Add & Norm Adapter FF Up Add & Norm Feed-forward FF Down Adapter 2 Add & Norm Related Work Multi-Head Attention There have been works using pre-trained transformers to build models for character-based word segmentation for Chinese (Yang, 2019; Tian et al., 2020; Che et al., 2020); POS tagging for Dutch, English, Chinese, and Vietnamese (de Vries et al., 2019; Tenney et al., 2019; Tian et al., 2020; Che et al., 2020; Nguyen and Nguyen, 2020); morphological feature tagging for Estonian and Persian (Kittask et al., 2020; Mohseni and Tebbifakhr, 2019); and dependency parsing for English and Chinese (Tenney et al., 2019; Che et al., 2020). However, all of these works are only developed for some specific language, thus potentially unable to support and scale to the multilingual setting. Some works have designed multilingual transformer-based systems via m"
2021.eacl-demos.10,W02-2024,0,0.249791,"alization. System Evaluation der, 2003), GermEval14 (Benikova et al., 2014), OntoNotes (Weischedel et al., 2013), and WikiNER (Nothman et al., 2012). Hyper-parameters for all models and datasets are selected based on the development data in this work. Datasets & Hyper-parameters To achieve a fair comparison, we follow Stanza (Qi et al., 2020) to train and evaluate all the models on the same canonical data splits of 90 Universal Dependencies treebanks v2.5 (UD2.5)3 (Zeman et al., 2019), and 11 public NER datasets provided in the following corpora: AQMAR (Mohit et al., 2012), CoNLL02 (Tjong Kim Sang, 2002), CoNLL03 (Tjong Kim Sang and De Meul5.2 Universal Dependencies performance Table 1 compares the performance of Trankit and the latest available versions of other popular toolkits, including Stanza (v1.1.1) with current stateof-the-art performance, UDPipe (v1.2), and spaCy (v2.3) on the UD2.5 test sets. The performance for all systems is obtained using the official scorer 3 We skip 10 treebanks whose languages are not supported by XLM-Roberta. 84 System Trankit (plug-and-play with adapters) Multilingual No-adapters Tokens 99.05 96.69 95.06 Sents. 95.12 88.95 89.57 Words 98.96 96.35 94.08 UPOS"
2021.eacl-demos.10,W19-4302,0,0.04269,"Missing"
2021.eacl-demos.10,W03-0419,0,0.389165,"Missing"
2021.eacl-demos.10,2020.emnlp-main.180,0,0.0863549,"Missing"
2021.eacl-demos.4,W04-1213,0,0.154095,"RGANISM SUBSTANCE, SIMPLE CHEMICAL, TISSUE Entity Recognition We use biomedical entity recognition models specialized for predicting entity type and provided by SciSpacy (Neumann et al., 2019) (Table 1). Each of the models is trained on a different annotated corpus, thus, covers a different set of biomedical entities. By using multiple entity systems, we can obtain various specialized entity information: chemicals and diseases with BCD5CDR (Li et al., 2016), cell types, chemicals, proteins, and genes with CRAFT (Bada et al., 2012), cell lines, cell types, DNAs, RNAs, and proteins with JNLPBA (Collier and Kim, 2004), and cancer genetics with BioNLP13CG (Pyysalo et al., 2015). • ReVerb (Fader et al., 2011) tackles the problems of incoherent and uninformative extractions by introducing constraints on binary, verb-based relation phrases. • OLLIE (Mausam et al., 2012) addresses the problems that Open IE systems such as ReVerb only extract relations that are mediated by verbs. Not only by verbs, OLIEE extracts relations mediated also by nouns, adjectives, and more. 3.4 Relation Clustering We build a cluster hierarchy on a subset of the extracted relations (this subset contains all relations in which both arg1"
2021.eacl-demos.4,D11-1142,0,0.0957587,"tion models specialized for predicting entity type and provided by SciSpacy (Neumann et al., 2019) (Table 1). Each of the models is trained on a different annotated corpus, thus, covers a different set of biomedical entities. By using multiple entity systems, we can obtain various specialized entity information: chemicals and diseases with BCD5CDR (Li et al., 2016), cell types, chemicals, proteins, and genes with CRAFT (Bada et al., 2012), cell lines, cell types, DNAs, RNAs, and proteins with JNLPBA (Collier and Kim, 2004), and cancer genetics with BioNLP13CG (Pyysalo et al., 2015). • ReVerb (Fader et al., 2011) tackles the problems of incoherent and uninformative extractions by introducing constraints on binary, verb-based relation phrases. • OLLIE (Mausam et al., 2012) addresses the problems that Open IE systems such as ReVerb only extract relations that are mediated by verbs. Not only by verbs, OLIEE extracts relations mediated also by nouns, adjectives, and more. 3.4 Relation Clustering We build a cluster hierarchy on a subset of the extracted relations (this subset contains all relations in which both arg1 and arg2 are biomedical entities), so users can quickly find their interested relation exp"
2021.eacl-demos.4,P15-1034,0,0.0288929,"onnected phrases, not for identifying clause type like ClauseIE. We utilize FINCH (Sarfraz et al., 2019), hierarchical clustering method, and BERT (Devlin et al., 2019) for this task. First, BERT-Base model is used to encode each relation as a simple sentence “ arg1 rel arg2 ” into a 768-dimensional vector. Then, FINCH is used to build the cluster hierarchy. For each cluster, representative expressions of the cluster are selected from its rels from top informative relations scored by the formula presented in the next subsection. The result cluster hierarchy is illustrated in Fig. 3. • OpenIE (Angeli et al., 2015) extracts relations by breaking a long sentence into short, coherent clauses, and then finds the maximally simple relations. The extracted relations are also tagged with biomedical entities recognized by using entity recognition models presented in the next subsection. 26 Figure 3: Illustration of cluster hierarchy. “DISEASE-0-7”: the type of an entity contained in the arg1 is DISEASE, the id of the level 0 (root) cluster is 0, the id of the level 1 cluster is 7. An expression has the form of ENTITY TYPE (in arg1 , omitted) relation/verb phrase ENTITY TYPE (in arg2 ). Expressions are separated"
2021.eacl-demos.4,D12-1048,0,0.0533372,"ted corpus, thus, covers a different set of biomedical entities. By using multiple entity systems, we can obtain various specialized entity information: chemicals and diseases with BCD5CDR (Li et al., 2016), cell types, chemicals, proteins, and genes with CRAFT (Bada et al., 2012), cell lines, cell types, DNAs, RNAs, and proteins with JNLPBA (Collier and Kim, 2004), and cancer genetics with BioNLP13CG (Pyysalo et al., 2015). • ReVerb (Fader et al., 2011) tackles the problems of incoherent and uninformative extractions by introducing constraints on binary, verb-based relation phrases. • OLLIE (Mausam et al., 2012) addresses the problems that Open IE systems such as ReVerb only extract relations that are mediated by verbs. Not only by verbs, OLIEE extracts relations mediated also by nouns, adjectives, and more. 3.4 Relation Clustering We build a cluster hierarchy on a subset of the extracted relations (this subset contains all relations in which both arg1 and arg2 are biomedical entities), so users can quickly find their interested relation expressions or they can choose some clusters which may contain their interested relation expressions. • ClausIE (Del Corro and Gemulla, 2013) is a clause-based appro"
2021.eacl-demos.4,W19-5034,0,0.0213431,"ISSUE STRUCTURE, ORGANISM SUBDIVISION, PATHOLOGICAL FORMATION, 3.2 Relation Extraction 3.3 With the objective of extracting as many relations as possible, we employ several relation extraction methods. Each method has their own characteristics, thus, may extract different kinds of relations. By combining several methods, we can obtain higher extraction coverage. The methods are briefly described as follows. ORGAN, ORGANISM, ORGANISM SUBSTANCE, SIMPLE CHEMICAL, TISSUE Entity Recognition We use biomedical entity recognition models specialized for predicting entity type and provided by SciSpacy (Neumann et al., 2019) (Table 1). Each of the models is trained on a different annotated corpus, thus, covers a different set of biomedical entities. By using multiple entity systems, we can obtain various specialized entity information: chemicals and diseases with BCD5CDR (Li et al., 2016), cell types, chemicals, proteins, and genes with CRAFT (Bada et al., 2012), cell lines, cell types, DNAs, RNAs, and proteins with JNLPBA (Collier and Kim, 2004), and cancer genetics with BioNLP13CG (Pyysalo et al., 2015). • ReVerb (Fader et al., 2011) tackles the problems of incoherent and uninformative extractions by introducin"
2021.eacl-demos.4,2020.sdp-1.5,0,0.0281385,"D-19 outbreak, it is essential to grasp valuable knowledge from a huge number of COVID-19-related papers for dealing with the pandemic effectively. Sohrab et al. (2020) introduced the BENNERD system that detects named entities in biomedical text and links them to the unified medical language system (UMLS) to facilitate the COVID-19 research. Hope et al. (2020) created a dataset annotated for mechanism relations and trained an information extraction model on this data. Then, they used the model to extract a Knowledge Base (KB) of mechanism and effect relations from papers relating to COVID-19. Zhang et al. (2020) built Covidex, a search infrastructure that provides information access to the COVID-19 Open Research Dataset such as answering questions. Esteva et al. (2020) also presented Co-Search, a retriever-ranker semantic search engine designed to handle complex queries over the COVID-19 literature. Wang et al. (2020) created the EvidenceMiner web-based system. Given a query as a natural language statement, EvidenceMiner automatically retrieves sentence-level textual evidence from the CORD-19 corpus. Clearly, previous works made a great effort to acquire useful knowledge from the COVID-19 literature,"
2021.eacl-demos.4,2020.emnlp-demos.24,0,0.0957812,"Missing"
2021.emnlp-main.439,W06-0901,0,0.383101,"event to document context that can fit into the BERT types (event trigger words). For instance, in the length limit. The typical approaches involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major approaches from other NLP tasks can be"
2021.emnlp-main.439,P15-1017,0,0.175775,"tem needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major approaches from other NLP tasks can be considered: (1) Architecture Change for Self-Attention (Zaheer et al., 2020; Beltagy et al., 2020; Kitaev et al., 2020): In this group, the vanilla self-attention of transformer is replaced with some variant mechanism such as sparse selfattention (Zaheer et al., 2020) that can encode larger cont"
2021.emnlp-main.439,D18-1158,0,0.0578434,"4 78.12 ACE 2005 (WP) P R F1 EKD 79.10 78.00 78.60 73.42 78.68 75.96 70.91 79.38 74.91 72.84 79.46 76.01 70.31 80.98 75.27 74.39 79.07 76.66 79.32 73.24 76.16 76.19 79.70 77.91 75.13 83.51 79.10 CySecED P R F1 DEEB-RNN (word2vec) 68.40 72.18 54.95 62.40 71.77 60.23 65.50 71.42 56.32 62.98 70.13 55.54 61.99 70.70 57.12 63.19 72.91 54.43 62.33 62.64 58.30 66.71 75.14 65.57 70.03 Table 1: Performance of the models on ACE 2005 and CySecED test sets. SL and WP stands for sequence-labeling and word-classification. The proposed model is significantly better than baselines with p &lt; 0.01. ing HBTNGMA (Chen et al., 2018) that employs gated multi-level attention mechanism and DEEBRNN (BERT) (Zhao et al., 2018) that uses a bidirectional RNN for encoding the sentences of the documents. Note that as BERT is not originally used in these models, we use their provided implementations and inject the BERTbase model into the encoding components for a fairer comparison. Furthermore, we compare ED3C with other variants of pre-trained transformer-based language models capable of encoding input texts with longer length than BERTbase limit. Specifically, we consider three commonly used language models: BigBird (Zaheer et al"
2021.emnlp-main.439,2020.emnlp-main.435,1,0.900055,"ess of the proposed model, called Event Detection with Dynamic Document Context (ED3C), we evaluate its performance on two benchmark datasets ACE 2005 (Walker et al., 2006) and CySecED (Trong et al., 2020). We choose these two datasets as they provide documents that are much longer than the input length limit for BERTbase , thus being more suitable to our focus on document-context modeling for ED2 . We use full document context for the documents in these datasets. ACE 2005 annotates 599 documents for 33 event types. We use the same data split and preprocessing as prior work (Lin et al., 2020; Lai et al., 2020b; Tong et al., 2020) for this dataset. The numbers of documents for the training/test/validation data are 529/40/30 respectively. In prior work, the ED problem on ACE 2005 has been addressed via both the sequence-labeling (Wang et al., 2020b; Lin et al., 2020) and word-classification (Lai et al., 2020b; Tong et al., 2020) formulations. The sequencelabeling formulation adheres to the original annotation in ACE 2005 to allow multiple words in event triggers. The word-classification formulation, in contrast, simplifies the problem by only concerning the single most important words in event trigg"
2021.emnlp-main.439,2021.eacl-main.237,1,0.772918,"e trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learnable component for context seED in the low-shot learning settings to improve the lection in ED3C. Interestingly, selecting only right data efficiency of"
2021.emnlp-main.439,P13-1008,0,0.0335033,"ighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for c"
2021.emnlp-main.439,C10-1077,0,0.0467773,"at augment the target sentence Si with all neighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms"
2021.emnlp-main.439,P10-1081,0,0.0494868,"at augment the target sentence Si with all neighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms"
2021.emnlp-main.439,2020.acl-main.713,0,0.556362,"earch, Vietnam 3 Raytheon BBN Technologies, USA {apouranb,minhnv,thien}@cs.uoregon.edu, v.nghiant66@vinai.io,bonan.min@raytheon.com Abstract Nguyen et al., 2021). Similar to other NLP tasks, the current best systems for ED leverage Event Detection (ED) aims to recognize transformer-based language models, e.g., BERT and classify trigger words of events in (Devlin et al., 2019), as a critical encoding compotext. The recent progress has featured adnent to achieve state-of-the-art performance (Lai vanced transformer-based language models (e.g., BERT) as a critical component in stateet al., 2020b; Lin et al., 2020). As such, most of of-the-art models for ED. However, the length the current transformer-based models for ED only limit for input texts is a barrier for such focus on sentence-level context in which the scope ED models as they cannot encode long-range of context to predict event type for each word is document-level context that has been shown to limited to the host sentence (Lu et al., 2019; Wang be beneficial for ED. To address this issue, we et al., 2019). However, it has been shown that propose a novel method to model documentdocument-level context also provides important inlevel context wi"
2021.emnlp-main.439,P19-1429,0,0.0260634,"Missing"
2021.emnlp-main.439,2020.coling-main.78,0,0.239236,"ications events and classifying them into predefined event to document context that can fit into the BERT types (event trigger words). For instance, in the length limit. The typical approaches involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major a"
2021.emnlp-main.439,C14-1214,0,0.013261,"involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major approaches from other NLP tasks can be considered: (1) Architecture Change for Self-Attention (Zaheer et al., 2020; Beltagy et al., 2020; Kitaev et al., 2020): In this group, the vanilla"
2021.emnlp-main.439,2021.naacl-main.3,1,0.814374,"Missing"
2021.emnlp-main.439,N16-1034,1,0.834623,"tences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learn"
2021.emnlp-main.439,P15-2060,1,0.933277,"on module using the performance of BERT for ED as the reward. In addition, we introduce auxiliary rewards based on linguistic intuition (i.e., semantic and discourse relations between the input sentence Si and selected context sentences) to enhance the selection process. Our extensive experiments on benchmark datasets show that the proposed method can achieve state-of-theart results for ED on both the sequence-labeling and the word-classification formulations. 2 Model In the literature, ED has been formulated as sequence-labeling (Lin et al., 2020; Nguyen et al., 2021) or word-classification (Nguyen and Grishman, 2015) problems. In this work, we explore both formulations of the task. Formally, given the input sentence Si = [w1 , w2 , . . . , wn ] (with n words) from the document D = [S1 , S2 , . . . , SN ] (with N sentences), the goal is to recognize and To this end, to develop an effective BERT- classify event triggers in Si , leveraging the broader based document-level model for ED, our motiva- context in D. In the sequence-labeling formulation tion in this work is to explicitly select only im- (Lin et al., 2020), as event triggers are allowed to portant/relevant parts of a document for a given involve mu"
2021.emnlp-main.439,D09-1016,0,0.0598491,"r and “Neighbor Sentence”) that augment the target sentence Si with all neighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA dee"
2021.emnlp-main.439,2021.ccl-1.54,0,0.0473379,"Missing"
2021.emnlp-main.439,2020.acl-main.522,0,0.0199792,"model, called Event Detection with Dynamic Document Context (ED3C), we evaluate its performance on two benchmark datasets ACE 2005 (Walker et al., 2006) and CySecED (Trong et al., 2020). We choose these two datasets as they provide documents that are much longer than the input length limit for BERTbase , thus being more suitable to our focus on document-context modeling for ED2 . We use full document context for the documents in these datasets. ACE 2005 annotates 599 documents for 33 event types. We use the same data split and preprocessing as prior work (Lin et al., 2020; Lai et al., 2020b; Tong et al., 2020) for this dataset. The numbers of documents for the training/test/validation data are 529/40/30 respectively. In prior work, the ED problem on ACE 2005 has been addressed via both the sequence-labeling (Wang et al., 2020b; Lin et al., 2020) and word-classification (Lai et al., 2020b; Tong et al., 2020) formulations. The sequencelabeling formulation adheres to the original annotation in ACE 2005 to allow multiple words in event triggers. The word-classification formulation, in contrast, simplifies the problem by only concerning the single most important words in event triggers (Nguyen and Grish"
2021.emnlp-main.439,2021.acl-long.490,1,0.683626,"tly, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learnable component for context seED in the low-shot learning settings to improve the lection in ED3C. Interestingly, selecting only right data efficiency of the models (Lai et al., 2020a, or left context achieves better results than “Neigh2021). The majority of prior DL models for ED bor Sentences”. It suggests that important context are restricted to sentence-level context. In recent sentences might be far away from the target senyears, encoding document context with DL has"
2021.emnlp-main.439,P18-2066,0,0.2939,"el context in which the scope ED models as they cannot encode long-range of context to predict event type for each word is document-level context that has been shown to limited to the host sentence (Lu et al., 2019; Wang be beneficial for ED. To address this issue, we et al., 2019). However, it has been shown that propose a novel method to model documentdocument-level context also provides important inlevel context with BERT for ED that dynamically selects relevant sentences in the docuformation for deep learning models for ED (Chen ment for the event prediction of the target senet al., 2018; Zhao et al., 2018). For instance, in the tence. The target sentence will be then augdocument “The troops were retreating cautiously. mented with the selected sentences and conHe was shocked after he heard “Fire!"".”, to corsumed entirely by BERT for improved reprerectly predict Attack as the type of the event evoked sentation learning for ED. To this end, the REby “Fire” (i.e., avoiding the confusion with the INFORCE algorithm is employed to train the event type End-Position), it is necessary to consider relevant sentence selection for ED. Several inthe previous sentence with the important context formation type"
2021.emnlp-main.439,D19-1032,0,0.0252258,"Missing"
2021.emnlp-main.439,N19-1105,0,0.0294209,"Missing"
2021.emnlp-main.439,2020.emnlp-main.129,0,0.1737,"e input texts with up to 512 Event Detection (ED) is one of the fundamental sub-tokens (due to the quadratic self-attention comtasks for Information Extraction. Its goal is to plexity), current BERT-based document-level modidentify the word(s) in text that most clearly evoke els for ED has only constrained their applications events and classifying them into predefined event to document context that can fit into the BERT types (event trigger words). For instance, in the length limit. The typical approaches involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further"
2021.emnlp-main.439,N16-1033,0,0.0166467,"Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al.,"
2021.emnlp-main.439,P19-1522,0,0.0150764,"texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learnable component for context seED in the low-shot learning settings to improve the lection in ED3C. Interestingl"
2021.emnlp-main.440,2020.acl-main.554,0,0.0123433,"the target language to improve the cross-lingual representations for REE. This section presents the typical approaches for leveraging unlabeled target language data for crosslingual transfer learning in NLP, offering additional baselines for our proposed model later. Language Adversarial Training (LADV): To leverage unlabeled data in the target language, this method introduces a language discriminator that receives representation vectors for input sentences and predicts the language identity (i.e., source or target) of the sentences (Chen et al., 2019; Huang et al., 2019; Keung et al., 2019; Cao et al., 2020). As such, given an REE task t ∈ {ED, RE, EAE}, the method seeks to jointly train a model for t (i.e., those described in Section 3.1) and the language 4 Proposed Method discriminator so that the induced representation 4.1 Class-based Alignment vectors for t can contain necessary information for the predictions in t and be language-agnostic to An overview for the proposed model is shown in better transfer knowledge across languages at the Figure 1. As described in the introduction, to avoid same time. the potential cross-class alignment of representaTo implement this method, we first obtain a"
2021.emnlp-main.440,P19-1299,0,0.108687,"REE. ample of a different class. To address this However, previous work on crosslingual REE issue, we propose a novel crosslingual alignsuffers from the monolingual bias issue due to the ment method that leverages class information of REE tasks for representation learning. In monolingual training of models on only the source particular, we propose to learn two versions language data, leading to non-optimal crosslingual of representation vectors for each class in an performance. A solution for this issue can resort REE task based on either source or target lanto language adversarial training (Chen et al., 2019; guage examples. Representation vectors for Huang et al., 2019; Keung et al., 2019; Lange et al., corresponding classes will then be aligned to 2020; He et al., 2020) where unlabeled data in achieve class-aware alignment for crosslingual the target language is used to aid crosslingual reprepresentations. In addition, we propose to further align representation vectors for languageresentations via fooling a language discriminator. universal word categories (i.e., parts of speech The underlying principle for this approach is to and dependency relations). As such, a novel encourage the closeness"
2021.emnlp-main.440,P15-1017,0,0.053443,"ferent classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due t"
2021.emnlp-main.440,N19-1423,0,0.0142691,"from Ldisc . Overall, fooling the language discriminator in LADV with GRL eliminates languagespecific features to improve generalization across languages for t. mBERT Finetuning (FMBERT): Recently, it has been shown that fine-tuning multilingual pretrained language models on unlabeled data of the target language can improve the crosslingual performance for NLP tasks (Pfeiffer et al., 2020). Motivated by such prior work, this baseline exploits the unlabeled data in the target language for cross-lingual representation learning by fine-tuning mBERT on the data using mask language modeling (MLM) (Devlin et al., 2019). Afterward, the finetuned mBERT model is utilized in the encoders for the baseline models for REE tasks in Section 3.1. To avoid the monolingual bias in the cross-lingual methods for REE in Section 3.1, our work aims to exploit unlabeled data in the target language to improve the cross-lingual representations for REE. This section presents the typical approaches for leveraging unlabeled target language data for crosslingual transfer learning in NLP, offering additional baselines for our proposed model later. Language Adversarial Training (LADV): To leverage unlabeled data in the target langua"
2021.emnlp-main.440,I17-2072,1,0.832228,"ed Research Projects Activet al., 2020; He et al., 2020). Unfortunately, LADV suffers from the cross-class alignment issue, mak- ity (IARPA), via IARPA Contract No. 2019ing it less optimal for crosslingual REE. Finally, we 19051600006 under the Better Extraction from Text note that language-universal representation learn- Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are ing is related to domain adaption research where models seek to learn domain-invariant representa- those of the authors and should not be interpreted tions (Ganin and Lempitsky, 2015; Fu et al., 2017; as necessarily representing the official policies, eiAdel et al., 2017; Xie et al., 2018; Cicek and Soatto, ther expressed or implied, of ARO, ODNI, IARPA, the Department of Defense, or the U.S. Govern2019; Tang et al., 2020; Ngo et al., 2021). ment. The U.S. Government is authorized to reproduce and distribute reprints for governmental 7 Conclusions purposes notwithstanding any copyright annotation We present a novel method for crosslingual transfer therein. This document does not contain technollearning for REE that leverages unlabeled data in ogy or technical data controlled under either"
2021.emnlp-main.440,N19-1383,0,0.29477,"vious work on crosslingual REE issue, we propose a novel crosslingual alignsuffers from the monolingual bias issue due to the ment method that leverages class information of REE tasks for representation learning. In monolingual training of models on only the source particular, we propose to learn two versions language data, leading to non-optimal crosslingual of representation vectors for each class in an performance. A solution for this issue can resort REE task based on either source or target lanto language adversarial training (Chen et al., 2019; guage examples. Representation vectors for Huang et al., 2019; Keung et al., 2019; Lange et al., corresponding classes will then be aligned to 2020; He et al., 2020) where unlabeled data in achieve class-aware alignment for crosslingual the target language is used to aid crosslingual reprepresentations. In addition, we propose to further align representation vectors for languageresentations via fooling a language discriminator. universal word categories (i.e., parts of speech The underlying principle for this approach is to and dependency relations). As such, a novel encourage the closeness of representation vectors filtering mechanism is presented to f"
2021.emnlp-main.440,D18-1330,0,0.0282069,", Eugene, OR, USA 2 Raytheon BBN Technologies, USA 3 VinAI Research, Vietnam {minhnv,tnguyen,thien}@cs.uoregon.edu, bonan.min@raytheon.com Abstract REE in which a model is trained on a language, i.e., source language, and applied to another lanPrevious work on crosslingual Relation and guage, i.e., target language, where the annotations Event Extraction (REE) suffers from the monoare not available. Recent approaches for crosslinlingual bias issue due to the training of models gual REE have mainly employed multilingual word on only the source language data. An approach embeddings, e.g., MUSE, (Joulin et al., 2018; Ni to overcome this issue is to use unlabeled data and Florian, 2019; Liu et al., 2019; Subburathinam in the target language to aid the alignment of et al., 2019) or multilingual pre-trained language crosslingual representations, i.e., via fooling a language discriminator. However, as this apmodels, e.g., multilingual BERT, (Devlin et al., proach does not condition on class informa2019; M’hamdi et al., 2019; Ahmad et al., 2021; tion, a target language example of a class could Nguyen and Nguyen, 2021) to learn crosslingual be incorrectly aligned to a source language exrepresentation vectors f"
2021.emnlp-main.440,D19-1138,0,0.323614,"ingual REE issue, we propose a novel crosslingual alignsuffers from the monolingual bias issue due to the ment method that leverages class information of REE tasks for representation learning. In monolingual training of models on only the source particular, we propose to learn two versions language data, leading to non-optimal crosslingual of representation vectors for each class in an performance. A solution for this issue can resort REE task based on either source or target lanto language adversarial training (Chen et al., 2019; guage examples. Representation vectors for Huang et al., 2019; Keung et al., 2019; Lange et al., corresponding classes will then be aligned to 2020; He et al., 2020) where unlabeled data in achieve class-aware alignment for crosslingual the target language is used to aid crosslingual reprepresentations. In addition, we propose to further align representation vectors for languageresentations via fooling a language discriminator. universal word categories (i.e., parts of speech The underlying principle for this approach is to and dependency relations). As such, a novel encourage the closeness of representation vectors filtering mechanism is presented to facilitate for senten"
2021.emnlp-main.440,2020.repl4nlp-1.14,0,0.017951,"od achieves SOTA performance for three REE tasks in different crosslingual settings. In the future, we plan to extend our methods to related problems in IE (e.g., coreference resolution). Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-21-1-0112 and the NSF grant CNS-1747798 to the IUCRC Center for Big Learning. This research is unlabeled data in the target language to perform crosslingual representation alignment (Chen et al., also based upon work supported by the Office of the Director of National Intelligence (ODNI), 2019; Huang et al., 2019; Lange et al., 2020; Cao Intelligence Advanced Research Projects Activet al., 2020; He et al., 2020). Unfortunately, LADV suffers from the cross-class alignment issue, mak- ity (IARPA), via IARPA Contract No. 2019ing it less optimal for crosslingual REE. Finally, we 19051600006 under the Better Extraction from Text note that language-universal representation learn- Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are ing is related to domain adaption research where models seek to learn domain-invariant representa- those of the authors and should not be interpreted tions (Ga"
2021.emnlp-main.440,P13-1008,0,0.0246106,"ue by pushing representations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021"
2021.emnlp-main.440,R11-1002,0,0.0153547,"LADV can address this issue by pushing representations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen"
2021.emnlp-main.440,2020.acl-main.713,0,0.024048,"on on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV has discussed earlier, a"
2021.emnlp-main.440,D19-1068,0,0.0296773,"Missing"
2021.emnlp-main.440,K19-1061,0,0.0407902,"Missing"
2021.emnlp-main.440,2021.findings-acl.351,1,0.755762,"Missing"
2021.emnlp-main.440,2021.naacl-main.3,1,0.849686,"Missing"
2021.emnlp-main.440,2021.eacl-demos.10,1,0.727369,"Missing"
2021.emnlp-main.440,2021.wanlp-1.27,1,0.887473,"Missing"
2021.emnlp-main.440,P19-1423,0,0.0133095,"ettings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In ot"
2021.emnlp-main.440,K18-2020,0,0.0145777,"e cross-lingual alignment We conduct extensive experiments with differfor representation vectors in REE. As such univer- ent crosslingual settings on English, Chinese, and sal word categories have been consistently anno- Arabic for three REE tasks, i.e., Relation Extractated for more than 100 languages (Zeman et al., tion, Event Detection, and Event Argument Extrac2020) and can be generated with high accuracy tion. The results demonstrate the benefits of the via existing toolkits, e.g., the transformer-based proposed method that significantly advances the toolkit Trankit for multilingual NLP (Straka, 2018; state-of-the-art performance in these settings. 5415 2 Problem Statement We study cross-lingual transfer learning for three REE tasks as defined in the ACE 2005 dataset (Walker et al., 2006), i.e., Relation Extraction (RE), Event Detection (ED), and Event Argument Extraction (EAE). Given two entity mentions in an input sentence, the goal of RE is to determine the semantic relationship between the mentions according to predefined relation types/classes (e.g., Employment). For ED, its purpose is to identify event triggers, which can be verbs/normalization with one or multiple words, that expre"
2021.emnlp-main.440,K17-3009,0,0.0159522,"ions by RE EAE sending the score vectors sED tgt,k , stgt , and stgt ED to a softmax layer: ˆ yED tgt,k = softmax(stgt,k ), and ˆyttgt = softmax(sttgt ) (for t = RE or EAE). As such, we obtain the target-language representation for l via the weighted sum of rttgt (for RE and EAE): 4.2 Word Category-based Alignment We further exploit universal parts of speech (UPOS) and dependency relations as the language-agnostic knowledge to align crosslingual representations for REE. To achieve a fair comparison with prior work (Subburathinam et al., 2019; Ahmad et al., 2021), we employ the UDPipe toolkit (Straka and Straková, 2017) to obtain parts of speech and dependency relations for the sentences. Due to their similarity, we will only describe the UPOS-based alignment process and the dependency-based alignment can be done in the same way. As such, we utilize an embedding table U (initialized randomly) to capture representation vectors for the possible UPOS, serving as an anchor knowledge across languages. Next, to facilitate the UPOS-based representation alignment, we comP t t ˆ y r tgt tgt,l x ∈D tgt tgt pute additional representation vectors for UPOS cttgt,l = P (5) ˆt xtgt ∈Dtgt ytgt,l based on representation vect"
2021.emnlp-main.440,N16-1034,1,0.8894,"unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance o"
2021.emnlp-main.440,D19-1030,0,0.241678,"Missing"
2021.emnlp-main.440,P15-2060,1,0.81307,"tions for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the mon"
2021.emnlp-main.440,D19-1038,0,0.0264843,"t to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV has discussed earlier, a major issue for LADV is that been explored to address this issue by leveraging 5421 a) GATE+CCCAR 80 b) GATE+LADV 0 1 2 3 4 40 0 1 2 3 4"
2021.emnlp-main.440,D09-1016,0,0.0508587,"esentation alignment in GATE+LADV can address this issue by pushing representations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (A"
2021.emnlp-main.440,2020.emnlp-main.617,0,0.0460523,"Missing"
2021.emnlp-main.440,2020.acl-demos.14,0,0.0254322,". 2021 Association for Computational Linguistics Class-aware Alignment Averaging Target Lang Source Lang Class Representations Class Representations FFN ... Contextualized Embeddings Epoch-level Path Transformer ... Dsrc={(xsrc , ysrc)} UPOS/DEP Representation Alignment MBERT D={(x )} tgt tgt Lcls Lpos/dep Word Classifier Gradient Reversal Layer t align ctx Lpos/dep Task Classifier t L Example Representations Figure 1: Overall architecture of the proposed models for RE, EAE. For ED, example representations are the contextualized embeddings. erally invariant across languages that can be lever- Qi et al., 2020; Nguyen et al., 2021b), we expect aged as anchors to bridge representation vectors for this information to provide helpful anchor knowlexamples in different languages. As such, we can edge for cross-lingual representation learning. To obtain two semantic representation vectors for each this end, similar to the class-aware alignment, we class in an REE task based on representation vec- propose to align representation vectors of the same tors of examples in either source or target language. universal word categories that are computed using Afterward, the representation vectors of the same conte"
2021.emnlp-main.440,2020.acl-main.715,1,0.735548,"ue to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV h"
2021.emnlp-main.440,2020.findings-emnlp.326,1,0.720993,"ue to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV h"
2021.emnlp-main.440,D19-1584,0,0.0116059,"imal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Propo"
2021.emnlp-main.440,N16-1033,0,0.0144251,"resentations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental"
2021.emnlp-main.440,N10-1000,0,0.0435046,"Missing"
2021.findings-acl.211,W06-0901,0,0.117514,"NLP for historical texts has mainly focused on spelling and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 2020c; Nguyen et al., 2021). Some recent studies in EE have also addressed extensible learning settings for EE to new event types, e.g. zero-shot learning (Huang et al., 2018), fewshot learning (Lai et al., 2020a,b), or new domains (Naik and Ros´e, 2020). The closet works to ours involve recent efforts to create new datasets for EE (Satyapanich et al., 2020; Ebner et al., 2020; Wang et al., 2020; Trong et al., 2020; Le and Nguyen, 2021). However, these works"
2021.findings-acl.211,P17-1031,0,0.0161853,"2005. The BRAD# columns report the performance with BERT fine-tuned on the African American corpus. history, thus impairing the models and requiring appropriate adaptation to boost the EE performance. Finally, we note that the human performance (F1 scores) for Entity, Trig-C, and Arg-C on BRAD are 95.43, 88.3, and 79.8 respectively. The large performance gaps between human and current EE systems thus presents many research opportunities for future work on BRAD. 4 Related work Prior work in NLP for historical texts has mainly focused on spelling and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al."
2021.findings-acl.211,P15-1017,0,0.0143508,"g and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 2020c; Nguyen et al., 2021). Some recent studies in EE have also addressed extensible learning settings for EE to new event types, e.g. zero-shot learning (Huang et al., 2018), fewshot learning (Lai et al., 2020a,b), or new domains (Naik and Ros´e, 2020). The closet works to ours involve recent efforts to create new datasets for EE (Satyapanich et al., 2020; Ebner et al., 2020; Wang et al., 2020; Trong et al., 2020; Le and Nguyen, 2021). However, these works do not consider historical texts as we do. 5 Acknowledgement T"
2021.findings-acl.211,N19-1423,0,0.0126723,"age models to better capture the nature of historical texts which, in turn, will facilitate a more accurate performance of EE. 3 Experiment There are three major EE tasks that BRAD supports for historical texts, including entity mention detection (EMD), event trigger detection (ED), and event argument extraction (EAE). This section aims to reveal the complexity of the EE tasks in BRAD by evaluating the performance of existing state-of-theart models for EE on this dataset. In particular, we focus on the following state-of-the-art models for EE that leverage the pre-trained language model BERT (Devlin et al., 2019) for the text encoding and jointly perform predictions for all EE tasks in an end-to-end fashion (i.e., joint inference): DyGIE++ (Wadden et al., 2019): This model utilizes dynamic span graphs to exploit long-range OneIE (Lin et al., 2020): This model first identifies spans of entity mentions and event triggers. The detected spans are then paired to jointly predict entity types, event types, relations, and argument roles for IE. Global features are used to capture cross-task and cross-instance dependencies and are employed in the decoding phase with beam searches to improve extraction performa"
2021.findings-acl.211,2020.acl-main.718,0,0.0331035,"Missing"
2021.findings-acl.211,P19-1157,0,0.0131066,"report the performance with BERT fine-tuned on the African American corpus. history, thus impairing the models and requiring appropriate adaptation to boost the EE performance. Finally, we note that the human performance (F1 scores) for Entity, Trig-C, and Arg-C on BRAD are 95.43, 88.3, and 79.8 respectively. The large performance gaps between human and current EE systems thus presents many research opportunities for future work on BRAD. 4 Related work Prior work in NLP for historical texts has mainly focused on spelling and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 20"
2021.findings-acl.211,P18-1201,0,0.0182895,"ction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 2020c; Nguyen et al., 2021). Some recent studies in EE have also addressed extensible learning settings for EE to new event types, e.g. zero-shot learning (Huang et al., 2018), fewshot learning (Lai et al., 2020a,b), or new domains (Naik and Ros´e, 2020). The closet works to ours involve recent efforts to create new datasets for EE (Satyapanich et al., 2020; Ebner et al., 2020; Wang et al., 2020; Trong et al., 2020; Le and Nguyen, 2021). However, these works do not consider historical texts as we do. 5 Acknowledgement This work is supported by an I3 grant from the University of Oregon Provost’s Office (Incubating Interdisciplinary Initiatives) and the Army Research Office (ARO) grant W911NF-21-1-0112. This research is also based upon work supported by the Office of"
2021.findings-acl.211,P19-1353,0,0.0376032,"Missing"
2021.mrl-1.6,P98-1012,0,0.299182,"lopment data and the other half for unlabeled data in the language discriminators. Similarly for the testing on KBP 2017, articles in KBP 2016 will be used for development and unlabeled data. Finally, to focus the evaluation of cross-lingual transfer learning, we employ golden event mentions in documents in this work. Following (Choubey and Huang, 2018; Huang et al., 2019), we employ the official KBP 2017 scorer (version 1.8) to obtain the coreference resolution performance for models. This evaluation script reports common performance metrics for ECR, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998) and CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b) and Average CoNLL (the average of four prior metrics). Hyper-parameters for the models are fine-tuned by Average CoNLL scores over development data. The suggested values from the fine-tuning involve: 5e-5 for the learning rate with the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 512 for the numbers of hidden units in the middle layers of the feed-forward language discriminator D, D1 and D2 (selected from [64, 128, 256, 512, 1024]); 1 2 α = 0.1, αdisc = 0.1, αdisc = 0.1, αdiver = 0.01, αconst = 0.01 for the trade-off paramete"
2021.mrl-1.6,P19-1409,0,0.073484,"ata are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models"
2021.mrl-1.6,Q18-1039,0,0.160846,"wn and arrested Sohel Rana. When loudspeakers at the rescue site announced his capture, local news reports said, the crowd broke out in cheers. An ECR system in information extraction (IE) should be able to recognize the coreference of the two event mentions associated with the trigger words “arrested” and “capture” in this text. 62 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 62–73 November 11, 2021. ©2021 Association for Computational Linguistics model baselines? Treating the source and target languages as the source and target domains in domain adaptation (Chen et al., 2018a, 2019; Keung et al., 2019), one can borrow the popular technique of domain adversarial neural networks (DANN) (Ganin et al., 2016; Fu et al., 2017) to induce better language-general representations for ECR, called language adversarial neural networks (LANN) to make it consistent with our language generalization problem. As such, in addition to traditional learning objectives (e.g., cross-entropy), the key idea of LANN is to introduce a language discriminator that seeks to differentiate representation vectors for text inputs from the source and target languages. To enhance the language genera"
2021.mrl-1.6,W09-2209,0,0.0510269,"led set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b),"
2021.mrl-1.6,W09-3208,0,0.0364161,"led set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b),"
2021.mrl-1.6,2020.acl-main.478,0,0.0191807,"ithin-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbi"
2021.mrl-1.6,S18-2001,0,0.0169137,"while sentences in test data are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent"
2021.mrl-1.6,P19-4007,0,0.131857,"clear, our work considers zero-resource cross-lingual learning that requires no labeled data for ECR in the target languages as well as human or machine generated parallel text. The systems in this work only have access to unlabeled text in the target languages to aid the cross-lingual learning for ECR. To our knowledge, this is the first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new problem of cross-lingual transfer lea"
2021.mrl-1.6,D19-1138,0,0.025207,". When loudspeakers at the rescue site announced his capture, local news reports said, the crowd broke out in cheers. An ECR system in information extraction (IE) should be able to recognize the coreference of the two event mentions associated with the trigger words “arrested” and “capture” in this text. 62 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 62–73 November 11, 2021. ©2021 Association for Computational Linguistics model baselines? Treating the source and target languages as the source and target domains in domain adaptation (Chen et al., 2018a, 2019; Keung et al., 2019), one can borrow the popular technique of domain adversarial neural networks (DANN) (Ganin et al., 2016; Fu et al., 2017) to induce better language-general representations for ECR, called language adversarial neural networks (LANN) to make it consistent with our language generalization problem. As such, in addition to traditional learning objectives (e.g., cross-entropy), the key idea of LANN is to introduce a language discriminator that seeks to differentiate representation vectors for text inputs from the source and target languages. To enhance the language generalization, models will attemp"
2021.mrl-1.6,N19-1423,0,0.17832,"languages (target languages). To be clear, our work considers zero-resource cross-lingual learning that requires no labeled data for ECR in the target languages as well as human or machine generated parallel text. The systems in this work only have access to unlabeled text in the target languages to aid the cross-lingual learning for ECR. To our knowledge, this is the first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new p"
2021.mrl-1.6,P18-2063,0,0.0205673,"19; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Bas"
2021.mrl-1.6,D13-1203,0,0.0202485,"h network will be first aligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses on crosslingual transfer learning fo"
2021.mrl-1.6,D12-1045,0,0.448392,"he source language) while sentences in test data are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu"
2021.mrl-1.6,I17-2072,1,0.927029,"system in information extraction (IE) should be able to recognize the coreference of the two event mentions associated with the trigger words “arrested” and “capture” in this text. 62 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 62–73 November 11, 2021. ©2021 Association for Computational Linguistics model baselines? Treating the source and target languages as the source and target domains in domain adaptation (Chen et al., 2018a, 2019; Keung et al., 2019), one can borrow the popular technique of domain adversarial neural networks (DANN) (Ganin et al., 2016; Fu et al., 2017) to induce better language-general representations for ECR, called language adversarial neural networks (LANN) to make it consistent with our language generalization problem. As such, in addition to traditional learning objectives (e.g., cross-entropy), the key idea of LANN is to introduce a language discriminator that seeks to differentiate representation vectors for text inputs from the source and target languages. To enhance the language generalization, models will attempt to generate representation vectors so the language discriminator is fooled, i.e., its performance is minimized to align"
2021.mrl-1.6,D17-1018,0,0.0228789,"ligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses on crosslingual transfer learning for ECR where traini"
2021.mrl-1.6,D13-1037,0,0.0229113,"oubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation l"
2021.mrl-1.6,P17-1004,0,0.0179203,"ation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine"
2021.mrl-1.6,C16-1114,0,0.0268238,"Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et"
2021.mrl-1.6,liu-etal-2014-supervised,0,0.024526,"les. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et"
2021.mrl-1.6,N19-1085,0,0.185594,"e Resolution with Multi-view Alignment and Optimal Transport Duy Phung1 , Hieu Minh Tran1 , Minh Van Nguyen2 , and Thien Huu Nguyen2 1 VinAI Research, Vietnam 2 Dept. of Computer and Information Science, University of Oregon, Eugene, OR, USA {v.duypv1,v.hieutm4}@vinai.io, {minhnv,thien}@cs.uoregon.edu Abstract Prior work on ECR assumes the monolingual setting where training and test data are presented in the same languages. Current state-of-the-art ECR systems thus rely on large monolingual datasets to train advanced models (Nguyen et al., 2016; Choubey and Huang, 2018; Lu and Ng, 2017, 2018; Huang et al., 2019) that are only annotated for popular languages (e.g., English). As document annotation for ECR is an expensive process, porting ECR models for English to other languages is crucial and appealing to enhance the accessibility of ECR systems. To this end, this paper explores cross-lingual transfer learning for ECR where models are trained on annotated documents in English (source language) and tested on documents from other languages (target languages). To be clear, our work considers zero-resource cross-lingual learning that requires no labeled data for ECR in the target languages as well as hum"
2021.mrl-1.6,2021.emnlp-main.440,1,0.841117,"Missing"
2021.mrl-1.6,C16-1308,0,0.0147211,"al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and"
2021.mrl-1.6,H05-1004,0,0.0538389,"nlabeled data in the language discriminators. Similarly for the testing on KBP 2017, articles in KBP 2016 will be used for development and unlabeled data. Finally, to focus the evaluation of cross-lingual transfer learning, we employ golden event mentions in documents in this work. Following (Choubey and Huang, 2018; Huang et al., 2019), we employ the official KBP 2017 scorer (version 1.8) to obtain the coreference resolution performance for models. This evaluation script reports common performance metrics for ECR, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998) and CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b) and Average CoNLL (the average of four prior metrics). Hyper-parameters for the models are fine-tuned by Average CoNLL scores over development data. The suggested values from the fine-tuning involve: 5e-5 for the learning rate with the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 512 for the numbers of hidden units in the middle layers of the feed-forward language discriminator D, D1 and D2 (selected from [64, 128, 256, 512, 1024]); 1 2 α = 0.1, αdisc = 0.1, αdisc = 0.1, αdiver = 0.01, αconst = 0.01 for the trade-off parameters in the loss function"
2021.mrl-1.6,D16-1038,0,0.022258,"ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, incl"
2021.mrl-1.6,P15-1138,0,0.0171163,"uang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for tex"
2021.mrl-1.6,2021.textgraphs-1.4,1,0.759919,"another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016;"
2021.mrl-1.6,D10-1048,0,0.0357544,"ges. Representation vectors from each network will be first aligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses o"
2021.mrl-1.6,2020.acl-main.681,0,0.0228985,"Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Baseline Model As this is the first work on cross-lingual transfer learning for ECR, this section aims to establish a baseline method for further research. In particular, recent work has shown that multilingual pre-trained language models with deep stacks of transformer layers, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), can provide strong baselines with competitive performance for zer"
2021.mrl-1.6,N12-1090,0,0.0255098,"uyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-in"
2021.mrl-1.6,P10-1142,0,0.0376624,"s from each network will be first aligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses on crosslin"
2021.mrl-1.6,D19-1030,0,0.0513258,"Missing"
2021.mrl-1.6,2021.findings-acl.351,1,0.741977,"., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Baseline Model As this is the first work on cross-lingual transfer learning for ECR, this section aims to establish a baseline method for further research. In particular, recent work has shown that multilingual pre-trained language models with deep stacks of transformer layers, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), can provide strong baselines with competitive performance for zero-shot cross-lingua"
2021.mrl-1.6,2021.eacl-demos.10,1,0.779685,"Missing"
2021.mrl-1.6,2021.acl-long.374,1,0.697118,"model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is d"
2021.mrl-1.6,2021.wanlp-1.27,1,0.840068,"Missing"
2021.mrl-1.6,W19-2806,0,0.016874,"2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Baseline Model As this is"
2021.mrl-1.6,M95-1005,0,0.552904,"2017 articles for the development data and the other half for unlabeled data in the language discriminators. Similarly for the testing on KBP 2017, articles in KBP 2016 will be used for development and unlabeled data. Finally, to focus the evaluation of cross-lingual transfer learning, we employ golden event mentions in documents in this work. Following (Choubey and Huang, 2018; Huang et al., 2019), we employ the official KBP 2017 scorer (version 1.8) to obtain the coreference resolution performance for models. This evaluation script reports common performance metrics for ECR, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998) and CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b) and Average CoNLL (the average of four prior metrics). Hyper-parameters for the models are fine-tuned by Average CoNLL scores over development data. The suggested values from the fine-tuning involve: 5e-5 for the learning rate with the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 512 for the numbers of hidden units in the middle layers of the feed-forward language discriminator D, D1 and D2 (selected from [64, 128, 256, 512, 1024]); 1 2 α = 0.1, αdisc = 0.1, αdisc = 0.1, αdiver = 0.01, αconst ="
2021.mrl-1.6,C18-1099,0,0.0250727,"ic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmal"
2021.mrl-1.6,D19-1077,0,0.128205,"systems in this work only have access to unlabeled text in the target languages to aid the cross-lingual learning for ECR. To our knowledge, this is the first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new problem of cross-lingual transfer learning for event coreference resolution (ECR) where models trained on data from a source language are adapted for evaluations in different target languages. We introduce the first ba"
2021.mrl-1.6,2020.repl4nlp-1.16,0,0.0200621,"e first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new problem of cross-lingual transfer learning for event coreference resolution (ECR) where models trained on data from a source language are adapted for evaluations in different target languages. We introduce the first baseline model for this task based on XLM-RoBERTa, a state-of-the-art multilingual pre-trained language model. We also explore language adversarial neura"
2021.mrl-1.6,Q15-1037,0,0.0191121,"work focuses on crosslingual transfer learning for ECR where training data involve input documents W in English (the source language) while sentences in test data are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al.,"
2021.mrl-1.6,C18-1037,0,0.0264128,"2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et"
2021.naacl-main.3,2020.emnlp-main.435,1,0.644727,"instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from"
2021.naacl-main.3,D18-1307,0,0.038813,"Missing"
2021.naacl-main.3,P15-1017,0,0.34431,"uires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For ins"
2021.naacl-main.3,D14-1198,0,0.0438891,"Missing"
2021.naacl-main.3,Q16-1026,0,0.0399163,"only three possible values (i.e., B, I, and O) for the tags of the words. In particular, following (Lin et al., 2020), we first feed w into the pre-trained BERT encoder (Devlin et al., 2019) to obtain a sequence of vectors X = [x1 , x2 , . . . , xn ] to represent w. Here, each vector xi serves as the representation vector for the word wi ∈ w that is obtained by averaging the hidden vectors of the word-pieces of wi returned by BERT. Afterward, X is fed into two conditional random field (CRF) layers to determine the best BIO tag sequences for event mentions and event triggers for w, following (Chiu and Nichols, 2016). As such, the Viterbi algorithm is used to decode the input sentence while the negative log-likelihood losses are employed as the training objectives for the span detection component of the model. For trg convenience, let Lent span and Lspan be the negative log-likelihoods of the gold tag sequences for entity mentions and event triggers (respectively) for w. These terms will be included in the overall loss function of the model later. 3.2 tasks. As such, the prediction instances for EME and ETD, called entity and trigger instances, correspond directly to the entity mentions and event triggers"
2021.naacl-main.3,P13-1008,0,0.750015,"viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from the dependency that the Victim of a Die event has a high chance to Introduction Information Extraction (IE) is an important and challenging task in Natural Language Processing (NLP) that aims to extract structured inform"
2021.naacl-main.3,N19-1423,0,0.0383325,"nt triggers in w that would be used to form the nodes in the interaction graph between different instances of our four IE tasks for w. As such, we formulate the span detection 29 problems as sequence labeling tasks where each word wi in w is associated with two BIO tags to capture the span information for entity mentions and event triggers in w. Note that we do not predict entity types and event types at this step, leading to only three possible values (i.e., B, I, and O) for the tags of the words. In particular, following (Lin et al., 2020), we first feed w into the pre-trained BERT encoder (Devlin et al., 2019) to obtain a sequence of vectors X = [x1 , x2 , . . . , xn ] to represent w. Here, each vector xi serves as the representation vector for the word wi ∈ w that is obtained by averaging the hidden vectors of the word-pieces of wi returned by BERT. Afterward, X is fed into two conditional random field (CRF) layers to determine the best BIO tag sequences for event mentions and event triggers for w, following (Chiu and Nichols, 2016). As such, the Viterbi algorithm is used to decode the input sentence while the negative log-likelihood losses are employed as the training objectives for the span dete"
2021.naacl-main.3,2020.acl-main.713,0,0.126095,"onsidered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent work has considered joint four-task IE, using deep learning to produce state-of-the-art (SOTA) performance for the tasks (Wadden et al., 2019; Lin et al., 2020). However, there are still two problems that hinder further improvement of such models. First, at the instance level, an important component of deep learning models for joint IE involves the representation vectors of the instances that are used to perform the corresponding prediction tasks for IE in an input sentence (called predictive instance representations). For joint fourtask IE, we argue that there are inter-dependencies between predictive representation vectors of related instances for the four tasks that should be modeled to improve the performance for IE. For instance, the entity type"
2021.naacl-main.3,P19-1136,0,0.0325797,"Missing"
2021.naacl-main.3,N19-1308,0,0.0429031,"Missing"
2021.naacl-main.3,P16-1105,0,0.0240636,"turing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent work has considered joint four-task IE, using deep learning to produce state-of-the"
2021.naacl-main.3,D19-1041,0,0.0828176,"Missing"
2021.naacl-main.3,D14-1200,0,0.184343,"r instances of the four tasks. At the label level, GCNtype is responsible for capturing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent wo"
2021.naacl-main.3,N16-1034,1,0.946838,"Missing"
2021.naacl-main.3,C16-1215,0,0.0374214,"Missing"
2021.naacl-main.3,P15-2060,1,0.901627,"s). First, at the instance level, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence"
2021.naacl-main.3,P17-1085,0,0.0461339,"Missing"
2021.naacl-main.3,W15-1506,1,0.809111,"s). First, at the instance level, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence"
2021.naacl-main.3,N16-1033,0,0.28193,"tasks. At the label level, GCNtype is responsible for capturing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent work has considered joint fo"
2021.naacl-main.3,W09-1406,0,0.0516797,"t of Defense, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. This document does not contain technology or technical data controlled under either the U.S. International Traffic in Arms Regulations or the U.S. Export Administration Regulations. The early joint methods for IE have employed feature engineering to capture the dependencies between IE tasks, including Integer Linear Programming for Global Constraints (Roth and Yih, 2004; Li et al., 2011), Markov Logic Networks (Riedel et al., 2009; Venugopal et al., 2014), Structured Perceptron (Li et al., 2013, 2014; Miwa and Sasaki, 2014; Judea and Strube, 2016), and Graphical Models (Yu and Lam, 2010; Yang and Mitchell, 2016). Recently, the application of deep learning has facilitated the joint modeling for IE via shared parameter mechanisms across tasks. These joint models have focused on different subsets of the IE tasks, including EME and RE (Zheng et al., 2017; Katiyar and Cardie, 2017; Bekoulis et al., 2018; Fu et al., 2019; Luan et al., 2019; Sun et al., 2019; Veyseh et al., 2020b,a), event and temporal RE (Han et al., 2019),"
2021.naacl-main.3,C10-2160,0,0.0916288,"Missing"
2021.naacl-main.3,W04-2401,0,0.583024,"used to enrich the representations for instances of the four tasks. At the label level, GCNtype is responsible for capturing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issu"
2021.naacl-main.3,W15-3904,0,0.0321291,"evel, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance fo"
2021.naacl-main.3,P17-1113,0,0.0411689,"Missing"
2021.naacl-main.3,P19-1131,0,0.0435976,"Missing"
2021.naacl-main.3,P05-1053,0,0.107816,"s. prediction models). First, at the instance level, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencie"
2021.naacl-main.3,D14-1090,0,0.0263154,"U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. This document does not contain technology or technical data controlled under either the U.S. International Traffic in Arms Regulations or the U.S. Export Administration Regulations. The early joint methods for IE have employed feature engineering to capture the dependencies between IE tasks, including Integer Linear Programming for Global Constraints (Roth and Yih, 2004; Li et al., 2011), Markov Logic Networks (Riedel et al., 2009; Venugopal et al., 2014), Structured Perceptron (Li et al., 2013, 2014; Miwa and Sasaki, 2014; Judea and Strube, 2016), and Graphical Models (Yu and Lam, 2010; Yang and Mitchell, 2016). Recently, the application of deep learning has facilitated the joint modeling for IE via shared parameter mechanisms across tasks. These joint models have focused on different subsets of the IE tasks, including EME and RE (Zheng et al., 2017; Katiyar and Cardie, 2017; Bekoulis et al., 2018; Fu et al., 2019; Luan et al., 2019; Sun et al., 2019; Veyseh et al., 2020b,a), event and temporal RE (Han et al., 2019), and ETD and EAE (Nguyen e"
2021.naacl-main.3,2020.acl-main.715,1,0.836939,"event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from the dependency that the Victim of a Die event has a high chance to Introduction Information Extraction (IE) is an important and challenging task in Natural Language Processing (NLP) that aims to extract structured information from unstructured texts. Following"
2021.naacl-main.3,2020.findings-emnlp.326,1,0.856589,"event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from the dependency that the Victim of a Die event has a high chance to Introduction Information Extraction (IE) is an important and challenging task in Natural Language Processing (NLP) that aims to extract structured information from unstructured texts. Following"
2021.sigdial-1.6,N19-1078,0,0.016594,"ogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings: a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training. 1 Introduction Named entity recognition (NER) is the task of extracting proper names of people, locations, and so on from text or speech (Grishman and Sundheim, 1996). There has been a lot of work on NER from written text with many systems achieving impressive results (Devlin et al., 2019; Akbik et al., 2019). Although, NER from speech has been around for the same time as NER from text (starting with work by Kubala et al. (1998)), accuracy of NER from speech still lags behind the accuracy of NER from text. The rise in popularity of spoken dialog systems such as Siri or Alexa 45 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 45–55 July 29–31, 2021. ©2021 Association for Computational Linguistics We propose two models that exploit dialog context and speech patterns which are available in open-domain dialogs from spoken dialog systems to achieve"
2021.sigdial-1.6,C02-1130,0,0.142338,"ttle named entity overlap). Table 2 illustrates the difference in term of named entity overlap measured using vocabulary transfer rate (Palmer and Day, 1997). VoAlthough named entities are typically classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity"
2021.sigdial-1.6,galibert-etal-2014-etape,0,0.0409569,"Missing"
2021.sigdial-1.6,2020.lrec-1.797,0,0.0281511,"tures other than what were used in this paper. However, many previous studies have shown the usefulness of these additional features in other tasks so there are reasons to believe that the findings should translate to other datasets and settings. Figure 6: Speech pattern helps locating named entities. Without speech pattern, models predicted the wrong entity spans (e.g. “jonas brothers once” and “with mclovin”). SP: speech patterns 5.2 Future work Towards robust NER in dialog system Current ASR systems still perform poorly in domains that require special vocabulary and under noisy conditions (Georgila et al., 2020). Unfamiliar words or recording noise may lead to ASR errors that affect downstream tasks such as NER. Although continuously retraining the ASR and NER models can reduce these errors, such effort may be costly. Integrating features such as speech pattern features, which are less affected by changing vocabulary and recording conditions, could make NER models more robust and reduce the frequency of having to retrain the models. Speech pattern features have been used for NER in spoken broadcast news although this did not lead to improvement in performance (Hakkani-T¨ur et al., 1999). This could b"
2021.sigdial-1.6,2020.lrec-1.211,0,0.0397973,"Missing"
2021.sigdial-1.6,bick-2004-named,0,0.0598518,"y classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the a"
2021.sigdial-1.6,C96-1079,0,0.357568,"h challenging. We propose two models that exploit dialog context and speech pattern clues to extract named entities more accurately from open-domain dialogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings: a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training. 1 Introduction Named entity recognition (NER) is the task of extracting proper names of people, locations, and so on from text or speech (Grishman and Sundheim, 1996). There has been a lot of work on NER from written text with many systems achieving impressive results (Devlin et al., 2019; Akbik et al., 2019). Although, NER from speech has been around for the same time as NER from text (starting with work by Kubala et al. (1998)), accuracy of NER from speech still lags behind the accuracy of NER from text. The rise in popularity of spoken dialog systems such as Siri or Alexa 45 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 45–55 July 29–31, 2021. ©2021 Association for Computational Linguistics We prop"
2021.sigdial-1.6,2020.lrec-1.556,0,0.0381628,"Missing"
2021.sigdial-1.6,N06-2015,0,0.0144524,"Missing"
2021.sigdial-1.6,W17-4418,0,0.0599053,"Missing"
2021.sigdial-1.6,D17-1215,0,0.0271203,"t Hard split 51,362 147,724 15,733 46,435 152,728 23,394 146,858 146,858 19,585 19,984 19,279 20,583 23,499 81,829 1,975 5,942 11,066 836 5,648 11,257 1,079 7,402 7,402 934 1,254 952 1,391 cabulary transfer is the proportion of unique named entities appearing in both training and test set, and as expected, the development and test sets of the hard split have much lower vocabulary transfer than that of the standard split. Although standard split is a common practice in machine learning, deep learning models can perform well on the standard split by exploiting the spurious patterns in the data (Jia and Liang, 2017). Thus, the hard split is necessary for measuring how well the models can generalize, since NER models relying heavily on surface patterns will underperform when there are a lot of unseen named entities (Augenstein et al., 2017). Furthermore, the test set of the hard split more closely resembles the test data during deployment because the data the models see during deployment usually differ from the data collected during training (little overlap of named entities). Thus, the performance on the hard split is a more realistic reflection of the models performance during deployment. A comparison b"
2021.sigdial-1.6,N19-1423,0,0.0350581,"from open-domain dialogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings: a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training. 1 Introduction Named entity recognition (NER) is the task of extracting proper names of people, locations, and so on from text or speech (Grishman and Sundheim, 1996). There has been a lot of work on NER from written text with many systems achieving impressive results (Devlin et al., 2019; Akbik et al., 2019). Although, NER from speech has been around for the same time as NER from text (starting with work by Kubala et al. (1998)), accuracy of NER from speech still lags behind the accuracy of NER from text. The rise in popularity of spoken dialog systems such as Siri or Alexa 45 Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 45–55 July 29–31, 2021. ©2021 Association for Computational Linguistics We propose two models that exploit dialog context and speech patterns which are available in open-domain dialogs from spoken dialo"
2021.sigdial-1.6,H01-1034,0,0.413136,"h because NER is a core component for understanding what users said in dialogs. In spoken dialog systems, humans interact with the systems using natural speech to accomplish certain tasks (task-oriented dialog) or just to be entertained (chitchat or open-domain dialog) (Jurafsky and Martin, 2009). These systems require speech transcripts as input in real-time and the transcripts are obtained using automatic speech recognition (ASR) components (Turmo et al., 2009). Much previous work on NER from speech data, such as broadcast news, applied text-based NER systems to the output of an ASR system (Palmer and Ostendorf, 2001). However, NER performance degraded significantly (20 points drop in F1 score) when applying a NER trained on written data to transcribed speech (Kubala et al., 1998). This could be because applying text-based NER system to ASR output ignores the differences in styles and conventions in written and spoken language (Palmer and Ostendorf, 2001). For example, spoken utterances in spontaneous speech are usually much shorter than written prose so the utterances could be ambiguous when taken out of context. In addition, speech also contains disfluencies, repetitions, restarts and corrections (Turmo"
2021.sigdial-1.6,W14-1609,0,0.0118097,"he notebook”, while BERT misclassified it as Book. In contrast, speech pattern features may help locating the named entities. Figure 6 shows that NER models without speech pattern features might predict the wrong text spans as named entities (e.g. “jonas brothers once” instead of “jonas brothers”). Interestingly, although the predicted type is not correct, the type of “mclovin” predicted by BERT is more plausible than BiLSTM-CRF. This might be because BERT gained some world knowledge after pre-training, and NER models usually benefit from external sources of knowledge (Ratinov and Roth, 2009; Passos et al., 2014). study by removing the features one by one. In particular, starting with a model that uses all 4 features (denoted as 4F): namely token ASR confidence, token duration, the pauses preceding and succeeding the token, we first remove the ASR confidence from the model input (denoted as 3F) and then remove the token duration from the model input (denoted as 2F). We trained all the models with ablated features from scratch with hyperparameter search similar to what was done in Section 4.2. For the hard split, the BERT 4F model did better than the BERT 3F model, showing that the ASR confidence is pr"
2021.sigdial-1.6,N16-1030,0,0.027565,"). The user’s utterance includes lexical features (i.e. word tokens or word pieces) and speech pattern features which are pauses’ duration, words’ duration, and tokens’ ASR confidence. Both models have three components: (1) a context encoder, (2) a speech pattern encoder, and (3) a sequence tagger. The context encoder and speech pattern encoder are the same in both models and the encoders provide additional clues for the sequence tagger to accurately label named entities. The first model’s sequence tagger is a widely used model for NER from written text based on BiLSTM-CRF (Ma and Hovy, 2016; Lample et al., 2016), which combines bidirectional LSTM (Graves and Schmidhuber, 2005) with conditional random field (Lafferty et al., 2001). The second model’s sequence tagger is based on BERT (Devlin et al., 2019), which achieved stateof-the-art result for the CoNLL dataset. Figure 2 shows the models’ structure. The context encoder is a bag-of-embedding model (Fig47 Tokens Turns Train Bot 22,908 User 624,168 146,858 Avg. Len. Train Bot User Number of Tokens 27.2 6.4 26.9 27.2 6.5 6.4 27.1 27.3 6.6 6.8 CoNLL OntoNotes WNUT Standard Split Dev Test 3,000 3,000 80,749 81,668 19,585 19,279 Standard split Hard split"
2021.sigdial-1.6,D14-1162,0,0.0820089,"Missing"
2021.sigdial-1.6,I05-1058,0,0.0563849,"of the hard split are created such that they have more named entities that are not seen in the training set (i.e. little named entity overlap). Table 2 illustrates the difference in term of named entity overlap measured using vocabulary transfer rate (Palmer and Day, 1997). VoAlthough named entities are typically classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving informati"
2021.sigdial-1.6,W09-1119,0,0.144513,"CRF missed the entity “the notebook”, while BERT misclassified it as Book. In contrast, speech pattern features may help locating the named entities. Figure 6 shows that NER models without speech pattern features might predict the wrong text spans as named entities (e.g. “jonas brothers once” instead of “jonas brothers”). Interestingly, although the predicted type is not correct, the type of “mclovin” predicted by BERT is more plausible than BiLSTM-CRF. This might be because BERT gained some world knowledge after pre-training, and NER models usually benefit from external sources of knowledge (Ratinov and Roth, 2009; Passos et al., 2014). study by removing the features one by one. In particular, starting with a model that uses all 4 features (denoted as 4F): namely token ASR confidence, token duration, the pauses preceding and succeeding the token, we first remove the ASR confidence from the model input (denoted as 3F) and then remove the token duration from the model input (denoted as 2F). We trained all the models with ablated features from scratch with hyperparameter search similar to what was done in Section 4.2. For the hard split, the BERT 4F model did better than the BERT 3F model, showing that th"
2021.sigdial-1.6,W04-1221,0,0.0256859,"n (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the average entity length by types respectively. The Movie, Book, and Song t"
2021.sigdial-1.6,P16-1101,0,0.0224917,"the bot’s utterance). The user’s utterance includes lexical features (i.e. word tokens or word pieces) and speech pattern features which are pauses’ duration, words’ duration, and tokens’ ASR confidence. Both models have three components: (1) a context encoder, (2) a speech pattern encoder, and (3) a sequence tagger. The context encoder and speech pattern encoder are the same in both models and the encoders provide additional clues for the sequence tagger to accurately label named entities. The first model’s sequence tagger is a widely used model for NER from written text based on BiLSTM-CRF (Ma and Hovy, 2016; Lample et al., 2016), which combines bidirectional LSTM (Graves and Schmidhuber, 2005) with conditional random field (Lafferty et al., 2001). The second model’s sequence tagger is based on BERT (Devlin et al., 2019), which achieved stateof-the-art result for the CoNLL dataset. Figure 2 shows the models’ structure. The context encoder is a bag-of-embedding model (Fig47 Tokens Turns Train Bot 22,908 User 624,168 146,858 Avg. Len. Train Bot User Number of Tokens 27.2 6.4 26.9 27.2 6.5 6.4 27.1 27.3 6.6 6.8 CoNLL OntoNotes WNUT Standard Split Dev Test 3,000 3,000 80,749 81,668 19,585 19,279 Stan"
2021.sigdial-1.6,W03-1307,0,0.1056,"e big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the average entity length by type"
2021.sigdial-1.6,A97-1028,0,0.361283,"utterances are output from an ASR system and are in lower case. The data are divided into two different splits: a standard split and a hard split, and the two splits share the same training set (Table 1). While the training, development, and test set of the standard split are formed by randomly partitioning the data, the development and test set of the hard split are created such that they have more named entities that are not seen in the training set (i.e. little named entity overlap). Table 2 illustrates the difference in term of named entity overlap measured using vocabulary transfer rate (Palmer and Day, 1997). VoAlthough named entities are typically classified into three big types: Person, Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (B"
2021.sigdial-1.6,P06-1078,0,0.125913,"1995; Lenzi et al., 2012). Although, joint decoding of ASR transcript and NER output (Caubri`ere et al., 2020) partly lessens the impact of ASR errors on NER, detecting named entities in ASR transcripts remains a challenging problem (Galibert et al., 2014). Prior work on NER from ASR transcripts focus on reducing ASR errors (Palmer and Ostendorf, 2001), exploiting multiple ASR hypotheses (Horlock and King, 2003; B´echet et al., 2004), or exploiting additional information such as speech pattern features (Katerenchuk and Rosenberg, 2014). Examples of speech pattern features are ASR confidence (Sudoh et al., 2006), pauses, and word durations (Hakkani-T¨ur et al., 1999). Recently, Cervantes and Ward (2020) used solely prosidic speech features to spot location mentions. Our work is similar to Katerenchuk and Rosenberg (2014) in that we also utilize speech pattern features. However, while Katerenchuk and Rosenberg (2014) focused on broadcast news speech, our work focuses on spoken dialogs. Thus, besides speech pattern features, our models also exploit dialog context for more accurate NER. In addition, Katerenchuk and Rosenberg (2014) used a separate classifier trained on Figure 1: Dialog context and speec"
2021.sigdial-1.6,M95-1002,0,0.426072,"Missing"
2021.sigdial-1.6,W03-0419,0,0.0713989,"Missing"
2021.sigdial-1.6,N18-1007,0,0.0284586,"ting data are significantly different, demonstrating that it is possible to combine lexical and speech pattern features to achieve more robust NER system. Figure 5: Without context, both models either predicted the wrong entity type or missed the named entity. 5.3 We show that short context and minimal speech pattern features can improve NER performance. Better performance might be achieved by modeling longer context and more features (e.g. prosodies, parts of speech, punctuation) from a SOTA ASR system. Prosodic features can also be extracted automatically to better align to sub-word tokens (Tran et al., 2018). It would also be interesting to see how robust NER would improve entity linking especially when entity mentions contain ASR errors. Since our work only explored open-domain conversations between humans and a chatbot, it is important to validate the benefits of modeling context and speech pattern features in other settings. Examples of other settings include open-domain conversations between humans or task-oriented conversations between humans or between humans and chatbots. For these different settings, NER models might need longer context or speech pattern features other than what were used"
2021.sigdial-1.6,W03-1306,0,0.179035,", Location, and Organization (Nadeau and Sekine, 2007), fine-grained typing may be more useful, especially for questionanswering and information retrieval (Fleischman, 2001). For example, Location can be subdivided into City, State, and Country (Lee and Lee, 2005). Similarly, Person can be subdivided into Politician 48 Type Length Type Length and Entertainer (Fleischman and Hovy, 2002). In addition, special types may be used to address systems’ specific needs, for example Film (Etzioni et al., 2005), Book title (Brin, 1998; Witten et al., 1999), Brand (Bick, 2004), Protein (Shen et al., 2003; Tsuruoka and Tsujii, 2003; Settles, 2004), Drug (Rindflesch et al., 1999), and Chemical (Narayanaswamy et al., 2002). Since the Gunrock chatbot needs to converse with users in different topics, fine-grained typing is more useful for accurately retrieving information about named entities. Named entities in data samples were manually labelled by Gunrock team members using 6 named entity types: Movie, Book, Song, Person, Character, and Other. The BIO scheme was used for labeling the data. Figure 3 and Table 4 show the distribution of named entities by types and the average entity length by types respectively. The Movie,"
2021.wanlp-1.27,P15-1017,0,0.0554856,"demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Li"
2021.wanlp-1.27,W09-2209,0,0.294419,"based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et a"
2021.wanlp-1.27,N19-1423,0,0.0256202,"d to the state-ofthe-art performance for different experiments scenarios for CEAE. In the future, we plan to apply the proposed model to other related tasks, e.g., crosslingual relation extraction (Veyseh et al., 2020). In addition, motivated by the recent introduction of high-performance multilingual NLP toolkits, e.g., Trankit (Nguyen et al., 2021), we expect to extend our work to other languages to better demonstrate the benefits of the proposed models. Finally, we will also explore the performance of our models when recent pre-trained multilingual language models, e.g., multilingual BERT (Devlin et al., 2019), are employed to encode input texts for different languages. Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-17-S-0002. This research is also based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 201919051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official p"
2021.wanlp-1.27,N15-1151,0,0.0236256,", 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as"
2021.wanlp-1.27,C16-1114,0,0.104667,"based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event f"
2021.wanlp-1.27,P08-1030,0,0.0752359,"eriments are conducted with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic st"
2021.wanlp-1.27,D18-1330,0,0.0627197,"Missing"
2021.wanlp-1.27,C10-1064,0,0.031916,"earning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , .."
2021.wanlp-1.27,D19-5532,1,0.841018,"ance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our wo"
2021.wanlp-1.27,2020.emnlp-main.435,1,0.745645,"bic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related"
2021.wanlp-1.27,D14-1198,0,0.0273177,"English to demonstrate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, whi"
2021.wanlp-1.27,P13-1008,0,0.0599007,"s for representation learning in this work. Finally, we conduct extensive experiments to demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et"
2021.wanlp-1.27,R11-1002,0,0.666743,"with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences acr"
2021.wanlp-1.27,P14-1055,0,0.0283731,"twardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence"
2021.wanlp-1.27,P19-1423,0,0.05824,"g for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role y ∗ of wa for the event triggered by wt . Following (Subburathinam et al., 2019), we use the UDPipe toolkit (Straka and Strakov´a, 2017) to obtain the universal dependency tree for W , the part of speech (POS) tag"
2021.wanlp-1.27,P17-1004,0,0.0888869,", 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word a"
2021.wanlp-1.27,K17-3009,0,0.103138,"Missing"
2021.wanlp-1.27,N19-1112,0,0.023469,"15; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role"
2021.wanlp-1.27,D19-1030,0,0.291797,"Missing"
2021.wanlp-1.27,D18-1156,0,0.0171188,"t Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In particular, with the multilingual word embeddings"
2021.wanlp-1.27,2020.findings-emnlp.409,1,0.795913,"Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role y ∗ of wa for the event triggered by wt . Following (Subburathinam et al., 2019), we use the UDPipe toolkit (Straka and Strakov´a, 2017) to obtain the universal dependency tree for W , the part of speech (POS) tags and BIO entity typ"
2021.wanlp-1.27,N19-1392,0,0.0510224,"Missing"
2021.wanlp-1.27,P18-2106,0,0.0564393,"Missing"
2021.wanlp-1.27,2021.eacl-demos.10,1,0.620789,"e introduce two novel sentence structures for cross-lingual EAE with GCNs based on the semantic similarity and the universal dependency relations of the words in the input sentences. The experiments demonstrate the benefits of the proposed sentence structures that lead to the state-ofthe-art performance for different experiments scenarios for CEAE. In the future, we plan to apply the proposed model to other related tasks, e.g., crosslingual relation extraction (Veyseh et al., 2020). In addition, motivated by the recent introduction of high-performance multilingual NLP toolkits, e.g., Trankit (Nguyen et al., 2021), we expect to extend our work to other languages to better demonstrate the benefits of the proposed models. Finally, we will also explore the performance of our models when recent pre-trained multilingual language models, e.g., multilingual BERT (Devlin et al., 2019), are employed to encode input texts for different languages. Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-17-S-0002. This research is also based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IA"
2021.wanlp-1.27,N16-1034,1,0.878003,"he proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In part"
2021.wanlp-1.27,P15-2060,1,0.870008,"trate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lin"
2021.wanlp-1.27,2020.acl-main.715,1,0.932968,"the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure mod"
2021.wanlp-1.27,P19-1432,1,0.845506,", 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role y ∗ of wa for the event triggered by wt . Following (Subburathinam et al., 2019), we use the UDPipe toolkit (Straka and Strakov´a, 2017) to obtain the universal dependency tree for W , the part of speech (POS) tags and BIO entity type tags for the words in W . For convenience, let R"
2021.wanlp-1.27,C18-1099,0,0.109863,"itchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e.,"
2021.wanlp-1.27,D19-1584,0,0.231593,"ssify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In particular, with the multilingual word embeddings, Subburathinam et al. (2019) develop a m"
2021.wanlp-1.27,N16-1033,0,0.0531917,"ion learning in this work. Finally, we conduct extensive experiments to demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2"
2021.wanlp-1.27,D09-1016,0,0.181809,"t all the structures A rel and A are fed into GCN models for representation learning in this work. Finally, we conduct extensive experiments to demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqu"
2021.wanlp-1.27,2020.findings-emnlp.326,1,0.929278,"the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure mod"
2021.wanlp-1.27,D18-1244,0,0.0292328,"considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In particular, with the multilingual word embeddings, Subburathinam et al. (2019) develop a model based on Graph Convolutional Networks (GCNs) (Kipf and Welling, 2017; Zhang et al., 2018), which operates on universal dependency trees to capture the shared structures. Notably, the use of the dependency trees of the sentences for GCNs in (Subburathinam et al., 2019) essentially treats the existence of the syntactic connections between the words in the universal dependency trees as the language-universal knowledge that can be exploited to bridge the gap between languages for EAE. In (Subburathinam et al., 2019), such syntactic connection existences are formalized via the adjacency matrices Adep = {adep ij }i,j=1..N of the dependency trees (i.e., N is the number of words in the in"
2021.wanlp-1.27,C18-1037,0,0.115389,", 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argum"
2021.wnut-1.5,Q14-1022,0,0.0243768,"g the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works"
2021.wnut-1.5,N19-1423,0,0.0369462,"Abaseline is those computed for the model that always guesses the median. • Comparison on UDS-T: We compare the FineTempRel model in this work (called ONLSTM-GCN) with the best-reported models on the UDS-T dataset in (Vashishtha et al., 2019). In particular, we use the top four models in (Vashishtha et al., 2019) (called System1, System2, System3, and System4) as the baselines in this work. Table 1 reports the performance of the models. Note that in addition to the ELMo embeddings as in (Vashishtha et al., 2019), we also show the performance of the ON-LSTM-GCN model when the BERT embeddings (Devlin et al., 2019) (i.e., the base model) are employed to encode the sentences. Both ELMo and BERT are fine-tuned during training in this work. As we can see, using the same ELMo embeddings, the proposed model ON-LSTM-GCN significantly outperforms all the models in (Vashishtha et al., 2019) with substantial performance gap over different performance metrics and the two subtasks (i.e., event duration prediction and temporal relation prediction). This clearly demonstrates the effectiveness of the proposed model for FineTempRel. We also see that replacing ELMo with the BERT embeddings can help to improve the perfo"
2021.wnut-1.5,E17-2118,0,0.175331,"more useful context information for FineTempRel than the farther ones. For instance, Introduction An important step in event understanding involves identifying the temporal relations between events (i.e., TempRel), finding its applications in different natural language processing (NLP) systems such as question answering and timeline construction. A large volume of the prior works has focused on the classification setting for this problem where categorical temporal relations should be predicted for pairs of event-referring and/or time-referring expressions in text (i.e., categorical TempRel) (Dligach et al., 2017; Cheng and Miyao, 2017; Ning et al., 2019). For instance, in the sentence “The meeting to discuss the possible merger of the two financial companies lasted for two hours, eventually leading to their union yesterday.”, a system for TempRel should be able to realize that the “discussion” event happens before the “union” event (i.e., the categorical label of BEFORE). ∗ The first two authors contribute equally to this paper. 35 Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 35–45 November 11, 2021. ©2021 Association for Computational Linguis"
2021.wnut-1.5,N13-1112,0,0.0739355,"Missing"
2021.wnut-1.5,W01-1313,0,0.185668,"(Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained langua"
2021.wnut-1.5,P19-1433,0,0.015995,"epresentation learning for FineTempRel. words for the representation vectors of the event mentions involve the syntactic neighboring words of the event mentions in the dependency trees. For instance, in our example, the words “lasted” and “two hours” are crucial to determine the duration for the event mention “meeting”. Note that although these words are far away from “meeting” in the sentence, they are directly connected to “meeting” in the dependency tree (i.e., the syntactic neighboring words). Second, for temporal relation prediction, our intuition is based on (Cheng and Miyao, 2017) and (Goyal and Durrett, 2019) that use the shortest dependency paths between the event mentions to capture the important context words for categorical TempRel (e.g., the word “leading” in our example). Motivated by these benefits of the dependency trees for FineTempRel, in this work, we propose to run Graph Convolutional Neural Networks (GCN) (Kipf and Welling, 2017; Nguyen and Grishman, 2018) over the dependency structures of the sentences to facilitate the incorporation of the dependency-based important context words into the representation vectors for FineTempRel. To our knowledge, this is the first work on using GCNs"
2021.wnut-1.5,W11-0116,0,0.0320814,"t al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al.,"
2021.wnut-1.5,S13-2002,0,0.0327634,"portant context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTem"
2021.wnut-1.5,K19-1062,0,0.172101,"elations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2"
2021.wnut-1.5,P14-2082,0,0.161812,"ecompose FineTempRel into two subtasks that would be solved jointly for a given pair of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, d"
2021.wnut-1.5,D19-1041,0,0.175158,"elations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2"
2021.wnut-1.5,W16-1701,0,0.0601497,"Missing"
2021.wnut-1.5,D17-1108,0,0.0974236,"ription (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al."
2021.wnut-1.5,P18-1212,0,0.0145996,"of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (D"
2021.wnut-1.5,D19-1642,0,0.0493625,"Rel than the farther ones. For instance, Introduction An important step in event understanding involves identifying the temporal relations between events (i.e., TempRel), finding its applications in different natural language processing (NLP) systems such as question answering and timeline construction. A large volume of the prior works has focused on the classification setting for this problem where categorical temporal relations should be predicted for pairs of event-referring and/or time-referring expressions in text (i.e., categorical TempRel) (Dligach et al., 2017; Cheng and Miyao, 2017; Ning et al., 2019). For instance, in the sentence “The meeting to discuss the possible merger of the two financial companies lasted for two hours, eventually leading to their union yesterday.”, a system for TempRel should be able to realize that the “discussion” event happens before the “union” event (i.e., the categorical label of BEFORE). ∗ The first two authors contribute equally to this paper. 35 Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 35–45 November 11, 2021. ©2021 Association for Computational Linguistics in our running example, the word “lead"
2021.wnut-1.5,P17-1009,0,0.0191599,"s is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The f"
2021.wnut-1.5,P18-1122,0,0.013777,"of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (D"
2021.wnut-1.5,C16-1308,0,0.0288235,"et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of EL"
2021.wnut-1.5,P06-1095,0,0.0975168,"e argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning mo"
2021.wnut-1.5,S18-2018,0,0.0165623,"of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (D"
2021.wnut-1.5,P18-1049,0,0.0192044,"e fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event"
2021.wnut-1.5,W16-5706,0,0.0389344,"Missing"
2021.wnut-1.5,L16-1699,0,0.0357237,"Missing"
2021.wnut-1.5,C16-1007,0,0.0137213,"tasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duratio"
2021.wnut-1.5,N18-1202,0,0.0255135,"do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The first component in our model for FineTempRel aims to exploit the consistency between the syntax-based and model-based importance scores for the words in the input sentence to improve the representation vectors in the deep learning models for FineTempRel. In particular, the syntaxbased importance scores are supposed to evaluate the potential contributions of the words in W f"
2021.wnut-1.5,2021.naacl-main.3,1,0.820189,"Missing"
2021.wnut-1.5,P17-2035,0,0.0130308,"et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of r"
2021.wnut-1.5,2021.acl-long.374,1,0.76159,"et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The first component in ou"
2021.wnut-1.5,2021.naacl-main.273,1,0.72013,"FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The first component in our model for FineTempRel aims to exploit the consistency between the syntax"
2021.wnut-1.5,S13-2001,0,0.214353,"ha et al., 2019), we decompose FineTempRel into two subtasks that would be solved jointly for a given pair of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et a"
2021.wnut-1.5,P19-1280,0,0.0307981,"Missing"
2021.wnut-1.5,2020.acl-main.715,1,0.816482,"uce the information from the syntax-based importance scores into the models for FineTempRel by enforcing the similarity/consistency between the syntax-based and model-based importance scores for the words in the sentence. The motivation is to leverage the importance score consistency to guide the representation learning process of the deep learning models (using the extracted syntactic information) so more effective representation vectors for FineTempRel can be induced. In order to implement this idea, we utilize the Ordered-Neuron Long Short-Term Memory Networks (ON-LSTM) (Shen et al., 2019; Veyseh et al., 2020a) to facilitate the computation of the model-based importance scores and the effective integration of the syntax-based scores for better representation vectors for FineTempRel. For the second type of syntactic information, the main motivation is to leverage the syntactic dependency connections between the words to identify the important context words that should be encoded to compute effective representation vectors for the event mentions in the sentences. In particular, following (Vashishtha et al., 2019), we decompose FineTempRel into two subtasks that would be solved jointly for a given pa"
2021.wnut-1.5,2020.findings-emnlp.326,1,0.729854,"uce the information from the syntax-based importance scores into the models for FineTempRel by enforcing the similarity/consistency between the syntax-based and model-based importance scores for the words in the sentence. The motivation is to leverage the importance score consistency to guide the representation learning process of the deep learning models (using the extracted syntactic information) so more effective representation vectors for FineTempRel can be induced. In order to implement this idea, we utilize the Ordered-Neuron Long Short-Term Memory Networks (ON-LSTM) (Shen et al., 2019; Veyseh et al., 2020a) to facilitate the computation of the model-based importance scores and the effective integration of the syntax-based scores for better representation vectors for FineTempRel. For the second type of syntactic information, the main motivation is to leverage the syntactic dependency connections between the words to identify the important context words that should be encoded to compute effective representation vectors for the event mentions in the sentences. In particular, following (Vashishtha et al., 2019), we decompose FineTempRel into two subtasks that would be solved jointly for a given pa"
2021.wnut-1.5,P12-2044,0,0.0216999,"terger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W i"
C04-1107,A00-1043,0,0.0794484,"Missing"
C04-1107,W03-1101,0,0.178941,"Missing"
C04-1107,Y03-1033,1,0.750683,"Missing"
C18-1060,M92-1003,0,0.740127,"Missing"
C18-1060,Q16-1026,0,0.039607,"ormance, as described in Section 3.4. 3.3 LSTM+CNN+CRF model for FG-NER We re-implemented the LSTM+CNN+CRF NER model described by Ma and Hovy (2016) and adjust the model to work with FG-NER. The LSTM+CNN+CRF model originally described by (Ma and Hovy, 2016) is for NER problem with few NE categories. It first uses Convolutional Neural Network (CNN) to learn character level embeddings in the training process. For NLP tasks, previous works have shown that CNN is likely to extract morphological features such as prefix and suffix effectively (Ma and Hovy, 715 2016; dos Santos and Guimar˜aes, 2015; Chiu and Nichols, 2016). The model then concatenates the character level embeddings with word embeddings to create a feature vector for each token in the input sentence. The input sentence is then fed to a BiLSTM network (Bi-directional Long-Short Term Memory network). Finally, CRF is used at the top layer of the BiLSTM to explore the correlations between outputs and jointly decode the best sequence of labels (i.e., NE categories). For both English and Japanese FG-NER task, we use pre-trained word embeddings as input for our models. Previous studies have shown that GloVe achieves the best performance for English NER"
C18-1060,W15-3904,0,0.0457865,"Missing"
C18-1060,N16-1030,0,0.0742374,"Missing"
C18-1060,P16-1101,0,0.488972,"lect the best model for different settings of training data size and target language. In FG-NER, because the number of NE categories is large, some categories might face with the data sparseness problem, whereas some other categories might have a large number of training samples in a dataset. Hence, it would be worth investigating the relation between dataset size and the performance of the system. The current state-of-the-art method for English NER (coarse-grained NER) is a neural network-based method, which uses convolutional neural network (CNN) to calculate the character level embeddings (Ma and Hovy, 2016). This leads to the question whether this method works well for languages with a large number of character types, such as Japanese. In this paper, we first investigate the relationship between the F-score of various FG-NER algorithms with the size of training datasets for both English and Japanese. Second, we suggest the direction to choose an appropriate FG-NER algorithm for appropriate target language and training data size. We show that the state-of-the-art method for English NER also performs well for English FG-NER. On the other hand, for Japanese FG-NER, the state-of-the-art method does"
C18-1060,W03-0430,0,0.0211231,"put for our models. Previous studies have shown that GloVe achieves the best performance for English NER task (Reimers and Gurevych, 2017). Consequently, we use the embeddings based on GloVe for English5 . For Japanese, we use pretrained word2vec6 embeddings. The vector dimension is 300 for English and 200 for Japanese. We use the default hyperparameters by Ma and Hovy (2016) in our model: learning rate = 0.01, batch size = 10 and decay rate = 0.09. 3.4 Incorporating dictionary information Dictionary information (gazetteer feature) has been proved to be efficient in many NER and FG-NER tasks (McCallum and Li, 2003; Sekine and Nobata, 2004; Yosef et al., 2012). While there are previous studies that use dictionary for CRF (McCallum and Li, 2003) or SVM (Yosef et al., 2012) in the NER/FGNER tasks, we believe that dictionary information would be useful in both sequence labelling and entity category disambiguation phase in the CRF+SVM method. Furthermore, the dictionary information can also be used in LSTM+CNN+CRF method. Consequently, we propose a method that efficiently utilizes dictionary information in the method LSTM+CNN+CRF and in both sequence labelling (CRF) and entity category disambiguation (SVM)"
C18-1060,W17-4114,0,0.0298835,"Missing"
C18-1060,D17-1035,0,0.0147056,"odel then concatenates the character level embeddings with word embeddings to create a feature vector for each token in the input sentence. The input sentence is then fed to a BiLSTM network (Bi-directional Long-Short Term Memory network). Finally, CRF is used at the top layer of the BiLSTM to explore the correlations between outputs and jointly decode the best sequence of labels (i.e., NE categories). For both English and Japanese FG-NER task, we use pre-trained word embeddings as input for our models. Previous studies have shown that GloVe achieves the best performance for English NER task (Reimers and Gurevych, 2017). Consequently, we use the embeddings based on GloVe for English5 . For Japanese, we use pretrained word2vec6 embeddings. The vector dimension is 300 for English and 200 for Japanese. We use the default hyperparameters by Ma and Hovy (2016) in our model: learning rate = 0.01, batch size = 10 and decay rate = 0.09. 3.4 Incorporating dictionary information Dictionary information (gazetteer feature) has been proved to be efficient in many NER and FG-NER tasks (McCallum and Li, 2003; Sekine and Nobata, 2004; Yosef et al., 2012). While there are previous studies that use dictionary for CRF (McCallu"
C18-1060,D11-1141,0,0.061483,"ed classification to recognize a music band name to answer the question “Which band was Paul in”, from the information shown in Figure 1. A fine-grained named entity recognition (FG-NER) model refers to a NER model that can recognize and classify a large number of entity categories (e.g., hundreds of NE categories). In classical coarse-grained named entity (NE) definition, often less than ten named entity categories are defined. For example, in the CoNLL-2003 Named Entity Recognition task, there are four NE categories: Person, Location, Organization and Miscellaneous (Sang and Meulder, 2003). Ritter et al. (2011) proposed a NER algorithm to recognize ten categories of entities from Twitter text. On the other hand, in FG-NER, there are hundreds of NE categories, which are fine-grained classification of coarse-grained categories. *) Equally contributed to the paper This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creativecommons.org/licenses/by/4.0/ 711 Proceedings of the 27th International Conference on Computational Linguistics, pages 711–722 Santa Fe, New Mexico, USA, August 20-26, 2018. Paul, a former member of The Beatles, known for &quot;Let"
C18-1060,sekine-nobata-2004-definition,1,0.820793,"category Country and Organization Other. This is because the category Country is very easy to recognize, as there are only about 200 entities frequently used in this category, whereas, recognizing Organization Other or Car Stop is very difficult because of the ambiguity. This also indicates that the performance of an FG-NER system tends to depend on the categories and we can confirm this in the experimental results in the next sections. 3 Fine-Grained Named Entity Recognition Methods 3.1 Dictionary and Rule-based FG-NER The simplest method for FG-NER is using a dictionary and a set of rules. Sekine and Nobata (2004) presented a dictionary and rule-based Japanese FG-NER system that contains more than 1400 rules to recognize 140 entity categories. In this work, we added 200 rules to the existing 1400 rules by Sekine and Nobata to create a rule set of 1600 rules to classify 200 NE categories in the Sekine’s Extended Named Entity Hierarchy. We then built a rule-based Japanese FG-NER model to recognize 200 NE categories based on these 1600 rules. We use a Japanese FG-NER dictionary containing 1.6 million Wikipedia entities in this model. In the 1.6 million entities in the dictionary, only 70 thousand entities"
C18-1060,sekine-etal-2002-extended,1,0.613956,"egories from a knowledge base such as Freebase (Bollacker et al., 2008) or YAGO (Suchanek et al., 2007), filtering out the categories with a small number of entities and merging the categories with similar semantic meaning into one FG-NER category (Ling and Weld, 2012; Yosef et al., 2012; Gillick et al., 2014). The second method is to manually build an entity hierarchy to cover important domains in the real world. Following the second method, Sekine et al. proposed an Extended Named Entity Hierarchy (ENEH), which contains 200 entity categories in a three-layer hierarchy, as shown in Figure 2 (Sekine et al., 2002; Sekine, 2008). In this paper, we use the entity hierarchy described by Sekine (2008), which contains 200 NE categories at the leaf-level, as our tag set3 . At the top level of the hierarchy, there are about twenty coarse-grained named entity categories, such as Person, Organization, Location, Facility, Product, Event, . . . Each top-level categories is further divided into several second-level categories as shown in Figure 2. Each second-level category is in turn divided into several leaf-level categories. We use this hierarchy because it is carefully designed by humans, it does not ignore i"
C18-1060,sekine-2008-extended,1,0.793193,"International Conference on Computational Linguistics, pages 711–722 Santa Fe, New Mexico, USA, August 20-26, 2018. Paul, a former member of The Beatles, known for &quot;Let It Be”, Paul, a former member of The Beatles, known for &quot;Let It Be”, Person Person Artifact Organization Org > Show_Org will be holding a concert at Carnegie Hall in New York. Location Location Product > Art > Music will be holding a concert at Carnegie Hall in New York. Facilty > GOE > Theatre (a) Named entity recognition result Location > GPE > City (b) Fine-grained NER result Figure 1: Example of NER and FG-NER For example, Sekine (2008) divided the coarse-grained category Organization into the fine-grained categories such as Political Party, Military, Sports Organization, Show Organization, as shown in Figure 2. Person International Org Family Government ... Location Organization ... Show Org Political Party Time Numx Political Org Cabinet Military Other Political Org Figure 2: Sekine’s Extended Named Entity (ENE) hierarchy FG-NER is still an open research domain, with little information concerning the state-of-the-art performance, the relation between training data size and performance, and how to select the best model for"
C18-1060,W02-2029,0,0.218657,"Missing"
C18-1060,P15-2048,0,0.023901,"eral SVM models (each for a top-level category) to classify the entities into the leaf-level categories. We use the following features for both SVM and CRF: bag-of-words, POS-tag, the number of digits in the word, the Brown cluster of the current word, the appearance of the word as a substring of a word in the Wikipedia ENE dictionary, the orthography features (the word is written in Kanji, Hiragana, Katakana or Romanji), is capital letter, and the last 2-3 characters. Those features are proved to be useful in previous work on named entity recognition (Ling and Weld, 2012; Yosef et al., 2012; Yogatama et al., 2015; Suzuki et al., 2016). Once we have the sequence labelling result, we have already known the surfaces and the top-level categories of the entities in the input sentence. We then use SVM to classify the entities into leaf-level categories. Because the number of leaf-level categories in each top-level categories is also not too large (e.g., less than 15), SVM can achieve a reasonable performance at this step. We also propose a method to incorporate dictionary information in both CRF and SVM step to improve the entire performance, as described in Section 3.4. 3.3 LSTM+CNN+CRF model for FG-NER We"
C18-1060,C12-2133,0,0.31149,"nd Datasets 2.1 FG-NER tag set The first challenge in FG-NER is defining a comprehensive tag set with a very large number of entity categories (Ling and Weld, 2012). There are two methods for defining a tag set (i.e., set of entity categories to recognize) in previous studies on FG-NER. The first method is to take the entity categories from a knowledge base such as Freebase (Bollacker et al., 2008) or YAGO (Suchanek et al., 2007), filtering out the categories with a small number of entities and merging the categories with similar semantic meaning into one FG-NER category (Ling and Weld, 2012; Yosef et al., 2012; Gillick et al., 2014). The second method is to manually build an entity hierarchy to cover important domains in the real world. Following the second method, Sekine et al. proposed an Extended Named Entity Hierarchy (ENEH), which contains 200 entity categories in a three-layer hierarchy, as shown in Figure 2 (Sekine et al., 2002; Sekine, 2008). In this paper, we use the entity hierarchy described by Sekine (2008), which contains 200 NE categories at the leaf-level, as our tag set3 . At the top level of the hierarchy, there are about twenty coarse-grained named entity categories, such as Perso"
C18-1060,P02-1060,0,0.404785,"Missing"
C18-1193,H05-1091,0,0.0760554,"ght lead to an incorrect impression to consider the sentence as actually positive. For instance, consider the following negative sentence with the words in the similar word lists written in bold3 : Marion Police Department have arrested TARGET , 20 , of Marion , in connection with the fatal hit. In this sentence, the extreme emphasis on “Police”, “TARGET” and “fatal” might lead to the incorrect prediction that this sentence is expressing a fatal event caused by police. In order to overcome this issue, we observe that police killing recognition can be seen as a relation identification problem (Bunescu and Mooney, 2005), attempting to decide whether the entities of interests (i.e, the “TARGET”) has a semantical relation of “killed by” with the similar words of “police” (if any) in the sentence or not. In such relation identification problem, it has been shown that the shortest dependency path connecting the two word of interests (i.e, the words “TARGET” and “police” in our case) in the dependency trees involve the most important context words for the problem (Bunescu and Mooney, 2005). Consequently, in this work, we propose to select the words along the shortest dependency paths between the entity name of in"
C18-1193,P07-1073,0,0.0271402,"vent types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence rep"
C18-1193,P15-1017,0,0.0470026,"To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce train"
C18-1193,P16-1046,0,0.0370437,"ment of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position embeddings and supervised attentions to inject external knowledge (i.e, the heuristics for guid"
C18-1193,P17-1020,0,0.0362323,"et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position embeddings and supervised attentions to i"
C18-1193,D17-1163,0,0.0856913,"Missing"
C18-1193,P14-1038,0,0.0168207,"for the problem of detecting police killings. To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, dis"
C18-1193,P16-1200,0,0.0253152,"killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position e"
C18-1193,P17-1164,0,0.495871,"ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position embeddings and supervised attentions to inject external knowledge (i.e, the heuristics for guidance words). Finally, supervised attention mechanisms have been used recently for several natural language tasks. For machine translation, the attention guidance is based on word alignment (Mi et al., 2016; Liu et al., 2016) while entity mentions are chosen as the guidance words for event detection (Liu et al., 2017a). Our work in this paper is different as we consider supervised attention for police killing recognition using semantical word lists and dependency parsing trees (Schuster and Manning, 2016) to guide the attention components. Our model features hierarchical LSTMs to tackle distant supervision data that does not emerge in such prior work. 3 Model We formalize the problem of finding people killed by police as follows. Let D be a set of documents (corpus), E = {ei }N i=1 be the set of entities (people) whose names appear in D (N is the number of the entities in E), and C = {ci }N i=1 be the set"
C18-1193,D16-1249,0,0.447331,"nd relatively low weights to the other important context words in the sentences. Such failure to adequately capture those context words would potentially lead to incorrect predictions for the containers. This problem is stem from the use of the position embeddings to specify the names of interests that might put too much emphasis on the current names. In order to solve this problem, we propose to integrate the supervised attention mechanisms into the hierarchical LSTM model that help to bias the attention scores toward the heuristically important words in the sentences (supervised attention) (Mi et al., 2016). In particular, we rely on linguistic intuitions to heuristically select the informative context words for the problem of police killing detection. These words are then used to guide the attention computation via penalizing the model parameters that generate low attention scores for such guidance words. We investigate several heuristics to choose the guidance words based on semantical word lists and dependency trees. The experiments show that the supervised attention mechanism with those heuristics helps to improve the performance of the hierarchical LSTM model and yield the state-of-the-art"
C18-1193,P09-1113,0,0.483699,"police killings from text is a relatively new problem in machine learning research with no available training datasets to supervise the models. The only sources of supervision on which we can rely for this problem are the current databases that record the names of the police-killed victims in the past. Among these databases, the Fatal Encounters1 (FE) database has emerged as the most comprehensive database with a relatively large number of recorded victims (over 23,000 victims). In order to take advantage of this database, (Keith et al., 2017) employs distant supervision (Craven et al., 1999; Mintz et al., 2009) that extracts person names from a corpus and aligns them with the victim names in the database. The matched names are considered as corresponding to people killed by police (positive entities) while the non-matched names constitute the negative examples in a binary classification problem for names in police killing detection. As the name itself does not carry much information, each extracted name is associated with the set of sentences in which the name appears in the corpus. This set of sentences is called the sentence container for the corresponding name (person). The sentence containers al"
C18-1193,W15-1506,1,0.947701,"f detecting police killings. To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been u"
C18-1193,P15-2060,1,0.947652,"f detecting police killings. To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been u"
C18-1193,D16-1085,1,0.85262,"knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extra"
C18-1193,N16-1034,1,0.946742,"trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke e"
C18-1193,W16-1618,1,0.912772,"trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke e"
C18-1193,reschke-etal-2014-event,0,0.0147358,"al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) th"
C18-1193,L16-1376,0,0.0539323,"haracterizing position embeddings and supervised attentions to inject external knowledge (i.e, the heuristics for guidance words). Finally, supervised attention mechanisms have been used recently for several natural language tasks. For machine translation, the attention guidance is based on word alignment (Mi et al., 2016; Liu et al., 2016) while entity mentions are chosen as the guidance words for event detection (Liu et al., 2017a). Our work in this paper is different as we consider supervised attention for police killing recognition using semantical word lists and dependency parsing trees (Schuster and Manning, 2016) to guide the attention components. Our model features hierarchical LSTMs to tackle distant supervision data that does not emerge in such prior work. 3 Model We formalize the problem of finding people killed by police as follows. Let D be a set of documents (corpus), E = {ei }N i=1 be the set of entities (people) whose names appear in D (N is the number of the entities in E), and C = {ci }N i=1 be the set of sentence containers for the entities in E (i.e, ci is the set of sentences that contain the name of the entity ei in D). Each entity ei in E has a label yei ∈ {0, 1}, denoting whether ei h"
C18-1193,D12-1042,0,0.0181933,"Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most rel"
C18-1193,N16-1174,0,0.401786,"sentence level classifiers, the performance of the EM-based framework drops significantly. We attribute this problem to the limitation of the EM-based framework to train the non-convex classifiers of deep learning, causing the inability to exploit the automatically learnt representations from deep learning and necessitating the use of complicated and laborious feature engineering. In order to overcome this problem, we propose a novel deep learning framework for the problem of police killing recognition via hierarchical long short-term memory networks (LSTM) (Hochreiter and Schmidhuber, 1997; Yang et al., 2016). Our model does not make individual predictions on each sentence with the latent variables but involves a direct prediction to the name of interest based on its sentence container. Two layers of LSTMs are applied to model the sentence containers. The first LSTM layer learns the representations for the sentences in the containers by recurring over their words (the word level). The second LSTM layer, on the other hand, consumes the sentence representations (the sentence level) to produce container representations for police killing predictions. Attention mechanisms are then introduced into both"
D18-1320,W17-4109,0,0.0294392,"Missing"
D18-1320,P17-1188,0,0.0393453,"Missing"
D18-1320,W17-4122,0,0.0255767,"Missing"
D18-1320,P15-2098,0,0.0633725,"Missing"
D18-1320,P15-1150,0,0.0298776,"Missing"
D18-1320,I17-2064,0,0.0399608,"Missing"
D18-1320,D16-1100,0,0.0504821,"Missing"
D18-1320,D17-1027,0,0.0325963,"Missing"
E17-1085,P14-2131,0,0.0261195,"ng this approach. Additionally, a discussion on the proposed method’s shortcomings is provided in the analysis of error cases. 1 Introduction Vector-based language representation schemes have gained large popularity in Natural Language Processing (NLP) research in the recent years. Their success comes from both the asserted benefits in several NLP tasks and from the ability to built them from unannotated textual data, widely available in the World Wide Web. The tasks benefiting from vector representations include Part-ofSpeech (POS) tagging (dos Santos and Zadrozny, 2014), dependency parsing (Bansal et al., 2014), Named Entity Recognition (NER) (Seok et al., 1 www.wiktionary.org 905 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 905–915, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics in several semantic relatedness test sets, covering words, senses and entire texts. Recski et al. (2016) presented a hybrid system for measuring the semantic similarity of word pairs, using a combination of four distributional representations (SENNA (Collobert and Weston, 2008), (Huang et al., 201"
E17-1085,P14-2050,0,0.271487,"ntations from Concept Definitions Danilo S. Carvalho and Minh Le Nguyen Japan Advanced Institute of Science and Technology 1-1 Asahidai, Nomi City, Ishikawa, Japan {danilo, nguyenml}@jaist.ac.jp Abstract 2016), Machine Translation (Sutskever et al., 2014), among others. Such representation schemes are, however, not an all-in-one solution for the many NLP application scenarios. Thus, different representation methods were developed, each one focusing in a limited set of concerns, e.g., semantic relatedness measurement (Mikolov et al., 2013; Pennington et al., 2014) and grammatical dependencies (Levy and Goldberg, 2014). Most of the popular methods are based on a distributional approach: the meaning of a word is defined by the context of its use, i.e., the neighboring words. However, distributional representations carry no explicit linguistic information and cannot easily represent some important semantic relationships, such as synonymy and antonymy (Nguyen et al., 2016). Further problems include the difficulty in obtaining representations for out-of-vocabulary (OOV) words and complex constructs (collocations, idiomatic expressions), the lack of interpretable representations (Faruqui and Dyer, 2015), and the"
E17-1085,P16-2074,0,0.115995,"cation scenarios. Thus, different representation methods were developed, each one focusing in a limited set of concerns, e.g., semantic relatedness measurement (Mikolov et al., 2013; Pennington et al., 2014) and grammatical dependencies (Levy and Goldberg, 2014). Most of the popular methods are based on a distributional approach: the meaning of a word is defined by the context of its use, i.e., the neighboring words. However, distributional representations carry no explicit linguistic information and cannot easily represent some important semantic relationships, such as synonymy and antonymy (Nguyen et al., 2016). Further problems include the difficulty in obtaining representations for out-of-vocabulary (OOV) words and complex constructs (collocations, idiomatic expressions), the lack of interpretable representations (Faruqui and Dyer, 2015), and the necessity of specific model construction for crosslanguage representation. This paper presents a linguistically motivated language representation method, aimed at capturing and providing information unavailable on distributional approaches. Our contributions are: (i) a technique for building conceptual representations of linguistic elements (morphemes, wo"
E17-1085,P98-1013,0,0.114525,"exploring the details of each sense definition. This includes term etymologies, morphological decomposition and translation links, available in Wiktionary. Another difference is that the translation links are used to map senses between languages in this work, whereas they are used for bridging gaps between sense sets on monolingual text in Pilehvar and Navigli (2015). Another concern regarding distributional representations is their lack of interpretability from a linguistic standpoint. Faruqui and Dyer (2015) addresses this point, relying on linguistic information from Wordnet, Framenet (F. Baker et al., 1998), among other sources (excluding Wiktionary), to build interpretable word vectors. Such vectors accommodate several types of information, ranging from Part-of-Speech (POS) tags to sentiment classification and polarity. The obtained linguistic vectors achieved very good performance in a semantic similarity test. Those vectors, however, do not include morphological and translation information, offering discrete, binary features. Regarding the extraction of definition data from Wiktionary, an effective approach is presented by Zesch et al. (2008a), which is also used for building a semantic repre"
E17-1085,P15-2076,0,0.214499,"encies (Levy and Goldberg, 2014). Most of the popular methods are based on a distributional approach: the meaning of a word is defined by the context of its use, i.e., the neighboring words. However, distributional representations carry no explicit linguistic information and cannot easily represent some important semantic relationships, such as synonymy and antonymy (Nguyen et al., 2016). Further problems include the difficulty in obtaining representations for out-of-vocabulary (OOV) words and complex constructs (collocations, idiomatic expressions), the lack of interpretable representations (Faruqui and Dyer, 2015), and the necessity of specific model construction for crosslanguage representation. This paper presents a linguistically motivated language representation method, aimed at capturing and providing information unavailable on distributional approaches. Our contributions are: (i) a technique for building conceptual representations of linguistic elements (morphemes, words, collocations, idiomatic expressions) from a single collaborative language resource (Wiktionary 1 ); (ii) a method of combining said representations and comparing them to obtain a semantic similarity measurement. The conceptual r"
E17-1085,D14-1162,0,0.0845065,"www.wiktionary.org 905 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 905–915, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics in several semantic relatedness test sets, covering words, senses and entire texts. Recski et al. (2016) presented a hybrid system for measuring the semantic similarity of word pairs, using a combination of four distributional representations (SENNA (Collobert and Weston, 2008), (Huang et al., 2012), word2vec (Mikolov et al., 2013), and GloVe (Pennington et al., 2014)), WordNet-based features and 4lang (Kornai, 2010) graph-based features to train a RBF kernel Support Vector Regression on the SimLex-999 (Hill et al., 2015) data set. This system achieved state-ofthe-art performance in SimLex-999. The work presented in this paper takes a similar approach to Pilehvar and Navigli (2015), but stops short on obtaining a far reaching concept graph. Instead, it focuses on exploring the details of each sense definition. This includes term etymologies, morphological decomposition and translation links, available in Wiktionary. Another difference is that the translati"
E17-1085,J15-4004,0,0.32562,"05–915, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics in several semantic relatedness test sets, covering words, senses and entire texts. Recski et al. (2016) presented a hybrid system for measuring the semantic similarity of word pairs, using a combination of four distributional representations (SENNA (Collobert and Weston, 2008), (Huang et al., 2012), word2vec (Mikolov et al., 2013), and GloVe (Pennington et al., 2014)), WordNet-based features and 4lang (Kornai, 2010) graph-based features to train a RBF kernel Support Vector Regression on the SimLex-999 (Hill et al., 2015) data set. This system achieved state-ofthe-art performance in SimLex-999. The work presented in this paper takes a similar approach to Pilehvar and Navigli (2015), but stops short on obtaining a far reaching concept graph. Instead, it focuses on exploring the details of each sense definition. This includes term etymologies, morphological decomposition and translation links, available in Wiktionary. Another difference is that the translation links are used to map senses between languages in this work, whereas they are used for bridging gaps between sense sets on monolingual text in Pilehvar an"
E17-1085,P12-1092,0,0.0173339,"sal et al., 2014), Named Entity Recognition (NER) (Seok et al., 1 www.wiktionary.org 905 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 905–915, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics in several semantic relatedness test sets, covering words, senses and entire texts. Recski et al. (2016) presented a hybrid system for measuring the semantic similarity of word pairs, using a combination of four distributional representations (SENNA (Collobert and Weston, 2008), (Huang et al., 2012), word2vec (Mikolov et al., 2013), and GloVe (Pennington et al., 2014)), WordNet-based features and 4lang (Kornai, 2010) graph-based features to train a RBF kernel Support Vector Regression on the SimLex-999 (Hill et al., 2015) data set. This system achieved state-ofthe-art performance in SimLex-999. The work presented in this paper takes a similar approach to Pilehvar and Navigli (2015), but stops short on obtaining a far reaching concept graph. Instead, it focuses on exploring the details of each sense definition. This includes term etymologies, morphological decomposition and translation li"
E17-1085,zesch-etal-2008-extracting,0,0.0602096,"Missing"
I13-1088,H01-1069,0,0.130565,"Missing"
I13-1088,P04-1043,0,0.122341,"Missing"
I13-1088,voorhees-tice-2000-trec,0,0.130671,"Missing"
I13-1138,P11-1062,0,0.0192858,"erence rules that specify the entailment relationship between two triples. Therefore, we propose several simple heuristic methods to extract additional binary relations from a text segment. First, we extract “isA” relations from three information sources: i) co-reference resolution information; ii) noun phrases which the ending parts are recognized as a named entity;; and iii) “abbrev” relations in dependency parses. Second, entailment rules or inference rules which specify directional entailment relations between two text fragments have been shown to be useful for RTE and question answering (Berant et al., 2011). In this study, we transform triples generated by REVERB by looking up the corpus of 30, 000 entailment rules between typed predicates obtained from (Berant et al., 2011). 3 Contradiction Detection by Matching Semantic Frames Let us denote an SRL frame by a tuple S = {V, E1 , . . . , Ek }, where V is used to denote the verb predicate; and Ei represents the i-th SRL element in the frame. Each SRL element has a type and underlying words. Types of SRL elements follow the annotation guideline in PropBank (Palmer et al., 2005). SRL elements can be arguments or modifiers (adjuncts). We denote two s"
I13-1138,W07-1401,0,0.354575,"y relations extracted from sentences for the CD task. The proposed system consists of two modules. The first module relies on the alignment of semantic role (SRL) frames extracted from the text and the hypothesis in each pair while the second one performs contradiction detection over binary relations extracted from the pair. If the SRL-based module fails to identify the contradiction relationship in the pair, the second module will be applied. We expect that the second module will improve the coverage of the first one. Evaluation experiments on standard data sets obtained from RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008; Bentivogli et al., 2009) show that the proposed system achieves better recall and F1 score for contradiction detection than most of baseline methods, and the same recall as a state of the art supervised method for the task. 2 Linguistic Analysis After parsing the text and the hypothesis of a pair by using Stanford CoreNLP 1 , we utilize SENNA 1 Stanford CoreNLP is available online http://nlp.stanford.edu/software/corenlp.shtml 1017 International Joint Conference on Natural Language Processing, pages 1017–1021, Nagoya, Japan, 14-18 October 2013. on: package2 (Collobe"
I13-1138,W04-3205,0,0.0542735,"filter out “not contradictory” SRL frame pairs by calculating their relatedness. The relatedness of two SRL frames is defined as product of the relatedness of their verb predicates and SRL elements: (t) online (t) max (t) (h) Si ∈T,Sj ∈H (h) (1) (2) R(S1 , S2 ) = R(V1 , V2 )×maxi,j R(Ei , Ej ), (2) 1018 where R represents the relatedness between two (1) (t) (2) (h) items; Ei ∈ S1 and Ej ∈ S2 are SRL el(t) (h) ements; V1 and V2 are verbs of S1 and S2 , respectively. The relatedness of two verbs is assigned to 1.0 if their relation is found in WordNet (Fellbaum, 1998) or in VerbOcean database (Chklovski and Pantel, 2004). In other cases, we employ WordNet::Similarity package (Pedersen et al., 2004) to compute the similarity of two verbs. The related(1) (2) ness of two SRL elements Ei and Ej is defined as the local lexical level matching score. The relatedness of two SRL frames is compared with a threshold. If it is below the threshold, then (t) (h) S1 and S2 are not related. If two SRL frames are related, we consider two situations: 1) two verb predicates are matching and 2) Two verb predicates are opposite. Note that if two verb predicates are neither matching nor op(t) (h) posite, f (S1 , S2 ) is also assig"
I13-1138,J05-1004,0,0.00925474,"fragments have been shown to be useful for RTE and question answering (Berant et al., 2011). In this study, we transform triples generated by REVERB by looking up the corpus of 30, 000 entailment rules between typed predicates obtained from (Berant et al., 2011). 3 Contradiction Detection by Matching Semantic Frames Let us denote an SRL frame by a tuple S = {V, E1 , . . . , Ek }, where V is used to denote the verb predicate; and Ei represents the i-th SRL element in the frame. Each SRL element has a type and underlying words. Types of SRL elements follow the annotation guideline in PropBank (Palmer et al., 2005). SRL elements can be arguments or modifiers (adjuncts). We denote two sets of (t) SRL frames of T and H by T = {Si }m i=1 and (h) n H = {Sj }j=1 , in which m and n are the number of SRL frames extracted from T and H, respectively. 2 SENNA is available labs.com/senna/ 3.1 Contradiction Detection Model The contradiction detection model consists of a contradiction function FS (T, H) which calculates the contradiction measurement for the pair (T, H) on their SRL frames. Then, FS (T, H) is compared with a threshold value t1 . If FS (T, H) ≥ t1 , we determine that T and H are contradictory. In orde"
I13-1138,P08-1118,0,0.0520952,"Missing"
I13-1138,D11-1142,0,0.0499857,"s a state of the art supervised method for the task. 2 Linguistic Analysis After parsing the text and the hypothesis of a pair by using Stanford CoreNLP 1 , we utilize SENNA 1 Stanford CoreNLP is available online http://nlp.stanford.edu/software/corenlp.shtml 1017 International Joint Conference on Natural Language Processing, pages 1017–1021, Nagoya, Japan, 14-18 October 2013. on: package2 (Collobert et al., 2011) for semantic role labeling. Then, we extract SRL frames from the output of SENNA. An SRL frame consists of a verb predicate and a list of SRL elements. In the system, we use REVERB (Fader et al., 2011) – a tool which can automatically identify and extract binary relations from English sentences. The input of REVERB is a POS-tagged and NP-chunked sentence and its output is a set of extraction triples of the form (arg1, R, arg2), in which R represents the relation phrase between two arguments: arg1 and arg2. REVERB cannot extract some useful relations such as “isA” relations which specify the equivalent relation of two objects. In addition, in some cases, relation phrases of two extraction triples cannot be compared without using inference rules that specify the entailment relationship betwee"
I13-1138,N04-3012,0,0.0177899,"e relatedness of two SRL frames is defined as product of the relatedness of their verb predicates and SRL elements: (t) online (t) max (t) (h) Si ∈T,Sj ∈H (h) (1) (2) R(S1 , S2 ) = R(V1 , V2 )×maxi,j R(Ei , Ej ), (2) 1018 where R represents the relatedness between two (1) (t) (2) (h) items; Ei ∈ S1 and Ej ∈ S2 are SRL el(t) (h) ements; V1 and V2 are verbs of S1 and S2 , respectively. The relatedness of two verbs is assigned to 1.0 if their relation is found in WordNet (Fellbaum, 1998) or in VerbOcean database (Chklovski and Pantel, 2004). In other cases, we employ WordNet::Similarity package (Pedersen et al., 2004) to compute the similarity of two verbs. The related(1) (2) ness of two SRL elements Ei and Ej is defined as the local lexical level matching score. The relatedness of two SRL frames is compared with a threshold. If it is below the threshold, then (t) (h) S1 and S2 are not related. If two SRL frames are related, we consider two situations: 1) two verb predicates are matching and 2) Two verb predicates are opposite. Note that if two verb predicates are neither matching nor op(t) (h) posite, f (S1 , S2 ) is also assigned to 0. In the system, that two verbs are matching are determined by utilizin"
I13-1138,D08-1002,0,0.0190702,"tion answering systems or multi-document summarization systems (Harabagiu et al., 2006). The task is to detect whether the contradiction relationship exists in a pair of a text T and a hypothesis H. There are several approaches to the CD task. Contradiction detection can be formalized as a binary classification problem (Harabagiu et al., 2006; De Marneffe et al., 2008). The main effort of work which adopt this approach is to find out effective features for recognizing contradiction. The other approach is using functional relations indicated by verb or noun phrases for detecting contradiction (Ritter et al., 2008). Beyond string-based matching approaches, one can approach to the CD task by applying logical inference techniques. Although the logical inference approach may obtain good precision, it is not widely used for the task due to the fact that full predicate-logic analysis is currently not practical for wide-coverage semantic processing (Burchardt et al., 2009). Given that fact, (Burchardt et al., 2009) pointed out that using shallow semantic representations based on predicate-argument structures and frame knowledge is an intuitive and straightforward approach to textual inference tasks. In contra"
I13-1138,P08-1008,0,0.0185205,"trast to previous work, we combine shallow semantic representations derived from semantic role labeling with binary relations extracted from sentences in a rule-based framework. Evaluation experiments conducted on standard data sets indicated that our system achieves better recall and F1 score for contradiction detection than most of baseline methods, and the same recall as a state of the art supervised method for the task. 1 Introduction Contradiction detection (CD) in text is a fundamental task in natural language understanding, and necessary for many applications (De Marneffe et al., 2008; Voorhees, 2008). For instance, contradictions need to be recognized by question answering systems or multi-document summarization systems (Harabagiu et al., 2006). The task is to detect whether the contradiction relationship exists in a pair of a text T and a hypothesis H. There are several approaches to the CD task. Contradiction detection can be formalized as a binary classification problem (Harabagiu et al., 2006; De Marneffe et al., 2008). The main effort of work which adopt this approach is to find out effective features for recognizing contradiction. The other approach is using functional relations ind"
I17-1054,Q13-1033,0,0.0139599,"cohyponym nature. In the SKIP-GRAM model, the contexts of a word are the words surrounding it in the text. However, there is a limitation of SKIP-GRAM word embeddings: Contexts need not correspond to all of the words and the number of context-types maybe larger than the number of word-types. Therefore, dependencybased contexts capture more information than bagof-words contexts. In Figure 3, the contexts are extracted for each word in the sentence and the contexts of a word are derived from syntactic relations of a word in the sentence. For parsing syntactic dependencies, we use a parser from (Goldberg and Nivre, 2013) for Stanford dependencies and the corpus are tagged with parts-of-speech using Stanford parser 1 . After parsing each sentence, we consider word context as Figure 3: For a target word w with modifiers m1 , m2 , ..., mn and a head h, we form the contexts as (m1 , lbl1 ), ..., (mn , lbln ), (h, lblh−1 ), where lbl is the type of the dependency relation between the head and the modifier, lbl−1 is used to mark the inverse-relation. The advantages of syntactic dependencies are inclusive and more focused than bag-of-words. In addition, they can capture relations that out-of-reach with small windows"
I17-1054,D14-1181,0,0.0161256,"Missing"
I17-1054,P14-2050,0,0.173719,"ture vectors and attending on the best feature vectors. CharAVs can capture the morphology and shape of a word. The morphological and shape information illustrate how words are 536 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 536–544, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP while the LexW2Vs can capture the sentiment of words (Shin et al., 2016). DependencyW2Vs derive the syntactic relations of words and exhibit more functional similarity than the original skipgram embeddings led to form global syntactic contexts of words (Levy and Goldberg, 2014). Twitter sentiment label belongs to global sentence level while traditional word embeddings capture local contexts only. Therefore, DependencyW2Vs are useful in capturing global context of tweets. On the other hand, we create two advanced embeddings by integrating LexW2Vs and CharAVs with ContinuousW2Vs and DependencyW2Vs for BiCGRNN. A Bi-CGRNN is enhanced from a standard Bi-GRNN of (Chung et al., 2014) by incorporating contextual features (e.g., dependency-based contexts) into the model. The Bi-CGRNN produces a sentence-level representation from sentence compositions in order to maintain th"
I17-1054,S13-2053,0,0.123948,"xtual words Colloquial words & Emoticons Table 1: The types of words in lexicon dataset. We call such lexicon-based features as lexicon embeddings because embeddings are a feature input of deep learning model and describe the properties of a word or a phrase. Each word in each lexicon datasets actually has many values that can be built by training a neural network. The deep learning model uses this input for calculating a computational graph (weight matrix) that describe relatedness among words (n-gram order). • Bing Liu Opinion Lexicon (Hu and Liu, 2004). 2.6 • NRC Hashtag Sentiment Lexicon (Mohammad et al., 2013). Character Attention Vectors (CharAVs) Figure 2 describes the way of forming a character attention vector. We use a DeepCNN with two wide convolutions. The first convolution produces a fixed-size character feature vector named mgram features by extracting local features around each character window of the given word and using a max pooling over vertical character windows. The second convolution retrieves the fixedsize character feature and transforms the representation to yield a character attention vector by performing max pooling on each row of matrix instead of each column. The purpose of"
I17-1054,C14-1008,0,0.546944,"Japan Advanced Institute of Science and Technology Ishikawa, Japan {huy.nguyen, nguyenml}@jaist.ac.jp Abstract word representation and deep learning achieved impressive results because word embeddings enable efficient computation of word similarities through low-dimensional matrix operations (Kim, 2014). In addition, deep learning models achieved remarkable performance. Some researchers use Convolution Neural Network (CNN) for sentiment classification. CNN utilizes convolution filters applied to local features. CNN models has been shown to be effective for NLP. For example, the model of (Dos Santos and Gatti, 2014) used CNN to form a sentence-level representation for sentiment classification. In addition, Bidirectional Gated Recurrent Neural Network (Bi-GRNN) is another deep learning model that has achieved an excellent result for sentiment analysis and other traditional tasks (Chung et al., 2014). Inspired by the models above, the goal of this research is to build a model for exploiting syntax, semantic, sentiment and context of tweets by constructing four kinds of embeddings: CharAVs, LexW2Vs, ContinuousW2Vs and DependencyW2Vs. On the other hand, we modify BiGRNN of (Chung et al., 2014) into Bi-CGRNN"
I17-1054,W17-5220,0,0.0381298,"Missing"
I17-1054,D11-1014,0,0.0470577,"tter sentiment classification datasets. Experimental results show that our model can improve the classification accuracy of sentence-level sentiment analysis in Twitter social networking. 1 Introduction Tweet-level sentiment classification is a fundamental task of sentiment analysis in Twitter social networking and is essential to understand user generated contents in social networking. Twitter sentiment classification have intensively researched in recent years (Go et al., 2009) (Nakov et al., 2016). There are many works related to deep learning methods involved learning word representation (Socher et al., 2011). Word representation is central to deep learning and essential feature extractor that encode different features of words in their dimensions. The combination of • We construct a tweet processor which standardizes tweets by using pre-processing steps and a semantic rule-based approach. We construct four kinds of embeddings: CharAvs, LexW2Vs, ContinuousW2Vs and DependencyW2Vs. A DeepCNN is used for training CharAVs by producing fixed-size feature vectors and attending on the best feature vectors. CharAVs can capture the morphology and shape of a word. The morphological and shape information ill"
I17-1054,W11-2207,0,0.0285729,"s, LexW2Vs and DependencyW2Vs, where CharAVs are generated from a DeepCNN. The DeepCNN is constructed from two wide convolutions which can learn to recognize specific n-grams at every position in a word and allow features to be extracted independently of these positions in the word. These features maintain the order and relative positions of characters and are formed at a higher abstract level. In those embeddings, ContinuousW2Vs take the syntax and semantic of words (Mikolov et al., 2013) • Health Care Reform (HCR): This dataset was constructed by crawling tweets containing the hashtag #hcr (Speriosu et al., 2011). The task of this paper is to predict positive/negative tweets. 2.3 Tweet Processor We first take the unique properties of Twitter to reduce the feature space such as Username, Usage of links, None, URLs and Repeated Letters. We then process retweets, stop words, links, URLs, mentions, punctuation and accentuation. For emoticons in the dataset, we consider them as words in order that deep learning classifiers can capture information from emoticons. Because the test set contains emoticons, they do not influence classifiers if emoticons do not contain in its training data. Therefore, the emotic"
I17-1054,C14-1018,0,0.0213789,"its semantic relatedness with characters of each word. Another advantage is that this attention model is differentiable, so that it could be easily trained together with other components in an end-to-end fashion. In the next sub-section, we introduce the • Sentiment140 Lexicon (Mohammad et al., 2013). • NRC Sentiment140 Lexicon (Kiritchenko et al., 2014). • MaxDiff Twitter Sentiment Lexicon (Kiritchenko et al., 2014). • National Research Council Canada (NRC) Hashtag Affirmative and Negated Context Sentiment Lexicon (Kiritchenko et al., 2014). • Large-Scale Twitter-Specific Sentiment Lexicon (Tang et al., 2014). The purpose of building LexW2Vs is to take the different kinds of words for capturing the different sentiments of words. Table 1 illustrates the type of words for each dataset. We share idea with (Shin et al., 2016). However, our LexW2Vs are distinguished their approaches in the aspect: We cover the colloquial expressions and colloquial emoticons in tweets by using Large-scale TwitterSpecific Sentiment Lexicon. 539 a word at the margins. The resulting matrix has dimension d × (s + m − 1). structure of CNN with wide convolution. 2.7 To construct context embeddings, we use the idea of (Levy an"
I17-1065,D15-1168,0,0.0278571,"y (JAIST) nguyenml@jaist.ac.jp Abstract sentiment polarity (positive, negative) of a comment or review. Wang (2012) used a Support Vector Machine variant with Naive Bayes feature (NBSVM). Presenting a document or a sentence with Bag of bi-gram features, NBSVM consistently performs well across datasets of long and short reviews. Recently, the success of deep learning in natural language processing has led to many efficient methods for sentiment analysis such as Paragraph Vector (Le and Mikolov, 2014), CNN (Kalchbrenner et al., 2014; Kim, 2014; Zhang and Wallace, 2015), LSTM (Wang et al., 2015; Liu et al., 2015). In Paragraph Vector, Le and Mikolov employed the technique of Word embedding representation using neural networks (Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013) to represent a document or paragraph as a vector. This document modeling outperformed the Bag of Words model in sentiment analysis and information retrieval. Li (2015) has enhanced the architecture of Paragraph Vector by allowing the model to predict not only words but also n-gram features (DVngram). CNN is capable of capturing local relationships between neighbor w"
I17-1065,P11-1015,0,0.489292,"ral network. We proposed an ensemble method to employ these scores. similar sentences/documents into similar vectors. For that reason, we designed an autoencoder model to learn representation vectors for sentences/documents and used these vectors for clustering. The prediction score of NBSVM method is provided to enhance the sentiment prediction of each cluster. Figure 1 shows the architecture of our framework. We compared our method with NBSVM, CNN, LSTM, Paragraph Vector, LinearEnsemble (Mesnil et al., 2014), DSCNN (Zhang et al., 2016) on three well-known datasets: IMDB large movie reviews (Maas et al., 2011) for document level, Pang & Lee (2005) movie reviews and Stanford Sentiment Treebank (Socher et al., 2013) for sentence level. The experimental results show that our method consistently performs well on both document and sentence level data. The main contributions of this work are as follows: 2 Sentiment representation learning In this section, we describe the freezing scheme to generate sentiment vectors from two models: (i) CNN, (ii) LSTM; and a method to employ these vectors. To feed into LSTM/CNN model, each word of a sentence/document is transformed into a word embedding vector using Word"
I17-1065,P15-1162,0,0.0297685,"Missing"
I17-1065,P05-1015,0,0.626413,"thod to employ these scores. similar sentences/documents into similar vectors. For that reason, we designed an autoencoder model to learn representation vectors for sentences/documents and used these vectors for clustering. The prediction score of NBSVM method is provided to enhance the sentiment prediction of each cluster. Figure 1 shows the architecture of our framework. We compared our method with NBSVM, CNN, LSTM, Paragraph Vector, LinearEnsemble (Mesnil et al., 2014), DSCNN (Zhang et al., 2016) on three well-known datasets: IMDB large movie reviews (Maas et al., 2011) for document level, Pang & Lee (2005) movie reviews and Stanford Sentiment Treebank (Socher et al., 2013) for sentence level. The experimental results show that our method consistently performs well on both document and sentence level data. The main contributions of this work are as follows: 2 Sentiment representation learning In this section, we describe the freezing scheme to generate sentiment vectors from two models: (i) CNN, (ii) LSTM; and a method to employ these vectors. To feed into LSTM/CNN model, each word of a sentence/document is transformed into a word embedding vector using Word2Vec1 . Le and Mikolov (2014) extended"
I17-1065,P14-1062,0,0.0318203,"ST) ntienhuy@jaist.ac.jp Nguyen Minh Le Japan Advanced Institute of Science and Technology (JAIST) nguyenml@jaist.ac.jp Abstract sentiment polarity (positive, negative) of a comment or review. Wang (2012) used a Support Vector Machine variant with Naive Bayes feature (NBSVM). Presenting a document or a sentence with Bag of bi-gram features, NBSVM consistently performs well across datasets of long and short reviews. Recently, the success of deep learning in natural language processing has led to many efficient methods for sentiment analysis such as Paragraph Vector (Le and Mikolov, 2014), CNN (Kalchbrenner et al., 2014; Kim, 2014; Zhang and Wallace, 2015), LSTM (Wang et al., 2015; Liu et al., 2015). In Paragraph Vector, Le and Mikolov employed the technique of Word embedding representation using neural networks (Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013) to represent a document or paragraph as a vector. This document modeling outperformed the Bag of Words model in sentiment analysis and information retrieval. Li (2015) has enhanced the architecture of Paragraph Vector by allowing the model to predict not only words but also n-gram featu"
I17-1065,D14-1181,0,0.0270188,"Missing"
I17-1065,D11-1014,0,0.0601764,"ires an intensive effort. Recently, the emergence of deep learning models has provided an efficient way to learn continuous representation vectors for sentiment classification. Bengio (2003) and Mikolov (2013) introduced learning techniques for semantic word representation. By using a neural network in the context of a word prediction task, the authors generated word embedding vectors carrying semantic meanings. Embedding vectors of words which share similar meanings are close to each other. Semantic information maybe provides opposite opinions in different contexts. Therefore, some research (Socher et al., 2011; Tang et al., 2014) worked on learning sentiment-specific word representation by employing sentiment text. For sentence and document level, composition approach attracted many studies. Yessenalina and Cardie (2011) modeled each word as a matrix and used 7 Conclusion In this work, we introduced a novel approach to synthesize feature vectors for sentiment analysis from CNN, LSTM. These vectors provide a simple and efficient way to integrate the strong abilities of these models. For sentiment classification with CNN, LSTM vectors, we proposed a 3-layer neural network which efficiently takes adva"
I17-1065,J11-2001,0,0.0195262,"Missing"
I17-1065,D15-1167,0,0.0311833,"s were employed to learn sentence representation for sentiment classification such as DRNN with binary parse trees (Irsoy and Cardie, 2014), Recursive tensor neural network with sentiment treebank (Socher et al., 2013). CNN has recently been applied efficiently for semantic composition (Kim, 2014; Zhang and Wallace, 2015). This technique uses convolutional filters to capture local dependencies in term of context windows and applies a pooling layer to extract global features. Le and Mikolov (2014) applied paragraph information into the word embedding technique to learn semantic representation. Tang et al. (2015) used CNN or LSTM to learn sentence representation and encoded these semantic vectors in document representation by Gated recurrent neural network. Zhang (2016) proposed Dependency Sensitive CNN to build hierarchically textual representations by processing pretrained word embeddings. Wang (2016) used a regional CNN-LSTM to predict the valence arousal ratings of texts. In our work, we designed a freezing approach for learning efficiently sentiment document representation from two variant deep-learning models: CNN and LSTM. Afterward, these sentimentspecific vectors and the semantic DVngram vect"
I17-1065,P14-1146,0,0.030026,"ort. Recently, the emergence of deep learning models has provided an efficient way to learn continuous representation vectors for sentiment classification. Bengio (2003) and Mikolov (2013) introduced learning techniques for semantic word representation. By using a neural network in the context of a word prediction task, the authors generated word embedding vectors carrying semantic meanings. Embedding vectors of words which share similar meanings are close to each other. Semantic information maybe provides opposite opinions in different contexts. Therefore, some research (Socher et al., 2011; Tang et al., 2014) worked on learning sentiment-specific word representation by employing sentiment text. For sentence and document level, composition approach attracted many studies. Yessenalina and Cardie (2011) modeled each word as a matrix and used 7 Conclusion In this work, we introduced a novel approach to synthesize feature vectors for sentiment analysis from CNN, LSTM. These vectors provide a simple and efficient way to integrate the strong abilities of these models. For sentiment classification with CNN, LSTM vectors, we proposed a 3-layer neural network which efficiently takes advantages of these vect"
I17-1065,P10-1040,0,0.0655604,"ent or a sentence with Bag of bi-gram features, NBSVM consistently performs well across datasets of long and short reviews. Recently, the success of deep learning in natural language processing has led to many efficient methods for sentiment analysis such as Paragraph Vector (Le and Mikolov, 2014), CNN (Kalchbrenner et al., 2014; Kim, 2014; Zhang and Wallace, 2015), LSTM (Wang et al., 2015; Liu et al., 2015). In Paragraph Vector, Le and Mikolov employed the technique of Word embedding representation using neural networks (Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013) to represent a document or paragraph as a vector. This document modeling outperformed the Bag of Words model in sentiment analysis and information retrieval. Li (2015) has enhanced the architecture of Paragraph Vector by allowing the model to predict not only words but also n-gram features (DVngram). CNN is capable of capturing local relationships between neighbor words in a sentence but fails for long-distance dependencies. LSTM can handle CNN’s limitation because it is able to memorize information for a long period of time. Our motivation is to build a combination app"
I17-1065,P16-2037,0,0.0237637,"Missing"
I17-1065,P12-2018,0,0.0363679,"imes. A whole lot foul, freaky and funny. L 1 0 0 1 Table 5: Examples of the wrong prediction. L denotes the true label with 0,1 for negative, positive sentiment labels respectively) 6 Related work Sentiment analysis is a study of determining people’s opinions, emotions toward to entities. Taboada (2011) assigned sentiment labels to text by extracting sentiment words. Liu (2012) formulated the sentiment analysis as a classification task and applied machine learning techniques for this problem. In this approach, dominant research concentrated on designing effective features such as word ngram (Wang and Manning, 2012), emoticon (Zhao et al., 2012), sentiment words (Kiritchenko et al., 2014). However, designing handcraft features requires an intensive effort. Recently, the emergence of deep learning models has provided an efficient way to learn continuous representation vectors for sentiment classification. Bengio (2003) and Mikolov (2013) introduced learning techniques for semantic word representation. By using a neural network in the context of a word prediction task, the authors generated word embedding vectors carrying semantic meanings. Embedding vectors of words which share similar meanings are close"
I17-1065,P15-1130,0,0.0137006,"ience and Technology (JAIST) nguyenml@jaist.ac.jp Abstract sentiment polarity (positive, negative) of a comment or review. Wang (2012) used a Support Vector Machine variant with Naive Bayes feature (NBSVM). Presenting a document or a sentence with Bag of bi-gram features, NBSVM consistently performs well across datasets of long and short reviews. Recently, the success of deep learning in natural language processing has led to many efficient methods for sentiment analysis such as Paragraph Vector (Le and Mikolov, 2014), CNN (Kalchbrenner et al., 2014; Kim, 2014; Zhang and Wallace, 2015), LSTM (Wang et al., 2015; Liu et al., 2015). In Paragraph Vector, Le and Mikolov employed the technique of Word embedding representation using neural networks (Bengio et al., 2003; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013) to represent a document or paragraph as a vector. This document modeling outperformed the Bag of Words model in sentiment analysis and information retrieval. Li (2015) has enhanced the architecture of Paragraph Vector by allowing the model to predict not only words but also n-gram features (DVngram). CNN is capable of capturing local relationships"
I17-1065,D11-1016,0,0.0257268,"013) introduced learning techniques for semantic word representation. By using a neural network in the context of a word prediction task, the authors generated word embedding vectors carrying semantic meanings. Embedding vectors of words which share similar meanings are close to each other. Semantic information maybe provides opposite opinions in different contexts. Therefore, some research (Socher et al., 2011; Tang et al., 2014) worked on learning sentiment-specific word representation by employing sentiment text. For sentence and document level, composition approach attracted many studies. Yessenalina and Cardie (2011) modeled each word as a matrix and used 7 Conclusion In this work, we introduced a novel approach to synthesize feature vectors for sentiment analysis from CNN, LSTM. These vectors provide a simple and efficient way to integrate the strong abilities of these models. For sentiment classification with CNN, LSTM vectors, we proposed a 3-layer neural network which efficiently takes advantages of these vectors. In addition, we proposed a strategy to cluster documents/sentences by their similarity. In each cluster, we applied an ensemble method of the 3-layer neural network and NBSVM. It achieves th"
I17-1065,N16-1177,0,0.025952,"Missing"
K16-2020,J09-3003,0,0.0521729,"ith modal verbs, patterns indicate the passive voice expression or patterns begin with a prepositions which express the purpose. Base on pre-defined regular expressions, we extract a list of POS patterns that have high frequency (>= 100) in training corpus. Table 3 shows top patterns extracted from the training corpus. • Similarity features: instead of using the cosine similarity between whole text span of two arguments, we compute 5 cosine similarity scores of nouns, noun phrases, verbs, verb phrase, adjectives between two arguments to obtain similarity features. • MPQA Subjectivity Lexicon (Wilson et al., 2009)- feature): We realize that the polarity (positive, negative, neural) of words may be a good indicator for machine learning algorithms to identify the sense of discourse rela• Word2Vec pair features: Some pair of words have the same context relationship that 146 may reveal the meaning of discourse relation. Such as, ”find” and ”know” may reveal a Contingency.Cause.Result discourse relations. First, for each sense, we create a word pair list from word pairs of arguments of discourse relation of that sense in the training corpus that have the cosine similarity score using word2vec higher than a"
K16-2020,K15-2004,0,0.0742604,"Missing"
K16-2020,K15-2001,0,0.0797321,"Missing"
K16-2020,K16-2001,0,0.0395753,"Missing"
K16-2020,K15-2010,0,0.0420417,"Missing"
K16-2020,K15-2015,0,0.0294432,"in the development data set. Table 8 shows the contribution of exploited feature sets. In non-explicit sense classification the result would improve significantly if we use these features. NonNon NonALL Exp. Exp. ALL Exp. Ex. ALL Exp. Exp. P 60.5 90.3 34.3 57.4 88.7 28.8 51.4 74.9 31.4 R 60.5 90.3 34.3 57.4 88.7 28.8 51.3 74.6 31.4 F1 60.5 90.3 34.3 57.4 88.7 28.8 51.3 74.8 31.4 Table 8: Comparison between feature sets in sense classification task Table 5: Result on test data set of our system and top-4 last year systems including lan: (Wang and Lan, 2015), ste. (Stepanov et al., 2015), yo. (Yoshida et al., 2015) ALL Exp. NonExpl System Arg 1 Arg2 Arg1 Arg2 Connective Parser Arg 1 Arg2 Arg1 Arg2 Connective Parser Arg 1 Arg2 Arg1 Arg2 Parser lan 49.4 60.1 72.5 94.2 29.7 45.2 50.7 77.3 94.2 40.0 53.0 67.1 68.3 20.8 step. 40.7 47.8 60.7 92.7 25.4 44.6 50.1 76.2 92.7 39.6 37.3 44.4 47.4 13.3 yo. 43.8 52.5 64.4 89.1 25.0 38.8 46.1 68.3 89.1 34.5 48.8 57.9 60.1 15.1 Features Similarity features NonAll features mentioned Exp. above Connective words Connective words and their Exp. POS POS pattern of arguments, Regular expression and Others xue Our system 30.2 42.0 37.8 51.2 46.5 60.8 89.4 87.6 21.8 24.7 41.6"
K16-2020,K15-2003,0,0.0217503,"se they achieved best results in the development data set. Table 8 shows the contribution of exploited feature sets. In non-explicit sense classification the result would improve significantly if we use these features. NonNon NonALL Exp. Exp. ALL Exp. Ex. ALL Exp. Exp. P 60.5 90.3 34.3 57.4 88.7 28.8 51.4 74.9 31.4 R 60.5 90.3 34.3 57.4 88.7 28.8 51.3 74.6 31.4 F1 60.5 90.3 34.3 57.4 88.7 28.8 51.3 74.8 31.4 Table 8: Comparison between feature sets in sense classification task Table 5: Result on test data set of our system and top-4 last year systems including lan: (Wang and Lan, 2015), ste. (Stepanov et al., 2015), yo. (Yoshida et al., 2015) ALL Exp. NonExpl System Arg 1 Arg2 Arg1 Arg2 Connective Parser Arg 1 Arg2 Arg1 Arg2 Connective Parser Arg 1 Arg2 Arg1 Arg2 Parser lan 49.4 60.1 72.5 94.2 29.7 45.2 50.7 77.3 94.2 40.0 53.0 67.1 68.3 20.8 step. 40.7 47.8 60.7 92.7 25.4 44.6 50.1 76.2 92.7 39.6 37.3 44.4 47.4 13.3 yo. 43.8 52.5 64.4 89.1 25.0 38.8 46.1 68.3 89.1 34.5 48.8 57.9 60.1 15.1 Features Similarity features NonAll features mentioned Exp. above Connective words Connective words and their Exp. POS POS pattern of arguments, Regular expression and Others xue Our system 30.2 42.0 37.8 51.2 46.5 60"
K16-2020,K15-2002,0,0.0526484,"t discourse relations because they achieved best results in the development data set. Table 8 shows the contribution of exploited feature sets. In non-explicit sense classification the result would improve significantly if we use these features. NonNon NonALL Exp. Exp. ALL Exp. Ex. ALL Exp. Exp. P 60.5 90.3 34.3 57.4 88.7 28.8 51.4 74.9 31.4 R 60.5 90.3 34.3 57.4 88.7 28.8 51.3 74.6 31.4 F1 60.5 90.3 34.3 57.4 88.7 28.8 51.3 74.8 31.4 Table 8: Comparison between feature sets in sense classification task Table 5: Result on test data set of our system and top-4 last year systems including lan: (Wang and Lan, 2015), ste. (Stepanov et al., 2015), yo. (Yoshida et al., 2015) ALL Exp. NonExpl System Arg 1 Arg2 Arg1 Arg2 Connective Parser Arg 1 Arg2 Arg1 Arg2 Connective Parser Arg 1 Arg2 Arg1 Arg2 Parser lan 49.4 60.1 72.5 94.2 29.7 45.2 50.7 77.3 94.2 40.0 53.0 67.1 68.3 20.8 step. 40.7 47.8 60.7 92.7 25.4 44.6 50.1 76.2 92.7 39.6 37.3 44.4 47.4 13.3 yo. 43.8 52.5 64.4 89.1 25.0 38.8 46.1 68.3 89.1 34.5 48.8 57.9 60.1 15.1 Features Similarity features NonAll features mentioned Exp. above Connective words Connective words and their Exp. POS POS pattern of arguments, Regular expression and Others xue Our syst"
P14-1076,P07-1034,0,0.642021,"y, Australia § DSO National Laboratories, Singapore mlnguyen@i2r.a-star.edu.sg, ivor.tsang@gmail.com {ckianmin,chaileon}@dso.org.sg Abstract organizations, which are interconnected by various semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval (Salton and McGill, 1986) and information extraction for question answering (Etzioni et al., 2008). Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance (Jiang and Zhai, 2007b). However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more cost-effective to adapt an existing relation extraction system to the new domain using a small set of labeled data. This paper considers relation adaptation, where a relation extraction system trained on many source domains is adapted to a new target domain. There a"
P14-1076,P08-1004,0,0.0288503,"ated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce Third, the annotated instances for the target domain are typically much fewer than those for the source domains. This is primarily due to the lack o"
P14-1076,N07-1015,0,0.35216,"y, Australia § DSO National Laboratories, Singapore mlnguyen@i2r.a-star.edu.sg, ivor.tsang@gmail.com {ckianmin,chaileon}@dso.org.sg Abstract organizations, which are interconnected by various semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval (Salton and McGill, 1986) and information extraction for question answering (Etzioni et al., 2008). Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance (Jiang and Zhai, 2007b). However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more cost-effective to adapt an existing relation extraction system to the new domain using a small set of labeled data. This paper considers relation adaptation, where a relation extraction system trained on many source domains is adapted to a new target domain. There a"
P14-1076,P09-1114,0,0.0750193,"main of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common features in source and"
P14-1076,W06-1615,0,0.212546,"en IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a"
P14-1076,N10-1087,0,0.0312965,"009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the"
P14-1076,P07-1056,0,0.400589,"Missing"
P14-1076,D13-1043,0,0.0130419,"e target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce Third, the annotated instances for the target domain are typically much fewer than those for the source domains. This is primarily due to the lack of resources such as raw"
P14-1076,N13-1095,0,0.015138,"led data Dl = {(xi , yi )}ni=1 and nl +nu plenty of unlabeled data Du = {(xi )}nl +1 , where nl and nu are the number of labeled and unlabeled samples respectively, xi is the feature vector, yi is the corresponding label (if available). Let n = nl + nu . For the sth source domain, we have an adequate labeled data set Ds . We define domain adaptation as the problem of learning a classifier p for relation extraction in the target domain using the data sets Dl , Du and Ds , s = 1, . . . , k. labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transf"
P14-1076,P09-1113,0,0.0635713,"on types. The target dol main has a few labeled data Dl = {(xi , yi )}ni=1 and nl +nu plenty of unlabeled data Du = {(xi )}nl +1 , where nl and nu are the number of labeled and unlabeled samples respectively, xi is the feature vector, yi is the corresponding label (if available). Let n = nl + nu . For the sth source domain, we have an adequate labeled data set Ds . We define domain adaptation as the problem of learning a classifier p for relation extraction in the target domain using the data sets Dl , Du and Ds , s = 1, . . . , k. labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema match"
P14-1076,P04-1054,0,0.0367685,"t domain. One example is named entities extraction adaptation, where na¨ıve transfer of information from a mixed-case domain with capitalization information (e.g., news-wire) to a single-case domain (e.g., conversational speech transcripts) will miss most names in the single-case domain due to the absence of case information, which is typically important in the mixed-case domain. 2 Related Work Relation extraction is usually considered a classification problem: determine if two given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they req"
P14-1076,P07-1033,0,0.0737704,"pora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation me"
P14-1076,P13-1147,0,0.305646,"unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common features in source and target domains and then use those features as pivots to map source domain features to the target"
P14-1076,C08-1088,0,0.245146,"mixed-case domain with capitalization information (e.g., news-wire) to a single-case domain (e.g., conversational speech transcripts) will miss most names in the single-case domain due to the absence of case information, which is typically important in the mixed-case domain. 2 Related Work Relation extraction is usually considered a classification problem: determine if two given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initia"
P14-1076,N06-1039,0,0.0435777,"terations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce Third, the annotated instances for the target domain are typically much fewer than those for the source domains. This is primarily due to the lack of resources such as raw target domain documents, time, and people with the expertise. Together with imbalanced relation distributions inherent in the domain,"
P14-1076,P12-1076,0,0.0228643,"dol main has a few labeled data Dl = {(xi , yi )}ni=1 and nl +nu plenty of unlabeled data Du = {(xi )}nl +1 , where nl and nu are the number of labeled and unlabeled samples respectively, xi is the feature vector, yi is the corresponding label (if available). Let n = nl + nu . For the sth source domain, we have an adequate labeled data set Ds . We define domain adaptation as the problem of learning a classifier p for relation extraction in the target domain using the data sets Dl , Du and Ds , s = 1, . . . , k. labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not addre"
P14-1076,C10-2155,0,0.444072,"have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstra"
P14-1076,P13-2117,0,0.0392603,"Missing"
P14-1076,P06-1104,0,0.266864,"Missing"
P14-1076,J03-4003,0,\N,Missing
P17-4007,P05-1045,0,0.0578589,"an utilize the start and length information to calculate the exact position of the entity in the input sentence. The ENE tag can then be used in various subsequent tasks such as Relation Extraction (RE), Question Answering (QA) or automatic dialogue generation. The AL+ ENER API is freely accessible online.2 Currently, the API supports Japanese only, but we are also developing an API for English ENER. Figure 3 shows an example input sentence and output ENE tags. 2 Extended Named Entity recognition algorithms Existing NER systems often use Conditinal Random Fields (CRFs) (McCallum and Li, 2003; Finkel et al., 2005), HMM (Zhou and Su, 2002) or SVM (Yamada et al., 2002; Takeuchi and Collier, 2002; Sasano and Kurohashi, 2008) to assign tags to the tokens in an input sentence. However, these methods are supposed to work with only small number of categories (e.g., 10 categories). In the ENER problem, the number of categories is 200, which is very large, compared with the number in traditional NER. Consequently, traditional approaches might not achieve good performance and even be infeasible. Actually, we have tried to use CRF for 200 classes, but the training process took too long time and did not finish. In"
P17-4007,W03-0430,0,0.111565,"who uses the ENER API can utilize the start and length information to calculate the exact position of the entity in the input sentence. The ENE tag can then be used in various subsequent tasks such as Relation Extraction (RE), Question Answering (QA) or automatic dialogue generation. The AL+ ENER API is freely accessible online.2 Currently, the API supports Japanese only, but we are also developing an API for English ENER. Figure 3 shows an example input sentence and output ENE tags. 2 Extended Named Entity recognition algorithms Existing NER systems often use Conditinal Random Fields (CRFs) (McCallum and Li, 2003; Finkel et al., 2005), HMM (Zhou and Su, 2002) or SVM (Yamada et al., 2002; Takeuchi and Collier, 2002; Sasano and Kurohashi, 2008) to assign tags to the tokens in an input sentence. However, these methods are supposed to work with only small number of categories (e.g., 10 categories). In the ENER problem, the number of categories is 200, which is very large, compared with the number in traditional NER. Consequently, traditional approaches might not achieve good performance and even be infeasible. Actually, we have tried to use CRF for 200 classes, but the training process took too long time"
P17-4007,I08-2080,1,0.735218,"sentence. The ENE tag can then be used in various subsequent tasks such as Relation Extraction (RE), Question Answering (QA) or automatic dialogue generation. The AL+ ENER API is freely accessible online.2 Currently, the API supports Japanese only, but we are also developing an API for English ENER. Figure 3 shows an example input sentence and output ENE tags. 2 Extended Named Entity recognition algorithms Existing NER systems often use Conditinal Random Fields (CRFs) (McCallum and Li, 2003; Finkel et al., 2005), HMM (Zhou and Su, 2002) or SVM (Yamada et al., 2002; Takeuchi and Collier, 2002; Sasano and Kurohashi, 2008) to assign tags to the tokens in an input sentence. However, these methods are supposed to work with only small number of categories (e.g., 10 categories). In the ENER problem, the number of categories is 200, which is very large, compared with the number in traditional NER. Consequently, traditional approaches might not achieve good performance and even be infeasible. Actually, we have tried to use CRF for 200 classes, but the training process took too long time and did not finish. In this system, we use a combination approach to recognize ENEs. We first implement four base algorithms, namely"
P17-4007,sekine-nobata-2004-definition,1,0.843586,"et user feedbacks from this service to improve the ENER system, and the statistics obtained from the user feedIntroduction Named entity recognition (NER) is one of the most fundamental tasks in Information Retrieval, Information Extraction and Question Answering (Bellot et al., 2002; Nadeau and Sekine, 2007). A high quality named entity recognition API (Application Programming Interface) is therefore important for higher level tasks such as entity retrieval, recommendation and automatic dialogue generation. To extend the ability of named entity recognition, Sekine et al. (Sekine et al., 2002; Sekine and Nobata, 2004) have proposed an Extended Named Entity (ENE) hierarchy, which refines the definition of named entity. The ENE hierarchy is a three-level hierarchy, which contains more than ten coarse-grained categories at the top level and 200 fine-grained categories at the leaf level. The top level of the hierarchy includes traditional named entity categories, such as Person, Location or Organization. The middle level and leaf level refine the top level categories to more fine37 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics-System Demonstrations, pages 37–42 c Vanco"
P17-4007,sekine-etal-2002-extended,1,0.632536,"ners, the method to get user feedbacks from this service to improve the ENER system, and the statistics obtained from the user feedIntroduction Named entity recognition (NER) is one of the most fundamental tasks in Information Retrieval, Information Extraction and Question Answering (Bellot et al., 2002; Nadeau and Sekine, 2007). A high quality named entity recognition API (Application Programming Interface) is therefore important for higher level tasks such as entity retrieval, recommendation and automatic dialogue generation. To extend the ability of named entity recognition, Sekine et al. (Sekine et al., 2002; Sekine and Nobata, 2004) have proposed an Extended Named Entity (ENE) hierarchy, which refines the definition of named entity. The ENE hierarchy is a three-level hierarchy, which contains more than ten coarse-grained categories at the top level and 200 fine-grained categories at the leaf level. The top level of the hierarchy includes traditional named entity categories, such as Person, Location or Organization. The middle level and leaf level refine the top level categories to more fine37 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics-System Demonstra"
P17-4007,W02-2029,0,0.111615,"of the entity in the input sentence. The ENE tag can then be used in various subsequent tasks such as Relation Extraction (RE), Question Answering (QA) or automatic dialogue generation. The AL+ ENER API is freely accessible online.2 Currently, the API supports Japanese only, but we are also developing an API for English ENER. Figure 3 shows an example input sentence and output ENE tags. 2 Extended Named Entity recognition algorithms Existing NER systems often use Conditinal Random Fields (CRFs) (McCallum and Li, 2003; Finkel et al., 2005), HMM (Zhou and Su, 2002) or SVM (Yamada et al., 2002; Takeuchi and Collier, 2002; Sasano and Kurohashi, 2008) to assign tags to the tokens in an input sentence. However, these methods are supposed to work with only small number of categories (e.g., 10 categories). In the ENER problem, the number of categories is 200, which is very large, compared with the number in traditional NER. Consequently, traditional approaches might not achieve good performance and even be infeasible. Actually, we have tried to use CRF for 200 classes, but the training process took too long time and did not finish. In this system, we use a combination approach to recognize ENEs. We first implement"
P17-4007,P02-1060,0,\N,Missing
S15-2038,J93-2003,0,0.0283481,"tions have been successfully used in finding similar questions in Question Answering archive. We adapt the idea and build translation models between the questions and their answers using the training data and the Qatar Living forum data. We treat the question-answer pairs similar to dual language sentence pairs in machine translation. First, each question-answer pair is tokenized and all special characters are removed. In the process, if any answer has too few tokens (less than two tokens), it is removed from the training data. Then the translation probabilities are calculated by IBM Model 1 (Brown et al., 1993) and Hidden Markov Model. Each model is trained with 200 iterations. The calculated translation probabilities help us to calculate the probability that an answer is the translation of the question. The translation feature will be detailed in Section 2.3. We build two topic models, the first one is trained in the training data, the second one is trained in ˇ uˇrek and Wikipedia data1 using Gensim toolkit (Reh˚ Sojka, 2010) and Mallet toolkit (McCallum, 2002). 1 The compressed version of all article from Wikipedia downloaded at http://dumps.wikimedia.org/enwiki/ 216 These LDA models have 100 top"
S15-2038,W14-3348,0,0.0207487,"Missing"
S15-2038,P02-1054,0,0.0930229,"a crucial role in supporting people to seek desired information. Users can post their questions on these sites for finding help as well as personal advice. However, the quality of these answers varies greatly. Typically, only a few of the answers in an answer thread are useful to the users and it may take a lot of efforts to identify them manually. Thus, a system that automatically identifies answer quality is much needed. The task of identifying answer quality has been studied by many researchers in the field of Question Answering. Many methods have been proposed: web redundancy information (Magnini et al., 2002), non-textual features (Jeon et al., 2006), textual entailment (Wang and Neumann, 2007), syntactic features (Grundstr¨om and Nugues, 2014). However, most of these works used independent dataset and evaluation metrics; thus it is difficult to compare the results of these methods. The SEMEVAL task System Description For extracting the features, we first preprocess the questions and the answers then build a number of models based on training data or other sources (Figure 1). 2.1 Preprocessing All the questions and the answers are preprocessed through the following steps: Tokenization, POStagging,"
S15-2038,P14-5010,0,0.00246658,"Missing"
S15-2038,S15-2047,0,0.227222,"Missing"
S15-2038,P08-1082,0,0.366928,"using the two versions is made using experiments in 215 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 215–219, c Denver, Colorado, June 4-5, 2015. 2015 Association for Computational Linguistics Figure 1: System components development set. 2.2 Building models from data In this section, we describe the resources we use, or build for extracting features, these resources are: Translation models, LDA models, Word vector representation models, Word Lists. The translation models are built to bridge the lexical chasm between the questions and the answers (Surdeanu et al., 2008). In previous works (Jeon et al., 2005; Zhou et al., 2011), monolingual translation models between questions have been successfully used in finding similar questions in Question Answering archive. We adapt the idea and build translation models between the questions and their answers using the training data and the Qatar Living forum data. We treat the question-answer pairs similar to dual language sentence pairs in machine translation. First, each question-answer pair is tokenized and all special characters are removed. In the process, if any answer has too few tokens (less than two tokens), i"
S15-2038,P11-1066,0,0.0462663,"edings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 215–219, c Denver, Colorado, June 4-5, 2015. 2015 Association for Computational Linguistics Figure 1: System components development set. 2.2 Building models from data In this section, we describe the resources we use, or build for extracting features, these resources are: Translation models, LDA models, Word vector representation models, Word Lists. The translation models are built to bridge the lexical chasm between the questions and the answers (Surdeanu et al., 2008). In previous works (Jeon et al., 2005; Zhou et al., 2011), monolingual translation models between questions have been successfully used in finding similar questions in Question Answering archive. We adapt the idea and build translation models between the questions and their answers using the training data and the Qatar Living forum data. We treat the question-answer pairs similar to dual language sentence pairs in machine translation. First, each question-answer pair is tokenized and all special characters are removed. In the process, if any answer has too few tokens (less than two tokens), it is removed from the training data. Then the translation"
W03-1119,P99-1045,0,0.0680147,"Missing"
W03-1119,A00-1043,0,0.0611914,"jaist.ac.jp (S.H. Olivers and W.B.Dolan, 1999) proposed removing clauses in sentences before indexing document for information retrieval. Those methods remove phrases based on their syntactic categories but not rely on the context of words, phrases and sentences around. Without using that information can be reduced the accuracy of sentence reduction problem. Mani and Maybury also present a process of writing a reduced sentence by reversing the original sentence with a set of revised rules to improve the performance of summarization. (Inderject Mani and Mark Maybury, 1999). Jing and McKeown(H. Jing, 2000) studied a new method to remove extraneous phrase from sentences by using multiple source of knowledge to decide which phrase in the sentences can be removed. The multiple sources include syntactic knowledge, context information and statistic computed from a corpus that consists of examples written by human professional. Their method prevented removing some phrases that were relative to its context around and produced a grammatical sentence. Recently, Knight and Marcu(K.Knight and D.Marcu, 2002) demonstrated two methods for sentence compression problem, which are similar to sentence reduction"
W03-1119,P95-1037,0,0.0600709,"ples written by human professional. Their method prevented removing some phrases that were relative to its context around and produced a grammatical sentence. Recently, Knight and Marcu(K.Knight and D.Marcu, 2002) demonstrated two methods for sentence compression problem, which are similar to sentence reduction one. They devised both noisychannel and decision tree approach to the problem. The noisy-channel framework has been used in many applications, including speech recognition, machine translation, and information retrieval. The decision tree approach has been used in parsing sentence. (D. Magerman, 1995)(Ulf Hermijakob and J.Mooney, 1997) to define the rhetorical of text documents (Daniel Marcu, 1999). Most of the previous methods only produce a short sentence whose word order is the same as that of the original sentence, and in the same language, e.g., English. When nonnative speaker reduce a long sentence in foreign language, they usually try to link the meaning of words within the original sentence into meanings in their language. In addition, in some cases, the reduced sentence and the original sentence had their word order are difference. Therefore, two reduced sentences are performed by"
W03-1119,P97-1062,0,0.0395264,"Missing"
W03-1119,P99-1047,0,0.0302489,"its context around and produced a grammatical sentence. Recently, Knight and Marcu(K.Knight and D.Marcu, 2002) demonstrated two methods for sentence compression problem, which are similar to sentence reduction one. They devised both noisychannel and decision tree approach to the problem. The noisy-channel framework has been used in many applications, including speech recognition, machine translation, and information retrieval. The decision tree approach has been used in parsing sentence. (D. Magerman, 1995)(Ulf Hermijakob and J.Mooney, 1997) to define the rhetorical of text documents (Daniel Marcu, 1999). Most of the previous methods only produce a short sentence whose word order is the same as that of the original sentence, and in the same language, e.g., English. When nonnative speaker reduce a long sentence in foreign language, they usually try to link the meaning of words within the original sentence into meanings in their language. In addition, in some cases, the reduced sentence and the original sentence had their word order are difference. Therefore, two reduced sentences are performed by non-native speaker, one is the reduced sentence in foreign language and another is in their langua"
W08-2119,W06-1606,0,0.044529,"Missing"
W08-2119,P04-1083,0,0.0812144,"Missing"
W08-2119,A00-2018,0,0.12335,"on tool. A number of tools were used in our experiments. Vietnamese sentences were segmented using a wordsegmentation program (Nguyen et al., 2003). For learning phrase translations and decoding, we used Pharaoh (Koehn, 2004), a state-of-the-art phrasebased SMT system which is available for research purpose. For word alignment, we used the GIZA++ tool (Och and Ney, 2000). For learning language models, we used SRILM toolkit (Stolcke, 2002). For MT evaluation, we used BLEU measure (Papineni et al., 2001) calculated by the NIST script version 11b. For the parsing task, we used Charniak’s parser (Charniak, 2000). For experiments with chunking (or shallow parsing), we used a CRFs-based chunking tool 5 to split a source sentence into syntactic chunks. Then a pseudo CFG rule over chunks is built to generate a two-level syntactic tree. This tree can be used in the Table 2 shows our decoding algorithm. Step 1 distributes translation options to leaf nodes using a procedure similar to Step 1 of algorithm in Table 1. Step 147 3 http://www2.nict.go.jp/x/x161/members/mutiyama/index.html http://chasen.aist-nara.ac.jp/chasen/distribution.html.en 5 http://crfpp.sourceforge.net/ 4 + Input: + Output: + Step 1: + St"
W08-2119,P06-1121,0,0.0240383,"nd English-Vietnamese translation showed a significant improvement over two baseline phrase-based SMT systems. 1 Introduction Based on the kind of linguistic information which is made use of, syntactic SMT can be divided into four types: tree-to-string, string-to-tree, tree-to-tree, and hierarchical phrase-based. The tree-to-string approach (Collins et al., 2005; Nguyen and Shimazu, 2006; Liu et al., 2006 and 2007) supposes that syntax of the source language is known. This approach can be applied when a source language parser is available. The string-to-tree approach (Yamada and Knight, 2001; Galley et al., 2006) focuses on syntactic modelling of the target language in cases it has syntactic resources such as treebanks and parsers. The tree-to-tree approach models the syntax of both languages, therefore extra cost is required. The fourth approach (Chiang, 2005) constraints phrases under context-free grammar structure without any requirement of linguistic annotation. In this paper, we present a tree-to-string phrasebased method which is based on synchronous CFGs. This method has two important properties: syntactic transformation is used in the decoding phase including a word-to-phrase tree transformati"
W08-2119,J06-4004,0,0.0458073,"Missing"
W08-2119,koen-2004-pharaoh,0,0.0429808,"collection whose word span is [i1 , i2 ] at a node whose tag is X expresses that: Vietnamese 16,809 Experimental Results 6.1 Experimental Settings We used Reuters3 , an English-Japanese bilingual corpus, and Conversation, an English-Vietnamese corpus (Table 4). These corpora were split into data sets as shown in Table 3. Japanese sentences were analyzed by ChaSen4 , a word-segmentation tool. A number of tools were used in our experiments. Vietnamese sentences were segmented using a wordsegmentation program (Nguyen et al., 2003). For learning phrase translations and decoding, we used Pharaoh (Koehn, 2004), a state-of-the-art phrasebased SMT system which is available for research purpose. For word alignment, we used the GIZA++ tool (Och and Ney, 2000). For learning language models, we used SRILM toolkit (Stolcke, 2002). For MT evaluation, we used BLEU measure (Papineni et al., 2001) calculated by the NIST script version 11b. For the parsing task, we used Charniak’s parser (Charniak, 2000). For experiments with chunking (or shallow parsing), we used a CRFs-based chunking tool 5 to split a source sentence into syntactic chunks. Then a pseudo CFG rule over chunks is built to generate a two-level s"
W08-2119,D07-1091,0,0.0429903,"Missing"
W08-2119,N03-1017,0,0.427181,"make use of such kind of phrasal translation by word-to-phrase tree transformation. We carried out experiments with two language pairs English-Japanese and English-Vietnamese. Our system achieved significant improvements over Pharaoh, a state-of-the-art phrase-based SMT system. We also analyzed the dependence of translation quality on the level of syntactic analysis (shallow or deep). Figure 1 shows the architecture of our system. The input of this system is a source-language tree and the output is a target-language string. This system uses all features of conventional phrase-based SMT as in (Koehn et al., 2003). There are two new features including a word-to-phrase tree transformation model and a phrase reordering model. The decoding algo1 See Section 6.2. 143 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 143–150 Manchester, August 2008 P (T1 ) can be omitted since only one syntactic tree is used. P (T2 |T1 ) is a word-to-phrase tree transformation model we describe later. P (T3 |T2 ) is a reordering model. P (T4 |T3 ) can be calculated using a phrase translation model and a language model. This is the fundamental equation of our study represented i"
W08-2119,P06-1077,0,0.408451,"tituent and non-constituent phrasal translations in the decoding phase. We considered various levels of syntactic analysis ranging from chunking to full parsing. Our experimental results of English-Japanese and English-Vietnamese translation showed a significant improvement over two baseline phrase-based SMT systems. 1 Introduction Based on the kind of linguistic information which is made use of, syntactic SMT can be divided into four types: tree-to-string, string-to-tree, tree-to-tree, and hierarchical phrase-based. The tree-to-string approach (Collins et al., 2005; Nguyen and Shimazu, 2006; Liu et al., 2006 and 2007) supposes that syntax of the source language is known. This approach can be applied when a source language parser is available. The string-to-tree approach (Yamada and Knight, 2001; Galley et al., 2006) focuses on syntactic modelling of the target language in cases it has syntactic resources such as treebanks and parsers. The tree-to-tree approach models the syntax of both languages, therefore extra cost is required. The fourth approach (Chiang, 2005) constraints phrases under context-free grammar structure without any requirement of linguistic annotation. In this paper, we present a"
W08-2119,2006.amta-papers.16,1,0.944538,"ally make use of both constituent and non-constituent phrasal translations in the decoding phase. We considered various levels of syntactic analysis ranging from chunking to full parsing. Our experimental results of English-Japanese and English-Vietnamese translation showed a significant improvement over two baseline phrase-based SMT systems. 1 Introduction Based on the kind of linguistic information which is made use of, syntactic SMT can be divided into four types: tree-to-string, string-to-tree, tree-to-tree, and hierarchical phrase-based. The tree-to-string approach (Collins et al., 2005; Nguyen and Shimazu, 2006; Liu et al., 2006 and 2007) supposes that syntax of the source language is known. This approach can be applied when a source language parser is available. The string-to-tree approach (Yamada and Knight, 2001; Galley et al., 2006) focuses on syntactic modelling of the target language in cases it has syntactic resources such as treebanks and parsers. The tree-to-tree approach models the syntax of both languages, therefore extra cost is required. The fourth approach (Chiang, 2005) constraints phrases under context-free grammar structure without any requirement of linguistic annotation. In this p"
W08-2119,P00-1056,0,0.12316,"tings We used Reuters3 , an English-Japanese bilingual corpus, and Conversation, an English-Vietnamese corpus (Table 4). These corpora were split into data sets as shown in Table 3. Japanese sentences were analyzed by ChaSen4 , a word-segmentation tool. A number of tools were used in our experiments. Vietnamese sentences were segmented using a wordsegmentation program (Nguyen et al., 2003). For learning phrase translations and decoding, we used Pharaoh (Koehn, 2004), a state-of-the-art phrasebased SMT system which is available for research purpose. For word alignment, we used the GIZA++ tool (Och and Ney, 2000). For learning language models, we used SRILM toolkit (Stolcke, 2002). For MT evaluation, we used BLEU measure (Papineni et al., 2001) calculated by the NIST script version 11b. For the parsing task, we used Charniak’s parser (Charniak, 2000). For experiments with chunking (or shallow parsing), we used a CRFs-based chunking tool 5 to split a source sentence into syntactic chunks. Then a pseudo CFG rule over chunks is built to generate a two-level syntactic tree. This tree can be used in the Table 2 shows our decoding algorithm. Step 1 distributes translation options to leaf nodes using a proce"
W08-2119,2001.mtsummit-papers.68,0,0.0554325,"pora were split into data sets as shown in Table 3. Japanese sentences were analyzed by ChaSen4 , a word-segmentation tool. A number of tools were used in our experiments. Vietnamese sentences were segmented using a wordsegmentation program (Nguyen et al., 2003). For learning phrase translations and decoding, we used Pharaoh (Koehn, 2004), a state-of-the-art phrasebased SMT system which is available for research purpose. For word alignment, we used the GIZA++ tool (Och and Ney, 2000). For learning language models, we used SRILM toolkit (Stolcke, 2002). For MT evaluation, we used BLEU measure (Papineni et al., 2001) calculated by the NIST script version 11b. For the parsing task, we used Charniak’s parser (Charniak, 2000). For experiments with chunking (or shallow parsing), we used a CRFs-based chunking tool 5 to split a source sentence into syntactic chunks. Then a pseudo CFG rule over chunks is built to generate a two-level syntactic tree. This tree can be used in the Table 2 shows our decoding algorithm. Step 1 distributes translation options to leaf nodes using a procedure similar to Step 1 of algorithm in Table 1. Step 147 3 http://www2.nict.go.jp/x/x161/members/mutiyama/index.html http://chasen.ais"
W08-2119,P05-1034,0,0.0468661,"-to-string system was to-phrase tree transformation, all possible phrases much faster than baseline systems’. This is an option are considered in translation. Our method does for developing applications which require high speed not suppose a uniform distribution over all possible such as web translation. phrase segmentations as (Koehn et al., 2003) since each phrase tree has a probability. We believe that 7 Related Works other kinds of translation unit such as n-gram (Jos et al., 2006), factored phrasal translation (Koehn and 7.1 A Comparison of Syntactic SMT Methods Hoang, 2007), or treelet (Quirk et al., 2005) can be To advance the state of the art, SMT system design- used in this method. We would like to consider this ers have experimented with tree-structured transla- problem as a future study. Moreover we would like to tion models. The underlying computational models use n-best trees as the input of our system. A number Figure 6: Two phrase trees. 149 Method Input Koehn et al. (2003) Yamada and Knight (2001) Melamed (2003) Chiang (2005) Quirk et al. (2005) Galley et al. (2006) Liu et al. (2006) Our work string string string string dep. tree string tree tree Theoretical model FSTs SCFGs SCFGs SCF"
W08-2119,P01-1067,0,0.110663,"lts of English-Japanese and English-Vietnamese translation showed a significant improvement over two baseline phrase-based SMT systems. 1 Introduction Based on the kind of linguistic information which is made use of, syntactic SMT can be divided into four types: tree-to-string, string-to-tree, tree-to-tree, and hierarchical phrase-based. The tree-to-string approach (Collins et al., 2005; Nguyen and Shimazu, 2006; Liu et al., 2006 and 2007) supposes that syntax of the source language is known. This approach can be applied when a source language parser is available. The string-to-tree approach (Yamada and Knight, 2001; Galley et al., 2006) focuses on syntactic modelling of the target language in cases it has syntactic resources such as treebanks and parsers. The tree-to-tree approach models the syntax of both languages, therefore extra cost is required. The fourth approach (Chiang, 2005) constraints phrases under context-free grammar structure without any requirement of linguistic annotation. In this paper, we present a tree-to-string phrasebased method which is based on synchronous CFGs. This method has two important properties: syntactic transformation is used in the decoding phase including a word-to-ph"
W08-2119,P07-1089,0,0.0591304,"hand crafted rules to carry out word reordering in the preprocessing phase but not decoding phase. Nguyen and Shimazu (2006) presented a more general method in which lexicalized syntactic reordering models based on PCFGs can be learned from source-parsed bitext and then applied in the preprocessing phase. Liu et al. (2006) changed the translation unit from phrases to tree-to-string alignment templates (TATs) while we do not. TATs was represented as xRs rules while we use synchronous CFG rules. In order to overcome the limitation that TATs can not capture non-constituent phrasal translations, Liu et al. (2007) proposed forest-to-string rules while our system can naturally make use of such kind of phrasal translation by word-to-phrase tree transformation. We carried out experiments with two language pairs English-Japanese and English-Vietnamese. Our system achieved significant improvements over Pharaoh, a state-of-the-art phrase-based SMT system. We also analyzed the dependence of translation quality on the level of syntactic analysis (shallow or deep). Figure 1 shows the architecture of our system. The input of this system is a source-language tree and the output is a target-language string. This s"
W08-2119,P02-1040,0,\N,Missing
W18-2410,P11-1041,0,0.0269949,"participating teams. 1 Introduction Transliteration is defined as the phonetic translation of words across languages (Knight and Graehl, 1998; Li et al., 2009). It can be considered as a machine translation problem at the character level. Transliteration converts words written in one writing system (source language, e.g., English) into phonetically equivalent words in another writing system (target language, e.g., Hindi) and is often used to translate foreign names of people, locations, organizations, and products (Gia et al., 2015). With names comprising over 75 percent of the unseen words (Bhargava and Kondrak, 2011), they are a challenging problem in machine translation, multilingual information retrieval, corpus alignment and other natural language processing applications. More so, studies suggest that cross-lingual information retrieval performances can improve by as much as 50 percent if the system is provided with suitably transliterated named entities (Larkey et al., 2003). 2 Data The corpus sizes of each of the data partitions, namely training, development and test for the 19 language pairs used in the transliteration experiments is summarized in Table 1. 3 Methods In this section, we describe the"
W18-2410,J93-2003,0,0.0881198,"ence translation tasks and hence is a popular tool in machine transliteration. It is different from many translation tools, as it is able to train a joint n-gram model from unaligned data. Higher order n-grams are trained iteratively from the smaller ones — first, a unigram model is trained, which is then used for a bigram model, and so on. We report results on a 5-gram Sequitur model in this paper. 3.2 Phrase-based machine translation model breaks the source sentence into phrases and translates these phrases in the target language before combining them to produce one final translated result (Brown et al., 1993; Collins, 2011). Its use can be extended in the field of transliteration — as transliteration is defined as a translation task at the character level (Koehn et al., 2007). The best transliteration sequence, H best , in the target language is generated by multiplying the probabilities of the transliteration model, P and the language model, P(E |H), along with their respective weights, α and β, as Table 1: Corpus Size for the 19 language pairs, where En: English, Th: Thai, Pe: Persian, Ch: Chinese, Vi: Vietnamese, Ba: Bangla, Hi: Hindi, He: Hebrew, Ka: Kannada, Ta: Tamil, Ar: Arabic, Ko: Korean"
W18-2410,W15-3913,0,0.021899,"is used to rank the consolidated hypothesis list. The feature set consists of 10 scores from lexical reordering, language modelling, word penalty, phrase penalty, and translation from Moses and 1 confidence score from Sequitur. We use constrained decoding to obtain Moses scores for Sequitur transliterations which do not occur in the top-n Moses hypotheses. A linear regression model similar to that adopted by Shao et al. (2015) is used for re-ranking. For each transliteration, we use the edit distance of the hypothesis from the reference as the output of the linear regression model, following Wang et al. (2015). The hypotheses are ranked in increasing order of their calculated edit distance. The linear regression model can be mathematically represented using: ED = c + 10 X αi xi 4.2 Experimental Setup for Moses For this experiment, we augment word representations with boundary markers ( ˆ for the start of the word and $ for the end of the word). Adding boundary markers ensures that character position is encoded in these word representations, which is otherwise ignored in PBSMT models (Kunchukuttan and Bhattacharyya, 2015). This significantly improves transliteration accuracy for languages (e.g., all"
W18-2410,P07-2045,0,0.00731253,"om unaligned data. Higher order n-grams are trained iteratively from the smaller ones — first, a unigram model is trained, which is then used for a bigram model, and so on. We report results on a 5-gram Sequitur model in this paper. 3.2 Phrase-based machine translation model breaks the source sentence into phrases and translates these phrases in the target language before combining them to produce one final translated result (Brown et al., 1993; Collins, 2011). Its use can be extended in the field of transliteration — as transliteration is defined as a translation task at the character level (Koehn et al., 2007). The best transliteration sequence, H best , in the target language is generated by multiplying the probabilities of the transliteration model, P and the language model, P(E |H), along with their respective weights, α and β, as Table 1: Corpus Size for the 19 language pairs, where En: English, Th: Thai, Pe: Persian, Ch: Chinese, Vi: Vietnamese, Ba: Bangla, Hi: Hindi, He: Hebrew, Ka: Kannada, Ta: Tamil, Ar: Arabic, Ko: Korean, Ja: Japanese Katakana, Jn: English, Jk: Japanese Kanji. and Moses, which adopts phrase-based statistical machine translation. It should be noted that identical settings"
W18-2410,W15-3912,0,0.022755,"ance of the hypothesis from the reference as the output of the linear regression model, following Wang et al. (2015). The hypotheses are ranked in increasing order of their calculated edit distance. The linear regression model can be mathematically represented using: ED = c + 10 X αi xi 4.2 Experimental Setup for Moses For this experiment, we augment word representations with boundary markers ( ˆ for the start of the word and $ for the end of the word). Adding boundary markers ensures that character position is encoded in these word representations, which is otherwise ignored in PBSMT models (Kunchukuttan and Bhattacharyya, 2015). This significantly improves transliteration accuracy for languages (e.g., all Indian languages) which have different characters for identical phonological symbols depending on where (initial, medial or terminal position) they occur in a word. Figure 2 shows an example of how the strings are represented after pre-processing for Moses. (3) i=1 where ED is the edit distance calculated by the regression model, c is the intercept, and αi and xi are the coefficient and value of the i-th feature. As the edit distance between the hypothesis and reference is a measure of their similarity, it is seen"
W18-2410,W09-3501,0,0.028051,"We focus on creating the baseline systems trained using two open-source, statistical transliteration tools, namely Sequitur and Moses. We discuss the pre-processing steps performed on this dataset for both the systems. We also provide a re-ranking system which uses top hypotheses from Sequitur and Moses to create a consolidated list of transliterations. The results obtained from each of these models can be used to present a good starting point for the participating teams. 1 Introduction Transliteration is defined as the phonetic translation of words across languages (Knight and Graehl, 1998; Li et al., 2009). It can be considered as a machine translation problem at the character level. Transliteration converts words written in one writing system (source language, e.g., English) into phonetically equivalent words in another writing system (target language, e.g., Hindi) and is often used to translate foreign names of people, locations, organizations, and products (Gia et al., 2015). With names comprising over 75 percent of the unseen words (Bhargava and Kondrak, 2011), they are a challenging problem in machine translation, multilingual information retrieval, corpus alignment and other natural langu"
W18-2410,P04-1021,0,0.0836333,"ranking approach in an attempt to improve over the individual Moses and Sequitur results. = P (< e1 , h1 >, ..., < ek , hk >) = (2) where h is the set of all phonologically correct words in the target orthography. Moses is the statistical translation tool, which adopts the Phrase-Based Statistical Machine Translation approach. GIZA++ is used for aligning the word pairs and KenLM is used for creating the n-gram language models. We create 5gram language models using the target language corpus. The decoders log-linear model is tuned using MERT. The Joint Source-Channel Model was first studied by Li et al. (2004), where a direct orthographic mapping was proposed for transliteration. Given a pair of languages, for example English and Hindi, where e and h are representative of their transliteration units, respectively; the transliteration process is nding the alignment for sub-sequences of the input string, E and the output string, H (Pervouchine et al., 2009), and can be represented for an n-gram model as k Y Phrase-Based Statistical Machine Translation (PB-SMT) i−1 P (< e, h >i |< e, h >i−n+1 ) i=1 (1) where k is number of alignment units. P(E, H) is, thus, the joint probability of the i-th alignment"
W18-2410,P09-1016,0,0.027851,"for aligning the word pairs and KenLM is used for creating the n-gram language models. We create 5gram language models using the target language corpus. The decoders log-linear model is tuned using MERT. The Joint Source-Channel Model was first studied by Li et al. (2004), where a direct orthographic mapping was proposed for transliteration. Given a pair of languages, for example English and Hindi, where e and h are representative of their transliteration units, respectively; the transliteration process is nding the alignment for sub-sequences of the input string, E and the output string, H (Pervouchine et al., 2009), and can be represented for an n-gram model as k Y Phrase-Based Statistical Machine Translation (PB-SMT) i−1 P (< e, h >i |< e, h >i−n+1 ) i=1 (1) where k is number of alignment units. P(E, H) is, thus, the joint probability of the i-th alignment 75 Moses + Sequitur: We conduct an experiment to analyze the outcome when using hypotheses from both Sequitur and Moses, where a linear combination of their corresponding scores is used to rank the consolidated hypothesis list. The feature set consists of 10 scores from lexical reordering, language modelling, word penalty, phrase penalty, and transla"
W18-2410,W15-3908,0,0.0180092,"alignment 75 Moses + Sequitur: We conduct an experiment to analyze the outcome when using hypotheses from both Sequitur and Moses, where a linear combination of their corresponding scores is used to rank the consolidated hypothesis list. The feature set consists of 10 scores from lexical reordering, language modelling, word penalty, phrase penalty, and translation from Moses and 1 confidence score from Sequitur. We use constrained decoding to obtain Moses scores for Sequitur transliterations which do not occur in the top-n Moses hypotheses. A linear regression model similar to that adopted by Shao et al. (2015) is used for re-ranking. For each transliteration, we use the edit distance of the hypothesis from the reference as the output of the linear regression model, following Wang et al. (2015). The hypotheses are ranked in increasing order of their calculated edit distance. The linear regression model can be mathematically represented using: ED = c + 10 X αi xi 4.2 Experimental Setup for Moses For this experiment, we augment word representations with boundary markers ( ˆ for the start of the word and $ for the end of the word). Adding boundary markers ensures that character position is encoded in t"
W18-2410,W10-2409,0,0.0264859,"ve weights, α and β, as Table 1: Corpus Size for the 19 language pairs, where En: English, Th: Thai, Pe: Persian, Ch: Chinese, Vi: Vietnamese, Ba: Bangla, Hi: Hindi, He: Hebrew, Ka: Kannada, Ta: Tamil, Ar: Arabic, Ko: Korean, Ja: Japanese Katakana, Jn: English, Jk: Japanese Kanji. and Moses, which adopts phrase-based statistical machine translation. It should be noted that identical settings were used for all 19 language pairs. 3.1 H best = argmaxHh P (H|E) = argmaxHh αP (E|H) × βP (H) Joint Source-Channel Model 3.3 P (E, H) = P (e1 , e2 , ..., ek , h1 , h2 , ..., hk ) Hypothesis Re-ranking Song et al. (2010) proposed that re-ranking the output candidates is expected to boost transliteration accuracy, as the Shared Task considers only the top-1 hypothesis when evaluating the accuracy of the system. We adopt the following re-ranking approach in an attempt to improve over the individual Moses and Sequitur results. = P (< e1 , h1 >, ..., < ek , hk >) = (2) where h is the set of all phonologically correct words in the target orthography. Moses is the statistical translation tool, which adopts the Phrase-Based Statistical Machine Translation approach. GIZA++ is used for aligning the word pairs and KenL"
Y03-1030,oz-cicekli-1998-ordering,0,0.0217687,"Missing"
Y03-1030,P91-1024,0,\N,Missing
Y03-1030,2001.mtsummit-ebmt.1,0,\N,Missing
Y03-1033,P99-1045,0,0.0377589,"Missing"
Y03-1033,A00-1043,0,0.0765461,"Missing"
Y03-1033,P95-1037,0,0.0895859,"Missing"
Y03-1033,P97-1062,0,0.0285156,"Missing"
Y03-1033,P99-1047,0,0.0330738,"Missing"
Y03-1033,A00-2018,0,0.0658297,"ion based on decision tree model, in which the original sentence was parsed into a syntax tree and transfer to a shorter sentence by using rewriting process. The decision model for compression could not deal with the changeable order problem and not using semantic information. To overcome these problems, we extend the sentence compression decision tree model with an assumption that the semantic information will support to generate action decision more accuracy. To integrate semantic information into our model, the original sentence was parsed into a syntax tree by using the Charniak's parser (Charniak, 2000). Afterward, the syntax tree was enriched semantic information by using WORDNET (Fellbaum, 1998) database and a sub-categorization table that describes the syntactic and semantic role for verbs. The following sections will present a sentence reduction based on decision tree model using rich semantic information. 2.1 Definition Let t and s be a syntax tree of the original sentence and a reduced sentence respectively. To perform a rewriting process we used an Input list, two stacks and some rewriting operators are defined as follows. An Input list consists of a sequence of words subsumed by the"
Y05-1015,W05-0602,0,0.0501375,"Missing"
Y05-1015,P96-1008,0,0.103789,"Missing"
Y05-1015,N03-1028,0,0.0373003,"Missing"
Y05-1015,J98-4004,0,\N,Missing
Y05-1015,Y05-1000,0,\N,Missing
Y11-1042,S10-1022,0,0.124282,"ion 3 describes our listwise approach to this shared task. Section 4 presents experimental results on the corpora of this SemEval-2010 shared task. Finally, section 5 gives some conclusion and future work. 2 Related Work In this section, we preview previous approaches of the systems participated in the SemEval-2010 shared task 1. The experimental results of these systems are also used to make an experimental comparison with our proposed approach’s results. Here, we preview four systems: (1) RelaxCor system (Sapena et al., 2010); (2) SUCRE system (Kobdani and Schutze, 2010); (3) TANL-1 system (Attardi et al., 2010); and (4) UBIU system (Zhekova and Kubler, 2010). Table 1 presents an overview of the systems, their architecture and machine learning methods. Table 1: Main characteristics of the previous systems. Systems RelaxCor SUCRE TANL-1 UBIU 2.1 System Architecture Graph Partitioning (solved by relaxation labeling) Best-first clustering, Relational database model, Regular feature definition language Highest entity-mention similarity Pairwise model Machine learning methods Decision trees, Rules Decision trees, Nave Bayes, SVM, MaxEnt MaxEnt MBL RelaxCor system RelaxCor (Sapena et al., 2010) is a constr"
Y11-1042,D09-1120,0,0.0670275,"e efficient for Coreference Resolution in Multiple Languages. Keywords: listwise approach, coreference resolution, multiple languages. 1 Introduction Reference resolution (Jurafsky and Martin, 2009) (chapter 21, section 21.4) is a task of determining to which entities are referred by which linguistic expressions. This task plays an important role in a large number of NLP applications such as Information Retrieval, Question Answering and Machine Translation. Therefore, it has attracted many attentions within the NLP community. Many works on various aspects (linguistic features (Ng, V., 2007), (Haghighi and Klein, 2009); machine learning models (Soon et al., 2001); multiple languages (Recasens et al., 2010a); and so on) of the coreference resolution task have been published. Until the release of the SemEval-2010 task 1 (Recasens et al., 2010a), there has no competition or public corpus that allows evaluating different coreference resolution systems in multiple languages. Most published systems only focus on a specific language and use the same data sets for example ACE or MUC corpora to train and test the systems. This makes the systems easy to unintentionally adapt themselves to the corpus but not to the pr"
Y11-1042,W03-2604,0,0.120938,"Missing"
Y11-1042,S10-1018,0,0.0283365,"Missing"
Y11-1042,H05-1004,0,0.230632,"42 39 140 Development #sents #tokens 1,445 42,072 741 17,044 1,419 44,460 #docs 167 85 168 Testing #sents #tokens 1,698 49,260 1,141 24,206 1,705 51,040 In the experiments, we evaluate our system using closed gold-standard setting. It means that we use the gold-standard columns with true mention boundaries and our system was built strictly with the information provided in the task datasets. This is because our system focuses on evaluating various approaches of previous participating systems versus our proposed listwise approach. To evaluate our system, we also use four metrics which are CEAF (Luo, 2005), MUC (Vilain et al., 1995), BCUB (Bagga and Baldwin, 1998) and BLANC scores ( Recasens and Marti, 2010b) provided by this shared task. The first three measures have been widely used, while BLANC is a proposal of a new measure interesting to test. 405 MUC-6/7 (Vilain et al., 1995) This is the oldest and most widely-used metric measure. This metric is based on coreference links. First, we count the number of common links between the reference ( or ”truth”) and the system output (or ”response”). The link precision is the number of common links divided by the number of links in the system output,"
Y11-1042,P07-1068,0,0.0240247,"Missing"
Y11-1042,P10-1142,0,0.0513645,"Missing"
Y11-1042,D09-1101,0,0.0660478,"Missing"
Y11-1042,J01-4004,0,0.0961908,"anguages. Keywords: listwise approach, coreference resolution, multiple languages. 1 Introduction Reference resolution (Jurafsky and Martin, 2009) (chapter 21, section 21.4) is a task of determining to which entities are referred by which linguistic expressions. This task plays an important role in a large number of NLP applications such as Information Retrieval, Question Answering and Machine Translation. Therefore, it has attracted many attentions within the NLP community. Many works on various aspects (linguistic features (Ng, V., 2007), (Haghighi and Klein, 2009); machine learning models (Soon et al., 2001); multiple languages (Recasens et al., 2010a); and so on) of the coreference resolution task have been published. Until the release of the SemEval-2010 task 1 (Recasens et al., 2010a), there has no competition or public corpus that allows evaluating different coreference resolution systems in multiple languages. Most published systems only focus on a specific language and use the same data sets for example ACE or MUC corpora to train and test the systems. This makes the systems easy to unintentionally adapt themselves to the corpus but not to the problem in general. Therefore, this SemEval-201"
Y11-1042,S10-1017,0,0.0757226,"rganized as follows. Section 2 reviews related work proposed for this shared task. Section 3 describes our listwise approach to this shared task. Section 4 presents experimental results on the corpora of this SemEval-2010 shared task. Finally, section 5 gives some conclusion and future work. 2 Related Work In this section, we preview previous approaches of the systems participated in the SemEval-2010 shared task 1. The experimental results of these systems are also used to make an experimental comparison with our proposed approach’s results. Here, we preview four systems: (1) RelaxCor system (Sapena et al., 2010); (2) SUCRE system (Kobdani and Schutze, 2010); (3) TANL-1 system (Attardi et al., 2010); and (4) UBIU system (Zhekova and Kubler, 2010). Table 1 presents an overview of the systems, their architecture and machine learning methods. Table 1: Main characteristics of the previous systems. Systems RelaxCor SUCRE TANL-1 UBIU 2.1 System Architecture Graph Partitioning (solved by relaxation labeling) Best-first clustering, Relational database model, Regular feature definition language Highest entity-mention similarity Pairwise model Machine learning methods Decision trees, Rules Decision trees, Nave"
Y11-1042,M95-1005,0,0.209346,"ment #sents #tokens 1,445 42,072 741 17,044 1,419 44,460 #docs 167 85 168 Testing #sents #tokens 1,698 49,260 1,141 24,206 1,705 51,040 In the experiments, we evaluate our system using closed gold-standard setting. It means that we use the gold-standard columns with true mention boundaries and our system was built strictly with the information provided in the task datasets. This is because our system focuses on evaluating various approaches of previous participating systems versus our proposed listwise approach. To evaluate our system, we also use four metrics which are CEAF (Luo, 2005), MUC (Vilain et al., 1995), BCUB (Bagga and Baldwin, 1998) and BLANC scores ( Recasens and Marti, 2010b) provided by this shared task. The first three measures have been widely used, while BLANC is a proposal of a new measure interesting to test. 405 MUC-6/7 (Vilain et al., 1995) This is the oldest and most widely-used metric measure. This metric is based on coreference links. First, we count the number of common links between the reference ( or ”truth”) and the system output (or ”response”). The link precision is the number of common links divided by the number of links in the system output, and the link recall is the"
Y11-1042,P03-1023,0,0.131713,"their final results. The participating systems differed in terms of architecture, machine learning methods, etc. These systems mostly based on pairwise models, graph partitioning and entitymention models. Unfortunately, these models suffered from an important weakness (Ng, V., 2010). In these models, each antecedent candidate is resolved independently with the other candidates. So the models could not determine the best candidate in the relation with the other candidates. To address this drawback, ranking models were proved to be a useful solution (Denis and Baldridge, 2007), (Ng, V., 2005), (Yang et al., 2003). Motivated from ranking models, in this paper, we present our proposal approach for learning-based reference resolution task in multiple languages. Copyright 2011 by Oanh Thi Tran, Bach Xuan Ngo, Minh Le Nguyen, and Akira Shimazu 25th Pacific Asia Conference on Language, Information and Computation, pages 400–409 400 We exploit the listwise approach, which is originally proposed for learning to rank task in information retrieval (Cao et al., 2007), to solve the SemEval-2010 Task on Coreference Resolution in Multiple Languages. This method allows the system to choose the best candidate for a g"
Y11-1042,S10-1019,0,0.0741159,"s shared task. Section 4 presents experimental results on the corpora of this SemEval-2010 shared task. Finally, section 5 gives some conclusion and future work. 2 Related Work In this section, we preview previous approaches of the systems participated in the SemEval-2010 shared task 1. The experimental results of these systems are also used to make an experimental comparison with our proposed approach’s results. Here, we preview four systems: (1) RelaxCor system (Sapena et al., 2010); (2) SUCRE system (Kobdani and Schutze, 2010); (3) TANL-1 system (Attardi et al., 2010); and (4) UBIU system (Zhekova and Kubler, 2010). Table 1 presents an overview of the systems, their architecture and machine learning methods. Table 1: Main characteristics of the previous systems. Systems RelaxCor SUCRE TANL-1 UBIU 2.1 System Architecture Graph Partitioning (solved by relaxation labeling) Best-first clustering, Relational database model, Regular feature definition language Highest entity-mention similarity Pairwise model Machine learning methods Decision trees, Rules Decision trees, Nave Bayes, SVM, MaxEnt MaxEnt MBL RelaxCor system RelaxCor (Sapena et al., 2010) is a constraint-based graph partitioning approach to corefe"
Y11-1042,C10-2125,0,\N,Missing
Y11-1042,D08-1067,0,\N,Missing
