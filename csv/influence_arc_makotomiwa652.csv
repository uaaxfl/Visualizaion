2020.emnlp-demos.24,N19-1423,0,0.138737,"on SARS-CoV-2 needs to be disambiguated. Since the term SARSCoV-2 in this sentence refers to a virus, it should be linked to an entry of a virus in the knowledge base, not to an entry of ‘SARS-CoV-2 vaccination’, which corresponds to therapeutic or preventive procedure to prevent a disease. We present a BERT-based Exhaustive Neural Named Entity Recognition and Disambiguation (BENNERD) system. The system is composed of four models: NER model (Sohrab and Miwa, 2018) that enumerates all possible spans as potential entity mentions and classifies them into entity types, masked language model BERT (Devlin et al., 2019), candidate generation model to find a list of candidate entities in the unified medical language system (UMLS) knowledge base (KB) for entity linking (EL) and candidate ranking model to disambiguate the entity for concept indexing. The BENNERD system provides a web interface to facilitate the process of text annotation and its disambiguation without any training for end users. In addition, we introduce CORD-NERD (COVID-19 Open Research Dataset for Named Entity Recognition and Disambiguation) dataset an extended version of CORD-NER as for leveraging EL task. 2 System Description The main objec"
2020.emnlp-demos.24,K19-1049,0,0.111298,"dentify its ID in the target KB.3 Let us call the ID a concept unique identifier (CUI). The input is all predicted mention spans M = {m1 , m2 , . . . , mn }, where mi denotes the i-th mention and n denotes the total number of predicted mentions. The list of entity mentions {mi }i=1,...,n needs to be mapped to a list of corresponding CUIs {ci }i=1,...,n . We decompose EL into two subtasks: candidate generation and candidate ranking. Candidate Generation To find a list of candidate entities in KB to link with a given mention, we build a candidate generation layer adapting a dual-encoders model (Gillick et al., 2019). Instead of normalizing entity definition to disambiguate entities, we simply normalize the semantic types in both mention and entity sides from UMLS. The representation of a mention m in a document by the semantic type tm , can be denoted as: vm = [wm ; tm ] , (2) where tm ∈ Rdtm is the mention type embedding. For the entity (concept) side with semantic type information, the representation ae , and its entity type embedding te ∈ Rdte can be computed as: 184 ve = [ae ; te ] . 3 We used the UMLS KB in the experiments. (3) types4 . CORD-NER mainly supports four sources including 18 biomedical e"
2020.emnlp-demos.24,D17-1018,0,0.0285025,"vide a quick inside look of our BENNERD web interface (BWI). The data flow of BWI is presented as follows: 183 Server-side initialization (a) The BWI configuration, concept embeddings, and NER and EL models are loaded (b) GENIA sentence splitter and BERT basic tokenizer instances are initialized (c) 2 https://brat.nlplab.org layer assigns a vector vi,j to the j-th subword of the i-th word. Then, we generate the vector embedding vi for each word xi by computing the unweighted average of its subword embeddings vi,j . We generate mention candidates based on the same idea as the span-based model (Lee et al., 2017; Sohrab and Miwa, 2018; Sohrab et al., 2019a,b), in which all continuous word sequences are generated given a maximal size Lx (span width). The representation xb,e ∈ Rdx for the span from the b-th word to the e-th word in a sentence is calculated from the embeddings of the first word, the last word, and the weighted average of all words in the span as follows: "" # e X xb,e = vb ; αb,e,i vi ; ve , (1) Figure 2: BENNERD Users’ Input Interface i=b where αb,e,i denotes the attention value of the i-th word in a span from the b-th word to the e-th word, and [; ; ] denotes concatenation. Figure 3: E"
2020.emnlp-demos.24,P18-1010,0,0.0268445,"gene, chemical, and disease based on our UMLS-based test set. Besides, in Table 4, we also show the NER performances comparison of BENNERD with BC5CDR corpus-based SciSpacy model on the manually annotated disease entities. Candidate Ranking Performance As we are the first to perform EL task on CORD-19 dataset, we present different scenarios to evaluate our candidate ranking performance. The results of EL are depicted in Table 5. In this table, we evaluate our candidate ranking performances based on two experiment settings. In setting1, we train the CUIs based on manually annotated MedMention (Murty et al., 2018) dataset. In setting2, the BENNERD model is trained on automatically annotated CORD-NERD dataset. Table 5 also shows that our BENNERD model with setting2 is outperformed in compare to setting1 in every cases in terms of accuracy@(1, 10, 20, 30, 40, 50). Table 6 shows the EL performance on the manually annotated test set. In this table, it also shows that our system with setting2 is outperformed in compare to setting1. Besides, we also evaluate the manually annotated test set simply with string matching approach where the results of the top 10, 20, 30, 40 or 50 predictions for a gold candidate"
2020.emnlp-demos.24,D18-1309,1,0.882922,"Missing"
2020.emnlp-demos.24,D19-5708,1,0.811757,"eb interface (BWI). The data flow of BWI is presented as follows: 183 Server-side initialization (a) The BWI configuration, concept embeddings, and NER and EL models are loaded (b) GENIA sentence splitter and BERT basic tokenizer instances are initialized (c) 2 https://brat.nlplab.org layer assigns a vector vi,j to the j-th subword of the i-th word. Then, we generate the vector embedding vi for each word xi by computing the unweighted average of its subword embeddings vi,j . We generate mention candidates based on the same idea as the span-based model (Lee et al., 2017; Sohrab and Miwa, 2018; Sohrab et al., 2019a,b), in which all continuous word sequences are generated given a maximal size Lx (span width). The representation xb,e ∈ Rdx for the span from the b-th word to the e-th word in a sentence is calculated from the embeddings of the first word, the last word, and the weighted average of all words in the span as follows: "" # e X xb,e = vb ; αb,e,i vi ; ve , (1) Figure 2: BENNERD Users’ Input Interface i=b where αb,e,i denotes the attention value of the i-th word in a span from the b-th word to the e-th word, and [; ; ] denotes concatenation. Figure 3: Entity Annotation and Linking with BENNERD Co"
2020.emnlp-demos.24,E12-2021,1,0.75114,"Missing"
2020.lrec-1.239,N15-1122,0,0.0135455,"Bs. Therefore, we have presented a domain specific corpus of the synthesis process for ASSBs, and an automated machine-reading system for extracting the synthesis processes buried in the scientific literature. drying 9. Li4 Ti5 O12 LTO Material Operation Property Next Condition Coreference Figure 12: Synthesis graph of the extracted synthesis process in Figure 11. occurrence (Guo et al., 2018), and several attempts to structure and extract a series of cooking-related actions, such as baking and boiling, from cooking recipe sentences (Mori et al., 2014; Kiddon et al., 2015; Maeta et al., 2015; Abend et al., 2015). Numerous language resources exist in the organic chemistry field (Kim et al., 2003; Krallinger et al., 2015; Tsubaki et al., 2017; Kulkarni et al., 2018; Tanaka et al., 2018), which have been annotated with the experimental processes that appear in the papers. Moreover, an attempt has been made to extract processes by applyConclusion This study has addressed the problem of the lack of labeled data, which is a major bottleneck in developing ASSBs. We constructed the novel SynthASSBs corpus, consisting of the experimental sections of 243 papers. The corpus annotates synthesis graphs that repre"
2020.lrec-1.239,N19-4010,0,0.0223071,"Missing"
2020.lrec-1.239,D19-1371,0,0.0144314,"and condition edges, respectively. Random Fields (Huang et al., 2015) as a sequence-tagging model to identify the spans of the vertices. We used six different base representations in the neural network-based sequence tagger: character-level embedding (CE) (Zhang et al., 2015); byte pair encoding (BPE) (Sennrich et al., 2016); word embeddings for inorganic material science Mat-WE (Kim et al., 2017) and mat2vec (Tshitoyan et al., 2019); Mat-ELMo (Kim et al., 2017), which is an embeddings from language models (ELMo) (Peters et al., 2018) model pretrained on materials science texts; and SciBERT (Beltagy et al., 2019), which is a bidirectional encoder representations from transformers (BERT) model (Devlin et al., 2019), pretrained on biomedical and computer science texts. These representations were fine-tuned during training on the sequence-tagging task. Sequence Tagging To train the sequence-tagging model, we employed Bidirectional Long Short-Term Memory with Conditional 3 Count 2,749 1,319 138 532 212 548 1,680 3,994 704 642 66 81 275 2,226 4,139 3,018 759 23,082 https://github.com/allenai/scispacy 4.2. Relation Extraction We developed the following five rules using the training portion of the SynthASSBs"
2020.lrec-1.239,D14-1159,0,0.0295194,"tances, drug names, and their relations are structurally annotated in documents such as papers, patents, and medical documents, while composition names are provided in the abstracts of molecular biology papers. Linguistic resources are available in abundance, such as the GENIA corpus (Kim et al., 2003) of biomedical events on biomedical texts and the annotated corpus (Kulkarni et al., 2018) of liquid-phase experimental processes on biological papers. In biomedical text mining, the detection of semantic relations is actively researched as a central task (Miwa et al., 2012; Scaria et al., 2013; Berant et al., 2014; Rao et al., 2017; Rahul et al., 2017; Bj¨orne and Salakoski, 2018). However, the relations in biomedical text mining represent the cause and effect of a physical phenomenon among two or more biochemical reactions, which differs from the procedure of synthesizing materials. In the field of inorganic chemistry, only several corpora have been proposed in recent years. Kononova et al. (2019) constructed a general-purpose corpus of material synthesis for inorganic material by aligning the phrases extracted by a trained sequence-tagging model. However, this corpus did not include relations between"
2020.lrec-1.239,W18-2311,0,0.0240337,"Missing"
2020.lrec-1.239,N18-1144,0,0.0350103,"Missing"
2020.lrec-1.239,N19-1423,0,0.00624722,"entify the spans of the vertices. We used six different base representations in the neural network-based sequence tagger: character-level embedding (CE) (Zhang et al., 2015); byte pair encoding (BPE) (Sennrich et al., 2016); word embeddings for inorganic material science Mat-WE (Kim et al., 2017) and mat2vec (Tshitoyan et al., 2019); Mat-ELMo (Kim et al., 2017), which is an embeddings from language models (ELMo) (Peters et al., 2018) model pretrained on materials science texts; and SciBERT (Beltagy et al., 2019), which is a bidirectional encoder representations from transformers (BERT) model (Devlin et al., 2019), pretrained on biomedical and computer science texts. These representations were fine-tuned during training on the sequence-tagging task. Sequence Tagging To train the sequence-tagging model, we employed Bidirectional Long Short-Term Memory with Conditional 3 Count 2,749 1,319 138 532 212 548 1,680 3,994 704 642 66 81 275 2,226 4,139 3,018 759 23,082 https://github.com/allenai/scispacy 4.2. Relation Extraction We developed the following five rules using the training portion of the SynthASSBs corpus. The illustrations following the rule descriptions are used for visualization. The 1944 circles"
2020.lrec-1.239,D15-1114,0,0.0131362,"raction system exist for synthesizing ASSBs. Therefore, we have presented a domain specific corpus of the synthesis process for ASSBs, and an automated machine-reading system for extracting the synthesis processes buried in the scientific literature. drying 9. Li4 Ti5 O12 LTO Material Operation Property Next Condition Coreference Figure 12: Synthesis graph of the extracted synthesis process in Figure 11. occurrence (Guo et al., 2018), and several attempts to structure and extract a series of cooking-related actions, such as baking and boiling, from cooking recipe sentences (Mori et al., 2014; Kiddon et al., 2015; Maeta et al., 2015; Abend et al., 2015). Numerous language resources exist in the organic chemistry field (Kim et al., 2003; Krallinger et al., 2015; Tsubaki et al., 2017; Kulkarni et al., 2018; Tanaka et al., 2018), which have been annotated with the experimental processes that appear in the papers. Moreover, an attempt has been made to extract processes by applyConclusion This study has addressed the problem of the lack of labeled data, which is a major bottleneck in developing ASSBs. We constructed the novel SynthASSBs corpus, consisting of the experimental sections of 243 papers. The cor"
2020.lrec-1.239,N18-2016,0,0.185325,"ine reading systems that can comprehensively investigate the synthesis process buried in the scientific literature is necessary. In the field of organic chemistry, Krallinger et al. (2015) proposed a corpus in which chemical substances, drug names, and their relations are structurally annotated in documents such as papers, patents, and medical documents, while composition names are provided in the abstracts of molecular biology papers. Linguistic resources are available in abundance, such as the GENIA corpus (Kim et al., 2003) of biomedical events on biomedical texts and the annotated corpus (Kulkarni et al., 2018) of liquid-phase experimental processes on biological papers. In biomedical text mining, the detection of semantic relations is actively researched as a central task (Miwa et al., 2012; Scaria et al., 2013; Berant et al., 2014; Rao et al., 2017; Rahul et al., 2017; Bj¨orne and Salakoski, 2018). However, the relations in biomedical text mining represent the cause and effect of a physical phenomenon among two or more biochemical reactions, which differs from the procedure of synthesizing materials. In the field of inorganic chemistry, only several corpora have been proposed in recent years. Kono"
2020.lrec-1.239,P16-1138,0,0.0245407,"Missing"
2020.lrec-1.239,W15-2206,0,0.0207121,"for synthesizing ASSBs. Therefore, we have presented a domain specific corpus of the synthesis process for ASSBs, and an automated machine-reading system for extracting the synthesis processes buried in the scientific literature. drying 9. Li4 Ti5 O12 LTO Material Operation Property Next Condition Coreference Figure 12: Synthesis graph of the extracted synthesis process in Figure 11. occurrence (Guo et al., 2018), and several attempts to structure and extract a series of cooking-related actions, such as baking and boiling, from cooking recipe sentences (Mori et al., 2014; Kiddon et al., 2015; Maeta et al., 2015; Abend et al., 2015). Numerous language resources exist in the organic chemistry field (Kim et al., 2003; Krallinger et al., 2015; Tsubaki et al., 2017; Kulkarni et al., 2018; Tanaka et al., 2018), which have been annotated with the experimental processes that appear in the papers. Moreover, an attempt has been made to extract processes by applyConclusion This study has addressed the problem of the lack of labeled data, which is a major bottleneck in developing ASSBs. We constructed the novel SynthASSBs corpus, consisting of the experimental sections of 243 papers. The corpus annotates synthe"
2020.lrec-1.239,mori-etal-2014-flow,0,0.0310165,", no corpus and extraction system exist for synthesizing ASSBs. Therefore, we have presented a domain specific corpus of the synthesis process for ASSBs, and an automated machine-reading system for extracting the synthesis processes buried in the scientific literature. drying 9. Li4 Ti5 O12 LTO Material Operation Property Next Condition Coreference Figure 12: Synthesis graph of the extracted synthesis process in Figure 11. occurrence (Guo et al., 2018), and several attempts to structure and extract a series of cooking-related actions, such as baking and boiling, from cooking recipe sentences (Mori et al., 2014; Kiddon et al., 2015; Maeta et al., 2015; Abend et al., 2015). Numerous language resources exist in the organic chemistry field (Kim et al., 2003; Krallinger et al., 2015; Tsubaki et al., 2017; Kulkarni et al., 2018; Tanaka et al., 2018), which have been annotated with the experimental processes that appear in the papers. Moreover, an attempt has been made to extract processes by applyConclusion This study has addressed the problem of the lack of labeled data, which is a major bottleneck in developing ASSBs. We constructed the novel SynthASSBs corpus, consisting of the experimental sections o"
2020.lrec-1.239,W19-4007,0,0.0200101,"in biomedical text mining represent the cause and effect of a physical phenomenon among two or more biochemical reactions, which differs from the procedure of synthesizing materials. In the field of inorganic chemistry, only several corpora have been proposed in recent years. Kononova et al. (2019) constructed a general-purpose corpus of material synthesis for inorganic material by aligning the phrases extracted by a trained sequence-tagging model. However, this corpus did not include relations between operations, and therefore, it was difficult to extract the step-by-step synthesis process. Mysore et al. (2019) created an annotated corpus with relations between operations for synthesis processes of general materials such as solar cell and thermoelectric materials. However, the synthesis processes of ASSBs are hardly included even though the operations, operation sequences, and conditions also have differences due to the characteristics of the synthesis process for each material category. In this study, we took the first step towards developing a framework for extracting synthesis processes of ASSBs. We designed our annotation scheme to treat a synthesis process as a synthesis flow graph, and perform"
2020.lrec-1.239,W19-5034,0,0.0142068,"ecting types. However, the kappa coefficients in the All settings were lower than those in the Type settings. This indicates that annotation ambiguity was caused when deciding which phrase should be involved in the synthesis process. We leave the improvements in the annotation guidelines to reduce this ambiguity problem for future work. 3.3. Statistics Several key statistics of the SynthASSBs corpus, such as the number of documents, sentences, tokens, and entities, are summarized in Table 2. The number of vertices or edges per type is indicated in Table 3. In the statistics, we used scispaCy (Neumann et al., 2019) 3 to split sentences, perform tokenization and extract entities. 4. Synthesis Process Extraction Our framework performed extraction of synthesis processes in a pipeline manner, using two modules: deep learning-based sequence taggers for extracting the phrases we defined as vertices, and a rule-based relation extractor (RE) for connecting the edges that were pairs of extracted phrases. As illustrated in Figure 4, our framework first performed sequence tagging (a) to extract the phrases related to the material synthesis process. Thereafter, the relations between entities were extracted by the r"
2020.lrec-1.239,N18-1202,0,0.0109867,"and yellow indicates properties. The solid and broken arrows represent the next and condition edges, respectively. Random Fields (Huang et al., 2015) as a sequence-tagging model to identify the spans of the vertices. We used six different base representations in the neural network-based sequence tagger: character-level embedding (CE) (Zhang et al., 2015); byte pair encoding (BPE) (Sennrich et al., 2016); word embeddings for inorganic material science Mat-WE (Kim et al., 2017) and mat2vec (Tshitoyan et al., 2019); Mat-ELMo (Kim et al., 2017), which is an embeddings from language models (ELMo) (Peters et al., 2018) model pretrained on materials science texts; and SciBERT (Beltagy et al., 2019), which is a bidirectional encoder representations from transformers (BERT) model (Devlin et al., 2019), pretrained on biomedical and computer science texts. These representations were fine-tuned during training on the sequence-tagging task. Sequence Tagging To train the sequence-tagging model, we employed Bidirectional Long Short-Term Memory with Conditional 3 Count 2,749 1,319 138 532 212 548 1,680 3,994 704 642 66 81 275 2,226 4,139 3,018 759 23,082 https://github.com/allenai/scispacy 4.2. Relation Extraction We"
2020.lrec-1.239,W17-2340,0,0.185285,"Missing"
2020.lrec-1.239,W17-2315,0,0.0311662,"Missing"
2020.lrec-1.239,D13-1177,0,0.0333787,"n which chemical substances, drug names, and their relations are structurally annotated in documents such as papers, patents, and medical documents, while composition names are provided in the abstracts of molecular biology papers. Linguistic resources are available in abundance, such as the GENIA corpus (Kim et al., 2003) of biomedical events on biomedical texts and the annotated corpus (Kulkarni et al., 2018) of liquid-phase experimental processes on biological papers. In biomedical text mining, the detection of semantic relations is actively researched as a central task (Miwa et al., 2012; Scaria et al., 2013; Berant et al., 2014; Rao et al., 2017; Rahul et al., 2017; Bj¨orne and Salakoski, 2018). However, the relations in biomedical text mining represent the cause and effect of a physical phenomenon among two or more biochemical reactions, which differs from the procedure of synthesizing materials. In the field of inorganic chemistry, only several corpora have been proposed in recent years. Kononova et al. (2019) constructed a general-purpose corpus of material synthesis for inorganic material by aligning the phrases extracted by a trained sequence-tagging model. However, this corpus did not incl"
2020.lrec-1.239,P16-1162,0,0.00735646,"at 800 ℃ for 12 h after drying. (a) Sequence Tagging (b) Rule-based RE Figure 4: Overview of synthesis process extraction. The red phrases and circles indicate terms related to materials, green indicates operations, and yellow indicates properties. The solid and broken arrows represent the next and condition edges, respectively. Random Fields (Huang et al., 2015) as a sequence-tagging model to identify the spans of the vertices. We used six different base representations in the neural network-based sequence tagger: character-level embedding (CE) (Zhang et al., 2015); byte pair encoding (BPE) (Sennrich et al., 2016); word embeddings for inorganic material science Mat-WE (Kim et al., 2017) and mat2vec (Tshitoyan et al., 2019); Mat-ELMo (Kim et al., 2017), which is an embeddings from language models (ELMo) (Peters et al., 2018) model pretrained on materials science texts; and SciBERT (Beltagy et al., 2019), which is a bidirectional encoder representations from transformers (BERT) model (Devlin et al., 2019), pretrained on biomedical and computer science texts. These representations were fine-tuned during training on the sequence-tagging task. Sequence Tagging To train the sequence-tagging model, we employe"
2020.lrec-1.239,E12-2021,0,0.0607743,"and unified certain orthographical variants in composition formulae and quantitative expressions. For example, a “◦ C” was replaced with the token “degC”. Finally, we annotated the synthesis graph on the obtained texts. Three annotators, who were master’s course students in materials science, were involved in the annotation. Annotator A tagged 77 papers, annotator B tagged 68 papers, and annotator C tagged 98 papers. Finally, one professional in materials science verified the annotations of the three student annotators and corrected the annotation errors. We used the brat annotation toolkit (Stenetorp et al., 2012) for manual annotation. Figure 3 illustrates an annotation interface by brat. 3.2. Inter-Annotator Agreement The agreement calculations were based on whether the spans of the labels were precisely matched the three annotators in materials science on the spans by using 30 randomly selected synthesis processes from the SynthASSBs corpus. We calculated the agreements using Cohen’s kappa. For each pair of two annotators selected from the three annotators A, B, and C, the agreement score was calculated by regarding the labels identified by one annotator as gold and the labels by the other annotator"
2020.lrec-1.239,L18-1356,0,0.0183221,"ried in the scientific literature. drying 9. Li4 Ti5 O12 LTO Material Operation Property Next Condition Coreference Figure 12: Synthesis graph of the extracted synthesis process in Figure 11. occurrence (Guo et al., 2018), and several attempts to structure and extract a series of cooking-related actions, such as baking and boiling, from cooking recipe sentences (Mori et al., 2014; Kiddon et al., 2015; Maeta et al., 2015; Abend et al., 2015). Numerous language resources exist in the organic chemistry field (Kim et al., 2003; Krallinger et al., 2015; Tsubaki et al., 2017; Kulkarni et al., 2018; Tanaka et al., 2018), which have been annotated with the experimental processes that appear in the papers. Moreover, an attempt has been made to extract processes by applyConclusion This study has addressed the problem of the lack of labeled data, which is a major bottleneck in developing ASSBs. We constructed the novel SynthASSBs corpus, consisting of the experimental sections of 243 papers. The corpus annotates synthesis graphs that represent the synthesis process of ASSBs in text. Moreover, we proposed an automatic synthesis process extraction framework using our corpus by combining a deep learning-based seque"
2020.lrec-1.239,W19-2609,0,\N,Missing
2020.lrec-1.599,N19-4010,0,0.0375597,"Missing"
2020.lrec-1.599,P18-2014,1,0.865789,"Missing"
2020.lrec-1.599,N19-1423,0,0.00537161,"mited to several relation classes (i.e., RDF properties) such as domain, range, and subClassOf, which makes the RE task much easier. • Ontology-style relation annotations can be used as clear documentations of Ontology contents. If we have all the Ontology contents in text, we can well understand the Ontology content. Moreover, embedding 1 https://www.w3.org/RDF/ vectors of not only entity terms (i.e., Ontology classes) but also relation mentions (i.e., Ontology properties) can be obtained using word2vec (Mikolov et al., 2013) or Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2019) based on Ontologically annotated corpora. This will lead to a new way to integrate textual information and knowledge structures in the future. This paper presents our experience in the OSR annotations on the documents titled Rules of the Road (RoR) that deal with Japanese traffic rules. We converted the in-house corpus in the conventional annotations into the OSR annotations, and we built a new corpus named the OSR-RoR corpus. The inter-annotator agreements (IAA) are high among the annotators, and this shows that the conversion into the OSR annotations is easy. We also applied neural NER and"
2020.lrec-1.599,doddington-etal-2004-automatic,0,0.207396,"Missing"
2020.lrec-1.599,P15-1061,0,0.0609261,"Missing"
2020.lrec-1.599,kingsbury-palmer-2002-treebank,0,0.332599,"Missing"
2020.lrec-1.599,P16-1200,0,0.0568396,"Missing"
2020.lrec-1.599,C18-1060,0,0.0566856,"Missing"
2020.lrec-1.599,P16-1105,1,0.899163,"Missing"
2020.lrec-1.599,C04-1204,0,0.12838,"Missing"
2020.lrec-1.599,E12-2021,0,0.0464385,"Missing"
2020.lrec-1.599,N18-1075,0,0.0559011,"Missing"
2020.lrec-1.599,N18-1080,0,0.0231382,"Missing"
2020.lrec-1.599,S10-1014,0,0.0570684,"Missing"
2020.lrec-1.599,C14-1220,0,0.0767033,"Missing"
2020.lrec-1.599,D15-1203,0,0.0894943,"Missing"
2020.lrec-1.599,D17-1004,0,0.0313064,"Missing"
2020.lrec-1.599,P16-2034,0,0.0504788,"Missing"
2020.wnut-1.38,D19-1371,0,0.0512799,"Missing"
2020.wnut-1.38,E99-1043,0,0.157853,"Missing"
2020.wnut-1.38,N19-1423,0,0.0304642,"Missing"
2020.wnut-1.38,P16-2011,0,0.043839,"Missing"
2020.wnut-1.38,D17-1018,0,0.0219261,"sentence S has n words and the i-th word, represented by Si , is split into sub-words. This layer assigns a vector vi,j to the j-th sub-word of the i-th word. It also produces the representation vS as a local context for the sentence S, which corresponds to the embedding of [CLS] token. 3.2 Entity Recognition layer We build mention detection layer, a.k.a named entity recognition (NER) on top of the BERT. This layer assigns entity or trigger types to overlapping text spans, or word sequences, in a sentence. We firstly generate mention candidates based on the same idea as the span-based model (Lee et al., 2017; Sohrab and Miwa, 2018; Sohrab et al., 2019a), in which all continuous word sequences are generated given a maximum span length Lx . Since BERT layer works only on sub-words, we choose the embedding of the first sub-word vi,1 as word embedding vi of i-th word. The representation xb,e ∈ Rdx for the span from the b-th word to the e-th word in a sentence is calculated from the 291 Role Classiﬁcation Layer Acts-0n Site Measure Role Exhaustive Layer for Trigger-Arg. Representation NER Classiﬁcation Layer Action Reagent Amount Location NER Exhaustive Layer for Span Representation Weigthed Avg. BERT"
2020.wnut-1.38,P16-1105,1,0.609901,"r wet-lab protocol (Tabassum et al., 2020) shared task1 is an open challenge that allows participants to use any methodology and knowledge sources for the wet lab protocols that specify the steps in performing a lab procedure. The task aims at two sub-tasks in wet lab protocols domain: named entity recognition (NER), and relation recognition or extraction (RE). In NER, the task is to detect mentions and classify them into entity types or no entity. NER has drawn considerable attentions as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 1 http://noisy-text.github.io/2020/ wlp-task.html 2 Related Work Most NER work focus on flat entities. Lample et al. (2016) proposed a LSTM-CRF (conditional ran290 Proceedings of the 2020 EMNLP Workshop W-NUT: The Sixth Workshop on Noisy User-generated Text, pages 290–298 c Online, Nov 19, 2020. 2020 Association for Computational Linguistics dom fields) model and this has been widely used and extended for the flat NER, e.g., Akbik et al. (2018). In recent studies of neural network based flat NER, Gungor et al. (2018, 2019) have shown that morphological analysis"
2020.wnut-1.38,D18-1309,1,0.887327,"Missing"
2020.wnut-1.38,D19-5708,1,0.745813,"tional Institute of Advanced Industrial Science and Technology (AIST), 2-4-7 Aomi, Koto-ku, Tokyo, 135-0064, Japan ‡ Toyota Technological Institute, Japan {sohrab.mohammad, khoa.duong, takamura.hiroya}@aist.go.jp, makoto-miwa@toyota-ti.ac.jp Abstract 2016), and co-reference resolution (Fragkou, 2017). In contrast, relation extraction (RE) is a task to identify relation types between known or predicted entity mentions in a sentence. In this paper, we present a BERT-based neural exhaustive approach that addresses both NER and RE tasks. We employ a neural exhaustive model (Sohrab and Miwa, 2018; Sohrab et al., 2019b) for NER and the extended model that addresses RE task. The model detects flat and nested entities by reasoning over all the spans within a specified maximum span length. Unlike the existing models that rely on token-level labels, our model directly employs an entity type as the label of a span. The spans with the representations are classified into their entity types or non-entity. With the mentions predicted by the NER module, we then feed the detected or known mentions to the RE layer that enumerates all trigger-argument pairs as trigger-trigger or trigger-entity pairs and assigns a role"
2020.wnut-1.38,C18-1177,0,0.0481316,"Missing"
2020.wnut-1.38,N18-1131,1,0.729762,"Missing"
2020.wnut-1.38,N18-2016,0,0.273777,"Missing"
2020.wnut-1.38,N16-1030,0,0.059416,"Missing"
2020.wnut-1.38,N19-1308,0,0.0727792,"Missing"
2021.findings-acl.234,2020.lrec-1.239,1,0.914836,"nthesis procedures are annotated as a graph in a document, where 19 node types such as materials, operations, and conditions and 15 directed relation types are defined. The corpus consists of 200 documents for training, 15 for development, and 15 for test. The statistics of the corpus are shown in Appendix A. We chose this corpus since this corpus is publicly available, manually annotated, and it deals with a dense document-level relation graph. We prepared a rule-based model (RULE) as a baseline and as an existing model to initialize the edges, which was adapted from the rule-based system in Kuniyoshi et al. (2020). The rules are summarized in Appendix B. We employ the micro F-score for each relation class as the evaluation metric. We tune the hyper-parameters such as the number and dimensions of layers and dropout rate on the development set using the hyper-parameter optimization E DIT E DIT-IE E DIT-GCN R ANDOM E DIT R ANDOM I NIT Dev 0.788 0.732 0.744 0.751 0.756 Test 0.729 0.685 0.703 0.690 0.720 Table 1: Evaluation results in micro F-score without RULE framework Optuna (Akiba et al., 2019) and the details are shown in Appendix C. We employ the Adam (Kingma and Ba, 2015) optimizer with the default p"
2021.findings-acl.234,D19-1398,0,0.0172775,"valuate a neural model for extracting synthesis procedures from text for the first time. 2 Approach Our approach extracts a relation graph on given entities from a document. We formulate the extraction task as an edge-editing task, where the approach iteratively edits edges with a neural edge classifier in a close-first manner (Miwa and Sasaki, 2014). 2.1 Iterative Edge Editing We build a relation graph by editing the edges iteratively using the edge classifier in Section 2.2. The building finishes when all edges are edited. The edges are edited in a close-first manner (Miwa and Sasaki, 2014; Ma et al., 2019) that edits the close edges first and far edges later. The distance between the entity pair is defined based on the appearing order of entities in a document; if two entities in a pair appear m-th and m + 3-th, the distance becomes 3. Note that each edge is edited only once throughout the entire editing process. Algorithm 1 shows the method to build the graph by the iterative edge editing. To reduce the computational cost, the pairs with the same distance are edited simultaneously and the pairs with distances more than or equal to the maximum distance dmax are edited simultaneously. This reduc"
2021.findings-acl.234,P16-1105,1,0.838712,"s on the development and test sets indicate an imbalance in the corpus split. 4 Case Study We illustrated 6 graphs for an example document (Zhang et al., 2007) in the development data set shown in Figure 2: the result on the right side Related Work RE has been widely studied to identify the relation between two entities in a sentence. In addition to traditional feature/kernel-based methods (Zelenko et al., 2003; Miwa and Sasaki, 2014), many neural RE methods have been proposed based on convolutional neural networks (CNNs) (Zeng et al., 2014), recurrent neural networks (RNNs) (Xu et al., 2015; Miwa and Bansal, 2016), graph convolutional networks (GCNs) (Zhang et al., 2018; Schlichtkrull et al., 2018), and transformers (Wang et al., 2019). However, sentence-level RE is not enough to cover the relations in a document, and document-level RE has increasingly received research attention in recent years. Major approaches for document-level RE are graph-based methods and transformer-based methods. For graph-based methods, Quirk and Poon (2017) first proposed a document graph for document-level RE. Christopoulou et al. (2019) constructed a graph that included heterogeneous nodes such as entity mentions, entities"
2021.findings-acl.234,D14-1200,1,0.913215,"edge-editing approach for document-level RE that utilizes contexts in both relation graphs and documents. Second, we build a strong rule-based model and show that our approach can effectively utilize and enhance the output of the rule-based model. Third, we build and evaluate a neural model for extracting synthesis procedures from text for the first time. 2 Approach Our approach extracts a relation graph on given entities from a document. We formulate the extraction task as an edge-editing task, where the approach iteratively edits edges with a neural edge classifier in a close-first manner (Miwa and Sasaki, 2014). 2.1 Iterative Edge Editing We build a relation graph by editing the edges iteratively using the edge classifier in Section 2.2. The building finishes when all edges are edited. The edges are edited in a close-first manner (Miwa and Sasaki, 2014; Ma et al., 2019) that edits the close edges first and far edges later. The distance between the entity pair is defined based on the appearing order of entities in a document; if two entities in a pair appear m-th and m + 3-th, the distance becomes 3. Note that each edge is edited only once throughout the entire editing process. Algorithm 1 shows the"
2021.findings-acl.234,E17-1110,0,0.029427,"i, 2014), many neural RE methods have been proposed based on convolutional neural networks (CNNs) (Zeng et al., 2014), recurrent neural networks (RNNs) (Xu et al., 2015; Miwa and Bansal, 2016), graph convolutional networks (GCNs) (Zhang et al., 2018; Schlichtkrull et al., 2018), and transformers (Wang et al., 2019). However, sentence-level RE is not enough to cover the relations in a document, and document-level RE has increasingly received research attention in recent years. Major approaches for document-level RE are graph-based methods and transformer-based methods. For graph-based methods, Quirk and Poon (2017) first proposed a document graph for document-level RE. Christopoulou et al. (2019) constructed a graph that included heterogeneous nodes such as entity mentions, entities, and sentences and represented edges between entities from the graph. Nan et al. (2020) proposed the automatic induction of a latent graph for relational reasoning across sentences. The document graphs in these methods are defined on nodes of linguistic units such as words and sentences, which are different from our relation graphs. Unlike our method, these methods do not directly deal with relation graphs among entities. Fo"
2021.findings-acl.234,2020.emnlp-main.520,0,0.0145754,"embedding. Tang et al. (2020) proposed a Hierarchical Inference Network (HIN) for documentlevel RE, which aggregates information from entity level to document level. Zhou et al. (2021) tackled document-level RE with an Adaptive Thresholding and Localized cOntext Pooling (ATLOP) model that introduces a learnable entity-dependent threshold for classification and aggregated local mentionlevel contexts that are relevant to both entities. Several studies focus on procedural texts such as cooking recipes (Bosselut et al., 2018), scientific processes (Dalvi et al., 2018) and open domain procedures (Tandon et al., 2020). They, however, do not directly treat relation graphs. Several efforts have been made to annotate procedural or action graphs in procedural text (Mori et al., 2014; Mysore et al., 2019; Kuniyoshi et al., 2020). Kuniyoshi et al. (2020) and Mehr et al. (2020) individually proposed rule-based systems to extract procedures from a document, but no neural methods have been proposed for the extraction. 6 Conclusions We proposed a novel edge editing approach for document-level relation extraction. This approach treats the task as the edge editing of relation graphs, given nodes. It edits edges consid"
2021.findings-acl.234,N18-1080,0,0.071108,"RULE) and empty graphs (without RULE). E DIT: Proposed model E DIT-IE: E DIT without iterative edge editing, i.e., dmax = 1. ¯G E DIT-GCN: E DIT without GCN by replacing N ¯ in Equation (2) with N R ANDOM E DIT: E DIT with random-order editing Additionally, we evaluate the following model with randomly initialized graphs. R ANDOM I NIT: E DIT with randomly connected edges, the number of which is same as that of the extraction results of RULE, with random classes Note that although we did not provide the direct comparison with the existing models, our E DITGCN without RULE is similar to BRAN (Verga et al., 2018); the only differences are that we use Longformer (Beltagy et al., 2020) instead of transformers, and NER training is not included. Moreover, most of the models for the document-level RE require dataset annotating both entities and their mentions, so the existing models like ATLOP (Zhou et al., 2021) cannot be directly applied to the current task. 3.2 Results without RULE We show the results with empty initial graphs in Table 1. E DIT shows the highest scores and this indicates the effectiveness of our approach when the initial graphs are empty. When we compare E DIT, E DIT-IE, and R ANDOM E D"
2021.findings-acl.234,P19-1132,0,0.0161824,"e document (Zhang et al., 2007) in the development data set shown in Figure 2: the result on the right side Related Work RE has been widely studied to identify the relation between two entities in a sentence. In addition to traditional feature/kernel-based methods (Zelenko et al., 2003; Miwa and Sasaki, 2014), many neural RE methods have been proposed based on convolutional neural networks (CNNs) (Zeng et al., 2014), recurrent neural networks (RNNs) (Xu et al., 2015; Miwa and Bansal, 2016), graph convolutional networks (GCNs) (Zhang et al., 2018; Schlichtkrull et al., 2018), and transformers (Wang et al., 2019). However, sentence-level RE is not enough to cover the relations in a document, and document-level RE has increasingly received research attention in recent years. Major approaches for document-level RE are graph-based methods and transformer-based methods. For graph-based methods, Quirk and Poon (2017) first proposed a document graph for document-level RE. Christopoulou et al. (2019) constructed a graph that included heterogeneous nodes such as entity mentions, entities, and sentences and represented edges between entities from the graph. Nan et al. (2020) proposed the automatic induction of"
2021.findings-acl.234,D15-1206,0,0.0238143,"ifferent behaviors on the development and test sets indicate an imbalance in the corpus split. 4 Case Study We illustrated 6 graphs for an example document (Zhang et al., 2007) in the development data set shown in Figure 2: the result on the right side Related Work RE has been widely studied to identify the relation between two entities in a sentence. In addition to traditional feature/kernel-based methods (Zelenko et al., 2003; Miwa and Sasaki, 2014), many neural RE methods have been proposed based on convolutional neural networks (CNNs) (Zeng et al., 2014), recurrent neural networks (RNNs) (Xu et al., 2015; Miwa and Bansal, 2016), graph convolutional networks (GCNs) (Zhang et al., 2018; Schlichtkrull et al., 2018), and transformers (Wang et al., 2019). However, sentence-level RE is not enough to cover the relations in a document, and document-level RE has increasingly received research attention in recent years. Major approaches for document-level RE are graph-based methods and transformer-based methods. For graph-based methods, Quirk and Poon (2017) first proposed a document graph for document-level RE. Christopoulou et al. (2019) constructed a graph that included heterogeneous nodes such as e"
2021.findings-acl.234,C14-1220,0,0.0450642,"AN DOM E DIT is harmful in this case. Moreover, the different behaviors on the development and test sets indicate an imbalance in the corpus split. 4 Case Study We illustrated 6 graphs for an example document (Zhang et al., 2007) in the development data set shown in Figure 2: the result on the right side Related Work RE has been widely studied to identify the relation between two entities in a sentence. In addition to traditional feature/kernel-based methods (Zelenko et al., 2003; Miwa and Sasaki, 2014), many neural RE methods have been proposed based on convolutional neural networks (CNNs) (Zeng et al., 2014), recurrent neural networks (RNNs) (Xu et al., 2015; Miwa and Bansal, 2016), graph convolutional networks (GCNs) (Zhang et al., 2018; Schlichtkrull et al., 2018), and transformers (Wang et al., 2019). However, sentence-level RE is not enough to cover the relations in a document, and document-level RE has increasingly received research attention in recent years. Major approaches for document-level RE are graph-based methods and transformer-based methods. For graph-based methods, Quirk and Poon (2017) first proposed a document graph for document-level RE. Christopoulou et al. (2019) constructed"
2021.naacl-main.2,N19-1307,0,0.662694,"tention mechanisms (Lin et al., 2016; Ye and Ling, 2019; Yuan et al., 2019), or hard constraints by explicitly selecting non-noisy instances with reinforcement (Feng et al., 2018; Qin et al., 2018b,a; Wu et al., 2019; Yang et al., 2019) and curriculum learning (Huang and Du, 2019). Noise at the word level was addressed in Liu et al. (2018a) via sub-tree parsing on sentences. Adversarial training has been shown to improve DSRE in Wu et al. (2017), while additional unlabelled examples were exploited to assist classification with Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) in Li et al. (2019). Recent methods use additional information from external resources such as entity types and relations (Vashishth et al., 2018), entity Distantly Supervised RE. Methods developed for DSRE have been around for a long time, building upon the idea of distant supervision (Mintz et al., 2009) with the widely used NYT 10 corpus by Riedel et al. (2010). Methods investigating this problem can be divided into several categories. Initial approaches were mostly graphical models, adopted to perform multi-instance learning (Riedel et al., 2010), sentential evaluation (Hoffmann et al., 2011; Bai and Ritter,"
2021.naacl-main.2,P16-1200,0,0.341587,", the mayor of New Orleans , ... bag 2 Figure 1: Example of the bag-level setting in distantly supervised relation extraction and the main idea of our approach. Sentences are adapted from the NYT 10 dataset (Riedel et al., 2010). The usefulness of distantly supervised relation extraction (DSRE) is reflected in facilitating automatic data annotation, as well as the usage of such data to train models for KB population (Ji and Grishman, 2011). However, DSRE suffers from noisy instances, long-tail relations and unbalanced bag sizes. Typical noise reduction methods have focused on using attention (Lin et al., 2016; Ye and Ling, 2019) or reinforcement learning (Qin et al., 2018b; Wu et al., 2019). For long-tail relations, relation type hierarchies and entity descriptors have been proposed (She et al., 2018; Zhang et al., 2019; Hu et al., 2019), while the limited bag size is usually tackled through incorporation of external data (Beltagy et al., 2019), information from KBs (Vashishth et al., 2018) or pre-trained language models (Alt et al., 2019). Our goal is not to investigate noise reduction, since it has already been widely addressed. Instead, we aim to propose a more general framework that can be eas"
2021.naacl-main.2,D19-1005,0,0.0599611,"Missing"
2021.naacl-main.2,D18-1243,0,0.0643796,"award for best actress . Table 5: Sentence reconstruction examples from the W IKI D ISTANT validation set using different priors. _ corresponds to the UNK word and # indicates a number. 6 Related Work selection of informative instances using either soft constraints, i.e., attention mechanisms (Lin et al., 2016; Ye and Ling, 2019; Yuan et al., 2019), or hard constraints by explicitly selecting non-noisy instances with reinforcement (Feng et al., 2018; Qin et al., 2018b,a; Wu et al., 2019; Yang et al., 2019) and curriculum learning (Huang and Du, 2019). Noise at the word level was addressed in Liu et al. (2018a) via sub-tree parsing on sentences. Adversarial training has been shown to improve DSRE in Wu et al. (2017), while additional unlabelled examples were exploited to assist classification with Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) in Li et al. (2019). Recent methods use additional information from external resources such as entity types and relations (Vashishth et al., 2018), entity Distantly Supervised RE. Methods developed for DSRE have been around for a long time, building upon the idea of distant supervision (Mintz et al., 2009) with the widely used NYT 10 corpus"
2021.naacl-main.2,P18-1046,0,0.548992,"bag-level setting in distantly supervised relation extraction and the main idea of our approach. Sentences are adapted from the NYT 10 dataset (Riedel et al., 2010). The usefulness of distantly supervised relation extraction (DSRE) is reflected in facilitating automatic data annotation, as well as the usage of such data to train models for KB population (Ji and Grishman, 2011). However, DSRE suffers from noisy instances, long-tail relations and unbalanced bag sizes. Typical noise reduction methods have focused on using attention (Lin et al., 2016; Ye and Ling, 2019) or reinforcement learning (Qin et al., 2018b; Wu et al., 2019). For long-tail relations, relation type hierarchies and entity descriptors have been proposed (She et al., 2018; Zhang et al., 2019; Hu et al., 2019), while the limited bag size is usually tackled through incorporation of external data (Beltagy et al., 2019), information from KBs (Vashishth et al., 2018) or pre-trained language models (Alt et al., 2019). Our goal is not to investigate noise reduction, since it has already been widely addressed. Instead, we aim to propose a more general framework that can be easily combined with existing noise reduction methods or pre-traine"
2021.naacl-main.2,P18-1199,0,0.0983512,"bag-level setting in distantly supervised relation extraction and the main idea of our approach. Sentences are adapted from the NYT 10 dataset (Riedel et al., 2010). The usefulness of distantly supervised relation extraction (DSRE) is reflected in facilitating automatic data annotation, as well as the usage of such data to train models for KB population (Ji and Grishman, 2011). However, DSRE suffers from noisy instances, long-tail relations and unbalanced bag sizes. Typical noise reduction methods have focused on using attention (Lin et al., 2016; Ye and Ling, 2019) or reinforcement learning (Qin et al., 2018b; Wu et al., 2019). For long-tail relations, relation type hierarchies and entity descriptors have been proposed (She et al., 2018; Zhang et al., 2019; Hu et al., 2019), while the limited bag size is usually tackled through incorporation of external data (Beltagy et al., 2019), information from KBs (Vashishth et al., 2018) or pre-trained language models (Alt et al., 2019). Our goal is not to investigate noise reduction, since it has already been widely addressed. Instead, we aim to propose a more general framework that can be easily combined with existing noise reduction methods or pre-traine"
2021.naacl-main.2,P19-1023,0,0.105189,"10 and 30 words for W IKI D ISTANT. Each bag in the training set is allowed to contain maximum 500 sentences selected randomly. For prediction on the validation and test sets, all sentences (with full length) are used. W IKI D ISTANT. The WikiDistant dataset is almost double the size of the NYT 10 and contains 454 target relation categories, including the negative relation. It was recently introduced by Han et al. (2020) as a cleaner and more well structured bag-level dataset compared to NYT 10, with fewer negative instances. For the Knowledge Base, we use the version of Wikidata3 provided by Wang et al. (2019b) (in particular the transductive split4 ), containing approximately 5 million entities. Similarly to Freebase, we remove all links between pairs in the test set from the resulting KB, which contains approximately 20 million triples after pruning. 3.2 Bags Table 1: Datasets statistics. ‘NA’ correponds to the ‘no relation’ category. Experimental Settings 3.1 Instances NYT 10 (9) where λ corresponds to a weight in [0, 1]. We weigh the classification loss more than the ELBO to allow the model to better fit the target task. 3 Split 3.4 Baselines In this work we compare with various models applied"
2021.naacl-main.2,N19-1325,0,0.0119584,"t film was ‘ the _ ’ , starring _ and starring _ . _ , who was the first female actress to win the academy award for best actress . Table 5: Sentence reconstruction examples from the W IKI D ISTANT validation set using different priors. _ corresponds to the UNK word and # indicates a number. 6 Related Work selection of informative instances using either soft constraints, i.e., attention mechanisms (Lin et al., 2016; Ye and Ling, 2019; Yuan et al., 2019), or hard constraints by explicitly selecting non-noisy instances with reinforcement (Feng et al., 2018; Qin et al., 2018b,a; Wu et al., 2019; Yang et al., 2019) and curriculum learning (Huang and Du, 2019). Noise at the word level was addressed in Liu et al. (2018a) via sub-tree parsing on sentences. Adversarial training has been shown to improve DSRE in Wu et al. (2017), while additional unlabelled examples were exploited to assist classification with Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) in Li et al. (2019). Recent methods use additional information from external resources such as entity types and relations (Vashishth et al., 2018), entity Distantly Supervised RE. Methods developed for DSRE have been around for a long time"
2021.naacl-main.2,D18-1157,0,0.319431,"Missing"
2021.naacl-main.2,N19-1288,0,0.0493428,"Orleans , ... bag 2 Figure 1: Example of the bag-level setting in distantly supervised relation extraction and the main idea of our approach. Sentences are adapted from the NYT 10 dataset (Riedel et al., 2010). The usefulness of distantly supervised relation extraction (DSRE) is reflected in facilitating automatic data annotation, as well as the usage of such data to train models for KB population (Ji and Grishman, 2011). However, DSRE suffers from noisy instances, long-tail relations and unbalanced bag sizes. Typical noise reduction methods have focused on using attention (Lin et al., 2016; Ye and Ling, 2019) or reinforcement learning (Qin et al., 2018b; Wu et al., 2019). For long-tail relations, relation type hierarchies and entity descriptors have been proposed (She et al., 2018; Zhang et al., 2019; Hu et al., 2019), while the limited bag size is usually tackled through incorporation of external data (Beltagy et al., 2019), information from KBs (Vashishth et al., 2018) or pre-trained language models (Alt et al., 2019). Our goal is not to investigate noise reduction, since it has already been widely addressed. Instead, we aim to propose a more general framework that can be easily combined with ex"
2021.naacl-main.2,D15-1203,0,0.0972093,"RE. Methods developed for DSRE have been around for a long time, building upon the idea of distant supervision (Mintz et al., 2009) with the widely used NYT 10 corpus by Riedel et al. (2010). Methods investigating this problem can be divided into several categories. Initial approaches were mostly graphical models, adopted to perform multi-instance learning (Riedel et al., 2010), sentential evaluation (Hoffmann et al., 2011; Bai and Ritter, 2019) or multi-instance learning and multi-label classification (Surdeanu et al., 2012). Subsequent approaches utilised neural models, with the approach of Zeng et al. (2015) introducing Piecewise Convolutional Neural Networks (PCNN) into the task. Later approaches focused on noise reduction via 18 descriptors (Ji et al., 2017; She et al., 2018; Hu et al., 2019) or Knowledge Bases (Weston et al., 2013; Xu and Barbosa, 2019; Li et al., 2020b). context agnostic knowledge base triples information as latent signals into context aware bag-level entity pairs. Our method is based on a variational autoencoder that is trained jointly with a relation classifier. KB information via a link prediction model is used in the form of prior distributions on the VAE for each pair. T"
2021.naacl-main.2,N19-1306,0,0.0373478,"Missing"
C10-1088,W04-3224,0,0.0147143,"PAS Figure 5: Format conversion dependencies in six parsers. Formats adopted for the evaluation are shown in solid boxes. SD: Stanford Dependency format, CCG: Combinatory Categorial Grammar output format, PTB: Penn Treebank format, and PAS: Predicate Argument Structure in Enju format. CONJ Figure 3: CoNLL-X dependency tree noun_arg1 arg1 Conll-X CCG prep_arg12 prep_arg12 arg1 arg2 NFAT/AP-1 complex formed only with P and P2 verb_arg1 arg1 adj_arg1 coord_arg12 coord_arg12 arg1 arg1 arg2 Figure 4: Predicate Argument Structure parsers are GDep (Sagae and Tsujii, 2007), the Bikel parser (Bikel) (Bikel, 2004), the Stanford parser with two probabilistic context-free grammar (PCFG) models1 (Wall Street Journal (WSJ) model (Stanford WSJ) and “augmented English” model (Stanford eng)) (Klein and Manning, 2003), the Charniak-Johnson reranking parser, using David McClosky’s self-trained biomedical parsing model (MC) (McClosky, 2009), the C&C CCG parser, adapted to biomedical text (C&C) (Rimell and Clark, 2009), and the Enju parser with the GENIA model (Miyao et al., 2009). The formats are Stanford Dependencies (SD) (Figure 2), the CoNLL-X dependency format (CoNLL) (Figure 3) and the predicateargument str"
C10-1088,W09-1402,0,0.127233,"Missing"
C10-1088,de-marneffe-etal-2006-generating,0,0.160065,"Missing"
C10-1088,W07-2416,0,0.039232,"format containing predicate argument structures along with a phrase structure tree in Enju format, which can be converted into PTB format (Miyao et al., 2009). For direct comparison and for the study of contribution of the formats in which the six parsers output their analyses to task performance, we apply a number of conversions between the outputs, shown in Figure 5. The Enju PAS output is converted into PTB using the method introduced by (Miyao et al., 2009). SD is generated from PTB by the Stanford tools (de Marneffe et al., 2006), and CoNLL generated from PTB by using Treebank Converter (Johansson and Nugues, 2007). With the exception of GDep, all CoNLL outputs are generated by the conversion and thus share dependency types. We note that all of these conversions can introduce some errors in the conversion process. 781 4 Evaluation Setting 4.1 Event Extraction Evaluation Event extraction performance is evaluated using the evaluation script provided by the BioNLP’09 shared task organizers for the development data set, and the online evaluation system of the task for the test data set2 . Results are reported under the official evaluation criterion of the task, i.e. the “Approximate Span Matching/Approximat"
C10-1088,W09-1401,1,0.485832,"rresponding to locations and sites considered in Task 2. Theme phosphorylation Theme TRAF2 2.1 Binding binding Theme Theme TRAF2 CD40 Figure 1: Event Extraction. sults shows that performance against gold standard annotations is not always correlated with event extraction performance. We further find that the dependency types and overall structures employed by the different dependency representations have specific advantages and disadvantages for the event extraction task. 2 Bio-molecular Event Extraction In this study, we adopt the event extraction task defined in the BioNLP 2009 Shared Task (Kim et al., 2009) as a model information extraction task. Figure 1 shows an example illustrating the task of event extraction from a sentence. The shared task provided common and consistent task definitions, data sets for training and evaluation, and evaluation criteria. The shared task defined five simple events (Gene expression, Transcription, Protein catabolism, Phosphorylation, and Localization) that take one core argument, a multiparticipant binding event (Binding), and three regulation events (Regulation, Positive regulation, and Negative regulation) used to capture both biological regulation and general"
C10-1088,P03-1054,0,0.00137982,"ar output format, PTB: Penn Treebank format, and PAS: Predicate Argument Structure in Enju format. CONJ Figure 3: CoNLL-X dependency tree noun_arg1 arg1 Conll-X CCG prep_arg12 prep_arg12 arg1 arg2 NFAT/AP-1 complex formed only with P and P2 verb_arg1 arg1 adj_arg1 coord_arg12 coord_arg12 arg1 arg1 arg2 Figure 4: Predicate Argument Structure parsers are GDep (Sagae and Tsujii, 2007), the Bikel parser (Bikel) (Bikel, 2004), the Stanford parser with two probabilistic context-free grammar (PCFG) models1 (Wall Street Journal (WSJ) model (Stanford WSJ) and “augmented English” model (Stanford eng)) (Klein and Manning, 2003), the Charniak-Johnson reranking parser, using David McClosky’s self-trained biomedical parsing model (MC) (McClosky, 2009), the C&C CCG parser, adapted to biomedical text (C&C) (Rimell and Clark, 2009), and the Enju parser with the GENIA model (Miyao et al., 2009). The formats are Stanford Dependencies (SD) (Figure 2), the CoNLL-X dependency format (CoNLL) (Figure 3) and the predicateargument structure (PAS) format used by Enju (Figure 4). With the exception of Stanford and Enju, the analyses of these parsers were provided by the BioNLP 2009 Shared Task organizers. The six parsers operate in"
C10-1088,W10-1905,1,0.178147,"vents as arguments, creating complex event structures. We consider two subtasks, Task 1 and Task 2, out of the three defined in the shared task. Task 1 focuses on core event extraction, and Task 2 involves augmenting extracted events with secondary arguments (Kim et al., 2009). Events are represented with a textual trigger, type, and arguments, where the trigger is a span of text that states the event in text. In Task 1 the event arguments that need to be extracted are restricted to the core Theme and Cause roles, with secondary arEvent Extraction System For evaluation, we apply the system of Miwa et al. (2010b). The system was originally developed for finding core events (Task 1) using the native output of the Enju and GDep parsers. The system consists of three supervised classification-based modules: a trigger detector, an event edge detector, and a complex event detector. The trigger detector classifies each word into the appropriate event types, the event edge detector classifies each edge between an event and a candidate participant into an argument type, and the complex event detector classifies event candidates constructed by all edge combinations, deciding between event and non-event. The s"
C10-1088,W07-1004,1,0.839951,"e results on the test data set. Results on simple, binding, regulation, and all events are shown. GDep and Enju with PAS are used. Results by Miwa et al. (2010b), Bj¨orne et al. (2009), Riedel et al. (2009), and Baseline for Task 1 and Task 2 are shown for comparison. Baseline results are produced by removing dependency information from the parse results of GDep and Enju. The best score in each result is shown in bold. tem. 6 Related Work Many approaches for parser comparison have been proposed, and most comparisons have used gold treebanks with intermediate formats (Clegg and Shepherd, 2007; Pyysalo et al., 2007). Parser comparison has also been proposed on specific tasks such as unbounded dependencies (Rimell ¨ et al., 2009) and textual entailment (Onder Eker, 7 2009) . Among them, application-oriented parser comparison across several formats was first introduced by Miyao et al. (2009), who compared eight parsers and five formats for the protein-protein interaction (PPI) extraction task. PPI extraction, the 785 7 http://pete.yuret.com/ recognition of binary relations of between proteins, is one of the most basic information extraction tasks in the BioNLP field. Our findings do not conflict with those"
C10-1088,W09-1406,1,0.675638,"the event extraction (shown with the gold treebank data in Table 3), but the types and relations of CoNLL were well predicted, and MC and Enju performed better for CoNLL than for SD in total. 5.5 Performance of Event Extraction System Several systems are compared by the extraction performance on the shared task test data in Table 5. GDep and Enju with PAS are used for the evaluation, which is the same evaluation setting with the original system by Miwa et al. (2010b). The performance of the best systems in the original shared task is shown for reference ((Bj¨orne et al., 2009) in Task 1 and (Riedel et al., 2009) in Task 2). The event extraction system performs significantly better than the best systems in the shared task, further outperforming the original system. This shows that the comparison of the parsers is performed with a state-of-the-art sys784 Baseline Bikel Stanford WSJ Stanford eng GDep MC C&C Enju GENIA SD 51.05 53.29 53.51 55.02 55.60 56.09 55.48 56.34 Task 1 CoNLL 53.22 54.38 53.66 55.70 56.01 55.74 56.09 PAS 50.42 56.57 57.94 SD 49.17 51.40 52.02 53.41 53.94 54.27 54.06 55.04 Task 2 CoNLL 51.27 52.04 52.74 54.37 54.51 54.37 54.57 PAS 48.88 55.31 56.40 Table 3: Comparison of F-score res"
C10-1088,D09-1085,0,0.0439988,"Missing"
C10-1088,D07-1111,1,0.192022,"lex formed only with P and P2 NMOD VMOD PMOD SD PTB PAS Figure 5: Format conversion dependencies in six parsers. Formats adopted for the evaluation are shown in solid boxes. SD: Stanford Dependency format, CCG: Combinatory Categorial Grammar output format, PTB: Penn Treebank format, and PAS: Predicate Argument Structure in Enju format. CONJ Figure 3: CoNLL-X dependency tree noun_arg1 arg1 Conll-X CCG prep_arg12 prep_arg12 arg1 arg2 NFAT/AP-1 complex formed only with P and P2 verb_arg1 arg1 adj_arg1 coord_arg12 coord_arg12 arg1 arg1 arg2 Figure 4: Predicate Argument Structure parsers are GDep (Sagae and Tsujii, 2007), the Bikel parser (Bikel) (Bikel, 2004), the Stanford parser with two probabilistic context-free grammar (PCFG) models1 (Wall Street Journal (WSJ) model (Stanford WSJ) and “augmented English” model (Stanford eng)) (Klein and Manning, 2003), the Charniak-Johnson reranking parser, using David McClosky’s self-trained biomedical parsing model (MC) (McClosky, 2009), the C&C CCG parser, adapted to biomedical text (C&C) (Rimell and Clark, 2009), and the Enju parser with the GENIA model (Miyao et al., 2009). The formats are Stanford Dependencies (SD) (Figure 2), the CoNLL-X dependency format (CoNLL)"
C10-1088,I05-2038,1,0.573522,"ax have been successfully applied to a number of tasks in BioNLP. Several parsers and representations have been applied in high-performing methods both in domain studies in general and in the BioNLP’09 shared task in particular, but no direct comparison of parsers or representations has been performed. Likewise, a number of evaluation of parser outputs against gold standard corpora have been performed in the domain, but the broader implications of the results of such intrinsic evaluations are rarely considered. The BioNLP’09 shared task involved documents contained also in the GENIA treebank (Tateisi et al., 2005), creating an opportunity for direct study of intrinsic and task-oriented evaluation results. As the treebank can be converted into various dependency formats using existing format conversion methods, evaluation can further be extended to cover the effects of different representations. 1 Introduction Advanced syntactic parsing methods have been shown to effective for many information extraction tasks. The BioNLP 2009 Shared Task, a recent bio-molecular event extraction task, is one such task: analysis showed that the application of a parser correlated with high rank in the task (Kim In this th"
C10-1089,W08-0601,0,0.0955005,"heir method might remove important information for a given target relation. For example, they might accidentally simplify a noun phrase that is needed to extract the relation. Still, they improved overall PPI extraction recall using such simplifications. To remove unnecessary information from a sentence, some works have addressed sentence simplification by iteratively removing unnecessary phrases. Most of this work is not task-specific; it is intended to compress all information in a target sentence into a few words (Dorr et al., 2003; Vanderwende et al., 2007). Among them, Vickrey and Koller (2008) applied sentence simplification to semantic role labeling. With retaining all arguments of a verb, Vickrey simplified the sentence by removing some information outside of the verb and arguments. 3 Entity-Focused Sentence Simplification We simplify a target sentence using simple rules applicable to the output of a deep parser called Mogura (Matsuzaki et al., 2007), to remove noisy information for relation extraction. Our method relies on the deep parser; the rules depend on the Head-driven Phrase Structure Grammar (HPSG) used by Mogura, and all the rules are written for the parser Enju XML out"
C10-1089,H05-1091,0,0.0707068,"sed as an example relation extraction problem. A dozen simple rules are defined on output from a deep parser. Each rule specifically examines the entities in one target interaction pair. These simple rules were tested using several PPI corpora. The PPI extraction performance was improved on all the PPI corpora. Recently, machine-learning methods, boosted by NLP techniques, have proved to be effective for RE. These methods are usually intended to highlight or select the relation-related regions in parsed sentences using feature vectors or kernels. The shortest paths between a pair of entities (Bunescu and Mooney, 2005) or pair-enclosed trees (Zhang et al., 2006) are widely used as focus regions. These regions are useful, but they can include unnecessary sub-paths such as appositions, which cause noisy features. 1 Introduction Relation extraction (RE) is the task of finding a relevant semantic relation between two given target entities in a sentence (Sarawagi, 2008). Some example relation types are person–organization relations (Doddington et al., 2004), protein– protein interactions (PPI), and disease–gene associations (DGA) (Chun et al., 2006). Among the possible RE tasks, we chose the PPI extraction probl"
C10-1089,W09-1304,0,0.0196783,"es sufficient information to determine the value of the relation in these examples. Relation-related mentions remained for most of the simplification error cases. There were only five critical errors, which changed the truth-value of the relation, out of 46 errors in 241 pairs shown in Table 8. Please note that some rules can be dangerous for other relation extraction tasks. For example, the sentence clause rule could remove modality information (negation, speculation, etc.) modifying the clause, but there are few such cases in the PPI corpora (see Table 8). Also, the task of hedge detection (Morante and Daelemans, 2009) can be solved separately, in the original sentences, after the interacting pairs have been found. For example, in the BioNLP shared task challenge and the BioInfer corpus, interaction detection and modality are treated as two different tasks. Once other NLP tasks, like static relation (Pyysalo et 794 al., 2009) or coreference resolution, become good enough, they can supplement or even substitute some of the proposed rules. There are different difficulties in the BioInfer and AIMed corpora. BioInfer includes more complicated sentences and problems than the other corpora do, because 1) the appo"
C10-1089,W09-1301,1,0.461091,"Missing"
C10-1089,doddington-etal-2004-automatic,0,0.0213557,"ded to highlight or select the relation-related regions in parsed sentences using feature vectors or kernels. The shortest paths between a pair of entities (Bunescu and Mooney, 2005) or pair-enclosed trees (Zhang et al., 2006) are widely used as focus regions. These regions are useful, but they can include unnecessary sub-paths such as appositions, which cause noisy features. 1 Introduction Relation extraction (RE) is the task of finding a relevant semantic relation between two given target entities in a sentence (Sarawagi, 2008). Some example relation types are person–organization relations (Doddington et al., 2004), protein– protein interactions (PPI), and disease–gene associations (DGA) (Chun et al., 2006). Among the possible RE tasks, we chose the PPI extraction problem. PPI extraction is a major RE task; In this paper, we propose a method to remove information that is deemed unnecessary for RE. Instead of selecting the whole region between a target pair, the target sentence is simplified into simpler, pair-related, sentences using general, task-independent, rules. By addressing particularly the target entities, the rules do not affect important relation-related expressions between the target entities"
C10-1089,W03-0501,0,0.00953737,"k grammar parser by simplifying the target sentence in a general manner, so their method might remove important information for a given target relation. For example, they might accidentally simplify a noun phrase that is needed to extract the relation. Still, they improved overall PPI extraction recall using such simplifications. To remove unnecessary information from a sentence, some works have addressed sentence simplification by iteratively removing unnecessary phrases. Most of this work is not task-specific; it is intended to compress all information in a target sentence into a few words (Dorr et al., 2003; Vanderwende et al., 2007). Among them, Vickrey and Koller (2008) applied sentence simplification to semantic role labeling. With retaining all arguments of a verb, Vickrey simplified the sentence by removing some information outside of the verb and arguments. 3 Entity-Focused Sentence Simplification We simplify a target sentence using simple rules applicable to the output of a deep parser called Mogura (Matsuzaki et al., 2007), to remove noisy information for relation extraction. Our method relies on the deep parser; the rules depend on the Head-driven Phrase Structure Grammar (HPSG) used by"
C10-1089,P08-1040,0,0.189425,"eneral manner, so their method might remove important information for a given target relation. For example, they might accidentally simplify a noun phrase that is needed to extract the relation. Still, they improved overall PPI extraction recall using such simplifications. To remove unnecessary information from a sentence, some works have addressed sentence simplification by iteratively removing unnecessary phrases. Most of this work is not task-specific; it is intended to compress all information in a target sentence into a few words (Dorr et al., 2003; Vanderwende et al., 2007). Among them, Vickrey and Koller (2008) applied sentence simplification to semantic role labeling. With retaining all arguments of a verb, Vickrey simplified the sentence by removing some information outside of the verb and arguments. 3 Entity-Focused Sentence Simplification We simplify a target sentence using simple rules applicable to the output of a deep parser called Mogura (Matsuzaki et al., 2007), to remove noisy information for relation extraction. Our method relies on the deep parser; the rules depend on the Head-driven Phrase Structure Grammar (HPSG) used by Mogura, and all the rules are written for the parser Enju XML out"
C10-1089,P06-1104,0,0.166397,"ozen simple rules are defined on output from a deep parser. Each rule specifically examines the entities in one target interaction pair. These simple rules were tested using several PPI corpora. The PPI extraction performance was improved on all the PPI corpora. Recently, machine-learning methods, boosted by NLP techniques, have proved to be effective for RE. These methods are usually intended to highlight or select the relation-related regions in parsed sentences using feature vectors or kernels. The shortest paths between a pair of entities (Bunescu and Mooney, 2005) or pair-enclosed trees (Zhang et al., 2006) are widely used as focus regions. These regions are useful, but they can include unnecessary sub-paths such as appositions, which cause noisy features. 1 Introduction Relation extraction (RE) is the task of finding a relevant semantic relation between two given target entities in a sentence (Sarawagi, 2008). Some example relation types are person–organization relations (Doddington et al., 2004), protein– protein interactions (PPI), and disease–gene associations (DGA) (Chun et al., 2006). Among the possible RE tasks, we chose the PPI extraction problem. PPI extraction is a major RE task; In th"
C14-1214,W06-0901,0,0.253654,"g., Riloff (1996). In contrast, supervised learning approaches have constituted a more popular means of approaching the ACE tasks2 . In this paper, we choose to focus on adapting our biomedical-focussed event extraction method to the ACE 2005 task. Our choice is based on the task definition for ACE 2005 having more in common with the BioNLP 2013 GENIA ST definition than the MUC event template task definition. In terms of the characteristics of state-of-the-art event extraction systems designed according to the ACE 2005 model, pipeline-based approaches have been popular (Grishman et al., 2005; Ahn, 2006). Grishman et al. (2005) proposed a method that sequentially identifies textual spans of arguments, role types, and event triggers. This pipeline approach has been further extended in several subsequent studies. For example, Liao et al. (2010) investigated document-level cross-event consistency using co-occurrence of events and event arguments, while Hong et al. (2011) exploited information gathered from the web to ensure cross-entity consistency. 2 Note that there are also approaches using few or no training data (e.g., (Ji and Grishman, 2008; Lu and Roth, 2012)) for the ACE 2005 task, but th"
C14-1214,W13-2003,0,0.0309991,"Missing"
C14-1214,J92-4003,0,0.309509,"Missing"
C14-1214,M98-1001,0,0.129253,"Missing"
C14-1214,W06-2202,0,0.0313226,"trigger and arguments (see Figures 1 and 2.) A trigger is typically a verb or a nominalised verb that denotes the presence of the event in the text, while the arguments are usually entities. In general, arguments are assigned semantic roles that characterise their contribution towards the event description. Until now, however, there has been little, if any, effort by researchers working on event extraction in different domains to share ideas and techniques, unlike syntactic tasks (e.g., (Miyao and Tsujii, 2008)) and other information extraction tasks, such as named entity recognition (e.g., (Giuliano et al., 2006)) and relation extraction (e.g., (Qian and Zhou, 2012)). This means that the potential to exploit crossdomain features of events to develop more adaptable event extraction systems is an under-studied area. Consequently, although there is a large number of published studies on event extraction, proposing many different methods, no work has previously been reported that aims to adapt an event extraction method developed for one domain to a new domain. In response to the above, we have investigated the feasibility of adapting an event extraction method developed for the biomedical domain to the n"
C14-1214,P13-2082,0,0.0252783,"investigate the adaptation of alternative methods proposed for use in one domain to another domain. Several interesting approaches have been described, such as the utilisation of contextual information beyond the boundaries of individual sentences in the newswire domain (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011) and joint approaches in the biomedical domain (McClosky et al., 2012), but their adaptability to other domains has not yet been investigated. We also intend to investigate the possibility of discovering and utilising shared information between the two domains (Goldwasser and Roth, 2013). Encouraging greater levels of communication between researchers working on NLP tasks in different domains will help to stimulate such new directions of research, both for event extraction and for other related information extraction tasks, such as relation extraction and coreference resolution. Acknowledgements This work was supported by the Arts and Humanities Research Council (AHRC) [grant number AH/L00982X/1], the Medical Research Council [grant number MR/L01078X/1], the European Community’s Seventh Program (FP7/2007-2013) [grant number 318736 (OSSMETER)], and the JSPS Grant-inAid for You"
C14-1214,W13-2004,0,0.0233546,"Missing"
C14-1214,P11-1113,0,0.412161,"tion than the MUC event template task definition. In terms of the characteristics of state-of-the-art event extraction systems designed according to the ACE 2005 model, pipeline-based approaches have been popular (Grishman et al., 2005; Ahn, 2006). Grishman et al. (2005) proposed a method that sequentially identifies textual spans of arguments, role types, and event triggers. This pipeline approach has been further extended in several subsequent studies. For example, Liao et al. (2010) investigated document-level cross-event consistency using co-occurrence of events and event arguments, while Hong et al. (2011) exploited information gathered from the web to ensure cross-entity consistency. 2 Note that there are also approaches using few or no training data (e.g., (Ji and Grishman, 2008; Lu and Roth, 2012)) for the ACE 2005 task, but they are not so many and we will focus on the supervised learning approaches in this paper. 2271 Li et al. (2013) recently proposed a joint detection method to detect both triggers and arguments (together with their role types) using a structured perceptron model. The system outperformed the best results reported for the ACE 2005 task in the literature, without the use o"
C14-1214,P08-1030,0,0.49716,"ne-based approaches have been popular (Grishman et al., 2005; Ahn, 2006). Grishman et al. (2005) proposed a method that sequentially identifies textual spans of arguments, role types, and event triggers. This pipeline approach has been further extended in several subsequent studies. For example, Liao et al. (2010) investigated document-level cross-event consistency using co-occurrence of events and event arguments, while Hong et al. (2011) exploited information gathered from the web to ensure cross-entity consistency. 2 Note that there are also approaches using few or no training data (e.g., (Ji and Grishman, 2008; Lu and Roth, 2012)) for the ACE 2005 task, but they are not so many and we will focus on the supervised learning approaches in this paper. 2271 Li et al. (2013) recently proposed a joint detection method to detect both triggers and arguments (together with their role types) using a structured perceptron model. The system outperformed the best results reported for the ACE 2005 task in the literature, without the use of any external resources. 2.2 Biomedical Event Extraction The task of event extraction has received a large amount of attention from BioNLP researchers in recent years. Interest"
C14-1214,P13-1008,0,0.103204,"nts, role types, and event triggers. This pipeline approach has been further extended in several subsequent studies. For example, Liao et al. (2010) investigated document-level cross-event consistency using co-occurrence of events and event arguments, while Hong et al. (2011) exploited information gathered from the web to ensure cross-entity consistency. 2 Note that there are also approaches using few or no training data (e.g., (Ji and Grishman, 2008; Lu and Roth, 2012)) for the ACE 2005 task, but they are not so many and we will focus on the supervised learning approaches in this paper. 2271 Li et al. (2013) recently proposed a joint detection method to detect both triggers and arguments (together with their role types) using a structured perceptron model. The system outperformed the best results reported for the ACE 2005 task in the literature, without the use of any external resources. 2.2 Biomedical Event Extraction The task of event extraction has received a large amount of attention from BioNLP researchers in recent years. Interest in this task was largely initiated by the BioNLP 2009 ST, and has been sustained through the organisation of further STs in 2011 and 2013. The STs consist of a nu"
C14-1214,P10-1081,0,0.735232,"mber of ways. Apart from the different textual domain, the tasks adopt varying annotation schemes. The exact kinds of annotations provided at training time are also different, as are the evaluation settings. Several variants of the official task setting for the ACE 2005 corpus have been defined. This is partly due to the demanding nature of the official task definition, which requires the detection of events from scratch, including the recognition of named entities participating in events, together with the resolution of coreferences. Alternative task settings (such as Ji and Grishman (2008); Liao and Grishman (2010))) generally simplify the official task definition, e.g., by omitting the requirement to perform coreference resolution. A further issue is that the test data sets for the official task setting have not been made publicly available. As a result of the multiple existing variations of the ACE 2005 task definition that have been employed by different research efforts, direct comparison of our results with those obtained by other state-of-the art systems is problematic. The solution we have chosen is to adopt the same ACE 2005 event extraction task specification that has been adopted in recent res"
C14-1214,P12-1088,0,0.0204545,"e been popular (Grishman et al., 2005; Ahn, 2006). Grishman et al. (2005) proposed a method that sequentially identifies textual spans of arguments, role types, and event triggers. This pipeline approach has been further extended in several subsequent studies. For example, Liao et al. (2010) investigated document-level cross-event consistency using co-occurrence of events and event arguments, while Hong et al. (2011) exploited information gathered from the web to ensure cross-entity consistency. 2 Note that there are also approaches using few or no training data (e.g., (Ji and Grishman, 2008; Lu and Roth, 2012)) for the ACE 2005 task, but they are not so many and we will focus on the supervised learning approaches in this paper. 2271 Li et al. (2013) recently proposed a joint detection method to detect both triggers and arguments (together with their role types) using a structured perceptron model. The system outperformed the best results reported for the ACE 2005 task in the literature, without the use of any external resources. 2.2 Biomedical Event Extraction The task of event extraction has received a large amount of attention from BioNLP researchers in recent years. Interest in this task was lar"
C14-1214,J08-1002,0,0.0961272,"domains, the same general features of events normally hold across domains. An event usually consists of a trigger and arguments (see Figures 1 and 2.) A trigger is typically a verb or a nominalised verb that denotes the presence of the event in the text, while the arguments are usually entities. In general, arguments are assigned semantic roles that characterise their contribution towards the event description. Until now, however, there has been little, if any, effort by researchers working on event extraction in different domains to share ideas and techniques, unlike syntactic tasks (e.g., (Miyao and Tsujii, 2008)) and other information extraction tasks, such as named entity recognition (e.g., (Giuliano et al., 2006)) and relation extraction (e.g., (Qian and Zhou, 2012)). This means that the potential to exploit crossdomain features of events to develop more adaptable event extraction systems is an under-studied area. Consequently, although there is a large number of published studies on event extraction, proposing many different methods, no work has previously been reported that aims to adapt an event extraction method developed for one domain to a new domain. In response to the above, we have investi"
C14-1214,D07-1111,0,0.0272836,"VENT TOTAL results obtained using the approximate span & recursive evaluation method, as recommended by the organisers. The method individually evaluates each complete core event, i.e., event triggers with their Theme and/or Cause role arguments, with relaxed span matching, after nested events have been broken down as explained in Section 3.1. Note that the scores do not count the non-named entities, hedges, and links between arguments, since only core events are considered in the official evaluation. We applied both a deep parser, Enju (Miyao and Tsujii, 2008) and a dependency parser, ksdep (Sagae and Tsujii, 2007) to generate features for the ACE 2005 task, and their bio-adapted versions for the GENIA task. We also employed the GENIA sentence splitter (Sætre et al., 2007) for sentence splitting, and the snowball (Porter2) stemmer4 for stemming. We did not make use of any other external resources, such as dictionaries, since this would hinder direct comparison of the two versions of the system. 4.2 Evaluation on GENIA The “Event Detection” column in Table 2 shows evaluation results of BioEE on GENIA. The effects on performance by including entity-related features, i.e., entity base forms and Brown clust"
C14-1214,W13-2002,0,\N,Missing
C16-1176,E12-1004,0,0.561272,"ikolov et al., 2013) and ivLBL (Mnih and Kavukcuoglu, 2013) has been often employed for the task of detecting hypernymy, since such representation are shared among words. Most models using word embeddings focus on a hypernymy classification task where a model needs to predict whether a given word pair is in hypernymy or not. They take distributional vectors for a pair of a word x and its candidate hypernym y as input, calculate features from these vectors, and predict whether the pair is in hypernymy or not using a classifier like support vector machines (SVMs). For example, the concat model (Baroni et al., 2012) uses the concatenation of hypernymy pair hx, yi, while the diff model (Roller et al., 2014; Weeds et al., 2014; Fu et al., 2015) uses hy − xi. Here, x and y represent word embeddings of x and y, respectively. These classification-based models, however, have not been evaluated on hypernym generation, where a model generates hypernyms for a given word. Less work has been done on hypernym generation using word embeddings (Fu et al., 2015; Tan et al., 2015). Fu et al. (2015) proposed a model of using the projection matrices, each of which projects x to y. They proposed a two-step, pipeline algori"
C16-1176,P05-1014,0,0.198625,"ypernym classification task. 1 Introduction Hypernym-hyponym relations, a.k.a. hypernymy, are important information for several NLP tasks such as question answering and ontology construction. Some manually-constructed semantic resources like WordNet contain hypernymy; however, they have limited coverage. Plenty of studies have been conducted to automatically detect hypernymy, e.g., (Hearst, 1992; Roller et al., 2014; Fu et al., 2015). Hypernymy detection was traditionally often tackled with unsupervised methods using Hearst-style patterns (Hearst, 1992) or distributional inclusion hypothesis (Geffet and Dagan, 2005). These methods treat hypernymy pairs individually. Recent progress in the word representation allows to represent words in a shared low-dimensional vector space, and several models using the distributional word representation or word embeddings have been proposed for hypernymy detection (Roller et al., 2014; Weeds et al., 2014; Turney and Mohammad, 2015; Levy et al., 2015). Such models employ supervised learning. Most of the models focus on a hypernymy classification problem, i.e., whether a given word pair is in hypernymy or not, and they ignore a more practical hypernym generation problem t"
C16-1176,C92-2082,0,0.267061,"of Japanese and English hypernym generation and showed a significant improvement over an existing pipeline model. Our model also compared favorably to existing distributed hypernym detection models on the English hypernym classification task. 1 Introduction Hypernym-hyponym relations, a.k.a. hypernymy, are important information for several NLP tasks such as question answering and ontology construction. Some manually-constructed semantic resources like WordNet contain hypernymy; however, they have limited coverage. Plenty of studies have been conducted to automatically detect hypernymy, e.g., (Hearst, 1992; Roller et al., 2014; Fu et al., 2015). Hypernymy detection was traditionally often tackled with unsupervised methods using Hearst-style patterns (Hearst, 1992) or distributional inclusion hypothesis (Geffet and Dagan, 2005). These methods treat hypernymy pairs individually. Recent progress in the word representation allows to represent words in a shared low-dimensional vector space, and several models using the distributional word representation or word embeddings have been proposed for hypernymy detection (Roller et al., 2014; Weeds et al., 2014; Turney and Mohammad, 2015; Levy et al., 2015"
C16-1176,D10-1108,0,0.125336,"our model on hypernym generation tasks in Japanese and English, as well as a well-studied hypernymy classification task in English. Our joint learning model shows a significant improvement over a pipeline learning model (Fu et al., 2015) on the hypernym generation tasks. As for the hypernymy classification, our model showed a comparable performance to the state-of-the-art hypernymy classification model (Levy et al., 2015). 2 Related Work In the task of detecting hypernym, traditional approaches focused on Hearst-style lexical patterns that indicate hypernymy (Hearst, 1992; Snow et al., 2005; Kozareva and Hovy, 2010). For instance, from a sentence ... works by such authors as Shakespeare ..., an “is-a” pair between Shakespeare and author can be detected by using a pattern that a word A is a hypernym of another word B when A and B are linked by such A as B. These methods typically show high precision but suffer from low recall because many hypernymy pairs are not explicitly mentioned in texts as such patterns. To overcome the problems of the lack of explicit hypernymy mentions, several other traditional unsupervised methods are proposed based on distributional inclusion hypothesis. This hypothesis states t"
C16-1176,N15-1098,0,0.529952,"g., (Hearst, 1992; Roller et al., 2014; Fu et al., 2015). Hypernymy detection was traditionally often tackled with unsupervised methods using Hearst-style patterns (Hearst, 1992) or distributional inclusion hypothesis (Geffet and Dagan, 2005). These methods treat hypernymy pairs individually. Recent progress in the word representation allows to represent words in a shared low-dimensional vector space, and several models using the distributional word representation or word embeddings have been proposed for hypernymy detection (Roller et al., 2014; Weeds et al., 2014; Turney and Mohammad, 2015; Levy et al., 2015). Such models employ supervised learning. Most of the models focus on a hypernymy classification problem, i.e., whether a given word pair is in hypernymy or not, and they ignore a more practical hypernym generation problem to generate hypernyms for a given word. Few studies have examined hypernym generation using word embeddings (Fu et al., 2015; Tan et al., 2015). Fu et al. (2015) proposed a two-step, pipeline model that partitions hypernymy pairs into several clusters and learns a projection matrix between words in a pair for each cluster separately. The projection matrix projects the embedd"
C16-1176,C14-1097,0,0.391591,"d English hypernym generation and showed a significant improvement over an existing pipeline model. Our model also compared favorably to existing distributed hypernym detection models on the English hypernym classification task. 1 Introduction Hypernym-hyponym relations, a.k.a. hypernymy, are important information for several NLP tasks such as question answering and ontology construction. Some manually-constructed semantic resources like WordNet contain hypernymy; however, they have limited coverage. Plenty of studies have been conducted to automatically detect hypernymy, e.g., (Hearst, 1992; Roller et al., 2014; Fu et al., 2015). Hypernymy detection was traditionally often tackled with unsupervised methods using Hearst-style patterns (Hearst, 1992) or distributional inclusion hypothesis (Geffet and Dagan, 2005). These methods treat hypernymy pairs individually. Recent progress in the word representation allows to represent words in a shared low-dimensional vector space, and several models using the distributional word representation or word embeddings have been proposed for hypernymy detection (Roller et al., 2014; Weeds et al., 2014; Turney and Mohammad, 2015; Levy et al., 2015). Such models employ"
C16-1176,sumida-etal-2008-boosting,0,0.028566,"e Yahoo Answers (Yahoo Chiebukuro)1 . As for English, we used a pretrained Google News word embeddings2 (Mikolov et al., 2013), which has shown high performance in several word similarity tasks. Table 1 summarizes the settings in learning word embeddings. We use the words in the word embedding as our vocabularies. To obtain supervision for training hypernymy, we used ALAGIN typed hierarchies for Japanese3 , and the data by Baroni et al. (2012) for English. The statistics of the data are shown in Table 2. Word pairs in ALAGIN were made by automatically extracting word hierarchy from Wikipedia (Sumida et al., 2008), selecting the top-level pairs, and manually cleaning the selected pairs. Since this data deal with not only words but phrases, we selected hypernymy pairs that include only words and split the pairs into training, validation, and test pairs. Word pairs of Baroni’s data were extracted from WordNet. While the data originally include 1,385 positives and 1,385 negatives that are from a random permutation of positive pairs, we used only positive pairs for training because our model generates negative pairs during training. 4.2 Task and evaluation settings We optimized our model parameters with Ad"
C16-1176,S15-2155,0,0.113099,"Missing"
C16-1176,C14-1212,0,0.490949,"conducted to automatically detect hypernymy, e.g., (Hearst, 1992; Roller et al., 2014; Fu et al., 2015). Hypernymy detection was traditionally often tackled with unsupervised methods using Hearst-style patterns (Hearst, 1992) or distributional inclusion hypothesis (Geffet and Dagan, 2005). These methods treat hypernymy pairs individually. Recent progress in the word representation allows to represent words in a shared low-dimensional vector space, and several models using the distributional word representation or word embeddings have been proposed for hypernymy detection (Roller et al., 2014; Weeds et al., 2014; Turney and Mohammad, 2015; Levy et al., 2015). Such models employ supervised learning. Most of the models focus on a hypernymy classification problem, i.e., whether a given word pair is in hypernymy or not, and they ignore a more practical hypernym generation problem to generate hypernyms for a given word. Few studies have examined hypernym generation using word embeddings (Fu et al., 2015; Tan et al., 2015). Fu et al. (2015) proposed a two-step, pipeline model that partitions hypernymy pairs into several clusters and learns a projection matrix between words in a pair for each cluster separa"
D09-1013,D07-1024,0,0.440421,"ume that the feature space is same, and that the labels may be different in only some examples, while most of DA methods assume that the labels are the same, and that the feature space is different. Among the methods, we use adaptive SVM (aSVM) (Yang et al., 2007), singular value decomposition (SVD) based alternating structure optimization (SVDASO) (Ando et al., 2005), and transfer AdaBoost (TrAdaBoost) (Dai et al., 2007) to compare with SVM-CW. We do not use semi-supervised learning (SSL) methods, because it would be considerably costly to generate enough clean unlabeled data needed for SSL (Erkan et al., 2007). aSVM is seen as a promising DA method among several modifications of SVM including SVM-CW. aSVM tries to find a model that is close to the one made from other classification problems. SVDASO is one of the most successful SSL, DA, or multi-task learning methods in NLP. The method tries to find an additional useful feature space by solving auxiliary problems that are close to the target problem. With well-designed auxiliary problems, the method has been applied to text classification, text chunking, and word sense disambiguation (Ando, 2006). The method was reported to perform better than or c"
D09-1013,W06-2911,0,0.0115377,"enough clean unlabeled data needed for SSL (Erkan et al., 2007). aSVM is seen as a promising DA method among several modifications of SVM including SVM-CW. aSVM tries to find a model that is close to the one made from other classification problems. SVDASO is one of the most successful SSL, DA, or multi-task learning methods in NLP. The method tries to find an additional useful feature space by solving auxiliary problems that are close to the target problem. With well-designed auxiliary problems, the method has been applied to text classification, text chunking, and word sense disambiguation (Ando, 2006). The method was reported to perform better than or comparable to the best state-of-the-art systems in all of these tasks. TrAdaBoost was proposed as an ITL method. In training, the method reduces the effect of incompatible examples by decreasing their weights, and thereby tries to use useful examples from source corpora. The method has been applied to text classification, and the reported performance was better than SVM and transductive SVM (Dai et al., 2007). Related Works While sentence-based, pair-wise PPI extraction was initially tackled by using simple methods based on co-occurrences, la"
D09-1013,P08-1006,1,0.760868,"es (PAS) from Enju, and by using the dependency trees from KSDEP. 3.1.1 3.1 Feature Vector Bag-of-Words (BOW) Features The BOW feature includes the lemma form of a word, its relative position to the target pair of proteins (Before, Middle, After), and its frequency in the target sentence. BOW features form the BOW kernel in the original kernel method. BOW features for the pair in Figure 2 are shown in Figure 4. We propose a feature vector with three types of features, corresponding to the three different kernels, which were each combined with the two parsers: the Enju 2.3.0, and KSDEP beta 1 (Miyao et al., 2008); this feature vector is used because the kernels with these parsers were shown to be effective for PPI extraction by Miwa et al. (2008), and because it is important to start from a good performance single corpus system. Both parsers were retrained using the GENIA Treebank corpus provided by Kim et al. (2003). By using our linear feature vector, we can perform calculations faster by using fast linear classifiers like L2-SVM, and we also obtain a more accurate extraction, than by using the original kernel method. Figure 3 summarizes the way in which the feature vector is constructed. The system"
D09-1013,W02-1001,0,\N,Missing
D13-1137,P13-1088,0,0.220172,"that both phrase categories and task-specific weighting significantly improve the prediction accuracy of the model. We also show that averaging the model parameters is effective in stabilizing the learning and improves generalization capacity. The proposed model marks scores competitive with state-of-the-art RNN-based models. 1 Introduction Recursive Neural Network (RNN) models are promising deep learning models which have been applied to a variety of natural language processing (NLP) tasks, such as sentiment classification, compound similarity, relation classification and syntactic parsing (Hermann and Blunsom, 2013; Socher et al., 2012; Socher et al., 2013). RNN models can represent phrases of arbitrary length in a vector space of a fixed dimension. Most of them use minimal syntactic information (Socher et al., 2012). Recently, Hermann and Blunsom (2013) proposed a method for leveraging syntactic information, namely CCG combinatory operators, to guide composition of phrases in RNN models. While their models were successfully applied to binary sentiment classification and compound similarity tasks, there are questions yet to be answered, e.g., whether such enhancement is beneficial in other NLP tasks as"
D13-1137,J08-1002,0,0.0106005,"o add W add to θ: θ = (We , Wlr , b, W label , W add , blabel ). The gradient of J(θ) ∂J(θ) ∑ ∂E(x) = + λθ ∂θ ∂θ x is efficiently computed via backpropagation through structure (Goller and K¨uchler, 1996). To minimize J(θ), we use batch L-BFGS1 (Hermann and Blunsom, 2013; Socher et al., 2012). 2.4 Averaging We use averaged model parameters 1 ∑ θt T +1 T θ= t=0 at test time, where θt is the vector of model parameters after t iterations of the L-BFGS optimization. Our preliminary experimental results suggest that averaging θ except We works well. 3 Experimental Settings We used the Enju parser (Miyao and Tsujii, 2008) for syntactic parsing. We used 13 phrase categories given by Enju. 3.1 Task: Semantic Relation Classification We evaluated our model on a semantic relation classification task: SemEval 2010 Task 8 (Hendrickx et al., 2010). Following Socher et al. (2012), we regarded the task as a 19-class classification problem. There are 8,000 samples for training, and 2,717 for 1 We used libLBFGS provided at http://www. chokkan.org/software/liblbfgs/. 1374 Figure 2: Classifying the relation between two entities. test. For the validation set, we randomly sampled 2,182 samples from the training data. To predi"
D13-1137,S10-1057,0,0.265915,"Missing"
D13-1137,D12-1110,0,0.746211,"s and task-specific weighting significantly improve the prediction accuracy of the model. We also show that averaging the model parameters is effective in stabilizing the learning and improves generalization capacity. The proposed model marks scores competitive with state-of-the-art RNN-based models. 1 Introduction Recursive Neural Network (RNN) models are promising deep learning models which have been applied to a variety of natural language processing (NLP) tasks, such as sentiment classification, compound similarity, relation classification and syntactic parsing (Hermann and Blunsom, 2013; Socher et al., 2012; Socher et al., 2013). RNN models can represent phrases of arbitrary length in a vector space of a fixed dimension. Most of them use minimal syntactic information (Socher et al., 2012). Recently, Hermann and Blunsom (2013) proposed a method for leveraging syntactic information, namely CCG combinatory operators, to guide composition of phrases in RNN models. While their models were successfully applied to binary sentiment classification and compound similarity tasks, there are questions yet to be answered, e.g., whether such enhancement is beneficial in other NLP tasks as well, and whether a s"
D13-1137,P13-1045,0,0.0558948,"eighting significantly improve the prediction accuracy of the model. We also show that averaging the model parameters is effective in stabilizing the learning and improves generalization capacity. The proposed model marks scores competitive with state-of-the-art RNN-based models. 1 Introduction Recursive Neural Network (RNN) models are promising deep learning models which have been applied to a variety of natural language processing (NLP) tasks, such as sentiment classification, compound similarity, relation classification and syntactic parsing (Hermann and Blunsom, 2013; Socher et al., 2012; Socher et al., 2013). RNN models can represent phrases of arbitrary length in a vector space of a fixed dimension. Most of them use minimal syntactic information (Socher et al., 2012). Recently, Hermann and Blunsom (2013) proposed a method for leveraging syntactic information, namely CCG combinatory operators, to guide composition of phrases in RNN models. While their models were successfully applied to binary sentiment classification and compound similarity tasks, there are questions yet to be answered, e.g., whether such enhancement is beneficial in other NLP tasks as well, and whether a similar improvement can"
D13-1137,P06-1104,0,0.0468267,"irectly connect features on any other nodes to the softmax classifier. In this work, we used three such internal features: two vector representations of target entities and one averaged vector representation of words between the entities2 . 3.2 Weights on Phrases We tuned the weight αl (or αr ) introduced in Section 2.2 for this particular task. There are two factors: syntactic heads and syntactic path between target entities. Our model puts a weight β ∈ [0.5, 1] on head phrases, and 1 − β on the others. For relation classification tasks, syntactic paths between target entities are important (Zhang et al., 2006), so our model also puts another weight γ ∈ [0.5, 1] on phrases on the path, and 1 − γ on the others. When both child nodes are on the path or neither of them on the path, we set γ = 0.5. The two weight factors are summed up and divided by 2 to be the final weights αl and αr to combine the phrases. For exand αr = β+(1−γ) ample, we set αl = (1−β)+γ 2 2 when the right child node is the head and the left child node is on the path. 3.3 Initialization of Model Parameters and Tuning of Hyperparameters We initialized We with 50-dimensional word vectors3 trained with the model of Collobert et 2 Socher"
D13-1137,S10-1006,0,\N,Missing
D14-1163,D10-1115,0,0.605812,"phrases (Mitchell and Lapata, 2010; Blacoe and Lapata, 2012). The obvious limitation with these simple approaches is that information about word order and syntactic relations is lost. To incorporate syntactic information into composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hermann and Blunsom, 2013; Socher et al., 2013a). More recently, syntactic dependency-based 1545 compositional models have been proposed (Paperno et al., 2014; Socher et al., 2014; Tsubaki et al., 2013). One of the advantages of these models is that they are less restricted by word order. Among these, Tsubaki et al. (2013) introduced a novel compositional NNLM mainly focusing on verb-object dependencies and achieved state-of-the-art performance for the task of measuring the semantic similarity between subjectverb-object phrases. 3 PAS"
D14-1163,D12-1050,0,0.219803,"nsional vector space (Bengio et al., 2003; Collobert et al., 2011). Recently, Mikolov et al. (2013b) and Mnih and Kavukcuoglu (2013) proposed highly scalable models to learn high-dimensional word vectors. Levy and Goldberg (2014) extended the model of Mikolov et al. (2013b) by treating syntactic dependencies as contexts. Mitchell and Lapata (2008) investigated a variety of compositional operators to combine word vectors into phrasal representations. Among these operators, simple element-wise addition and multiplication are now widely used to represent short phrases (Mitchell and Lapata, 2010; Blacoe and Lapata, 2012). The obvious limitation with these simple approaches is that information about word order and syntactic relations is lost. To incorporate syntactic information into composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011"
D14-1163,D08-1094,0,0.231181,"Missing"
D14-1163,W13-3203,0,0.0157278,"s jointly while training. 2 Related Work There is a large body of work on how to represent the meaning of a word in a vector space. Distributional approaches assume that the meaning of a word is determined by the contexts in which it appears (Firth, 1957). The context of a word is often defined as the words appearing in a window of fixed-length (bag-of-words) and a simple approach is to treat the co-occurrence statistics of a word w as a vector representation for w (Mitchell and Lapata, 2008; Mitchell and Lapata, 2010); alternatively, dependencies between words can be used to define contexts (Goyal et al., 2013; Erk and Pad´o, 2008; Thater et al., 2010). In contrast to distributional representations, NNLMs represent words in a low-dimensional vector space (Bengio et al., 2003; Collobert et al., 2011). Recently, Mikolov et al. (2013b) and Mnih and Kavukcuoglu (2013) proposed highly scalable models to learn high-dimensional word vectors. Levy and Goldberg (2014) extended the model of Mikolov et al. (2013b) by treating syntactic dependencies as contexts. Mitchell and Lapata (2008) investigated a variety of compositional operators to combine word vectors into phrasal representations. Among these operato"
D14-1163,D11-1129,0,0.0465968,"Missing"
D14-1163,D13-1137,1,0.512175,"The obvious limitation with these simple approaches is that information about word order and syntactic relations is lost. To incorporate syntactic information into composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hermann and Blunsom, 2013; Socher et al., 2013a). More recently, syntactic dependency-based 1545 compositional models have been proposed (Paperno et al., 2014; Socher et al., 2014; Tsubaki et al., 2013). One of the advantages of these models is that they are less restricted by word order. Among these, Tsubaki et al. (2013) introduced a novel compositional NNLM mainly focusing on verb-object dependencies and achieved state-of-the-art performance for the task of measuring the semantic similarity between subjectverb-object phrases. 3 PAS-CLBLM: A Compositional Log-Bilinear Language Model Using"
D14-1163,P13-1088,0,0.278818,"ith these simple approaches is that information about word order and syntactic relations is lost. To incorporate syntactic information into composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hermann and Blunsom, 2013; Socher et al., 2013a). More recently, syntactic dependency-based 1545 compositional models have been proposed (Paperno et al., 2014; Socher et al., 2014; Tsubaki et al., 2013). One of the advantages of these models is that they are less restricted by word order. Among these, Tsubaki et al. (2013) introduced a novel compositional NNLM mainly focusing on verb-object dependencies and achieved state-of-the-art performance for the task of measuring the semantic similarity between subjectverb-object phrases. 3 PAS-CLBLM: A Compositional Log-Bilinear Language Model Using Predicate-Argument Structur"
D14-1163,P12-1092,0,0.347535,"ationship to previous work. If we omit the the category-specific weight vectors hci in Eq. (1), our model is similar to the CBOW model in Mikolov et al. (2013a). CBOW predicts a target word given its surrounding bag-of-words context, while our model uses its PAS-based context. To incorporate the PAS information in our model more efficiently, we use category-specific weight vectors. Similarly, the vLBL model of Mnih and Kavukcuoglu (2013) uses different weight vectors depending on the position relative to the target word. As with previous neural network language models (Collobert et al., 2011; Huang et al., 2012), our model and vLBL can use weight matrices rather than weight vectors. However, as discussed by Mnih and Teh (2012), using weight vectors makes the training significantly faster than using weight matrices. Despite the simple formulation of the element-wise operations, the categoryspecific weight vectors efficiently propagate PASbased context information as explained next. 3.2.2 Training Word Vectors To train the PAS-LBLM, we use a scoring function to evaluate how well the target word wt fits the given context: s(wt , p(wt )) = v˜(wt )T p(wt ), (4) where v˜(wt ) ∈ Rd×1 is the scoring weight v"
D14-1163,D13-1166,0,0.282877,"Missing"
D14-1163,W13-3513,0,0.0612916,"nexpectedly high scores for these three tasks. Previously these kinds of models (Mikolov et al., 2013b; Mnih and Kavukcuoglu, 2013) have mainly been evaluated for word analogy tasks and, to date, there has been no work using these word vectors for the task of measuring the semantic similarity between phrases. However, this experimental result suggests that word2vec can serve as a strong baseline for these kinds of tasks, in addition to word analogy tasks. In Table 3, BL, HB, KS, and K denote the work of Blacoe and Lapata (2012), Hermann and Blunsom (2013), Kartsaklis and Sadrzadeh (2013), and Kartsaklis et al. (2013) respectively. Among these, 5 1550 https://code.google.com/p/word2vec/ Model PAS-CLBLM (Addl ) PAS-CLBLM (Addnl ) PAS-CLBLM (Waddl ) PAS-CLBLM (Waddnl ) PAS-LBLM word2vec Grefenstette and Sadrzadeh (2011) Tsubaki et al. (2013) Van de Cruys et al. (2013) Human agreement Corpus BNC BNC BNC ukWaC ukWaC Averaged SVO-SVO SVO-V 0.29 0.34 0.27 0.32 0.25 0.26 0.42 0.50 0.21 0.06 0.12 0.32 n/a n/a n/a 0.47 n/a n/a 0.75 Non-averaged SVO-SVO SVO-V 0.24 0.28 0.24 0.28 0.21 0.23 0.34 0.41 0.18 0.08 0.12 0.28 0.21 n/a n/a n/a 0.32 0.37 0.62 Table 4: Spearman’s rank correlation scores ρ for the SVO task. Ave"
D14-1163,P14-2050,0,0.418227,"o, 3-7-1 Hongo, Bunkyo-ku, Tokyo, Japan {hassy,pontus,tsuruoka}@logos.t.u-tokyo.ac.jp ‡Toyota Technological Institute, 2-12-1 Hisakata, Tempaku-ku, Nagoya, Japan makoto-miwa@toyota-ti.ac.jp Abstract Recently, the main focus of research on vector space representation is shifting from word representations to phrase representations (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Combining the ideas of NNLMs and semantic composition, Tsubaki et al. (2013) introduced a novel NNLM incorporating verb-object dependencies. More recently, Levy and Goldberg (2014) presented a NNLM that integrated syntactic dependencies. However, to the best of our knowledge, there is no previous work on integrating a variety of syntactic and semantic dependencies into NNLMs in order to learn composition functions as well as word representations. The following question thus arises naturally: We introduce a novel compositional language model that works on PredicateArgument Structures (PASs). Our model jointly learns word representations and their composition functions using bagof-words and dependency-based contexts. Unlike previous word-sequencebased models, our PAS-base"
D14-1163,P08-1028,0,0.788883,"ver, the proposed model does not require any pre-trained word vectors produced by external models, but rather induces word vectors jointly while training. 2 Related Work There is a large body of work on how to represent the meaning of a word in a vector space. Distributional approaches assume that the meaning of a word is determined by the contexts in which it appears (Firth, 1957). The context of a word is often defined as the words appearing in a window of fixed-length (bag-of-words) and a simple approach is to treat the co-occurrence statistics of a word w as a vector representation for w (Mitchell and Lapata, 2008; Mitchell and Lapata, 2010); alternatively, dependencies between words can be used to define contexts (Goyal et al., 2013; Erk and Pad´o, 2008; Thater et al., 2010). In contrast to distributional representations, NNLMs represent words in a low-dimensional vector space (Bengio et al., 2003; Collobert et al., 2011). Recently, Mikolov et al. (2013b) and Mnih and Kavukcuoglu (2013) proposed highly scalable models to learn high-dimensional word vectors. Levy and Goldberg (2014) extended the model of Mikolov et al. (2013b) by treating syntactic dependencies as contexts. Mitchell and Lapata (2008) i"
D14-1163,J08-1002,0,0.0501574,"sis of our model. We then introduce a Log-Bilinear Language Model using Predicate-Argument Structures (PAS-LBLM) to learn word representations using both bag-ofwords and dependency-based contexts. Finally, we propose integrating compositions of words into the model. Figure 1 (b) shows the overview of the proposed model. 3.1 Predicate-Argument Structures Due to advances in deep parsing technologies, syntactic parsers that can produce predicateargument structures are becoming accurate and fast enough to be used for practical applications. In this work, we use the probabilistic HPSG parser Enju (Miyao and Tsujii, 2008) to obtain the predicate-argument structures of individual sentences. In its grammar, each word in a sentence is treated as a predicate of a certain category with zero or more arguments. Table 1 shows some exCategory adj arg1 noun arg1 verb arg12 prep arg12 predicate heavy car cause at arg1 rain accident rain eat arg2 accident restaurant Table 1: Examples of predicates of different categories from the grammar of the Enju parser. arg1 and arg2 denote the first and second arguments. amples of predicates of different categories.1 For example, a predicate of the category verb arg12 expresses a ver"
D14-1163,P14-1009,0,0.0244756,"o composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hermann and Blunsom, 2013; Socher et al., 2013a). More recently, syntactic dependency-based 1545 compositional models have been proposed (Paperno et al., 2014; Socher et al., 2014; Tsubaki et al., 2013). One of the advantages of these models is that they are less restricted by word order. Among these, Tsubaki et al. (2013) introduced a novel compositional NNLM mainly focusing on verb-object dependencies and achieved state-of-the-art performance for the task of measuring the semantic similarity between subjectverb-object phrases. 3 PAS-CLBLM: A Compositional Log-Bilinear Language Model Using Predicate-Argument Structures In some recent studies on representing words as vectors, word vectors are learned by solving word prediction tasks (Mikolov et al."
D14-1163,D12-1110,0,0.862473,"presentations and Composition Functions Using Predicate-Argument Structures Kazuma Hashimoto† , Pontus Stenetorp† , Makoto Miwa‡ , and Yoshimasa Tsuruoka† †The University of Tokyo, 3-7-1 Hongo, Bunkyo-ku, Tokyo, Japan {hassy,pontus,tsuruoka}@logos.t.u-tokyo.ac.jp ‡Toyota Technological Institute, 2-12-1 Hisakata, Tempaku-ku, Nagoya, Japan makoto-miwa@toyota-ti.ac.jp Abstract Recently, the main focus of research on vector space representation is shifting from word representations to phrase representations (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Combining the ideas of NNLMs and semantic composition, Tsubaki et al. (2013) introduced a novel NNLM incorporating verb-object dependencies. More recently, Levy and Goldberg (2014) presented a NNLM that integrated syntactic dependencies. However, to the best of our knowledge, there is no previous work on integrating a variety of syntactic and semantic dependencies into NNLMs in order to learn composition functions as well as word representations. The following question thus arises naturally: We introduce a novel compositional language model that works on PredicateArgument Structures (PASs)."
D14-1163,P13-1045,0,0.255766,"ated a variety of compositional operators to combine word vectors into phrasal representations. Among these operators, simple element-wise addition and multiplication are now widely used to represent short phrases (Mitchell and Lapata, 2010; Blacoe and Lapata, 2012). The obvious limitation with these simple approaches is that information about word order and syntactic relations is lost. To incorporate syntactic information into composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hermann and Blunsom, 2013; Socher et al., 2013a). More recently, syntactic dependency-based 1545 compositional models have been proposed (Paperno et al., 2014; Socher et al., 2014; Tsubaki et al., 2013). One of the advantages of these models is that they are less restricted by word order. Among these, Tsubaki et al. (2013) in"
D14-1163,D13-1170,0,0.21026,"ated a variety of compositional operators to combine word vectors into phrasal representations. Among these operators, simple element-wise addition and multiplication are now widely used to represent short phrases (Mitchell and Lapata, 2010; Blacoe and Lapata, 2012). The obvious limitation with these simple approaches is that information about word order and syntactic relations is lost. To incorporate syntactic information into composition functions, a variety of compositional models have been proposed. These include recursive neural networks using phrase-structure trees (Socher et al., 2012; Socher et al., 2013b) and models in which words have a specific form of parameters according to their syntactic roles and composition functions are syntactically dependent on the relations of input words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hermann and Blunsom, 2013; Socher et al., 2013a). More recently, syntactic dependency-based 1545 compositional models have been proposed (Paperno et al., 2014; Socher et al., 2014; Tsubaki et al., 2013). One of the advantages of these models is that they are less restricted by word order. Among these, Tsubaki et al. (2013) in"
D14-1163,P10-1097,0,0.0689392,"Missing"
D14-1163,D13-1014,0,0.122155,"azuma Hashimoto† , Pontus Stenetorp† , Makoto Miwa‡ , and Yoshimasa Tsuruoka† †The University of Tokyo, 3-7-1 Hongo, Bunkyo-ku, Tokyo, Japan {hassy,pontus,tsuruoka}@logos.t.u-tokyo.ac.jp ‡Toyota Technological Institute, 2-12-1 Hisakata, Tempaku-ku, Nagoya, Japan makoto-miwa@toyota-ti.ac.jp Abstract Recently, the main focus of research on vector space representation is shifting from word representations to phrase representations (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Combining the ideas of NNLMs and semantic composition, Tsubaki et al. (2013) introduced a novel NNLM incorporating verb-object dependencies. More recently, Levy and Goldberg (2014) presented a NNLM that integrated syntactic dependencies. However, to the best of our knowledge, there is no previous work on integrating a variety of syntactic and semantic dependencies into NNLMs in order to learn composition functions as well as word representations. The following question thus arises naturally: We introduce a novel compositional language model that works on PredicateArgument Structures (PASs). Our model jointly learns word representations and their composition functions"
D14-1163,P10-1040,0,0.0613101,"Missing"
D14-1163,N13-1134,0,0.281979,"Missing"
D14-1163,Q14-1017,0,\N,Missing
D14-1200,Q13-1017,0,0.00977115,"lized (lines 4 and 6 in Figure 5) (Freund and Schapire, 1999). s′ (x, y) = s(x, y) + ∆(y, ygold ) (5) Similarly to the scoring function s, the margin ∆ is defined as a decomposable function using 0-1 loss as follows: ∆(y, ygold ) = |x| ∑ i=1 ∆(yi , yigold ) = { ∆(yi , yigold ), 0 if yi = yigold 1 otherwise (6) Secondly, we update the weights w based on a max-violation update rule following Huang et al. (2012) (lines 6-7 in Figure 5). Finally, we employ not only perceptron (Collins, 2002) but also AROW (Mejer and Crammer, 2010; Crammer et al., 2013), AdaGrad (Duchi et al., 2011), and DCD-SSVM (Chang and Yih, 2013) for learning methods (line 7 in Figure 5.) We employ parameter averaging except for DCD-SSVM. AROW and AdaGrad store additional information for covariance and feature counts respectively, and DCDSSVM keeps a working set and performs additional updates in each iteration. Due to space limitations, we refer to the papers for the details of the learning methods. 2.5 Features Here, we explain the local features flocal and the global features fglobal introduced in §2.2. 2.5.1 Local features Our focus is not to exploit useful local features for entities and relations, so we incorporate several featu"
D14-1200,P04-1015,0,0.0218095,"tions, and between entities and relations. Similarly, features f are divided into local features flocal and global features fglobal , and they are defined on its target cell and surrounding contexts. The features will be explained in §2.5. The weights w can also be divided, but they are tuned jointly in learning as shown in §2.4. 2.3 Decoding The scoring function s(x, y, 1, i) in Equation (2) uses all the preceding assignments and does not rely on the Markov assumption, so we cannot employ dynamic programming. We instead employ a beam search to find the best assignment with the highest score (Collins and Roark, 2004). The beam search assigns labels to cells one by one with keeping the top K best assignments when moving from a cell to the next cell, and it returns the best assignment when labels are assigned to all the cells. The pseudo code for decoding with the beam search is shown in Figure 3. 1859 Mrs. Tsutayama is from Kumamoto Prefecture in Japan . Mrs. B-PER ⊥ ⊥ ⊥ ⊥ ⊥ ⊥ ⊥ ⊥ Tsutayama is from Kumamoto Prefecture in Japan . L-PER ⊥ ⊥ ⊥ Live in→ ⊥ Live in→ ⊥ O ⊥ ⊥ ⊥ ⊥ ⊥ ⊥ O ⊥ ⊥ ⊥ ⊥ ⊥ B-LOC ⊥ ⊥ ⊥ ⊥ L-LOC ⊥ Located in→ ⊥ O ⊥ ⊥ U-LOC ⊥ ⊥ Figure 2: The entity and relation table for the example in Figure 1."
D14-1200,W02-1001,0,0.0506515,"2 illustrates an entity and relation table corresponding to an example in Figure 1. We use only the lower triangular part because the table is symmetric, so the number of cells is n(n + 1)/2 when there are n words in a sentence. With this entity and relation table representation, the joint extraction problem can be mapped to a table-filling problem in that labels are assigned to cells in the table. 2.2 Model We tackle the table-filling problem by a historybased structured learning approach that assigns labels to cells one by one. This is mostly the same as the traditional history-based model (Collins, 2002) except for the table representation. Let x be an input table, Y(x) be all possible assignments to the table, and s(x, y) be a scoring function that assesses the assignment of y ∈ Y(x) to x. With these definitions, we define our model to predict the most probable assignment as follows: y∗ = arg max s(x, y) y∈Y(x) (1) This scoring function is a decomposable function, and each decomposed function assesses the assignment of a label to a cell in the table. s(x, y) = |x| ∑ s(x, y, 1, i) (2) i=1 Here, i represents an index of a cell in the table, which will be explained in §2.3.1. The decomposed fun"
D14-1200,W03-0425,0,0.0361941,"nts respectively, and DCDSSVM keeps a working set and performs additional updates in each iteration. Due to space limitations, we refer to the papers for the details of the learning methods. 2.5 Features Here, we explain the local features flocal and the global features fglobal introduced in §2.2. 2.5.1 Local features Our focus is not to exploit useful local features for entities and relations, so we incorporate several features from existing work to realize a reasonable baseline. Table 4 summarizes the local features. Local features for entities (or words) are similar to the features used by Florian et al. (2003), but some features are generalized and extended, and gazetteer features are excluded. For relations (or pairs of words), we employ and extend features in Miwa et al. (2009). 2.5.2 Global features We design global features to represent dependencies among entities and relations. Table 5 summarizes the global features2 . These global features are activated when all the information is available during decoding. We incorporate label dependency features like traditional sequential labeling for entities. Although our model can include other non-local features between entities (Ratinov and Roth, 2009"
D14-1200,N10-1115,0,0.0233446,"YPE I-TYPE L-TYPE O U-TYPE O/S Label on wi+2 B-TYPE I-TYPE L-TYPE O U-TYPE O/S Table 1: Label dependencies from relations to entities. * indicates any type. Label on wi B-*, I-*, O L-*, U-* Label on wi+1 I-*, L-* B-*, U-*, O Relations from/to wi ⊥ * Relations from/to wi ⊥ * Table 2: Label dependencies from entities to relations. and 4(d). We further define two close-first mappings (Figures 4(e) and 4(f)) since entities are easier to find than relations and close relations are easier to find than distant relations. We also investigate dynamic mappings (search orders) with an easy-first policy (Goldberg and Elhadad, 2010). Dynamic mappings are different from the static mappings above, since we reorder the cells before each decoding1 . We evaluate the cells using the local scoring function, and assign indices to the cells so that the cells with higher scores have higher priorities. In addition to this na¨ıve easy-first policy, we define two other dynamic mappings that restricts the reordering by combining the easy-first policy with one of the following two policies: entity-first (all entities are detected before relations) and close-first (closer cells are detected before distant cells) policies. 2.3.2 Label de"
D14-1200,N12-1015,0,0.0794323,"Missing"
D14-1200,C12-1106,0,0.0106306,"our model performs better than the other models. Compared to Table 6, Table 7 also shows that the inclusion of entity boundary detection degrades the performance about 0.09 in F-score. 4 Related Work Search order in structured learning has been studied in several NLP tasks. Left-to-right and rightto-left orderings have been often investigated in sequential labeling tasks (Kudo and Matsumoto, 2001). Easy-first policy was firstly introduced by Goldberg and Elhadad (2010) for dependency parsing, and it was successfully employed in several tasks, such as joint POS tagging and dependency parsing (Ma et al., 2012) and co-reference resolution (Stoyanov and Eisner, 2012). Search order, however, has not been focused in relation extraction tasks. Named entity recognition (Florian et al., 2003; Nadeau and Sekine, 2007) and relation extraction (Zelenko et al., 2003; Miwa et al., 2009) have often been treated as separate tasks, but there are some previous studies that treat entities and relations jointly in learning. Most studies built joint learning models upon individual models for subtasks, such as Integer Linear Programming (ILP) (Roth and Yih, 2007; Yang and Cardie, 2013) and Card-Pyramid Parsing (Kate a"
D14-1200,D10-1095,0,0.0179262,"n as follows so that wrong assignments with small differences from gold assignments are penalized (lines 4 and 6 in Figure 5) (Freund and Schapire, 1999). s′ (x, y) = s(x, y) + ∆(y, ygold ) (5) Similarly to the scoring function s, the margin ∆ is defined as a decomposable function using 0-1 loss as follows: ∆(y, ygold ) = |x| ∑ i=1 ∆(yi , yigold ) = { ∆(yi , yigold ), 0 if yi = yigold 1 otherwise (6) Secondly, we update the weights w based on a max-violation update rule following Huang et al. (2012) (lines 6-7 in Figure 5). Finally, we employ not only perceptron (Collins, 2002) but also AROW (Mejer and Crammer, 2010; Crammer et al., 2013), AdaGrad (Duchi et al., 2011), and DCD-SSVM (Chang and Yih, 2013) for learning methods (line 7 in Figure 5.) We employ parameter averaging except for DCD-SSVM. AROW and AdaGrad store additional information for covariance and feature counts respectively, and DCDSSVM keeps a working set and performs additional updates in each iteration. Due to space limitations, we refer to the papers for the details of the learning methods. 2.5 Features Here, we explain the local features flocal and the global features fglobal introduced in §2.2. 2.5.1 Local features Our focus is not to"
D14-1200,D09-1013,1,0.899074,"rning methods. 2.5 Features Here, we explain the local features flocal and the global features fglobal introduced in §2.2. 2.5.1 Local features Our focus is not to exploit useful local features for entities and relations, so we incorporate several features from existing work to realize a reasonable baseline. Table 4 summarizes the local features. Local features for entities (or words) are similar to the features used by Florian et al. (2003), but some features are generalized and extended, and gazetteer features are excluded. For relations (or pairs of words), we employ and extend features in Miwa et al. (2009). 2.5.2 Global features We design global features to represent dependencies among entities and relations. Table 5 summarizes the global features2 . These global features are activated when all the information is available during decoding. We incorporate label dependency features like traditional sequential labeling for entities. Although our model can include other non-local features between entities (Ratinov and Roth, 2009), we do not include them expecting that global features on entities and relations can cover them. We design three types of global features for relations. These features are"
D14-1200,J08-1002,0,0.0106034,"using a 5-fold cross validation on the training data set, and evaluated the performance on the test set. We prepared a pipeline approach as a baseline. We first trained an entity recognition model using the local and global features, and then trained a relation extraction model using the local features and global features without global “Relation” features in Table 5. We did not employ the global “Relation” features in this baseline since it is common to treat relation extraction as a multi-class classification problem. We extracted features using the results from two syntactic parsers Enju (Miyao and Tsujii, 2008) and LRDEP (Sagae and Tsujii, 2007). We employed feature hashing (Weinberger et al., 2009) and limited the feature space to 224 . The numbers of features greatly varied for categories and targets. They also caused biased predictions that prefer entities to relations in our preliminary experiments. We thus chose to re-scale the features as follows. We normalized local features for each feature category and then for each target. We also normalized global features for each feature category, but we did not normalize them for each target since normalization was impossible during decoding. We instea"
D14-1200,W09-1119,0,0.512157,"ntity and relation structures in a sentence. We then overview our model on the table. We finally explain the decoding, learning, search order, and features in our model. 2.1 Entity and relation table The task we address in this work is the extraction of entities and their relations from a sentence. Entities are typed and may span multiple words. Relations are typed and directed. We use words to represent entities and relations. We assume entities do not overlap. We employ a BILOU (Begin, Inside, Last, Outside, Unit) encoding scheme that has been shown to outperform the traditional BIO scheme (Ratinov and Roth, 2009), and we will show that this scheme induces several label dependencies between words and between words and relations in §2.3.2. A label is assigned to a word according to the relative position to its corresponding entity and the type of the entity. Relations are represented with their types and directions. ⊥ denotes a non-relation pair, and → and ← denote left-to-right and right-to-left relations, respectively. Relations are defined on not entities but words, since entities are not always given when relations are extracted. Relations on entities are mapped to relations on the last words of the"
D14-1200,W10-2924,0,0.426241,"ticipating entity Relation label and the label and word of its participating entity Table 5: Global features. for the test set evaluation, and show the performance on the test data set. 3.1 Evaluation settings We used an entity and relation recognition corpus by Roth and Yih (2004)3 . The corpus defines four named entity types Location, Organization, Person, and Other and five relation types Kill, Live In, Located In, OrgBased In and Work For. All the entities were words in the original corpus because all the spaces in entities were replaced with slashes. Previous systems (Roth and Yih, 2007; Kate and Mooney, 2010) used these word 3 conll04.corp at http://cogcomp.cs.illinois. edu/page/resource_view/43 boundaries as they were, treated the boundaries as given, and focused the entity classification problem alone. Differently from such systems, we recovered these spaces by replacing these slashes with spaces to evaluate the entity boundary detection performance on this corpus. Due to this replacement and the inclusion of the boundary detection problem, our task is more challenging than the original task, and our results are not comparable with those by the previous systems. The corpus contains 1,441 sentenc"
D14-1200,W04-2401,0,0.367586,"le) Combinations of two relation labels and the shared word Relation shortest path features between non-shared words, augmented by a combination of relation labels and the shared word Combinations of three relation labels that make a cycle Combinations of two relation labels that cross each other Relation label and the label of its participating entity Relation label and the label and word of its participating entity Table 5: Global features. for the test set evaluation, and show the performance on the test data set. 3.1 Evaluation settings We used an entity and relation recognition corpus by Roth and Yih (2004)3 . The corpus defines four named entity types Location, Organization, Person, and Other and five relation types Kill, Live In, Located In, OrgBased In and Work For. All the entities were words in the original corpus because all the spaces in entities were replaced with slashes. Previous systems (Roth and Yih, 2007; Kate and Mooney, 2010) used these word 3 conll04.corp at http://cogcomp.cs.illinois. edu/page/resource_view/43 boundaries as they were, treated the boundaries as given, and focused the entity classification problem alone. Differently from such systems, we recovered these spaces by"
D14-1200,N01-1025,0,0.0142206,"t was different from theirs since their splits were not available. We employed the default parameter setting in §3.2 for this comparison. Table 7 shows the evaluation results. Although we cannot directly compare the results, our model performs better than the other models. Compared to Table 6, Table 7 also shows that the inclusion of entity boundary detection degrades the performance about 0.09 in F-score. 4 Related Work Search order in structured learning has been studied in several NLP tasks. Left-to-right and rightto-left orderings have been often investigated in sequential labeling tasks (Kudo and Matsumoto, 2001). Easy-first policy was firstly introduced by Goldberg and Elhadad (2010) for dependency parsing, and it was successfully employed in several tasks, such as joint POS tagging and dependency parsing (Ma et al., 2012) and co-reference resolution (Stoyanov and Eisner, 2012). Search order, however, has not been focused in relation extraction tasks. Named entity recognition (Florian et al., 2003; Nadeau and Sekine, 2007) and relation extraction (Zelenko et al., 2003; Miwa et al., 2009) have often been treated as separate tasks, but there are some previous studies that treat entities and relations j"
D14-1200,D07-1111,0,0.0302239,"the training data set, and evaluated the performance on the test set. We prepared a pipeline approach as a baseline. We first trained an entity recognition model using the local and global features, and then trained a relation extraction model using the local features and global features without global “Relation” features in Table 5. We did not employ the global “Relation” features in this baseline since it is common to treat relation extraction as a multi-class classification problem. We extracted features using the results from two syntactic parsers Enju (Miyao and Tsujii, 2008) and LRDEP (Sagae and Tsujii, 2007). We employed feature hashing (Weinberger et al., 2009) and limited the feature space to 224 . The numbers of features greatly varied for categories and targets. They also caused biased predictions that prefer entities to relations in our preliminary experiments. We thus chose to re-scale the features as follows. We normalized local features for each feature category and then for each target. We also normalized global features for each feature category, but we did not normalize them for each target since normalization was impossible during decoding. We instead scaled the global features, and t"
D14-1200,C12-1154,0,0.0157229,"ls. Compared to Table 6, Table 7 also shows that the inclusion of entity boundary detection degrades the performance about 0.09 in F-score. 4 Related Work Search order in structured learning has been studied in several NLP tasks. Left-to-right and rightto-left orderings have been often investigated in sequential labeling tasks (Kudo and Matsumoto, 2001). Easy-first policy was firstly introduced by Goldberg and Elhadad (2010) for dependency parsing, and it was successfully employed in several tasks, such as joint POS tagging and dependency parsing (Ma et al., 2012) and co-reference resolution (Stoyanov and Eisner, 2012). Search order, however, has not been focused in relation extraction tasks. Named entity recognition (Florian et al., 2003; Nadeau and Sekine, 2007) and relation extraction (Zelenko et al., 2003; Miwa et al., 2009) have often been treated as separate tasks, but there are some previous studies that treat entities and relations jointly in learning. Most studies built joint learning models upon individual models for subtasks, such as Integer Linear Programming (ILP) (Roth and Yih, 2007; Yang and Cardie, 2013) and Card-Pyramid Parsing (Kate and Mooney, 2010). Our approach does not require such ind"
D14-1200,P13-1161,0,0.0431915,"in Figure 1. For dependencies between subtasks, a Live in relation requires PER and LOC entities, and vice versa. For in-subtask dependencies, the Live in relation between “Mrs. Tsutayama” and “Japan” can be inferred from the two other relations. Figure 1 also shows that the task has a flexible graph structure. This structure usually does not cover all the words in a sentence differently from other natural language processing (NLP) tasks such as part-of-speech (POS) tagging and dependency parsing, so local constraints are considered to be more important in the task. Joint learning approaches (Yang and Cardie, 2013; Singh et al., 2013) incorporate these dependencies and local constraints in their models; however most approaches are time-consuming and employ complex structures consisting of multiple models. Li and Ji (2014) recently proposed a history-based structured learning approach that is simpler and more computationally efficient than other approaches. While this approach is promising, it still has a complexity in search and restricts the search order partly due to its semi-Markov representation, and thus the potential of the historybased learning is not fully investigated. In this paper, we introd"
D14-1200,C10-2160,0,0.403646,"2007) and relation extraction (Zelenko et al., 2003; Miwa et al., 2009) have often been treated as separate tasks, but there are some previous studies that treat entities and relations jointly in learning. Most studies built joint learning models upon individual models for subtasks, such as Integer Linear Programming (ILP) (Roth and Yih, 2007; Yang and Cardie, 2013) and Card-Pyramid Parsing (Kate and Mooney, 2010). Our approach does not require such individual models, and it also can detect entity boundaries that these approaches except for Yang and Cardie (2013) did not treat. Other studies (Yu and Lam, 2010; Singh et al., 2013) built global probabilistic graphical models. They need to compute distributions over variables, but our approach does not. Li and Ji (2014) proposed an approach to jointly find entities and relations. They incorporated a semi-Markov chain in representing entities and they defined two actions during search, but our approach does not employ such representation and actions, and thus it is more simple and flexible to investigate search orders. 5 Conclusions In this paper, we proposed a history-based structured learning approach that jointly detects enti1866 Parameter Perceptr"
D14-1200,P14-1038,0,\N,Missing
D18-1309,W07-1009,0,0.816369,"s. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a specified maximum size. The model represents each region using the outputs of bidirectional long short-term memory (LSTM) by combining the boundary representation of a region and inside representation that simply treats all the tokens in a region equally by taking the average of LSTM outputs corresponding to tokens inside the region. It then"
D18-1309,W16-6320,0,0.0630833,"Missing"
D18-1309,W16-2922,0,0.334564,"al LSTM layer. The model enumerates all possible regions or spans that can include all the nested entities. It then represent the regions by using the outputs of the LSTM layer and detect the entities from the regions. The number of possible regions depend on the predefined maximum size. In this section, we describe the architecture of our neural exhaustive model in detail, which is summarized in Figure 1. 2.1 Word Representation We represent each word by concatenating word embeddings and character-based word representations. Pre-trained word embeddings are used to initialize word embeddings (Chiu et al., 2016). For the character-based word representations, we encode the character-level information of each word following the successes of Ma and Hovy (2016) and Lample et al. (2016) that utilized character embeddings for the flat NER task. The embedding of each character in a word is randomly initialized. We feed the sequence of character embeddings comprising a word to a bidirectional LSTM layer and concatenate the forward and backward output representations to obtain the word representations. 2.2 Exhaustive Combination using LSTM Given an input sentence sequence X = {x1 , x2 , ...xn }, where xi deno"
D18-1309,E99-1043,0,0.161058,"Missing"
D18-1309,P16-2011,0,0.0422977,"ult because an individual token can be included in several entities and defining a label for each token can be difficult. For example, in the following phrase from the GENIA corpus (Kim et al., 2004), four levels of nested entities occur and the token “IL-2” is a Protein on its own, and it is also a part of two other Proteins and one DNA. [[[[IL-2]Protein receptor]Protein (IL-2R) alpha chain]Protein gene]DNA NER has drawn considerable attention as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). S"
D18-1309,D09-1015,0,0.828392,"Missing"
D18-1309,D17-1284,0,0.0325191,"can be difficult. For example, in the following phrase from the GENIA corpus (Kim et al., 2004), four levels of nested entities occur and the token “IL-2” is a Protein on its own, and it is also a part of two other Proteins and one DNA. [[[[IL-2]Protein receptor]Protein (IL-2R) alpha chain]Protein gene]DNA NER has drawn considerable attention as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowl"
D18-1309,N18-1131,1,0.365067,"Missing"
D18-1309,N18-1079,0,0.340971,"Missing"
D18-1309,W04-1213,0,0.384436,"rces. 1 Introduction Named entity recognition (NER) is a task of finding entities with specific semantic types such as Protein, Cell, and RNA in text. NER is generally treated as a sequential labeling task, where each token is tagged with a label that corresponds to its surrounding entity. However, when entities overlap or are nested within one another, treating the task as a sequential labeling task becomes difficult because an individual token can be included in several entities and defining a label for each token can be difficult. For example, in the following phrase from the GENIA corpus (Kim et al., 2004), four levels of nested entities occur and the token “IL-2” is a Protein on its own, and it is also a part of two other Proteins and one DNA. [[[[IL-2]Protein receptor]Protein (IL-2R) alpha chain]Protein gene]DNA NER has drawn considerable attention as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen"
D18-1309,N16-1030,0,0.792583,"elation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a speci"
D18-1309,D15-1102,0,0.19053,"tor]Protein (IL-2R) alpha chain]Protein gene]DNA NER has drawn considerable attention as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) ar"
D18-1309,P16-1101,0,0.560337,"iwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a specified maximum size."
D18-1309,P16-1105,1,0.795992,"a sequential labeling task becomes difficult because an individual token can be included in several entities and defining a label for each token can be difficult. For example, in the following phrase from the GENIA corpus (Kim et al., 2004), four levels of nested entities occur and the token “IL-2” is a Protein on its own, and it is also a part of two other Proteins and one DNA. [[[[IL-2]Protein receptor]Protein (IL-2R) alpha chain]Protein gene]DNA NER has drawn considerable attention as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gr"
D18-1309,D17-1276,0,0.172612,"[IL-2]Protein receptor]Protein (IL-2R) alpha chain]Protein gene]DNA NER has drawn considerable attention as the first step towards many natural language processing (NLP) applications including relation extraction (Miwa and Bansal, 2016), event extraction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Mu"
D18-1309,W03-1307,0,0.372705,"to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a specified maximum size. The model represents each region using the outputs of bidirectional long short-term memory (LSTM) by combining the boundary representation of a region and inside representation that simply treats all the tokens in a region equally by taking the average of LSTM outputs corresponding to tokens inside"
D18-1309,D17-1283,0,0.0492936,"ction (Feng et al., 2016), co-reference resolution (Fragkou, 2017; Stone and Arora, 2017), and entity linking (Gupta et al., 2017). Much work on NER, however, has ignored nested entities and instead chosen to focus on the non-nested entities, which are also referred to as flat entities. Only a few studies target the nested named entity recognition (Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a specified maximum size. The model represents each region using"
D18-1309,P17-1114,0,0.123045,"(Muis and Lu, 2017; Lu and Roth, 2015; Finkel and Manning, 2009). Recent successes in neural networks have shown impressive performance gains on flat named entity recognition in several domains (Lample et al., 2016; Ma and Hovy, 2016; Gridach, 2017; Strubell et al., 2017). Such models achieve state-of-the-art results without requiring any hand crafted features or external knowledge resources. In contrast, fewer approaches have emphasized the nested entity recognition problem. Existing approaches to nested NER (Shen et al., 2003; Alex et al., 2007; Finkel and Manning, 2009; Lu and Roth, 2015; Xu et al., 2017; Muis and Lu, 2017) are mostly feature-based and thus suffer from heavy feature engineering. In this paper, we present a novel neural exhaustive model that reasons over all the regions within a specified maximum size. The model represents each region using the outputs of bidirectional long short-term memory (LSTM) by combining the boundary representation of a region and inside representation that simply treats all the tokens in a region equally by taking the average of LSTM outputs corresponding to tokens inside the region. It then classifies regions into their entity types or non-entity. Unl"
D19-1381,P16-1231,0,0.026668,"tions, our model detects nested events by searching a sequence of actions that construct event structures incrementally in a bottom-up manner. We focus on event detection since the existing methods do not consider nested and overlapping structures as a whole during learning. Treating them simultaneously helps the model avoid inferring wrong causality relations between entities. Our model detects overlapping events by maintaining multiple beams and detecting events from all the beams, in contrast to existing transitionbased methods (Nivre, 2003, 2006; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016; Vlachos and Craven, 2012). We define an LSTM-based neural network model that can represent nested event structure to choose actions. linear layer score Model We describe our search-based neural network (SBNN) model that constitutes events from a relation graph by structured prediction. SBNN resembles an incremental transition-based parser (Nivre, 2006), but the search order, actions and representations are defined for DAG structures. We first discuss how we generate the relation graph in §2.1, then describe the structured prediction algorithm in §2.2 and the neural network in §2.3 and lastly"
D19-1381,W18-2311,0,0.0443169,"Missing"
D19-1381,D14-1082,0,0.0207605,"n a relation graph of trigger-argument relations, our model detects nested events by searching a sequence of actions that construct event structures incrementally in a bottom-up manner. We focus on event detection since the existing methods do not consider nested and overlapping structures as a whole during learning. Treating them simultaneously helps the model avoid inferring wrong causality relations between entities. Our model detects overlapping events by maintaining multiple beams and detecting events from all the beams, in contrast to existing transitionbased methods (Nivre, 2003, 2006; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016; Vlachos and Craven, 2012). We define an LSTM-based neural network model that can represent nested event structure to choose actions. linear layer score Model We describe our search-based neural network (SBNN) model that constitutes events from a relation graph by structured prediction. SBNN resembles an incremental transition-based parser (Nivre, 2006), but the search order, actions and representations are defined for DAG structures. We first discuss how we generate the relation graph in §2.1, then describe the structured prediction algorithm in §2.2 an"
D19-1381,P15-1017,0,0.0277166,"3–7, 2019. 2019 Association for Computational Linguistics relations into complete event structures. Joint approaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo et al., 2013) without the use of any syntacti"
D19-1381,W16-2922,0,0.0137891,"sted events, to compute the precision, we compare the predicted nested events with all gold events and to compute recall, we compare gold nested events with all predicted events. The evaluation script detects nested events by comparing the whole tree structure down to its sub-events until it reaches the flat events. Hence, the performance scores of the nested events inevitably include the performance on flat events. 3.2 Training Details and Model Parameters We implemented our model using the Chainer library (Tokui et al., 2015). We initialised the word embeddings using pre-trained embeddings (Chiu et al., 2016) while other embeddings are initialised using the normal distribution. All the embeddings and weight parameters were updated with mini-batch using the AMSGrad optimiser (Reddi et al., 2018). We also incorporated early stopping to choose the number of training epochs and tuned hyper-parameters (dropout, learning rate and weight decay rate) using grid search. The model parameters can be found in appendix A. 4 Results and Analyses Table 1 shows the event detection performance of the models on the test set. Our model achieves performance comparable to the state-of-the-art TEES event detection modu"
D19-1381,P04-1015,0,0.16143,"word dimensions so that it can be used as argument representation in nested events as shown in Figure 2. Then, we passed the event embedding into a linear hidden layer and output zt . Finally, the scoring function σ is calculated as σ(at |St−1 , Bt−1 ) = sigmoid(zt ). 2.4 Training From the relation graph generated in §2.1, we calculate gold action sequences that construct the gold event structures on the graph. The loss is summed over all actions and for all the events during the beam search and thus the objective function is to minimise their negative log-likelihood. We employ early updates (Collins and Roark, 2004): if the gold falls out of the beam, we stop searching and update the model immediately. 3 Experimental Settings We applied our model to the BioNLP CG shared task 2013 (Pyysalo et al., 2015). We used the original data partition and employed the official evaluation metrics. We focussed on the CG task dataset over other BioNLP datasets because of its complexity and size (N´edellec et al., 2013; Bj¨orne and Salakoski, 2018; Pyysalo et al., 2013). The CG dataset has the most number of entity types and event types and thus is the most complex among the available (and accessible) BioNLP datasets. Fu"
D19-1381,P15-1033,0,0.0204009,"igger-argument relations, our model detects nested events by searching a sequence of actions that construct event structures incrementally in a bottom-up manner. We focus on event detection since the existing methods do not consider nested and overlapping structures as a whole during learning. Treating them simultaneously helps the model avoid inferring wrong causality relations between entities. Our model detects overlapping events by maintaining multiple beams and detecting events from all the beams, in contrast to existing transitionbased methods (Nivre, 2003, 2006; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016; Vlachos and Craven, 2012). We define an LSTM-based neural network model that can represent nested event structure to choose actions. linear layer score Model We describe our search-based neural network (SBNN) model that constitutes events from a relation graph by structured prediction. SBNN resembles an incremental transition-based parser (Nivre, 2006), but the search order, actions and representations are defined for DAG structures. We first discuss how we generate the relation graph in §2.1, then describe the structured prediction algorithm in §2.2 and the neural networ"
D19-1381,P16-2011,0,0.0224431,"pages 3679–3686, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics relations into complete event structures. Joint approaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo"
D19-1381,N18-1131,1,0.85565,"Missing"
D19-1381,P11-1163,0,0.535477,"red argument event, a flat event (E1). Introduction Nested and overlapping event structures, which occur widely in text, are important because they can capture relations between events such as causality, e.g., a “production” event is a consequence of a “discovery” event, which in turn is a result of an “exploration” event. Event extraction involves the identification of a trigger and a set of its arguments in a given text. Figure 1 shows an example of a nested and overlapping event structure in the biomedical domain. The relation graph (topmost) forms a directed acyclic graph (DAG) structure (McClosky et al., 2011) and it encapsulates 15 event structures. It contains nested event structures such as E2,E3 because one of their arguments, in this case E1, is an event. Specifically, E1 is a flat event since its argument is an entity. Moreover, E2 and E3 are also overlapping events (explicitly shown in the relation graph having two induction triggers) because they share a common argument, E1. State-of-the-art approaches to event extraction in the biomedical domain are pipeline systems (Bj¨orne and Salakoski, 2018; Miwa et al., 2013) that decompose event extraction into simpler tasks such as: i) trigger/entit"
D19-1381,C14-1214,1,0.823874,"roaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo et al., 2013) without the use of any syntactic and hand-engineered features. Furthermore, analyses on the development set show our model performs fewer num"
D19-1381,D16-1008,0,0.069396,"Missing"
D19-1381,W13-2001,0,0.0826722,"Missing"
D19-1381,N16-1034,0,0.0161426,"ociation for Computational Linguistics relations into complete event structures. Joint approaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo et al., 2013) without the use of any syntactic and hand-engineered"
D19-1381,P15-2060,0,0.0238132,"Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics relations into complete event structures. Joint approaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo et al., 2013) without the"
D19-1381,W03-3017,0,0.168499,"AG structures. Given a relation graph of trigger-argument relations, our model detects nested events by searching a sequence of actions that construct event structures incrementally in a bottom-up manner. We focus on event detection since the existing methods do not consider nested and overlapping structures as a whole during learning. Treating them simultaneously helps the model avoid inferring wrong causality relations between entities. Our model detects overlapping events by maintaining multiple beams and detecting events from all the beams, in contrast to existing transitionbased methods (Nivre, 2003, 2006; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016; Vlachos and Craven, 2012). We define an LSTM-based neural network model that can represent nested event structure to choose actions. linear layer score Model We describe our search-based neural network (SBNN) model that constitutes events from a relation graph by structured prediction. SBNN resembles an incremental transition-based parser (Nivre, 2006), but the search order, actions and representations are defined for DAG structures. We first discuss how we generate the relation graph in §2.1, then describe the structured p"
D19-1381,W13-2008,1,0.827655,"., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo et al., 2013) without the use of any syntactic and hand-engineered features. Furthermore, analyses on the development set show our model performs fewer number of classifications in less time. action scoring function (shared) embedding S B E1 score BiLSTM layer event emb layer S B structure and buffer emb layer relation embedding layer Bcl-2 / VEGF induction of BiLSTM layer word emb layer tumor angiogenesis Figure 2: An illustration of the proposed neural model detecting event structures in a bottom-up manner, where E1 event representation becomes an argument to E2 event structure on the example sentence us"
D19-1381,C00-2137,0,0.13641,"Missing"
D19-1381,W17-2315,0,0.137684,"Missing"
D19-1381,W11-1807,0,0.0327068,"which words and phrases in a sentence potentially constitute as participants of an event, ii) relation detection, which finds pairwise relations between triggers and arguments, and iii) event detection, which combines pairwise 3679 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3679–3686, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics relations into complete event structures. Joint approaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transiti"
D19-1381,C08-1095,0,0.0198556,"us on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency parsing, e.g., (Sagae and Tsujii, 2008; Wang et al., 2018), however, they do not consider overlapping and nested structures. E2 We show that our event detection model achieves performance comparable to the event detection module of the state-of-the-art TEES system (Bj¨orne and Salakoski, 2018) on the BioNLP CG Shared Task 2013 (Pyysalo et al., 2013) without the use of any syntactic and hand-engineered features. Furthermore, analyses on the development set show our model performs fewer number of classifications in less time. action scoring function (shared) embedding S B E1 score BiLSTM layer event emb layer S B structure and buffe"
D19-1381,D14-1090,0,0.0236886,"stitute as participants of an event, ii) relation detection, which finds pairwise relations between triggers and arguments, and iii) event detection, which combines pairwise 3679 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 3679–3686, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics relations into complete event structures. Joint approaches have also been explored (Rao et al., 2017; Riedel and McCallum, 2011; Vlachos and Craven, 2012; Venugopal et al., 2014), but they focus on finding relation graphs and detect events with rules. McClosky et al. (2011) treats events as dependency structures by constraining event structures to map to trees, thus their method cannot represent overlapping event structures. Other neural models in event extraction are in the general domain (Feng et al., 2016; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016), but they used the ACE2005 corpus which does not have nested events (Miwa et al., 2014). Furthermore, there are some efforts on applying transition-based methods on DAG structures in dependency pa"
D19-1498,N19-1370,0,0.110406,"nodes are words and edges represent intra- and inter-sentential relations between the words. They connected words with different dependency edges and trained a binary logistic regression classifier. They evaluated their model on distantly supervised full-text articles from PubMed for Gene-Drug associations, restricting pairs within a window of consecutive sentences. Following this work, other approaches incorporated graphical models for document-level RE such as graph LSTM (Peng et al., 2017), graph CNN (Song et al., 2018) or RNNs on dependency tree structures (Gupta et al., 2019). Recently, Jia et al. (2019) improved n-ary RE using information from multiple sentences and paragraphs in a document. Similar to our approach, they choose to directly classify concept-level pairs rather than multiple mention-level pairs. Although they consider sub-relations to model related tuples, they ignore interactions with other entities outside of the target tuple in the discourse units. Non-graph-based approaches utilise different intra- and inter-sentence models and merge the resulted predictions (Gu et al., 2016, 2017). Other approaches extract document-level representations for each candidate entity pair (Zhen"
D19-1498,C16-1139,0,0.034617,"in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal, 4932 2016; Zhang et al., 2018). Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence. Other approaches deal with distantlysupervised datasets but are also limited to intra-sentential relations. They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair. Recently, Zeng et al. (2017) proposed a method for extracting paths between entities using the target entities’ mentions in several different sentences (in possibly different documents) as intermediate connectors. They allow mention-mention edges only if these mentions belong to the same entity and consider that a single mention pair exists in a sentence. On the contrary, we not only allow interactions between all mentions in the same sentence, but also consider multip"
D19-1498,P16-1200,0,0.0524628,"vised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal, 4932 2016; Zhang et al., 2018). Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence. Other approaches deal with distantlysupervised datasets but are also limited to intra-sentential relations. They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair. Recently, Zeng et al. (2017) proposed a method for extracting paths between entities using the target entities’ mentions in several different sentences (in possibly different documents) as intermediate connectors. They allow mention-mention edges only if these mentions belong to the same entity and consider that a single mention pair exists in a sentence. On the contrary, we not only allow interactions betwee"
D19-1498,N19-1308,0,0.0282338,"unusual central bitemporal hemianopic scotoma was found . Figure 1: Example of document-level, inter-sentence relations adapted from the CDR dataset (Li et al., 2016a). The solid and dotted lines represent intra- and inter-sentence relations, respectively. Introduction The extraction of relations between named entities in text, known as Relation Extraction (RE), is an important task of Natural Language Processing (NLP). Lately, RE has attracted a lot of attention from the field, in an effort to improve the inference capability of current methods (Zeng et al., 2017; Christopoulou et al., 2018; Luan et al., 2019). In real-world scenarios, a large amount of relations are expressed across sentences. The task of identifying these relations is named inter-sentence RE. Typically, inter-sentence relations occur in 1 Source code available at https://github.com/ fenchri/edge-oriented-graph textual snippets with several sentences, such as documents. In these snippets, each entity is usually repeated with the same phrases or aliases, the occurrences of which are often named entity mentions and regarded as instances of the entity. The multiple mentions of the target entities in different sentences can be useful"
D19-1498,P09-1113,0,0.0421887,"can help us infer that the entity ethambutol has a relation with the entity scotoma. The most common technique that is currently 4925 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 4925–4936, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics used to deal with multiple mentions of named entities is Multi-Instance Learning (MIL). Initially, MIL was introduced by Riedel et al. (2010) in order to reduce noise in distantly supervised corpora (Mintz et al., 2009). In DS, training instances are created from large, raw corpora using Knowledge Base (KB) entity linking and automatic annotation with heuristic rules. MIL in this setting considers multiple sentences (bags) that contain a pair of entities serving as the multiple instances of this pair. Verga et al. (2018) introduced another MIL setting for relation extraction between named entities in a document. In this setting, entities mapped to the same KB ID are considered as mentions of an entity concept and pairs of mentions correspond to the pair’s multiple instances. However, document-level RE is not"
D19-1498,P16-1105,1,0.775874,"Missing"
D19-1498,W18-2314,0,0.421678,"d to the same KB ID are considered as mentions of an entity concept and pairs of mentions correspond to the pair’s multiple instances. However, document-level RE is not common in the general domain, as the entity types of interest can often be found in the same sentence (Banko et al., 2007). On the contrary, in the biomedical domain, document-level relations are particularly important given the numerous aliases that biomedical entities can have (Quirk and Poon, 2017). To deal with document-level RE, recent approaches assume that only two mentions of the target entities reside in the document (Nguyen and Verspoor, 2018; Verga et al., 2018) or utilise different models for intra- and inter-sentence RE (Gu et al., 2016; Li et al., 2016b; Gu et al., 2017). In contrast with approaches that employ sequential models (Nguyen and Verspoor, 2018; Gu et al., 2017; Zhou et al., 2016), graph-based neural approaches have proven useful in encoding longdistance, inter-sentential information (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). These models interpret words as nodes and connections between them as edges. They typically perform on the nodes by updating the representations during training. However, a"
D19-1498,W15-1506,0,0.0373678,"s potentially simulate such links, by encoding the co-referring entities into the sentence representation. Finally, incomplete entity linking results into additional model errors. For instance, in the third example, hemorrhage and intracranial bleeding are synonymous terms. However, they are assigned different KB IDs, hence treated as different entities. The model can find the intra-sentential relation but not the inter-sentential one. 6 Related Work Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal, 4932 2016; Zhang et al., 2018). Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence. Other approaches deal with distantlysupervised datasets but are also limited to intra-sentential relations. They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) t"
D19-1498,Q17-1008,0,0.404919,"ven the numerous aliases that biomedical entities can have (Quirk and Poon, 2017). To deal with document-level RE, recent approaches assume that only two mentions of the target entities reside in the document (Nguyen and Verspoor, 2018; Verga et al., 2018) or utilise different models for intra- and inter-sentence RE (Gu et al., 2016; Li et al., 2016b; Gu et al., 2017). In contrast with approaches that employ sequential models (Nguyen and Verspoor, 2018; Gu et al., 2017; Zhou et al., 2016), graph-based neural approaches have proven useful in encoding longdistance, inter-sentential information (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). These models interpret words as nodes and connections between them as edges. They typically perform on the nodes by updating the representations during training. However, a relation between two entities depends on different contexts. It could thus be better expressed with an edge connection that is unique for the pair. A straightforward way to address this is to create graph-based models that rely on edge representations rather focusing on node representations, which are shared between multiple entity pairs. In this work, we tackle document-level, i"
D19-1498,D14-1162,0,0.09477,"(a) Overall 40 20 EoG (SS) EoG (SS direct) 0 2 4 8 16 32 Number of inference steps (c) Inter-sentential Figure 3: Performance as a function of the number of inference steps when using direct (SSdirect ) or direct and indirect (SS) sentence-to-sentence edges, on the CDR development set. 5 Overall 55.14 63.57 62.77 61.57 62.92 61.41 59.70 57.41 60.46 56.86 Analysis & Discussion We first analyse the performance of our main model (EoG) using different pre-trained word embeddings. Table 3 shows the performance difference between domain-specific (PubMed) (Chiu et al., 2016), general-domain (GloVe) (Pennington et al., 2014) and randomly initialized (random) word embeddings. As observed, our proposed model performs consistently with both in-domain and out-of-domain pre-trained word embeddings. The low performance of random embeddings is due to the small size of the dataset, which results in lower quality embeddings. For further analysis, we choose the CDR dataset as it is manually annotated. To better analyse the behaviour of our model, we conduct analysis on the effect of direct and indirect sentence-tosentence edges as a function of the inference steps. Figures 3a, 3b and 3c illustrate the performance of both g"
D19-1498,E17-1110,0,0.199859,"pair. Verga et al. (2018) introduced another MIL setting for relation extraction between named entities in a document. In this setting, entities mapped to the same KB ID are considered as mentions of an entity concept and pairs of mentions correspond to the pair’s multiple instances. However, document-level RE is not common in the general domain, as the entity types of interest can often be found in the same sentence (Banko et al., 2007). On the contrary, in the biomedical domain, document-level relations are particularly important given the numerous aliases that biomedical entities can have (Quirk and Poon, 2017). To deal with document-level RE, recent approaches assume that only two mentions of the target entities reside in the document (Nguyen and Verspoor, 2018; Verga et al., 2018) or utilise different models for intra- and inter-sentence RE (Gu et al., 2016; Li et al., 2016b; Gu et al., 2017). In contrast with approaches that employ sequential models (Nguyen and Verspoor, 2018; Gu et al., 2017; Zhou et al., 2016), graph-based neural approaches have proven useful in encoding longdistance, inter-sentential information (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). These models interp"
D19-1498,N19-1147,0,0.0439499,"s. Non-graph-based approaches utilise different intra- and inter-sentence models and merge the resulted predictions (Gu et al., 2016, 2017). Other approaches extract document-level representations for each candidate entity pair (Zheng et al., 2018; Li et al., 2018; Wu et al., 2019), or use syntactic dependency structures (Zhou et al., 2016; Peng et al., 2016). Verga et al. (2018) proposed a Transformer-based model for documentlevel relation extraction with multi-instance learning, merging multiple mention pairs. Nguyen and Verspoor (2018) used a CNN with additional character-level embeddings. Singh and Bhatia (2019) also utilised Transformer and connected two target entities by combining them directly and via a contextual token. However, they consider a single target entity pair per document. 7 Conclusion We presented a novel edge-oriented graph neural model for document-level relation extraction using multi-instance learning. The proposed model constructs a document-level graph with heterogeneous types of nodes and edges, modelling intraand inter-sentence pairs simultaneously with an iterative algorithm over the graph edges. To the best of our knowledge, this is the first approach to utilise an edge-ori"
D19-1498,D18-1246,0,0.136044,"ostly graph-based. Quirk and Poon (2017) introduced the notion of a document graph, where nodes are words and edges represent intra- and inter-sentential relations between the words. They connected words with different dependency edges and trained a binary logistic regression classifier. They evaluated their model on distantly supervised full-text articles from PubMed for Gene-Drug associations, restricting pairs within a window of consecutive sentences. Following this work, other approaches incorporated graphical models for document-level RE such as graph LSTM (Peng et al., 2017), graph CNN (Song et al., 2018) or RNNs on dependency tree structures (Gupta et al., 2019). Recently, Jia et al. (2019) improved n-ary RE using information from multiple sentences and paragraphs in a document. Similar to our approach, they choose to directly classify concept-level pairs rather than multiple mention-level pairs. Although they consider sub-relations to model related tuples, they ignore interactions with other entities outside of the target tuple in the discourse units. Non-graph-based approaches utilise different intra- and inter-sentence models and merge the resulted predictions (Gu et al., 2016, 2017). Othe"
D19-1498,D18-1157,0,0.0353429,"Missing"
D19-1498,N18-1080,0,0.480983,"4936, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics used to deal with multiple mentions of named entities is Multi-Instance Learning (MIL). Initially, MIL was introduced by Riedel et al. (2010) in order to reduce noise in distantly supervised corpora (Mintz et al., 2009). In DS, training instances are created from large, raw corpora using Knowledge Base (KB) entity linking and automatic annotation with heuristic rules. MIL in this setting considers multiple sentences (bags) that contain a pair of entities serving as the multiple instances of this pair. Verga et al. (2018) introduced another MIL setting for relation extraction between named entities in a document. In this setting, entities mapped to the same KB ID are considered as mentions of an entity concept and pairs of mentions correspond to the pair’s multiple instances. However, document-level RE is not common in the general domain, as the entity types of interest can often be found in the same sentence (Banko et al., 2007). On the contrary, in the biomedical domain, document-level relations are particularly important given the numerous aliases that biomedical entities can have (Quirk and Poon, 2017). To"
D19-1498,P16-1123,0,0.279624,"Missing"
D19-1498,D15-1206,0,0.0398492,"s the length of the edge and eik corresponds to the representation of the edge between nodes i and k. During the second step, we aggregate the original (short) edge representation and the new (longer) edge representation resulted from Equation (3) with linear interpolation as follows: (2l) (l) eij = β eij + (1 − β) X   (l) (l) f eik , ekj , (4) k6=i,j where β ∈ [0, 1] is a scalar that controls the contribution of the shorter edge presentation. In general β is larger for shorter edges as we expect that the relation between two nodes is better expressed through the shortest path between them (Xu et al., 2015; Borgwardt and Kriegel, 2005). The two steps are repeated a finite number of times N . The number of iterations is correlated with the final length of the edge representations. With initial edge length l equal to 1, the first iteration results in edges of length up-to 2. The second iteration results in edges of length up-to 4. Similarly, after N iterations, the length of edges will be up-to 2N . 2.5 Classification Layer To classify the concept-level entity pairs of interest, we incorporate a softmax classifier, using the entity-to-entity edges (EE) of the document graph that correspond to the"
D19-1498,D15-1203,0,0.138169,"l approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal, 4932 2016; Zhang et al., 2018). Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence. Other approaches deal with distantlysupervised datasets but are also limited to intra-sentential relations. They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair. Recently, Zeng et al. (2017) proposed a method for extracting paths between entities using the target entities’ mentions in several different sentences (in possibly different documents) as intermediate connectors. They allow mention-mention edges only if these mentions belong to the same entity and consider that a single mention pair exists in a sentence. On the contrar"
D19-1498,C14-1220,0,0.272301,"these edges, S nodes potentially simulate such links, by encoding the co-referring entities into the sentence representation. Finally, incomplete entity linking results into additional model errors. For instance, in the third example, hemorrhage and intracranial bleeding are synonymous terms. However, they are assigned different KB IDs, hence treated as different entities. The model can find the intra-sentential relation but not the inter-sentential one. 6 Related Work Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal, 4932 2016; Zhang et al., 2018). Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence. Other approaches deal with distantlysupervised datasets but are also limited to intra-sentential relations. They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNN"
D19-1498,D17-1186,0,0.127266,"d . A bilateral retrobulbar neuropathy with an unusual central bitemporal hemianopic scotoma was found . Figure 1: Example of document-level, inter-sentence relations adapted from the CDR dataset (Li et al., 2016a). The solid and dotted lines represent intra- and inter-sentence relations, respectively. Introduction The extraction of relations between named entities in text, known as Relation Extraction (RE), is an important task of Natural Language Processing (NLP). Lately, RE has attracted a lot of attention from the field, in an effort to improve the inference capability of current methods (Zeng et al., 2017; Christopoulou et al., 2018; Luan et al., 2019). In real-world scenarios, a large amount of relations are expressed across sentences. The task of identifying these relations is named inter-sentence RE. Typically, inter-sentence relations occur in 1 Source code available at https://github.com/ fenchri/edge-oriented-graph textual snippets with several sentences, such as documents. In these snippets, each entity is usually repeated with the same phrases or aliases, the occurrences of which are often named entity mentions and regarded as instances of the entity. The multiple mentions of the targe"
D19-1498,D18-1244,0,0.127672,"Finally, incomplete entity linking results into additional model errors. For instance, in the third example, hemorrhage and intracranial bleeding are synonymous terms. However, they are assigned different KB IDs, hence treated as different entities. The model can find the intra-sentential relation but not the inter-sentential one. 6 Related Work Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal, 4932 2016; Zhang et al., 2018). Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence. Other approaches deal with distantlysupervised datasets but are also limited to intra-sentential relations. They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair. Recently, Zeng"
D19-5708,C18-1177,0,0.177662,"Missing"
D19-5708,N18-1131,1,0.777796,"Missing"
D19-5708,N16-1030,0,0.195418,"Missing"
D19-5708,C18-1139,0,0.0497414,"Missing"
D19-5708,P16-1105,1,0.877267,"Missing"
D19-5708,E99-1043,0,0.128647,"Missing"
D19-5708,D14-1162,0,0.0832,"ist of corresponding CUIs {ci }i=1,...,T . Using the SNOMED-CT database, we first conduct dictionary look-up matching for each mention mi with CUIs’ term names to retrieve an optimal CUI. If the CUI is not found for a mention, we then compute a similarity score using the dotproduct with entity embeddings that supposedly should capture possible related CUIs and select the maximum score to predict the optimal CUI for a mention. We use fixed, continuous, task-specific entity embeddings, namely the pre-trained entity embeddings of Spanish SNOMED-CT KB by extracting all CUIs term name using GloVe (Pennington et al., 2014). For the multi-token term name of a CUI, we simply compute the average embeddings. 4 4.2 Hyper-parameters Word representations We generated task specific word embeddings of Spanish PharmaCoNER corpus by merging the raw text of training, development, and test (including background set) sets using GloVe (Pennington et al., 2014). We set the dimension of word embeddings to 200, the dimension of character embeddings for character encoding to 25, and character embeddings for morphological analysis to 25. Hidden dimensions The hidden states in the LSTMs had 200 dimensions. Each feed forward neural"
D19-5708,D18-1309,1,0.875232,"Missing"
D19-5708,P16-2011,0,0.143735,"Missing"
D19-5708,D19-5701,0,0.0632783,"Missing"
D19-5708,P16-1218,0,0.190418,"apture its semantic type by encoding the whole semantic information of the span. We use the average of all the outputs corresponding to the words in the span for the inside representation. Following the above contextual, boundary, and inside representations, we represent the representation R(i, k)[F,L,A,R,B] (Forward-context, Leftboundary, inside with Average, Right-boundary, and Backward-context) of the span (i, k) as follows:  − → h i−1 ; hi ; 1 k−i+1 h→ − ← − i R(i, k)[F,L,A,R,B] = h i−1 ; hi ; xi ; hk ; h i−1 . (5) Contextual LSTM-Minus-based Span Representations We also try LSTM-Minus (Wang and Chang, 2016) for the boundary representation4 . The left boundary is computed as the representation of the previous word of the span subtracted from the representation of the last word of the current span. Similarly, the right boundary is computed as the representation of the next word of the span subtracted from the representation of the first word of the current span. In contextual LSTMMinus-based span representations of an input sequence, we compute the forward- and backwardcontext of a target span as the same manner that stated to represent the forward- and backwardcontext representations of R(i, k)[F"
D19-5727,N19-1423,0,0.156661,"many cases, a mention and its antecedent are far away, e.g., a mention can occur in the result section of a paper while its antecedent is in the abstract section. To address these problems, we enhance the baseline system in two ways; we propose to filter noisy spans by using syntactic information and increase the number of antecedent candidates to capture such long-distance coreferent pairs. We further boost the system by replacing the underlying Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) layer with the Bidirectional Encoder Representations from Transformer (BERT) model (Devlin et al., 2019)—a contextualized language model that can efficiently capture context in a wide range of NLP tasks. We have evaluated our system on six common metrics for coreference resolution including B3 , BLANC, CEAFE, CEAFM, LEA, and MUC using the official evaluation script provided by the shared task organizers. By increasing the numThis paper describes our system developed for the coreference resolution task of the CRAFT Shared Tasks 2019. The CRAFT corpus is more challenging than other existing corpora because it contains full text articles. We have employed an existing span-based state-of-theart neur"
D19-5727,D17-1018,0,0.107226,"n2 , Makoto Miwa1,3 , Hiroya Takamura1 , Sophia Ananiadou2 1 Artificial Intelligence Research Center (AIRC), National Institute of Advanced Industrial Science and Technology (AIST), Japan 2 National Centre for Text Mining, University of Manchester, United Kingdom 3 Toyota Technological Institute, Japan {long.trieu, khoa.duong, takamura.hiroya}@aist.go.jp, makoto-miwa@toyota-ti.ac.jp, {nhung.nguyen, Sophia.Ananiadou}@manchester.ac.uk Abstract present our approach to address the coreference resolution task in this challenging corpus. We employ the state-of-the-art end-to-end coreference system (Lee et al., 2017) as our baseline. The system generates all continuous sequences of words (or spans) in each sentence as mention candidates, which means the number of candidates increases linearly to the number of sentences. Such candidates may contain a large number of noisy spans, which are spans in a sentence that do not fit any noun phrases according to the corresponding parse tree. Such noisy spans are often wasteful when being included in the list of candidates for the coreference resolution step. Especially for the CRAFT corpus, of which the average number of sentences is more than 300, the number of no"
D19-5727,W11-1811,0,0.0703575,"Missing"
D19-5727,W18-2324,1,0.892144,"Missing"
E17-3028,bird-etal-2008-acl,0,0.0690463,"Missing"
E17-3028,D15-1175,0,0.0534879,"Missing"
E17-3028,D14-1113,0,\N,Missing
E17-3028,D15-1161,0,\N,Missing
I17-2064,P15-2098,0,0.149776,". We employed mini-batch training and font images without pre-training, but it did not work well even after many training epochs. 3 http://www.nii.ac.jp/dsc/idr/en/ rakuten/rakuten.html 4 https://github.com/ikegami-yukino/ neologdn 5 We empirically chose this threshold. We got lower score when we used all the characters. 6 http://ipafont.ipa.go.jp/ 380 Method character-based HAN Our method #parameters 270,900 37,312 Several other related work has exploited processing the character components, mostly radicals, in Japanese (Yencken and Baldwin, 2008) and Chinese (Jin et al., 2012; Lepage, 2014; Shi et al., 2015; Li et al., 2015; Dong et al., 2016). Sun et al. (2014) proposed radical-enhanced Chinese character embeddings for word segmentation in Chinese. They utilized radical information of Chinese characters using a radical-mapping dictionary. Their model consists of two models for words segmentation and radical prediction with sharing parameters of character embeddings. They incorporate the radical information into character embeddings by this radical prediction. Their method was tailored for Chinese where all the characters have radicals as character components. Some kinds of Japanese characters l"
I17-2064,N16-1174,0,0.62194,"ly contain many kinds of characters. For example, a typical Japanese character set JIS X 0213 contains 11,233 different characters including Hiraganas, Katakanas, and Kanjis. This large number of characters often makes it difficult to apply recent character embedding models to such languages, and this fact prompts us to reduce the number of parameters used to store information for characters. We propose a novel method to analyze Japanese review documents with exploiting the visual information of ideograms and logograms. Our method extends character-based Hierarchical Attention Networks (HAN) (Yang et al., 2016) by incorporating visual information of characters. The method first builds character embeddings from their font images and then feeds them as inputs into the character-based HAN. Our main contribution is to show the usability of font images as potential character representation not to use them as additional information but to substitute for integer indices. Our method represents documents without the need for external Introduction Some languages like Japanese and Chinese have ideograms and logograms that are characters representing words or phrases by themselves. In these languages, such kind"
I17-2064,C08-1131,0,0.0326288,"els by Adam with suggested parameters on the paper (Kingma and Ba, 2015). We employed mini-batch training and font images without pre-training, but it did not work well even after many training epochs. 3 http://www.nii.ac.jp/dsc/idr/en/ rakuten/rakuten.html 4 https://github.com/ikegami-yukino/ neologdn 5 We empirically chose this threshold. We got lower score when we used all the characters. 6 http://ipafont.ipa.go.jp/ 380 Method character-based HAN Our method #parameters 270,900 37,312 Several other related work has exploited processing the character components, mostly radicals, in Japanese (Yencken and Baldwin, 2008) and Chinese (Jin et al., 2012; Lepage, 2014; Shi et al., 2015; Li et al., 2015; Dong et al., 2016). Sun et al. (2014) proposed radical-enhanced Chinese character embeddings for word segmentation in Chinese. They utilized radical information of Chinese characters using a radical-mapping dictionary. Their model consists of two models for words segmentation and radical prediction with sharing parameters of character embeddings. They incorporate the radical information into character embeddings by this radical prediction. Their method was tailored for Chinese where all the characters have radical"
I17-2064,W04-3230,0,0.094302,"Missing"
I17-2064,D15-1098,0,0.0314668,"-batch training and font images without pre-training, but it did not work well even after many training epochs. 3 http://www.nii.ac.jp/dsc/idr/en/ rakuten/rakuten.html 4 https://github.com/ikegami-yukino/ neologdn 5 We empirically chose this threshold. We got lower score when we used all the characters. 6 http://ipafont.ipa.go.jp/ 380 Method character-based HAN Our method #parameters 270,900 37,312 Several other related work has exploited processing the character components, mostly radicals, in Japanese (Yencken and Baldwin, 2008) and Chinese (Jin et al., 2012; Lepage, 2014; Shi et al., 2015; Li et al., 2015; Dong et al., 2016). Sun et al. (2014) proposed radical-enhanced Chinese character embeddings for word segmentation in Chinese. They utilized radical information of Chinese characters using a radical-mapping dictionary. Their model consists of two models for words segmentation and radical prediction with sharing parameters of character embeddings. They incorporate the radical information into character embeddings by this radical prediction. Their method was tailored for Chinese where all the characters have radicals as character components. Some kinds of Japanese characters like Hiraganas and"
K15-1027,P14-2131,0,0.316157,"paku-ku, Nagoya, Japan makoto-miwa@toyota-ti.ac.jp words. For example, word2vec1 (Mikolov et al., 2013b) is a well-established tool for learning word embeddings. Although word2vec has successfully been used to learn word embeddings, these kinds of word embeddings capture only co-occurrence relationships between words (Levy and Goldberg, 2014). While simply adding word embeddings trained using window-based contexts as additional features to existing systems has proven valuable (Turian et al., 2010), more recent studies have focused on how to tune and enhance word embeddings for specific tasks (Bansal et al., 2014; Boros et al., 2014; Chen et al., 2014; Guo et al., 2014; Nguyen and Grishman, 2014) and we continue this line of research for the task of relation classification. In this work we present a learning method for word embeddings specifically designed to be useful for relation classification. The overview of our system and the embedding learning process are shown in Figure 1. First we train word embeddings by predicting each of the words between noun pairs using lexical relation-specific features on a large unlabeled corpus. We then use the word embeddings to construct lexical feature vectors for"
K15-1027,D10-1115,0,0.0394017,"ings. To discriminate between words in n from those in win , wbef , and waf t , we have two sets of word embeddings: N ∈ Rd×|N |and W ∈ Rd×|W |. W is a set of words and N is also a set of words but contains only nouns. Hence, the word cause has two embeddings: one in N and another in W. In general cause is used as a noun and a verb, and thus we expect the noun embeddings to capture the meanings focusing on their noun usage. This is inspired by some recent work on word representations that explicitly assigns an independent representation for each word usage according to its part-of-speech tag (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hashimoto et al., 2014; Kartsaklis and Sadrzadeh, 2013). n i=1 j=1 (3) where is a word randomly drawn from the unigram noise distribution weighted by an exponent of 0.75. Maximizing Junlabeled means that our method can discriminate between each target word and k noise words given the target word’s context. This approach is much less computationally expensive than the one-versus-rest approach and has proven effective in learning word embeddings. wj′ 270 noun pair: To reduce redundancy during training we use subsampling. A training samp"
K15-1027,D14-1199,0,0.136415,"Missing"
K15-1027,H05-1091,0,0.706306,"el features and no external annotated resources. Furthermore, our qualitative analysis of the learned embeddings shows that n-grams of our embeddings capture salient syntactic patterns similar to semantic relation types. 2 Related Work A traditional approach to relation classification is to train classifiers in a supervised fashion using a variety of features. These features include lexical bag-of-words features and features based on syntactic parse trees. For syntactic parse trees, the paths between the target entities on constituency and dependency trees have been demonstrated to be useful (Bunescu and Mooney, 2005; Zhang et al., 2006). On the shared task introduced by Hendrickx et al. (2010), Rink and Harabagiu (2010) achieved the best score using a variety of handcrafted features which were then used to train a Support Vector Machine (SVM). Recently, word embeddings have become popular as an alternative to hand-crafted features (Collobert et al., 2011). However, one of the limitations is that word embeddings are usually learned by predicting a target word in its context, leading to only local co-occurrence information being captured (Levy and Goldberg, 2014). Thus, several recent studies have focused"
K15-1027,C14-1078,0,0.0277905,"Missing"
K15-1027,D14-1163,1,0.870336,"two sets of word embeddings: N ∈ Rd×|N |and W ∈ Rd×|W |. W is a set of words and N is also a set of words but contains only nouns. Hence, the word cause has two embeddings: one in N and another in W. In general cause is used as a noun and a verb, and thus we expect the noun embeddings to capture the meanings focusing on their noun usage. This is inspired by some recent work on word representations that explicitly assigns an independent representation for each word usage according to its part-of-speech tag (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hashimoto et al., 2014; Kartsaklis and Sadrzadeh, 2013). n i=1 j=1 (3) where is a word randomly drawn from the unigram noise distribution weighted by an exponent of 0.75. Maximizing Junlabeled means that our method can discriminate between each target word and k noise words given the target word’s context. This approach is much less computationally expensive than the one-versus-rest approach and has proven effective in learning word embeddings. wj′ 270 noun pair: To reduce redundancy during training we use subsampling. A training sample, whose target word is w, √ is discarded with the probability t Pd (w) = 1 − p(w"
K15-1027,W06-1670,0,0.155868,"Missing"
K15-1027,P15-1061,0,0.28635,"RNN models to better handle the relations. These methods rely on syntactic parse trees. Yu et al. (2014) introduced their novel Factorbased Compositional Model (FCM) and presented results from several model variants, the best performing being FCMEMB and FCMFULL . The former only uses word embedding information and the latter relies on dependency paths and NE features, in addition to word embeddings. Zeng et al. (2014) used a Convolutional Neural Network (CNN) with WordNet hypernyms. Noteworthy in relation to the RNN-based methods, the CNN model does not rely on parse trees. More recently, dos Santos et al. (2015) have introduced CR-CNN by extending the CNN model and achieved the best result to date. The key point of CR-CNN is that it improves the classification score by omitting the noisy class “Other” in the dataset described in Section 5.1. We call CR-CNN using the “Other” class CR-CNNOther and CRCNN omitting the class CR-CNNBest . (a) Financial [stress]E1 is one of the main causes of [divorce]E2 (b) The [burst]E1 has been caused by water hammer [pressure]E2 Training example (a) is classified as CauseEffect(E1 , E2 ) which denotes that E2 is an effect caused by E1 , while training example (b) is cla"
K15-1027,N15-1133,0,0.0136109,"bag-of-words features included the noun pairs and words between, before, and after the pairs, and we used LIBLINEAR6 as our classifier. noun pairs in their contexts. The dataset, containing 8,000 training and 2,717 test samples, defines nine classes (Cause-Effect, Entity-Origin, etc.) for ordered relations and one class (Other) for other relations. Thus, the task can be treated as a 19class classification task. Two examples from the training set are shown below. 5.2.3 Neural Network Models Socher et al. (2012) used Recursive Neural Network (RNN) models to classify the relations. Subsequently, Ebrahimi and Dou (2015) and Hashimoto et al. (2013) proposed RNN models to better handle the relations. These methods rely on syntactic parse trees. Yu et al. (2014) introduced their novel Factorbased Compositional Model (FCM) and presented results from several model variants, the best performing being FCMEMB and FCMFULL . The former only uses word embedding information and the latter relies on dependency paths and NE features, in addition to word embeddings. Zeng et al. (2014) used a Convolutional Neural Network (CNN) with WordNet hypernyms. Noteworthy in relation to the RNN-based methods, the CNN model does not re"
K15-1027,D13-1166,0,0.0424757,"Missing"
K15-1027,S07-1003,0,0.0433618,"Missing"
K15-1027,D11-1129,0,0.0721086,"Missing"
K15-1027,D14-1012,0,0.0246398,"r example, word2vec1 (Mikolov et al., 2013b) is a well-established tool for learning word embeddings. Although word2vec has successfully been used to learn word embeddings, these kinds of word embeddings capture only co-occurrence relationships between words (Levy and Goldberg, 2014). While simply adding word embeddings trained using window-based contexts as additional features to existing systems has proven valuable (Turian et al., 2010), more recent studies have focused on how to tune and enhance word embeddings for specific tasks (Bansal et al., 2014; Boros et al., 2014; Chen et al., 2014; Guo et al., 2014; Nguyen and Grishman, 2014) and we continue this line of research for the task of relation classification. In this work we present a learning method for word embeddings specifically designed to be useful for relation classification. The overview of our system and the embedding learning process are shown in Figure 1. First we train word embeddings by predicting each of the words between noun pairs using lexical relation-specific features on a large unlabeled corpus. We then use the word embeddings to construct lexical feature vectors for relation classification. Lastly, the feature vectors are"
K15-1027,D13-1137,1,0.921942,"ef , and waf t , we have two sets of word embeddings: N ∈ Rd×|N |and W ∈ Rd×|W |. W is a set of words and N is also a set of words but contains only nouns. Hence, the word cause has two embeddings: one in N and another in W. In general cause is used as a noun and a verb, and thus we expect the noun embeddings to capture the meanings focusing on their noun usage. This is inspired by some recent work on word representations that explicitly assigns an independent representation for each word usage according to its part-of-speech tag (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Hashimoto et al., 2013; Hashimoto et al., 2014; Kartsaklis and Sadrzadeh, 2013). n i=1 j=1 (3) where is a word randomly drawn from the unigram noise distribution weighted by an exponent of 0.75. Maximizing Junlabeled means that our method can discriminate between each target word and k noise words given the target word’s context. This approach is much less computationally expensive than the one-versus-rest approach and has proven effective in learning word embeddings. wj′ 270 noun pair: To reduce redundancy during training we use subsampling. A training sample, whose target word is w, √ is discarded with the probab"
K15-1027,P06-1104,0,0.0440265,"l annotated resources. Furthermore, our qualitative analysis of the learned embeddings shows that n-grams of our embeddings capture salient syntactic patterns similar to semantic relation types. 2 Related Work A traditional approach to relation classification is to train classifiers in a supervised fashion using a variety of features. These features include lexical bag-of-words features and features based on syntactic parse trees. For syntactic parse trees, the paths between the target entities on constituency and dependency trees have been demonstrated to be useful (Bunescu and Mooney, 2005; Zhang et al., 2006). On the shared task introduced by Hendrickx et al. (2010), Rink and Harabagiu (2010) achieved the best score using a variety of handcrafted features which were then used to train a Support Vector Machine (SVM). Recently, word embeddings have become popular as an alternative to hand-crafted features (Collobert et al., 2011). However, one of the limitations is that word embeddings are usually learned by predicting a target word in its context, leading to only local co-occurrence information being captured (Levy and Goldberg, 2014). Thus, several recent studies have focused on overcoming this li"
K15-1027,P14-2012,0,0.142311,"c1 (Mikolov et al., 2013b) is a well-established tool for learning word embeddings. Although word2vec has successfully been used to learn word embeddings, these kinds of word embeddings capture only co-occurrence relationships between words (Levy and Goldberg, 2014). While simply adding word embeddings trained using window-based contexts as additional features to existing systems has proven valuable (Turian et al., 2010), more recent studies have focused on how to tune and enhance word embeddings for specific tasks (Bansal et al., 2014; Boros et al., 2014; Chen et al., 2014; Guo et al., 2014; Nguyen and Grishman, 2014) and we continue this line of research for the task of relation classification. In this work we present a learning method for word embeddings specifically designed to be useful for relation classification. The overview of our system and the embedding learning process are shown in Figure 1. First we train word embeddings by predicting each of the words between noun pairs using lexical relation-specific features on a large unlabeled corpus. We then use the word embeddings to construct lexical feature vectors for relation classification. Lastly, the feature vectors are used to train a relation cl"
K15-1027,S10-1057,0,0.278814,"use syntactic information or manually constructed external resources. 1 Introduction Automatic classification of semantic relations has a variety of applications, such as information extraction and the construction of semantic networks (Girju et al., 2007; Hendrickx et al., 2010). A traditional approach to relation classification is to train classifiers using various kinds of features with class labels annotated by humans. Carefully crafted features derived from lexical, syntactic, and semantic resources play a significant role in achieving high accuracy for semantic relation classification (Rink and Harabagiu, 2010). In recent years there has been an increasing interest in using word embeddings as an alternative to traditional hand-crafted features. Word embeddings are represented as real-valued vectors and capture syntactic and semantic similarity between 1 https://code.google.com/p/word2vec/. 268 Proceedings of the 19th Conference on Computational Language Learning, pages 268–278, c Beijing, China, July 30-31, 2015. 2015 Association for Computational Linguistics Figure 1: The overview of our system (a) and the embedding learning method (b). In the example sentence, each of are, caused, and by is treate"
K15-1027,D12-1110,0,0.706942,"ty of useful features have been proposed for relation classification. Among them, we use dependency path features (Bunescu and Mooney, 2005) based on the untyped binary dependencies of the Stanford parser to find the shortest path between target nouns. The dependency path features are computed by averaging word embeddings from W on the shortest path, and are then concatenated to the feature vector e. Furthermore, we directly incorporate semantic information using word-level semantic features from Named Entity (NE) tags and WordNet hypernyms, as used in previous work (Rink and Harabagiu, 2010; Socher et al., 2012; Yu et al., 2014). We refer to this extended method as RelEmbFULL . Concretely, RelEmbFULL uses the same binary features as in Socher et al. (2012). The features come from NE tags and WordNet hypernym tags of target nouns provided by a sense tagger (Ciaramita and Altun, 2006). 4 4.2 Initialization and Optimization We initialized the embedding matrices N and W with zero-mean gaussian noise with a variance of 1 ˜ d . W and b were zero-initialized. The model parameters were optimized by maximizing the objective function in Eq. (3) using stochastic gradient ascent. The learning rate was set to α"
K15-1027,P14-1146,0,0.0362761,"target word to be predicted during training. Bansal et al. (2014) trained embeddings by defining parent and child nodes in dependency trees as contexts. Chen et al. (2014) introduced the concept of feature embeddings induced by parsing a large unannotated corpus and then learning embeddings for the manually crafted features. For information extraction, Boros et al. (2014) trained word embeddings relevant for event role extraction, and Nguyen and Grishman (2014) employed word embeddings for domain adaptation of relation extraction. Another kind of task-specific word embeddings was proposed by Tang et al. (2014), which used sentiment labels on tweets to adapt word embeddings for a sentiment analysis tasks. However, such an approach is only feasible when a large amount of labeled data is available. cal level features and no external annotated resources. Furthermore, our qualitative analysis of the learned embeddings shows that n-grams of our embeddings capture salient syntactic patterns similar to semantic relation types. 2 Related Work A traditional approach to relation classification is to train classifiers in a supervised fashion using a variety of features. These features include lexical bag-of-wo"
K15-1027,P10-1040,0,0.066139,"rsity College London, London, United Kingdom pontus@stenetorp.se §Toyota Technological Institute, 2-12-1 Hisakata, Tempaku-ku, Nagoya, Japan makoto-miwa@toyota-ti.ac.jp words. For example, word2vec1 (Mikolov et al., 2013b) is a well-established tool for learning word embeddings. Although word2vec has successfully been used to learn word embeddings, these kinds of word embeddings capture only co-occurrence relationships between words (Levy and Goldberg, 2014). While simply adding word embeddings trained using window-based contexts as additional features to existing systems has proven valuable (Turian et al., 2010), more recent studies have focused on how to tune and enhance word embeddings for specific tasks (Bansal et al., 2014; Boros et al., 2014; Chen et al., 2014; Guo et al., 2014; Nguyen and Grishman, 2014) and we continue this line of research for the task of relation classification. In this work we present a learning method for word embeddings specifically designed to be useful for relation classification. The overview of our system and the embedding learning process are shown in Figure 1. First we train word embeddings by predicting each of the words between noun pairs using lexical relation-sp"
K15-1027,P12-2018,0,0.0413567,"in our method, and 1.6 × 107 in CRCNNOther assuming N is 10. dos Santos et al. (2015) also boosted the score of CR-CNNOther by omitting the noisy class “Other” by a rankingbased classifier, and achieved the best score (CRCNNBest ). Our results may also be improved by using the same technique, but the technique is dataset-dependent, so we did not incorporate the technique. These results show that our task-specific word embeddings are more useful than those trained using window-based contexts. A point that we would like to emphasize is that the baselines are unexpectedly strong. As was noted by Wang and Manning (2012), we should carefully implement strong baselines and see whether complex models can outperform these baselines. 5.3.2 Comparison with SVM-Based Systems RelEmb performs much better than the bag-ofwords-based SVM. This is not surprising given that we use a large unannotated corpus and embeddings with a large number of parameters. RelEmb also outperforms the SVM system of Rink and Harabagiu (2010), which demonstrates the effectiveness of our task-specific word embeddings, despite our only requirement being a large unannotated corpus and a POS tagger. 5.3.3 Comparison with Neural Network Models Re"
K15-1027,C14-1220,0,0.0554248,"w. 5.2.3 Neural Network Models Socher et al. (2012) used Recursive Neural Network (RNN) models to classify the relations. Subsequently, Ebrahimi and Dou (2015) and Hashimoto et al. (2013) proposed RNN models to better handle the relations. These methods rely on syntactic parse trees. Yu et al. (2014) introduced their novel Factorbased Compositional Model (FCM) and presented results from several model variants, the best performing being FCMEMB and FCMFULL . The former only uses word embedding information and the latter relies on dependency paths and NE features, in addition to word embeddings. Zeng et al. (2014) used a Convolutional Neural Network (CNN) with WordNet hypernyms. Noteworthy in relation to the RNN-based methods, the CNN model does not rely on parse trees. More recently, dos Santos et al. (2015) have introduced CR-CNN by extending the CNN model and achieved the best result to date. The key point of CR-CNN is that it improves the classification score by omitting the noisy class “Other” in the dataset described in Section 5.1. We call CR-CNN using the “Other” class CR-CNNOther and CRCNN omitting the class CR-CNNBest . (a) Financial [stress]E1 is one of the main causes of [divorce]E2 (b) The"
K15-1027,J08-1002,0,\N,Missing
N15-1100,P14-2131,0,0.0132781,"013; Pennington et al., 2014). Word embeddings have also been effectively employed in several tasks such as named entity recognition (Turian et al., 2010; Guo et al., 2014), adjectival scales (Kim and de Marneffe, 2013) and text classification (Le and Mikolov, 2014). Such embeddings trained based on distributional hypothesis (Harris, 1954), however, often fail to recognize antonyms since antonymous words, e.g. strong and weak, occur in similar contexts. Recent studies focuses on learning word embeddings for specific tasks, such as sentiment analysis (Tang et al., 2014) and dependency parsing (Bansal et al., 2014; Chen et al., 2014). These motivate a new approach to learn word embeddings to capture antonyms. In this paper, we propose a novel approach to construct word embeddings that can capture antonyms. Unlike the previous approaches, our approach directly trains word embeddings to represent antonyms. We propose two models: a Word Embedding on Thesauri information (WE-T) model and a Word Embeddings on Thesauri and Distributional information (WE-TD) model. The WE-T model receives supervised information from synonym and antonym pairs in thesauri and infers the relations of the other word pairs in the"
N15-1100,C14-1078,0,0.0215438,"., 2014). Word embeddings have also been effectively employed in several tasks such as named entity recognition (Turian et al., 2010; Guo et al., 2014), adjectival scales (Kim and de Marneffe, 2013) and text classification (Le and Mikolov, 2014). Such embeddings trained based on distributional hypothesis (Harris, 1954), however, often fail to recognize antonyms since antonymous words, e.g. strong and weak, occur in similar contexts. Recent studies focuses on learning word embeddings for specific tasks, such as sentiment analysis (Tang et al., 2014) and dependency parsing (Bansal et al., 2014; Chen et al., 2014). These motivate a new approach to learn word embeddings to capture antonyms. In this paper, we propose a novel approach to construct word embeddings that can capture antonyms. Unlike the previous approaches, our approach directly trains word embeddings to represent antonyms. We propose two models: a Word Embedding on Thesauri information (WE-T) model and a Word Embeddings on Thesauri and Distributional information (WE-TD) model. The WE-T model receives supervised information from synonym and antonym pairs in thesauri and infers the relations of the other word pairs in the thesauri from the su"
N15-1100,D14-1012,0,0.0514665,"Missing"
N15-1100,D13-1169,0,0.0767675,"Missing"
N15-1100,N13-1090,0,0.0718617,"nd indirect antonym pairs, e.g., synonym of antonym, will also have low similarity scores since the embeddings of the words in the pairs will be dissimilar. We use AdaGrad (Duchi et al., 2011) to maximize this objective function. AdaGrad is an online learning method using a gradient-based update with automatically-determined learning rate. 2.2 Word embeddings using thesauri and distributional information Now we explain a model to incorporate corpusbased distributional information into the WE-T model, which is called the WE-TD model. We hereby introduce Skip-Gram with Negative Sampling (SGNS) (Mikolov et al., 2013a), which the WE-TD model bases on. Levy and Goldberg (2014) shows the objective function for SGNS can be rewritten as follows. ∑∑ {#(w, c) log σ(sim(w, c)) w∈V c∈V (3) + k#(w)P0 (c) log σ(−sim(w, c))} The first term represents the co-occurrence pairs within a context window of C words preceding and following target words. #(w, c) stands for the number of appearances of a target word w and its context c. The second term represents the negative sampling. k is a number of negatively sampled words for each target word. #p (w) is the number of appearances of w as a target word, and its negative co"
N15-1100,D08-1103,0,0.169,"Missing"
N15-1100,J13-3004,0,0.470582,"hen the coefficients are less than 1. 3 Experiments 3.1 Evaluation settings This section explains the task setting, resource for training, parameter settings, and evaluation metrics. 3.1.1 GRE antonym question task We evaluate our models and compare them with other existing models using GRE antonym question dataset originally provided by Mohammad et al. (2008). This dataset is widely used to evaluate the performance of antonym detection. Each question has a target word and five candidate words, and the system has to choose the most contrasting word to the target word from the candidate words (Mohammad et al., 2013). All the words in the questions are single-token words. This dataset consists of two parts, development and test, and they have 162 and 950 questions, respectively. Since the test part contains 160 development data set, We will also report results on 790 (950-160) questions following Mohammad et al. (2013). In evaluating our models on the questions, we first calculated similarities between a target word and its candidate words. The similarities were calculated by averaging asymmetric similarity scores using the similarity function in Equation 2. We then chose a word which had the lowest simil"
N15-1100,D14-1162,0,0.076169,"Missing"
N15-1100,P14-1146,0,0.00930807,"olov et al., 2013b; Mnih and Kavukcuoglu, 2013; Pennington et al., 2014). Word embeddings have also been effectively employed in several tasks such as named entity recognition (Turian et al., 2010; Guo et al., 2014), adjectival scales (Kim and de Marneffe, 2013) and text classification (Le and Mikolov, 2014). Such embeddings trained based on distributional hypothesis (Harris, 1954), however, often fail to recognize antonyms since antonymous words, e.g. strong and weak, occur in similar contexts. Recent studies focuses on learning word embeddings for specific tasks, such as sentiment analysis (Tang et al., 2014) and dependency parsing (Bansal et al., 2014; Chen et al., 2014). These motivate a new approach to learn word embeddings to capture antonyms. In this paper, we propose a novel approach to construct word embeddings that can capture antonyms. Unlike the previous approaches, our approach directly trains word embeddings to represent antonyms. We propose two models: a Word Embedding on Thesauri information (WE-T) model and a Word Embeddings on Thesauri and Distributional information (WE-TD) model. The WE-T model receives supervised information from synonym and antonym pairs in thesauri and infers t"
N15-1100,P10-1040,0,0.15866,"Missing"
N15-1100,D12-1111,0,0.28028,"Missing"
N15-1100,D14-1161,0,0.759904,"hich had the lowest similarity among them. When the model did not contain any words in a question, the question was left unanswered. 3.1.2 Resource for training (5) + Bw,c log σ(−sim(w, c))} Here, the coefficients Aw,c and Bw,c are sums of corresponding coefficients in Equation 4. These terms can be pre-calculated by using the number of appearances of contextual word pairs, unigram distributions, and synonym and antonym pairs in thesauri. 986 For supervised dataset, we used synonym and antonym pairs in two thesauri: WordNet (Miller, 1995) and Roget (Kipfer, 2009). These pairs were provided by Zhang et al. (2014)1 . There were 52,760 entries (words), each of which had 11.7 synonyms on average, and 21,319 entries, each of which had 6.5 antonyms on average. 1 https://github.com/iceboal/ word-representations-bptf Encarta lookup† WordNet & Roget lookup¶ WE-T WordNet + Affix heuristics + Adjacent category annotation§ WE-D Encarta PILSA + S2Net + Embedding† WordNet & Roget BPTF‡ WE-TD Prec. 0.65 1.00 0.92 Dev. Set Rec. F 0.61 0.63 0.49 0.66 0.71 0.80 Test Set (950) Prec. Rec. F 0.61 0.56 0.59 0.98 0.45 0.62 0.90 0.72 0.80 Test Set (790) Prec. Rec. F — — — 0.98 0.45 0.61 0.90 0.72 0.80 0.79 0.66 0.72 — — — 0"
P16-1105,P11-1056,0,0.017295,"ettings as Li and Ji (2014). We report the primary micro F1-scores as well as micro precision and recall on both entity and relation extraction to better explain model performance. We treat an entity as correct when its type and the region of its head are correct. We treat a relation as correct when its type and argument entities are correct; we thus treat all non-negative relations on wrong entities as false positives. ACE04 defines the same 7 coarse-grained entity types as ACE05 (Doddington et al., 2004), but defines 7 coarse-grained relation types. We follow the cross-validation setting of Chan and Roth (2011) and Li and Ji (2014), and the preprocessing and evaluation metrics of ACE05. SemEval-2010 Task 8 defines 9 relation types between nominals and a tenth type Other when two nouns have none of these relations (Hendrickx et al., 2010). We treat this Other type as a negative relation type, and no direction is considered. The dataset consists of 8,000 training and 2,717 test sentences, and each sentence is annotated with a relation between two given nominals. We randomly selected 800 sentences from the training set as our development set. We followed the official task setting, and report the offici"
P16-1105,D14-1082,0,0.0567617,"rection is considered. The dataset consists of 8,000 training and 2,717 test sentences, and each sentence is annotated with a relation between two given nominals. We randomly selected 800 sentences from the training set as our development set. We followed the official task setting, and report the official macro-averaged F1-score (Macro-F1) on the 9 relation types. For more details of the data and task settings, please refer to the supplementary material. 4.2 Experimental Settings We implemented our model using the cnn library.6 We parsed the texts using the Stanford neural dependency parser7 (Chen and Manning, 2014) with the original Stanford Dependencies. Based on preliminary tuning, we fixed embedding dimensions nw to 200, np , nd , ne to 25, and dimensions of intermediate layers (nls , nlt of LSTM-RNNs and nhe , nhr of hidden layers) to 100. We initialized word vectors via word2vec (Mikolov et al., 2013) trained on Wikipedia8 and randomly initialized all other parameters. We tuned hyper-parameters using development sets for ACE05 and SemEval2010 Task 8 to achieve high primary (Micro- and Macro-) F1-scores.9 For ACE04, we directly employed the best parameters for ACE05. The hyperparameter settings are"
P16-1105,W06-1670,0,0.0133803,"ee), FullTree performs significantly worse than other structures regardless of whether or not we distinguish the nodes in the shortest paths from the other nodes, which hints that the information outside of the shortest path significantly hurts the performance (p&lt;0.05). We also compare our treestructured LSTM-RNN (SPTree) with sequencebased LSTM-RNNs (SPSeq and SPXu) and treestructured LSTM-RNNs (Child-Sum). All these LSTM-RNNs perform slightly worse than our SP12 When incorporating WordNet information into our model, we prepared embeddings for WordNet hypernyms extracted by SuperSenseTagger (Ciaramita and Altun, 2006) and concatenated the embeddings to the input vector (the concatenation of word and POS embeddings) of the sequence LSTM. We tuned the dimension of the WordNet embeddings and set it to 15 using the development dataset. 1112 Settings SPTree −Hidden layer −Sequence layer −Pair −Pair, Sequence layer Stanford PCFG +WordNet Left-to-right candidates Neg. sampling (Xu et al., 2015a) Macro-F1 0.851 0.839 0.840 0.844 0.827∗ 0.844 0.854 0.843 0.848 mance, but the difference was small and hence the creation of right-to-left candidates was not critical. Treating the inverse relation candidate as a negativ"
P16-1105,doddington-etal-2004-automatic,0,0.221885,"ypes and 6 coarse-grained relation types between entities. We use the same data splits, preprocessing, and task settings as Li and Ji (2014). We report the primary micro F1-scores as well as micro precision and recall on both entity and relation extraction to better explain model performance. We treat an entity as correct when its type and the region of its head are correct. We treat a relation as correct when its type and argument entities are correct; we thus treat all non-negative relations on wrong entities as false positives. ACE04 defines the same 7 coarse-grained entity types as ACE05 (Doddington et al., 2004), but defines 7 coarse-grained relation types. We follow the cross-validation setting of Chan and Roth (2011) and Li and Ji (2014), and the preprocessing and evaluation metrics of ACE05. SemEval-2010 Task 8 defines 9 relation types between nominals and a tenth type Other when two nouns have none of these relations (Hendrickx et al., 2010). We treat this Other type as a negative relation type, and no direction is considered. The dataset consists of 8,000 training and 2,717 test sentences, and each sentence is annotated with a relation between two given nominals. We randomly selected 800 sentenc"
P16-1105,P15-1061,0,0.498544,"ing via neural network (NN) based models. There are two ways to represent relations between entities using neural networks: recurrent/recursive neural networks (RNNs) and convolutional neural networks (CNNs). Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015). Despite this representation ability, for relation classification tasks, the previously reported performance using long short-term memory (LSTM) based RNNs (Xu et al., 2015b; Li et al., 2015) is worse than one using CNNs (dos Santos et al., 2015). These previous LSTM-based systems mostly include limited linguistic structures and neural architectures, and do not model entities and relations jointly. We are able to achieve improvements over state-of-the-art models via endto-end modeling of entities and relations based on richer LSTM-RNN architectures that incorporate complementary linguistic structures. Word sequence and tree structure are known to be complementary information for extracting relations. For instance, dependencies between words 1105 Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, p"
P16-1105,W01-0722,0,0.351558,"ities is in turn encouraged by the presence of the context words transferred to, which indicate an employment relation. Previous joint models have employed feature-based structured learning. An alternative approach to this end-to-end relation extraction task is to employ automatic feature learning via neural network (NN) based models. There are two ways to represent relations between entities using neural networks: recurrent/recursive neural networks (RNNs) and convolutional neural networks (CNNs). Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015). Despite this representation ability, for relation classification tasks, the previously reported performance using long short-term memory (LSTM) based RNNs (Xu et al., 2015b; Li et al., 2015) is worse than one using CNNs (dos Santos et al., 2015). These previous LSTM-based systems mostly include limited linguistic structures and neural architectures, and do not model entities and relations jointly. We are able to achieve improvements over state-of-the-art models via endto-end modeling of entities and relations based on richer LSTM-RNN archit"
P16-1105,W03-0426,0,0.139057,"tion (SemEval-2010 Task 8), our model compares favorably to the state-of-the-art CNNbased model in F1-score. Finally, we also ablate and compare our various model components, which leads to some key findings (both positive and negative) about the contribution and effectiveness of different RNN structures, input dependency relation structures, different parsing models, external resources, and joint learning settings. 2 Related Work LSTM-RNNs have been widely used for sequential labeling, such as clause identification (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003). Recently, Huang et al. (2015) showed that building a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs comparably to the state-of-the-art methods in the partof-speech (POS) tagging, chunking, and NER. For relation classification, in addition to traditional feature/kernel-based approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al., 2010), including embedding-based models (Hashimoto et al., 2015), CNN-based models (dos Santos et al., 2015), and RNN-based models (Socher et"
P16-1105,K15-1027,1,0.788974,"cation (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003). Recently, Huang et al. (2015) showed that building a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs comparably to the state-of-the-art methods in the partof-speech (POS) tagging, chunking, and NER. For relation classification, in addition to traditional feature/kernel-based approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al., 2010), including embedding-based models (Hashimoto et al., 2015), CNN-based models (dos Santos et al., 2015), and RNN-based models (Socher et al., 2012). Recently, Xu et al. (2015a) and Xu et al. (2015b) showed that the shortest dependency paths between relation arguments, which were used in feature/kernel-based systems (Bunescu and Mooney, 2005), are also useful in NN-based models. Xu et al. (2015b) also showed that LSTMRNNs are useful for relation classification, but the performance was worse than CNN-based models. Li et al. (2015) compared separate sequence-based and tree-structured LSTM-RNNs on relation classification, using basic RNN model structures."
P16-1105,S10-1006,0,0.0387369,"Missing"
P16-1105,W10-2924,0,0.0935209,"al such novel model structures and training settings, investigating the simultaneous use of bidirectional sequential and bidirectional tree-structured LSTM-RNNs to jointly capture linear and dependency context for end-toend extraction of relations between entities. As for end-to-end (joint) extraction of relations between entities, all existing models are featurebased systems (and no NN-based model has been proposed). Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al., 2013). Among these, structured prediction methods are state-of-the-art on several corpora. We present an improved, NN-based alternative for the end-to-end relation extraction. 1106 neural net / softmax dropout PHYS Dependency (Relation) softmax LSTM unit tanh embeddings hidden label embeddings Sequence (Entity) B-PER born L-PER in Yates softmax tanh tanh Chicago Bi-TreeLSTM hidden ・・・ ・・・ dependency embeddings Bi-LSTM word/POS embeddings In 1909 nsubjpass , Sidney Yates was pobj prep born in Chicago . Fig. 1: Our incr"
P16-1105,P14-1038,0,0.849273,"8). Finally, we present an extensive ablation analysis of several model components. 1 Introduction Extracting semantic relations between entities in text is an important and well-studied task in information extraction and natural language processing (NLP). Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end (joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information. For instance, to learn that Toefting and Bolton have an OrganizationAffiliation (ORG-AFF) relation in the sentence Toefting transferred to Bolton, the entity information that Toefting and Bolton are Person and Organization entities is important. Extraction of these entities is in turn encouraged by the presence of the context words transferred to, which indicate an employment relation. Previous joint models have employed feature-based structured learning. An alternative approach to this end-to-end relation extra"
P16-1105,D15-1278,0,0.177916,"xtraction task is to employ automatic feature learning via neural network (NN) based models. There are two ways to represent relations between entities using neural networks: recurrent/recursive neural networks (RNNs) and convolutional neural networks (CNNs). Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015). Despite this representation ability, for relation classification tasks, the previously reported performance using long short-term memory (LSTM) based RNNs (Xu et al., 2015b; Li et al., 2015) is worse than one using CNNs (dos Santos et al., 2015). These previous LSTM-based systems mostly include limited linguistic structures and neural architectures, and do not model entities and relations jointly. We are able to achieve improvements over state-of-the-art models via endto-end modeling of entities and relations based on richer LSTM-RNN architectures that incorporate complementary linguistic structures. Word sequence and tree structure are known to be complementary information for extracting relations. For instance, dependencies between words 1105 Proceedings of the 54th Annual Meet"
P16-1105,D15-1102,0,0.0159106,"Missing"
P16-1105,D14-1200,1,0.90077,"resent an extensive ablation analysis of several model components. 1 Introduction Extracting semantic relations between entities in text is an important and well-studied task in information extraction and natural language processing (NLP). Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end (joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information. For instance, to learn that Toefting and Bolton have an OrganizationAffiliation (ORG-AFF) relation in the sentence Toefting transferred to Bolton, the entity information that Toefting and Bolton are Person and Organization entities is important. Extraction of these entities is in turn encouraged by the presence of the context words transferred to, which indicate an employment relation. Previous joint models have employed feature-based structured learning. An alternative approach to this end-to-end relation extraction task is to employ"
P16-1105,W09-1119,0,0.477485,"n ACE2005 and ACE2004, respectively. We also show that our LSTMRNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components. 1 Introduction Extracting semantic relations between entities in text is an important and well-studied task in information extraction and natural language processing (NLP). Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end (joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information. For instance, to learn that Toefting and Bolton have an OrganizationAffiliation (ORG-AFF) relation in the sentence Toefting transferred to Bolton, the entity information that Toefting and Bolton are Person and Organization entities is important. Extraction of these entities is in turn encouraged by the presence of the"
P16-1105,D12-1110,0,0.494793,"Missing"
P16-1105,P15-1150,0,0.663587,"context words transferred to, which indicate an employment relation. Previous joint models have employed feature-based structured learning. An alternative approach to this end-to-end relation extraction task is to employ automatic feature learning via neural network (NN) based models. There are two ways to represent relations between entities using neural networks: recurrent/recursive neural networks (RNNs) and convolutional neural networks (CNNs). Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015). Despite this representation ability, for relation classification tasks, the previously reported performance using long short-term memory (LSTM) based RNNs (Xu et al., 2015b; Li et al., 2015) is worse than one using CNNs (dos Santos et al., 2015). These previous LSTM-based systems mostly include limited linguistic structures and neural architectures, and do not model entities and relations jointly. We are able to achieve improvements over state-of-the-art models via endto-end modeling of entities and relations based on richer LSTM-RNN architectures that incorporate complementary linguistic st"
P16-1105,D15-1062,0,0.17918,"-to-end relation extraction task is to employ automatic feature learning via neural network (NN) based models. There are two ways to represent relations between entities using neural networks: recurrent/recursive neural networks (RNNs) and convolutional neural networks (CNNs). Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015). Despite this representation ability, for relation classification tasks, the previously reported performance using long short-term memory (LSTM) based RNNs (Xu et al., 2015b; Li et al., 2015) is worse than one using CNNs (dos Santos et al., 2015). These previous LSTM-based systems mostly include limited linguistic structures and neural architectures, and do not model entities and relations jointly. We are able to achieve improvements over state-of-the-art models via endto-end modeling of entities and relations based on richer LSTM-RNN architectures that incorporate complementary linguistic structures. Word sequence and tree structure are known to be complementary information for extracting relations. For instance, dependencies between words 1105 Proceedings of t"
P16-1105,D15-1206,0,0.240285,"-to-end relation extraction task is to employ automatic feature learning via neural network (NN) based models. There are two ways to represent relations between entities using neural networks: recurrent/recursive neural networks (RNNs) and convolutional neural networks (CNNs). Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015). Despite this representation ability, for relation classification tasks, the previously reported performance using long short-term memory (LSTM) based RNNs (Xu et al., 2015b; Li et al., 2015) is worse than one using CNNs (dos Santos et al., 2015). These previous LSTM-based systems mostly include limited linguistic structures and neural architectures, and do not model entities and relations jointly. We are able to achieve improvements over state-of-the-art models via endto-end modeling of entities and relations based on richer LSTM-RNN architectures that incorporate complementary linguistic structures. Word sequence and tree structure are known to be complementary information for extracting relations. For instance, dependencies between words 1105 Proceedings of t"
P16-1105,P13-1161,0,0.0106233,"dependency tree information. We propose several such novel model structures and training settings, investigating the simultaneous use of bidirectional sequential and bidirectional tree-structured LSTM-RNNs to jointly capture linear and dependency context for end-toend extraction of relations between entities. As for end-to-end (joint) extraction of relations between entities, all existing models are featurebased systems (and no NN-based model has been proposed). Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al., 2013). Among these, structured prediction methods are state-of-the-art on several corpora. We present an improved, NN-based alternative for the end-to-end relation extraction. 1106 neural net / softmax dropout PHYS Dependency (Relation) softmax LSTM unit tanh embeddings hidden label embeddings Sequence (Entity) B-PER born L-PER in Yates softmax tanh tanh Chicago Bi-TreeLSTM hidden ・・・ ・・・ dependency embeddings Bi-LSTM word/POS embeddings In 1909 nsubjpass , Sidney Yates wa"
P16-1105,C10-2160,0,0.0278642,"the simultaneous use of bidirectional sequential and bidirectional tree-structured LSTM-RNNs to jointly capture linear and dependency context for end-toend extraction of relations between entities. As for end-to-end (joint) extraction of relations between entities, all existing models are featurebased systems (and no NN-based model has been proposed). Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al., 2013). Among these, structured prediction methods are state-of-the-art on several corpora. We present an improved, NN-based alternative for the end-to-end relation extraction. 1106 neural net / softmax dropout PHYS Dependency (Relation) softmax LSTM unit tanh embeddings hidden label embeddings Sequence (Entity) B-PER born L-PER in Yates softmax tanh tanh Chicago Bi-TreeLSTM hidden ・・・ ・・・ dependency embeddings Bi-LSTM word/POS embeddings In 1909 nsubjpass , Sidney Yates was pobj prep born in Chicago . Fig. 1: Our incrementally-decoded end-to-end relation extraction model, with"
P16-1105,P05-1053,0,0.960797,"d model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components. 1 Introduction Extracting semantic relations between entities in text is an important and well-studied task in information extraction and natural language processing (NLP). Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end (joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information. For instance, to learn that Toefting and Bolton have an OrganizationAffiliation (ORG-AFF) relation in the sentence Toefting transferred to Bolton, the entity information that Toefting and Bolton are Person and Organization entities is important. Extraction of these entities is in turn encouraged by the presence of the context words transferred to, which indicate an employment relati"
P16-1105,W09-2415,0,\N,Missing
P16-1105,H05-1091,0,\N,Missing
P18-2014,P15-1061,0,0.273121,"Missing"
P18-2014,D15-1062,0,0.0818755,"dge graphs (KG) for knowledge graph completion (Jiang et al., 2017) and the creation of knowledge graph embeddings (Wang et al., 2017; Shi and Weninger, 2017). These models rely on paths between existing relations in order to infer new associations between entities in KGs. However, for relation extraction from a sentence, related pairs are not predefined and consequently all entity pairs need to be considered to extract relations. In addition, state-of-the-art RE models sometimes depend on external syntactic tools to build the shortest dependency path (SDP) between two entities in a sentence (Xu et al., 2015; Miwa and Bansal, 2016). This dependence on external tools leads to domain dependent models. Introduction Relation extraction (RE) is a task of identifying typed relations between known entity mentions in a sentence. Most existing RE models treat each relation in a sentence individually (Miwa and Bansal, 2016; Nguyen and Grishman, 2015). However, a sentence typically contains multiple relations between entity mentions. RE models need to consider these pairs simultaneously to model the dependencies among them. The relation between a pair of interest (namely “target” pair) can be influenced by"
P18-2014,C16-1138,0,0.029902,"/tticoin/LSTM-ER 4 84 The authors kindly provided us with the data split. # Entities l=1 l=2 l=4 l=8 2 3 [4, 6) [6, 12) [12, 23) 71.2 70.1 56.5 59.2 54.7 69.8 67.5 59.7 64.2∗ 59.3 72.9 67.8 59.3 62.2 62.3∗ 71.0 63.5∗ 59.9 60.4 55.0 able to encode linguistic and syntactic properties of long word sequences, making them preferable for sequence-related tasks, e.g. natural language generation (Goyal et al., 2016), machine translation (Sutskever et al., 2014). State-of-the-art systems have proved to achieve good performance on relation extraction using RNNs (Cai et al., 2016; Miwa and Bansal, 2016; Xu et al., 2016; Liu et al., 2015). Nevertheless, most approaches do not take into consideration the dependencies between relations in a single sentence (dos Santos et al., 2015; Nguyen and Grishman, 2015) and treat each pair separately. Current graph-based models are applied on knowledge graphs for distantly supervised relation extraction (Zeng et al., 2017). Graphs are defined on semantic types in their method, whereas we built entity-based graphs in sentences. Other approaches also treat multiple relations in a sentence (Gupta et al., 2016; Miwa and Sasaki, 2014; Li and Ji, 2014), but they fail to model l"
P18-2014,D17-1186,0,0.0762816,"Missing"
P18-2014,P16-2034,0,0.126561,"ntic type representation tz and two relative position representations: to target entity ei , pzi and to target entity ej , pzj . The final representation for a context word wz of a target pair is, vijz = [ez ; tz ; pzi ; pzj ]. For a sentence, the context representations for all entity pairs can be expressed as a three-dimensional matrix C, where rows and columns correspond to entities and the depth corresponds to the context words. The context words representations of each target pair are then compiled into a single representation with an attention mechanism. Following the method proposed in Zhou et al. (2016), we calculate weights for the context words of the targetpair and compute their weighted average, 2.4 Our main aim is to support the relation between an entity pair by using chains of intermediate relations between the pair entities. Thus, the goal of this layer is to generate a single representation for a finite number of different lengths walks between two target entities. To achieve this, we represent a sentence as a directed graph, where the entities constitute the graph nodes and edges correspond to the representation of the relation between the two nodes. The representation of one-lengt"
P18-2108,C14-1220,0,0.0460064,"f databases with high coverage and quick update to help medical experts. Deep neural network-based methods have recently drawn a considerable attention (Liu et al., 2016; Sahu and Anand, 2017; Zheng et al., 2017; Lim et al., 2018) since they show state-of-the-art performance without manual feature engineering. In parallel to the progress in DDI extraction from texts, Graph Convolutional Networks (GCNs) have been proposed and applied to estimate physical and chemical properties of molec2 2.1 Methods Text-based DDI Extraction Our model for extracting DDIs from texts is based on the CNN model by Zeng et al. (2014). When an input sentence S = (w1 , w2 , · · · , wN ) is given, We prepare word embedding wiw of wi and word 680 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 680–685 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics Figure 1: Overview of the proposed model p p position embeddings wi,1 and wi,2 that correspond to the relative positions from the first and second target entities, respectively. We concatenate these embeddings as in Equation (1), and we use the resulting vector as the input to t"
P18-2108,S13-2056,0,0.0856803,"Missing"
P19-1423,D14-1181,0,0.00942432,"stracts annotated with several biomedical named entities from PubMed. We selected chemical compounds from the annotated entities and aligned them with the graph database Biochem4j (Swainston et al., 2017). Biochem4j is a freely available database that integrates several resources such as 4311 2 http://www.nactem.ac.uk/Thalia/ Data CDR CHR Count # Articles # Positive pairs # Negative pairs # Articles # Positive pairs # Negative pairs Train 500 1,038 4,198 7,298 19,643 69,843 Dev. 500 1,012 4,069 1,182 3,185 11,466 Test 500 1,066 4,119 3,614 9,578 33,339 models: CNN-RE, a re-implementation from Kim (2014) and Zhou et al. (2016a) and RNN-RE, a reimplementation from Sahu and Anand (2018). In all models we use bi-affine pairwise scoring to detect relations. 3.4 Table 1: Statistics of the CDR and CHR datasets. UniProt, KEGG and NCBI Taxonomy3 . If two chemical entities have a relation in Biochem4j, we consider them as positive instances in the dataset, otherwise as negative. 3.2 Data Pre-processing Table 1 shows the statistics for CDR and CHR datasets. For both datasets, the annotated entities can have more than one associated Knowledge Base (KB) ID. If there is at least one common KB ID between m"
P19-1423,P16-1200,0,0.0589536,"ees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt. RNNs and CNNs, which are often used for intra-sentence RE (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016b; Lin et al., 2016), are not effective on longer sequences (Sahu and Anand, 2018) thus failing to capture such non-local dependencies. We propose a novel inter-sentence RE model that builds a labelled edge Graph CNN (GCNN) model (Marcheggiani and Titov, 2017) on a document-level graph. The graph nodes correspond to words and edges represent local and nonlocal dependencies among them. The documentlevel graph is formed by connecting words with local dependencies from syntactic parsing and sequential information, as well as non-local dependencies from coreference resolution and other semantic dependencies (Peng et"
P19-1423,P15-2047,0,0.0321442,"ties often span across multiple sentences. In order to extract inter-sentence relations, most approaches utilise distant supervision to automatically generate document-level corpora (Peng et al., 2017; Song et al., 2018). Recently, Verga et al. (2018) introduced multi-instance learning (MIL) (Riedel et al., 2010; Surdeanu et al., 2012) to treat multiple mentions of target entities in a document. Inter-sentential relations depend not only on local but also on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt. RNNs and CNNs, which are often used for intra-sentence RE (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016b; Lin et al., 2016), are not effective on longer sequences (Sahu and Anand, 2018) thus failing to capture such non-loca"
P19-1423,N16-1116,0,0.0654007,"Missing"
P19-1423,P14-5010,0,0.00430317,"Gu et al. (2017) and Verga et al. (2018). In the CHR dataset, both directions were generated for each candidate chemical pair as chemicals can be either a reactant (first argument) or a product (second argument) in an interaction. We processed the datasets using the GENIA Sentence Splitter4 and GENIA tagger (Tsuruoka et al., 2005) for sentence splitting and word tokenisation, respectively. Syntactic dependencies were obtained using the Enju syntactic parser (Miyao and Tsujii, 2008) with predicate-argument structures. Coreference type edges were constructed using the Stanford CoreNLP software (Manning et al., 2014). 3.3 Baseline Models For the CDR dataset, we compare with five stateof-the-art models: SVM (Xu et al., 2016b), ensemble of feature-based and neural-based models (Zhou et al., 2016a), CNN and Maximum Entropy (Gu et al., 2017), Piece-wise CNN (Li et al., 2018) and Transformer (Verga et al., 2018). We additionally prepare and evaluate the following 3 http://biochem4j.org http://www.nactem.ac.uk/y-matsu/ geniass/ 4 Model Training We used 100-dimentional word embeddings trained on PubMed with GloVe (Pennington et al., 2014; TH et al., 2015). Unlike Verga et al. (2018), we used the pre-trained word"
P19-1423,D17-1159,0,0.541903,"e for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt. RNNs and CNNs, which are often used for intra-sentence RE (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016b; Lin et al., 2016), are not effective on longer sequences (Sahu and Anand, 2018) thus failing to capture such non-local dependencies. We propose a novel inter-sentence RE model that builds a labelled edge Graph CNN (GCNN) model (Marcheggiani and Titov, 2017) on a document-level graph. The graph nodes correspond to words and edges represent local and nonlocal dependencies among them. The documentlevel graph is formed by connecting words with local dependencies from syntactic parsing and sequential information, as well as non-local dependencies from coreference resolution and other semantic dependencies (Peng et al., 2017). We infer relations between entities using MIL-based bi-affine pairwise scoring function (Verga et al., 2018) on the entity node representations. Our contribution is threefold. Firstly, we pro4309 Proceedings of the 57th Annual M"
P19-1423,P16-1105,1,0.795081,"i , d2i , respectively. As entities can have more than one mention, we calculate the relative position of a word from the closest target entity mention. For each word i, we concatenate the word and position representations into an input representation, xi = [wi ; d1i ; d2i ]. 2.2 Graph Construction In order to build a document-level graph for an entire abstract, we use the following categories of inter- and intra-sentence dependency edges, as shown with different colours in Figure 2. Syntactic dependency edge: The syntactic structure of a sentence reveals helpful clues for intrasentential RE (Miwa and Bansal, 2016). We thus use labelled syntactic dependency edges between the words of each sentence, by treating each syntactic dependency label as a different edge type. Coreference edge: As coreference is an important indicator of local and non-local dependencies (Ma et al., 2016), we connect co-referring phrases in a document using coreference type edges. Adjacent sentence edge: We connect the syntactic root of a sentence with the roots of the previous and next sentences with adjacent sentence type edges (Peng et al., 2017) for non-local dependencies between neighbouring sentences. Adjacent word edge: In"
P19-1423,J08-1002,0,0.0497906,"wn KB ID and removed relations between the same entity (self-relations). For the CDR dataset, we performed hypernym filtering similar to Gu et al. (2017) and Verga et al. (2018). In the CHR dataset, both directions were generated for each candidate chemical pair as chemicals can be either a reactant (first argument) or a product (second argument) in an interaction. We processed the datasets using the GENIA Sentence Splitter4 and GENIA tagger (Tsuruoka et al., 2005) for sentence splitting and word tokenisation, respectively. Syntactic dependencies were obtained using the Enju syntactic parser (Miyao and Tsujii, 2008) with predicate-argument structures. Coreference type edges were constructed using the Stanford CoreNLP software (Manning et al., 2014). 3.3 Baseline Models For the CDR dataset, we compare with five stateof-the-art models: SVM (Xu et al., 2016b), ensemble of feature-based and neural-based models (Zhou et al., 2016a), CNN and Maximum Entropy (Gu et al., 2017), Piece-wise CNN (Li et al., 2018) and Transformer (Verga et al., 2018). We additionally prepare and evaluate the following 3 http://biochem4j.org http://www.nactem.ac.uk/y-matsu/ geniass/ 4 Model Training We used 100-dimentional word embed"
P19-1423,Q17-1008,0,0.355248,"Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction. 1 Figure 1: Sentences with non-local dependencies between named entities. The red arrow represents a relation between co-referred entities and yellow arrows represent semantically dependent relations. Example adapted from the CDR dataset (Wei et al., 2015). Introduction Semantic relationships between named entities often span across multiple sentences. In order to extract inter-sentence relations, most approaches utilise distant supervision to automatically generate document-level corpora (Peng et al., 2017; Song et al., 2018). Recently, Verga et al. (2018) introduced multi-instance learning (MIL) (Riedel et al., 2010; Surdeanu et al., 2012) to treat multiple mentions of target entities in a document. Inter-sentential relations depend not only on local but also on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different depend"
P19-1423,D14-1162,0,0.0912602,"Coreference type edges were constructed using the Stanford CoreNLP software (Manning et al., 2014). 3.3 Baseline Models For the CDR dataset, we compare with five stateof-the-art models: SVM (Xu et al., 2016b), ensemble of feature-based and neural-based models (Zhou et al., 2016a), CNN and Maximum Entropy (Gu et al., 2017), Piece-wise CNN (Li et al., 2018) and Transformer (Verga et al., 2018). We additionally prepare and evaluate the following 3 http://biochem4j.org http://www.nactem.ac.uk/y-matsu/ geniass/ 4 Model Training We used 100-dimentional word embeddings trained on PubMed with GloVe (Pennington et al., 2014; TH et al., 2015). Unlike Verga et al. (2018), we used the pre-trained word embeddings in place of sub-word embeddings to align with our word graphs. Due to the size of the CDR dataset, we merged the training and development sets to train the models, similarly to Xu et al. (2016a) and Gu et al. (2017). We report the performance as the average of five runs with different parameter initialisation seeds in terms of precision (P), recall (R) and F1-score. We used the frequencies of the edge types in the training set to choose the top-N edges in Section 2.3. We refer to the supplementary materials"
P19-1423,P15-1061,0,0.0383207,"on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt. RNNs and CNNs, which are often used for intra-sentence RE (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016b; Lin et al., 2016), are not effective on longer sequences (Sahu and Anand, 2018) thus failing to capture such non-local dependencies. We propose a novel inter-sentence RE model that builds a labelled edge Graph CNN (GCNN) model (Marcheggiani and Titov, 2017) on a document-level graph. The graph nodes correspond to words and edges represent local and nonlocal dependencies among them. The documentlevel graph is formed by connecting words with local dependencies from syntactic parsing and sequential information, as well as non-local dependencies from coreference resolution an"
P19-1423,D18-1246,0,0.108412,"that all the types in the graph are effective for inter-sentence relation extraction. 1 Figure 1: Sentences with non-local dependencies between named entities. The red arrow represents a relation between co-referred entities and yellow arrows represent semantically dependent relations. Example adapted from the CDR dataset (Wei et al., 2015). Introduction Semantic relationships between named entities often span across multiple sentences. In order to extract inter-sentence relations, most approaches utilise distant supervision to automatically generate document-level corpora (Peng et al., 2017; Song et al., 2018). Recently, Verga et al. (2018) introduced multi-instance learning (MIL) (Riedel et al., 2010; Surdeanu et al., 2012) to treat multiple mentions of target entities in a document. Inter-sentential relations depend not only on local but also on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1"
P19-1423,P16-1220,0,0.0434194,"Missing"
P19-1423,D12-1042,0,0.041194,"non-local dependencies between named entities. The red arrow represents a relation between co-referred entities and yellow arrows represent semantically dependent relations. Example adapted from the CDR dataset (Wei et al., 2015). Introduction Semantic relationships between named entities often span across multiple sentences. In order to extract inter-sentence relations, most approaches utilise distant supervision to automatically generate document-level corpora (Peng et al., 2017; Song et al., 2018). Recently, Verga et al. (2018) introduced multi-instance learning (MIL) (Riedel et al., 2010; Surdeanu et al., 2012) to treat multiple mentions of target entities in a document. Inter-sentential relations depend not only on local but also on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the"
P19-1423,K17-1045,0,0.0152641,"in comparison with the state-of-the-art. tions. They restricted the relation candidates in up to two-span sentences. Verga et al. (2018) considered multi-instance learning for document-level RE. Our work is different from Verga et al. (2018) in that we replace Transformer with a GCNN model for full-abstract encoding using non-local dependencies such as entity coreference. GCNN was firstly proposed by Kipf and Welling (2017) and applied on citation networks and knowledge graph datasets. It was later used for semantic role labelling (Marcheggiani and Titov, 2017), multi-document summarization (Yasunaga et al., 2017) and temporal relation extraction (Vashishth et al., 2018). Zhang et al. (2018) used a GCNN on a dependency tree for intrasentence RE. Unlike previous work, we introduced a GCNN on a document-level graph, with both intra- and inter-sentence dependencies for intersentence RE. 6 Conclusion Figure 3: Performance of GCNN model on the CDR development set when using the top-N most frequent edge types and consider the rest as a single “rare” type. Model GCNN (best) − Adjacent word − Syntactic dependency − Coreference − Self-node − Adjacent sentence Overall 57.19 55.75 56.12 56.44 56.85 57.00 Intra 63"
P19-1423,C14-1220,0,0.293244,"only on local but also on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt. RNNs and CNNs, which are often used for intra-sentence RE (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016b; Lin et al., 2016), are not effective on longer sequences (Sahu and Anand, 2018) thus failing to capture such non-local dependencies. We propose a novel inter-sentence RE model that builds a labelled edge Graph CNN (GCNN) model (Marcheggiani and Titov, 2017) on a document-level graph. The graph nodes correspond to words and edges represent local and nonlocal dependencies among them. The documentlevel graph is formed by connecting words with local dependencies from syntactic parsing and sequential information, as well as non-local dependencies from"
P19-1423,W15-3820,1,0.847899,"ere constructed using the Stanford CoreNLP software (Manning et al., 2014). 3.3 Baseline Models For the CDR dataset, we compare with five stateof-the-art models: SVM (Xu et al., 2016b), ensemble of feature-based and neural-based models (Zhou et al., 2016a), CNN and Maximum Entropy (Gu et al., 2017), Piece-wise CNN (Li et al., 2018) and Transformer (Verga et al., 2018). We additionally prepare and evaluate the following 3 http://biochem4j.org http://www.nactem.ac.uk/y-matsu/ geniass/ 4 Model Training We used 100-dimentional word embeddings trained on PubMed with GloVe (Pennington et al., 2014; TH et al., 2015). Unlike Verga et al. (2018), we used the pre-trained word embeddings in place of sub-word embeddings to align with our word graphs. Due to the size of the CDR dataset, we merged the training and development sets to train the models, similarly to Xu et al. (2016a) and Gu et al. (2017). We report the performance as the average of five runs with different parameter initialisation seeds in terms of precision (P), recall (R) and F1-score. We used the frequencies of the edge types in the training set to choose the top-N edges in Section 2.3. We refer to the supplementary materials for the details o"
P19-1423,D18-1244,0,0.16069,"idates in up to two-span sentences. Verga et al. (2018) considered multi-instance learning for document-level RE. Our work is different from Verga et al. (2018) in that we replace Transformer with a GCNN model for full-abstract encoding using non-local dependencies such as entity coreference. GCNN was firstly proposed by Kipf and Welling (2017) and applied on citation networks and knowledge graph datasets. It was later used for semantic role labelling (Marcheggiani and Titov, 2017), multi-document summarization (Yasunaga et al., 2017) and temporal relation extraction (Vashishth et al., 2018). Zhang et al. (2018) used a GCNN on a dependency tree for intrasentence RE. Unlike previous work, we introduced a GCNN on a document-level graph, with both intra- and inter-sentence dependencies for intersentence RE. 6 Conclusion Figure 3: Performance of GCNN model on the CDR development set when using the top-N most frequent edge types and consider the rest as a single “rare” type. Model GCNN (best) − Adjacent word − Syntactic dependency − Coreference − Self-node − Adjacent sentence Overall 57.19 55.75 56.12 56.44 56.85 57.00 Intra 63.43 62.53 62.89 63.27 63.84 63.99 Inter 36.90 35.61 34.75 35.65 33.20 35.20 Tab"
P19-1423,P18-1149,0,0.0734011,"ge types. Hence, to include the node information itself into the representation, we form selfnode type edges on all the nodes of the graph. 2.3 GCNN Layer We compute the representation of each input word i by applying GCNN (Kipf and Welling, 2017; Defferrard et al., 2016) on the constructed document graph. GCNN is an advanced version of CNN for graph encoding that learns semantic representations for the graph nodes, while preserving its structural information. In order to learn edge type-specific representations, we use a labelled edge GCNN, which keeps separate parameters for each edge type (Vashishth et al., 2018). The GCNN iteratively updates the representation of each input word i as follows:    X  k xk+1 =f Wl(i,u) xku + bkl(i,u)  , i u∈ν(i) where xk+1 is the i-th word representation rei sulted from the k-th GCNN block, ν(i) is a set k of neighbouring nodes to i, Wl(i,u) and bkl(i,u) are the parameters of the k-th block for edge type l between nodes i and u. We stack K GCNN blocks to accumulate information from distant neighbouring nodes and use edge-wise gating to control information from neighbouring nodes. Similar to Marcheggiani and Titov (2017), we maintain separate parameters for each ed"
P19-1423,P16-2034,0,0.641295,"ncies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case between Oxytocin and hypotension. To capture their relation, it is essential to connect the co-referring entities Oxytocin and Oxt. RNNs and CNNs, which are often used for intra-sentence RE (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016b; Lin et al., 2016), are not effective on longer sequences (Sahu and Anand, 2018) thus failing to capture such non-local dependencies. We propose a novel inter-sentence RE model that builds a labelled edge Graph CNN (GCNN) model (Marcheggiani and Titov, 2017) on a document-level graph. The graph nodes correspond to words and edges represent local and nonlocal dependencies among them. The documentlevel graph is formed by connecting words with local dependencies from syntactic parsing and sequential information, as well as non-local dependencies from coreference resolution and other semantic de"
P19-1423,N18-1080,0,0.297141,"h are effective for inter-sentence relation extraction. 1 Figure 1: Sentences with non-local dependencies between named entities. The red arrow represents a relation between co-referred entities and yellow arrows represent semantically dependent relations. Example adapted from the CDR dataset (Wei et al., 2015). Introduction Semantic relationships between named entities often span across multiple sentences. In order to extract inter-sentence relations, most approaches utilise distant supervision to automatically generate document-level corpora (Peng et al., 2017; Song et al., 2018). Recently, Verga et al. (2018) introduced multi-instance learning (MIL) (Riedel et al., 2010; Surdeanu et al., 2012) to treat multiple mentions of target entities in a document. Inter-sentential relations depend not only on local but also on non-local dependencies. Dependency trees are often used to extract local dependencies of semantic relations (Culotta and Sorensen, 2004; Liu et al., 2015) in intra-sentence ∗ Corresponding author. relation extraction (RE). However, such dependencies are not adequate for inter-sentence RE, since different sentences have different dependency trees. Figure 1 illustrates such a case betwee"
P19-1423,P04-1054,0,\N,Missing
S13-2015,P07-2044,0,0.113125,"Missing"
S13-2015,J08-1002,0,0.0104023,"are extracted using Stanford coreNLP (Stanford NLP Group, 2012). • Lexical semantic information Synonyms of event word tokens from WordNet lexical database (Fellbaum, 1998) are used as features. • Event-Event information For event-event TLINKs, we use same sentence feature to differentiate pairs of events in the same sentence from pairs of events from different sentences (Chambers et al., 2007). In the case that temporal entities of a particular TLINK are in the same sentence, we extract two new types of sentence-level semantic information from a deep syntactic parser. We use the Enju parser (Miyao and Tsujii, 2008). It analyzes syntactic/semantic structures of sentences and provides phrase structures and predicate-argument structures. The features we extract from the deep parser are • Paths between event words in the phrase structure tree, and up(↑)/down(↓) lengths of paths. We use 3-grams of paths as features instead of full paths since these are too sparse. An example is shown in Figure 1. In this case, the path between the event words, estimates and worth, is VBZ↑, VX↑, VP↑, VP↑, VP, PP↓, PX↓, IN↓. The 3-grams of the path are, therefore, {VBZ↑VX↑-VP↑, VX↑-VP↑-VP↑, VP↑-VP↑-VP, VP↑-VP-PP↓, VP-PP↓-PX↓,"
S13-2015,P11-2061,0,0.0418153,"produces many unreasonable and excessive links. We thus use a machine learning approach to filter out those unreasonable links by training the model in Section 2.2 with an additional relation type, UNKNOWN, for links that satisfy the rules in Section 2.1 but do not appear in the training data. In this way, for Task C, we first extract all the links that satisfy the rules and classify the relation types of those links. After classifying temporal relations, we remove the links that are classified as UNKNOWN. 3 Evaluation The scores are calculated by the graph-based evaluation metric proposed by UzZaman and Allen (2011). We trained the models with TimeBank and AQUAINT corpora. We also trained our models on the training set with inverse relations. The performance analysis is based on 10-fold cross validation on the development data. 3.1 Task C In Task C, a system has to identify appropriate temporal links and to classify each link into one temporal relation type. For Task C evaluation, we compare the results of the models trained with and without the features from the deep parser. The results are shown in Table 1. The rule-based approach gives a very low precision. 3.2 Task C-relation-only Task C-relation-onl"
S17-2172,D14-1082,0,0.0254986,"Missing"
S17-2172,P14-1038,0,0.0260654,"the choice of appropriate pre-trained embeddings affected the performance significantly. With the best embeddings, our system was ranked third in the scenario 1 with the micro F1 score of 0.38. We also confirm that our system can produce the micro F1 score of 0.48 for the scenario 3 on the test data, and this score is close to the score of the 3rd ranked system in the task. 1 Introduction Semantic relationships between entities are useful for building knowledge bases and semantic search engines. Their automatic extraction has been widely studied in the natural language processing (NLP) field (Li and Ji, 2014; Miwa and Sasaki, 2014; Miwa and Bansal, 2016). SemEval2017 Task 10 (Augenstein et al., 2017) deals with relation extraction from scientific papers. While entity detection and relation extraction have often been treated as separate tasks, several studies show that joint treatment of these tasks can improve extraction performance on both tasks (Li and Ji, 2014; Miwa and Sasaki, 2014). We em2 System description In this section, we describe our base neural network system and pre-trained word embeddings 1 https://github.com/tticoin/LSTM-ER 985 Proceedings of the 11th International Workshop on Sem"
S17-2172,N15-1142,0,0.023463,"embeddings are frequently used for the inputs to neural network based models. It is wellknown that the performance of neural models can be improved by initializing embeddings with pretrained embeddings. Word2vec (Mikolov et al., 2013) is a widely-used toolkit to obtain such pretrained embeddings from raw texts. Word2vec implements two models: continuous bag-of-words (CBOW) and skip-gram. CBOW learns embeddings by predicting the distribution of target word from the surrounding words, while skip-gram learns embeddings by predicting the distribution of each surrounding word from the input word. Ling et al. (2015) introduced the structured skipgram model2 based on word2vec in order to consider the ordering of co-occurrence words by incorporating an attention mechanism. To investigate the effects of the pre-trained word embeddings, we employed two unlabeled data sets: Wikipedia articles3 and PubMed abstracts4 . After the preliminary experiments, we compared 100 dimensional word embeddings obtained by the skip-gram model on the Wikipedia articles and those by the structured skip-gram model on the PubMed abstracts. We used these embeddings for initialization, and we fine-tuned these embeddings during trai"
S17-2172,P16-1105,1,0.936711,"tion) corpora, but it does not depend on specific tasks and has high configurability (Miwa and Ananiadou, 2015) since it prepares a separate configuration file, where task specific settings like hyperparameters can be specified. The system was successfully applied to the end-to-end relation extraction setting (scenario 1 in the task) without modifying the original codes in our experiments, although small modifications to the inputs were required. This shows the generality of the system. Using this system, we also investigated how the pre-trained word embeddings affect the overall performance. Miwa and Bansal (2016) mostly focused on the model architectures and paid little attention to the differences in pre-trained embeddings. Our results show that selecting the appropriate initial embeddings is crucial since changing the pre-trained embeddings greatly affected the overall performance. This paper describes our TTI-COIN system that participated in SemEval-2017 Task 10. We investigated appropriate embeddings to adapt a neural end-to-end entity and relation extraction system LSTMER to this task. We participated in the full task setting of the entity segmentation, entity classification and relation classifi"
S17-2172,D14-1200,1,0.854952,"ropriate pre-trained embeddings affected the performance significantly. With the best embeddings, our system was ranked third in the scenario 1 with the micro F1 score of 0.38. We also confirm that our system can produce the micro F1 score of 0.48 for the scenario 3 on the test data, and this score is close to the score of the 3rd ranked system in the task. 1 Introduction Semantic relationships between entities are useful for building knowledge bases and semantic search engines. Their automatic extraction has been widely studied in the natural language processing (NLP) field (Li and Ji, 2014; Miwa and Sasaki, 2014; Miwa and Bansal, 2016). SemEval2017 Task 10 (Augenstein et al., 2017) deals with relation extraction from scientific papers. While entity detection and relation extraction have often been treated as separate tasks, several studies show that joint treatment of these tasks can improve extraction performance on both tasks (Li and Ji, 2014; Miwa and Sasaki, 2014). We em2 System description In this section, we describe our base neural network system and pre-trained word embeddings 1 https://github.com/tticoin/LSTM-ER 985 Proceedings of the 11th International Workshop on Semantic Evaluations (SemE"
W09-1414,W07-1033,1,\N,Missing
W10-1903,W09-1403,0,0.198686,"Missing"
W10-1903,W09-1313,1,0.711856,"applied to statements that involve the occurrence of a change in the state of an entity – even if stated as having occurred in the past, or only hypothetically – but not in cases merely discussing the state or properties of entities, even if these can serve as the basis for inference that a specific change has occurred. We found that many of the spans an2.5 Annotation results The new PTM annotation covers 157 PubMed abstracts. Following the model of the BioNLP shared task, all mentions of specific gene or gene product names in the abstracts were annotated, applying the annotation criteria of (Ohta et al., 2009). This new named entity annotation covers 1031 gene/gene product mentions, thus averaging more than six mentions per annotated abstract. In total, 422 events of which 405 are of the novel PTM 23 Event type Glycosylation Hydroxylation Methylation Acetylation Positive reg. Phosphorylation Protein modification TOTAL Count 122 103 90 90 12 3 2 422 applies a pipeline architecture consisting of three supervised classification-based modules: a trigger detector, an event edge detector, and an event detector. In evaluation on the BioNLP shared task test data, the system extracted phosphorylation events"
W10-1903,W09-1401,1,0.848379,"and the specific modified site are expected to be of more practical interest. However, we note that the greater number of multi-argument events is expected to make the dataset more challenging as an extraction target. 3 Evaluation 3.2 To estimate the capacity of the newly annotated resource to support the extraction of the targeted PTM events and the performance of current event extraction methods at open-domain PTM extraction, we performed a set of experiments using an event extraction method competitive with the state of the art, as established in the BioNLP shared task on event extraction (Kim et al., 2009a; Bj¨orne et al., 2009). 3.1 Data Preparation The corpus data was split into training and test sets on the document level with a sampling strategy that aimed to preserve a roughly 3:1 ratio of occurrences of each event type between training and test data. The test data was held out during system development and parameter selection and only applied in a single final experiment. The event extraction system was trained using the 112 abstracts of the training set, further using 24 of the abstracts Methods 6 We note that in the BioNLP shared task data, all arguments were contained within single se"
W10-1903,P06-4005,1,\N,Missing
W10-1903,P06-1128,1,\N,Missing
W10-1905,W07-1004,1,0.870303,"task, further outperforming the original system by Miwa et al. (2010). This result shows that the system applied for the comparison of syntactic parsers achieves state-of-the-art performance at event extraction. This result also shows that the system originally developed only for core events extraction can be easily extended for other arguments simply by treating the other arguments as additional arguments. 5 Related Work Many approaches for parser comparison have been proposed in the BioNLP field. Most comparisons have used gold treebanks with intermediate formats (Clegg and Shepherd, 2007; Pyysalo et al., 2007). Application-oriented parser comparison across several formats was first introduced by Miyao et al. (2009), who compared eight parsers and five formats for the protein-protein interaction (PPI) extraction task. PPI extraction, the recognition of binary relations of between proteins, is one of the most basic information extraction tasks in the BioNLP field. Our findings do not conflict with those of Miyao et al. Event extraction can be viewed as an additional extrinsic evaluation task for syntactic parsers, providing more reliable and evaluation and a broader perspective into parser performanc"
W10-1905,W04-3224,0,0.0429439,"ll and Clark, 2009)5 , and the Enju parser with the GENIA model (Miyao et al., 2009)6 . The formats are Stanford Dependencies (SD) (Figure 1), the CoNLL-X dependency format (Figure 2) and the predicate-argument structure (PAS) format used by Enju (Figure 3). With the exception of Enju, the analyses of these parsers were provided by the BioNLP 2009 Shared Task organizers. Analysis of system features in the task found that the use of parser output with one of Five parsers and three formats are adopted for the evaluation. The parsers are GDep (Sagae and Tsujii, 2007)2 , the Bikel parser (Bikel) (Bikel, 2004)3 , the Charniak-Johnson reranking parser, using David McClosky’s self-trained biomedical parsing model (MC) (McClosky, 2009)4 , the C&C CCG parser, adapted to biomedical text 1 http://www-tsujii.is.s.u-tokyo.ac.jp/ GENIA/SharedTask/ 2 http://www.cs.cmu.edu/∼sagae/parser/ gdep/ 3 http://www.cis.upenn.edu/∼dbikel/ software.html 4 http://www.cs.brown.edu/∼dmcc/ biomedical.html 5 http://svn.ask.it.usyd.edu.au/trac/ candc/ 6 http://www-tsujii.is.s.u-tokyo.ac.jp/ enju/ 38 formance on this data. However, it does not invalidate comparison within the dataset. We further note that the models do not inc"
W10-1905,W09-1402,0,0.315036,"Missing"
W10-1905,W09-1406,1,0.494963,"8.48 / 51.95 N/A 23.05 / 48.19 / 31.19 26.32 / 41.81 / 32.30 36.90 / 55.59 / 44.35 Riedel Task 2 Ours 65.77 / 75.29 / 70.21 47.56 / 49.55 / 48.54 38.24 / 53.57 / 44.62 49.48 / 61.87 / 54.99 Riedel N/A 22.35 / 46.99 / 30.29 25.75 / 40.75 / 31.56 35.86 / 54.08 / 43.12 Table 6: Comparison of Recall / Precision / F-score results on the test data set. MC with CoNLL-X format and Enju with Predicate Argument Structure in Enju format are used for the evaluation. Results on simple, binding, regulation, and all events are shown. Results by Miwa et al. (2010) (Miwa), Bj¨orne et al. (2009) (Bj¨orne), and Riedel et al. (2009) (Riedel) for Task 1 and Task 2 are shown for comparison. The best score in each result is shown in bold. semble of the three parser outputs are +0.01 for Task 1, and -0.26 for Task 2. This result suggests that adding more different parsers does not always improve the performance. The ensemble of three parser outputs, however, shows stable performance across categories, scoring in the top two for binding, regulation, and all events, in the top four for simple events. ple, is good for extracting regulation events, but produced weaker results for simple events. The ensembles of two parser output"
W10-1905,D07-1111,1,0.529816,"e in Enju format. 2.2 Parsers and Formats (C&C) (Rimell and Clark, 2009)5 , and the Enju parser with the GENIA model (Miyao et al., 2009)6 . The formats are Stanford Dependencies (SD) (Figure 1), the CoNLL-X dependency format (Figure 2) and the predicate-argument structure (PAS) format used by Enju (Figure 3). With the exception of Enju, the analyses of these parsers were provided by the BioNLP 2009 Shared Task organizers. Analysis of system features in the task found that the use of parser output with one of Five parsers and three formats are adopted for the evaluation. The parsers are GDep (Sagae and Tsujii, 2007)2 , the Bikel parser (Bikel) (Bikel, 2004)3 , the Charniak-Johnson reranking parser, using David McClosky’s self-trained biomedical parsing model (MC) (McClosky, 2009)4 , the C&C CCG parser, adapted to biomedical text 1 http://www-tsujii.is.s.u-tokyo.ac.jp/ GENIA/SharedTask/ 2 http://www.cs.cmu.edu/∼sagae/parser/ gdep/ 3 http://www.cis.upenn.edu/∼dbikel/ software.html 4 http://www.cs.brown.edu/∼dmcc/ biomedical.html 5 http://svn.ask.it.usyd.edu.au/trac/ candc/ 6 http://www-tsujii.is.s.u-tokyo.ac.jp/ enju/ 38 formance on this data. However, it does not invalidate comparison within the dataset."
W10-1905,de-marneffe-etal-2006-generating,0,0.191901,"Missing"
W10-1905,I05-2038,1,0.0972984,"g the method introduced by (Miyao et al., 2009). SD is generated from PTB by the Stanford tools (de Marneffe et al., 2006)7 , and CoNLLX dependencies are generated from PTB by using Treebank Converter (Johansson and Nugues, 2007)8 . We note that all of these conversions can introduce some errors in the conversion process. With the exception of Bikel, all the applied parsers have models specifically adapted for biomedical text. Further, all of the biomedical domain models have been created with reference and for many parsers with direct training on the data of (a subset of) the GENIA treebank (Tateisi et al., 2005). The results of parsing with these models as provided for the BioNLP Shared Task are used in this comparison. However, we note that the shared task data, drawn from the GENIA event corpus (Kim et al., 2008), contains abstracts that are also in the GENIA treebank. This implies that the parsers are likely to perform better on the texts used in the shared task than on other biomedical domain text, and similarly that systems building on their output are expected to achieve best per2.3 Event Extraction System The system by Miwa et al. (2010) is adopted for the evaluation. The system was originally"
W10-1905,W07-2416,0,0.0103989,"Phrase Structure Grammar (HPSG) and produces a format containing predicate argument structures (PAS) along with a phrase structure tree in Enju format. To study the contribution of the formats in which the five parsers output their analyses to task performance, we apply a number of conversions between the outputs, shown in Figure 4. The Enju PAS output is converted into Penn Treebank format using the method introduced by (Miyao et al., 2009). SD is generated from PTB by the Stanford tools (de Marneffe et al., 2006)7 , and CoNLLX dependencies are generated from PTB by using Treebank Converter (Johansson and Nugues, 2007)8 . We note that all of these conversions can introduce some errors in the conversion process. With the exception of Bikel, all the applied parsers have models specifically adapted for biomedical text. Further, all of the biomedical domain models have been created with reference and for many parsers with direct training on the data of (a subset of) the GENIA treebank (Tateisi et al., 2005). The results of parsing with these models as provided for the BioNLP Shared Task are used in this comparison. However, we note that the shared task data, drawn from the GENIA event corpus (Kim et al., 2008),"
W10-1905,W09-1418,0,0.0634223,"viously introduced base system is here improved with two modifications. One modification is removing two classes of features from the original features (for details of the original feature representation, we refer to (Miwa et al., 2010)); specifically the features representing governordependent relationships from the target word, and the features representing each event edges in the complex event detector are removed. The other modification is to use head words in a trigger expression as a gold trigger word. This modification is inspired by the part-of-speech (POS) based selection proposed by Kilicoglu and Bergler (2009). 7 http://www-nlp.stanford.edu/software/ lex-parser.shtml 8 http://nlp.cs.lth.se/software/ treebank converter/ 39 The system uses a head word “in” as a trigger word in a trigger expression “in the presence of” instead of using all the words of the expression. In cases where there is no head word information in a parser output, head words are selected heuristically: if a word does not modify another word in the trigger expression, the word is selected as a head word. The system is also modified to find secondary arguments (Task 2 in the BioNLP 2009 Shared Task). The second arguments are treate"
W10-1905,W09-1401,1,0.697119,"t of the BioNLP 2009 Shared Task. Section 2.2 then summarizes the five syntactic parsers and three formats adopted for the comparison. Section 2.3 described how the state-of-the-art event extraction system of Miwa et al. (2010) is modified and used for the comparison. prep pobj cc NFAT/AP-1 complex formed only with P and P2 nsubj dep conj Figure 1: Stanford basic dependency tree VMOD PMOD COORD ROOT root NFAT/AP-1 complex formed only with P and P2 2.1 Bio-molecular Event Extraction The bio-molecular event extraction task considered in this study is that defined in the BioNLP 2009 Shared Task (Kim et al., 2009)1 . The shared task provided common and consistent task definitions, data sets for training and evaluation, and evaluation criteria. The shared task consists of three subtasks: core event extraction (Task 1), augmenting events with secondary arguments (Task 2), and the recognition of speculation and negation of the events (Task 3) (Kim et al., 2009). In this paper we consider Task 1 and Task 2. The shared task defined nine event types, which can be divided into five simple events (Gene expression, Transcription, Protein catabolism, Phosphorylation, and Localization) that take one core argument"
W11-0215,W11-1828,0,0.226162,"Missing"
W11-0215,W09-1402,0,0.0757843,"Missing"
W11-0215,W10-1904,1,0.895723,"Missing"
W11-0215,W09-1403,0,0.369926,"Missing"
W11-0215,W11-1801,1,0.888281,"Missing"
W11-0215,C10-1088,1,0.850253,"criteria of the BioNLP Shared Task. The evaluation is event instance-based and uses the standard precision/recall/F1 -score metrics. We modified the shared task evaluation software to support the newly defined event types and ran experiments with the standard approximate span matching and partial recursive matching criteria (see (Kim et al., 2009)). We further follow the EPI task evaluation in reporting results separately for the extraction of only Theme and Cause arguments (core task) and for the full argument set. 5.2 Event extraction method We applied the EventMine event extraction system (Miwa et al., 2010a; Miwa et al., 2010b), an SVMbased pipeline system using an architecture similar to that of the best-performing system in the BioNLP ST’09 (Bj¨orne et al., 2009); we refer to the studies of Miwa et al. for detailed description of the base system. For analysing sentence structure, we applied the mogura 2.4.1 (Matsuzaki and Miyao, 2007) and GDep beta2 (Sagae and Tsujii, 2007) parsers. For the present study, we modified the base EventMine system as follows. First, to improve efficiency and generalizability, instead of using all words as trigger candidates as in the base system, we filtered candi"
W11-0215,nawaz-etal-2010-meta,0,0.0203,"egulation of modifi1 GO structure and statistics from data retrieved Dec. 2010. Figure 2: Comparison of hypothetical text-bound GO annotation with specific terms (top) and event annotation with general GO terms (bottom). cation, as these are captured using separate events in the applied representation, as illustrated in Figure 1. For an analogous reason, we do not separately include type-level distinctions for “magnitude” variants of terms (e.g. monoubiquitination, polyubiquitination) as these can be systematically modeled as aspects that can mark any event (cf. the low/neutral/high Manner of Nawaz et al. (2010)). Second, a number of the GO terms identify reactions that are in scope of previously defined (nonmodification) event types in existing resources. To avoid introducing redundant or conflicting annotation with e.g. the GENIA Event corpus (Kim et al., 2008) or BioNLP ST resources, we excluded terms that involve predominantly (or exclusively) noncovalent binding (included in the scope of the event type B INDING) and terms involving the removal of or binding between the amino acids of a protein, including protein maturation by peptide bond cleavage (annotated – arguably somewhat inaccurately – as"
W11-0215,W09-1313,1,0.83441,"performance. 4 Annotation This section presents the entity and event annotation approach, document selection, and the statistics of the created annotation. 8 The remarkably high coverage for a single type reflects the Zipfian distribution of the modification types; see e.g. Ohta et al. (2010). 4.1 To maximize compatibility with existing eventannotated resources, we chose to follow the general representation and annotation guidelines applied in the annotation of GENIA/BioNLP ST resources, specifically the BioNLP ST 2011 EPI task corpus. Correspondingly, we followed the GENIA gene/gene product (Ohta et al., 2009) annotation guidelines for marking protein mentions, extended the GENIA event corpus guidelines (Kim et al., 2008) for the annotation of protein modification events, and marked C ATALYSIS events following the EPI task representation. For compatibility, we also marked event negation and speculation as in these resources. We followed the GO definitions for individual modification types, and in the rare cases where a modification discussed in text had no existing GO definition, we extrapolated from the way in which protein modifications are generally defined in GO, consulting other domain ontolog"
W11-0215,W10-1903,1,0.913681,"ced substantially in recent years, shifting from the detection of simple binary associations such as protein-protein interactions toward resources and methods for the extraction of multiple types of structured associations of varying numbers participants in specific roles. These IE approaches are frequently termed event extraction (Ananiadou et al., 2010). While protein modifications have been considered in numerous IE studies in the domain (e.g. (Friedman et al., 2001; Rzhetsky et al., 2004; Hu et al., 2005; Narayanaswamy et al., 2005; Saric et al., 2006; Yuan et al., 2006; Lee et al., 2008; Ohta et al., 2010), event extraction efforts have brought increased focus also on the extraction of protein modifications: in the BioNLP Shared Task series that has popularized event extraction, the 2009 shared task (Kim et al., 2009) involved the extraction of nine event types including one PTM, and in the 2011 follow-up event (Kim et al., 2011) the Epigenetics and Post-translational modifications (EPI) task (Ohta et al., 2011) targeted six PTM types, their re114 Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 114–123, c Portland, Oregon, USA, June 23-24, 2011. 2"
W11-0215,W11-1803,1,0.879677,"Missing"
W11-0215,D07-1111,1,0.793565,"he EPI task evaluation in reporting results separately for the extraction of only Theme and Cause arguments (core task) and for the full argument set. 5.2 Event extraction method We applied the EventMine event extraction system (Miwa et al., 2010a; Miwa et al., 2010b), an SVMbased pipeline system using an architecture similar to that of the best-performing system in the BioNLP ST’09 (Bj¨orne et al., 2009); we refer to the studies of Miwa et al. for detailed description of the base system. For analysing sentence structure, we applied the mogura 2.4.1 (Matsuzaki and Miyao, 2007) and GDep beta2 (Sagae and Tsujii, 2007) parsers. For the present study, we modified the base EventMine system as follows. First, to improve efficiency and generalizability, instead of using all words as trigger candidates as in the base system, we filtered candidates using a dictionary extracted from training data and expanded by using the UMLS specialist lexicon (Bodenreider, 2004) and the “hypernyms” and “similar to” relations in WordNet (Fellbaum, 120 1998). Second, to allow generalization across argument types, we added support for solving a single classification problem for event argument detection instead of solving multiple"
W13-2012,W13-2009,1,0.627053,"biomedical natural language processing (BioNLP), automatic extraction of biomedical events from texts becomes practical and the extracted events have been successfully employed in several applications, such as EVEX (Bj¨orne et al., 2012; Van Landeghem et al., 2013) and PathText (Miwa et al., 2013a). The practical applications reveal a problem in that both event types and structures need to be covered more widely. The BioNLP Shared Task 2013 (BioNLP-ST 2013) offers several tasks addressing the problem, and especially in the Cancer Genetics (CG) (Pyysalo et al., 2013) and Pathway Curation (PC) (Ohta et al., 2013) tasks, new entity/event types and biomedical problems are focused. Among dozens of extraction systems proposed during and after the two previous BioNLP shared tasks (Kim et al., 2011; Kim et al., 2012; Pyysalo et al., 2012b), EventMine (Miwa et al., 2012)1 has been applied to several biomedical event extraction corpora, and it achieved the state-of-theart performance in several corpora (Miwa et al., 2013b). In these tasks, an event associates with 1 2 EventMine for CG and PC Tasks This section briefly introduces EventMine and the PC and CG tasks, and then explains its task specific configurat"
W13-2012,W12-2410,1,0.884482,"Missing"
W13-2012,W11-0215,1,0.845,"xternal corpora in the stacked models for the PC task. We train models for the CG task using the configuration described above. For PC, in addition to the configuration, we incorporated a stacking 3 4 Recall 42.87 43.37 43.59 Precision 47.72 46.42 48.77 F-score 45.16 44.84 46.04 Table 1: Effect of the type generalisations for expanding possible instances (+Exp.) and stacking method (+Stack.) on the PC development data set. method (Wolpert, 1992) using the models with the same configuration for seven other available corpora: GENIA, EPI, ID, DNA methylation (Ohta et al., 2011a), Exhaustive PTM (Pyysalo et al., 2011), mTOR (Ohta et al., 2011b) and CG. The prediction scores of all the models are used as additional features in the detectors. Although some corpora may not directly relate to the PC task and models trained on such corpora can produce noisy features, we use all the corpora without selection since the stacking often improve the performance, e.g., (Pyysalo et al., 2012a; Miwa et al., 2013b). 3 Evaluation We first evaluate the type generalisations for expanding possible event structures and the stacking method in Table 1. The scores were calculated using the evaluation script provided by the organ"
W13-2012,W13-2008,1,0.26313,"PC task. 1 Introduction With recent progress in biomedical natural language processing (BioNLP), automatic extraction of biomedical events from texts becomes practical and the extracted events have been successfully employed in several applications, such as EVEX (Bj¨orne et al., 2012; Van Landeghem et al., 2013) and PathText (Miwa et al., 2013a). The practical applications reveal a problem in that both event types and structures need to be covered more widely. The BioNLP Shared Task 2013 (BioNLP-ST 2013) offers several tasks addressing the problem, and especially in the Cancer Genetics (CG) (Pyysalo et al., 2013) and Pathway Curation (PC) (Ohta et al., 2013) tasks, new entity/event types and biomedical problems are focused. Among dozens of extraction systems proposed during and after the two previous BioNLP shared tasks (Kim et al., 2011; Kim et al., 2012; Pyysalo et al., 2012b), EventMine (Miwa et al., 2012)1 has been applied to several biomedical event extraction corpora, and it achieved the state-of-theart performance in several corpora (Miwa et al., 2013b). In these tasks, an event associates with 1 2 EventMine for CG and PC Tasks This section briefly introduces EventMine and the PC and CG tasks,"
W13-2012,D07-1111,0,0.0732521,"nces in the training data, we allow the creation of the latter instances by generalising the triggers, i.e., REGULATION:Theme-Gene expression, and we used all the created instances for classification. The type generalisations may incorporate noisy instances but they pose the possibility to find unannotated event structures. To avoid introducing unexpected event structures, we apply the generalisations only to the regulation trigger types. We basically follow the setting for EPI in Miwa et al. (2012). We employ a deep syntactic parser Enju (Miyao and Tsujii, 2008) and a dependency parser GDep (Sagae and Tsujii, 2007). We utilise liblinear-java (Fan et al., 2008)3 with the L2-regularised L2-loss linear SVM setting for the SVM implementation, and Snowball4 for the stemmer. We, however, use no external resources (e.g., dictionaries) or tools (e.g., a coreference resolver) except for the external corpora in the stacked models for the PC task. We train models for the CG task using the configuration described above. For PC, in addition to the configuration, we incorporated a stacking 3 4 Recall 42.87 43.37 43.59 Precision 47.72 46.42 48.77 F-score 45.16 44.84 46.04 Table 1: Effect of the type generalisations fo"
W13-2012,J08-1002,0,0.0920307,"are no Positive regulation:Theme-Gene expression instances in the training data, we allow the creation of the latter instances by generalising the triggers, i.e., REGULATION:Theme-Gene expression, and we used all the created instances for classification. The type generalisations may incorporate noisy instances but they pose the possibility to find unannotated event structures. To avoid introducing unexpected event structures, we apply the generalisations only to the regulation trigger types. We basically follow the setting for EPI in Miwa et al. (2012). We employ a deep syntactic parser Enju (Miyao and Tsujii, 2008) and a dependency parser GDep (Sagae and Tsujii, 2007). We utilise liblinear-java (Fan et al., 2008)3 with the L2-regularised L2-loss linear SVM setting for the SVM implementation, and Snowball4 for the stemmer. We, however, use no external resources (e.g., dictionaries) or tools (e.g., a coreference resolver) except for the external corpora in the stacked models for the PC task. We train models for the CG task using the configuration described above. For PC, in addition to the configuration, we incorporated a stacking 3 4 Recall 42.87 43.37 43.59 Precision 47.72 46.42 48.77 F-score 45.16 44.8"
W13-2012,W11-0214,0,0.0195847,"oreference resolver) except for the external corpora in the stacked models for the PC task. We train models for the CG task using the configuration described above. For PC, in addition to the configuration, we incorporated a stacking 3 4 Recall 42.87 43.37 43.59 Precision 47.72 46.42 48.77 F-score 45.16 44.84 46.04 Table 1: Effect of the type generalisations for expanding possible instances (+Exp.) and stacking method (+Stack.) on the PC development data set. method (Wolpert, 1992) using the models with the same configuration for seven other available corpora: GENIA, EPI, ID, DNA methylation (Ohta et al., 2011a), Exhaustive PTM (Pyysalo et al., 2011), mTOR (Ohta et al., 2011b) and CG. The prediction scores of all the models are used as additional features in the detectors. Although some corpora may not directly relate to the PC task and models trained on such corpora can produce noisy features, we use all the corpora without selection since the stacking often improve the performance, e.g., (Pyysalo et al., 2012a; Miwa et al., 2013b). 3 Evaluation We first evaluate the type generalisations for expanding possible event structures and the stacking method in Table 1. The scores were calculated using th"
W13-2012,U13-1019,0,\N,Missing
W14-3702,P02-1006,0,0.0270783,"he local approach. Our system outperformed the state-of-the-art system that utilizes global information and achieved about 1.4 percentage points higher accuracy. 1 Introduction Temporal relationships between entities, namely temporal expressions and events, are regarded as important information for deep understanding of documents. Being able to predict temporal relations between events and temporal expressions within a piece of text can support various NLP applications such as textual entailment (Bos et al., 2005), multi-document summarization (Bollegala et al., 2010), and question answering (Ravichandran and Hovy, 2002). Temporal relation classification, which is one of the subtasks TempEval-3 (UzZaman et al., 2013), aims to classify temporal relationships between pairs of temporal entities into one of the 14 re6 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 6–14, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics Figure 1: An example from the Timebank corpus temporal relation types. Following TempEval-3, all possible TLINKs are between: in our work, the full set of temporal relations specified in TimeML are used, rather t"
W14-3702,C08-1108,0,0.0179066,"connections between entities in a timegraph by following a set of inference rules. For example, if e1 happens AFTER e2 and e2 happens IMMEDIATELY AFTER e3, then we infer a new temporal relation “e1 happens AFTER e3”. In this paper, we add a new connection only when the inference gives only one type of temporal relation as a result from the relation inference. Figure 7b shows the timegraph after adding new inference relations to the original timegraph in Figure 7a. 4.2 (b) After relation inference. Two relations (e1-e2, e1-e3) are added. Time-time connection As with Chambers et al. (2007) and Tatu and Srikanth (2008), we also create new connections between time entities in a timegraph by applying some rules to normalized values of time entities provided in the corpus. after Figure 7c shows the timegraph after adding a time-time link and new inference relations to the original timegraph in Figure 7a. When the normalized value of t2 is more than the value of t1, a TLINK with the relation type AFTER is added between them. After that, as introduced in Subsection 4.2, new inference relations (e1-e2, e1-e3, e2-e3) are added. after (c) After time-time connection (t1-t2) and relation inference. Three relations (e"
W14-3702,P11-2061,0,0.013869,"y significant** (p < 10−5 , McNemar’s test, two-tailed) when applying deep syntactic information to the system. The overall result has about 1.4 pp higher accuracy than the result from their global model. Note that Yoshikawa et al. (2009) did not apply deep syntactic features in their system. The performance analysis is performed based on 10-fold cross validation over the training data. The classification F1 score improves by 0.18 pp and 0.16 pp compared to the local pairwise models with/without deep syntactic features. We evaluated the system using a graph-based evaluation metric proposed by UzZaman and Allen (2011). Table 5 shows the classification accuracy over the training set using graph-based evaluation. The stacked model affected the relation classification output of the local model, changing the relation types of 390 (out of 2520) E-E TLINKs and 169 (out of 2463) E-T TLINKs. 5.2 Comparison with the state of the art We compared our system to that of Yoshikawa et al. (2009) which uses global information to 12 Approach Yoshikawa et al. (2009) (local) Yoshikawa et al. (2009) (global) Our system (local) - baseline features Our system (local) - baseline + deep features Our system (stacked) - baseline fe"
W14-3702,S13-2001,0,0.0129706,"nd achieved about 1.4 percentage points higher accuracy. 1 Introduction Temporal relationships between entities, namely temporal expressions and events, are regarded as important information for deep understanding of documents. Being able to predict temporal relations between events and temporal expressions within a piece of text can support various NLP applications such as textual entailment (Bos et al., 2005), multi-document summarization (Bollegala et al., 2010), and question answering (Ravichandran and Hovy, 2002). Temporal relation classification, which is one of the subtasks TempEval-3 (UzZaman et al., 2013), aims to classify temporal relationships between pairs of temporal entities into one of the 14 re6 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 6–14, c October 29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics Figure 1: An example from the Timebank corpus temporal relation types. Following TempEval-3, all possible TLINKs are between: in our work, the full set of temporal relations specified in TimeML are used, rather than the reduced set used in the previous work. We evaluate our method on the TempEval-3’s Task C-r"
W14-3702,H05-1079,0,0.113493,"Missing"
W14-3702,S07-1014,0,0.0425913,"Missing"
W14-3702,P07-2044,0,0.184215,"be found in (Pustejovsky et al., 2005). X X X X All attributes associated with temporal expressions. The explanation of each attribute can be found in (Pustejovsky et al., 2005). X X X X X X Words, POS, lemmas within a window before/after event words extracted using Stanford coreNLP (Stanford NLP Group, 2012) X X X WordNet lexical database (Fellbaum, 1998) X X X X X X X X True if both temporal entities are in the same sentence X X X X Deep syntactic information extracted from Enju Parser (Miyao and Tsujii, 2008). The details are described in (Laokulrat et al., 2013) Details are described in (Chambers et al., 2007) Table 1: Local features Feature Adjacent nodes and links Other paths Generalized paths (E,V,E) tuples (V,E,V) tuples E-E X X X X X E-T X X X X X Description The details are described in Subsection 3.2 Table 2: Timegraph features 8 Figure 5: Local pairwise classification. Each TLINK is classified separately. Figure 2: path length ≤ 2 Figure 3: path length ≤ 3 3 Figure 6: Timegraph constructed from a document’s TLINKs Proposed method Rather than using only local information on two entities in a TLINK, our goal is to exploit more global information which can be extracted from a document’s timegr"
W14-3702,D08-1073,0,0.0449211,"Missing"
W14-3702,P06-1095,0,0.0708157,"Missing"
W14-3702,J08-1002,0,0.0147993,"cription X X X X X X X X X X All attributes associated with events. The explanation of each attribute can be found in (Pustejovsky et al., 2005). X X X X All attributes associated with temporal expressions. The explanation of each attribute can be found in (Pustejovsky et al., 2005). X X X X X X Words, POS, lemmas within a window before/after event words extracted using Stanford coreNLP (Stanford NLP Group, 2012) X X X WordNet lexical database (Fellbaum, 1998) X X X X X X X X True if both temporal entities are in the same sentence X X X X Deep syntactic information extracted from Enju Parser (Miyao and Tsujii, 2008). The details are described in (Laokulrat et al., 2013) Details are described in (Chambers et al., 2007) Table 1: Local features Feature Adjacent nodes and links Other paths Generalized paths (E,V,E) tuples (V,E,V) tuples E-E X X X X X E-T X X X X X Description The details are described in Subsection 3.2 Table 2: Timegraph features 8 Figure 5: Local pairwise classification. Each TLINK is classified separately. Figure 2: path length ≤ 2 Figure 3: path length ≤ 3 3 Figure 6: Timegraph constructed from a document’s TLINKs Proposed method Rather than using only local information on two entities in"
W14-3702,P09-1046,0,\N,Missing
W14-3702,S13-2015,1,\N,Missing
W17-2302,S13-2108,0,0.0438532,"Missing"
W17-2302,S13-2057,0,0.0132696,"reference, and the results of ablation tests. As is shown in the table, the attention mechanism by Wang et al. (2016) did not work in DDI extraction. However, our attention improved the performance. This result shows that the proposed extensions are crucial for modeling attentions in DDI extraction. The ablation test results show that both extensions to our attention mechanism, i.e., separate attentions for entities and incorporation of the bias term, are effective for the task. the performance without negative instance filtering, which omits some apparent negative instance pairs with rules (Chowdhury and Lavelli, 2013), since we did not incorporate it. We also show the performance of the existing models with negative instance filtering for reference. In the comparison without negative instance filtering, our model outperformed the existing CNN models (Liu et al., 2016; Quan et al., 2016; Zhao et al., 2016). The model was competitive with Joint AB-LSTM model (Sahu and Anand, 2017) that was composed of multiple RNN models. When considering negative instance filtering, our model showed lower performance than the state-of-the-art. However we believe we can get similar performance with theirs if we incorporate n"
W17-2302,P15-1061,0,0.0468341,"ht matrix W pred ∈ Ro×dp : s = W pred c, (2) Softmax We convert s into the probability of possible relations p by a softmax function: exp (sj ) p = [p1 , · · · , po ], pj = Po . l=1 exp (sl ) We apply the convolution to the embedding matrix as follows: zi,k + b), Lsof tmax = − (4) y log p (10) Lranking = log(1 + exp(γ(m+ − sy )) + log(1 + exp(γ(m− + sc )), 2.2.3 Pooling layer We employ the max pooling (Boureau et al., 2010) to convert the output of each filter in the convolution layer into a fixed-size vector as follows: i X Ranking We employ the ranking-based objective function following dos Santos et al. (2015). Using the scores s in the Equation (8), the loss is calculated as follows: where is an element-wise product, b is the bias term, and f is the ReLU function defined as: ( x, if x &gt; 0 f (x) = (5) 0, otherwise. ck = [c1,k , · · · , cdc ,k ], cj,k = max mi,j,k . (9) The loss function Lsof tmax is defined as in the Equation (10) when the gold type distribution y is given. y is a one-hot vector where the probability of the gold label is 1 and the others are 0. T T zi,k = [wbi−(k−1)/2c ; . . . ; wbi−(k+1)/2c ]T . (3) mi,j,k = (8) where o is the total number of relationships to be classified and s ="
W17-2302,S13-2056,0,0.0249023,"Missing"
W17-2302,W09-2415,0,0.0110812,"Missing"
W17-2302,S13-2105,0,0.0409662,"Missing"
W17-2302,D14-1181,0,0.0174655,"Missing"
W17-2302,P16-1123,0,0.0178962,"Missing"
W18-2324,W16-2922,0,0.0171056,"formance of both mention detection and mention linking on the BioNLP dataset, but the integration could not enhance the performance on the CRAFT corpus. 2 We incorporate the following domain-specific features to enhance the baseline system. In-domain word embeddings: The input word embeddings play an important role in deep learning. Instead of using embeddings trained on general domains, e.g., word embeddings provided with the word2vec tool (Mikolov et al., 2013), we use 200-dimensional embeddings trained on the whole PubMed and PubMed Central Open Access subset (PMC) with a window size of 2 (Chiu et al., 2016). Grammatical numbers: We check mentions’ grammatical numbers, i.e., whether each mention is singular or plural. A mention is singular if its part-of-speech tag is N N or if it is one of the five singular pronouns: it, its, itself, this, and that. A mention is plural if its part-of-speech tag is N N S or if it is one of the seven plural pronouns: they, their, theirs, them, themselves, these, and those. MetaMap entity tags: We employ MetaMapLite2 to identify all possible entities according to the UMLS semantic types.3 In cases that MetaMapLite assigns multiple semantic types for each entity, we"
W18-2324,P10-1040,0,0.0752527,"dataset, we also employed the scorer provided by the shared task organisers to make fair comparisons with previous work. We reported the performance on two sub-tasks: (1) mention detection, i.e., to identify coreferent mentions, such as named entities, prepositions or noun phrases, and (2) mention linking, i.e., to link these mentions if they refer to the same thing. The result of the first task affects that of the second one. Settings We first directly applied the Lee2017 system to the corpora. Lee2017 used two pretrained embeddings in general domains provided by Pennington et al. (2014) and Turian et al. (2010), and all default features such as speaker, genre, and distance. To train the Lee2017 system, we employed the same hyper-parameters as reported in Lee et al. (2017) except for a threshold ratio. Although Lee2017 used the ratio λ = 0.4 to reduce the number of mentions from the list of candidates, we tuned it on the BioNLP development set and used λ = 0.7. We then investigate the impact of each feature on the biomedical texts by preparing the following four systems: • Lee2017: general embeddings, speaker, genre, and distance features 3.3 Results Results on the development sets of the two corpora"
W18-2324,N16-1114,0,0.068981,"Missing"
W18-2324,D17-1018,0,0.330097,"al., 2011).1 Given the fact that deep learning methods can produce the state-of-the-art performance on general texts, we are motivated to apply such methods to biomedical texts. We therefore raise three research questions in this paper: • How does a general domain neural system with no parser information perform on biomedical domain? • How we can incorporate domain-specific information into the neural system? • Which performance range the system is in comparison with existing systems? In order to address these questions, we directly apply the end-to-end neural coreference resolution system by Lee et al. (2017) (Lee2017) to biomedical texts. We then investigate domain specific features such as domain-specific word embeddings, grammatical number agreements between mentions, i.e., mentions are singular or plural, and agreements of MetaMap (Aronson and Lang, 2010) entity tags of mentions. These features do not rely on any syntactic parsers. Moreover, these features are also general for any biomedical corpora and not restricted to the corpora we use. Existing biomedical coreference resolution systems depend on features and/or rules based on syntactic parsers. In this paper, we investigate the utility of"
