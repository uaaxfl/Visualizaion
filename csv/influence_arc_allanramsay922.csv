albogamy-ramsay-2017-universal,de-marneffe-etal-2006-generating,0,\N,Missing
albogamy-ramsay-2017-universal,R15-1001,1,\N,Missing
albogamy-ramsay-2017-universal,L16-1262,0,\N,Missing
albogamy-ramsay-2017-universal,W17-1312,1,\N,Missing
albogamy-ramsay-2017-universal,P13-2017,0,\N,Missing
almiman-ramsay-2017-hybrid,W07-1431,0,\N,Missing
almiman-ramsay-2017-hybrid,C08-1066,0,\N,Missing
almiman-ramsay-2017-using,C92-2082,0,\N,Missing
C00-2096,J94-2005,0,0.189467,"mbiguity that arises in the alternative form. This is all well-known, and is treated in most grammatical frameworks by hallucinating an item in the canonical position, and then remembering that hallucination up to the point at which the out-ofplace item is encountered. Exactly how the hallucination is remembered varies from one framework to another, with uni cation grammars generally carrying information about it on a category-valued feature (usually called slash). The main problem with this approach is that it is dicult to control the situations in which `traces' of this kind get proposed. (Johnson and Kay, 1994) suggest using `sponsors' in order to license the introduction of traces, where a sponsor is some item of the required kind that has already been found, and which is hence potentially going to cancel with the trace. If your parser works from left!right then this will work for items which have been left-shifted, but clearly it cannot work for right -shifted items, since the sponsor will not have been found at the time when it is needed. Thus we cannot use a sponsor to justify hallucinating an S-comp for `believed' in (4), or for the heavy-NP-shifts in 5 He gave up his job. 6 He built on that sp"
C00-2112,J95-2003,0,0.168716,"Missing"
C00-2112,J86-3001,0,\N,Missing
C92-1037,J90-3004,1,0.923351,"uage expression consists of a set of such presuppositions and a matrix, which corresponds to the usual notion of propositional content. The dements of this framework ate not universally accepted, but they do at least all have respectable ancestors. The most contentious is the view that definite reference and anaphora should be dealt with in terms of constraints on the situation of utterance. The basic notion here is similar to the use of ANCHORS in situation semantics [Barwise & Perry 1983], and to the treatment o f a n a p h o r a in DRT [Kamp 1984]. The details of our approach are given in [Ramsay 1990a]. Very little in the present discussion of bare plurals depends on this treatment of definite reference. Sceptics about this part of our framework are invited to suspend their disbelief while considering the treatment of bare plurals. The following analysis of (7) John a~e a peach. should illustrate the crucial aspects of our representation: (6) M a ~ is house-hunting. [.~tri~ : 3 A 3B V C mer.~r(C, B) -4 ~ h ( C ) which says what Mary is doing is hunting for something, and that what she is looking for is a house. 2 ^ objed(D, B) Semantic Framework The treatment of bare plurals proposed in t"
C92-1037,E91-1002,0,\N,Missing
C94-2142,E91-1044,0,\N,Missing
C94-2142,C92-1037,1,\N,Missing
C96-2150,C92-1037,1,0.835386,"&apos;(t&apos; C I --+ ~e(I&apos;.c A 3to(to &lt; t &apos; A t o E I A startpt(e, to)) A 3tl(t&apos; &lt; tt Atl E I are also easy to devise. Inventing analyses that cover specific phenomena is fairly easy. The difficult part is ensuring that all your analyses work at the same time and without introducing large nuinbers of spurious readings. It is important for my claim to have preserved compositionality that all the analyses in this paper have been obtained on the basis of the interpretations of the lexical items that appear in them and the semantics of the rules of combination, using a version of the system described in (Ramsay, 1992; Ramsay and Sch/~ler, 1995). A cn@t(e, t~)))) Ve&apos;((P.c&apos; References A 9t2(,startpt(e&apos;, t2) A t2 C i) --+ Vta(er~,dpt(c&apos;, ta)) Omitting this extra clause from the MP for perf means that the set, of ewmts in question could inelude one that is not yet complete, so that 19 I have also read the Guardian for years, but I am now becoming dissatisfied with it as well. has a past habitual reading which is ()pen to contimmtion in a way that the habitual reading of the simple past cannot be. The ramifications of this require further exploration, perhaps in conjunction with a treatment of implieature, lik"
C96-2150,W14-0904,0,0.0640916,"Missing"
C96-2150,J88-2003,0,\N,Missing
E85-1008,T75-2013,0,0.0790036,"Missing"
E89-1029,P87-1012,0,\N,Missing
E89-1029,P87-1033,0,\N,Missing
J90-3004,C88-1018,0,\N,Missing
J90-3004,P86-1038,0,\N,Missing
L16-1238,W12-3705,0,0.0514084,"Missing"
L16-1238,W15-4325,1,0.805634,"Missing"
L16-1238,R15-1001,1,0.125627,"Missing"
L16-1238,C10-2005,0,0.147938,"Missing"
L16-1238,J95-4004,0,0.384567,"Missing"
L16-1238,W03-0407,0,0.104978,"Based on that, we decide to further improve the accuracy of Stanford tagger while preserving its speed by using Arabic tweets training data. However, there is no labelled training data available to do so. Therefore, we use bootstrapping on unlabelled data to create a sufficient amount of labelled training tweets. 1504 5.2. Agreement-based Bootstrapping Bootstrapping is used to create a labelled training data from large amounts of unlabelled data (Cucerzan and Yarowsky, 2002; Zavrel and Daelemans, 2000). There are different ways to select the labelled data from the taggers’ outputs. We follow (Clark et al., 2003) in using agreement-based training method. We use the augmented versions of AMIRA, MADA and Stanford taggers to tag a large amount of Arabic tweets and add the tokens which they agreed upon to the pool of training data. Then, we retrain Stanford tagger on the selected labelled data. Tag CC CD DT IN JJ NN NNP PRP PUNC RB RP UH VB WP WRB Gloss coordinating conjunction cardinal number demonstrative pronoun subordinating conjunction or preposition adjective common noun proper noun personal pronoun punctuation adverb particle interjection verb relative pronoun wh-adverb as a training data. Finally,"
L16-1238,W02-2006,0,0.509599,"tage and they need more improvements. Due to the fact that we have no access to their codes, the reasons for the variation in speed are not visible. Based on that, we decide to further improve the accuracy of Stanford tagger while preserving its speed by using Arabic tweets training data. However, there is no labelled training data available to do so. Therefore, we use bootstrapping on unlabelled data to create a sufficient amount of labelled training tweets. 1504 5.2. Agreement-based Bootstrapping Bootstrapping is used to create a labelled training data from large amounts of unlabelled data (Cucerzan and Yarowsky, 2002; Zavrel and Daelemans, 2000). There are different ways to select the labelled data from the taggers’ outputs. We follow (Clark et al., 2003) in using agreement-based training method. We use the augmented versions of AMIRA, MADA and Stanford taggers to tag a large amount of Arabic tweets and add the tokens which they agreed upon to the pool of training data. Then, we retrain Stanford tagger on the selected labelled data. Tag CC CD DT IN JJ NN NNP PRP PUNC RB RP UH VB WP WRB Gloss coordinating conjunction cardinal number demonstrative pronoun subordinating conjunction or preposition adjective c"
L16-1238,R13-1026,0,0.133871,"Missing"
L16-1238,P11-2008,0,0.141792,"Missing"
L16-1238,P11-1038,0,0.0400857,"eft as it is. Token  á  J J  J  J  J  J  J ® ¯@@@@@@@@@@@@@ ð  Õæ @A®Ë@@ é<Ë@ MSA No Surface form Translation Standing á  ® ¯@ ð  Õæ A®Ë@ é<Ë@ No Yes Algasim Allah Table 3: Elongated words and their surface forms 5.1. Pre- and Post-processing As seen in error analysis, unknown words (out-ofvocabulary tokens or OOV) represent a large proportion of mistagged tokens. We argue that normalisation and external knowledge will reduce this proportion which will improve the performance of the proposed tagger. Normalisation is the process of providing in-vocabulary (IV) versions of OOV words (Han and Baldwin, 2011). We create a mapping from OOV tokens to their IV equivalents by using suitable dictionaries and the original token is replaced with its equivalent IV token. External sources of knowledge such as regular expression rules, gazetteer lists and an output of English tagger are also used. The combination of normalisation and external knowledge is applied to text as pre- and post-processing steps. Handling Concatenation Users may connect words deliberately to overcome tweets restricted length or accidentally. This forms tokens which all taggers struggle to tag them correctly. One approach to deal wi"
L16-1238,W13-1608,0,0.0545324,"Missing"
L16-1238,refaee-rieser-2014-arabic,0,0.045372,"Missing"
L16-1238,D11-1141,0,0.316543,"Missing"
L16-1238,N03-1033,0,0.0548855,"Missing"
L16-1238,zavrel-daelemans-2000-bootstrapping,0,0.0702608,"vements. Due to the fact that we have no access to their codes, the reasons for the variation in speed are not visible. Based on that, we decide to further improve the accuracy of Stanford tagger while preserving its speed by using Arabic tweets training data. However, there is no labelled training data available to do so. Therefore, we use bootstrapping on unlabelled data to create a sufficient amount of labelled training tweets. 1504 5.2. Agreement-based Bootstrapping Bootstrapping is used to create a labelled training data from large amounts of unlabelled data (Cucerzan and Yarowsky, 2002; Zavrel and Daelemans, 2000). There are different ways to select the labelled data from the taggers’ outputs. We follow (Clark et al., 2003) in using agreement-based training method. We use the augmented versions of AMIRA, MADA and Stanford taggers to tag a large amount of Arabic tweets and add the tokens which they agreed upon to the pool of training data. Then, we retrain Stanford tagger on the selected labelled data. Tag CC CD DT IN JJ NN NNP PRP PUNC RB RP UH VB WP WRB Gloss coordinating conjunction cardinal number demonstrative pronoun subordinating conjunction or preposition adjective common noun proper noun person"
P06-2044,P84-1038,0,\N,Missing
P06-2044,W83-0114,0,\N,Missing
R13-1002,N10-1145,0,0.0357822,"ve performance of the standard techniques on our Arabic testset replicates the results reported for these techniques for English testsets. We have also applied our ETED to the English RTE2 testset, where it again outperforms the standard version of TED. 2 TED for RTE The idea here is to convert both T and H from natural language expressions into parse trees through parsing and then to explicitly transform T’s parse tree into H’s parse tree, using a sequence of edit operations (Kouylekov and Magnini, 2005; BarHaim et al., 2007; Harmeling, 2009; Mehdad and Magnini, 2009; Wang and Manning, 2010; Heilman and Smith, 2010; Stern et al., 2012). If a lowcost transformation sequence can be found then it may be that T entails H. Dependency parsers (Kübler et al., 2009) are popular for this task, as in other NLP areas in recent years, since they allow us to be sensitive to the fact that the links in a dependency tree carry linguistic information about relations between complex units. Different sets of operations on trees, using various types of transformations in order to derive H from T, have been suggested. Herrera et al. (2005), for instance, used the notion of tree inclusion (Kilpeläinen, 1992), which obtained"
R13-1002,R11-2007,1,0.861702,"standard TED to deal with subtree operations as well as operations on single nodes. This allows the algorithm to treat semantically coherent parts of the tree as single items, thus allowing for instance entire modifiers (such as prepositional phrase (PPs)) to be inserted or deleted as single units. We have also applied the artificial bee colony (ABC) algorithm (Akay and Karaboga, 2012) to estimate costs both of edit operations (single node and subtree) and of threshold(s). The work was carried out as part of an attempt to build a textual entailment (TE) system for modern standard Arabic (MSA)(Alabbas, 2011). MSA poses a number of problems that, while familiar from other languages, make tasks such as TE particularly difficult for this language–the lack of diacritics in written MSA combines with the complex derivational and inflectional morphology of the language to produce worse levels of lexical ambiguity than occur in many other languages; the combination of free word-order, pro-drop, verbless sentences and complex nominals produces higher levels of syntactic ambiguity than occur in many other languages; and the combination of these combinations makes things even worse. We This paper introduces"
R13-1002,R13-2002,1,0.87745,"Missing"
R13-1002,W06-2932,0,0.0278456,"Missing"
R13-1002,W09-2505,0,0.0473118,"in recent times. Tree edit distance (TED), which models T-H pairs by explicitly transforming T into H via a minimal cost sequence of editing operations, has been widely used for this task. Using TED poses two challenges: the standard three operations (i.e. deletion, insertion and exchange) apply only to single nodes, rather than to subtrees; and estimating a combination of costs for these operations with threshold(s) is hard when dealing with complex problems. This is because alterations in these costs or choosing a different combination of them can lead to drastic changes in TED performance (Mehdad and Magnini, 2009). In order to overcome these challenges, we have extended the standard TED to deal with subtree operations as well as operations on single nodes. This allows the algorithm to treat semantically coherent parts of the tree as single items, thus allowing for instance entire modifiers (such as prepositional phrase (PPs)) to be inserted or deleted as single units. We have also applied the artificial bee colony (ABC) algorithm (Akay and Karaboga, 2012) to estimate costs both of edit operations (single node and subtree) and of threshold(s). The work was carried out as part of an attempt to build a te"
R13-1002,C96-1078,0,0.161677,"sers (Kübler et al., 2009) are popular for this task, as in other NLP areas in recent years, since they allow us to be sensitive to the fact that the links in a dependency tree carry linguistic information about relations between complex units. Different sets of operations on trees, using various types of transformations in order to derive H from T, have been suggested. Herrera et al. (2005), for instance, used the notion of tree inclusion (Kilpeläinen, 1992), which obtained one tree from another by deleting nodes. Herrera et al. (2006) and Marsi et al. (2006) used a tree alignment algorithm (Meyers et al., 1996), which produces a multiple sequence alignment on a set of sequences over a fixed tree. TED (Zhang and Shasha, 1989; Klein et al., 2000; Pawlik and Augsten, 2011) is another example of a transformation-based model 2.1 Standard TED In this paper we will use Zhang and Shasha (1989)’s TED algorithm (henceforth, ZS-TED), which is an efficient technique based on dynamic programming to calculate the approximate tree matching for two rooted ordered trees, as a starting point. Ordered trees are trees in which the left-toright order among siblings is significant. Approximate tree matching allows us to"
R13-1002,R11-1063,0,0.026673,"Missing"
R13-1002,P12-1030,0,0.0118805,"ndard techniques on our Arabic testset replicates the results reported for these techniques for English testsets. We have also applied our ETED to the English RTE2 testset, where it again outperforms the standard version of TED. 2 TED for RTE The idea here is to convert both T and H from natural language expressions into parse trees through parsing and then to explicitly transform T’s parse tree into H’s parse tree, using a sequence of edit operations (Kouylekov and Magnini, 2005; BarHaim et al., 2007; Harmeling, 2009; Mehdad and Magnini, 2009; Wang and Manning, 2010; Heilman and Smith, 2010; Stern et al., 2012). If a lowcost transformation sequence can be found then it may be that T entails H. Dependency parsers (Kübler et al., 2009) are popular for this task, as in other NLP areas in recent years, since they allow us to be sensitive to the fact that the links in a dependency tree carry linguistic information about relations between complex units. Different sets of operations on trees, using various types of transformations in order to derive H from T, have been suggested. Herrera et al. (2005), for instance, used the notion of tree inclusion (Kilpeläinen, 1992), which obtained one tree from another"
R13-1002,C10-1131,0,0.0286362,"n techniques. The relative performance of the standard techniques on our Arabic testset replicates the results reported for these techniques for English testsets. We have also applied our ETED to the English RTE2 testset, where it again outperforms the standard version of TED. 2 TED for RTE The idea here is to convert both T and H from natural language expressions into parse trees through parsing and then to explicitly transform T’s parse tree into H’s parse tree, using a sequence of edit operations (Kouylekov and Magnini, 2005; BarHaim et al., 2007; Harmeling, 2009; Mehdad and Magnini, 2009; Wang and Manning, 2010; Heilman and Smith, 2010; Stern et al., 2012). If a lowcost transformation sequence can be found then it may be that T entails H. Dependency parsers (Kübler et al., 2009) are popular for this task, as in other NLP areas in recent years, since they allow us to be sensitive to the fact that the links in a dependency tree carry linguistic information about relations between complex units. Different sets of operations on trees, using various types of transformations in order to derive H from T, have been suggested. Herrera et al. (2005), for instance, used the notion of tree inclusion (Kilpeläine"
R15-1001,C10-2005,0,0.251194,"Missing"
R15-1001,J95-4004,0,0.561652,"Missing"
R15-1001,W03-0407,0,0.323043,"to events, locations, English hashtags or retweet of English tweets with comments written in Arabic and they are part of the syntactic structure of Arabic tweets. So, they need to be tagged correctly. In this case, we use Stanford for English (Toutanova et al., 2003) to tag English words as a post-processing step. 5.2 Agreement-based Bootstrapping Bootstrapping is used to create a labelled training data from large amounts of unlabelled data (Cucerzan and Yarowsky, 2002; Zavrel and Daelemans, 2000). There are different ways to select the labelled data from the taggers’ outputs. We will follow (Clark et al., 2003) in using agreement-based training method. We will use the augmented versions of AMIRA, MADA and Stanford taggers to tag a large amount of Arabic tweets and add the tokens which they are agreed on to the training data. The taggers use different tagsets. Therefore, we will map these tagsets to a unified tagset consisting of main POS tags. Finally, we will retrain Stanford tagger on the selected labelled data. K_ B_ úæ» BAg.# !! ákA . AîD ®K . I  J.ËA¯ úGAJ k  I.Jk Ë@ ú æÒÊ ... !,punc !,punc #,punc jAlAksy,noun , noun lA,verb ,noun tklmny,verb K B úæ» BAg. !! ákA . AîD ®K . I  I."
R15-1001,W02-2006,0,0.319851,"like companies, football teams, etc.. Handling English Words Our focus is on Arabic tweets, but some of them contain English words. These words may refer to events, locations, English hashtags or retweet of English tweets with comments written in Arabic and they are part of the syntactic structure of Arabic tweets. So, they need to be tagged correctly. In this case, we use Stanford for English (Toutanova et al., 2003) to tag English words as a post-processing step. 5.2 Agreement-based Bootstrapping Bootstrapping is used to create a labelled training data from large amounts of unlabelled data (Cucerzan and Yarowsky, 2002; Zavrel and Daelemans, 2000). There are different ways to select the labelled data from the taggers’ outputs. We will follow (Clark et al., 2003) in using agreement-based training method. We will use the augmented versions of AMIRA, MADA and Stanford taggers to tag a large amount of Arabic tweets and add the tokens which they are agreed on to the training data. The taggers use different tagsets. Therefore, we will map these tagsets to a unified tagset consisting of main POS tags. Finally, we will retrain Stanford tagger on the selected labelled data. K_ B_ úæ» BAg.# !! ákA . AîD ®K . I"
R15-1001,R13-1026,0,0.0859238,"Missing"
R15-1001,P11-2008,0,0.0927512,"Missing"
R15-1001,W12-3705,0,0.173998,"Missing"
R15-1001,P11-1038,0,0.0611084,"G. QªË@ JJ . Ë@” this tweet is an example of this category. AMIRA and Stanford tagged foreign words in this tweet as ’I’m’ is a VBD, ’at’ is a PUNC, ’Arab’ is a NN and ’Bank’ as NN whereas MADA labelled them all as noun. 5 5.1 Pre- and Post-processing As seen in error analysis, unknown words (out-ofvocabulary tokens or OOV) represent a large proportion of mistagged tokens. We argue that normalisation and external knowledge will reduce this proportion which will improve the performance of the proposed tagger. Normalisation is the process of providing in-vocabulary (IV) versions of OOV words (Han and Baldwin, 2011). We create a mapping from OOV tokens to their IV equivalents by using suitable dictionaries and the original token is replaced with its equivalent IV token. External sources of knowledge such as regular expression rules, gazetteer lists and an output of English tagger are also used. The combination of normalisation and external knowledge is applied to text as pre- and post-processing steps. Handling Concatenation Users may connect words deliberately to overcome tweets restricted length or accidentally. This forms tokens which all taggers struggle to tag them correctly. One approach to deal wi"
R15-1001,W13-1608,0,0.0750395,"Missing"
R15-1001,refaee-rieser-2014-arabic,0,0.0449039,"are millions of tweets daily, yielding a corpus which is noisy and informal, but which is sometimes informative. As a result, Twitter has become one of the most important social informa1 Proceedings of Recent Advances in Natural Language Processing, pages 1–8, Hissar, Bulgaria, Sep 7–9 2015. sion of Stanford on it. rors. 3. Boosting the taggers’ performance on Arabic tweets by using pre- and post-processing techniques to address Arabic tweets’ noisiness. 2 3 Data Collection There is a growing interest within the NLP community to build Arabic social media corpora by harvesting the web such as (Refaee and Rieser, 2014; Abdul-Mageed et al., 2012). However, none of these resources are publicly available yet. They also do not contain all phenomena of tweets as they appear in their original forms in Twitter and they have been built to be used mainly in sentiment analysis. Hence, we built our own corpus which preserves all phenomena of Arabic tweets. We used Twitter Stream API to crawl Twitter by setting a query to retrieve tweets from the Arabian Peninsula and Egypt by using latitude and longitude coordinates of these regions since Arabic dialects in these regions share similar characteristics and they are the"
R15-1001,D11-1141,0,0.17152,"Missing"
R15-1001,N03-1033,0,0.21462,"ools on Arabic tweets, with an intention of developing a POS tagger for Arabic tweets by utilising the existing standard POS taggers for MSA instead of building a separate tagger. We use pre- and post-processing modules to improve their accuracy. Then, we will use agreement-based bootstrapping on unlabelled data to create a sufficient amount of labelled training tweets that we can retrain our augmented ver4 Evaluating Existing POS Taggers We evaluate three state-of-the-art publicly available POS taggers for Arabic, namely AMIRA (Diab, 2009), MADA (Habash et al., 2009) and Stanford Log-linear (Toutanova et al., 2003). 4.1 Gold Standard A set of correctly annotated tweets (gold standard) is required in order to be able to appraise the outputs of POS taggers. Once we have this, we can compare the outputs of the POS taggers with this gold standard. Since there is no publicly available annotated corpus for Arabic tweets, we have created POS tags for Twitter phenomena (i.e. REP, MEN, HASH, LINK, USERN and RET for replies, mentions, hashtags, links, usernames and retweets respectively) and we manually annotated our dataset. To speed up manual annotation, we tagged tweets by using the taggers, and then we correc"
R15-1001,zavrel-daelemans-2000-bootstrapping,0,0.0548977,"s, etc.. Handling English Words Our focus is on Arabic tweets, but some of them contain English words. These words may refer to events, locations, English hashtags or retweet of English tweets with comments written in Arabic and they are part of the syntactic structure of Arabic tweets. So, they need to be tagged correctly. In this case, we use Stanford for English (Toutanova et al., 2003) to tag English words as a post-processing step. 5.2 Agreement-based Bootstrapping Bootstrapping is used to create a labelled training data from large amounts of unlabelled data (Cucerzan and Yarowsky, 2002; Zavrel and Daelemans, 2000). There are different ways to select the labelled data from the taggers’ outputs. We will follow (Clark et al., 2003) in using agreement-based training method. We will use the augmented versions of AMIRA, MADA and Stanford taggers to tag a large amount of Arabic tweets and add the tokens which they are agreed on to the training data. The taggers use different tagsets. Therefore, we will map these tagsets to a unified tagset consisting of main POS tags. Finally, we will retrain Stanford tagger on the selected labelled data. K_ B_ úæ» BAg.# !! ákA . AîD ®K . I  J.ËA¯ úGAJ k  I.Jk Ë@ ú æ"
R15-1001,W15-4325,1,\N,Missing
R15-1032,W06-2922,0,0.695149,"rocessing nonprojective sentences is proposed by Kuhlmann and Nivre (2010), which is the non-adjacent arc transitions. This technique allows for creating arcs between non-neighbouring arcs. This is achieved by extending the arc-standard to do the followings: LEFT-ARC-2l : This operation creates an arc by making the topmost item on the stack the parent of the third topmost item on the stack, and removes the topmost item. RIGHT-ARC(2)l : This operation creates an arc by making the third topmost item on the stack the parent of the topmost item on the stack, and removes the topmost item. Although Attardi (2006) claims that LEFTARC(2)l and RIGHT-ARC-2l are sufficient for producing every non-projective tree Kuhlmann and Nivre (2010, p. 6) argues to the contrary. Our re-implementation of the arc-standard algorithm, which is a generalisation of proposFigure 2: Parsing the sentence in Figure 1 using the original arc-standard algorithm. In order to overcome the limitation of the arcstandard algorithm of MaltParser, we allow for combining the head of the queue with an item on the stack that may or may not be the topmost item. Here, we introduce LEFT-ARC(N) and RIGHTARC(N) where N is any non-zero integer: L"
R15-1032,P09-2056,0,0.139556,"element indicates that the pattern occurred j times during the training phase. 234 PARENT,[POS1 ,...,POSn ],DAUGHTER,LABEL,j 7 Figure 4: A schema of a pattern for a label. 6 Dataset The kind of data that is suitable for developing a data-driven parser is an annotated treebank. There are a number of treebanks available for inducing a dependency parser for a number of natural languages. Some of the most popular treebanks for Arabic are: Penn Arabic Treebank (PATB) (Maamouri and Bies, 2004), Prague Arabic dependency treebank (PADT) (Smrˇz and Hajiˇc, 2006), and Columbia Arabic treebank (CATiB) (Habash and Roth, 2009). The linguistic information in PATB is sufficient for inducing a parser. However, the limitation for using this treebank directly for generating a parse model is that its annotation schemata is based on a phrase structure format, which cannot be used for dependency parsing. However, we have converted the phrase structure trees of the PATB to dependency structure trees using the standard conversion algorithm for transforming phrase structure trees to dependency trees, as described is detail by Xia and Palmer (2001). Because we do not have access to the PATD and CATiB treebanks, we have used th"
R15-1032,W03-3017,0,0.185799,"his will lead to the production of a tree that will not match the original tree because that will make 5 the parent of 3, which does not match any relations in the original tree. On the other hand, performing RIGHT-ARC, which is allowed , will make 3 the parent of 5. However, performing RIGHT-ARC at this stage is not an ideal operation because 5 will not be available in subsequent stages when it is required to become the parent of 1, which remains on the queue1 . This means that 1 will subseIntroduction In this paper we present a new implementation of the arc-standard algorithm of MaltParser (Joakim, 2003; Nivre, 2006; Nivre, 2008). The key features of this implementation are that (i) it includes a new approach to handling non-projective trees (Section 3); (ii) it allows the inclusion of information about local subtrees as an extra guide to parsing (Section 8); (iii) the assignment of labels to arcs is carried out as a separate phase of analysis rather than during the determination of dependency relations between words (Section 5). We compare the performance of the arc-standard version of MaltParser with four different versions of our parser in Section 9. 2 Non-projective Parsing Deterministic"
R15-1032,W04-1602,0,0.437911,"re up to n POS tagged items between them and the dependency label between the parent item and daughter item is LABEL where the last element indicates that the pattern occurred j times during the training phase. 234 PARENT,[POS1 ,...,POSn ],DAUGHTER,LABEL,j 7 Figure 4: A schema of a pattern for a label. 6 Dataset The kind of data that is suitable for developing a data-driven parser is an annotated treebank. There are a number of treebanks available for inducing a dependency parser for a number of natural languages. Some of the most popular treebanks for Arabic are: Penn Arabic Treebank (PATB) (Maamouri and Bies, 2004), Prague Arabic dependency treebank (PADT) (Smrˇz and Hajiˇc, 2006), and Columbia Arabic treebank (CATiB) (Habash and Roth, 2009). The linguistic information in PATB is sufficient for inducing a parser. However, the limitation for using this treebank directly for generating a parse model is that its annotation schemata is based on a phrase structure format, which cannot be used for dependency parsing. However, we have converted the phrase structure trees of the PATB to dependency structure trees using the standard conversion algorithm for transforming phrase structure trees to dependency trees"
R15-1032,J08-4003,0,0.593229,"tion of a tree that will not match the original tree because that will make 5 the parent of 3, which does not match any relations in the original tree. On the other hand, performing RIGHT-ARC, which is allowed , will make 3 the parent of 5. However, performing RIGHT-ARC at this stage is not an ideal operation because 5 will not be available in subsequent stages when it is required to become the parent of 1, which remains on the queue1 . This means that 1 will subseIntroduction In this paper we present a new implementation of the arc-standard algorithm of MaltParser (Joakim, 2003; Nivre, 2006; Nivre, 2008). The key features of this implementation are that (i) it includes a new approach to handling non-projective trees (Section 3); (ii) it allows the inclusion of information about local subtrees as an extra guide to parsing (Section 8); (iii) the assignment of labels to arcs is carried out as a separate phase of analysis rather than during the determination of dependency relations between words (Section 5). We compare the performance of the arc-standard version of MaltParser with four different versions of our parser in Section 9. 2 Non-projective Parsing Deterministic Shift-reduce Parsing The a"
R15-1032,R15-1032,1,0.0513221,"Missing"
R15-1032,H01-1014,0,\N,Missing
S18-1030,C10-2005,0,0.0643488,"classes. There has been much work in the areas of sentiment detection (Rosenthal et al., 2017), emotion intensity (Mohammad and Bravo-Marquez, 2017) and emotion categorisation (Hasan et al., 2014). Sentiment analysis aims to classify tweets into positive, negative, and neutral categories, emotion intensity is determining the intensity or degree of an emotion felt by the speaker and emotion categorisation is the classification of tweets based on their emotions. The most commonly used classification techniques are Naive Bayes and Support Vector Machines (SVM). Some researchers report that SVMs (Barbosa and Feng, 2010) perform better while others support Naive Bayes (Pak and Paroubek, 2010). Furthermore, sophisticated techniques such as deep neural networks have also been proposed but such techniques are rarely used by non-experts of machine learning in practice (Sarker and Gonzalez, 2017) and they also take a long time to train. We propose a simple and effective method to classify tweets that performs reasonably well. Our system does not make use of any lexicons or stop word lists and is quick to train. In this paper we present our contribution to SemEval-2018, a classifier for classifying multi-label emot"
S18-1030,J95-4004,0,0.259567,"emonstrates and we identify the tokens that led us to these conclusions. A tweet is classified for each emotion by adding the scores for each token for each emotion. These scores are normalised and compared to a threshold t. If the value is less than t we deduce the tweet did not demonstrate the emotion, otherwise it did demonstrate the emotion. We are unsure what a good threshold is so we use a range of values for t from 0 to 1 (in steps of 0.1) to create score sets. We calculate the Jaccard for each of these and use the best one of these for classification. This approach is based on Brills (Brill, 1995) suggestion that one should attempt to learn from ones own mistakes. 2.1 Other Strategies Increased training data. We believe that having more training data might improve our classifer. One of the obvious places to get more data is from the datasets for some of the other tasks, specifically EI-reg and EI-oc. A key problem with this data is that both of these tasks only supply datasets for anger, fear, joy and sadness. The Elreg dataset is marked up with a per-tweet intensity value between 0-1 that represents the mental state of the tweeter. The EI-oc dataset tweets are marked up with one of fo"
S18-1030,S17-1007,0,0.0251883,"ool of Computer Science School of Computer Science University of Manchester University of Manchester Oxford Road, Manchester Oxford Road, Manchester M13 9PL, U.K. M13 9PL, U.K. tariq.ahmad@postgrad allan.ramsay@ .manchester.ac.uk manchester.ac.uk Abstract Multi-label classification of tweets is a classification problem where tweets are assigned to two or more classes. It is considered more complex than traditional classification tasks because the classifier has to predict several classes. There has been much work in the areas of sentiment detection (Rosenthal et al., 2017), emotion intensity (Mohammad and Bravo-Marquez, 2017) and emotion categorisation (Hasan et al., 2014). Sentiment analysis aims to classify tweets into positive, negative, and neutral categories, emotion intensity is determining the intensity or degree of an emotion felt by the speaker and emotion categorisation is the classification of tweets based on their emotions. The most commonly used classification techniques are Naive Bayes and Support Vector Machines (SVM). Some researchers report that SVMs (Barbosa and Feng, 2010) perform better while others support Naive Bayes (Pak and Paroubek, 2010). Furthermore, sophisticated techniques such as deep"
S18-1030,S18-1001,0,0.0583612,"Missing"
S18-1030,pak-paroubek-2010-twitter,0,0.0276599,"senthal et al., 2017), emotion intensity (Mohammad and Bravo-Marquez, 2017) and emotion categorisation (Hasan et al., 2014). Sentiment analysis aims to classify tweets into positive, negative, and neutral categories, emotion intensity is determining the intensity or degree of an emotion felt by the speaker and emotion categorisation is the classification of tweets based on their emotions. The most commonly used classification techniques are Naive Bayes and Support Vector Machines (SVM). Some researchers report that SVMs (Barbosa and Feng, 2010) perform better while others support Naive Bayes (Pak and Paroubek, 2010). Furthermore, sophisticated techniques such as deep neural networks have also been proposed but such techniques are rarely used by non-experts of machine learning in practice (Sarker and Gonzalez, 2017) and they also take a long time to train. We propose a simple and effective method to classify tweets that performs reasonably well. Our system does not make use of any lexicons or stop word lists and is quick to train. In this paper we present our contribution to SemEval-2018, a classifier for classifying multi-label emotions of Arabic and English tweets. We attempted “Affect in Tweets”, speci"
S18-1030,W11-0705,0,0.079644,"Missing"
S18-1030,S17-2088,0,0.0336389,"l Probabilities Tariq Ahmad Allan Ramsay School of Computer Science School of Computer Science University of Manchester University of Manchester Oxford Road, Manchester Oxford Road, Manchester M13 9PL, U.K. M13 9PL, U.K. tariq.ahmad@postgrad allan.ramsay@ .manchester.ac.uk manchester.ac.uk Abstract Multi-label classification of tweets is a classification problem where tweets are assigned to two or more classes. It is considered more complex than traditional classification tasks because the classifier has to predict several classes. There has been much work in the areas of sentiment detection (Rosenthal et al., 2017), emotion intensity (Mohammad and Bravo-Marquez, 2017) and emotion categorisation (Hasan et al., 2014). Sentiment analysis aims to classify tweets into positive, negative, and neutral categories, emotion intensity is determining the intensity or degree of an emotion felt by the speaker and emotion categorisation is the classification of tweets based on their emotions. The most commonly used classification techniques are Naive Bayes and Support Vector Machines (SVM). Some researchers report that SVMs (Barbosa and Feng, 2010) perform better while others support Naive Bayes (Pak and Paroubek, 201"
S18-1030,S17-2105,0,0.157906,"tral categories, emotion intensity is determining the intensity or degree of an emotion felt by the speaker and emotion categorisation is the classification of tweets based on their emotions. The most commonly used classification techniques are Naive Bayes and Support Vector Machines (SVM). Some researchers report that SVMs (Barbosa and Feng, 2010) perform better while others support Naive Bayes (Pak and Paroubek, 2010). Furthermore, sophisticated techniques such as deep neural networks have also been proposed but such techniques are rarely used by non-experts of machine learning in practice (Sarker and Gonzalez, 2017) and they also take a long time to train. We propose a simple and effective method to classify tweets that performs reasonably well. Our system does not make use of any lexicons or stop word lists and is quick to train. In this paper we present our contribution to SemEval-2018, a classifier for classifying multi-label emotions of Arabic and English tweets. We attempted “Affect in Tweets”, specifically Task E-c: Detecting Emotions (multi-label classification). Our method is based on preprocessing the tweets and creating word vectors combined with a self correction step to remove noise. We also"
S18-1030,R15-1001,1,0.901438,"Missing"
S18-1030,W16-3912,1,0.862657,"o we replace emojis with emoji identifiers (e.g. 45 ). We also separate out contiguous emojis because we want, for example, the individual emojis in a group of repeating unhappy face emojis to be recognised, and processed, as being the same emoji as a single unhappy face emoji. We remove usernames because we believe they are noise since, by and large, they will not reappear in the test set, are not helpful to us and if not removed will compromise our ability to detect useful information. Arabic tweets are stemmed using a stemmer developed specifically for Arabic tweets by Albogamy and Ramsay (Albogamy and Ramsay, 2016). English tweets are stemmed by taking the shortest result from Morphy (Fellbaum, 1998) when tokens are stemmed as nouns, verbs, adjectives and adverbs. Although there are surprisingly few examples of these, we believe that multi-word hashtags, joined by underscore or a dash, also contain useful information so we leave the hashtag as is but also take a copy of the hashtag and split it into its constituent words. This is so that where possible we improve the quality of information in the tweet. Stop word lists are not used at any stage. We debated using stop words vs insignificant words and, as"
W06-3903,T75-2014,0,0.698953,"iefs of John and Sally in this situation for the planner: (i) to be able to plan John’s utterance; and (ii) to additionally deduce whether John’s utterance would be felicitous or infelicitous, if he performed it. 3 4 The example is an English paraphrase of a task, written in the model in Prolog code. An albatross (Diomedea exulans) is a huge sea-faring bird, rarely seen from the land. 2.1 Linguistic motivations Our approach to planning the semantics of utterances was to build on seminal work in speech acts [3,28] and pragmatics [29,15,21]. In contrast to the ‘speech acts with STRIPS’ approach [6,11,1,2], which is fraught with well-documented difficulties [9,16,26,7,27], we aimed to develop a small set of linguistic acts that were unambiguously identifiable purely by surface linguistic form (after [7]), including ‘declare’, ‘request’, and perhaps others—a set of acts with negligible effects (after [27]), and minimal preconditions. We in fact developed a single linguistic act for all contexts. 2.2 Planner design The planner is essentially an epistemic theorem prover which employs some planning search. The development process we undertook is helpful in understanding the planner’s design: • • •"
W07-2320,P96-1009,0,0.0594129,"iscussed. To do this, the system would require the ability to write an appropriate summarised text on the basis of its expert knowledge. This would require the additional knowledge of how to construct an argument, as well as more in-depth knowledge of discourse structure (unless stock answers to anticipated questions had been prepared manually in advance for such occasions), work we consider feasible, given collaboration with argumentation experts, and considerable further development. We acknowledge that our work is just one of many in a tradition of dialogue system implementations, (TRAINS (Allen et al., 1996), TRINDIKIT (Larsson and Traum, 2000), and GoDiS (Larsson et al., 2000), to mention a few). 11 Acknowledgements Our thanks go to Floriana Grasso for her valuable input. This work was funded under EU-grant Figure 7: Fleshed-out message skeleton in response to (11) [YES, aspect(now,simple,#813(lambda(B,exists(C,walk(C) & theta(C,agent,B))),S)), state(#813(lambda(D,exists(E,walk(E) & theta(E,agent,D))),S)), theta(#813(lambda(F,exists(G,walk(G) & theta(G,agent,F))),S),pred,lambda(H,good(H))), lambda(I,theta(#813(lambda(J,exists(K,walk(K) & theta(K,agent,J))),S),topic(ref),I)) < lambda(J,exists(K,w"
W07-2320,W98-1410,0,0.0217206,"t the system dump all its expert knowledge on the user at once, regardless of the user’s desires and needs. It is viewing the user’s own utterances as insights into the gaps in the user’s knowledge that the user is keen to have filled, and then attempting to fill those particular gaps as precisely as possible, neither being more informative than necessary, nor less. Technically speaking, the explanatory information contained in the ‘because. . . ’ clause in (9) is drawn from the proof tree that was constructed by the theorem prover while working out its response to the user’s question (after (Fiedler, 1998)).1 The structure of all proof trees is as follows: (10) g1 +[g11 +[g111 +[] ], g12 +[g121 +[], g122 +[g1221 +[]] ] ] where G +[LIST...] means [LIST...] are the subproofs of GOAL. Fig. 5 is the proof tree that the system constructs while it is formulating its response to utterance (11): (11) U: I am overweight. Is walking good for me? One change has been made to make this proof tree easier to read. In the tree from the implementation, the skolem function #813(lambda(B, exists(C, walk(C) & theta(C, agent, B)))) appears many times, and means roughly There is a set of walking events C whose agent"
W07-2320,J95-2003,0,0.0489285,"ried out the action described by P. 4 Discourse model Having derived the meaning of a user’s utterance, the system adds the meaning plus a record of who uttered it to the ‘minutes’ (after (Thomason, 1990; Lewis, 1979; Stalnaker, 1972)). Individual entities (including the events) that have been mentioned during the discourse are represented in a ‘discourse model’ as unique skolem constants, while n-place predicates describe the detail of what has been said about each entity (Ramsay and Seville, 2000). The skolems are anchored (Barwise and Perry, 1983) and note is taken of the order of centres (Grosz et al., 1995) so that NPs in later user utterances can be dereferenced successfully, and that in its own utterances, the system will know how to refer to entities in ways which enable the user to dereference them. The discourse model enables the system to remember everything that has been said during the discourse, who said what, which order the utterances were made in, which entities have been mentioned during the discourse (and on which turn), and how they were referred to. This enables the system, during the formulation of a response to a user, to use information that she introduced into the conversatio"
W07-2320,W00-0302,0,0.0333203,"n appropriate summarised text on the basis of its expert knowledge. This would require the additional knowledge of how to construct an argument, as well as more in-depth knowledge of discourse structure (unless stock answers to anticipated questions had been prepared manually in advance for such occasions), work we consider feasible, given collaboration with argumentation experts, and considerable further development. We acknowledge that our work is just one of many in a tradition of dialogue system implementations, (TRAINS (Allen et al., 1996), TRINDIKIT (Larsson and Traum, 2000), and GoDiS (Larsson et al., 2000), to mention a few). 11 Acknowledgements Our thanks go to Floriana Grasso for her valuable input. This work was funded under EU-grant Figure 7: Fleshed-out message skeleton in response to (11) [YES, aspect(now,simple,#813(lambda(B,exists(C,walk(C) & theta(C,agent,B))),S)), state(#813(lambda(D,exists(E,walk(E) & theta(E,agent,D))),S)), theta(#813(lambda(F,exists(G,walk(G) & theta(G,agent,F))),S),pred,lambda(H,good(H))), lambda(I,theta(#813(lambda(J,exists(K,walk(K) & theta(K,agent,J))),S),topic(ref),I)) < lambda(J,exists(K,walk(K) & theta(K,agent,J))), for(#813(lambda(L,exists(M,walk(M) & theta"
W08-2216,C92-1037,1,0.689795,"Missing"
W08-2216,W14-0904,0,0.0608956,"Missing"
W09-3717,C96-2197,0,0.0815022,"Missing"
W14-3609,J95-4004,0,0.499143,"Missing"
W14-3609,C10-1094,0,0.0438189,"Missing"
W14-3609,C10-1045,0,0.028561,"een different kinds of nouns and verbs (e.g. between subject and object case nouns) in the absence of visible markers make this an extremely difficult tagset to work with. It is in general virtually impossible to decide the case of an Arabic noun until its overall syntactic role is determined, and it is similarly difficult to decide the form of a verb until the overall syntactic structure of the sentence is determined. For this reason taggers often work with a coarser set of tags, of which the ‘Bies tagset’ (Maamouri and Bies, 2004) is widely used (see for instance the Stanford Arabic parser (Green and Manning, 2010)). We carried out our experiments with a variant of the original fine-grained tagset, and also with a variant of the coarser-grained Bies set obtained by deleting details such as case- and agreement-markers. We carried out two sets of experiments, with a coarsegrained set of tags (a superset of the Bies tagset with 39 tags, shown in Figure 1) and the original fine-grained one with 305 tags. ABBREV ADJ ADV CONJ CV CVSUFF DO DEM PRON DET DET+ADJ DET+NOUN DET+NOUN PROP DET+NUM EMPH PART EXCEPT PART FOCUS PART FUT+IV INTERJ INTERROG PART IV IVSUFF DO LATIN NEG PART NOUN NOUN PROP NO FUNC NUM Coars"
W14-3609,W05-1518,0,0.0714614,"Missing"
W14-3609,E99-1047,0,0.152687,"Missing"
W14-3609,W04-1602,0,0.0445924,"rent kinds of verb and 44 for different kinds of noun. The very fine distinctions between different kinds of nouns and verbs (e.g. between subject and object case nouns) in the absence of visible markers make this an extremely difficult tagset to work with. It is in general virtually impossible to decide the case of an Arabic noun until its overall syntactic role is determined, and it is similarly difficult to decide the form of a verb until the overall syntactic structure of the sentence is determined. For this reason taggers often work with a coarser set of tags, of which the ‘Bies tagset’ (Maamouri and Bies, 2004) is widely used (see for instance the Stanford Arabic parser (Green and Manning, 2010)). We carried out our experiments with a variant of the original fine-grained tagset, and also with a variant of the coarser-grained Bies set obtained by deleting details such as case- and agreement-markers. We carried out two sets of experiments, with a coarsegrained set of tags (a superset of the Bies tagset with 39 tags, shown in Figure 1) and the original fine-grained one with 305 tags. ABBREV ADJ ADV CONJ CV CVSUFF DO DEM PRON DET DET+ADJ DET+NOUN DET+NOUN PROP DET+NUM EMPH PART EXCEPT PART FOCUS PART FU"
W14-3609,nivre-etal-2006-maltparser,0,\N,Missing
W14-3609,W99-0623,0,\N,Missing
W14-3609,W06-2932,0,\N,Missing
W16-3912,R15-1001,1,0.58305,"o six sub-tokens as illustrated by Figure1. Similarly a verb can comprise up to five sub-tokens as illustrated by Figure 2. The combination of words with affixes is governed by various rules. These rules are called grammar-lexis specifications (Dichy and Farghaly, 2003). An example of these specifications is a rule that states that the prefix ”s”, which denotes the future of verbs, is only combined with imperfective verb stems. 4 Our Approach Although Arabic tweets and MSA are closely related and share many characteristics, there are substantial differences between them in lexicon and syntax (Albogamy and Ramsay, 2015). The lexicon is always evolving and many words in Arabic tweets are not present in MSA. Therefore, dictionary-based stemming approaches will not work for Arabic tweets. The statistical approaches that are used to induce a list of affixes automatically are also not applicable because we predefined a limited set of prefixes and suffixes for Arabic tweets and there is no annotated training data available. In Arabic tweets domain, there are millions of words that need to be stemmed, so stemming approaches that use a set of rules to identify words patterns are not suitable because they consume lot"
W16-3912,N07-1020,0,0.0296981,"t may not even be a real Arabic word (Paice, 1994). (Al-Kabi et al., 2015) uses a light stemmer approach but does not cover all affixes in Arabic. Statistical approach is a process of inducing a list of affixes automatically and using clustering techniques to group word variants. Most statistical approaches require annotated training data such as (Darwish and Oard, 2007) and (De Roeck and Al-Fares, 2000). This data is expensive and is not always available. Although there have been some positive results with un annotated training data for many different languages such as (Goldsmith, 2001) and (Dasgupta and Ng, 2007), it seems likely the complexity of Arabic language makes that kind of approach is infeasible. On the other hand, there has been relatively little work on building stemmers for Arabic dialect. Most of these works targeted one specific dialect such as (Alamlahi and Ahmed, 2007) and (Al-Gaphari and Al-Yadoumi, 2010). Our work is, to the best of our knowledge, the first step towards developing a stemmer for Arabic tweets or similar text styles which can benefit a wide range of downstream NLP applications such as information extraction and machine translation. Our approach does not rely on any roo"
W16-3912,2003.mtsummit-semit.5,0,0.0301573,"at Arabic affixes (prefixes and suffixes) attach to the base word in a strict order. These affixes are differ based on the word type, but in general we can represent the word as follows: Word ≡ Prefixes + Stem + Suffixes Arabic morphotactics allow words to have affixes. Affixes themselves can be concatenated one after the other. A noun can comprise up to six sub-tokens as illustrated by Figure1. Similarly a verb can comprise up to five sub-tokens as illustrated by Figure 2. The combination of words with affixes is governed by various rules. These rules are called grammar-lexis specifications (Dichy and Farghaly, 2003). An example of these specifications is a rule that states that the prefix ”s”, which denotes the future of verbs, is only combined with imperfective verb stems. 4 Our Approach Although Arabic tweets and MSA are closely related and share many characteristics, there are substantial differences between them in lexicon and syntax (Albogamy and Ramsay, 2015). The lexicon is always evolving and many words in Arabic tweets are not present in MSA. Therefore, dictionary-based stemming approaches will not work for Arabic tweets. The statistical approaches that are used to induce a list of affixes autom"
W16-3912,J01-2001,0,0.213151,"y produce the stem that may not even be a real Arabic word (Paice, 1994). (Al-Kabi et al., 2015) uses a light stemmer approach but does not cover all affixes in Arabic. Statistical approach is a process of inducing a list of affixes automatically and using clustering techniques to group word variants. Most statistical approaches require annotated training data such as (Darwish and Oard, 2007) and (De Roeck and Al-Fares, 2000). This data is expensive and is not always available. Although there have been some positive results with un annotated training data for many different languages such as (Goldsmith, 2001) and (Dasgupta and Ng, 2007), it seems likely the complexity of Arabic language makes that kind of approach is infeasible. On the other hand, there has been relatively little work on building stemmers for Arabic dialect. Most of these works targeted one specific dialect such as (Alamlahi and Ahmed, 2007) and (Al-Gaphari and Al-Yadoumi, 2010). Our work is, to the best of our knowledge, the first step towards developing a stemmer for Arabic tweets or similar text styles which can benefit a wide range of downstream NLP applications such as information extraction and machine translation. Our appro"
W16-3912,P00-1026,0,\N,Missing
W17-1312,R15-1001,1,0.795379,"Missing"
W17-1312,L16-1238,1,0.846154,"ts to construct a treebank with a reasonable size. In the first experiment we used RBP only whereas in the second experiment we used RBP and MaltParser as described in Section 3. @ 4.1 The corpus from which we extract our dataset is an existing POS-tagged corpus taken from Twitter. Twitter Stream API was used to retrieve tweets from the Arabian Peninsula by using latitude and longitude coordinates of these regions since Arabic dialects in these regions share similar characteristics and they are the closest Arabic dialects to MSA. The corpus was tagged by the Arabic tweets tagger described in (Albogamy and Ramsay, 2016). We sampled 10K tagged tweets from the corpus to experiment on them. nagwahussein1 AJ m&apos; tHyA QåÓ mSr 4.2 Ð@ PA SAr Al∗y AJ KX dnyA È@ Al Y¯ H qd t AJ KX dnyA È@ Al http://... Figure 4: Using RBP as a Filter 4 Results In our experiments, we used two different strategies to create a dependency treebank: using RBP only and using RBP and MaltParser in a bootstrapping technique. We do the evaluation on tweets that RBP gives analyses for. The accuracy of other tweets which do not have sensible analyses cannot be tested because it is impossible to say what the right answer would be. As we men"
W17-1312,W02-2006,0,0.0856462,"Missing"
W17-1312,D14-1108,0,0.0357063,"Missing"
W17-1312,J93-2004,0,0.0588799,"se trees by applying these rules to input sentences. It uses a dictionary or lexicon to store information about each word in input text before applying the linguistic rules. Although this kind of parser is widely-used in a variety of NLP systems to provide deep linguistic analyses, they have disadvantages: they are slow and it is time-consuming, expensive and tedious to construct dictionaries and to write the rules by expert linguists and hard to maintain them. In recent years, data-driven parsers have been widely used due to the availability of annotated data such as the Penn Treebank (PTB) (Marcus et al., 1993) and the Penn Arabic Treebak (PATB) (Maamouri et al., 2004). These parsers are robust and produce state-of-the-art results compared to rule-based ones. However, the reliance on anno2 Related Work Although data-driven parsers have achieved stateof-the-art results on well-formed texts, they have not performed well on user-generated text because the nature of the texts found in user-contributed online forums rarely complies with the standard rules of the underlying language, which makes them challenging for traditional NLP tools, including data-driven approaches, even if domain adaptation techniq"
W17-1312,nivre-etal-2006-maltparser,0,0.173437,"a data-driven parser (version of MaltParser) with three basic data structures a queue of unexamined words, a stack of words that have been considered but which have not been assigned heads, and a collection of &lt;head,relation,daughter&gt; triples; and with three basic actions, namely shift (move an item from the queue to the stack), leftArc (make the top item on the stack a daughter of the head of the queue and remove it from the stack), rightArc (make the head of the queue a daughter of the top item of the stack, remove the head of the queue and move the top item of the stack back to the queue) (Nivre et al., 2006). The bootstrapping method (Figure 3) begins by using RBP to parse an existing POS-tagged corpus to create a small treebank of one thousand Arabic tweets. Then, MaltParser is trained on the small treebank which was created by RBP and used to parse a much larger set of POS-tagged Arabic tweets. During parsing, the RBP is used as a filter. To use it as a filter, we run the RBP but only allow hypothesises that correspond to links that were suggested by MaltParser so it produces a tree if and only if that tree was produced by MaltParser. As a result, all dependency analyses which do not conform to"
W17-1312,C12-1149,0,0.187568,"Treebak (PATB) (Maamouri et al., 2004). These parsers are robust and produce state-of-the-art results compared to rule-based ones. However, the reliance on anno2 Related Work Although data-driven parsers have achieved stateof-the-art results on well-formed texts, they have not performed well on user-generated text because the nature of the texts found in user-contributed online forums rarely complies with the standard rules of the underlying language, which makes them challenging for traditional NLP tools, including data-driven approaches, even if domain adaptation techniques have been used (Seddah et al., 2012). The nature of the text content of Arabic tweets 94 Proceedings of The Third Arabic Natural Language Processing Workshop (WANLP), pages 94–99, c Valencia, Spain, April 3, 2017. 2017 Association for Computational Linguistics will not be replicated in unseen tweets. Given that the RBP will fail to provide an analysis of such material, it acts as an automatic filter to remove it. RBP is, however, quite slow and to construct a large treebank using it is very time-consuming and difficult to make a big treebank. Therefore, we just use it to produce a small treebank as a seed training for MaltParser"
W99-0111,J86-3001,0,0.0932033,"Missing"
W99-0111,P97-1014,0,0.0418314,"Missing"
W99-0111,P98-1090,0,0.0237342,"Missing"
W99-0111,P93-1010,0,0.0592067,"Missing"
