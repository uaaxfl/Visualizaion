2021.emnlp-main.445,Exploring Strategies for Generalizable Commonsense Reasoning with Pre-trained Models,2021,-1,-1,5,1,9607,kaixin ma,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Commonsense reasoning benchmarks have been largely solved by fine-tuning language models. The downside is that fine-tuning may cause models to overfit to task-specific data and thereby forget their knowledge gained during pre-training. Recent works only propose lightweight model updates as models may already possess useful knowledge from past experience, but a challenge remains in understanding what parts and to what extent models should be refined for a given task. In this paper, we investigate what models learn from commonsense reasoning datasets. We measure the impact of three different adaptation methods on the generalization and accuracy of models. Our experiments with two models show that fine-tuning performs best, by learning both the content and the structure of the task, but suffers from overfitting and limited generalization to novel answers. We observe that alternative adaptation methods like prefix-tuning have comparable accuracy, but generalize better to unseen answers and are more robust to adversarial splits."
2021.dialdoc-1.14,Building Goal-oriented Document-grounded Dialogue Systems,2021,-1,-1,6,0,762,xi chen,Proceedings of the 1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021),0,"In this paper, we describe our systems for solving the two Doc2Dial shared task: knowledge identification and response generation. We proposed several pre-processing and post-processing methods, and we experimented with data augmentation by pre-training the models on other relevant datasets. Our best model for knowledge identification outperformed the baseline by 10.5+ f1-score on the test-dev split, and our best model for response generation outperformed the baseline by 11+ Sacrebleu score on the test-dev split."
2020.nlposs-1.6,Flexible retrieval with {NMSLIB} and {F}lex{N}eu{ART},2020,-1,-1,2,0,16040,leonid boytsov,Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS),0,"Our objective is to introduce to the NLP community NMSLIB, describe a new retrieval toolkit FlexNeuART, as well as their integration capabilities. NMSLIB, while being one the fastest k-NN search libraries, is quite generic and supports a variety of distance/similarity functions. Because the library relies on the distance-based structure-agnostic algorithms, it can be further extended by adding new distances. FlexNeuART is a modular, extendible and flexible toolkit for candidate generation in IR and QA applications, which supports mixing of classic and neural ranking signals. FlexNeuART can efficiently retrieve mixed dense and sparse representations (with weights learned from training data), which is achieved by extending NMSLIB. In that, other retrieval systems work with purely sparse representations (e.g., Lucene), purely dense representations (e.g., FAISS and Annoy), or only perform mixing at the re-ranking stage."
W19-5041,Pentagon at {MEDIQA} 2019: Multi-task Learning for Filtering and Re-ranking Answers using Language Inference and Question Entailment,2019,0,0,6,0,23974,hemant pugaliya,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have quickly become the state of the art, bypassing previous deep and shallow learning methods by a large margin. More recently, pre-trained models from large related datasets have been able to perform well on many downstream tasks by just fine-tuning on domain-specific datasets (similar to transfer learning). However, using powerful models on non-trivial tasks, such as ranking and large document classification, still remains a challenge due to input size limitations of parallel architecture and extremely small datasets (insufficient for fine-tuning). In this work, we introduce an end-to-end system, trained in a multi-task setting, to filter and re-rank answers in the medical domain. We use task-specific pre-trained models as deep feature extractors. Our model achieves the highest Spearman{'}s Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on the ACL-BioNLP workshop MediQA Question Answering shared-task."
W19-5048,{D}r.{Q}uad at {MEDIQA} 2019: Towards Textual Inference and Question Entailment using contextualized representations,2019,12,1,6,0,10462,vinayshekhar kumar,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"This paper presents the submissions by TeamDr.Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our system is based on the prior work Liu et al. (2019) which uses a multi-task objective function for textual entailment. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating domain knowledge through data augmentation is a powerful strategy for addressing challenges posed specialized domains such as medicine."
W19-5049,Sieg at {MEDIQA} 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment,2019,0,1,4,0,23987,sai bhaskar,Proceedings of the 18th BioNLP Workshop and Shared Task,0,This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our model to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.
P19-1606,Storyboarding of Recipes: Grounded Contextual Generation,2019,0,1,2,0.972222,6250,khyathi chandu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61{\%} found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes. We also discuss analysis of the output highlighting key important NLP issues for prospective directions."
D19-6003,Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering,2019,40,2,4,1,9607,kaixin ma,Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing,0,"Non-extractive commonsense QA remains a challenging AI task, as it requires systems to reason about, synthesize, and gather disparate pieces of information, in order to generate responses to queries. Recent approaches on such tasks show increased performance, only when models are either pre-trained with additional information or when domain-specific heuristics are used, without any special consideration regarding the knowledge resource type. In this paper, we perform a survey of recent commonsense QA methods and we provide a systematic analysis of popular knowledge resources and knowledge-integration methods, across benchmarks from multiple commonsense datasets. Our results and analysis show that attention-based injection seems to be a preferable choice for knowledge integration and that the degree of domain overlap, between knowledge bases and datasets, plays a crucial role in determining model success."
D19-5818,Bend but Don{'}t Break? Multi-Challenge Stress Test for {QA} Models,2019,0,0,5,0,23974,hemant pugaliya,Proceedings of the 2nd Workshop on Machine Reading for Question Answering,0,"The field of question answering (QA) has seen rapid growth in new tasks and modeling approaches in recent years. Large scale datasets and focus on challenging linguistic phenomena have driven development in neural models, some of which have achieved parity with human performance in limited cases. However, an examination of state-of-the-art model output reveals that a gap remains in reasoning ability compared to a human, and performance tends to degrade when models are exposed to less-constrained tasks. We are interested in more clearly defining the strengths and limitations of leading models across diverse QA challenges, intending to help future researchers with identifying pathways to generalizable performance. We conduct extensive qualitative and quantitative analyses on the results of four models across four datasets and relate common errors to model capabilities. We also illustrate limitations in the datasets we examine and discuss a way forward for achieving generalizable models and datasets that broadly test QA capabilities."
W18-5307,Extraction Meets Abstraction: Ideal Answer Generation for Biomedical Questions,2018,0,4,6,0,27996,yutong li,Proceedings of the 6th {B}io{ASQ} Workshop A challenge on large-scale biomedical semantic indexing and question answering,0,"The growing number of biomedical publications is a challenge for human researchers, who invest considerable effort to search for relevant documents and pinpointed answers. Biomedical Question Answering can automatically generate answers for a user{'}s topic or question, significantly reducing the effort required to locate the most relevant information in a large document corpus. Extractive summarization techniques, which concatenate the most relevant text units drawn from multiple documents, perform well on automatic evaluation metrics like ROUGE, but score poorly on human readability, due to the presence of redundant text and grammatical errors in the answer. This work moves toward abstractive summarization, which attempts to distill and present the meaning of the original text in a more coherent way. We incorporate a sentence fusion approach, based on Integer Linear Programming, along with three novel approaches for sentence ordering, in an attempt to improve the human readability of ideal answers. Using an open framework for configuration space exploration (BOOM), we tested over 2000 unique system configurations in order to identify the best-performing combinations for the sixth edition of Phase B of the BioASQ challenge."
W18-5310,Ontology-Based Retrieval {\\&} Neural Approaches for {B}io{ASQ} Ideal Answer Generation,2018,0,3,7,0,28002,ashwin kumar,Proceedings of the 6th {B}io{ASQ} Workshop A challenge on large-scale biomedical semantic indexing and question answering,0,"The ever-increasing magnitude of biomedical information sources makes it difficult and time-consuming for a human researcher to find the most relevant documents and pinpointed answers for a specific question or topic when using only a traditional search engine. Biomedical Question Answering systems automatically identify the most relevant documents and pinpointed answers, given an information need expressed as a natural language question. Generating a non-redundant, human-readable summary that satisfies the information need of a given biomedical question is the focus of the Ideal Answer Generation task, part of the BioASQ challenge. This paper presents a system for ideal answer generation (using ontology-based retrieval and a neural learning-to-rank approach, combined with extractive and abstractive summarization techniques) which achieved the highest ROUGE score of 0.659 on the BioASQ 5b batch 2 test."
W18-3204,Code-Mixed Question Answering Challenge: Crowd-sourcing Data and Techniques,2018,0,5,7,1,6250,khyathi chandu,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Code-Mixing (CM) is the phenomenon of alternating between two or more languages which is prevalent in bi- and multi-lingual communities. Most NLP applications today are still designed with the assumption of a single interaction language and are most likely to break given a CM utterance with multiple languages mixed at a morphological, phrase or sentence level. For example, popular commercial search engines do not yet fully understand the intents expressed in CM queries. As a first step towards fostering research which supports CM in NLP applications, we systematically crowd-sourced and curated an evaluation dataset for factoid question answering in three CM languages - Hinglish (Hindi+English), Tenglish (Telugu+English) and Tamlish (Tamil+English) which belong to two language families (Indo-Aryan and Dravidian). We share the details of our data collection process, techniques which were used to avoid inducing lexical bias amongst the crowd workers and other CM specific linguistic properties of the dataset. Our final dataset, which is available freely for research purposes, has 1,694 Hinglish, 2,848 Tamlish and 1,391 Tenglish factoid questions and their answers. We discuss the techniques used by the participants for the first edition of this ongoing challenge."
W18-2610,Comparative Analysis of Neural {QA} models on {SQ}u{AD},2018,14,1,3,0,28417,soumya wadhwa,Proceedings of the Workshop on Machine Reading for Question Answering,0,"The task of Question Answering has gained prominence in the past few decades for testing the ability of machines to understand natural language. Large datasets for Machine Reading have led to the development of neural models that cater to deeper language understanding compared to information retrieval tasks. Different components in these neural architectures are intended to tackle different challenges. As a first step towards achieving generalization across multiple domains, we attempt to understand and compare the peculiarities of existing end-to-end neural models on the Stanford Question Answering Dataset (SQuAD) by performing quantitative as well as qualitative analysis of the results attained by each of them. We observed that prediction errors reflect certain model-specific biases, which we further discuss in this paper."
W18-2312,{B}io{AMA}: Towards an End to End {B}io{M}edical Question Answering System,2018,0,4,5,0,27688,vasu sharma,Proceedings of the {B}io{NLP} 2018 workshop,0,"In this paper, we present a novel Biomedical Question Answering system, BioAMA: {``}Biomedical Ask Me Anything{''} on task 5b of the annual BioASQ challenge. In this work, we focus on a wide variety of question types including factoid, list based, summary and yes/no type questions that generate both exact and well-formed {`}ideal{'} answers. For summary-type questions, we combine effective IR-based techniques for retrieval and diversification of relevant snippets for a question to create an end-to-end system which achieves a ROUGE-2 score of 0.72 and a ROUGE-SU4 score of 0.71 on ideal answer questions (7{\%} improvement over the previous best model). Additionally, we propose a novel NLI-based framework to answer the yes/no questions. To train the NLI model, we also devise a transfer-learning technique by cross-domain projection of word embeddings. Finally, we present a two-stage approach to address the factoid and list type questions by first generating a candidate set using NER taggers and ranking them using both supervised or unsupervised techniques."
W18-1001,Towards Inference-Oriented Reading Comprehension: {P}arallel{QA},2018,18,2,4,0,28417,soumya wadhwa,Proceedings of the Workshop on Generalization in the Age of Deep Learning,0,"In this paper, we investigate the tendency of end-to-end neural Machine Reading Comprehension (MRC) models to match shallow patterns rather than perform inference-oriented reasoning on RC benchmarks. We aim to test the ability of these systems to answer questions which focus on referential inference. We propose ParallelQA, a strategy to formulate such questions using parallel passages. We also demonstrate that existing neural models fail to generalize well to this setting."
W17-5545,How Would You Say It? Eliciting Lexically Diverse Dialogue for Supervised Semantic Parsing,2017,0,4,6,0,10888,abhilasha ravichander,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"Building dialogue interfaces for real-world scenarios often entails training semantic parsers starting from zero examples. How can we build datasets that better capture the variety of ways users might phrase their queries, and what queries are actually realistic? Wang et al. (2015) proposed a method to build semantic parsing datasets by generating canonical utterances using a grammar and having crowdworkers paraphrase them into natural wording. A limitation of this approach is that it induces bias towards using similar language as the canonical utterances. In this work, we present a methodology that elicits meaningful and lexically diverse queries from users for semantic parsing tasks. Starting from a seed lexicon and a generative grammar, we pair logical forms with mixed text-image representations and ask crowdworkers to paraphrase and confirm the plausibility of the queries that they generated. We use this method to build a semantic parsing dataset from scratch for a dialog agent in a smart-home simulation. We find evidence that this dataset, which we have named SmartHome, is demonstrably more lexically diverse and difficult to parse than existing domain-specific semantic parsing datasets."
W17-4902,Shakespearizing Modern Language Using Copy-Enriched Sequence to Sequence Models,2017,27,13,4,0,5934,harsh jhamtani,Proceedings of the Workshop on Stylistic Variation,0,"Variations in writing styles are commonly used to adapt the content to a specific context, audience, or purpose. However, applying stylistic variations is still by and large a manual process, and there have been little efforts towards automating it. In this paper we explore automated methods to transform text from modern English to Shakespearean English using an end to end trainable neural model with pointers to enable copy action. To tackle limited amount of parallel data, we pre-train embeddings of words by leveraging external dictionaries mapping Shakespearean words to modern English words as well as additional text. Our methods are able to get a BLEU score of 31+, an improvement of {\mbox{$\approx$}} 6 points above the strongest baseline. We publicly release our code to foster further research in this area."
W17-2307,Tackling Biomedical Text Summarization: {OAQA} at {B}io{ASQ} 5{B},2017,11,5,6,1,6250,khyathi chandu,{B}io{NLP} 2017,0,"In this paper, we describe our participation in phase B of task 5b of the fifth edition of the annual BioASQ challenge, which includes answering factoid, list, yes-no and summary questions from biomedical data. We describe our techniques with an emphasis on ideal answer generation, where the goal is to produce a relevant, precise, non-redundant, query-oriented summary from multiple relevant documents. We make use of extractive summarization techniques to address this task and experiment with different biomedical ontologies and various algorithms including agglomerative clustering, Maximum Marginal Relevance (MMR) and sentence compression. We propose a novel word embedding based tf-idf similarity metric and a soft positional constraint which improve our system performance. We evaluate our techniques on test batch 4 from the fourth edition of the challenge. Our best system achieves a ROUGE-2 score of 0.6534 and ROUGE-SU4 score of 0.6536."
D17-1085,Structural Embedding of Syntactic Trees for Machine Comprehension,2017,0,2,5,0,8180,rui liu,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Deep neural networks for machine comprehension typically utilizes only word or character embeddings without explicitly taking advantage of structured linguistic information such as constituency trees and dependency trees. In this paper, we propose structural embedding of syntactic trees (SEST), an algorithm framework to utilize structured information and encode them into vector representations that can boost the performance of algorithms for the machine comprehension. We evaluate our approach using a state-of-the-art neural attention model on the SQuAD dataset. Experimental results demonstrate that our model can accurately identify the syntactic boundaries of the sentences and extract answers that are syntactically coherent over the baseline methods."
D17-1228,Steering Output Style and Topic in Neural Response Generation,2017,28,9,4,1,7685,di wang,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We propose simple and flexible training and decoding methods for influencing output style and topic in neural encoder-decoder based language generation. This capability is desirable in a variety of applications, including conversational systems, where successful agents need to produce language in a specific style and generate responses steered by a human puppeteer or external knowledge. We decompose the neural generation process into empirically easier sub-problems: a faithfulness model and a decoding method based on selective-sampling. We also describe training and sampling algorithms that bias the generation process with a specific language style restriction, or a topic restriction. Human evaluation results show that our proposed methods are able to to restrict style and topic without degrading output quality in conversational tasks."
D17-1315,{C}harmanteau: Character Embedding Models For Portmanteau Creation,2017,12,3,5,0,5960,varun gangal,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Portmanteaus are a word formation phenomenon where two words combine into a new word. We propose character-level neural sequence-to-sequence (S2S) methods for the task of portmanteau generation that are end-to-end-trainable, language independent, and do not explicitly use additional phonetic information. We propose a noisy-channel-style model, which allows for the incorporation of unsupervised word lists, improving performance over a standard source-to-target model. This model is made possible by an exhaustive candidate generation strategy specifically enabled by the features of the portmanteau task. Experiments find our approach superior to a state-of-the-art FST-based baseline with respect to ground truth accuracy and human evaluation."
W16-6640,{QGASP}: a Framework for Question Generation Based on Different Levels of Linguistic Information,2016,7,2,3,0,32252,hugo rodrigues,Proceedings of the 9th International Natural Language Generation conference,0,None
W16-5202,{LAPPS}/Galaxy: Current State and Next Steps,2016,0,3,3,0,16303,nancy ide,Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies ({WLSI}/{OIAF}4{HLT}2016),0,"The US National Science Foundation (NSF) SI2-funded LAPPS/Galaxy project has developed an open-source platform for enabling complex analyses while hiding complexities associated with underlying infrastructure, that can be accessed through a web interface, deployed on any Unix system, or run from the cloud. It provides sophisticated tool integration and history capabilities, a workflow system for building automated multi-step analyses, state-of-the-art evaluation capabilities, and facilities for sharing and publishing analyses. This paper describes the current facilities available in LAPPS/Galaxy and outlines the project{'}s ongoing activities to enhance the framework."
W16-3104,Learning to Answer Biomedical Questions: {OAQA} at {B}io{ASQ} 4{B},2016,18,18,3,0,19470,zi yang,Proceedings of the Fourth {B}io{ASQ} workshop,0,"This paper describes the OAQA system evaluated in the BioASQ 4B Question Answering track. The system extends the Yang et al. (2015) system and integrates additional biomedical and generalpurpose NLP annotators, machine learning modules for search result scoring, collective answer reranking, and yes/no answer prediction. We first present the overall architecture of the system, and then focus on describing the main extensions to the Yang et al. (2015) approach. Before the official evaluation, we used the development dataset (excluding the 3B Batch 5 subset) for training. We present initial evaluation results on a subset of the development data set to demonstrate the effectiveness of the proposed new methods, and focus on performance analysis of yes/no question answering."
P15-2116,A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering,2015,24,222,2,1,7685,di wang,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In this paper, we present an approach that address the answer sentence selection problem for question answering. The proposed method uses a stacked bidirectional Long-Short Term Memory (BLSTM) network to sequentially read words from question and answer sentences, and then outputs their relevance scores. Unlike prior work, this approach does not require any syntactic parsing or external knowledge resources such as WordNet which may not be available in some domains or languages. The full system is based on a combination of the stacked BLSTM relevance model and keywords matching. The results of our experiments on a public benchmark dataset from TREC show that our system outperforms previous work which requires syntactic features and external knowledge resources."
P14-1024,Metaphor Detection with Cross-Lingual Model Transfer,2014,42,67,4,0,3965,yulia tsvetkov,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We show that it is possible to reliably discriminate whether a syntactic construction is meant literally or metaphorically using lexical semantic features of the words that participate in the construction. Our model is constructed using English resources, and we obtain state-of-the-art performance relative to previous work in this language. Using a model transfer approach by pivoting through a bilingual dictionary, we show our model can identify metaphoric expressions in other languages. We provide results on three new test sets in Spanish, Farsi, and Russian. The results support the hypothesis that metaphors are conceptual, rather than lexical, in nature."
ide-etal-2014-language,The Language Application Grid,2014,19,32,4,0,16303,nancy ide,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Language Application (LAPPS) Grid project is establishing a framework that enables language service discovery, composition, and reuse and promotes sustainability, manageability, usability, and interoperability of natural language Processing (NLP) components. It is based on the service-oriented architecture (SOA), a more recent, web-oriented version of the ÂpipelineÂ architecture that has long been used in NLP for sequencing loosely-coupled linguistic analyses. The LAPPS Grid provides access to basic NLP processing tools and resources and enables pipelining such tools to create custom NLP applications, as well as composite services such as question answering and machine translation together with language resources such as mono- and multi-lingual corpora and lexicons that support NLP. The transformative aspect of the LAPPS Grid is that it orchestrates access to and deployment of language resources and processing functions available from servers around the globe and enables users to add their own language resources, services, and even service grids to satisfy their particular needs."
W11-0313,Assessing Benefit from Feature Feedback in Active Learning for Text Classification,2011,19,1,2,1,44416,shilpa arora,Proceedings of the Fifteenth Conference on Computational Natural Language Learning,0,"Feature feedback is an alternative to instance labeling when seeking supervision from human experts. Combination of instance and feature feedback has been shown to reduce the total annotation cost for supervised learning. However, learning problems may not benefit equally from feature feedback. It is well understood that the benefit from feature feedback reduces as the amount of training data increases. We show that other characteristics such as domain, instance granularity, feature space, instance selection strategy and proportion of relevant text, have a significant effect on benefit from feature feedback. We estimate the maximum benefit feature feedback may provide; our estimate does not depend on how the feedback is solicited and incorporated into the model. We extend the complexity measures proposed in the literature and propose some new ones to categorize learning problems, and find that they are strong indicators of the benefit from feature feedback."
W10-0216,Sentiment Classification using Automatically Extracted Subgraph Features,2010,29,27,4,1,44416,shilpa arora,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,0,"In this work, we propose a novel representation of text based on patterns derived from linguistic annotation graphs. We use a subgraph mining algorithm to automatically derive features as frequent subgraphs from the annotation graph. This process generates a very large number of features, many of which are highly correlated. We propose a genetic programming based approach to feature construction which creates a fixed number of strong classification predictors from these subgraphs. We evaluate the benefit gained from evolved structured features, when used in addition to the bag-of-words features, for a sentiment classification task."
W09-1903,Estimating Annotation Cost for Active Learning in a Multi-Annotator Environment,2009,15,26,2,1,44416,shilpa arora,Proceedings of the {NAACL} {HLT} 2009 Workshop on Active Learning for Natural Language Processing,0,"We present an empirical investigation of the annotation cost estimation task for active learning in a multi-annotator environment. We present our analysis from two perspectives: selecting examples to be presented to the user for annotation; and evaluating selective sampling strategies when actual annotation cost is not available. We present our results on a movie review classification task with rationale annotations. We demonstrate that a combination of instance, annotator and annotation task characteristics are important for developing an accurate estimator, and argue that both correlation coefficient and root mean square error should be used for evaluating annotation cost estimators."
N09-3010,Interactive Annotation Learning with Indirect Feature Voting,2009,14,10,2,1,44416,shilpa arora,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Student Research Workshop and Doctoral Consortium",0,"We demonstrate that a supervised annotation learning approach using structured features derived from tokens and prior annotations performs better than a bag of words approach. We present a general graph representation for automatically deriving these features from labeled data. Automatic feature selection based on class association scores requires a large amount of labeled data and direct voting can be difficult and error-prone for structured features, even for language specialists. We show that highlighted rationales from the user can be used for indirect feature voting and same performance can be achieved with less labeled data. We present our results on two annotation learning tasks for opinion mining from product and movie reviews."
W08-1801,Improving Text Retrieval Precision and Answer Accuracy in Question Answering Systems,2008,17,14,2,0,47721,matthew bilotti,Coling 2008: Proceedings of the 2nd workshop on Information Retrieval for Question Answering,0,"Question Answering (QA) systems are often built modularly, with a text retrieval component feeding forward into an answer extraction component. Conventional wisdom suggests that, the higher the quality of the retrieval results used as input to the answer extraction module, the better the extracted answers, and hence system accuracy, will be. This turns out to be a poor assumption, because text retrieval and answer extraction are tightly coupled. Improvements in retrieval quality can be lost at the answer extraction module, which can not necessarily recognize the additional answer candidates provided by improved retrieval. Going forward, to improve accuracy on the QA task, systems will need greater coordination between text retrieval and answer extraction modules."
D08-1099,Automatic Set Expansion for List Question Answering,2008,6,40,4,0,34021,richard wang,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"This paper explores the use of set expansion (SE) to improve question answering (QA) when the expected answer is a list of entities belonging to a certain class. Given a small set of seeds, SE algorithms mine textual resources to produce an extended list including additional members of the class represented by the seeds. We explore the hypothesis that a noise-resistant SE algorithm can be used to extend candidate answers produced by a QA system and generate a new list of answers that is better than the original list produced by the QA system. We further introduce a hybrid approach which combines the original answers from the QA system with the output from the SE algorithm. Experimental results for several state-of-the-art QA systems show that the hybrid system performs better than the QA systems alone when tested on list question data from past TREC evaluations."
P07-1099,Language-independent Probabilistic Answer Ranking for Question Answering,2007,16,19,3,1,22869,jeongwoo ko,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,This paper presents a language-independent probabilistic answer ranking framework for question answering. The framework estimates the probability of an individual answer candidate given the degree of answer relevance and the amount of supporting evidence provided in the set of answer candidates for the question. Our approach was evaluated by comparing the candidate answer sets generated by Chinese and Japanese answer extractors with the re-ranked answer sets produced by the answer ranking framework. Empirical results from testing on NTCIR factoid questions show a 40% performance improvement in Chinese answer selection and a 45% improvement in Japanese answer selection.
N07-1066,A Probabilistic Framework for Answer Selection in Question Answering,2007,20,30,3,1,22869,jeongwoo ko,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"This paper describes a probabilistic answer selection framework for question answering. In contrast with previous work using individual resources such as ontologies and the Web to validate answer candidates, our work focuses on developing a unified framework that not only uses multiple resources for validating answer candidates, but also considers evidence of similarity among answer candidates in order to boost the ranking of the correct answer. This framework has been used to select answers from candidates generated by four different answer extraction methods. An extensive set of empirical results based on TREC factoid questions demonstrates the effectiveness of the unified framework."
bilotti-nyberg-2006-evaluation,Evaluation for Scenario Question Answering Systems,2006,8,7,2,0,47721,matthew bilotti,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Scenario Question Answering is a relatively new direction in Question Answering (QA) research that presents a number of challenges for evaluation. In this paper, we propose a comprehensive evaluation strategy for Scenario QA, including amethodology for building reusable test collections for Scenario QA and metrics for evaluating system performance over such test collections. Using this methodology, we have built a test collection, which we have made available for public download as a service to the research community. It is our hope that widespread availability of quality evaluation materials fuels research in new approaches to the Scenario QA task."
ko-etal-2006-exploiting,Exploiting Multiple Semantic Resources for Answer Selection,2006,12,5,3,1,22869,jeongwoo ko,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes the utility of semantic resources such as the Web, WordNet and gazetteers in the answer selection process for a question-answering system. In contrast with previous work using individual semantic resources to support answer selection, our work combines multiple resources to boost the confidence scores assigned to correct answers and evaluates different combination strategies based on unweighted sums, weighted linear combinations, and logistic regression. We apply our approach to select answers from candidates produced by three different extraction techniques of varying quality, focusing on TREC questions whose answers represent locations or proper-names. Our experimental results demonstrate that the combination of semantic resources is more effective than individual resources for all three extraction techniques, improving answer selection accuracy by as much as 32.35{\%} for location questions and 72{\%} for proper-name questions. Of the combination strategies tested, logistic regression models produced the best results for both location and proper-name questions."
ko-etal-2006-analyzing,Analyzing the Effects of Spoken Dialog Systems on Driving Behavior,2006,6,0,4,1,22869,jeongwoo ko,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents an evaluation of a spoken dialog system for automotive environments. Our overall goal was to measure the impact of user-system interaction on the userÂs driving performance, and to determine whether adding context-awareness to the dialog system might reduce the degree of user distraction during driving. To address this issue, we incorporated context-awareness into a spoken dialog system, and implemented three system features using user context, network context and dialog context. A series of experiments were conducted under three different configurations: driving without a dialog system, driving while using a context-aware dialog system, and driving while using a context-unaware dialog system. We measured the differences between the three configurations by comparing the average car speed, the frequency of speed changes and the angle between the carÂs direction and the centerline on the road. These results indicate that context-awareness could reduce the degree of user distraction when using a dialog system during driving."
P04-3018,Resource Analysis for Question Answering,2004,14,36,3,0,48643,lucian lita,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"This paper attempts to analyze and bound the utility of various structured and unstructured resources in Question Answering, independent of a specific system or component. We quantify the degree to which gazetteers, web resources, encyclopedia, web documents and web-based query expansion can help Question Answering in general and specific question types in particular. Depending on which resources are used, the QA task may shift from complex answer-finding mechanisms to simpler data extraction methods followed by answer re-mapping in local documents."
N04-4016,Correction Grammars for Error Handling in a Speech Dialog System,2004,6,13,3,0,49162,hirohiko sagawa,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"Speech recognition errors are inevitable in a speech dialog system. This paper presents an error handling method based on correction grammars which recognize the correction utterances which follow a recognition error. Correction grammars are dynamically created from existing grammars and a set of correction templates. We also describe a prototype dialog system which incorporates this error handling method, and provide empirical evidence that this method can improve dialog success rate and reduce the number of dialog turns required for error recovery."
kupsc-etal-2004-pronominal,Pronominal Anaphora Resolution for Unrestricted Text,2004,10,5,4,0.952381,40003,anna kupsc,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The paper presents an anaphora resolution algorithm for unrestricted text. In particular, we examine portability of a knowledge-based approach of (Mitamura et al., 2002), proposed for a domain-specific task. We obtain up to 70% accuracy on unrestricted text, which is a significant improvement (almost 20%) over a baseline we set for general text. As the overall results leave much room for improvement, we provide a detailed error analysis and investigate possible enhancements."
pedro-etal-2004-information,An Information Repository Model for Advanced Question Answering Systems,2004,4,4,3,0,52307,vasco pedro,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents the design and implementation of the information repository which is the central core of the JAVELIN opendomain question answering system. JAVELIN is comprised of several modules that perform a wide variety of question answering (QA) tasks, such as question analysis, document and passage retrieval, answer candidate extraction, answer selection, answer justification, and planning. The architecture is designed to support comparative component-level evaluation, so that different strategies for each module can be integrated and tested in a straightforward way. Each time a module uses a particular piece of information to produce an output, a dependency is created. To support answer justification and introspective learning, the system can use this longterm memory to trace the origin of each answer it produces for a particular question. The JAVELIN Repository implements a complete, consistent relational model for all of the information associated with a question answering scenario."
W03-0908,Towards light semantic processing for question answering,2003,16,33,4,0.533333,668,benjamin durme,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Text Meaning,0,"The paper presents a lightweight knowledge-based reasoning framework for the JAVELIN open-domain Question Answering (QA) system. We propose a constrained representation of text meaning, along with a flexible unification strategy that matches questions with retrieved passages based on semantic similarities and weighted relations between words."
N03-4010,"{JAVELIN}: A Flexible, Planner-Based Architecture for Question Answering",2003,5,4,1,1,9610,eric nyberg,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Demonstrations,0,"The JAVELIN system integrates a flexible, planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text. The demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session."
2003.mtsummit-tttt.4,Teaching machine translation in a graduate language technologies program,2003,-1,-1,2,0,7705,teruko mitamura,Workshop on Teaching Translation Technologies and Tools,0,"This paper describes a graduate-level machine translation (MT) course taught at the Language Technologies Institute at Carnegie Mellon University. Most of the students in the course have a background in computer science. We discuss what we teach (the course syllabus), and how we teach it (lectures, homeworks, and projects). The course has evolved steadily over the past several years to incorporate refinements in the set of course topics, how they are taught, and how students {``}learn by doing{''}. The course syllabus has also evolved in response to changes in the field of MT and the role that MT plays in various social contexts."
2003.mtsummit-systems.13,"An integrated system for source language checking, analysis and term management",2003,-1,-1,1,1,9610,eric nyberg,Proceedings of Machine Translation Summit IX: System Presentations,0,"This paper presents an overview of the tools provided by KANTOO MT system for controlled source language checking, source text analysis, and terminology management. The steps in each process are described, and screen images are provided to illustrate the system architecture and example tool interfaces."
2003.mtsummit-papers.34,Source language diagnostics for {MT},2003,-1,-1,4,0,7705,teruko mitamura,Proceedings of Machine Translation Summit IX: Papers,0,"This paper presents a source language diagnostic system for controlled translation. Diagnostics were designed and implemented to address the most difficult rewrites for authors, based on an empirical analysis of log files containing over 180,000 sentences. The design and implementation of the diagnostic system are presented, along with experimental results from an empirical evaluation of the completed system. We found that the diagnostic system can correctly identify the problem in 90.2{\%} of the cases. In addition, depending on the type of grammar problem, the diagnostic system may offer a rewritten sentence. We found that 89.4{\%} of the rewritten sentences were correctly rewritten. The results suggest that these methods could be used as the basis for an automatic rewriting system in the future."
2003.eamt-1.10,Diagnostics for interactive controlled language checking,2003,-1,-1,3,0,7705,teruko mitamura,EAMT Workshop: Improving MT through other language technology tools: resources and tools for building MT,0,None
W02-0106,Design and Evolution of a Language Technologies Curriculum,2002,0,1,2,0,39652,robert frederking,Proceedings of the {ACL}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,0,The Language Technologies Institute (LTI) of the School of Computer Science at Carnegie Mellon University is one of the largest programs of its kind. We present here the initial design and subsequent evolution of our MS and PhD programs in Language Technologies. The motivations for the design and evolution are also presented.
2002.tmi-papers.13,Pronominal anaphora resolution in the {KANTOO} multilingual machine translation system,2002,-1,-1,2,0,7705,teruko mitamura,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
mitamura-etal-2002-kantoo,The {KANTOO} {MT} sytem: controlled language checker and lexical maintenance tool,2002,3,2,2,0,53711,teriuko mitamura,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: System Descriptions,0,"We will present the KANTOO machine translation environment, a set of software servers and tools for multilingual document production. KANTOO includes modules for source language analysis, target language generation, source terminology management, target terminology management, and knowledge source development (see Figure 1)."
nyberg-etal-2002-deriving,Deriving semantic knowledge from descriptive texts using an {MT} system,2002,6,6,1,1,9610,eric nyberg,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper describes the results of a feasibility study which focused on deriving semantic networks from descriptive texts using controlled language. The KANT system [3,6] was used to analyze input paragraphs, producing sentence-level interlingua representations. The interlinguas were merged to construct a paragraph-level representation, which was used to create a semantic network in Conceptual Graph (CG) [1] format. The interlinguas are also translated (using the KANTOO generator) into OWL statements for entry into the Ontology Works electrical power factbase [9]. The system was extended to allow simple querying in natural language."
H01-1039,"Integrated Information Management: An Interactive, Extensible Architecture for Information Retrieval",2001,21,1,1,1,9610,eric nyberg,Proceedings of the First International Conference on Human Language Technology Research,0,"Most current IR research is focused on specific technologies, such as filtering, classification, entity extraction, question answering, etc. There is relatively little research on merging multiple technologies into sophisticated applications, due in part to the high cost of integrating independently-developed text processing modules."
2001.mtsummit-papers.43,Pronominal anaphora resolution in {KANTOO} {E}nglish-to-{S}panish machine translation system,2001,9,1,2,0,7705,teruko mitamura,Proceedings of Machine Translation Summit VIII,0,"We describe the automatic resolution of pronominal anaphora using KANT Controlled English (KCE) and the KANTOO English-to-Spanish MT system. Our algorithm is based on a robust, syntax-based approach that applies a set of restrictions and preferences to select the correct antecedent. We report a success rate of 89.6{\%} on a training corpus with 289 anaphors, and 87.5{\%} on held-out data containing 145 anaphors. Resolution of anaphors is important in translation, due to gender mismatches among languages; our approach translates anaphors to Spanish with 97.2{\%} accuracy."
2000.amta-tutorials.3,Controlled languages,2000,-1,-1,2,0.461774,7705,teruko mitamura,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Tutorial Descriptions,0,None
nyberg-mitamura-2000-kantoo,The {KANTOO} machine translation environment,2000,3,18,1,1,9610,eric nyberg,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: System Descriptions,0,"In this paper we describe the KANTOO machine translation environment, a set of software services and tools for multilingual document production. KANTOO includes modules for source language analysis, target language generation, source terminology management, target terminology management, and knowledge source development. The KANTOOsystem represents a complete re-design and re-implementation of the KANT machine translation system."
cavalli-sforza-etal-2000-challenges,Challenges in adapting an interlingua for bidirectional {E}nglish-{I}talian translation,2000,4,3,4,0,28253,violetta cavallisforza,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"We describe our experience in adapting an existing high- quality, interlingual, unidirectional machine translation system to a new domain and bidirectional translation for a new language pair (English and Italian). We focus on the interlingua design changes which were necessary to achieve high quality output in view of the language mismatches between English and Italian. The representation we propose contains features that are interpreted differently, depending on the translation direction. This decision simplified the process of creating the interlingua for individual sentences, and allows the system to defer mapping of language-specific features (such as tense and aspect), which are realized when the target syntactic feature structure is created. We also describe a set of problems we encountered in translating modal verbs, and discuss the representation of modality in our interlingua."
1999.tmi-1.22,Multiple strategies for automatic disambiguation in technical translation,1999,-1,-1,2,0.499344,7705,teruko mitamura,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1997.mtsummit-papers.2,A Real-Time {MT} System for Translating Broadcast Captions,1997,-1,-1,1,1,9610,eric nyberg,Proceedings of Machine Translation Summit VI: Papers,0,"This presentation demonstrates a new multi-engine machine translation system, which combines knowledge-based and example-based machine translation strategies for real-time translation of business news captions from English to German."
C94-1012,Coping With Ambiguity in a Large-Scale Machine Translation System,1994,8,22,5,1,43387,kathryn baker,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In an interlingual knowledge-based machine translation system, ambignuity arises when the source language analyzer produces more than one interlingua expression for a source sentence. This can have a negative impact on translation quality, since a target sentence may be produced from an unintended meaning. In this paper we describe the methods used in the KANT machine translation system to reduce or eliminate ambiguity in a large-scale application domain. We also test these methods on a large corpus of test sentences, in order to illustrate how the different disambiguation methods reduce the average number of parses per sentence."
1994.amta-1.36,"{KANT}: Knowledge-Based, Accurate Natural Language Translation",1994,-1,-1,2,0.740741,7705,teruko mitamura,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
1991.mtsummit-papers.9,An Efficient Interlingua Translation System for Multi-lingual Document Production,1991,2,94,2,0.740741,7705,teruko mitamura,Proceedings of Machine Translation Summit III: Papers,0,"Knowledge-based interlingual machine translation systems produce semantically accurate translations, but typically require massive knowledge acquisition. This paper describes KANT, a system that reduces this requirement to produce practical, scalable, and accurate KBMT applications. First, the set of requirements is discussed, then the full KANT architecture is illustrated, and finally results from a fully implemented prototype are presented."
1988.tmi-1.4,Lexical realization in natural language generation,1988,-1,-1,3,0,32552,sergei nirenburg,Proceedings of the Second Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
