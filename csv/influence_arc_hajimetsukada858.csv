2005.iwslt-1.15,J04-4002,0,0.0250193,") roughly means the word stem (inflectional endings). For example, “Would it be possible to ship it to Japan” becomes “Woul+ it be poss+ to ship it to Japa+” by prefix-4, and “+ould it be +ible to ship it to +apan” by suffix-4, where “+” at the end or beginning of a word denotes deletion. Prefix-4 and suffix-4 are likely to contribute to word alignment and language modeling, respectively. 3.2. Phrase-based Features Our system adopts a phrase-based translation model represented by phrase-based features, which are based on phrase translation pairs extracted by the method proposed by Och and Ney [4]. First, many-to-many word alignment is set by using both one-to-many and many-to-one word alignments generated by GIZA++ toolkit. In the experiment, we used prefix-4 for word-to-word alignment. Using prefix-4 produced better translations than the original form in preliminary experiments. Next, phrase pairs consistent with word alignment are extracted. The words in a legal phrase pair are only aligned to each other and not to words outside. Hereafter, we use count(˜ e) and count(f˜, e˜) to denote the number of extracted phrase e˜ and extracted phrase pair ( f˜, e˜), respectively. We used the f"
2005.iwslt-1.15,N03-1017,0,0.0336733,"xtracted source/target phrases # of source/target phrases appearing in the corpus • Phrase pair extraction probability, i.e., # of sentences phrase pairs extracted # of sentences phrase pairs appearing in the corpus • Adjusted Dice coefficient, which is an extension of the measure proposed in [5], i.e., Dice(f˜, e˜)log(count(f˜, e˜) + 1) 3.3. Word-level Features We used the following word-level features, where w(f |e) =  count(f, e) ,  f  count(f , e) I is the number of words in the translation and J is the number of words in the input sentence. • Lexical weight pw (f˜|˜ e) and pw (˜ e|f˜) [6], where pw (f˜|˜ e) = maxa ·  J  1 |{i|(i, j) ∈ a)}| j=1 ∀(i,j)∈a w(fj |ei ) (I˜ + 1)J˜ j w(f˜j |˜ ei ) i • Viterbi IBM Model 1 score p M1 (f˜|˜ e) and pM1 (˜ e|f˜), where pM1 (f˜|˜ e) = J˜  1 (I˜ + 1)J˜ max w(f˜j |˜ ei ) j i • Noisy OR gate pN OR (f˜|˜ e) and pN OR (˜ e|f˜) [7], where e) = pN OR (f˜|˜   (1 − (1 − w(f˜j |˜ ei ))) j i e, f˜) where • Deletion penalty p del (˜ pdel (˜ e, f˜) =  ˜ del(˜ eI1 , f˜j ) j 2 • Phrase extraction probability of source/target, i.e., J˜  I˜  1 ˜ del(˜ eI1 , f˜j ) =   1  0 i does not exist s.t. w(˜ ei |f˜j ) &gt; threshold otherwise. 3.4. Lexical"
2005.iwslt-1.15,N04-1033,0,0.0174663,"posed in [5], i.e., Dice(f˜, e˜)log(count(f˜, e˜) + 1) 3.3. Word-level Features We used the following word-level features, where w(f |e) =  count(f, e) ,  f  count(f , e) I is the number of words in the translation and J is the number of words in the input sentence. • Lexical weight pw (f˜|˜ e) and pw (˜ e|f˜) [6], where pw (f˜|˜ e) = maxa ·  J  1 |{i|(i, j) ∈ a)}| j=1 ∀(i,j)∈a w(fj |ei ) (I˜ + 1)J˜ j w(f˜j |˜ ei ) i • Viterbi IBM Model 1 score p M1 (f˜|˜ e) and pM1 (˜ e|f˜), where pM1 (f˜|˜ e) = J˜  1 (I˜ + 1)J˜ max w(f˜j |˜ ei ) j i • Noisy OR gate pN OR (f˜|˜ e) and pN OR (˜ e|f˜) [7], where e) = pN OR (f˜|˜   (1 − (1 − w(f˜j |˜ ei ))) j i e, f˜) where • Deletion penalty p del (˜ pdel (˜ e, f˜) =  ˜ del(˜ eI1 , f˜j ) j 2 • Phrase extraction probability of source/target, i.e., J˜  I˜  1 ˜ del(˜ eI1 , f˜j ) =   1  0 i does not exist s.t. w(˜ ei |f˜j ) &gt; threshold otherwise. 3.4. Lexical Reordering Features We used the following features to control the reordering of phrases: • Distortion model d(a i − bi−1 ) = exp−|ai −bi−1 −1 |, where ai denotes the starting position of the foreign phrase translated into the i-th English phrase, and b i−1 denotes the end position of"
2005.iwslt-1.15,N04-1021,0,0.050617,"Missing"
2005.iwslt-1.15,W02-1021,0,0.0178786,"on of the foreign phrase translated into the i-th English phrase, and b i−1 denotes the end position of the foreign phrase translated into the (i − 1)-th English phrase [6]. • Right monotone model P R (˜ e, f˜) (and left monotone ˜ model PL (˜ e, f )) inspired by Och’s scheme [8], where PR (f˜, e˜) = countR , count(f˜, e˜) and countR denotes the number of right connected monotone phrases. 3.5. Other Features The following additional features are used. • number of words that constitute a translation • number of phrases that constitute a translation 4. Decoder The decoder is based on word graph [9] and uses a multi-pass strategy to generate n-best translations. It generates hypothesized translations in a left-to-right order by combining phrase translations for a source sentence. The first pass of our decoding algorithm generates a word graph, a compact representation of hypothesized translations, using a breadth-first beam search, as in [10][11][12][13]. Then, n-best translations are extracted from the generated word graph using A ∗ search. The search space for a beam search is constrained by restricting the reordering of source phrases. We have window size constraints that restrict the"
2005.iwslt-1.15,P97-1047,0,0.0296466,"umber of right connected monotone phrases. 3.5. Other Features The following additional features are used. • number of words that constitute a translation • number of phrases that constitute a translation 4. Decoder The decoder is based on word graph [9] and uses a multi-pass strategy to generate n-best translations. It generates hypothesized translations in a left-to-right order by combining phrase translations for a source sentence. The first pass of our decoding algorithm generates a word graph, a compact representation of hypothesized translations, using a breadth-first beam search, as in [10][11][12][13]. Then, n-best translations are extracted from the generated word graph using A ∗ search. The search space for a beam search is constrained by restricting the reordering of source phrases. We have window size constraints that restrict the number of words skipped before selecting a segment of the source sequence [6][12]. An ITG-constraint [14] is also implemented that prohibits the extension of a hypothesis that violates ITG constraints, which will be useful for language pairs with drastic reordering, such as Japanese-to-English and Korean-to-English translations. During the beam se"
2005.iwslt-1.15,J03-1005,0,0.0276819,"r of right connected monotone phrases. 3.5. Other Features The following additional features are used. • number of words that constitute a translation • number of phrases that constitute a translation 4. Decoder The decoder is based on word graph [9] and uses a multi-pass strategy to generate n-best translations. It generates hypothesized translations in a left-to-right order by combining phrase translations for a source sentence. The first pass of our decoding algorithm generates a word graph, a compact representation of hypothesized translations, using a breadth-first beam search, as in [10][11][12][13]. Then, n-best translations are extracted from the generated word graph using A ∗ search. The search space for a beam search is constrained by restricting the reordering of source phrases. We have window size constraints that restrict the number of words skipped before selecting a segment of the source sequence [6][12]. An ITG-constraint [14] is also implemented that prohibits the extension of a hypothesis that violates ITG constraints, which will be useful for language pairs with drastic reordering, such as Japanese-to-English and Korean-to-English translations. During the beam search"
2005.iwslt-1.15,2003.mtsummit-papers.53,0,0.0219439,"right connected monotone phrases. 3.5. Other Features The following additional features are used. • number of words that constitute a translation • number of phrases that constitute a translation 4. Decoder The decoder is based on word graph [9] and uses a multi-pass strategy to generate n-best translations. It generates hypothesized translations in a left-to-right order by combining phrase translations for a source sentence. The first pass of our decoding algorithm generates a word graph, a compact representation of hypothesized translations, using a breadth-first beam search, as in [10][11][12][13]. Then, n-best translations are extracted from the generated word graph using A ∗ search. The search space for a beam search is constrained by restricting the reordering of source phrases. We have window size constraints that restrict the number of words skipped before selecting a segment of the source sequence [6][12]. An ITG-constraint [14] is also implemented that prohibits the extension of a hypothesis that violates ITG constraints, which will be useful for language pairs with drastic reordering, such as Japanese-to-English and Korean-to-English translations. During the beam search sta"
2005.iwslt-1.15,C04-1006,0,0.0208502,"s in a left-to-right order by combining phrase translations for a source sentence. The first pass of our decoding algorithm generates a word graph, a compact representation of hypothesized translations, using a breadth-first beam search, as in [10][11][12][13]. Then, n-best translations are extracted from the generated word graph using A ∗ search. The search space for a beam search is constrained by restricting the reordering of source phrases. We have window size constraints that restrict the number of words skipped before selecting a segment of the source sequence [6][12]. An ITG-constraint [14] is also implemented that prohibits the extension of a hypothesis that violates ITG constraints, which will be useful for language pairs with drastic reordering, such as Japanese-to-English and Korean-to-English translations. During the beam search stage, three kinds of pruning are performed to further reduce the search space [11]. First, observation pruning limits the number of phrase translation candidates to a maximum of N candidates. Second, threshold pruning is performed by computing the most likely partial hypothesis and by discarding hypotheses whose probability is lower than the maximu"
2005.iwslt-1.15,W05-0834,0,0.0109953,"e fly and then integrated with the preceding score for beam pruning. We estimated future cost as described in [13]. Exact costs for the phrase-based features and word level features can be calculated for each extracted phrase pair. For the language model features, their costs were approximated by using only output words contained by each phrase pair. The upper bound of lexical reordering feature costs can be computed beforehand by considering the possible permutations of phrase pairs for a given input. After generating a word graph, it is then pruned using the posterior probabilities of edges [15] to further reduce the number of duplicate translations for A ∗ search. An edge is pruned if its posterior score is lower than the highest posterior score in the graph by a certain amount. 5. Experiments To validate the use of the reportedly effective features, we conducted translation experiments using all features introduced in Section 3. Also, we conducted comparable experiments in both supplied and unrestricted data tracks to study the effectiveness of additional language resources. English data sets IWSLT (supplied) ATR WEB Gigaword Corpus size (words) 190,177 1,100,194 8,482,782 1,799,53"
2005.iwslt-1.15,2004.iwslt-evaluation.13,0,0.0125922,".5 28.6 Chinese IWSLT LDC 56.6 462 56.1 449 50.7 432 Table 4: Input language perplexity of trigram trained by supplied corpora and IWSLT datasets are similar, WEB is closer to IWSLT than Gigaword, and that LDC is very different from IWSLT. Since the collection is enormous in Gigaword, the vocabulary set is first limited to that observed in the English part of supplied corpus and the ATR database. Then for decoding, an actual n-gram language model is estimated on the fly by constraining the vocabulary set to that observed in a given test set. 5.3. Other Setups Following one of the best systems [17] in IWSLT 2004, feature function scaling factors λ j are trained using NIST scores [18] in a loss function of minimum error rate training, and development set 1 (CSTAR) was used for it. For Japanese and Korean, ITG constraints of lexical reordering were applied, and for Arabic and Chinese, simple window size constraints up to 7 were used. 5.4. Results Table 5 summarizes the overall results of the supplied/unrestricted data tracks. The scores of the table are obtained by the comparable conditions for each language pair while some are not the same as those released by the organizer. “m unrestric"
2005.iwslt-1.15,W03-1506,0,\N,Missing
2005.iwslt-1.15,P02-1040,0,\N,Missing
2005.iwslt-1.15,P02-1038,0,\N,Missing
2005.iwslt-1.15,J03-1002,0,\N,Missing
2005.iwslt-1.15,2006.iwslt-evaluation.14,1,\N,Missing
2005.iwslt-1.15,P03-1021,0,\N,Missing
2006.iwslt-evaluation.14,J03-1002,0,0.00515357,"on-terminals are always instantiated with phrase translation pairs. Thus, we will be able to reduce the number of rules induced from a bilingual corpus, which, in turn, help reducing the decoding complexity. Note that we do not imply arbitrary synchronous-CFGs are transformed into the target normalized form. The form simply restricts the grammar extracted from a bilingual corpus explained in Section 2.4. 2.4. Training The phrase extraction algorithm is based on those presented by [3]. First, many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ [6], in both directions and by combining the results based on a heuristic [7]. Second, phrase translation pairs are extracted from the word aligned corpus [3]. This method ) from a senexhaustively extracts phrase pairs (fjj+m , ei+n i J I tence pair (f1 , e1 ) that do not violate the word alignment constraints a. In the hierarchical phrase-based model, production rules are accumulated by computing “holes” for extracted contiguous phrases [4]: 2.6. Feature Functions Feature functions evaluated during the decoding procedure is summarized as count-based models, lexicon-based models, language model,"
2006.iwslt-evaluation.14,J04-4002,0,0.069757,"we will be able to reduce the number of rules induced from a bilingual corpus, which, in turn, help reducing the decoding complexity. Note that we do not imply arbitrary synchronous-CFGs are transformed into the target normalized form. The form simply restricts the grammar extracted from a bilingual corpus explained in Section 2.4. 2.4. Training The phrase extraction algorithm is based on those presented by [3]. First, many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ [6], in both directions and by combining the results based on a heuristic [7]. Second, phrase translation pairs are extracted from the word aligned corpus [3]. This method ) from a senexhaustively extracts phrase pairs (fjj+m , ei+n i J I tence pair (f1 , e1 ) that do not violate the word alignment constraints a. In the hierarchical phrase-based model, production rules are accumulated by computing “holes” for extracted contiguous phrases [4]: 2.6. Feature Functions Feature functions evaluated during the decoding procedure is summarized as count-based models, lexicon-based models, language model, reordering models and length-based models. 1. A phrase pair (f¯, e¯) const"
2006.iwslt-evaluation.14,W05-1507,0,0.0304273,"boxed indices indicate non-terminal alignment. One of the major differences to the algorithm presented in [4] is the restriction of the target normalized form in the last step. 2.5. Decoding by Top-down Parsing Decoding is performed by parsing on the source-side and by combining the projected target-side. A conventional method of parsing is a CKY-based method in which ordering is governed by the span-size of the source words [4]. One of the problem is the high computational complexity when integrated with ngram language model of the target-side especially when the ngram’s order is quite high [8]. The complexity lies on the possible “holes” in the target-side. One of the solution is to perform a binarization so that the target-side will not contain holes [9]. We applied an Earley-style top-down parsing approach described in [5] that is similar to [10]. The basic idea is to perform a top-down parsing in order so that the projected target-side is generated in a left-to-right manner. The search is guided with a push-down automaton which keeps track of the span-size of uncovered source word positions. Combined with the rest-cost estimation aggregated in a bottom-up way, our decoder effici"
2006.iwslt-evaluation.14,N06-1033,0,0.0183208,"e last step. 2.5. Decoding by Top-down Parsing Decoding is performed by parsing on the source-side and by combining the projected target-side. A conventional method of parsing is a CKY-based method in which ordering is governed by the span-size of the source words [4]. One of the problem is the high computational complexity when integrated with ngram language model of the target-side especially when the ngram’s order is quite high [8]. The complexity lies on the possible “holes” in the target-side. One of the solution is to perform a binarization so that the target-side will not contain holes [9]. We applied an Earley-style top-down parsing approach described in [5] that is similar to [10]. The basic idea is to perform a top-down parsing in order so that the projected target-side is generated in a left-to-right manner. The search is guided with a push-down automaton which keeps track of the span-size of uncovered source word positions. Combined with the rest-cost estimation aggregated in a bottom-up way, our decoder efficiently searches for the most-likely translation. Our decoding algorithm can be regarded as an instance of Earley algorithm, but the predicted rule’s “dot” is moved sy"
2006.iwslt-evaluation.14,P02-1038,0,0.663191,"onal phrase-based model. In addition, our reranking algorithm further boosted the performance. = argmax P r(eI1 |f1J ) (1) eI1 = argmax P eI1 e′ I1 ′ P M  I J λ h (e , f ) m m 1 1 m=1 (2) P M J ′I′ exp m=1 λm hm (e 1 , f1 ) exp In this framework, the posterior probability P r(eI1 |f1J ) is directly maximized using a log-linear combination of feature functions hm (eI1 , f1J ), such as a ngram language model or a translation model. When decoding, the denominator is dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likelihood approach [1] or on a direct error minimization approach [2]. This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. 1. Introduction This paper describes the NTT statistical machine translation system which is experimented in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2006. 2.2. Hierarchical Phrase-based Approach In the phrase-based translation approach [3], the input foreign sentence is segmented into phrases, f¯1K , mapped into corresponding English-side e¯K 1 , then, reordered to f"
2006.iwslt-evaluation.14,P03-1021,0,0.0700907,"king algorithm further boosted the performance. = argmax P r(eI1 |f1J ) (1) eI1 = argmax P eI1 e′ I1 ′ P M  I J λ h (e , f ) m m 1 1 m=1 (2) P M J ′I′ exp m=1 λm hm (e 1 , f1 ) exp In this framework, the posterior probability P r(eI1 |f1J ) is directly maximized using a log-linear combination of feature functions hm (eI1 , f1J ), such as a ngram language model or a translation model. When decoding, the denominator is dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likelihood approach [1] or on a direct error minimization approach [2]. This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. 1. Introduction This paper describes the NTT statistical machine translation system which is experimented in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2006. 2.2. Hierarchical Phrase-based Approach In the phrase-based translation approach [3], the input foreign sentence is segmented into phrases, f¯1K , mapped into corresponding English-side e¯K 1 , then, reordered to form the output English sentence. The approach i"
2006.iwslt-evaluation.14,N03-1017,0,0.214202,"s dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likelihood approach [1] or on a direct error minimization approach [2]. This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. 1. Introduction This paper describes the NTT statistical machine translation system which is experimented in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2006. 2.2. Hierarchical Phrase-based Approach In the phrase-based translation approach [3], the input foreign sentence is segmented into phrases, f¯1K , mapped into corresponding English-side e¯K 1 , then, reordered to form the output English sentence. The approach is able to capture phrase-wise local-reordering, or possibly neighboring phrase reordering, but does not account for long-distance reordering of phrases. In the hierarchical phrase-based translation approach [4], translation is constituted by hierarchically combining phrases with the help of non-terminals embedded in phrases themselves. Each non-terminal represented in each phrase can capture reordering of phrases. Based"
2006.iwslt-evaluation.14,P05-1033,0,0.752177,"system which is experimented in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2006. 2.2. Hierarchical Phrase-based Approach In the phrase-based translation approach [3], the input foreign sentence is segmented into phrases, f¯1K , mapped into corresponding English-side e¯K 1 , then, reordered to form the output English sentence. The approach is able to capture phrase-wise local-reordering, or possibly neighboring phrase reordering, but does not account for long-distance reordering of phrases. In the hierarchical phrase-based translation approach [4], translation is constituted by hierarchically combining phrases with the help of non-terminals embedded in phrases themselves. Each non-terminal represented in each phrase can capture reordering of phrases. Based on the hierarchical phrase-based modeling, we adopted the left-to-right target generation method described in [5]. The method is able to generate translations efficiently, first, by simplifying the grammar so that the target-side takes a phrase-prefixed form, namely target normalized form. Our simplified grammar drastically reduces the number of rules extracted from a bilingual corpu"
2006.iwslt-evaluation.14,P06-1098,1,0.921865,"hen, reordered to form the output English sentence. The approach is able to capture phrase-wise local-reordering, or possibly neighboring phrase reordering, but does not account for long-distance reordering of phrases. In the hierarchical phrase-based translation approach [4], translation is constituted by hierarchically combining phrases with the help of non-terminals embedded in phrases themselves. Each non-terminal represented in each phrase can capture reordering of phrases. Based on the hierarchical phrase-based modeling, we adopted the left-to-right target generation method described in [5]. The method is able to generate translations efficiently, first, by simplifying the grammar so that the target-side takes a phrase-prefixed form, namely target normalized form. Our simplified grammar drastically reduces the number of rules extracted from a bilingual corpus empirically presented in [5]. Second, translation is generated in a left-to-right manner, similar to a phrase-based approach, using an Earley-style top-down parsing on the source-side. Coupled with the tarOur system consists of two parts. A hierarchical phrasebased translation system that generates a large n-best list. The"
2006.iwslt-evaluation.14,W06-3119,0,0.0424367,"side and by combining the projected target-side. A conventional method of parsing is a CKY-based method in which ordering is governed by the span-size of the source words [4]. One of the problem is the high computational complexity when integrated with ngram language model of the target-side especially when the ngram’s order is quite high [8]. The complexity lies on the possible “holes” in the target-side. One of the solution is to perform a binarization so that the target-side will not contain holes [9]. We applied an Earley-style top-down parsing approach described in [5] that is similar to [10]. The basic idea is to perform a top-down parsing in order so that the projected target-side is generated in a left-to-right manner. The search is guided with a push-down automaton which keeps track of the span-size of uncovered source word positions. Combined with the rest-cost estimation aggregated in a bottom-up way, our decoder efficiently searches for the most-likely translation. Our decoding algorithm can be regarded as an instance of Earley algorithm, but the predicted rule’s “dot” is moved synchronized with the left-to-right ordering of the projected target-side, not the left-to-right"
2006.iwslt-evaluation.14,P96-1041,0,0.0444429,"e hierarchical phrase-based model, production rules are accumulated by computing “holes” for extracted contiguous phrases [4]: 2.6. Feature Functions Feature functions evaluated during the decoding procedure is summarized as count-based models, lexicon-based models, language model, reordering models and length-based models. 1. A phrase pair (f¯, e¯) constitutes a rule: X → f¯, e¯ 96 2.6.3. Language Model 2.6.1. Count-based Models hφ (f1J |eI1 , D) and hφ (eI1 |f1J , D) estisentences f1J and eI1 over a derivaWe used mixed-cased 5-gram language model estimated with modified Kneser-Ney smoothing [11]: Y pn (ei |ei−4 ei−3 ei−2 ei−1 ) (11) hlm (eI1 ) = log Main feature functions mate the likelihood of two tion tree D. We assume that the production rules in D are independent of each other: Y φ(γ|α) (4) hφ (f1J |eI1 , D) = log i 2.6.4. Reordering Models hγ,αi∈D In order to limit the reorderings, two feature functions are employed: X height(Di ) (12) hheight (eI1 , f1J , D) = φ(γ|α) is estimated through the relative frequency on a given bilingual corpus. count(γ, α) φ(γ|α) = P γ count(γ, α) (5) Di ∈back(D) hwidth (eI1 , f1J , D) = where count(·) represents the cooccurrence frequency of rules γ"
2006.iwslt-evaluation.14,P02-1034,0,0.0145487,"titute a translation: j=1 max t(fj |ei ) &lt; τdel 0≤i≤I  (9) The deletion model simply counts the number of words whose lexicon model probability is lower than a threshold τdel . Likewise, an insertion model is integrated that penalizes the inserted English words that do not account for any foreign words in an input: hins (eI1 , f1J ) = I  X i=1 max t(ei |fj ) &lt; τins 0≤j≤J  (14) hr (D) = rule(D) (15) This section explains our discriminative reranking method which further improves the quality of baseline MT system. Our reranking method basically follows the parse reranking method explained in [12]. We first generate a n-best list of candidate outputs (translations) from a baseline MT system, the hierarchical phrase-based translation described in Section 2. Then, a reranking model is trained by a ranking voted perceptron on a development set. Finally, in the process of decoding, we re-rank the n-best list of test data fed from the baseline MT using the trained reranking model. We adopted the above method, [12], with a BLEU-score-based weight update scheme. The reranking setting of MT is an ordinal regression procedure in each output pairs, similar to the parse reranking task, which can"
2006.iwslt-evaluation.14,takezawa-etal-2002-toward,0,0.0312538,"running GIZA++ in both directions, and by refining word alignment with a heuristic. Third, from three distinctly preprocessed corpora, rules are extracted using the algorithm presented in 2.4. In this step, preprocessed corpora are recovered into their original form. When recovered, punctuation marks on the source-side were removed together with corresponding word alignments. The idea is to induce better word alignments by considering non-punctuation corpus, together with punctuation preserved corpus. 4. Tasks The experiments were carried out on the Basic Travel Expression Corpus (BTEC) task [13]. BTEC is a multilingual corpus in traveling domain which was collected from phrase books for tourists. In the IWSLT 2006 open data track, the subsets of BTEC consists of training set and three development sets (Dev1 through Dev3) indicated in Table 1. Another development set (Dev4) and the final test set were provided in this track1 . The translation pairs set up for the task are: Arabic-to-English, Italian-to-English, Japanese-toEnglish and Chinese-to-English. The task description for the IWSLT 2006 evaluation campaign can be summarized as follows: 1. Spoken language, instead of written text"
2006.iwslt-evaluation.14,W06-3115,1,0.730654,"ey algorithm, but the predicted rule’s “dot” is moved synchronized with the left-to-right ordering of the projected target-side, not the left-to-right ordering on the source-side. The use of target normalized form further simplify the decodig procedure. Since the rule form does not allow any holes for the target-side, the integration with ngram language model is straightforward: the prefixed phrases are simply concatenated and intersected. Our decoder is based on an in-house developed phrasebased decoder which uses a bit vector to represent uncovered foreign word positions for each hypothesis [14]. We basically replaced the bit vector structure to the stack structure: Almost no modification was required for the word graph structure and the beam search strategy implemented for a phrase-based modeling, since the target-side’s prefixed phrases are simply concatenated. The use of a stack structure directly models a synchronous-CFG formalism realized as a push-down automation, while the bit vector implementation is conceptualized as a finite state transducer. (3) where X is a non-terminal, γ is a source-side string of arbitrary terminals and/or non-terminals. ¯bβ is a corresponding target-s"
2006.iwslt-evaluation.14,2005.iwslt-1.8,0,0.0199399,"erings. 5.2. Results on Hierarchical Phrase-based Translation We first compared our baseline hierarchical phrase-based translation against an in-house developed phrase-based translation that performed quite well for the shared task of “Workshop on Statistical Machine Translation” [14]. Table 3 shows the number of phrases and rules extracted from each task. The grammar size for our hierarchical phrase-based system is almost twice as large as the size of the phrase table for our phrase-based system. The phrase-based system employs a lexicalized reordering model to capture phrase-wise reordering [15]. For the hierarchical phrase-based system, spansize for each non-terminal was constrained to 7 for all tasks. Window-size constraints were set to 7 in the phrase-based system. As indicated in Table 4, our hierarchical phrasebased system outperforms the phrase-based system in all tasks. mPER 56.65 54.15 48.13 41.57 55.12 52.17 59.72 57.71 53.70 5.3. Results on Reranking Table 5 shows the reranking results for IWSLT2006. The rows of ‘1-best’ in Table 5 show the performance of our baseline MT system, hierarchical phrase-based system (contrast1 system). Then, the rows of ‘SC’ display the performa"
2007.iwslt-1.16,N07-1008,0,0.0150061,"parameters are trained using an efficient online training algorithm: The decoder employs an online large-margin training method [4] that has been successfully applied in dependency parsing [5] or joint labeling/chunking [6]. The reranker uses a reranking voted perceptron which gave significant improvement in the last year’s IWSLT 2006 evaluation [2]. Both systems are tuned using approximated BLEU as an objective function that scales the sentence-wise BLEU to a document-wise BLEU. Domain mismatch is handled by a simple task adaptation scheme by selecting training data that resembles a test set [7]. In order to handle the ASR’s error prone input, we decoded all the nbest translations and let the reranker choose the right translation by treating the individually translated list as a single k-best list combined with the ASR’s n-best list’s confidence measures. This paper is organized as follows: The overview of our decoder is presented in Section 2. We will describe the feature functions experimented in [3] together with additional features. The reranking system is described in Section 3. The reranker is biased to use a slightly different feature set to avoid over training. Both systems s"
2007.iwslt-1.16,P03-1021,0,0.0149653,"e feature functions experimented in [3] together with additional features. The reranking system is described in Section 3. The reranker is biased to use a slightly different feature set to avoid over training. Both systems share the same online training algorithm, but differ in that the decoder’s parameters are updated based on the dynamically generated candidate list, whereby the reranking training is based on a fixed translation candidate list. Section 4 presents the results for the evaluation campaign of IWSLT 2007. 2. Machine Translation System We use a linear feature combination approach [8] in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: eˆ = argmax w⊤ · h(f, e) (1) e where h(f, e) is a large-dimension feature vector. w is a weight vector that scales the contribution from each feature. Each feature can take any real value, such as the log of the ngram language model to represent fluency, or a lexicon model to capture the word or phrase-wise correspondence. Under this maximization scenario, our system composed of two steps: The first step is a decoder that can efficiently generate k-best list of ca"
2007.iwslt-1.16,P05-1033,0,0.107755,"by seeking a maximum solution: eˆ = argmax w⊤ · h(f, e) (1) e where h(f, e) is a large-dimension feature vector. w is a weight vector that scales the contribution from each feature. Each feature can take any real value, such as the log of the ngram language model to represent fluency, or a lexicon model to capture the word or phrase-wise correspondence. Under this maximization scenario, our system composed of two steps: The first step is a decoder that can efficiently generate k-best list of candidate translations in a left-to-right manner [1] based on the hierarchical phrase-based translation[9]. The second step rerank the k-best list using a reranking voted perceptron[2]. 2.1. Hierarchical Phrase-based Translation We use the hierarchical phrase-based translation approach, in which non-terminals are embedded in each phrase [9]. A translation is generated by hierarchically combining phrases using the non-terminals. Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by a conventional phrase-based approach [10]. The non-terminal embedded phrases are learned from a bilingual corpus without a linguistically motivated syntactic str"
2007.iwslt-1.16,N03-1017,0,0.00424325,"te k-best list of candidate translations in a left-to-right manner [1] based on the hierarchical phrase-based translation[9]. The second step rerank the k-best list using a reranking voted perceptron[2]. 2.1. Hierarchical Phrase-based Translation We use the hierarchical phrase-based translation approach, in which non-terminals are embedded in each phrase [9]. A translation is generated by hierarchically combining phrases using the non-terminals. Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by a conventional phrase-based approach [10]. The non-terminal embedded phrases are learned from a bilingual corpus without a linguistically motivated syntactic structure. Based on hierarchical phrase-based modeling, we adopted the left-to-right target generation method [1] which performed better than a phrase-based system in the last year’s evaluation[2]. This method is able to generate translations efficiently, first, by simplifying the grammar so that the target side takes a phrase-prefixed form, namely a target normalized form: X → γ, ¯bβ, ∼ (2) where X is a non-terminal, γ is a source side string of arbitrary terminals and/or non-t"
2007.iwslt-1.16,P98-2230,0,0.0172839,"s efficiently, first, by simplifying the grammar so that the target side takes a phrase-prefixed form, namely a target normalized form: X → γ, ¯bβ, ∼ (2) where X is a non-terminal, γ is a source side string of arbitrary terminals and/or non-terminals. ¯bβ is a corresponding target side where ¯b is a string of terminals, or a phrase, and β is a (possibly empty) string of non-terminals. ∼ defines one-to-one mapping between non-terminals in γ and β. Second, a translation is generated in a left-to-right manner, similar to phrase-based decoding using Earley-style topdown parsing on the source side [11, 1, 12]. The basic idea is to perform top-down parsing so that the projected target side is generated in a left-to-right manner. The search is guided with a push-down automaton, which keeps track of the span of uncovered source word positions. Combined with the restcost estimation aggregated in a bottom-up way, our decoder efficiently searches for the most likely translation. The use of a target normalized form further simplifies the decoding procedure, at the expense for expressiveness. Since the rule form does not allow any holes in the target side, the integration with an n-gram language model is"
2007.iwslt-1.16,W06-3119,0,0.0336527,"s efficiently, first, by simplifying the grammar so that the target side takes a phrase-prefixed form, namely a target normalized form: X → γ, ¯bβ, ∼ (2) where X is a non-terminal, γ is a source side string of arbitrary terminals and/or non-terminals. ¯bβ is a corresponding target side where ¯b is a string of terminals, or a phrase, and β is a (possibly empty) string of non-terminals. ∼ defines one-to-one mapping between non-terminals in γ and β. Second, a translation is generated in a left-to-right manner, similar to phrase-based decoding using Earley-style topdown parsing on the source side [11, 1, 12]. The basic idea is to perform top-down parsing so that the projected target side is generated in a left-to-right manner. The search is guided with a push-down automaton, which keeps track of the span of uncovered source word positions. Combined with the restcost estimation aggregated in a bottom-up way, our decoder efficiently searches for the most likely translation. The use of a target normalized form further simplifies the decoding procedure, at the expense for expressiveness. Since the rule form does not allow any holes in the target side, the integration with an n-gram language model is"
2007.iwslt-1.16,2004.iwslt-evaluation.13,0,0.0146149,"nd intersected with an n-gram. 2.2. Features 2.2.1. Baseline Features The hierarchical phrase-based translation system employs standard real valued value features: • n-gram language model to capture the fluency of the target side. • Hierarchical phrase translation probabilities in both directions, h(γ|¯bβ) and h(¯bβ|γ), estimated by relative counts, count(γ, ¯bβ) [9]. • Word-based lexically weighted models of hlex (γ|¯bβ) and hlex (¯bβ|γ) using lexical translation models[9]. • Word-based insertion/deletion penalties that penalize through the low probabilities of the lexical translation models [13]. • Word/hierarchical-phrase length penalties. • Backtrack-based penalties inspired by the distortion penalties in phrase-based modeling [1]. 2.2.2. Sparse Features In addition to the baseline features, a large number of binary features are integrated in our MT system [3]. The features are designed with decoding efficiency in mind and are based on the word alignment structure preserved in hierarchical phrase translation pairs [14]. When hierarchical phrases are extracted, the word alignment is preserved. If multiple ei−1 ei f j−1 ei+1 fj ei+2 ei+3 f j+1 f j+2 ei+4 f j+3 Figure 1: An example of"
2007.iwslt-1.16,W06-3108,0,0.0191772,"(¯bβ|γ) using lexical translation models[9]. • Word-based insertion/deletion penalties that penalize through the low probabilities of the lexical translation models [13]. • Word/hierarchical-phrase length penalties. • Backtrack-based penalties inspired by the distortion penalties in phrase-based modeling [1]. 2.2.2. Sparse Features In addition to the baseline features, a large number of binary features are integrated in our MT system [3]. The features are designed with decoding efficiency in mind and are based on the word alignment structure preserved in hierarchical phrase translation pairs [14]. When hierarchical phrases are extracted, the word alignment is preserved. If multiple ei−1 ei f j−1 ei+1 fj ei+2 ei+3 f j+1 f j+2 ei+4 f j+3 Figure 1: An example of sparse features for a phrase translation. X1 X2 f j−1 fj f j+1 f j+3 X3 f j+2 Figure 2: Example hierarchical features. word alignments are observed with the same source and target sides, only the most frequently observed word alignment is kept to reduce the grammar size. Using the word alignment structure inside hierarchical phrases, we employs following feature set. • Word pair features directly capture the source/target word co"
2007.iwslt-1.16,P06-1098,1,0.894326,"parse binary features — of the order of millions — are integrated during the search. This paper gives the details of the two steps and shows the results for the Evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2007. 1. Introduction This paper presents NTT Statistical Machine Translation System evaluated in the evaluation campaign of International Workshop on Spoken Language Translation (IWSLT) 2007. Our system is composed of two steps: First, k-best translation candidates are generated using an efficient decoder for hierarchical phrase-based translation [1]. Next, the large kbest translation is reordered using a reranking voted perceptron [2]. Both systems employ a large number of sparse features — of the order of millions — to achieve a state of the art performance [3]. The large number of parameters are trained using an efficient online training algorithm: The decoder employs an online large-margin training method [4] that has been successfully applied in dependency parsing [5] or joint labeling/chunking [6]. The reranker uses a reranking voted perceptron which gave significant improvement in the last year’s IWSLT 2006 evaluation [2]. Both sys"
2007.iwslt-1.16,P04-1007,0,0.0263178,"(ei−1 , fj−1 ), (ei , fj+1 )). • Insertion/deletion features are integrated in which no word alignment is associated in the target/source side. Inserted words are associated with all the words in the source sentence, such as (ei+1 , f1 ), ..., (ei+1 , fJ ) for the non-aligned word ei+1 with the source sentence f1J in Figure 1. In the same way, we use hierarchical phrase-wise deletion features by associating each inserted source word in a phrase to all the target words in the same phrase. • Target bigram features are also included to directly capture the fluency as in the n-gram language model [15], such as (ei−1 , ei ), (ei , ei+1 ), (ei+1 , ei+2 )... in Figure 1. • Hierarchical features capture dependencies the source words in a parent phrase to the source words in child phrases, such as (fj−1 , fj ), (fj−1 , fj+1 ), (fj+3 , fj ), (fj+3 , fj+1 ), (fj , fj+2 ) and (fj+1 , fj+2 ) as indicated by the arrows in Figure 2. The hierarchical features are extracted only for those source words that are aligned with the target side to limit the feature size. Algorithm 1 Online Training Algorithm for decoder T 1: 2: 3: 4: 5: 6: 7: 8: 9: Training data: T = {(f t , et )}t=1 m-best oracles: O = {}Tt"
2007.iwslt-1.16,E99-1010,0,0.0399514,"ed only for those source words that are aligned with the target side to limit the feature size. Algorithm 1 Online Training Algorithm for decoder T 1: 2: 3: 4: 5: 6: 7: 8: 9: Training data: T = {(f t , et )}t=1 m-best oracles: O = {}Tt=1 i=0 for n = 1, ..., N do for t = 1, ..., T do C t ← bestk (f t ; wi ) Ot ← oraclem (Ot ∪ C t ; et ) wi+1 = update wi using C t w.r.t. Ot i=i+1 end for end for PN T i w return i=1 NT In order to achieve the generalization capability, we introduce normalized tokens for each surface form [3]. • Word class/part-of-speech/named entity. Words are clustered by mkcls [16]. The part-of-speech (POS) and named entity (NE) tags are also integrated to capture linguistic characteristics when taggers are available. A unique word class is assigned to each surface form. However, multiple POS/NE are potentially assigned to each surface word. In our approach, we do not disambiguate labels, but simply collect a surface word to multiple tags dictionary. Those tags are integrated by first running a tagger on the training data. Then, a surface form to POS/NE dictionary is generated by collecting all possible tags for each word. • Synsets from WordNet. In order to represent s"
2007.iwslt-1.16,D07-1080,1,0.562399,"ken Language Translation (IWSLT) 2007. 1. Introduction This paper presents NTT Statistical Machine Translation System evaluated in the evaluation campaign of International Workshop on Spoken Language Translation (IWSLT) 2007. Our system is composed of two steps: First, k-best translation candidates are generated using an efficient decoder for hierarchical phrase-based translation [1]. Next, the large kbest translation is reordered using a reranking voted perceptron [2]. Both systems employ a large number of sparse features — of the order of millions — to achieve a state of the art performance [3]. The large number of parameters are trained using an efficient online training algorithm: The decoder employs an online large-margin training method [4] that has been successfully applied in dependency parsing [5] or joint labeling/chunking [6]. The reranker uses a reranking voted perceptron which gave significant improvement in the last year’s IWSLT 2006 evaluation [2]. Both systems are tuned using approximated BLEU as an objective function that scales the sentence-wise BLEU to a document-wise BLEU. Domain mismatch is handled by a simple task adaptation scheme by selecting training data that"
2007.iwslt-1.16,P06-1091,0,0.0676827,"nese and Japanese. We consider all possible combination of those token types. For example, an English/Arabic word pair feature (violate, tnthk) is normalized and expanded to (viol+, tnthk), (viol+, tnth+), (violate, tnth+), etc. using the 4-letter prefix token type. As discussed above, the POS/NE/synsets labels are assigned by a one-to-many dictionary. Then, each surface form is expanded to all possible labels, then, all possible features are extracted. 2.3. Training Algorithm 1 is our generic online training algorithm. The algorithm is slightly different from other online training algorithms [17, 18] in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, e.g. BLEU [19]. In line 3, a k-best list is generated by bestk (·) using the current weight vector wi for the training instance of (f t , et ). Each training instance has multiple (or, possibly one) reference translations et for the source sentence f t . Using the k-best list, m-best oracle translations Ot are updated by oraclem (·) for every iteration (line 4). Usually, a decoder cannot generate translations that exactly match the reference translations due to its"
2007.iwslt-1.16,P05-1012,0,0.28923,"WSLT) 2007. Our system is composed of two steps: First, k-best translation candidates are generated using an efficient decoder for hierarchical phrase-based translation [1]. Next, the large kbest translation is reordered using a reranking voted perceptron [2]. Both systems employ a large number of sparse features — of the order of millions — to achieve a state of the art performance [3]. The large number of parameters are trained using an efficient online training algorithm: The decoder employs an online large-margin training method [4] that has been successfully applied in dependency parsing [5] or joint labeling/chunking [6]. The reranker uses a reranking voted perceptron which gave significant improvement in the last year’s IWSLT 2006 evaluation [2]. Both systems are tuned using approximated BLEU as an objective function that scales the sentence-wise BLEU to a document-wise BLEU. Domain mismatch is handled by a simple task adaptation scheme by selecting training data that resembles a test set [7]. In order to handle the ASR’s error prone input, we decoded all the nbest translations and let the reranker choose the right translation by treating the individually translated list as a s"
2007.iwslt-1.16,P06-2098,0,0.0623452,"sed of two steps: First, k-best translation candidates are generated using an efficient decoder for hierarchical phrase-based translation [1]. Next, the large kbest translation is reordered using a reranking voted perceptron [2]. Both systems employ a large number of sparse features — of the order of millions — to achieve a state of the art performance [3]. The large number of parameters are trained using an efficient online training algorithm: The decoder employs an online large-margin training method [4] that has been successfully applied in dependency parsing [5] or joint labeling/chunking [6]. The reranker uses a reranking voted perceptron which gave significant improvement in the last year’s IWSLT 2006 evaluation [2]. Both systems are tuned using approximated BLEU as an objective function that scales the sentence-wise BLEU to a document-wise BLEU. Domain mismatch is handled by a simple task adaptation scheme by selecting training data that resembles a test set [7]. In order to handle the ASR’s error prone input, we decoded all the nbest translations and let the reranker choose the right translation by treating the individually translated list as a single k-best list combined with"
2007.iwslt-1.16,P06-1096,0,0.119827,"nese and Japanese. We consider all possible combination of those token types. For example, an English/Arabic word pair feature (violate, tnthk) is normalized and expanded to (viol+, tnthk), (viol+, tnth+), (violate, tnth+), etc. using the 4-letter prefix token type. As discussed above, the POS/NE/synsets labels are assigned by a one-to-many dictionary. Then, each surface form is expanded to all possible labels, then, all possible features are extracted. 2.3. Training Algorithm 1 is our generic online training algorithm. The algorithm is slightly different from other online training algorithms [17, 18] in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, e.g. BLEU [19]. In line 3, a k-best list is generated by bestk (·) using the current weight vector wi for the training instance of (f t , et ). Each training instance has multiple (or, possibly one) reference translations et for the source sentence f t . Using the k-best list, m-best oracle translations Ot are updated by oraclem (·) for every iteration (line 4). Usually, a decoder cannot generate translations that exactly match the reference translations due to its"
2007.iwslt-1.16,P02-1040,0,0.07649,"rmalized and expanded to (viol+, tnthk), (viol+, tnth+), (violate, tnth+), etc. using the 4-letter prefix token type. As discussed above, the POS/NE/synsets labels are assigned by a one-to-many dictionary. Then, each surface form is expanded to all possible labels, then, all possible features are extracted. 2.3. Training Algorithm 1 is our generic online training algorithm. The algorithm is slightly different from other online training algorithms [17, 18] in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, e.g. BLEU [19]. In line 3, a k-best list is generated by bestk (·) using the current weight vector wi for the training instance of (f t , et ). Each training instance has multiple (or, possibly one) reference translations et for the source sentence f t . Using the k-best list, m-best oracle translations Ot are updated by oraclem (·) for every iteration (line 4). Usually, a decoder cannot generate translations that exactly match the reference translations due to its beam search pruning and OOV. Thus, we cannot always assign scores to each reference translation. Therefore, possible oracle translations are mai"
2007.iwslt-1.16,W04-3201,0,0.0272233,"Liang et at. [18] presented a similar updating strategy in which parameters were updated toward an oracle translation found in C t , but ignored potentially better translations discovered in the past iterations. A new wi+1 is computed using the k-best list C t with respect to the oracle translations Ot (line 5). After N iterations, the algorithm returns an averaged weight vector to avoid overfitting (line 9). When updating parameters in line 5, we use the Margin Infused Relaxed Algorithm (MIRA) [4] which is an online version of the large-margin training algorithm for structured classification [20] that has been successfully used for dependency parsing [5] and joint-labeling/chunking [6]. Line 5 of the weight vector update procedure in Algorithm 1 is reAlgorithm 2 Online Training Algorithm for Reranker placed by the solution of: X 1 ˆ i+1 = argmin ||wi+1 − wi ||2 + C ξ(ˆ e, e′ ) w wi+1 2 ′ eˆ,e subject to si+1 (f t , eˆ) − si+1 (f t , e′ ) + ξ(ˆ e, e′ ) ≥ L(ˆ e , e′ ; et ) ′ ξ(ˆ e, e ) ≥ 0 ∀ˆ e ∈ Ot , ∀e′ ∈ C t (3)  ⊤ where si (f t , e) = wi · h(f t , e). ξ(·) is a non-negative slack variable and C ≥ 0 is a constant to control the influence to the objective function. A larger C implies"
2007.iwslt-1.16,P02-1034,0,0.0176638,"ain the best oracle translations O1T = eˆ1 , ..., eˆT that is treated as a “bed” document. The approximated BLEU for a hypothesized translation e′ for the training instance (f t , et ) is computed over the bed O1T except for eˆt , which is replaced by e′ : BLEU({ˆ e1 , ..., eˆt−1 , e′ , eˆt+1 , ..., eˆT }; E) The loss computed by the approximated BLEU measures the document-wise loss of substituting the correct translation eˆt Our reranking system is basically identical to the system presented in the last year’s IWSLT 2006 evaluation [2] that is based on the parse reranking method explained in [21]. We first generate n-best lists of candidate translations from the decoder, then train reranking model using the development set with additional features by ranking voted perceptron. Finally, during the testing, we rerank the k-best list of test data from the decoder by the parameters for the reranking. A separately trained reranking model is used for the ASR’s nbest list. The reranker selects the best translation out of the merged k · n-best list generated by translating all the sentences in the n-best list. 3.1. Features The reranking system employs a slightly different feature set from the"
2007.iwslt-1.16,takezawa-etal-2002-toward,0,0.068604,"n line 8 is based on an perceptron algorithm with the update amount scaled by the loss function L(·).  wn = wn + L(Rj , Ri ; et ) · h(f t , Rj ) − h(f t , Ri ) (5) As our loss function, we employed the difference of the approximated BLEU in Section 2.4, but used a set of 1-best translations from the decoder as our bed document, instead of oracle translations. The idea is to directly measure the gain or loss by selecting the translation different from the original 1-best translation of the decoder. 4. Evaluation 4.1. Data The major training data comes from IWSLT supplied data, a subset of BTEC[22]. We also used common bilingual data either in the public domain or from the LDC as indicated in Table 1. Additional data for Arabic/English and Chinese/English comes from a set of LDC bilingual news data, lexicon and the named entity list. For Italian/English, a portion of EuroParl [23] was extracted. Additional data for Japanese/English come from the news data and misJapanese-to-English 1,055,144 10,811,003 8,646,894 384,236 254,442 NiCT, others Table 2: The source language perplexity for the “clean” development and test set. dev set test set Arabic-to-English 561.96 214.99 Italian-to-Englis"
2007.iwslt-1.16,2005.mtsummit-papers.11,0,0.00566131,"ions from the decoder as our bed document, instead of oracle translations. The idea is to directly measure the gain or loss by selecting the translation different from the original 1-best translation of the decoder. 4. Evaluation 4.1. Data The major training data comes from IWSLT supplied data, a subset of BTEC[22]. We also used common bilingual data either in the public domain or from the LDC as indicated in Table 1. Additional data for Arabic/English and Chinese/English comes from a set of LDC bilingual news data, lexicon and the named entity list. For Italian/English, a portion of EuroParl [23] was extracted. Additional data for Japanese/English come from the news data and misJapanese-to-English 1,055,144 10,811,003 8,646,894 384,236 254,442 NiCT, others Table 2: The source language perplexity for the “clean” development and test set. dev set test set Arabic-to-English 561.96 214.99 Italian-to-English 277.24 271.39 51.29 13.45 Japanese-to-English Chinese-to-English 188.49 73.18 cellaneous text data supplied by NiCT [24], together with textbook-like data, a lexicon and a named entity list in the public domain 1 . The corpus statistics is presented in Table 1. Since there exists large"
2007.iwslt-1.16,P03-1010,0,0.0124565,"ata for Arabic/English and Chinese/English comes from a set of LDC bilingual news data, lexicon and the named entity list. For Italian/English, a portion of EuroParl [23] was extracted. Additional data for Japanese/English come from the news data and misJapanese-to-English 1,055,144 10,811,003 8,646,894 384,236 254,442 NiCT, others Table 2: The source language perplexity for the “clean” development and test set. dev set test set Arabic-to-English 561.96 214.99 Italian-to-English 277.24 271.39 51.29 13.45 Japanese-to-English Chinese-to-English 188.49 73.18 cellaneous text data supplied by NiCT [24], together with textbook-like data, a lexicon and a named entity list in the public domain 1 . The corpus statistics is presented in Table 1. Since there exists larger mismatch with the IWSLT condition, we extracted texts that do not contain any digits by discarding sentences that match the regular expression, “[09]”. We used a development set of 4, 5 and 5b for estimating parameters both of the decoder and the reranker, since those data include ASR’s outputs. Tokenization/tagging are performed by the following tools: English data is POS tagged by a MaxEnt-based tool [25] for use in the decode"
2007.iwslt-1.16,H05-1059,0,0.0194319,"data supplied by NiCT [24], together with textbook-like data, a lexicon and a named entity list in the public domain 1 . The corpus statistics is presented in Table 1. Since there exists larger mismatch with the IWSLT condition, we extracted texts that do not contain any digits by discarding sentences that match the regular expression, “[09]”. We used a development set of 4, 5 and 5b for estimating parameters both of the decoder and the reranker, since those data include ASR’s outputs. Tokenization/tagging are performed by the following tools: English data is POS tagged by a MaxEnt-based tool [25] for use in the decoder, and by a rule-based Brill’s POS tagger for reranking. Arabic data is tokenized by simply isolating Arabic scripts. Italian data is POS tagged by treetagger [26]. Japanese/Chinese texts are POS tagged/NE chunked [27]. After tokenization, we removed all the punctuation marks in the source side of bilingual data and lowercased the texts. The English side of the bilingual data is case/punctuation preserved. 4.2. Task Adaptation As discussed in Section 4.1, we extracted bilingual data from various sources, ranging from in-domain travel related data to out-of-domain news, mi"
2007.iwslt-1.16,W03-1506,0,0.274806,"d texts that do not contain any digits by discarding sentences that match the regular expression, “[09]”. We used a development set of 4, 5 and 5b for estimating parameters both of the decoder and the reranker, since those data include ASR’s outputs. Tokenization/tagging are performed by the following tools: English data is POS tagged by a MaxEnt-based tool [25] for use in the decoder, and by a rule-based Brill’s POS tagger for reranking. Arabic data is tokenized by simply isolating Arabic scripts. Italian data is POS tagged by treetagger [26]. Japanese/Chinese texts are POS tagged/NE chunked [27]. After tokenization, we removed all the punctuation marks in the source side of bilingual data and lowercased the texts. The English side of the bilingual data is case/punctuation preserved. 4.2. Task Adaptation As discussed in Section 4.1, we extracted bilingual data from various sources, ranging from in-domain travel related data to out-of-domain news, miscellaneous texts and lexicons. Their characteristics are very different from the style in the IWSLT development and test conditions. Table 2 shows the development/test set perplexity of the source side language computed by the trigram of t"
2007.iwslt-1.16,N06-1014,0,0.0286367,"Missing"
2007.iwslt-1.16,2006.iwslt-evaluation.14,1,\N,Missing
2007.iwslt-1.16,C98-2225,0,\N,Missing
2008.iwslt-evaluation.13,D07-1080,1,0.906376,"Missing"
2008.iwslt-evaluation.13,2006.iwslt-evaluation.14,1,0.898254,"ted phrases, SCFG production rules are accumulated by ﬁnding “holes” in extracted contiguous phrases: • For a phrase pair (f¯, e¯), a rule X → hf¯, e¯i is extracted. • For a rule X → hγ, αi and a phrase pair (f¯, e¯) s.t. γ = γ1 f¯γ2 and α = α1 e¯α2 , a rule X → hγ1 X k γ2 , α1 X k α2 i is extracted. where boxed indices non-terminals. k indicate one-to-one mapping between 2.3. Decoder features Features used in our machine translation component are realvalued scores derived from the translation and language models. These features are those used as baseline features in our IWSLT 2006 evaluation [3]: • Hierarchical phrase translation probabilities We employs Pegasos1 , a fast optimization algorithm for linear-kernel SVMs. It uses only k samples to calculate subgradient for optimization, so learning time of Pegasos does not depend on the training data size [5]. 3.2. Approximated BLEU We use approximated BLEU [3] to choose the best translation candidates, for optimizing the reranker in terms of BLEU [11]. The approximated BLEU is independently calculated on each translation candidate for each sentence in reranker training data during pre-processing, although original BLEU required document"
2008.iwslt-evaluation.13,2007.iwslt-1.16,1,0.843688,"entences O1T = {e11 , ..., eT1 }, the approximated BLEU on i-best translation candidate for t-th input sentence eti is calculated by substituting et1 with eti , i.e. the BLEU on the sentence set t t+1 T {e11 , ..., et−1 1 , ei , e1 , ..., e1 }. 3.3. Reranker features We use a large number of sparse binary features for reranking, as well as a real-valued feature (decoder score). • Lexical translation probabilities in phrase pairs 3.3.1. Word alignment features • Word-based insertion/deletion penalties We use source-target word pairs extracted by separately running IBM Model 1 in both direction [4]. In addition to source-target word unigram pairs, we used pairs of targetside word bigram and their corresponding source-side words in terms of the word alignment. We also include POS-based features, target-side word surfaces are replaced with their POS tags in the word alignment features above. Target-side (English) POS tags are automatically annotated by Brill Tagger. • Word 5-gram language model scores • Reordering penalties • Length penalties on both words and hierarchical phrases 3. Reranking Component Our reranking component is based on Ranking SVMs [1]. Each decoder k-best translation"
2008.iwslt-evaluation.13,P03-1021,0,0.0231724,"2 - work in the experiments, because they failed to capture useful context information in the current condition. We discuss these features using distinctive examples between reranker selections and decoder 1-bests. This paper is organized as follows: Section 2 brieﬂy describes our SMT decoder. Section 3 describes our reranking component and sparse features for reranking. Section 4 presents the results for the evaluation campaign of IWSLT 2008, followed by discussion in Section 5. 2. Machine Translation Component 2.1. Statistical Machine Translation We use a linear feature combination approach [6] in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: eˆ = argmax w&gt; · h(f, e) (1) e where h(f, e) is a feature vector. w is a weight vector that scales the contribution from each feature. Feature weights (i.e. elements of w) are optimized based on minimum error rate training [6]. 2.2. Hierarchical Phrase-based Approach Our SMT component employs the hierarchical phrase-based approach [7], in which the translation model is based on a stochastic synchronous context-free grammar (SCFG). A translation is generated by hie"
2008.iwslt-evaluation.13,J07-2003,0,0.0606697,"on in Section 5. 2. Machine Translation Component 2.1. Statistical Machine Translation We use a linear feature combination approach [6] in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: eˆ = argmax w&gt; · h(f, e) (1) e where h(f, e) is a feature vector. w is a weight vector that scales the contribution from each feature. Feature weights (i.e. elements of w) are optimized based on minimum error rate training [6]. 2.2. Hierarchical Phrase-based Approach Our SMT component employs the hierarchical phrase-based approach [7], in which the translation model is based on a stochastic synchronous context-free grammar (SCFG). A translation is generated by hierarchically combining phrases using non-terminals. Each production rule of SCFG takes the following form. X → hγ, α, ∼i (2) In the notation above, X is a non-terminal symbol, γ is a source-side string of terminal and non-terminal symbols, and α is a target-side one. γ and α share the same number of non-terminals whose one-to-one mapping is deﬁned by ∼. Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by"
2008.iwslt-evaluation.13,N03-1017,0,0.0076853,"ased on a stochastic synchronous context-free grammar (SCFG). A translation is generated by hierarchically combining phrases using non-terminals. Each production rule of SCFG takes the following form. X → hγ, α, ∼i (2) In the notation above, X is a non-terminal symbol, γ is a source-side string of terminal and non-terminal symbols, and α is a target-side one. γ and α share the same number of non-terminals whose one-to-one mapping is deﬁned by ∼. Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by a conventional phrase-based approach [8]. The non-terminal embedded phrases are learned from a bilingual corpus without a linguistically motivated syntactic structure. Our decoder and rule extraction procedure is based on Hiero [7]. The decoder is an in-house developed CKY-based Proceedings of IWSLT 2008, Hawaii - U.S.A. one. Rules in forms of (2) are extracted using phrase pairs obtained by the phrase extraction algorithm [8]. The phrase extraction uses many-to-many word alignment, derived from heuristics on one-to-many word alignment in both directions [9, 10]. Using the extracted phrases, SCFG production rules are accumulated by"
2008.iwslt-evaluation.13,J03-1002,0,0.00281422,"hrases that is not directly modeled by a conventional phrase-based approach [8]. The non-terminal embedded phrases are learned from a bilingual corpus without a linguistically motivated syntactic structure. Our decoder and rule extraction procedure is based on Hiero [7]. The decoder is an in-house developed CKY-based Proceedings of IWSLT 2008, Hawaii - U.S.A. one. Rules in forms of (2) are extracted using phrase pairs obtained by the phrase extraction algorithm [8]. The phrase extraction uses many-to-many word alignment, derived from heuristics on one-to-many word alignment in both directions [9, 10]. Using the extracted phrases, SCFG production rules are accumulated by ﬁnding “holes” in extracted contiguous phrases: • For a phrase pair (f¯, e¯), a rule X → hf¯, e¯i is extracted. • For a rule X → hγ, αi and a phrase pair (f¯, e¯) s.t. γ = γ1 f¯γ2 and α = α1 e¯α2 , a rule X → hγ1 X k γ2 , α1 X k α2 i is extracted. where boxed indices non-terminals. k indicate one-to-one mapping between 2.3. Decoder features Features used in our machine translation component are realvalued scores derived from the translation and language models. These features are those used as baseline features in our IWSL"
2008.iwslt-evaluation.13,J04-4002,0,0.0283074,"hrases that is not directly modeled by a conventional phrase-based approach [8]. The non-terminal embedded phrases are learned from a bilingual corpus without a linguistically motivated syntactic structure. Our decoder and rule extraction procedure is based on Hiero [7]. The decoder is an in-house developed CKY-based Proceedings of IWSLT 2008, Hawaii - U.S.A. one. Rules in forms of (2) are extracted using phrase pairs obtained by the phrase extraction algorithm [8]. The phrase extraction uses many-to-many word alignment, derived from heuristics on one-to-many word alignment in both directions [9, 10]. Using the extracted phrases, SCFG production rules are accumulated by ﬁnding “holes” in extracted contiguous phrases: • For a phrase pair (f¯, e¯), a rule X → hf¯, e¯i is extracted. • For a rule X → hγ, αi and a phrase pair (f¯, e¯) s.t. γ = γ1 f¯γ2 and α = α1 e¯α2 , a rule X → hγ1 X k γ2 , α1 X k α2 i is extracted. where boxed indices non-terminals. k indicate one-to-one mapping between 2.3. Decoder features Features used in our machine translation component are realvalued scores derived from the translation and language models. These features are those used as baseline features in our IWSL"
2008.iwslt-evaluation.13,P02-1040,0,0.0764379,"in our machine translation component are realvalued scores derived from the translation and language models. These features are those used as baseline features in our IWSLT 2006 evaluation [3]: • Hierarchical phrase translation probabilities We employs Pegasos1 , a fast optimization algorithm for linear-kernel SVMs. It uses only k samples to calculate subgradient for optimization, so learning time of Pegasos does not depend on the training data size [5]. 3.2. Approximated BLEU We use approximated BLEU [3] to choose the best translation candidates, for optimizing the reranker in terms of BLEU [11]. The approximated BLEU is independently calculated on each translation candidate for each sentence in reranker training data during pre-processing, although original BLEU required document-wise calculation and is not suitable for sentence-level reranking. Given 1-best translation outputs for T input sentences O1T = {e11 , ..., eT1 }, the approximated BLEU on i-best translation candidate for t-th input sentence eti is calculated by substituting et1 with eti , i.e. the BLEU on the sentence set t t+1 T {e11 , ..., et−1 1 , ei , e1 , ..., e1 }. 3.3. Reranker features We use a large number of spar"
2008.iwslt-evaluation.13,W03-1506,0,0.0710488,"Missing"
2008.iwslt-evaluation.13,C08-1137,0,\N,Missing
2008.iwslt-evaluation.13,2007.iwslt-1.8,0,\N,Missing
2008.iwslt-evaluation.13,P07-1002,0,\N,Missing
2008.iwslt-evaluation.13,W06-3110,0,\N,Missing
2008.iwslt-evaluation.13,P06-1066,0,\N,Missing
2008.iwslt-evaluation.13,P07-2045,0,\N,Missing
2008.iwslt-evaluation.13,N04-1022,0,\N,Missing
2008.iwslt-evaluation.13,2005.iwslt-1.16,0,\N,Missing
2008.iwslt-evaluation.13,W06-3119,0,\N,Missing
2008.iwslt-evaluation.13,I08-1066,0,\N,Missing
2008.iwslt-evaluation.13,2006.iwslt-evaluation.22,0,\N,Missing
2009.iwslt-papers.3,P02-1038,0,0.263208,"tained by our proposed methods is more stable in various conditions than that obtained by MERT. Our experimental results on the FrenchEnglish WMT08 shared task show that degrade of our proposed methods is smaller than that of MERT in case of small training data or out-of-domain test data. 1. Introduction The state of the art statistical machine translation systems have been modeled by the log-linear approach which is a generalization of the noizy-channel approach. This approach has achieved a lot of great advances because it has provided a natural extention to integrate many useful components [1]. To estimate the weights toward these components according to their performance, minimum error rate training (MERT) [2] was introduced by Och (2003). MERT improves statistical machine translation quality by optimizing the parameter of the log-linear function by using such automatic translation evaluation metrics as the BLEU scores [3]. To train a small number of real-valued features used on a standard phrase-based statistical machine translation system like Moses [16], MERT with BLEU-based objective function is very effective due to line-search algorithm proposed by Och (2003). However, MERT"
2009.iwslt-papers.3,P03-1021,0,0.0865125,"on the FrenchEnglish WMT08 shared task show that degrade of our proposed methods is smaller than that of MERT in case of small training data or out-of-domain test data. 1. Introduction The state of the art statistical machine translation systems have been modeled by the log-linear approach which is a generalization of the noizy-channel approach. This approach has achieved a lot of great advances because it has provided a natural extention to integrate many useful components [1]. To estimate the weights toward these components according to their performance, minimum error rate training (MERT) [2] was introduced by Och (2003). MERT improves statistical machine translation quality by optimizing the parameter of the log-linear function by using such automatic translation evaluation metrics as the BLEU scores [3]. To train a small number of real-valued features used on a standard phrase-based statistical machine translation system like Moses [16], MERT with BLEU-based objective function is very effective due to line-search algorithm proposed by Och (2003). However, MERT tends to overfit to training data because its objective function consists of no regularizer. To enhance generalization a"
2009.iwslt-papers.3,2001.mtsummit-papers.68,0,0.120111,"l machine translation systems have been modeled by the log-linear approach which is a generalization of the noizy-channel approach. This approach has achieved a lot of great advances because it has provided a natural extention to integrate many useful components [1]. To estimate the weights toward these components according to their performance, minimum error rate training (MERT) [2] was introduced by Och (2003). MERT improves statistical machine translation quality by optimizing the parameter of the log-linear function by using such automatic translation evaluation metrics as the BLEU scores [3]. To train a small number of real-valued features used on a standard phrase-based statistical machine translation system like Moses [16], MERT with BLEU-based objective function is very effective due to line-search algorithm proposed by Och (2003). However, MERT tends to overfit to training data because its objective function consists of no regularizer. To enhance generalization ability, we would like to use other state-of-the-art machine learning techniques for machine translation. Support vector machines (SVM) have proven to be power† This research was conducted as an internship program 2008"
2009.iwslt-papers.3,P05-1033,0,0.0849286,"Missing"
2009.iwslt-papers.3,P05-1034,0,0.0712134,"Missing"
2009.iwslt-papers.3,W00-1303,0,0.04046,"fective due to line-search algorithm proposed by Och (2003). However, MERT tends to overfit to training data because its objective function consists of no regularizer. To enhance generalization ability, we would like to use other state-of-the-art machine learning techniques for machine translation. Support vector machines (SVM) have proven to be power† This research was conducted as an internship program 2008 of NTT. Watanabe now belongs to National Institute of Information and Communications Technology (NICT) in Japan. ∗ Taro - 144 - ful tools for many tasks in natural language processing [6][7]. The core of the form consists of a smooth convex regularizer such as 12 ||w||2 and the empirical risk term of hinge loss. In this paper we present an approach to optimize the parameter of the log-liner model using the primal form of structural SVM [12]. We expect the convex regularizer or the factor of enlarging the margin (between the reference and the incorrect translation) of SVM to reduce the overfitting problem and enhance generalization ability. Using the BLEU scores to define the hinge loss, our proposed method also inherits the advantages of MERT, which enhance the BLEU scores of tra"
2009.iwslt-papers.3,D07-1080,1,0.888167,"ˆelsi−1 .m−li−1 .m } i−1 .b−li .b xi = { lil.m−l } i−1 .m end if until no more intersections add(I , xi1 ) add(I , max(I ) + 2) xbest = argminx∈I Obj(w )d, Cs1 , {rj , ˆ e∗j , fj }sj=1 ) w+ = (xbest − ) delete(I , max(I ) + 2) end for return w + (x − S e∗s }1 ) − BLEU({rs , ˆ es }1 )}. Q × {BLEU({rs , ˆ 1-slack formulation with margin-rescaling is constructed usS ing the corpus-wise BLEU loss function Δ({ˆ e∗s , ˆ es }1 ): λ argmin w2 + ξ. w,ξ≥0 2 (7) eS ) ∈ CS : s.t. ∀(ˆ e1 , · · · , ˆ S 1 S w, δhs  ≥ Δ({ˆ e∗s , ˆ es }1 ) − ξ. S s=1 Unlike the margin infused relaxed algorithm (MIRA) [9] and S-slack formulation, we can directly apply the corpus-wise BLEU to the SVM objective function without approximating the BLEU scores. 4.3. Optimization Algorithm 4.3.1. Line-search Algorithm Next we describe extended Och’s line-search algorithms for S-slack and 1-slack formulation of the Structural SVM. These pseudocodes for the line-search to optimize parameter w are given by Algorithm 3,4. In Algorithm 3,4 we can find the range of values along the direction vector d to which each candidate translation is assigned the best score. Algorithm 3 is the line-search algorithm for S-slack formul"
2009.iwslt-papers.3,P05-1012,0,0.13106,"Missing"
2009.iwslt-papers.3,P06-2098,0,0.029702,"Missing"
2009.iwslt-papers.3,2005.eamt-1.36,0,0.401502,"ce. In the second subsection we define loss function Δ(rs , ˆ es ) using the BLEU scores, and the third subsection extends Och’s line-search algorithm as the optimization algorithm for the SVM-based objective function. 4.1. Selecting the Configuration in the K-best list For structural SVM, we need to label a correct candidate translation for each source sentence from its K-best list of candidates, which is called a configuration. Since the BLEU scores are not cumulative, we cannot efficiently select the best configuration from the K-best list. So we approximate it by a greedy search algorithm [14]. This algorithm considers the impact on the training set score when selecting an alternative translation by subtracting the statistics for the current configuration choice from the accumulated statistics and adding those for the alternative and selects the translation which results in the highest score. Repeat this process and continue untill there are no configuration changes. The configuration obtained by this algorithm specifies the correct candidate for each K-best list, and the BLEU scores are the upper bound for the BLEU scores on the training set. 4.2. Loss Function for Rescaling 4.2.1"
2009.iwslt-papers.3,2006.iwslt-evaluation.14,1,0.930093,"Missing"
2009.iwslt-papers.3,P07-2045,0,0.0638114,"s approach has achieved a lot of great advances because it has provided a natural extention to integrate many useful components [1]. To estimate the weights toward these components according to their performance, minimum error rate training (MERT) [2] was introduced by Och (2003). MERT improves statistical machine translation quality by optimizing the parameter of the log-linear function by using such automatic translation evaluation metrics as the BLEU scores [3]. To train a small number of real-valued features used on a standard phrase-based statistical machine translation system like Moses [16], MERT with BLEU-based objective function is very effective due to line-search algorithm proposed by Och (2003). However, MERT tends to overfit to training data because its objective function consists of no regularizer. To enhance generalization ability, we would like to use other state-of-the-art machine learning techniques for machine translation. Support vector machines (SVM) have proven to be power† This research was conducted as an internship program 2008 of NTT. Watanabe now belongs to National Institute of Information and Communications Technology (NICT) in Japan. ∗ Taro - 144 - ful too"
2009.iwslt-papers.3,J03-1002,0,0.00413523,"i = argminˆes ∈Cs ˆe∗s { ˆelsi−1 .m−li−1 .m } i−1 .b−li .b xi = { lil.m−l } i−1 .m end if until no more intersections add(I , xi1 ) end for add(I , max(I ) + 2) xbest = argminx∈I Obj(w )d, CS1 , {rs , ˆ e∗s , fs }S1 ) return w + (xbest − )d + (x − • Three orientation types reordering model[17]: p(m|f , e) , p(s|f , e) , p(d|f , e) to capture the lexicalized information. • Word , Phrase penalty: To control the target length and the average length of the phrases. In this paper, we trained these small number of features and phrases were extracted using a typical approach [16] that ran GIZA++ [18]. We used a Katz smoothing 5-gram language model that was created using the SRILM toolkit [19]. 5.2. Data Set For experiments we used the French-English data provided for the Europarl-based WMT08 shared task. Europarl corpus was collected from the proceedings of European Parliament [20]. This training corpus contains about 1.3 M sentences. Parameters were tuned over the provided development set (dev2006) that consisted of 2000 sentences with one reference. We used two open test sets: Europarl test 2008, consisting of 2000 sentences with one reference, and News newstest 2008 (out-of-domain), co"
2009.iwslt-papers.3,2005.mtsummit-papers.11,0,0.00816147,"g model[17]: p(m|f , e) , p(s|f , e) , p(d|f , e) to capture the lexicalized information. • Word , Phrase penalty: To control the target length and the average length of the phrases. In this paper, we trained these small number of features and phrases were extracted using a typical approach [16] that ran GIZA++ [18]. We used a Katz smoothing 5-gram language model that was created using the SRILM toolkit [19]. 5.2. Data Set For experiments we used the French-English data provided for the Europarl-based WMT08 shared task. Europarl corpus was collected from the proceedings of European Parliament [20]. This training corpus contains about 1.3 M sentences. Parameters were tuned over the provided development set (dev2006) that consisted of 2000 sentences with one reference. We used two open test sets: Europarl test 2008, consisting of 2000 sentences with one reference, and News newstest 2008 (out-of-domain), consisting of 1500 sentences. Table 1 shows these contents in more detail. Table 1: The Data statistics For the 1-slack formulation we should calculate slopes m and intercepts b the same as the S-slack formulation, but, to avoid bias toward the line-search procedure by sentencewise BLEU,"
2009.iwslt-papers.3,N09-1025,0,0.107757,"Missing"
2009.iwslt-papers.3,W08-0304,0,0.108941,"Missing"
2009.iwslt-papers.3,D08-1076,0,0.0713832,"Missing"
2009.iwslt-papers.3,C08-1074,0,0.0530567,"Missing"
2009.iwslt-papers.3,J93-2003,0,0.0179364,"Missing"
2009.iwslt-papers.3,P02-1040,0,\N,Missing
2009.iwslt-papers.3,2005.iwslt-1.8,0,\N,Missing
2010.iwslt-evaluation.19,2005.iwslt-1.19,0,\N,Missing
2010.iwslt-evaluation.19,W09-0424,0,\N,Missing
2010.iwslt-evaluation.19,P05-1056,0,\N,Missing
2010.iwslt-evaluation.19,2009.iwslt-evaluation.5,0,\N,Missing
2010.iwslt-evaluation.19,2005.eamt-1.19,0,\N,Missing
2010.iwslt-evaluation.19,zhang-etal-2004-interpreting,0,\N,Missing
2010.iwslt-evaluation.19,2010.iwslt-papers.5,1,\N,Missing
2010.iwslt-papers.5,D10-1044,0,\N,Missing
2010.iwslt-papers.5,W08-0334,0,\N,Missing
2010.iwslt-papers.5,W09-0424,0,\N,Missing
2010.iwslt-papers.5,D09-1040,0,\N,Missing
2010.iwslt-papers.5,J07-3002,0,\N,Missing
2010.iwslt-papers.5,D09-1074,0,\N,Missing
2010.iwslt-papers.5,D08-1090,0,\N,Missing
2010.iwslt-papers.5,W10-1759,0,\N,Missing
2010.iwslt-papers.5,J04-4002,0,\N,Missing
2010.iwslt-papers.5,P06-1002,0,\N,Missing
2010.iwslt-papers.5,D07-1036,0,\N,Missing
2010.iwslt-papers.5,2005.mtsummit-papers.11,0,\N,Missing
2010.iwslt-papers.5,W10-1713,0,\N,Missing
2010.iwslt-papers.5,2009.mtsummit-papers.5,0,\N,Missing
2011.mtsummit-papers.11,P06-1002,0,0.0218152,"s et al., 2009; Foster et al., 2010). A promising aspect about the latter two papers, in particular, is that they are able to incorporate supervised information (likelihood or expected TER on the dev set) for score adaptation. We emphasize that our contribution is orthogonal to previous work: alignment inference adaptation can be combined with any adaptation method in other parts of the pipeline. It remains to be seen whether the improvements are additive: while our results are positive in both alignment and final translation performance, some work have shown weak correlation between the two (Ayan and Dorr, 2006; Fraser and Marcu, 2009). There are also adaptation methods that do not target a particular step in the training pipeline. For example, the information retrieval approach (Hildebrand et al., 2005) begins by identifying a subset of out-of-domain bitext most similar to in-domain; this data subset can be used for any (or all) steps of the training pipeline. An alternative approach is to train separate translation models for in-domain and out-of-domain data, then combine the final models log-linearly (Koehn and Schroeder, 2007) or dynamically (Finch and Sumita, 2008; L¨u et al., 2007). 5 Conclusi"
2011.mtsummit-papers.11,W09-0432,0,0.0169878,"ng (not inference). 2) Alignment inference: To the best of our knowledge, there is no previous work in this area. The model training of Step 1 is related but not the same. Instead, alignment combination works (Deng and Zhou, 2009) may give some insights. 3) Phrase extraction: Out-of-domain text may contain unseen phrases useful for in-domain data. One approach attempts to discover paraphrases from large monolingual corpora (Marton et al., 2009; Snover et al., 2008). Another is a self-training approach that translates source in-domain text and re-trains the translation model on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to score adaptation involve combining in-domain and out-of-domain scores at either the sentence or the phrase level (Shah et al., 2010; Matsoukas et al., 2009; Foster et al., 2010). A"
2011.mtsummit-papers.11,J07-2003,0,0.0432673,"archical rules) required for the extraction/scoring steps. All we need are the standard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively balance the uncertainty in alignment from both in"
2011.mtsummit-papers.11,W07-0722,0,0.0256665,", and (b) if so, which step. Following the training pipeline in Section 1, we briefly survey the approaches in prior work: 1) Word alignment model training: Assume a probabilistic model of alignment, where the parameters (e.g. lexical translation probabilities in the IBM Models) are estimated from a mix of in-domain 119 and out-of-domain data. One method is to interpolate separate sets of parameters estimated from indomain and out-domain data. Wu et. al.(2005) sets the interpolation weights to be proportional to the relative frequency of observances in in-domain and out-of-domain data, while (Civera and Juan, 2007) treats it as a hidden parameter in a mixture model. These methods are similar to ours in that the motivation is to improve alignments, but differs in that the focus is on training (not inference). 2) Alignment inference: To the best of our knowledge, there is no previous work in this area. The model training of Step 1 is related but not the same. Instead, alignment combination works (Deng and Zhou, 2009) may give some insights. 3) Phrase extraction: Out-of-domain text may contain unseen phrases useful for in-domain data. One approach attempts to discover paraphrases from large monolingual cor"
2011.mtsummit-papers.11,P11-1043,0,0.0359624,"Missing"
2011.mtsummit-papers.11,P09-2058,0,0.0240098,"ed from indomain and out-domain data. Wu et. al.(2005) sets the interpolation weights to be proportional to the relative frequency of observances in in-domain and out-of-domain data, while (Civera and Juan, 2007) treats it as a hidden parameter in a mixture model. These methods are similar to ours in that the motivation is to improve alignments, but differs in that the focus is on training (not inference). 2) Alignment inference: To the best of our knowledge, there is no previous work in this area. The model training of Step 1 is related but not the same. Instead, alignment combination works (Deng and Zhou, 2009) may give some insights. 3) Phrase extraction: Out-of-domain text may contain unseen phrases useful for in-domain data. One approach attempts to discover paraphrases from large monolingual corpora (Marton et al., 2009; Snover et al., 2008). Another is a self-training approach that translates source in-domain text and re-trains the translation model on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that al"
2011.mtsummit-papers.11,2010.iwslt-papers.5,1,0.759658,"data. Outof-domain data is heterogeneous, consisting of Hansards, broadcast conversations, weblogs, etc. The data statistics are shown in Table 1. We compare 3 phrasal SMT systems: • in-domain model: Step1: Train word alignment model on in-domain bitext (M in ). Step 2-to-4: Alignment inference on in-domain text, followed by phrase extraction and scoring. • general-domain model: Step1: Train word alignment model on concatenated in-domain and out-of-domain bitext (M gen ). Step2-to-4: same as in-domain model. This simple approach is a strong adaptation baseline competitive in many tasks, c.f. (Duh et al., 2010). • bayes: Step1-to-2: Algorithm 1. Step3-to-4: same as in-domain model. Note that out-of-domain information is used only up to step 2 and excluded in further steps of the 4 www.itl.nist.gov/iad/mig/tests/mt/doc/ 118 pipeline. This clarifies the analysis: if we were to include out-of-domain bitext for phrase extraction, our SMT system might acquire new phrases, which reduces out-of-vocabulary rate and confounds the analysis of alignment inference results. Further, from preliminary experiments, we found that adding out-of-domain bitext to all four steps actually degrade results sometimes, due t"
2011.mtsummit-papers.11,W08-0334,0,0.0154527,"weak correlation between the two (Ayan and Dorr, 2006; Fraser and Marcu, 2009). There are also adaptation methods that do not target a particular step in the training pipeline. For example, the information retrieval approach (Hildebrand et al., 2005) begins by identifying a subset of out-of-domain bitext most similar to in-domain; this data subset can be used for any (or all) steps of the training pipeline. An alternative approach is to train separate translation models for in-domain and out-of-domain data, then combine the final models log-linearly (Koehn and Schroeder, 2007) or dynamically (Finch and Sumita, 2008; L¨u et al., 2007). 5 Conclusions and Future Work We proposed a flexible and efficient method for domain adaptation in machine translation. The idea is to decompose the word alignment process into model training and alignment inference, and view the latter as a sequential Bayesian update problem. The advantages of our approach are: 1. Its modularity enables the use of any model training algorithm for word alignment, as long as it outputs N-best lists or posteriors. 2. It gives consistent improvements over a multitude of datasets (2 tasks and 11 language pairs). We have shown how alignment inf"
2011.mtsummit-papers.11,D10-1044,0,0.0138276,"oldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to score adaptation involve combining in-domain and out-of-domain scores at either the sentence or the phrase level (Shah et al., 2010; Matsoukas et al., 2009; Foster et al., 2010). A promising aspect about the latter two papers, in particular, is that they are able to incorporate supervised information (likelihood or expected TER on the dev set) for score adaptation. We emphasize that our contribution is orthogonal to previous work: alignment inference adaptation can be combined with any adaptation method in other parts of the pipeline. It remains to be seen whether the improvements are additive: while our results are positive in both alignment and final translation performance, some work have shown weak correlation between the two (Ayan and Dorr, 2006; Fraser and Marc"
2011.mtsummit-papers.11,N04-1035,0,0.0363765,"l we need are the standard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively balance the uncertainty in alignment from both in-domain and general-domain bitexts. The contribution of this paper i"
2011.mtsummit-papers.11,2005.eamt-1.19,0,0.0322357,"the dev set) for score adaptation. We emphasize that our contribution is orthogonal to previous work: alignment inference adaptation can be combined with any adaptation method in other parts of the pipeline. It remains to be seen whether the improvements are additive: while our results are positive in both alignment and final translation performance, some work have shown weak correlation between the two (Ayan and Dorr, 2006; Fraser and Marcu, 2009). There are also adaptation methods that do not target a particular step in the training pipeline. For example, the information retrieval approach (Hildebrand et al., 2005) begins by identifying a subset of out-of-domain bitext most similar to in-domain; this data subset can be used for any (or all) steps of the training pipeline. An alternative approach is to train separate translation models for in-domain and out-of-domain data, then combine the final models log-linearly (Koehn and Schroeder, 2007) or dynamically (Finch and Sumita, 2008; L¨u et al., 2007). 5 Conclusions and Future Work We proposed a flexible and efficient method for domain adaptation in machine translation. The idea is to decompose the word alignment process into model training and alignment i"
2011.mtsummit-papers.11,W07-0733,0,0.0180875,"nslation performance, some work have shown weak correlation between the two (Ayan and Dorr, 2006; Fraser and Marcu, 2009). There are also adaptation methods that do not target a particular step in the training pipeline. For example, the information retrieval approach (Hildebrand et al., 2005) begins by identifying a subset of out-of-domain bitext most similar to in-domain; this data subset can be used for any (or all) steps of the training pipeline. An alternative approach is to train separate translation models for in-domain and out-of-domain data, then combine the final models log-linearly (Koehn and Schroeder, 2007) or dynamically (Finch and Sumita, 2008; L¨u et al., 2007). 5 Conclusions and Future Work We proposed a flexible and efficient method for domain adaptation in machine translation. The idea is to decompose the word alignment process into model training and alignment inference, and view the latter as a sequential Bayesian update problem. The advantages of our approach are: 1. Its modularity enables the use of any model training algorithm for word alignment, as long as it outputs N-best lists or posteriors. 2. It gives consistent improvements over a multitude of datasets (2 tasks and 11 language"
2011.mtsummit-papers.11,N03-1017,0,0.00872408,"d to particular model formalisms (e.g. phrase vs. hierarchical rules) required for the extraction/scoring steps. All we need are the standard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively b"
2011.mtsummit-papers.11,2005.mtsummit-papers.11,0,0.0204779,"ple is counted equally. It may be beneficial to have a parameter if it can be tuned well without of overfitting, but we do not consider it here. 3 Experiments 3.1 Datasets and Setup We evaluate our proposed method under two tasks: The EMEA task involves the translation of medical texts from the European Medical Agency (Tiedemann, 2009). We test on ten language pairs–Danish (da), German (de), Greek (el), Spanish (es), Finnish (fi), French (fr), Italian (it), Dutch (nl), Portuguese (pt), and Swedish (sv)–all translating into English. The out-of-domain data are parliamentary texts from Europarl (Koehn, 2005). The NIST task involves translating newswire text using Chinese-to-English NIST OpenMT 2008 data. da in-domain 45.3 general 46.1 bayes 47.1* de 35.5 36.1 36.4* el 41.3 41.6 42.5* es 45.0 46.9 46.2 EMEA fi fr 33.6 46.8 34.0 47.8 34.6* 47.9 it 47.7 49.2 49.3* nl 45.6 46.1 46.2* pt 46.3 47.0 47.5* sv 45.3 45.2 45.9* NIST mt06 mt08 27.7 24.4 28.7 24.6 28.7 25.0* Table 2: Main Results: Test BLEU for EMEA (da,de,...,sv) and NIST (mt06,08): Best results are in bold-font. Statistical significant improvement over general-domain model is indicated by asterisk (*). Language Pair In-domain #sent train #w"
2011.mtsummit-papers.11,D09-1106,0,0.0176991,"m might acquire new phrases, which reduces out-of-vocabulary rate and confounds the analysis of alignment inference results. Further, from preliminary experiments, we found that adding out-of-domain bitext to all four steps actually degrade results sometimes, due to increased ambiguity of additional translation options on the target side. For all systems, we use the Moses decoder, adapted SRILM 3gram (EMEA) and 4gram (NIST), MERT for weight optimization, and GIZA++ (Model4) as the underlying word alignment training tool. Phrase tables are extracted from alignment matrices using the method of (Liu et al., 2009). 3.2 Main Results Table 2 summarizes all our main results. We see that bayes gives robust improvements in testset BLEU. For example, for Danish-to-English translation, using in-domain data by itself achieves 45.3 BLEU (in-domain). This can be improved to 46.1 BLEU by concating out-of-domain data (general). The proposed method, however, further improves the result to 47.1 BLEU (bayes). For the NIST dataset, we see that bayes improves upon general and indomain for the MT08 testset, and ties with general for the MT06 testset. On average, bayes improves over in-domain model by 1.1 BLEU points. Fu"
2011.mtsummit-papers.11,D07-1036,0,0.0487968,"Missing"
2011.mtsummit-papers.11,D09-1040,0,0.0212628,"s it as a hidden parameter in a mixture model. These methods are similar to ours in that the motivation is to improve alignments, but differs in that the focus is on training (not inference). 2) Alignment inference: To the best of our knowledge, there is no previous work in this area. The model training of Step 1 is related but not the same. Instead, alignment combination works (Deng and Zhou, 2009) may give some insights. 3) Phrase extraction: Out-of-domain text may contain unseen phrases useful for in-domain data. One approach attempts to discover paraphrases from large monolingual corpora (Marton et al., 2009; Snover et al., 2008). Another is a self-training approach that translates source in-domain text and re-trains the translation model on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to"
2011.mtsummit-papers.11,D09-1074,0,0.0179112,"on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to score adaptation involve combining in-domain and out-of-domain scores at either the sentence or the phrase level (Shah et al., 2010; Matsoukas et al., 2009; Foster et al., 2010). A promising aspect about the latter two papers, in particular, is that they are able to incorporate supervised information (likelihood or expected TER on the dev set) for score adaptation. We emphasize that our contribution is orthogonal to previous work: alignment inference adaptation can be combined with any adaptation method in other parts of the pipeline. It remains to be seen whether the improvements are additive: while our results are positive in both alignment and final translation performance, some work have shown weak correlation between the two (Ayan and Dorr,"
2011.mtsummit-papers.11,P08-1023,0,0.0144565,"ndard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively balance the uncertainty in alignment from both in-domain and general-domain bitexts. The contribution of this paper is two-fold: • We i"
2011.mtsummit-papers.11,J04-4002,0,0.0486609,"l formalisms (e.g. phrase vs. hierarchical rules) required for the extraction/scoring steps. All we need are the standard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively balance the uncertain"
2011.mtsummit-papers.11,P05-1034,0,0.039829,"on/scoring steps. All we need are the standard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively balance the uncertainty in alignment from both in-domain and general-domain bitexts. The contrib"
2011.mtsummit-papers.11,W10-1759,0,0.0106112,"e translation model on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to score adaptation involve combining in-domain and out-of-domain scores at either the sentence or the phrase level (Shah et al., 2010; Matsoukas et al., 2009; Foster et al., 2010). A promising aspect about the latter two papers, in particular, is that they are able to incorporate supervised information (likelihood or expected TER on the dev set) for score adaptation. We emphasize that our contribution is orthogonal to previous work: alignment inference adaptation can be combined with any adaptation method in other parts of the pipeline. It remains to be seen whether the improvements are additive: while our results are positive in both alignment and final translation performance, some work have shown weak correlation between"
2011.mtsummit-papers.11,D08-1090,0,0.0212051,"meter in a mixture model. These methods are similar to ours in that the motivation is to improve alignments, but differs in that the focus is on training (not inference). 2) Alignment inference: To the best of our knowledge, there is no previous work in this area. The model training of Step 1 is related but not the same. Instead, alignment combination works (Deng and Zhou, 2009) may give some insights. 3) Phrase extraction: Out-of-domain text may contain unseen phrases useful for in-domain data. One approach attempts to discover paraphrases from large monolingual corpora (Marton et al., 2009; Snover et al., 2008). Another is a self-training approach that translates source in-domain text and re-trains the translation model on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to score adaptation invol"
2011.mtsummit-papers.11,P07-1004,0,0.0168471,"ent inference: To the best of our knowledge, there is no previous work in this area. The model training of Step 1 is related but not the same. Instead, alignment combination works (Deng and Zhou, 2009) may give some insights. 3) Phrase extraction: Out-of-domain text may contain unseen phrases useful for in-domain data. One approach attempts to discover paraphrases from large monolingual corpora (Marton et al., 2009; Snover et al., 2008). Another is a self-training approach that translates source in-domain text and re-trains the translation model on synthetic data (Bertoldi and Federico, 2009; Ueffing et al., 2007). 4) Scoring: Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model. In fact, one could argue that all the previous steps are simply pre-processing to narrow down the size of ruleset/phrasetable; if scores are well-tuned, good translations can be achieved even if the ruleset is infinite in size. Recent approaches to score adaptation involve combining in-domain and out-of-domain scores at either the sentence or the phrase level (Shah et al., 2010; Matsoukas et al., 2009; Foster et al., 2010). A promising aspect about"
2011.mtsummit-papers.11,P05-1058,0,0.0309943,"3, except we use scores from the general model M gen rather than M in ; βij is calculated analogously to Eq. 4:  βij = A ∈N 2.4 lgen (A )δ(Aij = 0)/Z (8) I J gen (e1 ,f1 ) Summary and Caveat The pseudocode for the overall algorithm is presented in Algorithm 1. Basically, the alignment matrix posteriors are computed for each sentence pair by combining statistics from in-domain and generaldomain models. It is worth noting two caveats: • Our Bayesian view is that there is a prior alignment matrix, which is updated by in-domain model statistics. This differs from previous work in Step 1, e.g. (Wu et al., 2005), which adopts a prior for alignment model parameters. The distinction between adapting inference results and model parameters is an important one, and this is what gives us a flexible generalpurpose method. • Eq. 6 does not contain a tuning parameter between likelihood aij and prior αij . This arises from the sequential Bayesian update perspective, where each additional sample is counted equally. It may be beneficial to have a parameter if it can be tuned well without of overfitting, but we do not consider it here. 3 Experiments 3.1 Datasets and Setup We evaluate our proposed method under two"
2011.mtsummit-papers.11,J97-3002,0,0.110319,") required for the extraction/scoring steps. All we need are the standard toolsets for the training pipeline, and a pre-existing word alignment model that can generate n-best lists. Therefore, adaptation in Step 2 has wide applicability. Although Step 1 and Step 2 are sometimes considered as a single process, we will show that the decomposition into two steps is quite beneficial and opens up new possibilities. Virtually all SMT systems can be interpreted as consisting of the aforementioned 4-stage pipeline (e.g. phrase-based (Koehn et al., 2003; Och and Ney, 2004), hierarchical (Chiang, 2007; Wu, 1997), and tree-based (Quirk et al., 2005; Galley et al., 2004; Mi et al., 2008)). Our approach can be briefly summarized as follows: First, we train a word alignment model on a large general-domain dataset, then predict the alignment points for an in-domain bitext. The n-best list of predictions are used to compute a Bayesian prior indicating the a priori belief of any two words being aligned. Then, alignment inference of in-domain bitext is viewed as a sequential Bayesian update on weighted alignment matrices. The idea is to effectively balance the uncertainty in alignment from both in-domain and"
2011.mtsummit-papers.11,zhang-etal-2004-interpreting,0,0.0273166,"LEU. For example, for Danish-to-English translation, using in-domain data by itself achieves 45.3 BLEU (in-domain). This can be improved to 46.1 BLEU by concating out-of-domain data (general). The proposed method, however, further improves the result to 47.1 BLEU (bayes). For the NIST dataset, we see that bayes improves upon general and indomain for the MT08 testset, and ties with general for the MT06 testset. On average, bayes improves over in-domain model by 1.1 BLEU points. Further, in 9 of 12 cases, bayes also outperforms general-domain model by statistically significant margins, p <0.05 (Zhang et al., 2004). We thus conclude that the proposed method is robust under adaptation scenarios. 3.3 Analyses of Alignments We are also interested in checking if BLEU improvements correlate with quantifiable alignment improvements. This evaluation is possible since the NIST dataset contains some manual alignment annotations (LDC2006E93). We identified 892 sentence-pairs in our in-domain bitext that have manual alignments. Note that this supervised information is never used in any part of our method. Figure 1 shows alignment precision/recall. The curve is computed by thresholding the estimated weighted aligme"
2011.mtsummit-papers.34,2008.iwslt-papers.1,0,0.0222347,"presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation system, which means generation of the virtual data can be performed on any kind of translation systems including rule based, statistical based or even human translation. The approach introduced in (Leusch et al., 2010) can combine the translation output of a test set produced by any pivot MTs per different languages, however the individual systems are not improved and novel training data is not exploited. Bertoldi et al. (2008) evaluated several methods of pivot languages but did apply the global corpus ﬁltering i.e. compatibility measure to control the quality of data. Our purpose is not only to improve the translation quality but also to provide useful linguistic resources for other NLP tasks. 5 Conclusion and Future Work Thousands of human languages are recognized in the world, and building up millions of translation systems between these language pairs suffers greatly on the scarce resource, such as parallel data. We introduced the idea of compatibility, where all languages can be mapped to the same semantic mea"
2011.mtsummit-papers.34,J93-2003,0,0.0230862,"f each sentence pair and choose a certain percentage of the best scored sentences for training. In order to include information from various resources, the quality of a sentence pair is measured using a log-linear model combining different sub-models. Let (f1J , eI1 ) be a bilingual sentence, the evaluation is performed using the following Equation: H(f1J , eI1 ) = M  λm hm (f1J , eI1 ) m=1 409 hm (f1J , eI1 ) is a score evaluated on this sentence pair using sub-model m. Each model m is assigned with a feature weight λm . For simplicity, we only include the negative logarithm of IBM model 1 (Brown et al., 1993) in normal and inverse direction as submodels. We combine the IBM model 1 in both directions in the log-linear model with an equal weight for each direction. We use the training software GIZA++ (Och and Ney, 2003) to obtain the lexicon probability. 3 Experimental Results 3.1 MT Setup We apply Moses (Koehn et al., 2007) as our baseline translation system and train standard alignment models in both directions with GIZA++ (Och and Ney, 2003) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993) which brings us the optimal translation performance and e"
2011.mtsummit-papers.34,2002.tmi-tutorials.2,0,0.0607427,"n the idea of compatibility. Generally speaking, the quality of compatible predictions provided by multiple systems is more reliable. For simple classiﬁcation problems, it is reasonable to take a prediction as good which the multiple systems agree on. This idea is widely used in ensemble learning and semi-supervised learning. Take Bootstrap aggregating, a meta-algorithm for ensemble learning as an example, multiple models are separately trained on randomly generated sub-samples, and then vote to achieve ﬁnal predictions. Another example closely related to our method is co-training such as in (Callison-Burch, 2002). One way to select automatic predictions for re-training in co-training is to choose the agreed ones. Different from simple classiﬁcation problems, even complex structured prediction problems such as parsing, the output of MT is in human languages, which may be the most complicated way to represent the meaning of another human language. It is too strict to ask multiple systems to provide exactly the same translated sentence for an input. We extend the agreement idea to the compatibility idea. Informally, two sentences are called compatible if they express the same meaning to some extent. We c"
2011.mtsummit-papers.34,P07-1092,0,0.0141798,"language. The cognate string edit distance was applied instead of a general MT system, so that the vocabulary learning is limited to mostly European languages. For bridge or pivot languages in MT, Kumar et al. (2007) described a method to improve word alignment quality using multiple bridge languages. In (Wu and Wang, 2007) and (Habash and Hu, 2009) phrase translation tables are improved using the phrase tables obtained from pivot languages in different ways, and in (Eisele et al., 2008) a hybrid method combining RBMT and SMT systems is introduced to ﬁll up the data gap for pivot translation. Cohn and Lapata (2007) presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation system, which means generation of the virtual data can be performed on any kind of translation systems including rule based, statistical based or even human translation. The approach introduced in (Leusch et al., 2010) can combine the translation output of a test set produced by any pivot MTs per different languages, however the individual systems are not improved and novel training data is not exploited."
2011.mtsummit-papers.34,P08-1010,0,0.0304425,"Missing"
2011.mtsummit-papers.34,2008.eamt-1.6,0,0.0108565,"d Yarowsky (2001) presented a method to induce translation lexicon based on transduction 412 models of cognate pairs via bridge language. The cognate string edit distance was applied instead of a general MT system, so that the vocabulary learning is limited to mostly European languages. For bridge or pivot languages in MT, Kumar et al. (2007) described a method to improve word alignment quality using multiple bridge languages. In (Wu and Wang, 2007) and (Habash and Hu, 2009) phrase translation tables are improved using the phrase tables obtained from pivot languages in different ways, and in (Eisele et al., 2008) a hybrid method combining RBMT and SMT systems is introduced to ﬁll up the data gap for pivot translation. Cohn and Lapata (2007) presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation system, which means generation of the virtual data can be performed on any kind of translation systems including rule based, statistical based or even human translation. The approach introduced in (Leusch et al., 2010) can combine the translation output of a test set produced by"
2011.mtsummit-papers.34,W09-0431,0,0.013434,"e, while their learning and application are constrained in a bilingual way without introducing any information from a third language. Mann and Yarowsky (2001) presented a method to induce translation lexicon based on transduction 412 models of cognate pairs via bridge language. The cognate string edit distance was applied instead of a general MT system, so that the vocabulary learning is limited to mostly European languages. For bridge or pivot languages in MT, Kumar et al. (2007) described a method to improve word alignment quality using multiple bridge languages. In (Wu and Wang, 2007) and (Habash and Hu, 2009) phrase translation tables are improved using the phrase tables obtained from pivot languages in different ways, and in (Eisele et al., 2008) a hybrid method combining RBMT and SMT systems is introduced to ﬁll up the data gap for pivot translation. Cohn and Lapata (2007) presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation system, which means generation of the virtual data can be performed on any kind of translation systems including rule based, statistical b"
2011.mtsummit-papers.34,P07-2045,0,0.00524468,"d using the following Equation: H(f1J , eI1 ) = M  λm hm (f1J , eI1 ) m=1 409 hm (f1J , eI1 ) is a score evaluated on this sentence pair using sub-model m. Each model m is assigned with a feature weight λm . For simplicity, we only include the negative logarithm of IBM model 1 (Brown et al., 1993) in normal and inverse direction as submodels. We combine the IBM model 1 in both directions in the log-linear model with an equal weight for each direction. We use the training software GIZA++ (Och and Ney, 2003) to obtain the lexicon probability. 3 Experimental Results 3.1 MT Setup We apply Moses (Koehn et al., 2007) as our baseline translation system and train standard alignment models in both directions with GIZA++ (Och and Ney, 2003) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993) which brings us the optimal translation performance and efﬁciency based on empirical evaluations. Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The language model is a statistical 5-gram model with modiﬁed Kneser-Ney smoothing estimated using SRI-LM toolkit (Stolcke, 2002). E"
2011.mtsummit-papers.34,2005.mtsummit-papers.11,0,0.0225646,"ll scarce resourced language pairs. The generated virtual parallel corpus can not only be applied into MT but also other NLP tasks. 2 2.1 Generating Virtual Parallel Data Background and Motivation There are only a few parallel corpora publicly available for some languages we work on. The JRC-Acquis(JRC) is a huge collection of European Union legislative documents translated into more than twenty ofﬁcial European languages (Steinberger et al., 2006). The European Parliament Proceedings Parallel Corpus (Europarl corpus) was extracted from the proceedings of the European Parliament (1996-today) (Koehn, 2005). News Commentary(NC) (SMT, 2011) and SETimes (SETIMES, 2011) are corpora collected from the news domains. In this paper, we are concerned with generating high-quality, virtual parallel data for machine translation. To do this, we exploit multiple parallel corpora in different language pairs. In particular, we generate parallel corpora for scarce resourced languages, taking Romanian to German as a case study for simplicity. We can also take German to Romanian or other language directions. In order to ﬁnd out the gap between the translation quality on better studied language pairs and that on l"
2011.mtsummit-papers.34,D07-1005,0,0.0133387,"Section 1 and Section 2.3. Uefﬁng et al. (2009) explored model adaptation methods to use the monolingual data from the source language, while their learning and application are constrained in a bilingual way without introducing any information from a third language. Mann and Yarowsky (2001) presented a method to induce translation lexicon based on transduction 412 models of cognate pairs via bridge language. The cognate string edit distance was applied instead of a general MT system, so that the vocabulary learning is limited to mostly European languages. For bridge or pivot languages in MT, Kumar et al. (2007) described a method to improve word alignment quality using multiple bridge languages. In (Wu and Wang, 2007) and (Habash and Hu, 2009) phrase translation tables are improved using the phrase tables obtained from pivot languages in different ways, and in (Eisele et al., 2008) a hybrid method combining RBMT and SMT systems is introduced to ﬁll up the data gap for pivot translation. Cohn and Lapata (2007) presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation sys"
2011.mtsummit-papers.34,2010.iwslt-papers.12,0,0.0117409,"les obtained from pivot languages in different ways, and in (Eisele et al., 2008) a hybrid method combining RBMT and SMT systems is introduced to ﬁll up the data gap for pivot translation. Cohn and Lapata (2007) presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation system, which means generation of the virtual data can be performed on any kind of translation systems including rule based, statistical based or even human translation. The approach introduced in (Leusch et al., 2010) can combine the translation output of a test set produced by any pivot MTs per different languages, however the individual systems are not improved and novel training data is not exploited. Bertoldi et al. (2008) evaluated several methods of pivot languages but did apply the global corpus ﬁltering i.e. compatibility measure to control the quality of data. Our purpose is not only to improve the translation quality but also to provide useful linguistic resources for other NLP tasks. 5 Conclusion and Future Work Thousands of human languages are recognized in the world, and building up millions o"
2011.mtsummit-papers.34,N01-1020,0,0.0187021,"rget languages. Callison-Burch (2002) presented a co-training method for SMT, the agreement of multiple translation systems is explored to ﬁnd the best translation for re-training. We applied compatibility instead of agreement based approach, detailed description on the difference between compatibility and agreement is referred to Section 1 and Section 2.3. Uefﬁng et al. (2009) explored model adaptation methods to use the monolingual data from the source language, while their learning and application are constrained in a bilingual way without introducing any information from a third language. Mann and Yarowsky (2001) presented a method to induce translation lexicon based on transduction 412 models of cognate pairs via bridge language. The cognate string edit distance was applied instead of a general MT system, so that the vocabulary learning is limited to mostly European languages. For bridge or pivot languages in MT, Kumar et al. (2007) described a method to improve word alignment quality using multiple bridge languages. In (Wu and Wang, 2007) and (Habash and Hu, 2009) phrase translation tables are improved using the phrase tables obtained from pivot languages in different ways, and in (Eisele et al., 20"
2011.mtsummit-papers.34,N04-1034,0,0.0782549,"Missing"
2011.mtsummit-papers.34,J03-1002,0,0.00497387,"model combining different sub-models. Let (f1J , eI1 ) be a bilingual sentence, the evaluation is performed using the following Equation: H(f1J , eI1 ) = M  λm hm (f1J , eI1 ) m=1 409 hm (f1J , eI1 ) is a score evaluated on this sentence pair using sub-model m. Each model m is assigned with a feature weight λm . For simplicity, we only include the negative logarithm of IBM model 1 (Brown et al., 1993) in normal and inverse direction as submodels. We combine the IBM model 1 in both directions in the log-linear model with an equal weight for each direction. We use the training software GIZA++ (Och and Ney, 2003) to obtain the lexicon probability. 3 Experimental Results 3.1 MT Setup We apply Moses (Koehn et al., 2007) as our baseline translation system and train standard alignment models in both directions with GIZA++ (Och and Ney, 2003) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993) which brings us the optimal translation performance and efﬁciency based on empirical evaluations. Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The language model is a s"
2011.mtsummit-papers.34,P02-1040,0,0.0841189,"Missing"
2011.mtsummit-papers.34,N10-1063,0,0.039881,"Missing"
2011.mtsummit-papers.34,W11-2100,0,0.0454475,"The generated virtual parallel corpus can not only be applied into MT but also other NLP tasks. 2 2.1 Generating Virtual Parallel Data Background and Motivation There are only a few parallel corpora publicly available for some languages we work on. The JRC-Acquis(JRC) is a huge collection of European Union legislative documents translated into more than twenty ofﬁcial European languages (Steinberger et al., 2006). The European Parliament Proceedings Parallel Corpus (Europarl corpus) was extracted from the proceedings of the European Parliament (1996-today) (Koehn, 2005). News Commentary(NC) (SMT, 2011) and SETimes (SETIMES, 2011) are corpora collected from the news domains. In this paper, we are concerned with generating high-quality, virtual parallel data for machine translation. To do this, we exploit multiple parallel corpora in different language pairs. In particular, we generate parallel corpora for scarce resourced languages, taking Romanian to German as a case study for simplicity. We can also take German to Romanian or other language directions. In order to ﬁnd out the gap between the translation quality on better studied language pairs and that on less studied language pairs, we co"
2011.mtsummit-papers.34,steinberger-etal-2006-jrc,0,0.0697896,"Missing"
2011.mtsummit-papers.34,C96-2141,0,0.280846,"ature weight λm . For simplicity, we only include the negative logarithm of IBM model 1 (Brown et al., 1993) in normal and inverse direction as submodels. We combine the IBM model 1 in both directions in the log-linear model with an equal weight for each direction. We use the training software GIZA++ (Och and Ney, 2003) to obtain the lexicon probability. 3 Experimental Results 3.1 MT Setup We apply Moses (Koehn et al., 2007) as our baseline translation system and train standard alignment models in both directions with GIZA++ (Och and Ney, 2003) using models of IBM-1 (Brown et al., 1993), HMM (Vogel et al., 1996) and IBM-4 (Brown et al., 1993) which brings us the optimal translation performance and efﬁciency based on empirical evaluations. Features in the log-linear model include translation models in two directions, a language model, a distortion model and a sentence length penalty. The language model is a statistical 5-gram model with modiﬁed Kneser-Ney smoothing estimated using SRI-LM toolkit (Stolcke, 2002). Each language model is trained with the target side of the parallel data. We do not apply any zmert tuning in EMS because it does not improve our translation results on the evaluation set. Imp"
2011.mtsummit-papers.34,P07-1108,0,0.0135407,"from the source language, while their learning and application are constrained in a bilingual way without introducing any information from a third language. Mann and Yarowsky (2001) presented a method to induce translation lexicon based on transduction 412 models of cognate pairs via bridge language. The cognate string edit distance was applied instead of a general MT system, so that the vocabulary learning is limited to mostly European languages. For bridge or pivot languages in MT, Kumar et al. (2007) described a method to improve word alignment quality using multiple bridge languages. In (Wu and Wang, 2007) and (Habash and Hu, 2009) phrase translation tables are improved using the phrase tables obtained from pivot languages in different ways, and in (Eisele et al., 2008) a hybrid method combining RBMT and SMT systems is introduced to ﬁll up the data gap for pivot translation. Cohn and Lapata (2007) presented a method to obtain more reliable translation estimates from small data sets using multi-parallel data. Different from the previous approaches, we work on a black-boxed translation system, which means generation of the virtual data can be performed on any kind of translation systems including"
2011.mtsummit-papers.36,2009.mtsummit-posters.1,0,0.0193042,"rules on syntactic parse trees. There are a lot of pre-ordering studies, but this is the ﬁrst work of post-ordering to our knowledge. The problem can be regarded as a variant of string-to-tree SMT, from Japanese sentences to English trees. We divide the string-to-tree problem into two simpliﬁed problems, which can be solved efﬁciently with less computational cost than a string-to-tree SMT. Post-ordering is also highly related to post-editing technologies, which aim to correct errors in a rulebased translation (Simard et al., 2007; Dugast et al., 2007; Ehara, 2007) or a different type of SMT (Aikawa and Ruopp, 2009). There is a major difference of the post-ordering from such an post-editing framework; in the post-editing framework, the preceding translation process is a complete source-totarget translation, and the post-editing itself works as an additional process to ﬁx errors. In contrast, the post-ordering framework divides the whole translation process into two sub-processes focusing on translation and reordering. It has an advantage that the sub-processes are simpliﬁed and easy to solve compared to a complete translation process in the post-editing. 3 Proposed method This section presents the propos"
2011.mtsummit-papers.36,J93-2003,0,0.0259478,"ainder of this paper is organized as follows. Section 2 brieﬂy reviews related studies on the reordering problem and another related technology called post-editing. Section 3 presents the proposed method in detail taking Japanese-to-English translation as a test case. Section 4 reports our experiments and discusses the results. Section 5 concludes this paper with our prospects for future work. 2 Related Work Reordering is a both theoretically and practically challenging problem in SMT. In the early period of SMT studies, reordering is modeled by distancebased constraints in translation model (Brown et al., 1993; Koehn et al., 2003). This reordering model is easy to compute and also works well in relatively similar language pair like French-to-English. The distance-based reordering constraint is not reasonable in some language pair such as English-toJapanese, because they have very different word ordering and appropriate reordering distances of words and phrases highly depend on their syntactic roles and contexts. Tillmann (2004) proposed a lexicalized reordering model that models orientation of phrases by monotone, swap, and discontinuous. This can directly model reordering of adjacent phrases but m"
2011.mtsummit-papers.36,J07-2003,0,0.106973,"Graehl and Knight, 2004) is a theoretically good solution. Reordering in syntax-based SMT is modeled in a similar manner as reordering of tree nodes in the same level (siblings), regardless of their reordering distance. Although this approach have some shortcomings with parse errors and its too strong constraints, syntactic information is expected to be effective in some language pairs. Another syntactic approach, originally proposed by Wu (1997), uses formally-syntactic structure between source and target language sentences. This framework was extended as the hierarchical phrase-based SMT by Chiang (2007) and is convincing alternative in recent SMT research. The reordering models mentioned above are applied in SMT decoding and solved simultaneously with phrase translation. Xiong et al. extended the hierarchical SMT by lexicalized reordering (Xiong et al., 2006; Xiong et al., 2008). However, the integrated search requires a large computational cost both in time and space. To keep the search tractable, we constrain reordering search by its reordering distance, as so-called distortion limit (or maximum span in tree-based decoder). It effectively reduces the computational cost but it also give up"
2011.mtsummit-papers.36,P05-1066,0,0.719105,"Missing"
2011.mtsummit-papers.36,W06-1609,0,0.0517088,"Missing"
2011.mtsummit-papers.36,W07-0732,0,0.0604907,"k for Japanese-to-English translation using English reordering rules on syntactic parse trees. There are a lot of pre-ordering studies, but this is the ﬁrst work of post-ordering to our knowledge. The problem can be regarded as a variant of string-to-tree SMT, from Japanese sentences to English trees. We divide the string-to-tree problem into two simpliﬁed problems, which can be solved efﬁciently with less computational cost than a string-to-tree SMT. Post-ordering is also highly related to post-editing technologies, which aim to correct errors in a rulebased translation (Simard et al., 2007; Dugast et al., 2007; Ehara, 2007) or a different type of SMT (Aikawa and Ruopp, 2009). There is a major difference of the post-ordering from such an post-editing framework; in the post-editing framework, the preceding translation process is a complete source-totarget translation, and the post-editing itself works as an additional process to ﬁx errors. In contrast, the post-ordering framework divides the whole translation process into two sub-processes focusing on translation and reordering. It has an advantage that the sub-processes are simpliﬁed and easy to solve compared to a complete translation process in th"
2011.mtsummit-papers.36,N10-1128,0,0.0291627,"ore phrase translation options efﬁciently. The pre-ordering is based on syntactic parse and can be regarded as a sub-problem of tree-to-string translation. On the other hand, there are several studies on pre-ordering without syntactic parsing. Costa-juss`a and Fonollosa (2006) tackled the pre-ordering problem as SMT, using reordering tables derived from phrase tables. Tromble and Eisner (2009) applied linear ordering models to preordering. Their techniques can be applied to any language pairs but rely on noisy automatic word alignment results as the reference of the reordering model training. Dyer and Resnik (2010) advanced such a pre-ordering-based translation to a novel uniﬁed approach of long-distance pre-ordering and decoding, with discriminative context-free reordering and ﬁnite-state phrase translation. In this paper, we reverse the pre-ordering SMT framework for Japanese-to-English translation using English reordering rules on syntactic parse trees. There are a lot of pre-ordering studies, but this is the ﬁrst work of post-ordering to our knowledge. The problem can be regarded as a variant of string-to-tree SMT, from Japanese sentences to English trees. We divide the string-to-tree problem into t"
2011.mtsummit-papers.36,2007.mtsummit-wpt.4,0,0.0178607,"lish translation using English reordering rules on syntactic parse trees. There are a lot of pre-ordering studies, but this is the ﬁrst work of post-ordering to our knowledge. The problem can be regarded as a variant of string-to-tree SMT, from Japanese sentences to English trees. We divide the string-to-tree problem into two simpliﬁed problems, which can be solved efﬁciently with less computational cost than a string-to-tree SMT. Post-ordering is also highly related to post-editing technologies, which aim to correct errors in a rulebased translation (Simard et al., 2007; Dugast et al., 2007; Ehara, 2007) or a different type of SMT (Aikawa and Ruopp, 2009). There is a major difference of the post-ordering from such an post-editing framework; in the post-editing framework, the preceding translation process is a complete source-totarget translation, and the post-editing itself works as an additional process to ﬁx errors. In contrast, the post-ordering framework divides the whole translation process into two sub-processes focusing on translation and reordering. It has an advantage that the sub-processes are simpliﬁed and easy to solve compared to a complete translation process in the post-editing"
2011.mtsummit-papers.36,N04-1035,0,0.0641016,"rdering constraint is not reasonable in some language pair such as English-toJapanese, because they have very different word ordering and appropriate reordering distances of words and phrases highly depend on their syntactic roles and contexts. Tillmann (2004) proposed a lexicalized reordering model that models orientation of phrases by monotone, swap, and discontinuous. This can directly model reordering of adjacent phrases but may not work for long distance reordering, because discontinuous supplies few constraints for reordering. On the other hand, syntaxbased SMT (Yamada and Knight, 2001; Galley et al., 2004; Graehl and Knight, 2004) is a theoretically good solution. Reordering in syntax-based SMT is modeled in a similar manner as reordering of tree nodes in the same level (siblings), regardless of their reordering distance. Although this approach have some shortcomings with parse errors and its too strong constraints, syntactic information is expected to be effective in some language pairs. Another syntactic approach, originally proposed by Wu (1997), uses formally-syntactic structure between source and target language sentences. This framework was extended as the hierarchical phrase-based SMT b"
2011.mtsummit-papers.36,C10-1043,0,0.193651,"ed English. The experiments on Japanese-to-English patent translation show the signiﬁcant advantage of postordering over baseline phrase-based, hierarchical phrase-based, and syntax-based translation methods by 1.56, 0.76, and 2.77 points in BLEU, respectively. 1 A recently attractive approach for this challenge is called pre-ordering, which reorders source language sentences into the target language word order prior to SMT decoding (Xia and McCord, 2004; Collins et al., 2005; Costa-juss`a and Fonollosa, 2006; Li et al., 2007; Wang et al., 2007; Tromble and Eisner, 2009; Isozaki et al., 2010; Genzel, 2010). The pre-ordering approach is able to reorder source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering. Recent research efforts developed novel technologies such as phrase-based SMT with"
2011.mtsummit-papers.36,N04-1014,0,0.0802119,"not reasonable in some language pair such as English-toJapanese, because they have very different word ordering and appropriate reordering distances of words and phrases highly depend on their syntactic roles and contexts. Tillmann (2004) proposed a lexicalized reordering model that models orientation of phrases by monotone, swap, and discontinuous. This can directly model reordering of adjacent phrases but may not work for long distance reordering, because discontinuous supplies few constraints for reordering. On the other hand, syntaxbased SMT (Yamada and Knight, 2001; Galley et al., 2004; Graehl and Knight, 2004) is a theoretically good solution. Reordering in syntax-based SMT is modeled in a similar manner as reordering of tree nodes in the same level (siblings), regardless of their reordering distance. Although this approach have some shortcomings with parse errors and its too strong constraints, syntactic information is expected to be effective in some language pairs. Another syntactic approach, originally proposed by Wu (1997), uses formally-syntactic structure between source and target language sentences. This framework was extended as the hierarchical phrase-based SMT by Chiang (2007) and is con"
2011.mtsummit-papers.36,W10-1736,1,0.779822,"d into correctly-ordered English. The experiments on Japanese-to-English patent translation show the signiﬁcant advantage of postordering over baseline phrase-based, hierarchical phrase-based, and syntax-based translation methods by 1.56, 0.76, and 2.77 points in BLEU, respectively. 1 A recently attractive approach for this challenge is called pre-ordering, which reorders source language sentences into the target language word order prior to SMT decoding (Xia and McCord, 2004; Collins et al., 2005; Costa-juss`a and Fonollosa, 2006; Li et al., 2007; Wang et al., 2007; Tromble and Eisner, 2009; Isozaki et al., 2010; Genzel, 2010). The pre-ordering approach is able to reorder source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering. Recent research efforts developed novel technologies such as phrase"
2011.mtsummit-papers.36,N03-1017,0,0.171751,"is able to reorder source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering. Recent research efforts developed novel technologies such as phrase-based SMT with phrase reordering models (Koehn et al., 2003; Tillmann, 2004), and tree-based (or syntax-based) SMT (Yamada and Knight, 2001; Galley et al., 316 In contrast, what can we do in the translation in the opposite direction? This is a non-trivial problem because the pre-ordering techniques are usually language dependent. Even if we have a good preordering technique in A-to-B translation such as reordering rules for syntactic parse trees, it cannot be used directly in B-to-A translation. Developing Bto-A pre-ordering is a different problem from A-toB, which may require a syntactic parser and/or linguistic insights. For example in Japanese-to-E"
2011.mtsummit-papers.36,P07-1091,0,0.280387,"rst translated into foreign-ordered English, and then reordered into correctly-ordered English. The experiments on Japanese-to-English patent translation show the signiﬁcant advantage of postordering over baseline phrase-based, hierarchical phrase-based, and syntax-based translation methods by 1.56, 0.76, and 2.77 points in BLEU, respectively. 1 A recently attractive approach for this challenge is called pre-ordering, which reorders source language sentences into the target language word order prior to SMT decoding (Xia and McCord, 2004; Collins et al., 2005; Costa-juss`a and Fonollosa, 2006; Li et al., 2007; Wang et al., 2007; Tromble and Eisner, 2009; Isozaki et al., 2010; Genzel, 2010). The pre-ordering approach is able to reorder source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering."
2011.mtsummit-papers.36,J08-1002,0,0.0320343,"node. The determiners “the” and “a” are eliminated by the rules, and a pseudo-particle “ va0” is inserted after the subject. 4 • Japanese tokenizer: Mecab3 (with ipadic-2.7.0) Experiment We investigated the advantage of our post-ordering method by the following Japanese-to-English translation experiment with the post-ordering and baseline SMTs. 4.1 Setup We used NTCIR-9 PatentMT (NTCIR-9, 2011) English and Japanese dataset for this experiment. Some statistics of this dataset are shown in Table 1. We preprocessed the dataset by the following softwares: • English syntactic (HPSG) parser: Enju2 (Miyao and Tsujii, 2008) • English tokenizer: stepp (included in Enju package) 2 http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html 320 Word alignment was automatically estimated using MGIZA++4 using bitexts of 64 or less words in the training set to avoid a problematic underﬂow. Language models are word 5-gram models of English and HFE, trained with SRILM5 . 4.2 Compared methods We compared the proposed post-ordering with three baseline SMTs: a standard phrase-based SMT (PBMT) with lexicalized reordering, a hierarchical phrase-based SMT (HPBMT), and a string-to-tree syntax-based SMT (SBMT), included in Moses6 . 3"
2011.mtsummit-papers.36,P03-1021,0,0.0766118,"DQGDVHFRQGOHQV Figure 5: An example of the post-ordering translation. English parse trees used in SBMT were identical to the ones used for generating HFE sentences in the post-ordering. The post-ordering used two Moses phrase-based decoders, one for Japanese-to-HFE and the other for HFE-to-English. The models for these decoders were trained in the standard manner with Moses, grow-diag-final-and heuristics for symmetric word alignment, msd-bidirectional-fe lexicalized reordering (in PBMT and the postordering). The parameter values are optimized by minimum error rate training (MERT) (Och, 2003) with mert-moses.pl. One difference among conﬁgurations of the decoders was distortion limit. The Japanese-to-HFE decoder did not require long distance reordering, so we compared two conditions with the values of 0 (monotone) and 6. The HFE-to-English and PBMT decoders had to drastically reorder phrases so we used the values of 12 and 20. In the HPBMT and SBMT decoders, we used 15 for its max-chart-span option. The other 321 Table 2 shows the results in BLEU (Papineni et al., 2002) in case-insensitive evaluation and average decoding times7 (on a Xeon 7460 2.66GHz computer) with the compared me"
2011.mtsummit-papers.36,P02-1040,0,0.102487,"icalized reordering (in PBMT and the postordering). The parameter values are optimized by minimum error rate training (MERT) (Och, 2003) with mert-moses.pl. One difference among conﬁgurations of the decoders was distortion limit. The Japanese-to-HFE decoder did not require long distance reordering, so we compared two conditions with the values of 0 (monotone) and 6. The HFE-to-English and PBMT decoders had to drastically reorder phrases so we used the values of 12 and 20. In the HPBMT and SBMT decoders, we used 15 for its max-chart-span option. The other 321 Table 2 shows the results in BLEU (Papineni et al., 2002) in case-insensitive evaluation and average decoding times7 (on a Xeon 7460 2.66GHz computer) with the compared methods. The proposed post-ordering translation (with monotone Japaneseto-HFE translation) achieved 0.2963 in BLEU, better than the best HPBMT baseline (0.2887) by 0.76 points and the standard PBMT baseline (0.2806) by 1.57 points. The differences were statistically signiﬁcant according to the bootstrap sampling test (p &lt; 0.05 with HPBMT and p &lt; 0.01 with PBMT, 1,000 samples) (Zhang et al., 2004), and it was consistent among all post-ordering conditions. In the Japanese-to-HFE transl"
2011.mtsummit-papers.36,N07-1064,0,0.0204361,"ordering SMT framework for Japanese-to-English translation using English reordering rules on syntactic parse trees. There are a lot of pre-ordering studies, but this is the ﬁrst work of post-ordering to our knowledge. The problem can be regarded as a variant of string-to-tree SMT, from Japanese sentences to English trees. We divide the string-to-tree problem into two simpliﬁed problems, which can be solved efﬁciently with less computational cost than a string-to-tree SMT. Post-ordering is also highly related to post-editing technologies, which aim to correct errors in a rulebased translation (Simard et al., 2007; Dugast et al., 2007; Ehara, 2007) or a different type of SMT (Aikawa and Ruopp, 2009). There is a major difference of the post-ordering from such an post-editing framework; in the post-editing framework, the preceding translation process is a complete source-totarget translation, and the post-editing itself works as an additional process to ﬁx errors. In contrast, the post-ordering framework divides the whole translation process into two sub-processes focusing on translation and reordering. It has an advantage that the sub-processes are simpliﬁed and easy to solve compared to a complete tran"
2011.mtsummit-papers.36,N04-4026,0,0.440185,"source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering. Recent research efforts developed novel technologies such as phrase-based SMT with phrase reordering models (Koehn et al., 2003; Tillmann, 2004), and tree-based (or syntax-based) SMT (Yamada and Knight, 2001; Galley et al., 316 In contrast, what can we do in the translation in the opposite direction? This is a non-trivial problem because the pre-ordering techniques are usually language dependent. Even if we have a good preordering technique in A-to-B translation such as reordering rules for syntactic parse trees, it cannot be used directly in B-to-A translation. Developing Bto-A pre-ordering is a different problem from A-toB, which may require a syntactic parser and/or linguistic insights. For example in Japanese-to-English translatio"
2011.mtsummit-papers.36,D09-1105,0,0.249521,"English, and then reordered into correctly-ordered English. The experiments on Japanese-to-English patent translation show the signiﬁcant advantage of postordering over baseline phrase-based, hierarchical phrase-based, and syntax-based translation methods by 1.56, 0.76, and 2.77 points in BLEU, respectively. 1 A recently attractive approach for this challenge is called pre-ordering, which reorders source language sentences into the target language word order prior to SMT decoding (Xia and McCord, 2004; Collins et al., 2005; Costa-juss`a and Fonollosa, 2006; Li et al., 2007; Wang et al., 2007; Tromble and Eisner, 2009; Isozaki et al., 2010; Genzel, 2010). The pre-ordering approach is able to reorder source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering. Recent research efforts developed novel techn"
2011.mtsummit-papers.36,D07-1077,0,0.0514298,"Missing"
2011.mtsummit-papers.36,J97-3002,0,0.389798,"e reordering, because discontinuous supplies few constraints for reordering. On the other hand, syntaxbased SMT (Yamada and Knight, 2001; Galley et al., 2004; Graehl and Knight, 2004) is a theoretically good solution. Reordering in syntax-based SMT is modeled in a similar manner as reordering of tree nodes in the same level (siblings), regardless of their reordering distance. Although this approach have some shortcomings with parse errors and its too strong constraints, syntactic information is expected to be effective in some language pairs. Another syntactic approach, originally proposed by Wu (1997), uses formally-syntactic structure between source and target language sentences. This framework was extended as the hierarchical phrase-based SMT by Chiang (2007) and is convincing alternative in recent SMT research. The reordering models mentioned above are applied in SMT decoding and solved simultaneously with phrase translation. Xiong et al. extended the hierarchical SMT by lexicalized reordering (Xiong et al., 2006; Xiong et al., 2008). However, the integrated search requires a large computational cost both in time and space. To keep the search tractable, we constrain reordering search by"
2011.mtsummit-papers.36,C04-1073,0,0.779624,"in the opposite direction and proposes post-ordering; foreign sentences are ﬁrst translated into foreign-ordered English, and then reordered into correctly-ordered English. The experiments on Japanese-to-English patent translation show the signiﬁcant advantage of postordering over baseline phrase-based, hierarchical phrase-based, and syntax-based translation methods by 1.56, 0.76, and 2.77 points in BLEU, respectively. 1 A recently attractive approach for this challenge is called pre-ordering, which reorders source language sentences into the target language word order prior to SMT decoding (Xia and McCord, 2004; Collins et al., 2005; Costa-juss`a and Fonollosa, 2006; Li et al., 2007; Wang et al., 2007; Tromble and Eisner, 2009; Isozaki et al., 2010; Genzel, 2010). The pre-ordering approach is able to reorder source language words in long distance by some reordering rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of t"
2011.mtsummit-papers.36,P06-1066,0,0.0589586,"Missing"
2011.mtsummit-papers.36,I08-1066,0,0.0191332,"e errors and its too strong constraints, syntactic information is expected to be effective in some language pairs. Another syntactic approach, originally proposed by Wu (1997), uses formally-syntactic structure between source and target language sentences. This framework was extended as the hierarchical phrase-based SMT by Chiang (2007) and is convincing alternative in recent SMT research. The reordering models mentioned above are applied in SMT decoding and solved simultaneously with phrase translation. Xiong et al. extended the hierarchical SMT by lexicalized reordering (Xiong et al., 2006; Xiong et al., 2008). However, the integrated search requires a large computational cost both in time and space. To keep the search tractable, we constrain reordering search by its reordering distance, as so-called distortion limit (or maximum span in tree-based decoder). It effectively reduces the computational cost but it also give up long distance reordering exceeding the speciﬁed distortion limit. A novel alternative to the reordering problem, called pre-ordering, has been studied over recent years (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Genzel, 2010). Xia and McCord (2004) proposed auto"
2011.mtsummit-papers.36,P01-1067,0,0.583016,"ng rules or models. This effectively solves the complex reordering problem and achieves good translation performance especially in language pairs with very different word ordering. A crucial issue on the pre-ordering is to develop good reordering methods in the source language. Introduction Statistical Machine Translation (SMT) consists of two major problems, translation of words or phrases and their reordering. Recent research efforts developed novel technologies such as phrase-based SMT with phrase reordering models (Koehn et al., 2003; Tillmann, 2004), and tree-based (or syntax-based) SMT (Yamada and Knight, 2001; Galley et al., 316 In contrast, what can we do in the translation in the opposite direction? This is a non-trivial problem because the pre-ordering techniques are usually language dependent. Even if we have a good preordering technique in A-to-B translation such as reordering rules for syntactic parse trees, it cannot be used directly in B-to-A translation. Developing Bto-A pre-ordering is a different problem from A-toB, which may require a syntactic parser and/or linguistic insights. For example in Japanese-to-English translation, pre-ordering of Japanese parse trees into English word order"
2011.mtsummit-papers.36,zhang-etal-2004-interpreting,0,0.0319715,"ed 15 for its max-chart-span option. The other 321 Table 2 shows the results in BLEU (Papineni et al., 2002) in case-insensitive evaluation and average decoding times7 (on a Xeon 7460 2.66GHz computer) with the compared methods. The proposed post-ordering translation (with monotone Japaneseto-HFE translation) achieved 0.2963 in BLEU, better than the best HPBMT baseline (0.2887) by 0.76 points and the standard PBMT baseline (0.2806) by 1.57 points. The differences were statistically signiﬁcant according to the bootstrap sampling test (p &lt; 0.05 with HPBMT and p &lt; 0.01 with PBMT, 1,000 samples) (Zhang et al., 2004), and it was consistent among all post-ordering conditions. In the Japanese-to-HFE translation, the monotone conﬁguration was slightly better than the reordering with the distortion limit of 6 but the difference was not signiﬁcant. In the HFE-to-English translation, the difference in the distortion limit did not affect the ﬁnal results. Among the baseline methods, HPBMT was better than other baselines by 0.5 points. 4.4 Discussion The proposed post-ordering method was consistently better than the baseline methods in the experiment. To investigate the results in detail, we analyzed the Japanese"
2013.iwslt-evaluation.12,N03-1017,0,0.0375042,"an compounds; and system combination of different types of SMT systems based on generalized minimum Bayes risk (GMBR) framework. This paper presents details of our systems and reports the results in German-English and English-German MT tasks in the evaluation campaign. 2. Translation Methods The main feature of our system for this evaluation is that we perform translation using three different translation models and combine the results through system combination. Each of the three methods is described briefly below. 2.1. Phrase-based Machine Translation Phrase-based machine translation (PBMT; [2]) models the translation process by splitting the source sentence into phrases, translating the phrases into target phrases, and reordering the phrases into the target language order. PBMT is currently the most widely used method in SMT as it is robust, does not require the availability of linguistic analysis tools, and achieves high accuracy, particularly for languages with similar syntactic structure. 2.2. Hierarchical Phrase-based Machine Translation Hierarchical phrase-based machine translation (Hiero; [3]) expands the class of translation rules that can be used in phrase-based machine tra"
2013.iwslt-evaluation.12,J07-2003,0,0.106892,"below. 2.1. Phrase-based Machine Translation Phrase-based machine translation (PBMT; [2]) models the translation process by splitting the source sentence into phrases, translating the phrases into target phrases, and reordering the phrases into the target language order. PBMT is currently the most widely used method in SMT as it is robust, does not require the availability of linguistic analysis tools, and achieves high accuracy, particularly for languages with similar syntactic structure. 2.2. Hierarchical Phrase-based Machine Translation Hierarchical phrase-based machine translation (Hiero; [3]) expands the class of translation rules that can be used in phrase-based machine translation by further allowing rules with gaps that can be filled in a hierarchical fashion. Hiero is generally considered to be more accurate than PBMT on language pairs that are less monotonic, but also requires a significantly larger amount of memory and decoding time. As the German-English pair has a significant amount of reordering, particularly with movement of verbs, we can expect that Hiero will be able to handle these reorderings more appropriately in some cases. 2.3. Forest-to-string Machine Translatio"
2013.iwslt-evaluation.12,P06-1077,0,0.131208,"at can be used in phrase-based machine translation by further allowing rules with gaps that can be filled in a hierarchical fashion. Hiero is generally considered to be more accurate than PBMT on language pairs that are less monotonic, but also requires a significantly larger amount of memory and decoding time. As the German-English pair has a significant amount of reordering, particularly with movement of verbs, we can expect that Hiero will be able to handle these reorderings more appropriately in some cases. 2.3. Forest-to-string Machine Translation Tree-to-string machine translation (T2S; [4]) performs translation by first syntactically parsing the source sentence, then translating from sub-structures of the parse to a string in the target language. Forest-to-string machine translation (F2S; [5]) generalizes this framework, making it possible to not only translate the single one-best syntactic parse, but a packed forest that encodes many possible parses, helping to pass along some of the ambiguity of parsing to be resolved during translation. While there are a number of proposed methods for incorporating source-side syntax into the translation process, here we use a method based o"
2013.iwslt-evaluation.12,D08-1022,0,0.0240076,"irs that are less monotonic, but also requires a significantly larger amount of memory and decoding time. As the German-English pair has a significant amount of reordering, particularly with movement of verbs, we can expect that Hiero will be able to handle these reorderings more appropriately in some cases. 2.3. Forest-to-string Machine Translation Tree-to-string machine translation (T2S; [4]) performs translation by first syntactically parsing the source sentence, then translating from sub-structures of the parse to a string in the target language. Forest-to-string machine translation (F2S; [5]) generalizes this framework, making it possible to not only translate the single one-best syntactic parse, but a packed forest that encodes many possible parses, helping to pass along some of the ambiguity of parsing to be resolved during translation. While there are a number of proposed methods for incorporating source-side syntax into the translation process, here we use a method based on tree-to-string transducers [6]. Syntax-driven methods such as T2S and F2S are particularly useful for language pairs with extremely large amounts of reordering, as the syntactic parse can help guide the ac"
2013.iwslt-evaluation.12,N04-1014,0,0.0445956,"st syntactically parsing the source sentence, then translating from sub-structures of the parse to a string in the target language. Forest-to-string machine translation (F2S; [5]) generalizes this framework, making it possible to not only translate the single one-best syntactic parse, but a packed forest that encodes many possible parses, helping to pass along some of the ambiguity of parsing to be resolved during translation. While there are a number of proposed methods for incorporating source-side syntax into the translation process, here we use a method based on tree-to-string transducers [6]. Syntax-driven methods such as T2S and F2S are particularly useful for language pairs with extremely large amounts of reordering, as the syntactic parse can help guide the accurate re-ordering of entire phrases or clauses. On the other hand, these methods are highly dependent on parsing accuracy, and also have limits on the rules that can be extracted, and are somewhat less robust than the previous two methods. different syntactic parser that did not provide this information. 3. SMT Technologies 3.2.2. English-to-German 3.1. Training data selection The target TED domain is different in both s"
2013.iwslt-evaluation.12,P13-2119,1,0.927042,"these methods are highly dependent on parsing accuracy, and also have limits on the rules that can be extracted, and are somewhat less robust than the previous two methods. different syntactic parser that did not provide this information. 3. SMT Technologies 3.2.2. English-to-German 3.1. Training data selection The target TED domain is different in both style and vocabulary from many of the other bitexts, e.g. Europarl, CommonCrawl (which we collectively call “general-domain” data1 ). To address this domain adaption problem, we performed adaptation training data selection using the method of [7].2 The intuition is to select general-domain sentences that are similar to in-domain text, while being dis-similar to the average general-domain text. To do so, one defines the score of an general-domain sentence pair (e, f ) as [8]: [INE (e) − GENE (e)] + [INF (f ) − GENF (f )] (1) where INE (e) is the length-normalized cross-entropy of e on the English in-domain LM. GENE (e) is the lengthnormalized cross-entropy of e on the English general-domain LM, which is built from a sub-sample of the general-domain text. By taking a sub-sample (same size as the target-domain data), we reduce training t"
2013.iwslt-evaluation.12,D11-1033,0,0.0655671,"mation. 3. SMT Technologies 3.2.2. English-to-German 3.1. Training data selection The target TED domain is different in both style and vocabulary from many of the other bitexts, e.g. Europarl, CommonCrawl (which we collectively call “general-domain” data1 ). To address this domain adaption problem, we performed adaptation training data selection using the method of [7].2 The intuition is to select general-domain sentences that are similar to in-domain text, while being dis-similar to the average general-domain text. To do so, one defines the score of an general-domain sentence pair (e, f ) as [8]: [INE (e) − GENE (e)] + [INF (f ) − GENF (f )] (1) where INE (e) is the length-normalized cross-entropy of e on the English in-domain LM. GENE (e) is the lengthnormalized cross-entropy of e on the English general-domain LM, which is built from a sub-sample of the general-domain text. By taking a sub-sample (same size as the target-domain data), we reduce training time and avoid training and testing language models on the same general-domain data. Similarly, INF (f ) and GENF (f ) are the cross-entropies of f on Foreign-side LM. Finally, sentence pairs are ranked according to Eq. 1 and those w"
2013.iwslt-evaluation.12,P05-1066,0,0.146142,") are added together with the in-domain bitext for translation model training. Here, the LMs are Recurrent Neural Network Language Models (RNNLMs), which have been shown to outperform n-gram LMs in this problem [7]. 3.2. Syntactic Rule-based Pre-ordering Preordering is a method that attempts to first re-order the source sentence into a word order that is closer to the target. As German and English have significantly different word order, we can imagine that this will help our accuracy for this language pair. 3.2.1. German-to-English We applied the clause restructuring method of Collins et al. [9] for German pre-ordering. The method is mainly based on moving German verbs in the end of clause structures towards the beginning of the clause. We re-implemented the method for German parse trees created using the Berkeley parser trained on TIGER corpus. We ignored some additional syntactic information such as subject markers and heads implemented in the original method of [9], because we used a 1 To give a sense of the domain difference, a 4-gram LM trained with Kneser-Ney smoothing on TED data gives a perplexity of 355 on the general domain data, compared to a perplexity of 99 on held-out T"
2013.iwslt-evaluation.12,E03-1076,0,0.18382,"ional feature to each translation hypothesis. We then re-run a single MERT optimization to find ideal weights for this new feature, and then extract the 1-best result from the 10,000-best list for the test set according to these new weights. The parameters for RNNLM training are tuned on the dev set to maximize perplexity, resulting in 300 hidden layers, 300 classes, and 4 steps of back-propogation through time. 3.4. German compound word splitting German compound words present sparsity challenges for machine translation. To address this, we split German words following the general approach of [11]. The idea is to split a word if the geometric average of its subword frequencies is larger than whole word frequency. In our implementation, for each word, we searched for all possible decompositions into two sub-words, considering the possibility of deleting common German fillers “e”, “es”, and “s” (as in ”Arbeit+s+tier”). For simplicity, we did not experiment with splitting into three or more sub-words as done in the compound-splitter.perl script distributed with the Moses package. The unigram frequencies for the subwords and whole word is computed from the German part of the bitext. This s"
2013.iwslt-evaluation.12,I11-1153,1,0.737728,"vial to handle recombination of German split words after reordering and translation. To ensure that the uniform hypotheses space gives the same decision as the original loss in the true space p(e|f ), we use a small development set to tune the parameter θ as follows. For any two hypotheses e1 , e2 , and a reference translation er (possibly not in N (f )) we first compute the true loss: L(e1 |er ) and L(e2 |er ). If L(e1 |er ) &lt; L(e2 |er ), then we would want θ such that: K ∑ ∑ 3.5. GMBR system combination We used a system combination method based on Generalized Minimum Bayes Risk optimization [12], which has been successfully applied to different types of SMT systems for patent translation [13]. Note that our system combination only picks one hypothesis from an N-best list and does not generate a new hypothesis by mixing partial hypotheses among the N-best. θk Lk (e1 |e) &lt; e∈N (f ) k=1 Minimum Bayes Risk (MBR) is a decision rule to choose hypotheses that minimize the expected loss. In the task of SMT from a French sentence (f ) to an English sentence (e), the MBR decision rule on δ(f ) → e′ with the loss function L over the possible space of sentence pairs (p(e, f )) is denoted as: ∑ a"
2013.iwslt-evaluation.12,P10-1017,0,0.0236144,"akes the problem amendable to solutions in “learning to rank” literature [15]. We used BLEU as the objective function and the subcomponents of BLEU as features (system identity feature was not used). There is one regularization hyperparameter for the Ranking SVM, which we set by cross-validation over the development set (dev2010). 3.6. What Didn’t Work Immediately We also tried several other methods that did not have a clear positive effect and were thus omitted from the final system. For example, we attempted to improve alignment accuracy using the discriminative alignment method proposed by [16] training on the 300 hand-aligned sentences.4 However, while this provided small gains in alignment accuracy on a held-out set, the gains were likely not enough, and MT results were inconclusive. We also attempted to use the reordering method of [17] as implemented in lader,5 again trained on the same 300 hand-aligned sentences, but increases in reordering accuracy on a held-out set were minimal. We believe that both of these techniques are promising, but require a larger set of hand-aligned data to provide gains large enough to appear in MT results. 4 http://user.phil-fak.uni-duesseldorf.de/"
2013.iwslt-evaluation.12,D12-1077,1,0.836426,"Ranking SVM, which we set by cross-validation over the development set (dev2010). 3.6. What Didn’t Work Immediately We also tried several other methods that did not have a clear positive effect and were thus omitted from the final system. For example, we attempted to improve alignment accuracy using the discriminative alignment method proposed by [16] training on the 300 hand-aligned sentences.4 However, while this provided small gains in alignment accuracy on a held-out set, the gains were likely not enough, and MT results were inconclusive. We also attempted to use the reordering method of [17] as implemented in lader,5 again trained on the same 300 hand-aligned sentences, but increases in reordering accuracy on a held-out set were minimal. We believe that both of these techniques are promising, but require a larger set of hand-aligned data to provide gains large enough to appear in MT results. 4 http://user.phil-fak.uni-duesseldorf.de/ tosch/ ˜ downloads.html 5 http://phontron.com/lader 4. Experiments 4.1. Setup 4.1.1. System overview We used three individual SMT systems for each language pairs: forest-to-string (F2S), hierarchical phrase-based (Hiero), and phrase-based with pre-or"
2013.iwslt-evaluation.12,P13-4016,1,0.84637,"believe that both of these techniques are promising, but require a larger set of hand-aligned data to provide gains large enough to appear in MT results. 4 http://user.phil-fak.uni-duesseldorf.de/ tosch/ ˜ downloads.html 5 http://phontron.com/lader 4. Experiments 4.1. Setup 4.1.1. System overview We used three individual SMT systems for each language pairs: forest-to-string (F2S), hierarchical phrase-based (Hiero), and phrase-based with pre-ordering (Preorder). In some of our comparisons we also use simple phrase-based translation without preordering (PBMT). F2S was implemented with Travatar [18] and Preorder, PBMT, and Hiero were implemented using Moses [19]. For the Moses models, we generally used the default settings, but with Good-Turing phrase table smoothing. For F2S translation we used Egret6 as a parser, and created forests using dynamic pruning including all edges that occurred in the 100-best hypotheses. We trained the parsing model using the Berkeley parser over the Wall Street Journal section of the Penn Treebank7 for English, and TIGER corpus [20] for German. For model training, the default settings for Travatar were used, with the exception of changing the number of comp"
2013.iwslt-evaluation.12,P07-2045,0,0.0147657,"e a larger set of hand-aligned data to provide gains large enough to appear in MT results. 4 http://user.phil-fak.uni-duesseldorf.de/ tosch/ ˜ downloads.html 5 http://phontron.com/lader 4. Experiments 4.1. Setup 4.1.1. System overview We used three individual SMT systems for each language pairs: forest-to-string (F2S), hierarchical phrase-based (Hiero), and phrase-based with pre-ordering (Preorder). In some of our comparisons we also use simple phrase-based translation without preordering (PBMT). F2S was implemented with Travatar [18] and Preorder, PBMT, and Hiero were implemented using Moses [19]. For the Moses models, we generally used the default settings, but with Good-Turing phrase table smoothing. For F2S translation we used Egret6 as a parser, and created forests using dynamic pruning including all edges that occurred in the 100-best hypotheses. We trained the parsing model using the Berkeley parser over the Wall Street Journal section of the Penn Treebank7 for English, and TIGER corpus [20] for German. For model training, the default settings for Travatar were used, with the exception of changing the number of composed rules to 6 and using Kneser-Ney rule table smoothing. All s"
2013.iwslt-evaluation.12,P02-1040,0,0.0871245,"t settings, but with Good-Turing phrase table smoothing. For F2S translation we used Egret6 as a parser, and created forests using dynamic pruning including all edges that occurred in the 100-best hypotheses. We trained the parsing model using the Berkeley parser over the Wall Street Journal section of the Penn Treebank7 for English, and TIGER corpus [20] for German. For model training, the default settings for Travatar were used, with the exception of changing the number of composed rules to 6 and using Kneser-Ney rule table smoothing. All systems were evaluated using the standard BLEU score [21] and also RIBES [22], a metric designed specifically to show whether reordering is being performed properly. All systems were optimized towards BLEU score. We measure statistical significance between results with bootstrap resampling with p &gt; 0.05. Bold numbers in each table indicate the best system, and all systems that do not show a statistically significant difference from the best system [23]. All words were lowercased prior to translation, and finally recased by a SMT-based recaser as implemented in Moses. 4.1.2. Translation models We trained the translation models using WIT3 training dat"
2013.iwslt-evaluation.12,D10-1092,1,0.836115,"Good-Turing phrase table smoothing. For F2S translation we used Egret6 as a parser, and created forests using dynamic pruning including all edges that occurred in the 100-best hypotheses. We trained the parsing model using the Berkeley parser over the Wall Street Journal section of the Penn Treebank7 for English, and TIGER corpus [20] for German. For model training, the default settings for Travatar were used, with the exception of changing the number of composed rules to 6 and using Kneser-Ney rule table smoothing. All systems were evaluated using the standard BLEU score [21] and also RIBES [22], a metric designed specifically to show whether reordering is being performed properly. All systems were optimized towards BLEU score. We measure statistical significance between results with bootstrap resampling with p &gt; 0.05. Bold numbers in each table indicate the best system, and all systems that do not show a statistically significant difference from the best system [23]. All words were lowercased prior to translation, and finally recased by a SMT-based recaser as implemented in Moses. 4.1.2. Translation models We trained the translation models using WIT3 training data (138,499 sentences"
2013.iwslt-evaluation.12,W04-3250,0,0.0816664,"lt settings for Travatar were used, with the exception of changing the number of composed rules to 6 and using Kneser-Ney rule table smoothing. All systems were evaluated using the standard BLEU score [21] and also RIBES [22], a metric designed specifically to show whether reordering is being performed properly. All systems were optimized towards BLEU score. We measure statistical significance between results with bootstrap resampling with p &gt; 0.05. Bold numbers in each table indicate the best system, and all systems that do not show a statistically significant difference from the best system [23]. All words were lowercased prior to translation, and finally recased by a SMT-based recaser as implemented in Moses. 4.1.2. Translation models We trained the translation models using WIT3 training data (138,499 sentences) and 1,000,000 sentences selected over other bitexts (Europarl, News Commentary, and Common Crawl) by the method described in 3.1. 4.1.3. Language models We used two types of word n-gram language models of German and English: interpolated 6-gram and Google 5-gram. The interpolated 6-gram LMs were from linear interpolation of several 6-gram LMs on different data sources (WIT3"
2013.iwslt-evaluation.12,P12-1001,1,0.853229,"at the F2S system did a significantly better job of accurately generating verbs at the end of the German sentence, demonstrating its superior capability for reordering. For German-English, on the other hand, F2S achieved a somewhat counter-intuitive low score on the reordering-based measure RIBES. Upon an analysis of the results, we found that the F2S system was largely getting the reordering right, but occasionally making big changes in reordering large clauses that were not reflected in the German reference. It is likely that if we optimized towards RIBES, or a combination of BLEU and RIBES [25] we might get better results. 4.4. Translation Method Comparison 4.5. Effect of Compound Splitting In this section, we provide a brief comparison of the three translation methods mentioned in Section 2 on tst2010 data. For all systems we used the TED data and 1M selected sentences for training, and used the language model described Next, we examine the effect of compound splitting for German-English translation. From the results in Table 7, we can see that compound splitting provides a gain for all systems, and particularly so for F2S translation. PBMT Hiero F2S en-de n-gram +RNNLM 23.11 23.81"
2013.iwslt-evaluation.12,federico-etal-2012-iwslt,0,\N,Missing
C10-1050,P06-1090,0,0.0477622,"anguage model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitly introduce reordering model to constrain word order. In contrast, lexicalized reordering models (Tillman, 2004; Koehn et al., 2005; Nagata et al., 2006) are extensively used This paper proposes a method that incorporates word-based reordering model into hierarchical phrase-based translation to constrain word order. In this paper, we adopt the reordering model originally proposed by Tromble and Eisner (2009) for the preprocessing approach in phrase-based translation. To integrate the word-based reordering model, we added a reordered source string into the right-hand-side of SCFG’s rules. By this extension, our system can generate the reordered source sentence as well as target sentence and is able to efficiently calculate the score of the reor"
C10-1050,P06-1067,0,0.0327337,"nd the right hand side of Figure 1, allowing us to score both global and local word reorderings. ′ ′ To add γ to rules, we permuted γ into γ after rule extraction based on Grow-diag-final (Koehn et al., 2005) alignment by GIZA++ (Och and Ney, 2003). To do this permutation on rules, we applied two methods. One is the same algorithm as Tromble and Eisner (2009), which reorders aligned source terminals and nonterminals in the same order as that of target side and moves unaligned source terminals to the front of aligned terminals or nonterminals (move-to-front). The other is the same algorithm as AI-Onaizan and Papineni (2006), which differs from Tromble and Eisner’s approach in attaching unaligned source terminals to the closest prealigned source terminals or nonterminals (attach). This extension of ′ adding γ does not increase the number of rules. Table 1 shows a Japanese-to-English example of the representation of rules for our proposed system. Japanese words are romanized. Suppose that source-side string is (X1 wa jinsei no X2 da) and target-side string is (X1 is X2 of life) and their word alignments are a=((jinsei , life) , (no , of) , (da , is)). Source-side aligned words and nonterminal symbols are sorted in"
C10-1050,J93-2003,0,0.0272701,"o handle global reordering in phrase-based translation, various preprocessing approaches have been proposed, where the source sentence is reordered to target language order beforehand (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009). However, preprocessing approaches cannot utilize other information in the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitly introduce reordering model to constrain word order. In contrast, lexicalized reordering models (Tillman, 2004; Koehn et al., 2005; Nagata et al., 2006) are extensively used This paper proposes a method that incorporates word-based reordering model into hierarchical phrase-based translation to constrain word order. In this paper, we adopt the reordering model originally p"
C10-1050,N09-1025,0,0.0662338,"Missing"
C10-1050,niessen-etal-2000-evaluation,0,0.0539958,"o preprocessing approach. PER 39.68 45.27 39.89 39.43 5 Table 5: BLEU and PER scores on the test set. Our training corpus contains about 200.8k sentences. Using the training corpus, we extracted hierarchical phrase rules and trained 4-gram language model and word-based reordering model. Parameters were tuned over 1.0k sentences (development data) with single reference by minimum error rate training (MERT) (Och, 2003). Test data consisted of 1.0k sentences with single reference. Table 4 shows the condition of corpus in detail. 4.3 Results Table 5 shows the BLEU (Papineni et al., 2001) and PER (Niesen et al., 2000) scores obtained by each system. The results clearly indicated that our proposed system with word-based reordering model (move-to-front or attach) outperformed baseline system on BLEU scores. In contrast, there is no significant improvement from baseline on PER. This suggests that the improvement of BLEU mainly comes from reordering. In our experiment, preprocessing approach resulted in very poor scores. 4.4 Discussion Table 6 displays examples showing the cause of the improvements of our system with reordering model (attach) comparing to baseline system. We can see that the outputs of our sys"
C10-1050,P02-1038,0,0.548257,"Missing"
C10-1050,J03-1002,0,0.012804,"equation: ( ) ′ ′ Tˆ = (Sˆ , Tˆ) = (S , T ) argmax w(D) . (6) D:S(D)=S Our system generates the reordered source sen′ tence S as well as target sentence T . Figure 2 ′ shows the generated reordered source sentence S when translating the example of Figure 1. Note ′ that the structure of S is the same as that of target sentence T . The decoder generates both Figure 2 and the right hand side of Figure 1, allowing us to score both global and local word reorderings. ′ ′ To add γ to rules, we permuted γ into γ after rule extraction based on Grow-diag-final (Koehn et al., 2005) alignment by GIZA++ (Och and Ney, 2003). To do this permutation on rules, we applied two methods. One is the same algorithm as Tromble and Eisner (2009), which reorders aligned source terminals and nonterminals in the same order as that of target side and moves unaligned source terminals to the front of aligned terminals or nonterminals (move-to-front). The other is the same algorithm as AI-Onaizan and Papineni (2006), which differs from Tromble and Eisner’s approach in attaching unaligned source terminals to the closest prealigned source terminals or nonterminals (attach). This extension of ′ adding γ does not increase the number"
C10-1050,P05-1066,0,0.562071,"les of hierarchical phrase-based model to include reordered source strings, allowing efficient calculation of reordering model scores during decoding. Our experimental results on Japanese-to-English basic travel expression corpus showed that the BLEU scores obtained by our proposed system were better than those obtained by a standard hierarchical phrase-based machine translation system. 1 To handle global reordering in phrase-based translation, various preprocessing approaches have been proposed, where the source sentence is reordered to target language order beforehand (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009). However, preprocessing approaches cannot utilize other information in the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it d"
C10-1050,P03-1021,0,0.214019,"X XXX System Baseline (Hiero) Preprocessing Hiero + move-to-front Hiero + attach 28.09 17.32 28.85 29.25 poorness, our proposed method effectively utilize this reordering model in contrast to preprocessing approach. PER 39.68 45.27 39.89 39.43 5 Table 5: BLEU and PER scores on the test set. Our training corpus contains about 200.8k sentences. Using the training corpus, we extracted hierarchical phrase rules and trained 4-gram language model and word-based reordering model. Parameters were tuned over 1.0k sentences (development data) with single reference by minimum error rate training (MERT) (Och, 2003). Test data consisted of 1.0k sentences with single reference. Table 4 shows the condition of corpus in detail. 4.3 Results Table 5 shows the BLEU (Papineni et al., 2001) and PER (Niesen et al., 2000) scores obtained by each system. The results clearly indicated that our proposed system with word-based reordering model (move-to-front or attach) outperformed baseline system on BLEU scores. In contrast, there is no significant improvement from baseline on PER. This suggests that the improvement of BLEU mainly comes from reordering. In our experiment, preprocessing approach resulted in very poor"
C10-1050,2005.iwslt-1.8,0,0.460908,"n model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitly introduce reordering model to constrain word order. In contrast, lexicalized reordering models (Tillman, 2004; Koehn et al., 2005; Nagata et al., 2006) are extensively used This paper proposes a method that incorporates word-based reordering model into hierarchical phrase-based translation to constrain word order. In this paper, we adopt the reordering model originally proposed by Tromble and Eisner (2009) for the preprocessing approach in phrase-based translation. To integrate the word-based reordering model, we added a reordered source string into the right-hand-side of SCFG’s rules. By this extension, our system can generate the reordered source sentence as well as target sentence and is able to efficiently calculate"
C10-1050,W08-0402,0,0.0145236,"on; incorpolated into sorted rules for the proposed implementation. To reveal the effectiveness of integrating the reordering model into decoder, we compared the following setups: Data Training • baseline: a standard hierarchical phrasebased machine translation (Hiero) system. Development Test • preprocessing: applied Tromble and Eisner’s approach, then translate by Hiero system. Word. 2.4M 2.3M 10.3K 9.8K 14.2K 13.5K Avg. leng 12.0 11.5 10.3 9.8 14.2 13.5 Table 4: The Data statistics • Hiero system + reordering model: integrated reordering model into Hiero system. We used the Joshua Decoder (Li and Khudanpur, 2008) as the baseline Hiero system. This decoder uses a log-linear model with seven features, which consist of N -gram language model PLM (T ), lexical translation model Pw (γ|α), Pw (α|γ), rule ja en ja en ja en Sent. 200.8K 200.8K 1.0K 1.0K 1.0K 1.0K For experiments we used a Japanese-English basic travel expression corpus (BTEC). Japanese word order is linguistically very different from English and we think Japanese-English pair is a very good test bed for evaluating reordering model. 443 XXX XXX Metrics BLEU XX XXX System Baseline (Hiero) Preprocessing Hiero + move-to-front Hiero + attach 28.09"
C10-1050,P07-1091,0,0.0761436,"rase-based model to include reordered source strings, allowing efficient calculation of reordering model scores during decoding. Our experimental results on Japanese-to-English basic travel expression corpus showed that the BLEU scores obtained by our proposed system were better than those obtained by a standard hierarchical phrase-based machine translation system. 1 To handle global reordering in phrase-based translation, various preprocessing approaches have been proposed, where the source sentence is reordered to target language order beforehand (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009). However, preprocessing approaches cannot utilize other information in the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitl"
C10-1050,2001.mtsummit-papers.68,0,0.0370106,"s reordering model in contrast to preprocessing approach. PER 39.68 45.27 39.89 39.43 5 Table 5: BLEU and PER scores on the test set. Our training corpus contains about 200.8k sentences. Using the training corpus, we extracted hierarchical phrase rules and trained 4-gram language model and word-based reordering model. Parameters were tuned over 1.0k sentences (development data) with single reference by minimum error rate training (MERT) (Och, 2003). Test data consisted of 1.0k sentences with single reference. Table 4 shows the condition of corpus in detail. 4.3 Results Table 5 shows the BLEU (Papineni et al., 2001) and PER (Niesen et al., 2000) scores obtained by each system. The results clearly indicated that our proposed system with word-based reordering model (move-to-front or attach) outperformed baseline system on BLEU scores. In contrast, there is no significant improvement from baseline on PER. This suggests that the improvement of BLEU mainly comes from reordering. In our experiment, preprocessing approach resulted in very poor scores. 4.4 Discussion Table 6 displays examples showing the cause of the improvements of our system with reordering model (attach) comparing to baseline system. We can s"
C10-1050,P08-1066,0,0.063341,"ur approach is similar to preprocessing approach (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009) in that it reorders source sentence in target order. The difference is this sentence reordering is done in decoding rather than in preprocessing. A lot of studies on lexicalized reordering (Tillman, 2004; Koehn et al., 2005; Nagata et al., 2006) focus on the phrase-based model. These works cannnot be directly applied to hierarchical phrase-based model because of the difference between normal phrases and hierarchical phrases that includes nonterminal symbols. Shen et al. (2008,2009) proposed a way to integrate dependency structure into target and source side string on hierarchical phrase rules. This approach is similar to our approach in extending the formalism of rules on hierarchical phrase-based model in order to consider the constraint of word order. But, our approach differs from (Shen et al., 2008; Shen et al., 2009) in that syntax annotation is not necessary. 6 Conclusion and Future Work We proposed a method to integrate word-based reordering model into hierarchical phrase-based ′ machine translation system. We add γ into the hiero rules, but this does not i"
C10-1050,D09-1008,0,0.0590956,"l., 2005; Nagata et al., 2006) focus on the phrase-based model. These works cannnot be directly applied to hierarchical phrase-based model because of the difference between normal phrases and hierarchical phrases that includes nonterminal symbols. Shen et al. (2008,2009) proposed a way to integrate dependency structure into target and source side string on hierarchical phrase rules. This approach is similar to our approach in extending the formalism of rules on hierarchical phrase-based model in order to consider the constraint of word order. But, our approach differs from (Shen et al., 2008; Shen et al., 2009) in that syntax annotation is not necessary. 6 Conclusion and Future Work We proposed a method to integrate word-based reordering model into hierarchical phrase-based ′ machine translation system. We add γ into the hiero rules, but this does not increase the number of rules. So, this extension itself does not affect the search space of decoding. In this paper we used Tromble and Eisner’s reordering model for our method, but various reordering model can ′ be incorporated to our method, for example S N -gram language model. Our experimental results on Japanese-to-English task showed that our sys"
C10-1050,N04-4026,0,0.216112,"the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitly introduce reordering model to constrain word order. In contrast, lexicalized reordering models (Tillman, 2004; Koehn et al., 2005; Nagata et al., 2006) are extensively used This paper proposes a method that incorporates word-based reordering model into hierarchical phrase-based translation to constrain word order. In this paper, we adopt the reordering model originally proposed by Tromble and Eisner (2009) for the preprocessing approach in phrase-based translation. To integrate the word-based reordering model, we added a reordered source string into the right-hand-side of SCFG’s rules. By this extension, our system can generate the reordered source sentence as well as target sentence and is able to e"
C10-1050,D09-1105,0,0.74067,"to include reordered source strings, allowing efficient calculation of reordering model scores during decoding. Our experimental results on Japanese-to-English basic travel expression corpus showed that the BLEU scores obtained by our proposed system were better than those obtained by a standard hierarchical phrase-based machine translation system. 1 To handle global reordering in phrase-based translation, various preprocessing approaches have been proposed, where the source sentence is reordered to target language order beforehand (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009). However, preprocessing approaches cannot utilize other information in the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitly introduce reordering mode"
C10-1050,P06-1098,1,0.822492,"than those obtained by a standard hierarchical phrase-based machine translation system. 1 To handle global reordering in phrase-based translation, various preprocessing approaches have been proposed, where the source sentence is reordered to target language order beforehand (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009). However, preprocessing approaches cannot utilize other information in the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global reordering by SCFG, it does not explicitly introduce reordering model to constrain word order. In contrast, lexicalized reordering models (Tillman, 2004; Koehn et al., 2005; Nagata et al., 2006) are extensively used This paper proposes a method that incorporates word-based reordering model into hierarchical phrase-based transl"
C10-1050,C04-1073,0,0.441205,"ontext-free grammar rules of hierarchical phrase-based model to include reordered source strings, allowing efficient calculation of reordering model scores during decoding. Our experimental results on Japanese-to-English basic travel expression corpus showed that the BLEU scores obtained by our proposed system were better than those obtained by a standard hierarchical phrase-based machine translation system. 1 To handle global reordering in phrase-based translation, various preprocessing approaches have been proposed, where the source sentence is reordered to target language order beforehand (Xia and McCord, 2004; Collins et al., 2005; Li et al., 2007; Tromble and Eisner, 2009). However, preprocessing approaches cannot utilize other information in the translation model and target language model, which has been proven helpful in decoding. Introduction Hierarchical phrase-based machine translation (Chiang, 2007; Watanabe et al., 2006) is one of the promising statistical machine translation approaches (Brown et al., 1993). Its model is formulated by a synchronous context-free grammar (SCFG) which captures the syntactic information between source and target languages. Although the model captures global re"
C10-1050,W02-1001,0,\N,Missing
C10-1050,P02-1040,0,\N,Missing
C10-1050,J07-2003,0,\N,Missing
D07-1080,P05-1012,0,0.310578,"ptimized toward a set of good translations found in the k-best list across iterations. The objective function is an approximated BLEU (Watanabe et al., 2006a) that scales the loss of a sentence BLEU to a documentwise loss. The parameters are trained using the 764 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 764–773, Prague, June 2007. 2007 Association for Computational Linguistics Margin Infused Relaxed Algorithm (MIRA) (Crammer et al., 2006). MIRA is successfully employed in dependency parsing (McDonald et al., 2005) or the joint-labeling/chunking task (Shimizu and Haas, 2006). Experiments were carried out on an Arabicto-English translation task, and we achieved significant improvements over conventional minimum error training with a small number of features. This paper is organized as follows: First, Section 2 introduces the framework of statistical machine translation. As a baseline SMT system, we use the hierarchical phrase-based translation with an efficient left-to-right generation (Watanabe et al., 2006b) originally proposed by Chiang (2005). In Section 3, a set of binary sparse features are defined"
D07-1080,J04-4002,0,0.0244586,"achine translation by using a large number of features with an online large-margin training algorithm. The millions of parameters were tuned only on a small development set consisting of less than 1K sentences. Experiments on Arabic-toEnglish translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features. 1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) or syntax-based translation (Galley et al., 2006). However, it does not scale well with a large number of features of the order of millions. Tillmann and Zhang (2006), Liang et al. (2006) and Bangalore et al. (2006) introduced sparse binary features for statistical machine translation trained on a large training corpus. In this framework, the problem of translation is regarded as a sequential labeling problem, in the same way as part-of-speech tagging, chunking or shallow parsing. However, the use of a large number of features did not provide any significant"
D07-1080,2004.iwslt-evaluation.13,0,0.0101531,"concatenated and intersected with n-gram. 3 Features 3.1 Baseline Features The hierarchical phrase-based translation system employs standard numeric value features: • n-gram language model to capture the fluency of the target side. • Hierarchical phrase translation probabilities in ¯ and h(bβ|γ), ¯ both directions, h(γ|bβ) estimated ¯ by relative counts, count(γ, bβ). • Word-based lexically weighted models of ¯ and hlex (bβ|γ) ¯ hlex (γ|bβ) using lexical translation models. • Word-based insertion/deletion penalties that penalize through the low probabilities of the lexical translation models (Bender et al., 2004). • Word/hierarchical-phrase length penalties. • Backtrack-based penalties inspired by the distortion penalties in phrase-based modeling (Watanabe et al., 2006b). 3.2 Sparse Features In addition to the baseline features, a large number of binary features are integrated in our MT system. We may use any binary features, such as   English word “violate” and Arabic    1 word “tnthk” appeared in e and f . h( f, e) =     0 otherwise. The features are designed by considering the decoding efficiency and are based on the word alignment structure preserved in hierarchical phrase translation pai"
D07-1080,P05-1033,0,0.854373,"ber of features with an online large-margin training algorithm. The millions of parameters were tuned only on a small development set consisting of less than 1K sentences. Experiments on Arabic-toEnglish translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features. 1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) or syntax-based translation (Galley et al., 2006). However, it does not scale well with a large number of features of the order of millions. Tillmann and Zhang (2006), Liang et al. (2006) and Bangalore et al. (2006) introduced sparse binary features for statistical machine translation trained on a large training corpus. In this framework, the problem of translation is regarded as a sequential labeling problem, in the same way as part-of-speech tagging, chunking or shallow parsing. However, the use of a large number of features did not provide any significant improvements over a conventional s"
D07-1080,P06-1121,0,0.0405344,"training algorithm. The millions of parameters were tuned only on a small development set consisting of less than 1K sentences. Experiments on Arabic-toEnglish translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features. 1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) or syntax-based translation (Galley et al., 2006). However, it does not scale well with a large number of features of the order of millions. Tillmann and Zhang (2006), Liang et al. (2006) and Bangalore et al. (2006) introduced sparse binary features for statistical machine translation trained on a large training corpus. In this framework, the problem of translation is regarded as a sequential labeling problem, in the same way as part-of-speech tagging, chunking or shallow parsing. However, the use of a large number of features did not provide any significant improvements over a conventional small feature set. Bangalore et al. (2006) trained"
D07-1080,N03-1017,0,0.244563,"by using a large number of features with an online large-margin training algorithm. The millions of parameters were tuned only on a small development set consisting of less than 1K sentences. Experiments on Arabic-toEnglish translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features. 1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) or syntax-based translation (Galley et al., 2006). However, it does not scale well with a large number of features of the order of millions. Tillmann and Zhang (2006), Liang et al. (2006) and Bangalore et al. (2006) introduced sparse binary features for statistical machine translation trained on a large training corpus. In this framework, the problem of translation is regarded as a sequential labeling problem, in the same way as part-of-speech tagging, chunking or shallow parsing. However, the use of a large number of features did not provide any significant improvements over a"
D07-1080,P03-1021,0,0.59948,"on 2 introduces the framework of statistical machine translation. As a baseline SMT system, we use the hierarchical phrase-based translation with an efficient left-to-right generation (Watanabe et al., 2006b) originally proposed by Chiang (2005). In Section 3, a set of binary sparse features are defined including numeric features for our baseline system. Section 4 introduces an online large-margin training algorithm using MIRA with our key components. The experiments are presented in Section 5 followed by discussion in Section 6. 2 Statistical Machine Translation We use a log-linear approach (Och, 2003) in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: eˆ = argmax wT · h( f, e) (1) e where h( f, e) is a large-dimension feature vector. w is a weight vector that scales the contribution from each feature. Each feature can take any real value, such as the log of the n-gram language model to represent fluency, or a lexicon model to capture the word or phrase-wise correspondence. 2.1 Hierarchical Phrase-based SMT Chiang (2005) introduced the hierarchical phrasebased translation approach, in which non-terminals are emb"
D07-1080,P02-1040,0,0.107918,"ed as “@@@@/@/@@”. We consider all possible combination of those token types. For example, the word pair feature (violate, tnthk) is normalized and expanded to (viol+, tnthk), (viol+, tnth+), (violate, tnth+), etc. using the 4-letter prefix token type. 4 Online Large-Margin Training Algorithm 1 is our generic online training algorithm. The algorithm is slightly different from other online training algorithms (Tillmann and Zhang, 2006; Liang et al., 2006) in that we keep and update oracle translations, which is a set of good translations reachable by a decoder according to a metric, i.e. BLEU (Papineni et al., 2002). In line 3, a k-best list is generated by bestk (·) using the current weight vector wi for the training instance of ( f t , et ). Each training instance has multiple (or, possibly one) reference translations et for the source sentence f t . Using the k-best list, m-best oracle translations Ot is updated by oraclem (·) for every iteration (line 4). Usually, a decoder cannot generate translations that exactly match the reference translations due to its beam search pruning and OOV. Thus, we cannot always assign scores for each reference translation. Therefore, possible oracle translations are ma"
D07-1080,P04-1007,0,0.0559747,"of phrase translation pairs, but it is trivial to define the features over hierarchical phrases. X1 X2 f j−1 fj f j+3 X3 f j+1 f j+2 Figure 2: Example hierarchical features. same way, we will be able to include deletion features where a non-aligned source word is associated with the target sentence. However, this would lead to complex decoding in which all the translated words are memorized for each hypothesis, and thus not integrated in our feature set. 3.2.3 Target Bigram Features Target side bigram features are also included to directly capture the fluency as in the n-gram language model (Roark et al., 2004). For instance, bigram features of (ei−1 , ei ), (ei , ei+1 ), (ei+1 , ei+2 )... are observed in Figure 1. 3.2.4 Hierarchical Features In addition to the phrase motivated features, we included features inspired by the hierarchical structure. Figure 2 shows an example of hierarchical phrases in the source side, consisting of X 1 → E E D D D E f j−1 X 2 f j+3 , X 2 → f j f j+1 X 3 and X 3 → f j+2 . Hierarchical features capture the dependency of the source words in a parent phrase to the source words in child phrases, such as ( f j−1 , f j ), ( f j−1 , f j+1 ), ( f j+3 , f j ), ( f j+3 , f j+1 )"
D07-1080,P06-2098,0,0.147558,"st list across iterations. The objective function is an approximated BLEU (Watanabe et al., 2006a) that scales the loss of a sentence BLEU to a documentwise loss. The parameters are trained using the 764 Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational c Natural Language Learning, pp. 764–773, Prague, June 2007. 2007 Association for Computational Linguistics Margin Infused Relaxed Algorithm (MIRA) (Crammer et al., 2006). MIRA is successfully employed in dependency parsing (McDonald et al., 2005) or the joint-labeling/chunking task (Shimizu and Haas, 2006). Experiments were carried out on an Arabicto-English translation task, and we achieved significant improvements over conventional minimum error training with a small number of features. This paper is organized as follows: First, Section 2 introduces the framework of statistical machine translation. As a baseline SMT system, we use the hierarchical phrase-based translation with an efficient left-to-right generation (Watanabe et al., 2006b) originally proposed by Chiang (2005). In Section 3, a set of binary sparse features are defined including numeric features for our baseline system. Section"
D07-1080,W04-3201,0,0.02528,"nslation are created, which amount to m × k large-margin constraints. In this online training, only active features constrained by Eq. 3 are kept and updated, unlike offline training in which all possible features have to be extracted and selected in advance. The Lagrange dual form of Eq. 3 is:   1 X maxα(·)≥0 − || α(ˆe, e′ ) h( f t , eˆ ) − h( f t , e′ ) ||2 2 eˆ ,e′ X + α(ˆe, e′ )L(ˆe, e′ ; et ) eˆ,e′ Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) (Crammer et al., 2006) is an online version of the large-margin training algorithm for structured classification (Taskar et al., 2004) that has been successfully used for dependency parsing (McDonald et al., 2005) and joint-labeling/chunking (Shimizu and Haas, 2006). The basic idea is to keep the norm of the updates to the weight vector as small as possible, considering a margin at least as large as the loss of the incorrect classification. Line 5 of the weight vector update procedure in Algorithm 1 is replaced by the solution of: X ˆ i+1 = argmin ||wi+1 − wi ||+ C ξ(ˆe, e′ ) w wi+1 eˆ ,e′ subject to si+1 ( f t , eˆ ) − si+1 ( f t , e′ ) + ξ(ˆe, e′ ) ≥ L(ˆe, e′ ; et ) ξ(ˆe, e′ ) ≥ 0 ∀ˆe ∈ Ot , ∀e′ ∈ Ct (3) n oT where si ( f"
D07-1080,P06-1091,0,0.438964,"an 1K sentences. Experiments on Arabic-toEnglish translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features. 1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) or syntax-based translation (Galley et al., 2006). However, it does not scale well with a large number of features of the order of millions. Tillmann and Zhang (2006), Liang et al. (2006) and Bangalore et al. (2006) introduced sparse binary features for statistical machine translation trained on a large training corpus. In this framework, the problem of translation is regarded as a sequential labeling problem, in the same way as part-of-speech tagging, chunking or shallow parsing. However, the use of a large number of features did not provide any significant improvements over a conventional small feature set. Bangalore et al. (2006) trained the lexical choice model by using Conditional Random Fields (CRF) realized on a WFST. Their modeling was reduced to M"
D07-1080,P06-1098,1,0.329931,"oice model by using Conditional Random Fields (CRF) realized on a WFST. Their modeling was reduced to Maximum Entropy Markov Model (MEMM) to handle a large number of features which, in turn, faced the labeling bias problem (Lafferty et al., 2001). Tillmann and Zhang (2006) trained their feature set using an online discriminative algorithm. Since the decoding is still expensive, their online training approach is approximated by enlarging a merged kbest list one-by-one with a 1-best output. Liang et al. (2006) introduced an averaged perceptron algorithm, but employed only 1-best translation. In Watanabe et al. (2006a), binary features were trained only on a small development set using a variant of voted perceptron for reranking k-best translations. Thus, the improvement is merely relative to the baseline translation system, namely whether or not there is a good translation in their k-best. We present a method to estimate a large number of parameters — of the order of millions — using an online training algorithm. Although it was intuitively considered to be prone to overfitting, training on a small development set — less than 1K sentences — was sufficient to achieve improved performance. In this method,"
D07-1080,P98-2230,0,0.0117577,"string of non-terminals. ∼ defines one-to-one mapping between non-terminals in γ and β. The use of phrase b¯ as a prefix maintains the strength of the phrasebase framework. A contiguous English side with a (possibly) discontiguous foreign language side preserves phrase-bounded local word reordering. At the same time, the target normalized framework still combines phrases hierarchically in a restricted manner. 2.3 Left-to-Right Target Generation Decoding is performed by parsing on the source side and by combining the projected target side. We applied an Earley-style top-down parsing approach (Wu and Wong, 1998; Watanabe et al., 2006b; Zollmann and Venugopal, 2006). The basic idea is to perform top-down parsing so that the projected target side is generated in a left-to-right manner. The search is guided with a push-down automaton, which keeps track of the span of uncovered source word positions. Combined with the rest-cost estimation aggregated in a bottom-up way, our decoder efficiently searches for the most likely translation. The use of a target normalized form further simplifies the decoding procedure. Since the rule form does not allow any holes for the target side, the integration with an n-g"
D07-1080,W06-3108,0,0.164848,"Word/hierarchical-phrase length penalties. • Backtrack-based penalties inspired by the distortion penalties in phrase-based modeling (Watanabe et al., 2006b). 3.2 Sparse Features In addition to the baseline features, a large number of binary features are integrated in our MT system. We may use any binary features, such as   English word “violate” and Arabic    1 word “tnthk” appeared in e and f . h( f, e) =     0 otherwise. The features are designed by considering the decoding efficiency and are based on the word alignment structure preserved in hierarchical phrase translation pairs (Zens and Ney, 2006). When hierarchical phrases are extracted, the word alignment is preserved. If multiple word alignments are observed 766 ei−1 f j−1 ei ei+1 fj ei+2 ei+3 f j+1 f j+2 ei+4 f j+3 Figure 1: An example of sparse features for a phrase translation. with the same source and target sides, only the frequently observed word alignment is kept to reduce the grammar size. 3.2.1 Word Pair Features Word pair features reflect the word correspondence in a hierarchical phrase. Figure 1 illustrates an example of sparse features for a phrase translation pair f j , ..., f j+2 and ei , ..., ei+3 1 . From the word al"
D07-1080,W06-3119,0,0.0385186,"one mapping between non-terminals in γ and β. The use of phrase b¯ as a prefix maintains the strength of the phrasebase framework. A contiguous English side with a (possibly) discontiguous foreign language side preserves phrase-bounded local word reordering. At the same time, the target normalized framework still combines phrases hierarchically in a restricted manner. 2.3 Left-to-Right Target Generation Decoding is performed by parsing on the source side and by combining the projected target side. We applied an Earley-style top-down parsing approach (Wu and Wong, 1998; Watanabe et al., 2006b; Zollmann and Venugopal, 2006). The basic idea is to perform top-down parsing so that the projected target side is generated in a left-to-right manner. The search is guided with a push-down automaton, which keeps track of the span of uncovered source word positions. Combined with the rest-cost estimation aggregated in a bottom-up way, our decoder efficiently searches for the most likely translation. The use of a target normalized form further simplifies the decoding procedure. Since the rule form does not allow any holes for the target side, the integration with an n-gram language model is straightforward: the prefixed phr"
D07-1080,P06-1096,0,\N,Missing
D07-1080,J03-1002,0,\N,Missing
D07-1080,2006.iwslt-evaluation.14,1,\N,Missing
D07-1080,C98-2225,0,\N,Missing
D10-1092,W05-0909,0,0.242163,"Missing"
D10-1092,W10-1749,0,0.0898134,"on of the square root to NKT imply that Chinese word order is close to that of English, and they have to measure subtle word order mistakes. 951 Table 3: NTCIR-7 √ meta-evaluation: Effects of square root (b(x) = 1 − 1 − x) √ NKT NKT b(NKT) Spearman w/ adequacy 0.940 0.940 0.922 Pearson w/ adequacy 0.922 0.817 0.941 Spearman w/ fluency 0.887 0.865 0.858 Pearson w/ fluency 0.931 0.917 0.833 In spite of these differences, the two groups independently recognized the usefulness of rank correlations for automatic evaluation of translation quality for distant language pairs. In their WMT-2010 paper (Birch and Osborne, 2010), they multiplied NKT with the brevity penalty and interpolated it with BLEU for the WMT-2010 shared task. This fact implies that incomprehensible or misleading word order mistakes are rare in translation among European languages. 6 Conclusions When Statistical Machine Translation is applied to distant language pairs such as Japanese and English, word order becomes an important problem. SMT systems often fail to find an appropriate translation because of a large search space. Therefore, they often output misleading or incomprehensible sentences such as “A because B” vs. “B because A.” To penal"
D10-1092,E06-1032,0,0.0197708,"a-evaluation of the NTCIR-7 PATMT JE task data shows that this metric outperforms conventional metrics. 1 Introduction Automatic evaluation of machine translation (MT) quality is essential to developing high-quality machine translation systems because human evaluation is time consuming, expensive, and irreproducible. If we have a perfect automatic evaluation metric, we can tune our translation system for the metric. BLEU (Papineni et al., 2002b; Papineni et al., 2002a) showed high correlation with human judgments and is still used as the de facto standard automatic evaluation metric. However, Callison-Burch et al. (2006) argued that the MT community is overly reliant on BLEU by showing examples of poor performance. For Japanese-to-English (JE) translation, Echizen-ya et al. (2009) showed that the popular BLEU and NIST do not work well by using the system outputs of the NTCIR-7 PATMT (patent translation) JE task (Fujii et al., 2008). On the other hand, ROUGE-L (Lin and Hovy, 2003), Word Error Rate (WER), and IMPACT (Echizen-ya and Araki, 2007) worked better. In these studies, Pearson’s correlation coefficient and Spearman’s rank correlation ρ with human evaluation scores are used to measure how closely an auto"
D10-1092,W07-0718,0,0.0467588,"f sentence-level scores. We used default settings for conventional metrics, but we tuned GTM (Melamed et al., 2007) with -e option. This option controls preferences on longer word runs. We also used the paraphrase database TERp (http://www.umiacs.umd. 949 edu/˜snover/terp) for METEOR (Banerjee and Lavie, 2005). 3.2 Meta-evaluation with WMT-07 data We developed our metric mainly for automatic evaluation of translation quality for distant language pairs such as Japanese-English, but we also want to know how well the metric works for similar language pairs. Therefore, we also use the WMT07 data (Callison-Burch et al., 2007) that covers only European language pairs. Callison-Burch et al. (2007) tried different human evaluation methods and showed detailed evaluation scores. The Europarl test set has 2,000 sentences, and The News Commentary test set has 2,007 sentences. This data has different language pairs: Spanish, French, German ⇒ English. We exclude CzechEnglish because there were so few systems (See the footnote of p. 146 in their paper). 4 4.1 Results Meta-evaluation with NTCIR-7 data Table 1 shows the main results of this paper. The left part has corpus-level meta-evaluation with adequacy. Error metrics, WE"
D10-1092,I05-2014,0,0.0369692,"l by using the system outputs of the NTCIR-7 PATMT (patent translation) JE task (Fujii et al., 2008). On the other hand, ROUGE-L (Lin and Hovy, 2003), Word Error Rate (WER), and IMPACT (Echizen-ya and Araki, 2007) worked better. In these studies, Pearson’s correlation coefficient and Spearman’s rank correlation ρ with human evaluation scores are used to measure how closely an automatic evaluation method correlates with human evaluation. This evaluation of automatic evaluation methods is called meta-evaluation. In human evaluation, people judge the adequacy and the fluency of each translation. Denoual and Lepage (2005) pointed out that BLEU assumes word boundaries, which is ambiguous in Japanese and Chinese. Here, we assume the word boundaries given by ChaSen, one of the standard morphological analyzers (http://chasenlegacy.sourceforge.jp/) following Fujii et al. (2008) In JE translation, most Statistical Machine Translation (SMT) systems translate the Japanese sentence (J0) kare wa sono hon wo yonda node sekaishi ni kyoumi ga atta which means 944 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 944–952, c MIT, Massachusetts, USA, 9-11 October 2010. 2010 Associat"
D10-1092,2007.mtsummit-papers.21,0,0.0340785,"eni et al., 2002b; Papineni et al., 2002a) showed high correlation with human judgments and is still used as the de facto standard automatic evaluation metric. However, Callison-Burch et al. (2006) argued that the MT community is overly reliant on BLEU by showing examples of poor performance. For Japanese-to-English (JE) translation, Echizen-ya et al. (2009) showed that the popular BLEU and NIST do not work well by using the system outputs of the NTCIR-7 PATMT (patent translation) JE task (Fujii et al., 2008). On the other hand, ROUGE-L (Lin and Hovy, 2003), Word Error Rate (WER), and IMPACT (Echizen-ya and Araki, 2007) worked better. In these studies, Pearson’s correlation coefficient and Spearman’s rank correlation ρ with human evaluation scores are used to measure how closely an automatic evaluation method correlates with human evaluation. This evaluation of automatic evaluation methods is called meta-evaluation. In human evaluation, people judge the adequacy and the fluency of each translation. Denoual and Lepage (2005) pointed out that BLEU assumes word boundaries, which is ambiguous in Japanese and Chinese. Here, we assume the word boundaries given by ChaSen, one of the standard morphological analyzers"
D10-1092,W10-1736,1,0.720649,") was designed to disregard word order completely. TER (Snover et al., 2006) was designed to allow phrase movements without large penalties. Therefore, these standard metrics are not optimal for evaluating translation between distant language pairs. In this paper, we propose an alternative automatic evaluation metric appropriate for distant language pairs. Our method is based on rank correlation coefficients. We use them to compare the word ranks in the reference with those in the hypothesis. There are two popular rank correlation coefficients: Spearman’s ρ and Kendall’s τ (Kendall, 1975). In Isozaki et al. (2010), we used Kendall’s τ to measure the effectiveness of our Head Finalization rule as a preprocessor for English-to-Japanese translation, but we measured the quality of translation by using conventional metrics. It is not clear how well τ works as an automatic evaluation metric of translation quality. Moreover, Spearman’s ρ might work better than Kendall’s τ . As we discuss later, τ considers only the direction of the rank change, whereas ρ considers the distance of the change. The first objective of this paper is to examine which is the better metric for distant language pairs. The second objec"
D10-1092,N03-1020,0,0.0120162,"tune our translation system for the metric. BLEU (Papineni et al., 2002b; Papineni et al., 2002a) showed high correlation with human judgments and is still used as the de facto standard automatic evaluation metric. However, Callison-Burch et al. (2006) argued that the MT community is overly reliant on BLEU by showing examples of poor performance. For Japanese-to-English (JE) translation, Echizen-ya et al. (2009) showed that the popular BLEU and NIST do not work well by using the system outputs of the NTCIR-7 PATMT (patent translation) JE task (Fujii et al., 2008). On the other hand, ROUGE-L (Lin and Hovy, 2003), Word Error Rate (WER), and IMPACT (Echizen-ya and Araki, 2007) worked better. In these studies, Pearson’s correlation coefficient and Spearman’s rank correlation ρ with human evaluation scores are used to measure how closely an automatic evaluation method correlates with human evaluation. This evaluation of automatic evaluation methods is called meta-evaluation. In human evaluation, people judge the adequacy and the fluency of each translation. Denoual and Lepage (2005) pointed out that BLEU assumes word boundaries, which is ambiguous in Japanese and Chinese. Here, we assume the word boundar"
D10-1092,P02-1040,0,0.100666,"ese metrics leads to inadequate translations. In this paper, we propose an automatic evaluation metric based on rank correlation coefficients modified with precision. Our meta-evaluation of the NTCIR-7 PATMT JE task data shows that this metric outperforms conventional metrics. 1 Introduction Automatic evaluation of machine translation (MT) quality is essential to developing high-quality machine translation systems because human evaluation is time consuming, expensive, and irreproducible. If we have a perfect automatic evaluation metric, we can tune our translation system for the metric. BLEU (Papineni et al., 2002b; Papineni et al., 2002a) showed high correlation with human judgments and is still used as the de facto standard automatic evaluation metric. However, Callison-Burch et al. (2006) argued that the MT community is overly reliant on BLEU by showing examples of poor performance. For Japanese-to-English (JE) translation, Echizen-ya et al. (2009) showed that the popular BLEU and NIST do not work well by using the system outputs of the NTCIR-7 PATMT (patent translation) JE task (Fujii et al., 2008). On the other hand, ROUGE-L (Lin and Hovy, 2003), Word Error Rate (WER), and IMPACT (Echizen-ya and A"
D10-1092,2006.amta-papers.25,0,0.103847,"evity Penalty (BP) min(1, exp(1 − r/h)), where r is the length of the reference and h is the length of the hypothesis. BLEU = BP × (p1 p2 p3 p4 )1/4 . Its range is [0, 1]. The BLEU score of (H0) with reference (R0) is 1.0×(11/11×9/10×6/9×4/8)1/4 = 0.740. Therefore, BLEU gives a very good score to this inadequate translation because it checks only ngrams and does not regard global word order. Since (R0) and (H0) look similar in terms of fluency, adequacy is more important than fluency in the translation between distant language pairs. Similarly, other popular scores such as NIST, PER, and TER (Snover et al., 2006) also give relatively good scores to this translation. NIST also considers only local word orders (n-grams). PER (Position-Independent Word Error Rate) was designed to disregard word order completely. TER (Snover et al., 2006) was designed to allow phrase movements without large penalties. Therefore, these standard metrics are not optimal for evaluating translation between distant language pairs. In this paper, we propose an alternative automatic evaluation metric appropriate for distant language pairs. Our method is based on rank correlation coefficients. We use them to compare the word ranks"
D10-1092,N03-2021,0,\N,Missing
D13-1139,P05-1033,0,0.11802,"uses rich syntax parsing features for word reordering and runs in linear time. We apply it to postordering of phrase-based machine translation (PBMT) for Japanese-to-English patent tasks. Our experimental results show that our method achieves a significant improvement of +3.1 BLEU scores against 30.15 BLEU scores of the baseline PBMT system. 1 Sourceordered. Target Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce parser for in"
D13-1139,P04-1015,0,0.056235,"wlef t1 of Y, and the rightmost word of phrase X is set to rightmost word wright0 of Z. Variable a is set to a1 of Y. The difference between reduce-MR-X and reduce-SR-X actions is new stack element s0 . The reduce-SR-X action generates s0 by combining s′0 and s′1 with binary rule X# →Y Z: s0 = {X# , h0 , wlef t0 , wright1 , a0 }. This action expands Y and Z in a reverse order, and the leftmost word of X# is set to wlef t0 of Z, and the rightmost word of X# is set to wright1 of Y. Variable a is set to a0 of Z. We use a linear model that is discriminatively trained with the averaged perceptron (Collins and Roark, 2004). Table 1 shows the feature templates used in our experiments and we call the features in the bottom two rows “non-local” features. # of sent. ave. leng. (J) ave. leng. (E) train dev test9 test10 3,191,228 36.4 33.3 2,000 36.6 33.3 2,000 37.0 33.7 2,300 43.1 39.6 Table 2: NTCIR-9 and 10 data statistics. 4 Experiments 4.1 Experimental Setups We conducted experiments for NTCIR-9 and 10 patent data using a Japanese-English language pair. Mecab2 was used for the Japanese morphological analysis. The data are summarized in Table 2. We used Enju (Miyao and Tsujii, 2008) for parsing the English traini"
D13-1139,P05-1066,0,0.27903,"Missing"
D13-1139,D11-1018,0,0.218258,"30.15 BLEU scores of the baseline PBMT system. 1 Sourceordered. Target Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce parser for inversion transduction grammars (ITG) (Wu, 1997). To the best of our knowledge, this is the first study on a shift-reduce parser for word reordering. The parser-based reordering approach uses rich syntax parsing features for reordering decisions. Our propoesd method can also easily define such non-local features a"
D13-1139,P06-1121,0,0.202823,"tax parsing features for word reordering and runs in linear time. We apply it to postordering of phrase-based machine translation (PBMT) for Japanese-to-English patent tasks. Our experimental results show that our method achieves a significant improvement of +3.1 BLEU scores against 30.15 BLEU scores of the baseline PBMT system. 1 Sourceordered. Target Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce parser for inversion transduction g"
D13-1139,P12-2061,0,0.351117,"arget Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce parser for inversion transduction grammars (ITG) (Wu, 1997). To the best of our knowledge, this is the first study on a shift-reduce parser for word reordering. The parser-based reordering approach uses rich syntax parsing features for reordering decisions. Our propoesd method can also easily define such non-local features as the N -gram words of reordered strings. Even when usin"
D13-1139,N04-1014,0,0.0387663,"ction grammars. Our model uses rich syntax parsing features for word reordering and runs in linear time. We apply it to postordering of phrase-based machine translation (PBMT) for Japanese-to-English patent tasks. Our experimental results show that our method achieves a significant improvement of +3.1 BLEU scores against 30.15 BLEU scores of the baseline PBMT system. 1 Sourceordered. Target Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce"
D13-1139,P10-1110,0,0.0256258,"j, S|s0 ⟩ : π where s′0 is {X, h, wlef t , wright , a} and s0 is {X, h, wlef t , wright , x} (i ≤ h, lef t, right < j). The side condition prevents the parser from inserting articles into phrase X more than twice. During parsing, articles are not explicitly inserted into the input string: they are inserted into it when backtracking to generate a reordered string after parsing. The reduce-MR-X action has a deduction rule: X→YZ∈P ∧q ∈π z q }| { : ⟨k, i, S|s′2 |s′1 ⟩ : π ′ ℓ : ⟨i, j, S|s′1 |s′0 ⟩ : π ℓ + 1 : ⟨k, j, S|s′2 |s0 ⟩ : π ′ 1 Since our notion of predictor states is identical to that in (Huang and Sagae, 2010), we omit the details here. 1384 s0 = {X, h0 , wlef t1 , wright0 , a1 }. New nonterminal X is lexicalized with head word wh0 of right nonterminal Z. This action expands Y and Z in a straight order. The leftmost word of phrase X is set to leftmost word wlef t1 of Y, and the rightmost word of phrase X is set to rightmost word wright0 of Z. Variable a is set to a1 of Y. The difference between reduce-MR-X and reduce-SR-X actions is new stack element s0 . The reduce-SR-X action generates s0 by combining s′0 and s′1 with binary rule X# →Y Z: s0 = {X# , h0 , wlef t0 , wright1 , a0 }. This action expa"
D13-1139,P07-2045,0,0.0104477,"ift-reduce parser for inversion transduction grammars. Our model uses rich syntax parsing features for word reordering and runs in linear time. We apply it to postordering of phrase-based machine translation (PBMT) for Japanese-to-English patent tasks. Our experimental results show that our method achieves a significant improvement of +3.1 BLEU scores against 30.15 BLEU scores of the baseline PBMT system. 1 Sourceordered. Target Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word r"
D13-1139,J08-1002,0,0.0206303,"with the averaged perceptron (Collins and Roark, 2004). Table 1 shows the feature templates used in our experiments and we call the features in the bottom two rows “non-local” features. # of sent. ave. leng. (J) ave. leng. (E) train dev test9 test10 3,191,228 36.4 33.3 2,000 36.6 33.3 2,000 37.0 33.7 2,300 43.1 39.6 Table 2: NTCIR-9 and 10 data statistics. 4 Experiments 4.1 Experimental Setups We conducted experiments for NTCIR-9 and 10 patent data using a Japanese-English language pair. Mecab2 was used for the Japanese morphological analysis. The data are summarized in Table 2. We used Enju (Miyao and Tsujii, 2008) for parsing the English training data and converted parse trees into HFE trees by a head-finalization scheme. We extracted grammar rules from all the HFE trees and randomly selected 500,000 HFE trees to train the shift-reduce parser. We used Moses (Koehn et al., 2007) with lexicalized reordering and a 6-gram language model (LM) trained using SRILM (Stolcke et al., 2011) to translate the Japanese sentences into HFE sentences. To recover the English sentences, our shift-reduce parser reordered only the 1-best HFE sentence. Our strategy is much simpler than Goto et al. (2012)’s because they used"
D13-1139,N07-1051,0,0.0337815,"articles “ga” “wo” “wa” into English sentences. We privilege the nonterminals of a phrase modified by a deleted article to determine which “the” “a/an” or “no articles” should be inserted at the front of the phrase. Note that an original English sentence can be recovered from its HFE tree by using # symbols and annotated articles and deleting Japanese particles. As well as Goto et al. (2012), we solve postordering by a parser whose model is trained with a set of HFE trees. The main difference between Goto et al. (2012)’s model and ours is that while the former simply used the Berkeley parser (Petrov and Klein, 2007), our shift-reduce parsing model can use such non-local task specific features as the N -gram words of reordered strings without sacrificing efficiency. Our method integrates postediting (Knight and Chander, 1994) with reordering and inserts articles into English translations by learning an additional “insert” action of the parser. Goto et al. (2012) solved the article generation problem by using an 1383 N -gram language model, but this somewhat complicates their approach. Compared with other parsers, one advantage of the shift-reduce parser is to easily define such additional operations as “i"
D13-1139,2011.mtsummit-papers.36,1,0.941844,". 1 Sourceordered. Target Sentence (HFE) Target Sentence (E) reordering Figure 1: A description of the postordering MT system. Introduction Even though phrase-based machine translation (PBMT) (Koehn et al., 2007) and tree-based MT (Graehl and Knight, 2004; Chiang, 2005; Galley et al., 2006) systems have achieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce parser for inversion transduction grammars (ITG) (Wu, 1997). To the best of our knowledge, this is the first study on a shift-reduce parser for word reordering. The parser-based reordering approach uses rich syntax parsing features for reordering decisions. Our propoesd method can also easily define such non-local features as the N -gram words of reordered str"
D13-1139,J97-3002,0,0.358339,"chieved great success, many problems remain for distinct language pairs, including long-distant word reordering. To improve such word reordering, one promising way is to separate it from the translation process as preordering (Collins et al., 2005; DeNero and Uszkoreit, 2011) or postordering (Sudoh et al., 2011; Goto et al., 2012). Many studies utilize a rulebased or a probabilistic model to perform a reordering decision at each node of a syntactic parse tree. This paper presents a parser-based word reordering model that employs a shift-reduce parser for inversion transduction grammars (ITG) (Wu, 1997). To the best of our knowledge, this is the first study on a shift-reduce parser for word reordering. The parser-based reordering approach uses rich syntax parsing features for reordering decisions. Our propoesd method can also easily define such non-local features as the N -gram words of reordered strings. Even when using these non-local features, the complexity of the shift-reduce parser does not increase at all due to give up achieving an optimal solution. Therefore, it works much more efficient. In our experiments, we apply our proposed method to postordering for J-to-E patent tasks becaus"
I05-1043,C00-1004,0,0.176137,"ame distance as the one in step 1. The highest ranking candidate is then presented to the user. Instance-Based Generation 5.2 491 Corpus Preprocessing Since Japanese does not provide word segmentation, we need to preprocess the corpus. The corpus consists of a set of dialogues. Each dialogue consists of a set of utterances. Each utterance is annotated for speaker and utterance type. In a dialogue, wizard and user utterance strictly alternate, with no interjections. Preprocessing is done as follows. Each utterance is stripped of its annotations and presented to the part-of-speech tagger Chasen [1]. Chasen segments the input sentence, reduces inﬂected words to their base forms and assigns part of speech tags to the base forms. We use the notation cw(u) to designate the content words in utterance, sentence or newspaper article u. For our purposes, content words are adjectives, nouns and verbs, de-inﬂected to their base form, if necessary. A subsequent processing step assigns semantic labels and named entity classes to the de-inﬂected word forms. 5.3 Sentence Selection In order to understand the motivation for our approaches to sentence selection, it is necessary to recall the context in"
I05-1043,P03-2028,1,0.384612,"ighly structured dialogue cards give the developers more control (at the price of a higher development cost) over the systems behavior than our method and is therefore less risky in situations where failure is expensive. In Small et al [8], retrieved documents are forced into frame structures. Mismatches or between the ﬁllers of the frame structures or missing ﬁllers trigger information seeking questions to the user. While the generation as it is actually used is not described in the paper, we believe that the frames provide suﬃcient structure for template-based approaches. Hori and coworkers [4] developed an interactive question answering system based on a Japanese newspaper corpus. The purpose of information seeking questions is to prompt the user for missing or disambiguating information. From a generation point of view, strong assumptions are made on the surface form of the generated information seeking question. More speciﬁcally, ambiguous keywords are combined with disambiguating options by means of the Japanese particle ’no’. 7.2 Summary To summarize, the presented approaches attempt in diﬀerent ways to compensate for the lack of structure in an question answering system. Struc"
I05-1043,C02-1084,0,0.425515,"om a database of unstructured text. (2) As in spoken dialogue systems, the system can interactively query for more information in the case of vague or ill-deﬁned user queries. 1.2 Problem Addressed in This Paper Restricted domain question answering systems can be deployed in interactive problem solving solutions, for example, software trouble shooting. In these scenarios, interactivity becomes a necessity. This is because it is highly unlikely that all facts relevant to retrieving the appropriate response are stated in the query. For example, in the software trouble shooting task described in [5], a frequent system generated information seeking question is for the version of the software. Therefore, R. Dale et al. (Eds.): IJCNLP 2005, LNAI 3651, pp. 486–497, 2005. c Springer-Verlag Berlin Heidelberg 2005  Instance-Based Generation 487 there is a need to inquire additional problem relevant information from the user, depending on the interaction history and the problem to be solved. In this paper, we speciﬁcally address the problem of how to generate information seeking questions in the case of ambiguous, vague or ill-deﬁned user questions. We assume that the decision of whether an inf"
I05-1043,P98-1116,0,0.037696,"ar on the use of parallel retrieval schemes to enable retrieval without conventional index selection. One aspect of memory-based systems is to choose a distance that appropriately selects candidate exemplars. Memory-based reasoning has been applied to machine translation, parsing, unit selection text-to-speech synthesis, part-of-speech tagging, and others. An overview of memory-based approaches to natural language processing can be found in the introduction to the special issue [2]. 2.2 Statistical and Instance-Based Generation The most prominent example for statistical generation is Nitrogen [6]. This system has been designed to allows large scale generation while requiring only a minimal knowledge base. An abstract meaning representation is turned into a lattice of surface sentences using a simple keyword based grammar. Using statistical information acquired from a corpus, the sentences in the lattices are re-ranked to determine the optimal surface string. More recently, example-based natural language generation using a corpus was proposed [11]. It is assumed in this work that content determination has already taken place and the input has been broken down to sentence-size pieces. T"
I05-1043,W00-0306,0,0.0306725,"from the IR subsystem, 2. A decision for a information seeking question Produce An information seeking question. Problems of this kind have appeared traditionally in task oriented spoken dialogue systems, where missing information needs to be prompted. However, in the case of spoken dialogue systems, question generation is typically not a substantial problem: the fact that the back-end is well-structured allows for simple template-based generation in many cases. For example, missing values for database queries or remote method invocations can be queried that way. (But see also Oh and Rudnicky [7] or Walker et al [12] for more elaborated approaches to generation for spoken dialogue systems). In our case, however, a template-based approach is unrealistic. This is due to the unstructured back-end application. Unlike as spoken dialogue systems, we cannot make assumptions over what kind of questions to ask as this is determined by the result set of articles as returned by the information retrieval engine. Existing interactive question-answering systems (see section 7.1 for a more detailed description) either use canned text on dialogue cards [5], break down the dialogue representation into"
I05-1043,C04-1189,0,0.150893,"eneration for spoken dialogue systems). In our case, however, a template-based approach is unrealistic. This is due to the unstructured back-end application. Unlike as spoken dialogue systems, we cannot make assumptions over what kind of questions to ask as this is determined by the result set of articles as returned by the information retrieval engine. Existing interactive question-answering systems (see section 7.1 for a more detailed description) either use canned text on dialogue cards [5], break down the dialogue representation into frames and then techniques from spoken dialogue systems [8], or make simplifying assumptions to the extent that generation essentially becomes equivalent to template-based generation. 1.3 Proposed Solution For reasons discussed above, we propose an example-based approach to generation. More speciﬁcally, we use an existing dialogue corpus to retrieve appropriate questions and modify in order to ﬁt the situation at hand. We describe two algorithms for instance-based natural language questions generation by ﬁrst selecting appropriate candidates from the corpus, then modifying the candidates to ﬁt the situation at hand, and ﬁnally re-rank the candidates."
I05-1043,P03-1005,0,0.14489,"paces. Furthermore, let x and y be two structured objects, and x = x1 , . . . , xD and y = y1 , . . . , yD their parts. The relation R ⊆ X1 × . . . × XD × X holds for x and x if x are the parts of x. The inverse R−1 maps each structured object onto its parts, i.e. R−1 (x) = {x : R(x, x)}. Then the kernel of x and y is given by the following generalized convolution: D    K(x, y) = Kd (xd , yd ) x∈R−1 (x) y∈R−1 (y) 1 Informally, the value of a convolution kernel for two objects X and Y is given by the sum of the kernel value for each of the substructures, i.e. their convolution. Suzuki et al [10] proposed Hierarchical Directed Acyclic Graph kernels in which the substructures contain nodes which can contain graphs themselves. The hierarchy of graphs allows extended information from multiple components to be represented and used in classiﬁcation. In addition, nodes may be annotated with attributes, such as part of speech tags, in order to add information. For example, in a Question-Answering system, components such as Named Entity Extraction, Question Classiﬁcation, Chunking and so on may each add to the graph. 4 Corpus We collected a corpus for our instance based generation system as f"
I05-1043,N01-1001,0,0.0215059,"ion to the special issue [2]. 2.2 Statistical and Instance-Based Generation The most prominent example for statistical generation is Nitrogen [6]. This system has been designed to allows large scale generation while requiring only a minimal knowledge base. An abstract meaning representation is turned into a lattice of surface sentences using a simple keyword based grammar. Using statistical information acquired from a corpus, the sentences in the lattices are re-ranked to determine the optimal surface string. More recently, example-based natural language generation using a corpus was proposed [11]. It is assumed in this work that content determination has already taken place and the input has been broken down to sentence-size pieces. The approach is to use a learned grammar to generate a list of candidates using a traditional chart based generation algorithm. The grammar is learned using statistical methods. During generation, edges that are added to the chart are ranked depending on their distance to the closest instance in the example base. This is where the memory-based approach comes into play. In order to allow for careful generalization in the instance base, the authors propose t"
I05-1043,N01-1003,0,0.0123814,"m, 2. A decision for a information seeking question Produce An information seeking question. Problems of this kind have appeared traditionally in task oriented spoken dialogue systems, where missing information needs to be prompted. However, in the case of spoken dialogue systems, question generation is typically not a substantial problem: the fact that the back-end is well-structured allows for simple template-based generation in many cases. For example, missing values for database queries or remote method invocations can be queried that way. (But see also Oh and Rudnicky [7] or Walker et al [12] for more elaborated approaches to generation for spoken dialogue systems). In our case, however, a template-based approach is unrealistic. This is due to the unstructured back-end application. Unlike as spoken dialogue systems, we cannot make assumptions over what kind of questions to ask as this is determined by the result set of articles as returned by the information retrieval engine. Existing interactive question-answering systems (see section 7.1 for a more detailed description) either use canned text on dialogue cards [5], break down the dialogue representation into frames and then tech"
I05-1043,C98-1112,0,\N,Missing
I11-1004,J08-1002,0,0.059746,"show that our proposal can significantly improve BLEU scores of 2.47∼3.15 points compared with using the original English sentences. We finally conclude this paper by summarizing our proposal and the experiment results. Specially, for English-to-Japanese translation, Isozaki et al. (2010b) proposed to move syntactic or semantic heads to the end of corresponding phrases or clauses so that to yield head finalized English (HFE) sentences which follow the word order of Japanese. The head information of an English sentence is detected by a head-driven phrase structure grammar (HPSG) parser, Enju1 (Miyao and Tsujii, 2008). In addition, transformation rules were manually written for appending particle seed words, refining POS tags to be used before parsing, and deleting English determiners. Due to the usage of the same parser, we take this HFE approach as one of our baseline systems. The goal in this paper, however, is to learn preordering rules from parallel data in an automatic way. Under this motivation, pre-ordering rules can be extracted in a language-independent manner. A number of researches follow this automatic way. For example, in (Xia and McCord, 2004), a variety of heuristic rules were applied to bi"
I11-1004,J03-1002,0,0.00568597,"ese sentences into SVO-style English sentences. For comparison, our proposal 1) makes use of not only PASs but also the source syntactic tree structures for preordering rule matching, 2) extracts pre-ordering 1 Figure 1 shows a word-aligned HPSG-tree-tostring pair for English-to-Japanese translation. PASs among lexical nodes and their argument nodes in this HPSG tree are described by arrows in thick-lines. For simplicity, we only draw the identifiers for the signs of the nodes in the HPSG tree. Note that the identifiers that start with ‘c’ 2 These word alignments are gained by running GIZA++ (Och and Ney, 2003) on the original parallel sentences. http://www-tsujii.is.s.u-tokyo.ac.jp/enju/index.html 30 c0 &lt;tok id=t0 cat=SC pos=WRB base=when lexentry=[when] pred=conj_arg12 arg1=c16 arg2=c3&gt; c0 c1 c1 c3 &lt;cons id=c16 cat=S xcat= head=c18 sem_head=c18 schema=mod_head&gt; t0 &lt;cons id=c3 cat=S xcat= head=c13 sem_head=c13 schema=subj_head&gt; c18 c6 c21 c8 c13 c10 c7 c5 c3 c2 c16 c4 c2 c16 c9 c11 t0 t1 t2 t3 when the fluid pressure c12 t4 cylinder t6 31 is c23 c15 c17 c20 c14 t5 c19 t7 t8 t9 used , c22 c24 c25 t10 t11 t12 is gradually applied fluid . 流体 圧 シリンダ 31 の 場合 は 流体 が 徐々に 排出 さ れる こと と なる 。 0 1 fluid pressu"
I11-1004,P05-1033,0,0.0598702,"otone or reordering) with probabilities for each bilingual phrase from the training data. For example, by taking lexical information as features, a maximum entropy phrase reordering model was proposed by Xiong et al. (2006). Second, syntax-based models attempt to solve the word ordering problem by employing syntactic structures. For example, linguistically syntaxbased approaches (Galley et al., 2004; Liu et al., 2006) first parse source and/or target sentences and then learn reordering templates from the subtree fragments of the parse trees. In contrast, hierarchical phrase based translation (Chiang, 2005) is a formally syntax-based approach which can automatically extract hierarchical ordering rules from aligned string-string pairs without using additional parsers. These approaches have been proved to be both algorithmically appealing and empirically successful. However, most of current syntax-based SMT systems use IBM models (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) to generate word alignments. These models have a penalty parameter associated with long distance jumps, and tend to misalign words which move far from the window sizes of their expected positions (Xu"
I11-1004,P03-1021,0,0.0213618,"topological order do if n is a terminal node then n.srcPhrase ← E[n.srcSpan[0]] else if n.srcPhrase = NULL then n.srcPhrase ← C ONNECT(n.children().srcPhrase) end if end for 3 Experiments 3.1 Setup We test our proposal by translating from English to Japanese. We use the NTCIR-9 English-Japanese patent corpus4 as our experiment set. Since the reference set of the official test set has not been released yet, we instead split the original development set averagely into two parts, named dev.a and dev.b. In our experiments, we first take dev.a as our development set for minimum-error rate tuning (Och, 2003) and then report the final translation accuracies on dev.b. For direct comparison with other systems in the future, we use the configuration of the official baseline system5 : • Moses6 (Koehn et al., 2007): revision = “3717” as the baseline decoder. Note that we also train Moses using HFE sentences (Isozaki et al., 2010b) and the English sentences pre-ordered by PASs; Algorithm 2 sketches the algorithm for applying pre-ordering rules to a given HPSG tree TE . The algorithm contains three parts: rule matching (Lines 4-12), bottom-up rule applying (Lines 13-19), and sentence collecting (Lines 20"
I11-1004,P05-1066,0,0.180454,"jumps, and tend to misalign words which move far from the window sizes of their expected positions (Xu et al., 2009; Genzel, 2010). The third type tackles the word-order problem in pre-ordering ways. Through the usage of a sequence of pre-ordering rules, the word order of an original source sentence is (approximately) changed into the word order of the target sentence. Here, the pre-ordering rules can be manually or automatically extracted. For manual extraction of pre-ordering rules, linguistic background and expertise are required for predetermined language pairs, such as for GermanEnglish (Collins et al., 2005), Chinese-to-English (Wang et al., 2007), Japanese-to-English (KatzBrown and Collins, 2007), and English-to-SOV languages (Xu et al., 2009). Word ordering remains as an essential problem for translating between languages with substantial structural differences, such as SOV and SVO languages. In this paper, we propose to automatically extract pre-ordering rules from predicateargument structures. A pre-ordering rule records the relative position mapping of a predicate word and its argument phrases from the source language side to the target language side. We propose 1) a lineartime algorithm to"
I11-1004,P02-1040,0,0.0821751,"Missing"
I11-1004,N04-1035,0,0.311955,"mmunication Science Laboratories, NTT Corporation 2-4 Hikaridai Seika-cho, Soraku-gun Kyoto 619-0237 Japan {wu.xianchao,sudoh.katsuhito,kevin.duh,tsukada.hajime,nagata.masaaki}@lab.ntt.co.jp Abstract orientations (monotone or reordering) with probabilities for each bilingual phrase from the training data. For example, by taking lexical information as features, a maximum entropy phrase reordering model was proposed by Xiong et al. (2006). Second, syntax-based models attempt to solve the word ordering problem by employing syntactic structures. For example, linguistically syntaxbased approaches (Galley et al., 2004; Liu et al., 2006) first parse source and/or target sentences and then learn reordering templates from the subtree fragments of the parse trees. In contrast, hierarchical phrase based translation (Chiang, 2005) is a formally syntax-based approach which can automatically extract hierarchical ordering rules from aligned string-string pairs without using additional parsers. These approaches have been proved to be both algorithmically appealing and empirically successful. However, most of current syntax-based SMT systems use IBM models (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et"
I11-1004,C10-1043,0,0.299656,"syntax-based approach which can automatically extract hierarchical ordering rules from aligned string-string pairs without using additional parsers. These approaches have been proved to be both algorithmically appealing and empirically successful. However, most of current syntax-based SMT systems use IBM models (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) to generate word alignments. These models have a penalty parameter associated with long distance jumps, and tend to misalign words which move far from the window sizes of their expected positions (Xu et al., 2009; Genzel, 2010). The third type tackles the word-order problem in pre-ordering ways. Through the usage of a sequence of pre-ordering rules, the word order of an original source sentence is (approximately) changed into the word order of the target sentence. Here, the pre-ordering rules can be manually or automatically extracted. For manual extraction of pre-ordering rules, linguistic background and expertise are required for predetermined language pairs, such as for GermanEnglish (Collins et al., 2005), Chinese-to-English (Wang et al., 2007), Japanese-to-English (KatzBrown and Collins, 2007), and English-to-S"
I11-1004,2007.tmi-papers.21,0,0.143543,"Missing"
I11-1004,D10-1092,1,0.904154,"Missing"
I11-1004,N04-4026,0,0.272773,"Missing"
I11-1004,W10-1736,1,0.754264,", in order to overcome the shortages of traditional distance based distortion models (Brown et al., 1993; Koehn et al., 2007), phrase dependent lexicalized reordering models were proposed by several researchers (Tillman, 2004; Kumar and Byrne, 2005). Lexicalized reordering models learn local 29 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 29–37, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP rules in an automatic way, and 3) use factored representations of syntactic features to refine the preordering rules. Following (Wu et al., 2010a; Isozaki et al., 2010b), we use the HPSG parser Enju to generate the PASs of English sentences. HPSG (Pollard and Sag, 1994) is a lexicalist grammar framework. In HPSG, linguistic entities such as words and phrases are represented by a data structure called a sign. A sign gives a factored representation of the syntactic features of a word/phrase, as well as a representation of their semantic content which corresponds to PASs. In order to record the relative positions among a predicate word and its argument phrases, we propose a linear-time algorithm to extract preordering rules from word-aligned HPSG-tree-tostring"
I11-1004,C96-2141,0,0.339493,"al., 2004; Liu et al., 2006) first parse source and/or target sentences and then learn reordering templates from the subtree fragments of the parse trees. In contrast, hierarchical phrase based translation (Chiang, 2005) is a formally syntax-based approach which can automatically extract hierarchical ordering rules from aligned string-string pairs without using additional parsers. These approaches have been proved to be both algorithmically appealing and empirically successful. However, most of current syntax-based SMT systems use IBM models (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) to generate word alignments. These models have a penalty parameter associated with long distance jumps, and tend to misalign words which move far from the window sizes of their expected positions (Xu et al., 2009; Genzel, 2010). The third type tackles the word-order problem in pre-ordering ways. Through the usage of a sequence of pre-ordering rules, the word order of an original source sentence is (approximately) changed into the word order of the target sentence. Here, the pre-ordering rules can be manually or automatically extracted. For manual extraction of pre-ordering rules, linguistic b"
I11-1004,D07-1077,0,0.403469,"e far from the window sizes of their expected positions (Xu et al., 2009; Genzel, 2010). The third type tackles the word-order problem in pre-ordering ways. Through the usage of a sequence of pre-ordering rules, the word order of an original source sentence is (approximately) changed into the word order of the target sentence. Here, the pre-ordering rules can be manually or automatically extracted. For manual extraction of pre-ordering rules, linguistic background and expertise are required for predetermined language pairs, such as for GermanEnglish (Collins et al., 2005), Chinese-to-English (Wang et al., 2007), Japanese-to-English (KatzBrown and Collins, 2007), and English-to-SOV languages (Xu et al., 2009). Word ordering remains as an essential problem for translating between languages with substantial structural differences, such as SOV and SVO languages. In this paper, we propose to automatically extract pre-ordering rules from predicateargument structures. A pre-ordering rule records the relative position mapping of a predicate word and its argument phrases from the source language side to the target language side. We propose 1) a lineartime algorithm to extract the pre-ordering rules from word"
I11-1004,P10-1034,1,0.926742,"dering ways. First, in order to overcome the shortages of traditional distance based distortion models (Brown et al., 1993; Koehn et al., 2007), phrase dependent lexicalized reordering models were proposed by several researchers (Tillman, 2004; Kumar and Byrne, 2005). Lexicalized reordering models learn local 29 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 29–37, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP rules in an automatic way, and 3) use factored representations of syntactic features to refine the preordering rules. Following (Wu et al., 2010a; Isozaki et al., 2010b), we use the HPSG parser Enju to generate the PASs of English sentences. HPSG (Pollard and Sag, 1994) is a lexicalist grammar framework. In HPSG, linguistic entities such as words and phrases are represented by a data structure called a sign. A sign gives a factored representation of the syntactic features of a word/phrase, as well as a representation of their semantic content which corresponds to PASs. In order to record the relative positions among a predicate word and its argument phrases, we propose a linear-time algorithm to extract preordering rules from word-ali"
I11-1004,P07-2045,0,0.0692904,"eline SMT systems. 1 Introduction Statistical machine translation (SMT) suffers from an essential problem for translating between languages with substantial structural differences, such as between English which is a subject-verbobject (SVO) language and Japanese which is a typical subject-object-verb (SOV) language. Numerous approaches have been consequently proposed to tackle this word-order problem, such as lexicalized reordering methods, syntax-based models, and pre-ordering ways. First, in order to overcome the shortages of traditional distance based distortion models (Brown et al., 1993; Koehn et al., 2007), phrase dependent lexicalized reordering models were proposed by several researchers (Tillman, 2004; Kumar and Byrne, 2005). Lexicalized reordering models learn local 29 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 29–37, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP rules in an automatic way, and 3) use factored representations of syntactic features to refine the preordering rules. Following (Wu et al., 2010a; Isozaki et al., 2010b), we use the HPSG parser Enju to generate the PASs of English sentences. HPSG (Pollard and Sag, 1994) i"
I11-1004,2006.iwslt-evaluation.11,1,0.751145,"is that, predicate-argument structures (PASs) are introduced to extract fine-grained pre-ordering rules. PASs have the following merits for describing reordering phenomena: • predicate words and argument phrases respectively record reordering phenomena in a lexicalized level and an abstract level; • PASs provide a fine-grained classification of the reordering phenomena since they include factored representations of syntactic features of the predicate words and their argument phrases. 2 Pre-ordering Rule Extraction and Application 2.1 An example The idea of using PASs for pre-ordering follows (Komachi et al., 2006). Several reordering operations were manually designed by Komachi et al. (2006) to pre-ordering Japanese sentences into SVO-style English sentences. For comparison, our proposal 1) makes use of not only PASs but also the source syntactic tree structures for preordering rule matching, 2) extracts pre-ordering 1 Figure 1 shows a word-aligned HPSG-tree-tostring pair for English-to-Japanese translation. PASs among lexical nodes and their argument nodes in this HPSG tree are described by arrows in thick-lines. For simplicity, we only draw the identifiers for the signs of the nodes in the HPSG tree."
I11-1004,C04-1073,0,0.419443,"phrase structure grammar (HPSG) parser, Enju1 (Miyao and Tsujii, 2008). In addition, transformation rules were manually written for appending particle seed words, refining POS tags to be used before parsing, and deleting English determiners. Due to the usage of the same parser, we take this HFE approach as one of our baseline systems. The goal in this paper, however, is to learn preordering rules from parallel data in an automatic way. Under this motivation, pre-ordering rules can be extracted in a language-independent manner. A number of researches follow this automatic way. For example, in (Xia and McCord, 2004), a variety of heuristic rules were applied to bilingual parse trees to extract pre-ordering rules for French-English translation. Rottmann and Vogen (2007) learned reordering rules based on sequences of part-of-speech (POS) tags, instead of parse trees. Dependency trees were used by Genzel (2010) to extract source-side reordering rules for translating languages from SVO to SOV, etc.. The novel idea expressed in this paper is that, predicate-argument structures (PASs) are introduced to extract fine-grained pre-ordering rules. PASs have the following merits for describing reordering phenomena:"
I11-1004,P06-1066,0,0.17735,"Missing"
I11-1004,H05-1021,0,0.0214174,"between languages with substantial structural differences, such as between English which is a subject-verbobject (SVO) language and Japanese which is a typical subject-object-verb (SOV) language. Numerous approaches have been consequently proposed to tackle this word-order problem, such as lexicalized reordering methods, syntax-based models, and pre-ordering ways. First, in order to overcome the shortages of traditional distance based distortion models (Brown et al., 1993; Koehn et al., 2007), phrase dependent lexicalized reordering models were proposed by several researchers (Tillman, 2004; Kumar and Byrne, 2005). Lexicalized reordering models learn local 29 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 29–37, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP rules in an automatic way, and 3) use factored representations of syntactic features to refine the preordering rules. Following (Wu et al., 2010a; Isozaki et al., 2010b), we use the HPSG parser Enju to generate the PASs of English sentences. HPSG (Pollard and Sag, 1994) is a lexicalist grammar framework. In HPSG, linguistic entities such as words and phrases are represented by a data structure"
I11-1004,N09-1028,0,0.247032,"05) is a formally syntax-based approach which can automatically extract hierarchical ordering rules from aligned string-string pairs without using additional parsers. These approaches have been proved to be both algorithmically appealing and empirically successful. However, most of current syntax-based SMT systems use IBM models (Brown et al., 1993) and hidden Markov model (HMM) (Vogel et al., 1996) to generate word alignments. These models have a penalty parameter associated with long distance jumps, and tend to misalign words which move far from the window sizes of their expected positions (Xu et al., 2009; Genzel, 2010). The third type tackles the word-order problem in pre-ordering ways. Through the usage of a sequence of pre-ordering rules, the word order of an original source sentence is (approximately) changed into the word order of the target sentence. Here, the pre-ordering rules can be manually or automatically extracted. For manual extraction of pre-ordering rules, linguistic background and expertise are required for predetermined language pairs, such as for GermanEnglish (Collins et al., 2005), Chinese-to-English (Wang et al., 2007), Japanese-to-English (KatzBrown and Collins, 2007), a"
I11-1004,J93-2003,0,\N,Missing
I11-1153,N09-2019,0,0.0494692,"Missing"
I11-1153,P09-1064,0,0.033943,"4 is the N-best approximation commonly used in practice: N (f ) contains the set of hypotheses in the N-best list, and the argmin and sum is only performed within this finite set. There are two difficulties with Eq. 4: 1. The N-best approximation is much smaller than the true space of all English hypotheses in the argmin and sum of Eq. 3. The approximation in the argmin causes search errors, while the approximation in the sum introduces bias. This problem can be somewhat mitigated by increasing the N-best list size or extending this space using lattices and hypergraphs (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009). We do not address this issue here. 2. The posterior probability p(e|f ) in Eq.3 and Eq. 4 refers to the true posterior probability arising from Ep(e,f ) [·] in the derivation of Eq. 2. In practice, this can only be estimated from the MT decoder’s model scores: P (exp i λi hi (e, f ))α P p(e|f ) ≈ P ′ α e′ ∈N (f ) (exp i λi hi (e , f )) (5) where hi (e, f ) are features, λi are feature weights, and α is a scaling factor that determines the flatness of the posterior distribution (Ehling et al., 2007). It is important to emphasize that we are assuming that the decoder’s sco"
I11-1153,C10-1036,0,0.0320563,"Missing"
I11-1153,P07-2026,0,0.0184181,"extending this space using lattices and hypergraphs (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009). We do not address this issue here. 2. The posterior probability p(e|f ) in Eq.3 and Eq. 4 refers to the true posterior probability arising from Ep(e,f ) [·] in the derivation of Eq. 2. In practice, this can only be estimated from the MT decoder’s model scores: P (exp i λi hi (e, f ))α P p(e|f ) ≈ P ′ α e′ ∈N (f ) (exp i λi hi (e , f )) (5) where hi (e, f ) are features, λi are feature weights, and α is a scaling factor that determines the flatness of the posterior distribution (Ehling et al., 2007). It is important to emphasize that we are assuming that the decoder’s score is an accurate surrogate for the true posterior distribution p(e|f ). The second difficulty poses a particular problem for system combination. Although the assumption in Eq. 5 is reasonable for single-system MT, it becomes P unclear how to compare the model scores i λi hi (e, f ) in a multi-system setting. To illustrate, consider two MT systems, their 2-best lists, and corresponding model scores: • System A: e1 , score=7; e2 , score=3; • System B: e3 , score=90; e4 , score=10; It is unclear what is the ranking of post"
I11-1153,E06-1005,0,0.124381,"Missing"
I11-1153,P08-1023,0,0.0352485,"satisfy the relations (Eq. 10) in its constraints while allowing for some slack ξ, whose amount depends on hyperparameter c. 1358 4 Experiments We experiment with the NTCIR-9 (2011) Englishto-Japanese Patent Translation task1 . This includes 3 million sentences for training individual MT systems; the official dev set is split into 1000 sentences for MERT of individual systems, 500 for system combination optimization (MBR, GMBR), and 500 for final evaluation. We combine three systems: • Phrase-based Moses with lexical reordering, distortion=6 (Koehn and others, 2007) • Forest-to-string system (Mi et al., 2008) • Weighted finite-state Transducer (WFST) (Zhou et al., 2006) with rule-based reordering as preprocessing (Isozaki et al., 2010b). Each system generates a 100-best list, so our system combination task involves hypothesis selection out of 300 hypotheses. As evaluation measure, we focus on BLEU, Normalized Kendall’s Tau (NKT), a metric that has been shown to correlate well with humans on this language pair (Isozaki et al., 2010a)2 , and a combination thereof. The loss function used for MBR is therefore the sum of BLEU and NKT. For GMBR, the sub-components of this loss function are derived from"
I11-1153,N07-1029,0,0.0560152,"Missing"
I11-1153,D08-1065,0,0.0343379,"BR) decision rule. Eq. 4 is the N-best approximation commonly used in practice: N (f ) contains the set of hypotheses in the N-best list, and the argmin and sum is only performed within this finite set. There are two difficulties with Eq. 4: 1. The N-best approximation is much smaller than the true space of all English hypotheses in the argmin and sum of Eq. 3. The approximation in the argmin causes search errors, while the approximation in the sum introduces bias. This problem can be somewhat mitigated by increasing the N-best list size or extending this space using lattices and hypergraphs (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009). We do not address this issue here. 2. The posterior probability p(e|f ) in Eq.3 and Eq. 4 refers to the true posterior probability arising from Ep(e,f ) [·] in the derivation of Eq. 2. In practice, this can only be estimated from the MT decoder’s model scores: P (exp i λi hi (e, f ))α P p(e|f ) ≈ P ′ α e′ ∈N (f ) (exp i λi hi (e , f )) (5) where hi (e, f ) are features, λi are feature weights, and α is a scaling factor that determines the flatness of the posterior distribution (Ehling et al., 2007). It is important to emphasize that we are assuming t"
I11-1153,D08-1011,0,0.0385247,"k e Lk (e k=1 θk Ck (e ), where P|e) =′ Ck (e′ ) = L (e |e) represents the come k ′ bined loss for e . So we first compute Ck (·) for all hypotheses, for an O(|N (f )|2 ) run-time. To find the GMBR P decision then requires a ′ search arg mine′ ∈N (f ) K k=1 θk Ck (e ). So in test, GMBR is on the same order as conventional MBR. To tune θ, we first extract all pairs of hypotheses where a difference exists in the true loss, then optimize θ in a formulation similar to RankSVM (Joachims, 2006). The pair-wise nature of Eq. 10 makes the problem amenable to solutions in “learning to rank” literature (He et al., 2008a). The pseudocode is shown in Algorithm 1. The RankSVM (line 8) tries to satisfy the relations (Eq. 10) in its constraints while allowing for some slack ξ, whose amount depends on hyperparameter c. 1358 4 Experiments We experiment with the NTCIR-9 (2011) Englishto-Japanese Patent Translation task1 . This includes 3 million sentences for training individual MT systems; the official dev set is split into 1000 sentences for MERT of individual systems, 500 for system combination optimization (MBR, GMBR), and 500 for final evaluation. We combine three systems: • Phrase-based Moses with lexical reo"
I11-1153,D10-1092,1,0.905756,"Missing"
I11-1153,W10-1736,1,0.870667,"Missing"
I11-1153,P07-2045,0,0.00573936,"Missing"
I11-1153,N04-1022,0,0.0385613,"e loss function in MBR and allows it to be optimized in the given hypothesis space of multiple systems. This extension better approximates the true Bayes Risk decision rule and empirically improves over MBR, even in cases where the combined systems are of mixed quality. 1 Introduction Minimum Bayes Risk (MBR) is a theoreticallyelegant decision rule that has been used for singlesystem decoding and system combination in machine translation (MT). MBR arose in Bayes decision theory (Duda et al., 2000) and has since been applied to speech recognition (Goel and Byrne, 2000) and machine translation (Kumar and Byrne, 2004). The idea is to choose hypotheses that minimize Bayes Risk as oppose to those that maximize posterior probability. This enables the use of taskspecific loss functions (e.g BLEU). However, the definition of Bayes Risk depends critically on the posterior probability of hypotheses. In single-system decoding, one could approximate this probability using model scores. However, for system combination, the various systems 2 The Difficulty with MBR Consider the task of translation from a French sentence (f ) to an English sentence (e). Our goal is to find a decision rule δ(f ) → e′ , which takes f as"
I11-1153,P09-1019,0,0.0167692,"oximation commonly used in practice: N (f ) contains the set of hypotheses in the N-best list, and the argmin and sum is only performed within this finite set. There are two difficulties with Eq. 4: 1. The N-best approximation is much smaller than the true space of all English hypotheses in the argmin and sum of Eq. 3. The approximation in the argmin causes search errors, while the approximation in the sum introduces bias. This problem can be somewhat mitigated by increasing the N-best list size or extending this space using lattices and hypergraphs (Tromble et al., 2008; DeNero et al., 2009; Kumar et al., 2009). We do not address this issue here. 2. The posterior probability p(e|f ) in Eq.3 and Eq. 4 refers to the true posterior probability arising from Ep(e,f ) [·] in the derivation of Eq. 2. In practice, this can only be estimated from the MT decoder’s model scores: P (exp i λi hi (e, f ))α P p(e|f ) ≈ P ′ α e′ ∈N (f ) (exp i λi hi (e , f )) (5) where hi (e, f ) are features, λi are feature weights, and α is a scaling factor that determines the flatness of the posterior distribution (Ehling et al., 2007). It is important to emphasize that we are assuming that the decoder’s score is an accurate sur"
P03-2028,C02-1169,0,\N,Missing
P06-1078,W03-0430,0,0.0527793,"Missing"
P06-1078,H01-1034,0,0.251074,"Hikaridai, Seika-cho, Keihanna Science City, Kyoto 619-0237, Japan {sudoh,tsukada,isozaki}@cslab.kecl.ntt.co.jp Abstract expressions and their categories. Unlike text data, speech data introduce automatic speech recognition (ASR) error problems to NER. Although improvements to ASR are needed, developing a robust NER for noisy word sequences is also important. In this paper, we focus on the NER of ASR results and discuss the suppression of ASR error problems in NER. Most previous studies of the NER of speech data used generative models such as hidden Markov models (HMMs) (Miller et al., 1999; Palmer and Ostendorf, 2001; Horlock and King, 2003b; B´echet et al., 2004; Favre et al., 2005). On the other hand, in text-based NER, better results are obtained using discriminative schemes such as maximum entropy (ME) models (Borthwick, 1999; Chieu and Ng, 2003), support vector machines (SVMs) (Isozaki and Kazawa, 2002), and conditional random fields (CRFs) (McCallum and Li, 2003). Zhai et al. (2004) applied a text-level ME-based NER to ASR results. These models have an advantage in utilizing various features, such as part-of-speech information, character types, and surrounding words, which may be overlapped, while o"
P06-1078,C00-2167,0,0.0542981,"Missing"
P06-1078,W98-1120,0,0.0374624,", especially in precision, compared to simply applying text-based NER to the ASR results. 2 Manual transcription Speech data Transcriptions ASR ASR results NE labeling NE-labeled transcriptions Setting ASR confidence feature to 1 SVM-based NER Text-based training data NER is a kind of chunking problem that can be solved by classifying words into NE classes that consist of name categories and such chunking states as PERSON-BEGIN (the beginning of a person’s name) and LOCATION-MIDDLE (the middle of a location’s name). Many discriminative methods have been applied to NER, such as decision trees (Sekine et al., 1998), ME models (Borthwick, 1999; Chieu and Ng, 2003), and CRFs (McCallum and Li, 2003). In this paper, we employ an SVM-based NER method in the following way that showed good NER performance in Japanese (Isozaki and Kazawa, 2002). We define three features for each word: the word itself, its part-of-speech tag, and its character type. We also use those features for the two preceding and succeeding words for context dependence and use 15 features when classifying a word. Each feature is represented by a binary value (1 or 0), for example, “whether the previous word is Japan,” and each word is class"
P06-1078,W03-0423,0,0.163739,"to NER. Although improvements to ASR are needed, developing a robust NER for noisy word sequences is also important. In this paper, we focus on the NER of ASR results and discuss the suppression of ASR error problems in NER. Most previous studies of the NER of speech data used generative models such as hidden Markov models (HMMs) (Miller et al., 1999; Palmer and Ostendorf, 2001; Horlock and King, 2003b; B´echet et al., 2004; Favre et al., 2005). On the other hand, in text-based NER, better results are obtained using discriminative schemes such as maximum entropy (ME) models (Borthwick, 1999; Chieu and Ng, 2003), support vector machines (SVMs) (Isozaki and Kazawa, 2002), and conditional random fields (CRFs) (McCallum and Li, 2003). Zhai et al. (2004) applied a text-level ME-based NER to ASR results. These models have an advantage in utilizing various features, such as part-of-speech information, character types, and surrounding words, which may be overlapped, while overlapping features are hard to use in HMM-based models. To deal with ASR error problems in NER, Palmer and Ostendorf (2001) proposed an HMMbased NER method that explicitly models ASR errors using ASR confidence and rejects erroneous word"
P06-1078,N04-4010,0,0.0913895,"on the NER of ASR results and discuss the suppression of ASR error problems in NER. Most previous studies of the NER of speech data used generative models such as hidden Markov models (HMMs) (Miller et al., 1999; Palmer and Ostendorf, 2001; Horlock and King, 2003b; B´echet et al., 2004; Favre et al., 2005). On the other hand, in text-based NER, better results are obtained using discriminative schemes such as maximum entropy (ME) models (Borthwick, 1999; Chieu and Ng, 2003), support vector machines (SVMs) (Isozaki and Kazawa, 2002), and conditional random fields (CRFs) (McCallum and Li, 2003). Zhai et al. (2004) applied a text-level ME-based NER to ASR results. These models have an advantage in utilizing various features, such as part-of-speech information, character types, and surrounding words, which may be overlapped, while overlapping features are hard to use in HMM-based models. To deal with ASR error problems in NER, Palmer and Ostendorf (2001) proposed an HMMbased NER method that explicitly models ASR errors using ASR confidence and rejects erroneous word hypotheses in the ASR results. Such rejection is especially effective when ASR accuracy is relatively low because many misrecognized words m"
P06-1078,H05-1062,0,0.023325,"Missing"
P06-1078,C02-1054,1,\N,Missing
P06-1098,P05-1066,0,0.0109351,"n Chinese engineers , construction design and construction methods of the recipient from . The Health and Welfare Ministry has decided to invoke the Disaster Relief Law in extending relief measures to the village and the city of Niigata . The Health and Welfare Ministry in that the Japanese people in the village are made law . The Health and Welfare Ministry decided to apply the Disaster Relief Law to the village in Niigata . Figure 3: Sample translations from two systems: Phrase and Normalized-2 as a set of rules that reorders the foreign language to match with English language sequentially. Collins et al. (2005) presented a method with hand-coded rules. Our method directly learns such serialization rules from a bilingual corpus without linguistic clues. The translation quality presented in Section 5 are rather low due to the limited size of the bilingual corpus, and also because of the linguistic difference of two languages. As our future work, we are in the process of experimenting our model for other languages with rich resources, such as Chinese and Arabic, as well as similar language pairs, such as French and English. Additional feature functions will be also investigated that were proved success"
P06-1098,W05-1507,0,0.0389301,"n-terminals in γ and α that are associated with ∼. Chiang (2005) proposed a hierarchical phrasebased translation model, a binary synchronousCFG, which restricted the form of production rules as follows: The integration with a ngram language model further increases the cost of decoding especially when incorporating a higher order ngram, such as 5-gram. In the hierarchical phrase-based model (Chiang, 2005), and an inversion transduction grammar (ITG) (Wu, 1997), the problem is resolved by restricting to a binarized form where at most two non-terminals are allowed in the righthand side. However, Huang et al. (2005) reported that the computational complexity for decoding amounted to O(J 3+3(n−1) ) with n-gram even using a hook technique. The complexity lies in memorizing the ngram’s context for each constituent. The order of ngram would be a dominant factor for higher order ngrams. • Only two types of non-terminals allowed: S and X. • Both of the strings γ and α must contain at least one terminal item. • Rules may have at most two non-terminals but non-terminals cannot be adjacent for the foreign language side γ. As an alternative to a binarized form, we present a target-normalized hierarchical phrasebas"
P06-1098,N03-1017,0,0.316076,"1I , f1J ) is a feature function, such as a ngram language model or a translation model. When decoding, the denominator is dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likely approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003). This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al., 2003; Zens and Ney, 2003; Tillman, 2004). The idea is based on a word-based source channel modeling of Brown et al. (1993): It assumes that e1I is segmented into a sequence of K phrases e¯ 1K . Each phrase e¯ k is transformed into f¯k . The translated phrases are reordered to form f1J . One of the benefits of the modeling is that the phrase translation unit preserves localized word reordering. However, it cannot hypothesize a long-distance reordering required for linguistically divergent language pairs. For instance, when translating Japanese to English, a Japanese SOV structure has to be reordere"
P06-1098,W04-3250,0,0.0419224,"Missing"
P06-1098,P02-1038,0,0.0250315,"pled with our top down parser implies a left-toright generation of translations which enables us a straightforward integration with ngram language models. Our model was experimented on a Japanese-to-English newswire translation task, and showed statistically significant performance improvements against a phrase-based translation system. 1 where hm (e1I , f1J ) is a feature function, such as a ngram language model or a translation model. When decoding, the denominator is dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likely approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003). This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al., 2003; Zens and Ney, 2003; Tillman, 2004). The idea is based on a word-based source channel modeling of Brown et al. (1993): It assumes that e1I is segmented into a sequence of K phrases e¯ 1K . Each phrase e¯ k is transformed into f¯k . The translated"
P06-1098,J03-1002,0,0.00440966,"ls but non-terminals cannot be adjacent for the foreign language side γ. As an alternative to a binarized form, we present a target-normalized hierarchical phrasebased translation model. The model is a class of a hierarchical phrase-based model, but constrained so that the English part of the right-hand side The production rules are induced from a bilingual corpus with the help of word alignments. To alleviate a data sparseness problem, glue rules are 778 added that prefer combining hierarchical phrases in a serial manner: D E S → S 1 X2 , S 1 X2 (5) E D (6) S → X1 , X1 model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Koehn et al., 2003). Second, phrase translation pairs are extracted from the word alignment corpus (Koehn et al., 2003). The method exhaustively extracts phrase j+m J I pairs ( f j , ei+n i ) from a sentence pair ( f1 , e1 ) that do not violate the word alignment constraints a: where boxed indices indicate non-terminal’s linkages represented in ∼. Our model is based on Chiang (2005)’s framework, but further restricts the form of production rules so that the aligned right-hand side α follows a GNF-like structure: D E ¯ ∼ X"
P06-1098,N04-4026,0,0.119691,"Missing"
P06-1098,J93-2003,0,0.00796207,"or is dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likely approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003). This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al., 2003; Zens and Ney, 2003; Tillman, 2004). The idea is based on a word-based source channel modeling of Brown et al. (1993): It assumes that e1I is segmented into a sequence of K phrases e¯ 1K . Each phrase e¯ k is transformed into f¯k . The translated phrases are reordered to form f1J . One of the benefits of the modeling is that the phrase translation unit preserves localized word reordering. However, it cannot hypothesize a long-distance reordering required for linguistically divergent language pairs. For instance, when translating Japanese to English, a Japanese SOV structure has to be reordered to match with an En1 Introduction In a classical statistical machine translation, a foreign language sentence f1J ="
P06-1098,P05-1033,0,0.605252,"ram language model is straightforward, since the model generates a translation in left-to-right order. Our decoder is based on an Earley-style top down parsing on the foreign language side. The projected English-side is generated in left-to-right order synchronized with the derivation of the foreign language side. The decoder’s implementation is taken after a decoder for an existing phrase-based model with a simple modification to account for production rules. Experimental results on a Japanese-toEnglish newswire translation task showed significant improvement against a phrase-based modeling. Chiang (2005) introduced a hierarchical phrasebased translation model that combined the strength of the phrase-based approach and a synchronous-CFG formalism (Aho and Ullman, 1969): A rewrite system initiated from a start symbol which synchronously rewrites paired nonterminals. Their translation model is a binarized synchronous-CFG, or a rank-2 of synchronousCFG, in which the right-hand side of a production rule contains at most two non-terminals. The form can be regarded as a phrase translation pair with at most two holes instantiated with other phrases. The hierarchically combined phrases provide a sort"
P06-1098,P03-1010,0,0.00564793,"f D, and height(Di ) and width(Di ) refer the height and width of subtree Di , respectively. In Figure 1(b), for instance, a rule of X 1 with non-terminals X 2 and X 4 , two rules X 2 and X 3 spanning two terminal symbols should be backtracked to proceed to X 4 . The rationale is that positive scaling factors prefer a deeper structure whereby negative scaling factors prefer a monotonized structure. 4.5 The bilingual corpus used for our experiments was obtained from an automatically sentence aligned Japanese/English Yomiuri newspaper corpus consisting of 180K sentence pairs (refer to Table 1) (Utiyama and Isahara, 2003). From one-toone aligned sentences, 1,500 sentence pairs were sampled for a development set and a test set1 . Since the bilingual corpus is rather small, especially for the newspaper translation domain, Japanese/English dictionaries consisting of 1.3M entries were added into a training set to alleviate an OOV problem2 . Word alignments were annotated by a HMM translation model (Och and Ney, 2003). After Length-based Models Three trivial length-based feature functions were used in our experiment. hl (e1I ) = I (21) hr (D) = rule(D) (22) h p (D) = phrase(D) (23) 1 Japanese sentences were segment"
P06-1098,J97-3002,0,0.208821,"ectively. ∼ is a one-to-one correspondence for the non-terminals appeared in γ and α. Starting from an initial non-terminal, each rule rewrites non-terminals in γ and α that are associated with ∼. Chiang (2005) proposed a hierarchical phrasebased translation model, a binary synchronousCFG, which restricted the form of production rules as follows: The integration with a ngram language model further increases the cost of decoding especially when incorporating a higher order ngram, such as 5-gram. In the hierarchical phrase-based model (Chiang, 2005), and an inversion transduction grammar (ITG) (Wu, 1997), the problem is resolved by restricting to a binarized form where at most two non-terminals are allowed in the righthand side. However, Huang et al. (2005) reported that the computational complexity for decoding amounted to O(J 3+3(n−1) ) with n-gram even using a hook technique. The complexity lies in memorizing the ngram’s context for each constituent. The order of ngram would be a dominant factor for higher order ngrams. • Only two types of non-terminals allowed: S and X. • Both of the strings γ and α must contain at least one terminal item. • Rules may have at most two non-terminals but no"
P06-1098,P03-1019,0,0.100533,"ure function, such as a ngram language model or a translation model. When decoding, the denominator is dropped since it depends only on f1J . Feature function scaling factors λm are optimized based on a maximum likely approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003). This modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted. A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al., 2003; Zens and Ney, 2003; Tillman, 2004). The idea is based on a word-based source channel modeling of Brown et al. (1993): It assumes that e1I is segmented into a sequence of K phrases e¯ 1K . Each phrase e¯ k is transformed into f¯k . The translated phrases are reordered to form f1J . One of the benefits of the modeling is that the phrase translation unit preserves localized word reordering. However, it cannot hypothesize a long-distance reordering required for linguistically divergent language pairs. For instance, when translating Japanese to English, a Japanese SOV structure has to be reordered to match with an E"
P06-1098,P03-1021,0,\N,Missing
P09-2086,D07-1090,0,0.558593,"responds to its node position in the unigram table, we can remove the word ids for the first order. Our implementation merges across different orders of N -grams, then separates into multiple tables such as word ids, smoothed probabilities, back-off coefficients, and pointers. The starting positions of different orders are memorized to allow access to arbitrary orders. To store N -gram counts, we use three tables for word ids, counts and pointers. We share the same tables for word ids and pointers with additional probability and back-off coefficient tables. To support distributed computation (Brants et al., 2007), we further split the N -gram data into “shards” by hash values of the first bigram. Unigram data are shared across shards for efficiency. 3 an imaginary super root node emits 10 for its only child, i.e., the root node. After the root node, its first child or node 1 follows. Since (M + 1)0s and M 1s are emitted for a trie with M nodes, LOUDS occupies 2M + 1 bits. We define a basic operation on the bit string. sel1 (i) returns the position of the i-th 1. We can also define similar operations over zero bit strings, sel0 (i). Given selb , we define two operations for a node x. parent(x) gives x’"
P09-2086,D07-1021,0,0.0512316,"xperimented with English Web 1T 5-gram from LDC consisting of 25 GB of gzipped raw text N -gram counts. By using 8-bit floating point quantization 1 , N -gram language models are compressed into 10 GB, which is comparable to a lossy representation (Talbot and Brants, 2008). Introduction There has been an increase in available N -gram data and a large amount of web-scaled N -gram data has been successfully deployed in statistical machine translation. However, we need either a machine with hundreds of gigabytes of memory or a large computer cluster to handle them. Either pruning (Stolcke, 1998; Church et al., 2007) or lossy randomizing approaches (Talbot and Brants, 2008) may result in a compact representation for the application run-time. However, the lossy approaches may reduce accuracy, and tuning is necessary. A lossless approach is obviously better than a lossy one if other conditions are the same. In addtion, a lossless approach can easly combined with pruning. Therefore, lossless representation of N -gram is a key issue even for lossy approaches. Raj and Whittaker (2003) showed a general N gram language model structure and introduced a lossless algorithm that compressed a sorted integer vector by"
P09-2086,P08-1058,0,0.0116879,"f probability pointer Figure 1: Data structure for language model and LOUDS succinctly represents it by a 2M + 1 bit string. The space is further reduced by considering the N -gram structure. We also use variable length coding and block-wise compression to compress the values associated with each node, such as word ids, probabilities or counts. We experimented with English Web 1T 5-gram from LDC consisting of 25 GB of gzipped raw text N -gram counts. By using 8-bit floating point quantization 1 , N -gram language models are compressed into 10 GB, which is comparable to a lossy representation (Talbot and Brants, 2008). Introduction There has been an increase in available N -gram data and a large amount of web-scaled N -gram data has been successfully deployed in statistical machine translation. However, we need either a machine with hundreds of gigabytes of memory or a large computer cluster to handle them. Either pruning (Stolcke, 1998; Church et al., 2007) or lossy randomizing approaches (Talbot and Brants, 2008) may result in a compact representation for the application run-time. However, the lossy approaches may reduce accuracy, and tuning is necessary. A lossless approach is obviously better than a lo"
P09-2086,W07-0712,0,\N,Missing
P12-1001,P07-1111,0,0.0175966,"tion of BLEU/TER is the most common technique (Zaidan, 2009), sometimes achieving good results in evaluation campaigns (Dyer et al., 2009). As far as we known, the only work that directly proposes a multi-objective technique is (He and Way, 2009), which modifies MERT to optimize a single metric subject to the constraint that it does not degrade others. These approaches all require some setting of constraint strength or combination weights {pk }. Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M`arquez, 2008) and may give insights for setting {pk }. We view our Pareto-based approach as orthogonal to these efforts. The tunability of metrics is a problem that is gaining recognition (Liu et al., 2011). If a good evaluation metric could not be used for tuning, it would be a pity. The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al., 2011). (Mauser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEU-TER being amenable. One unsolved question is whether metric tunabi"
P12-1001,W11-2103,0,0.162556,"These methods are effective because they tune the system to maximize an automatic evaluation metric such as BLEU, which serve as surrogate objective for translation quality. However, we know that a single metric such as BLEU is not enough. Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive. As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation metrics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good t"
P12-1001,N10-1080,0,0.0600026,"in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M`arquez, 2008) and may give insights for setting {pk }. We view our Pareto-based approach as orthogonal to these efforts. The tunability of metrics is a problem that is gaining recognition (Liu et al., 2011). If a good evaluation metric could not be used for tuning, it would be a pity. The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al., 2011). (Mauser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEU-TER being amenable. One unsolved question is whether metric tunability is a problem inherent to the metric only, or depends also on the underlying optimization algorithm. Our positive results with PMO suggest that the choice of optimization algorithm can help. Multi-objective ideas are being explored in other NLP areas. (Spitkovsky et al., 2011) describe a technique that alternates between hard and soft EM objectives in order to achieve better local optimum in grammar induction. (Hall et al., 2011) investigates joint"
P12-1001,N09-1025,0,0.0389566,", so the method not only learns to discriminate pareto vs. non-pareto but also also learns to discriminate among competing non-pareto points. Also, like other MT works, in line 5 the N-best list is concatenated to N-best lists from previous iterations, so {h} is a set with i · N elements. General PMO Approach: The strategy we outlined in Section 3.2 can be easily applied to other MT optimization techniques. For example, by replacing the optimization subroutine (line 10, Algorithm 2) with a Powell search (Och, 2003), one can get PMO-MERT4 . Alternatively, by using the largemargin optimizer in (Chiang et al., 2009) and moving it into the for-each loop (lines 4-9), one can get an online algorithm such PMO-MIRA. Virtually all MT optimization algorithms have a place where metric scores feedback into the optimization procedure; the idea of PMO is to replace these raw scores with labels derived from Pareto optimality. 4 Experiments 4.1 Evaluation Methodology We experiment with two datasets: (1) The PubMed task is English-to-Japanese translation of scientific 4 A difference with traditional MERT is the necessity of sentence-BLEU (Liang et al., 2006) in line 6. We use sentenceBLEU for optimization but corpus-B"
P12-1001,W09-0426,0,0.266662,"ts. In this case, we recommend the following trick: Set up a multi-objective problem where one metric is BLEU and the other is 3/4BLEU+1/4RIBES. This encourages PMO to explore the joint metric space but avoid solutions that sacrifice too much BLEU, and should also outperform Linear Combination that searches only on the (3/4,1/4) direction. 5 How many Pareto points? The number of pareto 7 Related Work Multi-objective optimization for MT is a relatively new area. Linear-combination of BLEU/TER is the most common technique (Zaidan, 2009), sometimes achieving good results in evaluation campaigns (Dyer et al., 2009). As far as we known, the only work that directly proposes a multi-objective technique is (He and Way, 2009), which modifies MERT to optimize a single metric subject to the constraint that it does not degrade others. These approaches all require some setting of constraint strength or combination weights {pk }. Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M`arquez, 2008) and may give insights for setting {pk }. We view our Pareto-based approach as orthogona"
P12-1001,I08-1042,0,0.0478355,"Missing"
P12-1001,D11-1138,0,0.0324528,"auser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEU-TER being amenable. One unsolved question is whether metric tunability is a problem inherent to the metric only, or depends also on the underlying optimization algorithm. Our positive results with PMO suggest that the choice of optimization algorithm can help. Multi-objective ideas are being explored in other NLP areas. (Spitkovsky et al., 2011) describe a technique that alternates between hard and soft EM objectives in order to achieve better local optimum in grammar induction. (Hall et al., 2011) investigates joint optimization of a supervised parsing objective and some extrinsic objectives based on downstream applications. (Agarwal et al., 2011) considers using multiple signals (of varying quality) from online users to train recommendation models. (Eisner and Daum´e III, 2011) trades off speed and accuracy of a parser with reinforcement learning. None of the techniques in NLP use Pareto concepts, however. 6 Opportunities and Limitations We introduce a new approach (PMO) for training MT systems on multiple metrics. Leveraging the diverse perspectives of different evaluation metrics ha"
P12-1001,2009.mtsummit-posters.8,0,0.158214,"and the other is 3/4BLEU+1/4RIBES. This encourages PMO to explore the joint metric space but avoid solutions that sacrifice too much BLEU, and should also outperform Linear Combination that searches only on the (3/4,1/4) direction. 5 How many Pareto points? The number of pareto 7 Related Work Multi-objective optimization for MT is a relatively new area. Linear-combination of BLEU/TER is the most common technique (Zaidan, 2009), sometimes achieving good results in evaluation campaigns (Dyer et al., 2009). As far as we known, the only work that directly proposes a multi-objective technique is (He and Way, 2009), which modifies MERT to optimize a single metric subject to the constraint that it does not degrade others. These approaches all require some setting of constraint strength or combination weights {pk }. Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M`arquez, 2008) and may give insights for setting {pk }. We view our Pareto-based approach as orthogonal to these efforts. The tunability of metrics is a problem that is gaining recognition (Liu et al., 2011). I"
P12-1001,D11-1125,0,0.225156,"Our approach is based on the theory of Pareto Optimality. It is simple to implement on top of existing single-objective optimization methods (e.g. MERT, PRO) and outperforms ad hoc alternatives based on linear-combination of metrics. We also discuss the issue of metric tunability and show that our Pareto approach is more effective in incorporating new metrics from MT evaluation for MT optimization. 1 Introduction Weight optimization is an important step in building machine translation (MT) systems. Discriminative optimization methods such as MERT (Och, 2003), MIRA (Crammer et al., 2006), PRO (Hopkins and May, 2011), and Downhill-Simplex (Nelder and Mead, 1965) have been influential in improving MT systems in recent years. These methods are effective because they tune the system to maximize an automatic evaluation metric such as BLEU, which serve as surrogate objective for translation quality. However, we know that a single metric such as BLEU is not enough. Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluat"
P12-1001,D10-1092,1,0.861646,"nce & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive. As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation metrics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good translation. The current approach of optimizing MT towards a single metric runs the risk of sacrificing other metrics. Can we really claim that a system is good if it has high BLEU, but very low METEOR? Similarly, is a high-METEOR low-BLEU system desirable? Our goal is to propose a multi-objective optimization method that avoids “overfitting to a single metric”. We want to build a MT system"
P12-1001,P07-2045,0,0.0130597,"Missing"
P12-1001,W07-0734,0,0.0337259,"s BLEU is not enough. Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive. As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation metrics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good translation. The current approach of optimizing MT towards a single metric runs the risk of sacrificing other metrics. Can we really claim that a system is good if it has high BLEU, but very low METEOR? Similarly, is"
P12-1001,P06-1096,0,0.0438141,"RT4 . Alternatively, by using the largemargin optimizer in (Chiang et al., 2009) and moving it into the for-each loop (lines 4-9), one can get an online algorithm such PMO-MIRA. Virtually all MT optimization algorithms have a place where metric scores feedback into the optimization procedure; the idea of PMO is to replace these raw scores with labels derived from Pareto optimality. 4 Experiments 4.1 Evaluation Methodology We experiment with two datasets: (1) The PubMed task is English-to-Japanese translation of scientific 4 A difference with traditional MERT is the necessity of sentence-BLEU (Liang et al., 2006) in line 6. We use sentenceBLEU for optimization but corpus-BLEU for evaluation here. 5 abstracts. As metrics we use BLEU and RIBES (which demonstrated good human correlation in this language pair (Goto et al., 2011)). (2) The NIST task is Chinese-to-English translation with OpenMT08 training data and MT06 as devset. As metrics we use BLEU and NTER. • BLEU = BP × (Πprecn )1/4 . BP is brevity penality. precn is precision of n-gram matches. 1/4 • RIBES = (τ + 1)/2 × prec1 , with Kendall’s τ computed by measuring permutation between matching words in reference and hypothesis5 . • NTER=max(1−TER,"
P12-1001,N07-1006,0,0.0190011,"w area. Linear-combination of BLEU/TER is the most common technique (Zaidan, 2009), sometimes achieving good results in evaluation campaigns (Dyer et al., 2009). As far as we known, the only work that directly proposes a multi-objective technique is (He and Way, 2009), which modifies MERT to optimize a single metric subject to the constraint that it does not degrade others. These approaches all require some setting of constraint strength or combination weights {pk }. Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M`arquez, 2008) and may give insights for setting {pk }. We view our Pareto-based approach as orthogonal to these efforts. The tunability of metrics is a problem that is gaining recognition (Liu et al., 2011). If a good evaluation metric could not be used for tuning, it would be a pity. The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al., 2011). (Mauser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEU-TER being amenable. One unsolved question"
P12-1001,D11-1035,0,0.262905,"a choice between picking the best weight according to BLEU (BLEU=.265,RIBES=.665) vs. another weight with higher RIBES but poorer BLEU, e.g. (.255,.675). Nevertheless, both the PMO and Linear-Combination with various (p1 , p2 ) samples this joint-objective space broadly. 3. Interestingly, a multi-objective approach can sometimes outperform a single-objective optimizer in its own metric. In Figure 2, singleobjective PRO focusing on optimizing RIBES only achieves 0.68, but PMO-PRO using both BLEU and RIBES outperforms with 0.685. The third observation relates to the issue of metric tunability (Liu et al., 2011). We found that RIBES can be difficult to tune directly. It is an extremely non-smooth objective with many local optima–slight changes in word ordering causes large changes in RIBES. So the best way to improve RIBES is to 6 0.694 0.146 0.148 0.15 0.152 0.154 0.156 0.158 0.16 0.162 0.164 bleu Figure 3: NIST Results not to optimize it directly, but jointly with a more tunable metric BLEU. The learning curve in Figure 4 show that single-objective optimization of RIBES quickly falls into local optimum (at iteration 3) whereas PMO can zigzag and sacrifice RIBES in intermediate iterations (e.g. iter"
P12-1001,D08-1076,0,0.0416377,"f combination weights. Further we observe that multiobjective approaches can be helpful for optimizing difficult-to-tune metrics; this is beneficial for quickly introducing new metrics developed in MT evaluation into MT optimization, especially when good {pk } are not yet known. We conclude by drawing attention to some limitations and opportunities raised by this work: Limitations: (1) The performance of PMO is limited by the size of the Pareto set. Small N-best lists lead to sparsely-sampled Pareto Frontiers, and a much better approach would be to enlarge the hypothesis space using lattices (Macherey et al., 2008). How to compute Pareto points directly from lattices is an interesting open research question. (2) The binary distinction between pareto vs. non-pareto points ignores the fact that 2nd-place non-pareto points may also lead to good practical solutions. A better approach may be to adopt a graded definition of Pareto optimality as done in some multi-objective works (Deb et al., 2002). (3) A robust evaluation methodology that enables significance testing for multi-objective problems is sorely needed. This will make it possible to compare multi-objective methods on more than 2 metrics. We also nee"
P12-1001,mauser-etal-2008-automatic,0,0.138462,"ts {pk }. Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M`arquez, 2008) and may give insights for setting {pk }. We view our Pareto-based approach as orthogonal to these efforts. The tunability of metrics is a problem that is gaining recognition (Liu et al., 2011). If a good evaluation metric could not be used for tuning, it would be a pity. The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al., 2011). (Mauser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEU-TER being amenable. One unsolved question is whether metric tunability is a problem inherent to the metric only, or depends also on the underlying optimization algorithm. Our positive results with PMO suggest that the choice of optimization algorithm can help. Multi-objective ideas are being explored in other NLP areas. (Spitkovsky et al., 2011) describe a technique that alternates between hard and soft EM objectives in order to achieve better local optimum in grammar induction. (Hall et al., 2011)"
P12-1001,P03-1021,0,0.424427,"e diverse aspects to improve overall quality. Our approach is based on the theory of Pareto Optimality. It is simple to implement on top of existing single-objective optimization methods (e.g. MERT, PRO) and outperforms ad hoc alternatives based on linear-combination of metrics. We also discuss the issue of metric tunability and show that our Pareto approach is more effective in incorporating new metrics from MT evaluation for MT optimization. 1 Introduction Weight optimization is an important step in building machine translation (MT) systems. Discriminative optimization methods such as MERT (Och, 2003), MIRA (Crammer et al., 2006), PRO (Hopkins and May, 2011), and Downhill-Simplex (Nelder and Mead, 1965) have been influential in improving MT systems in recent years. These methods are effective because they tune the system to maximize an automatic evaluation metric such as BLEU, which serve as surrogate objective for translation quality. However, we know that a single metric such as BLEU is not enough. Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While ma"
P12-1001,W07-0714,0,0.0433798,"Missing"
P12-1001,P02-1040,0,0.0840642,"e for translation quality. However, we know that a single metric such as BLEU is not enough. Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive. As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation metrics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good translation. The current approach of optimizing MT towards a single metric runs the risk of sacrificing other metrics. Can we really claim that"
P12-1001,2010.iwslt-evaluation.1,0,0.022396,"ecause they tune the system to maximize an automatic evaluation metric such as BLEU, which serve as surrogate objective for translation quality. However, we know that a single metric such as BLEU is not enough. Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive. As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation metrics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good translation. T"
P12-1001,2006.amta-papers.25,0,0.0542521,"ect correlation with human judgments of translation quality. ∗ *Now at Nara Institute of Science & Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive. As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation metrics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good translation. The current approach of optimizing MT towards a single metric runs the risk of sacrificing other metrics. Can we really claim that a system is good if it has high BLEU, but very low METEOR? Similarly, is a high-METEOR low-BLEU system desirable? Our goal is to propose a multi-objective o"
P12-1001,D11-1117,0,0.0468041,"not be used for tuning, it would be a pity. The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al., 2011). (Mauser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEU-TER being amenable. One unsolved question is whether metric tunability is a problem inherent to the metric only, or depends also on the underlying optimization algorithm. Our positive results with PMO suggest that the choice of optimization algorithm can help. Multi-objective ideas are being explored in other NLP areas. (Spitkovsky et al., 2011) describe a technique that alternates between hard and soft EM objectives in order to achieve better local optimum in grammar induction. (Hall et al., 2011) investigates joint optimization of a supervised parsing objective and some extrinsic objectives based on downstream applications. (Agarwal et al., 2011) considers using multiple signals (of varying quality) from online users to train recommendation models. (Eisner and Daum´e III, 2011) trades off speed and accuracy of a parser with reinforcement learning. None of the techniques in NLP use Pareto concepts, however. 6 Opportunities and Limit"
P12-2020,W06-2920,0,0.0329395,"ee of an example sentence. ‘*’/ ‘+’=syntactic/semantic heads. Arrows in red (upper)= PASs, orange (bottom)=word-level dependencies generated from PASs, blue=newly appended dependencies. both during rule extracting and target dependency language model (LM) training. 2.2 Dependency parsing Graph-based and transition-based are two predominant paradigms for data-driven dependency parsing. The MST parser (McDonald et al., 2005) and the Malt parser (Nivre, 2003) stand for two typical parsers, respectively. Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011). Here, we compare them on the SMT tasks through parsing the real-world SMT data. 2.3 PCFG parsing For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007). In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool3 written by Johansson and Nugues (2007). The head finding rules4 are according to Magerman (1995) and Collins (1997). Similar approach has been originally used by Shen et al. (2008). 2.4 HPSG parsing In the Enju English HPSG grammar (Miyao et al., 2003)"
P12-2020,J07-4004,0,0.0657609,"tsuhito@lab.ntt.co.jp, kevinduh@is.naist.jp,{tsukada.hajime,nagata.masaaki}@lab.ntt.co.jp Abstract tures. For example, using the constituent-todependency conversion approach proposed by Johansson and Nugues (2007), we can easily yield dependency trees from PCFG style trees. A semantic dependency representation of a whole sentence, predicate-argument structures (PASs), are also included in the output trees of (1) a state-of-the-art head-driven phrase structure grammar (HPSG) (Pollard and Sag, 1994; Sag et al., 2003) parser, Enju1 (Miyao and Tsujii, 2008) and (2) a state-of-the-art CCG parser2 (Clark and Curran, 2007). The motivation of this paper is to investigate the impact of these non-isomorphic dependency structures to be used for SMT. That is, we would like to provide a comparative evaluation of these dependencies in a string-to-dependency decoder (Shen et al., 2008). This paper presents a comparative study of target dependency structures yielded by several state-of-the-art linguistic parsers. Our approach is to measure the impact of these nonisomorphic dependency structures to be used for string-to-dependency translation. Besides using traditional dependency parsers, we also use the dependency struc"
P12-2020,P97-1003,0,0.248621,"typical parsers, respectively. Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011). Here, we compare them on the SMT tasks through parsing the real-world SMT data. 2.3 PCFG parsing For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007). In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool3 written by Johansson and Nugues (2007). The head finding rules4 are according to Magerman (1995) and Collins (1997). Similar approach has been originally used by Shen et al. (2008). 2.4 HPSG parsing In the Enju English HPSG grammar (Miyao et al., 2003) used in this paper, the semantic content of 3 4 http://nlp.cs.lth.se/software/treebank converter/ http://www.cs.columbia.edu/ mcollins/papers/heads 101 a sentence/phrase is represented by a PAS. In an HPSG tree, each leaf node generally introduces a predicate, which is represented by the pair made up of the lexical entry feature and predicate type feature. The arguments of a predicate are designated by the arrows from the argument features in a leaf node to"
P12-2020,W07-2416,0,0.0959405,"ng. The MST parser (McDonald et al., 2005) and the Malt parser (Nivre, 2003) stand for two typical parsers, respectively. Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011). Here, we compare them on the SMT tasks through parsing the real-world SMT data. 2.3 PCFG parsing For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007). In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool3 written by Johansson and Nugues (2007). The head finding rules4 are according to Magerman (1995) and Collins (1997). Similar approach has been originally used by Shen et al. (2008). 2.4 HPSG parsing In the Enju English HPSG grammar (Miyao et al., 2003) used in this paper, the semantic content of 3 4 http://nlp.cs.lth.se/software/treebank converter/ http://www.cs.columbia.edu/ mcollins/papers/heads 101 a sentence/phrase is represented by a PAS. In an HPSG tree, each leaf node generally introduces a predicate, which is represented by the pair made up of the lexical entry feature and predicate type feature. The arguments of a predica"
P12-2020,P07-2045,0,0.00633941,"icate types to the gold-standard grammatical relations can be found in Table 13 in (Clark and 102 Curran, 2007). The post-processing is like that described for HPSG parsing, except we greedily use the MST’s sentence root when we can not determine it based on the CCG parser’s PASs. 3 Experiments 3.1 Setup We re-implemented the string-to-dependency decoder described in (Shen et al., 2008). Dependency structures from non-isomorphic syntactic/semantic parsers are separately used to train the transfer rules as well as target dependency LMs. For intuitive comparison, an outside SMT system is Moses (Koehn et al., 2007). For Chinese-to-English translation, we use the parallel data from NIST Open Machine Translation Evaluation tasks. The training data contains 353,796 sentence pairs, 8.7M Chinese words and 10.4M English words. The NIST 2003 and 2005 test data are respectively taken as the development and test set. We performed GIZA++ (Och and Ney, 2003) and the grow-diag-final-and symmetrizing strategy (Koehn et al., 2007) to obtain word alignments. The Berkeley Language Modeling Toolkit, berkeleylm1.0b35 (Pauls and Klein, 2011), was employed to train (1) a five-gram LM on the Xinhua portion of LDC English Gi"
P12-2020,P95-1037,0,0.136107,"2003) stand for two typical parsers, respectively. Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011). Here, we compare them on the SMT tasks through parsing the real-world SMT data. 2.3 PCFG parsing For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007). In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool3 written by Johansson and Nugues (2007). The head finding rules4 are according to Magerman (1995) and Collins (1997). Similar approach has been originally used by Shen et al. (2008). 2.4 HPSG parsing In the Enju English HPSG grammar (Miyao et al., 2003) used in this paper, the semantic content of 3 4 http://nlp.cs.lth.se/software/treebank converter/ http://www.cs.columbia.edu/ mcollins/papers/heads 101 a sentence/phrase is represented by a PAS. In an HPSG tree, each leaf node generally introduces a predicate, which is represented by the pair made up of the lexical entry feature and predicate type feature. The arguments of a predicate are designated by the arrows from the argument features"
P12-2020,H94-1020,0,0.0614407,"Missing"
P12-2020,J11-1007,0,0.0363269,"age side dependency structures have been successfully used in statistical machine translation (SMT) by Shen et al. (2008) and achieved state-of-the-art results as reported in the NIST 2008 Open MT Evaluation workshop and the NTCIR-9 Chinese-to-English patent translation task (Goto et al., 2011; Ma and Matsoukas, 2011). A primary advantage of dependency representations is that they have a natural mechanism for representing discontinuous constructions, which arise due to longdistance dependencies or in languages where grammatical relations are often signaled by morphology instead of word order (McDonald and Nivre, 2011). It is known that dependency-style structures can be transformed from a number of linguistic struc∗ † Now at Baidu Inc. Now at Nara Institute of Science & Technology (NAIST) 2 Gaining Dependency Structures 2.1 Dependency tree We follow the definition of dependency graph and dependency tree as given in (McDonald and Nivre, 2011). A dependency graph G for sentence s is called a dependency tree when it satisfies, (1) the nodes cover all the words in s besides the ROOT; (2) one node can have one and only one head (word) with a determined syntactic role; and (3) the ROOT of the graph is reachable"
P12-2020,P05-1012,0,0.0580344,"_ aux_ verb_ punct_ noun_ arg0 arg1 arg12 arg12 arg1 when the fluid pressure cylinder 31 * c19 c13 c22 c24 c25 t10 t11 t12 aux_ arg12 adj_ arg1 verb_ arg12 is gradually applied . Figure 1: HPSG tree of an example sentence. ‘*’/ ‘+’=syntactic/semantic heads. Arrows in red (upper)= PASs, orange (bottom)=word-level dependencies generated from PASs, blue=newly appended dependencies. both during rule extracting and target dependency language model (LM) training. 2.2 Dependency parsing Graph-based and transition-based are two predominant paradigms for data-driven dependency parsing. The MST parser (McDonald et al., 2005) and the Malt parser (Nivre, 2003) stand for two typical parsers, respectively. Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011). Here, we compare them on the SMT tasks through parsing the real-world SMT data. 2.3 PCFG parsing For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007). In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool3 written by Johansson and Nugues (2007). The head find"
P12-2020,J08-1002,0,0.0193457,"o, Soraku-gun Kyoto 619-0237 Japan wuxianchao@gmail.com,sudoh.katsuhito@lab.ntt.co.jp, kevinduh@is.naist.jp,{tsukada.hajime,nagata.masaaki}@lab.ntt.co.jp Abstract tures. For example, using the constituent-todependency conversion approach proposed by Johansson and Nugues (2007), we can easily yield dependency trees from PCFG style trees. A semantic dependency representation of a whole sentence, predicate-argument structures (PASs), are also included in the output trees of (1) a state-of-the-art head-driven phrase structure grammar (HPSG) (Pollard and Sag, 1994; Sag et al., 2003) parser, Enju1 (Miyao and Tsujii, 2008) and (2) a state-of-the-art CCG parser2 (Clark and Curran, 2007). The motivation of this paper is to investigate the impact of these non-isomorphic dependency structures to be used for SMT. That is, we would like to provide a comparative evaluation of these dependencies in a string-to-dependency decoder (Shen et al., 2008). This paper presents a comparative study of target dependency structures yielded by several state-of-the-art linguistic parsers. Our approach is to measure the impact of these nonisomorphic dependency structures to be used for string-to-dependency translation. Besides using"
P12-2020,W03-3017,0,0.0491047,"g12 arg1 when the fluid pressure cylinder 31 * c19 c13 c22 c24 c25 t10 t11 t12 aux_ arg12 adj_ arg1 verb_ arg12 is gradually applied . Figure 1: HPSG tree of an example sentence. ‘*’/ ‘+’=syntactic/semantic heads. Arrows in red (upper)= PASs, orange (bottom)=word-level dependencies generated from PASs, blue=newly appended dependencies. both during rule extracting and target dependency language model (LM) training. 2.2 Dependency parsing Graph-based and transition-based are two predominant paradigms for data-driven dependency parsing. The MST parser (McDonald et al., 2005) and the Malt parser (Nivre, 2003) stand for two typical parsers, respectively. Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011). Here, we compare them on the SMT tasks through parsing the real-world SMT data. 2.3 PCFG parsing For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007). In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool3 written by Johansson and Nugues (2007). The head finding rules4 are according to Magerm"
P12-2020,J03-1002,0,0.00290707,"pendency decoder described in (Shen et al., 2008). Dependency structures from non-isomorphic syntactic/semantic parsers are separately used to train the transfer rules as well as target dependency LMs. For intuitive comparison, an outside SMT system is Moses (Koehn et al., 2007). For Chinese-to-English translation, we use the parallel data from NIST Open Machine Translation Evaluation tasks. The training data contains 353,796 sentence pairs, 8.7M Chinese words and 10.4M English words. The NIST 2003 and 2005 test data are respectively taken as the development and test set. We performed GIZA++ (Och and Ney, 2003) and the grow-diag-final-and symmetrizing strategy (Koehn et al., 2007) to obtain word alignments. The Berkeley Language Modeling Toolkit, berkeleylm1.0b35 (Pauls and Klein, 2011), was employed to train (1) a five-gram LM on the Xinhua portion of LDC English Gigaword corpus v3 (LDC2007T07) and (2) a tri-gram dependency LM on the English dependency structures of the training data. We report the translation quality using the case-insensitive BLEU-4 metric (Papineni et al., 2002). 3.2 Statistics of dependencies We compare the similarity of the dependencies with each other, as shown in Table 2. Ba"
P12-2020,P02-1040,0,0.0827304,"Missing"
P12-2020,P11-1027,0,0.01549,"as target dependency LMs. For intuitive comparison, an outside SMT system is Moses (Koehn et al., 2007). For Chinese-to-English translation, we use the parallel data from NIST Open Machine Translation Evaluation tasks. The training data contains 353,796 sentence pairs, 8.7M Chinese words and 10.4M English words. The NIST 2003 and 2005 test data are respectively taken as the development and test set. We performed GIZA++ (Och and Ney, 2003) and the grow-diag-final-and symmetrizing strategy (Koehn et al., 2007) to obtain word alignments. The Berkeley Language Modeling Toolkit, berkeleylm1.0b35 (Pauls and Klein, 2011), was employed to train (1) a five-gram LM on the Xinhua portion of LDC English Gigaword corpus v3 (LDC2007T07) and (2) a tri-gram dependency LM on the English dependency structures of the training data. We report the translation quality using the case-insensitive BLEU-4 metric (Papineni et al., 2002). 3.2 Statistics of dependencies We compare the similarity of the dependencies with each other, as shown in Table 2. Basically, we investigate (1) if two dependency graphs of one sentence share the same root word and (2) if the head of one word in one sentence are identical in two dependency graph"
P12-2020,P08-1066,0,0.377419,"le trees. A semantic dependency representation of a whole sentence, predicate-argument structures (PASs), are also included in the output trees of (1) a state-of-the-art head-driven phrase structure grammar (HPSG) (Pollard and Sag, 1994; Sag et al., 2003) parser, Enju1 (Miyao and Tsujii, 2008) and (2) a state-of-the-art CCG parser2 (Clark and Curran, 2007). The motivation of this paper is to investigate the impact of these non-isomorphic dependency structures to be used for SMT. That is, we would like to provide a comparative evaluation of these dependencies in a string-to-dependency decoder (Shen et al., 2008). This paper presents a comparative study of target dependency structures yielded by several state-of-the-art linguistic parsers. Our approach is to measure the impact of these nonisomorphic dependency structures to be used for string-to-dependency translation. Besides using traditional dependency parsers, we also use the dependency structures transformed from PCFG trees and predicate-argument structures (PASs) which are generated by an HPSG parser and a CCG parser. The experiments on Chinese-to-English translation show that the HPSG parser’s PASs achieved the best dependency and translation a"
P12-2020,N07-1051,0,\N,Missing
P13-2119,D10-1092,1,0.436516,"Missing"
P13-2119,W12-3139,0,0.0208124,"Missing"
P13-2119,N06-2001,0,0.028358,"Missing"
P13-2119,W04-3250,0,0.464764,"Missing"
P13-2119,W12-2703,0,0.060629,"Missing"
P13-2119,D11-1033,0,0.191828,"vector representation of words in neural language models makes them more effective than n-grams for modeling unknown word contexts, which are prevalent in general-domain text. In a comprehensive evaluation of 4 language pairs (English to German, French, Russian, Spanish), we found that neural language models are indeed viable tools for data selection: while the improvements are varied (i.e. 0.1 to 1.7 gains in BLEU), they are fast to train on small in-domain data and can sometimes substantially outperform conventional n-grams. 1 2 Data Selection Method We employ the data selection method of (Axelrod et al., 2011), which builds upon (Moore and Lewis, 2010). The intuition is to select general-domain sentences that are similar to indomain text, while being dis-similar to the average general-domain text. To do so, one defines the score of an generaldomain sentence pair (e, f ) as: Introduction A perennial challenge in building Statistical Machine Translation (SMT) systems is the dearth of high-quality bitext in the domain of interest. An effective and practical solution is adaptation data selection: the idea is to use language models (LMs) trained on in-domain text to select similar sentences from large g"
P13-2119,P10-2041,0,0.175474,"language models makes them more effective than n-grams for modeling unknown word contexts, which are prevalent in general-domain text. In a comprehensive evaluation of 4 language pairs (English to German, French, Russian, Spanish), we found that neural language models are indeed viable tools for data selection: while the improvements are varied (i.e. 0.1 to 1.7 gains in BLEU), they are fast to train on small in-domain data and can sometimes substantially outperform conventional n-grams. 1 2 Data Selection Method We employ the data selection method of (Axelrod et al., 2011), which builds upon (Moore and Lewis, 2010). The intuition is to select general-domain sentences that are similar to indomain text, while being dis-similar to the average general-domain text. To do so, one defines the score of an generaldomain sentence pair (e, f ) as: Introduction A perennial challenge in building Statistical Machine Translation (SMT) systems is the dearth of high-quality bitext in the domain of interest. An effective and practical solution is adaptation data selection: the idea is to use language models (LMs) trained on in-domain text to select similar sentences from large general-domain corpora. The selected sentenc"
P13-2119,C90-3038,0,0.351908,"with English (en) as source and German (de), Spanish (es), French (fr), Russian (ru) as target. This is the in-domain corpus, and consists of TED Talk transcripts covering topics in technology, entertainment, and design. As general-domain corpora, we collected bitext from the WMT2013 campaign, including CommonCrawl and NewsCommentary for all 4 languages, Europarl for de/es/fr, UN for es/fr, Gigaword for fr, and Yandex for ru. The indomain data is divided into a training set (for SMT 1 Another major type of neural LMs are the so-called feed-forward networks (Bengio et al., 2003; Schwenk, 2007; Nakamura et al., 1990). Both types of neural LMs have seen many improvements recently, in terms of computational scalability (Le et al., 2011) and modeling power (Arisoy et al., 2012; Wu et al., 2012; Alexandrescu and Kirchhoff, 2006). We focus on recurrent networks here since there are fewer hyper-parameters and its ability to model infinite context using recursion is theoretically attractive. But we note that feedforward networks are just as viable. 2 The recurrent states are unrolled for several time-steps, then stochastic gradient descent is applied. 679 en-de en-es In-domain Training Set #sentence 129k 140k #t"
P13-2119,2012.eamt-1.60,0,0.0186427,"ontext as an identity (n-gram hit-or-miss) function on [w(t − 1), w(t − 2), . . .], neural LMs summarize the context by a hidden state vector s(t). This is a continuous vector of dimension |S |whose elements are predicted by the previous word w(t − 1) and previous state s(t − 1). This is robust to rare contexts because continuous representations enable sharing of statistical strength between similar contexts. Bengio (2009) shows that such representations are better than multinomials in alleviating sparsity issues. 3 Experiment Setup We experimented with four language pairs in the WIT3 corpus (Cettolo et al., 2012), with English (en) as source and German (de), Spanish (es), French (fr), Russian (ru) as target. This is the in-domain corpus, and consists of TED Talk transcripts covering topics in technology, entertainment, and design. As general-domain corpora, we collected bitext from the WMT2013 campaign, including CommonCrawl and NewsCommentary for all 4 languages, Europarl for de/es/fr, UN for es/fr, Gigaword for fr, and Yandex for ru. The indomain data is divided into a training set (for SMT 1 Another major type of neural LMs are the so-called feed-forward networks (Bengio et al., 2003; Schwenk, 2007"
P13-2119,2012.amta-papers.19,0,0.122261,"Missing"
P13-2119,2010.iwslt-papers.5,1,0.84743,"one defines the score of an generaldomain sentence pair (e, f ) as: Introduction A perennial challenge in building Statistical Machine Translation (SMT) systems is the dearth of high-quality bitext in the domain of interest. An effective and practical solution is adaptation data selection: the idea is to use language models (LMs) trained on in-domain text to select similar sentences from large general-domain corpora. The selected sentences are then incorporated into the SMT training data. Analyses have shown that this augmented data can lead to better statistical estimation or word coverage (Duh et al., 2010; Haddow and Koehn, 2012). [INE (e) − GENE (e)] + [INF (f ) − GENF (f )] (1) where INE (e) is the length-normalized crossentropy of e on the English in-domain LM. GENE (e) is the length-normalized cross-entropy 678 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 678–683, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics Now, given state vector s(t), we can predict the probability of the current word. Figure 1 is expressed formally in the following equations: w(t) = [w0 (t), . . . , wk (t), . . . w|W |(t)]  Figure"
P13-2119,P02-1040,0,0.0858846,"Missing"
P13-2119,W12-2702,0,0.0173223,"Missing"
P13-2119,W12-3154,0,0.0129056,"core of an generaldomain sentence pair (e, f ) as: Introduction A perennial challenge in building Statistical Machine Translation (SMT) systems is the dearth of high-quality bitext in the domain of interest. An effective and practical solution is adaptation data selection: the idea is to use language models (LMs) trained on in-domain text to select similar sentences from large general-domain corpora. The selected sentences are then incorporated into the SMT training data. Analyses have shown that this augmented data can lead to better statistical estimation or word coverage (Duh et al., 2010; Haddow and Koehn, 2012). [INE (e) − GENE (e)] + [INF (f ) − GENF (f )] (1) where INE (e) is the length-normalized crossentropy of e on the English in-domain LM. GENE (e) is the length-normalized cross-entropy 678 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 678–683, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics Now, given state vector s(t), we can predict the probability of the current word. Figure 1 is expressed formally in the following equations: w(t) = [w0 (t), . . . , wk (t), . . . w|W |(t)]  Figure 1: Recurrent neural LM. w"
P13-2119,2006.amta-papers.25,0,0.0371213,"Missing"
P13-2119,C12-1173,0,0.0163768,"Missing"
P13-2119,I08-2088,0,0.0198878,"Missing"
P13-2119,D10-1044,0,\N,Missing
W04-3255,J93-2003,0,0.0245694,"d into a composition model beforehand. Furthermore, the ambiguity of the composition model is reduced by the statistics of hypotheses while decoding. The experimental results show that the proposed model representation drastically improves the efficiency of decoding compared to the dynamic composition of the submodels, which corresponds to conventional approaches. 1 Introduction Recently, research on statistical machine translation has grown along with the increase in computational power as well as the amount of bilingual corpora. The basic idea of modeling machine translation was proposed by Brown et al. (1993), who assumed that machine translation can be modeled on noisy channels. The source language is encoded from a target language by a noisy channel, and translation is performed as a decoding process from source language to target language. Knight (1999) showed that the translation problem defined by Brown et al. (1993) is NPcomplete. Therefore, with this model it is almost impossible to search for optimal solutions in the decoding process. Several studies have proposed methods for searching suboptimal solutions. Berger et al. (1996) and Och et al. (2001) proposed such depth-first search methods"
W04-3255,H91-1026,0,0.0265323,"crease model errors, but QR =S corrects the errors caused by merging states. Unlike ordinary FSA minimization, states are merged without considering their successor states. If the weight represents probability, thesum of the weights of output transitions may not be 1.0 after merging states, and then thecondition of probability may be destroyed. Since the decoder does not sum up all possible paths but searches for the most appropriate paths, this kind of state merging does not pose a serious problem in practice. In the following experiment, we measured the association between states by &quot; + in Gale and Church (1991). &quot; + is a T + -like statistic that is bounded between 0 and 1. If the &quot; + of two states is higher than the specified threshold, these two states are merged. The definition of &quot; + is U    U   V  V : as W fol-, :   V V V K lows, where , X Y  V  V  Z , and &gt;[ + G Z  K ]X . G +number of hypothesis lists.  V  V  is the  total   (  V V : V ) is the number of hypothesis lists in + (both V : and V appear). which V appears + &gt;   X &quot; +   O^   _^`X   K ^ + &gt;/  Xa^ (&gt;   K K Figure 6: FSA for All Input Permutations Merging the beginning and end states of a transition who"
W04-3255,knight-al-onaizan-1998-translation,0,0.544428,"1) studied WFST models in call-routing tasks, and Kumar and Byrne (2003) modeled phrase-based translation by WFSTs. All of these studies mainly focused on the representation of each submodel used in machine translation. However, few studies have focued on the integration of each WFST submodel to improve the decoding efficiency of machine translation. To this end, we propose a method that expands all of the submodels into a composition model, reducing the ambiguity of the expanded model by the statistics of hypotheses while decoding. First, we explain the translation model (Brown et al., 1993; Knight and Al-Onaizan, 1998) that we used as a base for our decoding research. Second, our proposed method is introduced. Finally, experimental results show that our proposed method drastically improves decoding efficiency. 2 IBM Model For our decoding research, we assume the IBMstyle modeling for translation proposed in Brown et al. (1993). In this model, translation from Japanese to find  . Using attempts to English  the  that maximizes Bayes’ rule,  is rewritten as                 is referred to as a language model and where     is  referred to as a tra"
W04-3255,J99-4005,0,0.0928239,"decoding compared to the dynamic composition of the submodels, which corresponds to conventional approaches. 1 Introduction Recently, research on statistical machine translation has grown along with the increase in computational power as well as the amount of bilingual corpora. The basic idea of modeling machine translation was proposed by Brown et al. (1993), who assumed that machine translation can be modeled on noisy channels. The source language is encoded from a target language by a noisy channel, and translation is performed as a decoding process from source language to target language. Knight (1999) showed that the translation problem defined by Brown et al. (1993) is NPcomplete. Therefore, with this model it is almost impossible to search for optimal solutions in the decoding process. Several studies have proposed methods for searching suboptimal solutions. Berger et al. (1996) and Och et al. (2001) proposed such depth-first search methods as stack decoders. Wand and Waibel (1997) and Tillmann and Ney (2003) proposed breadth-first search methods, i.e. beam search. Germann (2001) and Watanabe and Sumita (2003) proposed greedy type decoding methods. In all of these search algorithms, bett"
W04-3255,N03-1019,0,0.0778281,"otivation is to apply this approach to machine translation. However, WFST optimization operations such as determinization are nearly impossible to apply to WFSTs in machine translation because they are much more ambiguous than speech recognition. To reduce the ambiguity, we propose a WFST optimization method that considers the statistics of hypotheses while decoding. Some approaches have applied WFST to statistical machine translation. Knight and AlOnaizan (1998) proposed the representation of IBM model 3 with WFSTs; Bangalore and Riccardi (2001) studied WFST models in call-routing tasks, and Kumar and Byrne (2003) modeled phrase-based translation by WFSTs. All of these studies mainly focused on the representation of each submodel used in machine translation. However, few studies have focued on the integration of each WFST submodel to improve the decoding efficiency of machine translation. To this end, we propose a method that expands all of the submodels into a composition model, reducing the ambiguity of the expanded model by the statistics of hypotheses while decoding. First, we explain the translation model (Brown et al., 1993; Knight and Al-Onaizan, 1998) that we used as a base for our decoding res"
W04-3255,J03-1002,0,0.00755588,"adopted a simpler method to deal with a negative L loop as described above. 5 Experiments 5.1 Effect of Full Expansion To clarify the effectiveness of a full-expansion approach, we compared the computational costs while using the same decoder with both dynamic composition and static composition, a full-expansion model in other words. In the forward beam-search, 0dcd0de any hypothesis whose probability is lower than of the top of the hypothesis list is pruned. In this experiment, permutation is restricted, and words can be moved 6 positions at most. The translation model was trained by GIZA++ (Och and Ney, 2003), and the trigram was trained by the CMU-Cambridge Statistical Language Modeling Toolkit v2 (Clarkson and Rosenfeld, 1997). For the experiment, we used a Japanese-toEnglish bilingual corpus consisting of example sentences for a rule-based machine translation system. Each language sentence is aligned in the corpus. The total number of sentence pairs is 20,204. We used 17,678 pairs for training and 2,526 pairs for the test. The average length of Japanese sentences was 8.4 words, and that of English sentences was 6.7 words. The Japanese vocabulary consisted of 15,510 words, and the English vocabu"
W04-3255,W01-1408,0,0.015455,"ng machine translation was proposed by Brown et al. (1993), who assumed that machine translation can be modeled on noisy channels. The source language is encoded from a target language by a noisy channel, and translation is performed as a decoding process from source language to target language. Knight (1999) showed that the translation problem defined by Brown et al. (1993) is NPcomplete. Therefore, with this model it is almost impossible to search for optimal solutions in the decoding process. Several studies have proposed methods for searching suboptimal solutions. Berger et al. (1996) and Och et al. (2001) proposed such depth-first search methods as stack decoders. Wand and Waibel (1997) and Tillmann and Ney (2003) proposed breadth-first search methods, i.e. beam search. Germann (2001) and Watanabe and Sumita (2003) proposed greedy type decoding methods. In all of these search algorithms, better representation of the statistical model in systems can improve the search efficiency. For model representation, a search method based Masaaki Nagata NTT Cyber Space Labs. 1-1 Hikari-no-Oka Yokosuka-shi Kanagawa 239-0847 Japan nagata.masaaki@lab.ntt.co.jp on weighted finite-state transducer (WFST) (Mohri"
W04-3255,P02-1040,0,0.0716066,"Each language sentence is aligned in the corpus. The total number of sentence pairs is 20,204. We used 17,678 pairs for training and 2,526 pairs for the test. The average length of Japanese sentences was 8.4 words, and that of English sentences was 6.7 words. The Japanese vocabulary consisted of 15,510 words, and the English vocabulary was 11,806 words. Table 1 shows the size of the WFSTs used in the experiment. In these WFSTs, special symbols that express beginning and end of sentence are added to the WFSTs described in the previous section. The NIST score (Doddington, 2002) and BLEU Score (Papineni et al., 2002) were used to measure translation accuracy. Table 2 shows the experimental results. The fullexpansion model provided translations more than 10 times faster than conventional dynamic composition submodels without degrading accuracy. However, the NIST scores are slightly different. In the course of composition, some paths that do not reach the final states are produced. In the full-expansion model these paths are trimmed. These trimmed paths may cause a slight difference in NIST scores. 5.2 Effect of Ambiguity Reduction To show the effect of ambiguity reduction, we compared the translation resul"
W04-3255,J03-1005,0,0.0175463,"odeled on noisy channels. The source language is encoded from a target language by a noisy channel, and translation is performed as a decoding process from source language to target language. Knight (1999) showed that the translation problem defined by Brown et al. (1993) is NPcomplete. Therefore, with this model it is almost impossible to search for optimal solutions in the decoding process. Several studies have proposed methods for searching suboptimal solutions. Berger et al. (1996) and Och et al. (2001) proposed such depth-first search methods as stack decoders. Wand and Waibel (1997) and Tillmann and Ney (2003) proposed breadth-first search methods, i.e. beam search. Germann (2001) and Watanabe and Sumita (2003) proposed greedy type decoding methods. In all of these search algorithms, better representation of the statistical model in systems can improve the search efficiency. For model representation, a search method based Masaaki Nagata NTT Cyber Space Labs. 1-1 Hikari-no-Oka Yokosuka-shi Kanagawa 239-0847 Japan nagata.masaaki@lab.ntt.co.jp on weighted finite-state transducer (WFST) (Mohri et al., 2002) has achieved great success in the speech recognition field. The basic idea is that each statisti"
W04-3255,P97-1047,0,0.0740554,"Missing"
W04-3255,2003.mtsummit-papers.54,0,0.0259442,"and translation is performed as a decoding process from source language to target language. Knight (1999) showed that the translation problem defined by Brown et al. (1993) is NPcomplete. Therefore, with this model it is almost impossible to search for optimal solutions in the decoding process. Several studies have proposed methods for searching suboptimal solutions. Berger et al. (1996) and Och et al. (2001) proposed such depth-first search methods as stack decoders. Wand and Waibel (1997) and Tillmann and Ney (2003) proposed breadth-first search methods, i.e. beam search. Germann (2001) and Watanabe and Sumita (2003) proposed greedy type decoding methods. In all of these search algorithms, better representation of the statistical model in systems can improve the search efficiency. For model representation, a search method based Masaaki Nagata NTT Cyber Space Labs. 1-1 Hikari-no-Oka Yokosuka-shi Kanagawa 239-0847 Japan nagata.masaaki@lab.ntt.co.jp on weighted finite-state transducer (WFST) (Mohri et al., 2002) has achieved great success in the speech recognition field. The basic idea is that each statistical model is represented by a WFST and they are composed beforehand; the composed model is optimized by"
W04-3255,N01-1018,0,\N,Missing
W06-3115,2004.iwslt-evaluation.13,0,0.016641,"3,979 23,186,379 es-en 17,221,890 16,601,306 16,540,767 12,677,192 21,709,212 fr-en 16,176,075 15,635,900 15,610,319 11,645,404 20,760,539 en-de 17,596,764 17,052,808 16,936,710 12,218,997 23,066,052 en-es 17,237,723 16,597,274 16,530,810 12,688,773 21,698,267 en-fr 16,220,520 15,658,940 15,613,755 11,653,242 20,789,570 Table 2: Number of phrases extracted from differently preprocessed corpora. lower stem prefix4 merged de-en 37,711,217 46,550,101 53,429,522 80,260,191 es-en 61,161,868 75,610,696 78,193,818 111,153,303 fr-en 56,025,918 68,210,968 70,514,377 103,523,206 lexicon model t( f |e) (Bender et al., 2004): hdel (e1I , f1J ) = J  X j=1 max t( f j |ei ) < τdel 0≤i≤I  (4) The deletion model simply counts the number of words whose lexicon model probability is lower than a threshold τdel . Likewise, we also added an insertion model hins (e1I , f1J ) that penalizes the spuriously inserted English words using a lexicon model t(e |f ). For the hierarchical phrase-based model, we employed the same feature set except for the distortion model and the lexicalized reordering model. 3 Phrase Extraction from Different Word Alignment en-de 38,142,663 46,749,195 53,647,033 80,666,414 en-es 60,619,435 75,473,"
W06-3115,P05-1033,0,0.568763,"language, i.e. English, e1I = e1 , e2 , ..., eI by seeking a maximum likelihood solution of eˆ 1I = argmax Pr(e1I |f1J ) (1) e1I  I , f J) λ h (e m m m=1 1 1 = argmax P (2) P M ′ I′ , f J ) I ′ exp λ h (e I e1 ′ m m m=1 e 1 1 exp P M 1 1 Introduction We contrasted two translation methods for the Workshop on Statistical Machine Translation (WMT2006) shared-task. One is a phrase-based translation in which a phrasal unit is employed for translation (Koehn et al., 2003). The other is a hierarchical phrase-based translation in which translation is realized as a set of paired production rules (Chiang, 2005). Section 2 discusses those two models and details extraction algorithms, decoding algorithms and feature functions. We also explored three types of corpus preprocessing in Section 3. As expected, different tokenization would lead to different word alignments which, in turn, resulted in the divergence of the extracted phrase/rule size. In our method, In this framework, the posterior probability Pr(e1I |f1J ) is directly maximized using a log-linear combination of feature functions hm (e1I , f1J ), such as a ngram language model or a translation model. When decoding, the denominator is dropped"
W06-3115,N03-1017,0,0.292419,"Models We used a log-linear approach (Och and Ney, 2002) in which a foreign language sentence f1J = f1 , f2 , ... fJ is translated into another language, i.e. English, e1I = e1 , e2 , ..., eI by seeking a maximum likelihood solution of eˆ 1I = argmax Pr(e1I |f1J ) (1) e1I  I , f J) λ h (e m m m=1 1 1 = argmax P (2) P M ′ I′ , f J ) I ′ exp λ h (e I e1 ′ m m m=1 e 1 1 exp P M 1 1 Introduction We contrasted two translation methods for the Workshop on Statistical Machine Translation (WMT2006) shared-task. One is a phrase-based translation in which a phrasal unit is employed for translation (Koehn et al., 2003). The other is a hierarchical phrase-based translation in which translation is realized as a set of paired production rules (Chiang, 2005). Section 2 discusses those two models and details extraction algorithms, decoding algorithms and feature functions. We also explored three types of corpus preprocessing in Section 3. As expected, different tokenization would lead to different word alignments which, in turn, resulted in the divergence of the extracted phrase/rule size. In our method, In this framework, the posterior probability Pr(e1I |f1J ) is directly maximized using a log-linear combinati"
W06-3115,P02-1038,0,0.483885,"resent two translation systems experimented for the shared-task of “Workshop on Statistical Machine Translation,” a phrase-based model and a hierarchical phrase-based model. The former uses a phrasal unit for translation, whereas the latter is conceptualized as a synchronousCFG in which phrases are hierarchically combined using non-terminals. Experiments showed that the hierarchical phrasebased model performed very comparable to the phrase-based model. We also report a phrase/rule extraction technique differentiating tokenization of corpora. 2 Translation Models We used a log-linear approach (Och and Ney, 2002) in which a foreign language sentence f1J = f1 , f2 , ... fJ is translated into another language, i.e. English, e1I = e1 , e2 , ..., eI by seeking a maximum likelihood solution of eˆ 1I = argmax Pr(e1I |f1J ) (1) e1I  I , f J) λ h (e m m m=1 1 1 = argmax P (2) P M ′ I′ , f J ) I ′ exp λ h (e I e1 ′ m m m=1 e 1 1 exp P M 1 1 Introduction We contrasted two translation methods for the Workshop on Statistical Machine Translation (WMT2006) shared-task. One is a phrase-based translation in which a phrasal unit is employed for translation (Koehn et al., 2003). The other is a hierarchical phrase-b"
W06-3115,J03-1002,0,0.0144663,"h sentence. In the hierarchical phrase-based model, decoding is realized as an Earley-style top-down parser on the foreign language side with a beam search strategy synchronized with the cardinality of already translated foreign words (Watanabe et al., 2006). The major difference to the phrase-based model’s decoder is the handling of non-terminals, or holes, in each rule. 2.1 2.3 Phrase/Rule Extraction The phrase extraction algorithm is based on those presented by Koehn et al. (2003). First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Och and Ney, 2004). Second, phrase translation pairs are extracted from the word aligned corpus (Koehn et al., 2003). The method exhaustively exj+m tracts phrase pairs ( f j , ei+n i ) from a sentence pair I J ( f1 , e1 ) that do not violate the word alignment constraints a. In the hierarchical phrase-based model, production rules are accumulated by computing “holes” for extracted contiguous phrases (Chiang, 2005): Our phrase-based model uses a standard pharaoh feature functions listed as follows (Koehn et al., 2003): • Re"
W06-3115,J04-4002,0,0.0486513,"e top-down parser on the foreign language side with a beam search strategy synchronized with the cardinality of already translated foreign words (Watanabe et al., 2006). The major difference to the phrase-based model’s decoder is the handling of non-terminals, or holes, in each rule. 2.1 2.3 Phrase/Rule Extraction The phrase extraction algorithm is based on those presented by Koehn et al. (2003). First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Och and Ney, 2004). Second, phrase translation pairs are extracted from the word aligned corpus (Koehn et al., 2003). The method exhaustively exj+m tracts phrase pairs ( f j , ei+n i ) from a sentence pair I J ( f1 , e1 ) that do not violate the word alignment constraints a. In the hierarchical phrase-based model, production rules are accumulated by computing “holes” for extracted contiguous phrases (Chiang, 2005): Our phrase-based model uses a standard pharaoh feature functions listed as follows (Koehn et al., 2003): • Relative-count based phrase translation probabilities in both directions. • Lexically weight"
W06-3115,P06-1098,1,0.825285,"ociated with ∼. existing hypothesis, new hypothesis is generated by consuming a phrase translation pair that covers untranslated foreign word positions. The score for the newly generated hypothesis is updated by combining the scores of feature functions described in Section 2.3. The English side of the phrase is simply concatenated to form a new prefix of English sentence. In the hierarchical phrase-based model, decoding is realized as an Earley-style top-down parser on the foreign language side with a beam search strategy synchronized with the cardinality of already translated foreign words (Watanabe et al., 2006). The major difference to the phrase-based model’s decoder is the handling of non-terminals, or holes, in each rule. 2.1 2.3 Phrase/Rule Extraction The phrase extraction algorithm is based on those presented by Koehn et al. (2003). First, manyto-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Och and Ney, 2004). Second, phrase translation pairs are extracted from the word aligned corpus (Koehn et al., 2003). The method exhaustively exj+m tracts phrase pairs"
W06-3115,N04-1021,0,\N,Missing
W06-3115,P03-1021,0,\N,Missing
W10-1736,P07-1091,0,0.326335,"Missing"
W10-1736,2006.amta-papers.16,0,0.0396519,"Missing"
W10-1736,J03-1002,0,0.00303273,", 3, 2, 6] from this alignment. When the same word (or derivative words) appears twice or more in a single English sentence, two or more non-consecutive words in the English sentence are aligned to a single Japanese word: 3.1 Rough evaluation of reordering rate of change of speed NULL ({}) sokudo ({5}) henka ({3}) no ({2 4}) wariai ({1}) First, we examined rank correlation between Head Final English sentences produced by the Head Finalization rule and Japanese reference sentences. Since we do not have handcrafted word alignment data for an English-to-Japanese bilingual corpus, we used GIZA++ (Och and Ney, 2003) to get automatic word alignment. Based on this automatic word alignment, we measured Kendall’s τ for the word order between HFE sentences and Japanese sentences. Kendall’s τ is a kind of rank correlation measure defined as follows. Suppose a list of integers such as L = [2, 1, 3, 4]. The number of all integer pairs in this list is 4 C2 = 4 × 3/(2 × 1) = 6. The number of increasing pairs is five: (2, 3), (2, 4), (1, 3), (1, 4), and (3, 4). Kendall’s τ is defined by τ= We excluded the ambiguously aligned words (2 from the calculation of τ . We use only [5, 3, 1] and get τ = −1.0. The exclusion"
W10-1736,P05-1022,0,0.0389233,"Missing"
W10-1736,P02-1040,0,0.107213,"ecided to stop swapping them at coordination nodes, which are indicated cat and xcat attributes of the Enju output. We call this the coordination exception rule. In addition, we avoid Enju’s splitting of numerical expressions such as “12,345” and “(1)” because this splitting leads to inappropriate word orders. 246 3 Experiments John va1 a ball va2 hit . NULL ({3}) jon ({1}) wa ({2}) bohru ({4}) wo ({5}) utta ({6}) . ({7}) In order to show how closely our Head Finalization makes English follow Japanese word order, we measured Kendall’s τ , a rank correlation coefficient. We also measured BLEU (Papineni et al., 2002) and other automatic evaluation scores to show that Head Finalization can actually improve the translation quality. We used NTCIR7 PAT-MT’s Patent corpus (Fujii et al., 2008). Its training corpus has 1.8 million sentence pairs. We used MeCab (http:// mecab.sourceforge.net/) to segment Japanese sentences. Then, we get [1, 2, 4, 5, 6, 7] and τ = 1.0. We use τ or the average of τ over all training sentences to observe the tendency. Sometimes, one Japanese word corresponds to an English phrase: John went to Costa Rica . NULL ({}) jon ({1}) wa ({}) kosutarika ({4 5}) ni ({3}) itta ({2}) . ({6}) We"
W10-1736,P05-1066,0,0.769816,"Missing"
W10-1736,P05-1034,0,0.166265,"Missing"
W10-1736,de-marneffe-etal-2006-generating,0,0.00411069,"Missing"
W10-1736,2006.amta-papers.25,0,0.0277013,"it (http:// 5 Discussion Our method used an HPSG parser, which gives rich information, but it is not easy to build such a parser. It is much easier to build word dependency parsers and Penn Treebank-style parsers. In order use these parsers, we have to add some heuristic rules. www.mibel.cs.tsukuba.ac.jp/norimatsu/ bleu kit/) following the PATMT’s overview paper (Fujii et al., 2008). The table shows that dl=6 gives the best result, and even dl=0 (no reordering in Moses) gives better scores than the organizers’ Moses. Table 2 also shows Word Error Rates (WER) and Translation Error Rates (TER) (Snover et al., 2006). Since they are error rates, smaller is better. Although the improvement of BLEU is not very impressive, the score of WER is greatly reduced. This difference comes from the fact that BLEU measures only local word order, while WER mea5.1 Word Dependency Parsers At first, we thought that we could substitute a word dependency parser for Enju by simply rephrasing a head with a modified word. Xu et al. (2009) used a semantic head-based dependency parser for a similar purpose. Even when we use a syntactic head-based dependency parser instead, we encountered their ‘excessive movement’ problem. A str"
W10-1736,N07-1007,0,0.0105596,"ad c4 appears before c5, so c4 and c5 are swapped. The lower picture shows the swapped result. Then we get John a ball hit, which has the same word order as its Japanese translation jon wa bohru wo utta except for the functional words a, wa, and wo. We have to add Japanese particles wa (topic marker) or ga (nominative case marker) for John and wo (objective case marker) for ball to get an acceptable Japanese sentence. It is well known that SMT is not good at generating appropriate particles from English, whitch does not have particles. Particle generation was tackled by a few research groups (Toutanova and Suzuki, 2007; Hong et al., 2009). Here, we use Enju’s output to generate seeds Figure 1: Enju’s XML output (some attributes are removed for readability). c0 ? c1 ? c2 ? t0 John c3 ? c6 ? t2 a c4 ? t1 hit c0 c1 ? c2 ? t0 John jon (wa) Original English ? c5 ? c5 ? c7 ? t3 ball Head Final English c3 ? c7 c6 c4 ? ? ? t3 t2 t1 a ball hit – bohru (wo) utta Figure 2: Head Finalization of a simple sentence (? indicates a head). 245 0 Original English ? ? 4 ? 1? 2 John 5 went 6 ? 7 to 8 9 the 0 13 3 ? 10 police 11 ? 12 because 13 14 ? 15 Mary ? 16 ? 19 his 17 lost 18 ? 20 wallet Head Final English ? 3 11 ? ? ? 16"
W10-1736,C04-1073,0,0.835753,"Missing"
W10-1736,N09-1028,0,0.772582,"ral level. Why do we think this works? The reason is simple: Japanese is a typical head-final language. That is, a syntactic head word comes after nonhead (dependent) words. SOV is just one aspect of head-final languages. In order to implement this idea, we need a parser that outputs syntactic heads. Enju is such a parser from the University of Tokyo (http://www-tsujii.is.s. u-tokyo.ac.jp/enju). We discuss other parsers in section 5. There is another kind of head: semantic heads. Hong et al. (2009) used Stanford parser (de Marneffe et al., 2006), which outputs semantic headbased dependencies; Xu et al. (2009) also used the same representation. The use of syntactic heads and the number of dependents are essential for the simplicity of English is a typical SVO (Subject-VerbObject) language, while Japanese is a typical SOV language. Conventional Statistical Machine Translation (SMT) systems work well within each of these language families. However, SMT-based translation from an SVO language to an SOV language does not work well because their word orders are completely different. Recently, a few groups have proposed rulebased preprocessing methods to mitigate this problem (Xu et al., 2009; Hong et al."
W10-1736,P09-2059,0,0.540137,"ider part-of-speech tags or rule weights because the powerful Enju parser allows us to implement the rule at a general level. Why do we think this works? The reason is simple: Japanese is a typical head-final language. That is, a syntactic head word comes after nonhead (dependent) words. SOV is just one aspect of head-final languages. In order to implement this idea, we need a parser that outputs syntactic heads. Enju is such a parser from the University of Tokyo (http://www-tsujii.is.s. u-tokyo.ac.jp/enju). We discuss other parsers in section 5. There is another kind of head: semantic heads. Hong et al. (2009) used Stanford parser (de Marneffe et al., 2006), which outputs semantic headbased dependencies; Xu et al. (2009) also used the same representation. The use of syntactic heads and the number of dependents are essential for the simplicity of English is a typical SVO (Subject-VerbObject) language, while Japanese is a typical SOV language. Conventional Statistical Machine Translation (SMT) systems work well within each of these language families. However, SMT-based translation from an SVO language to an SOV language does not work well because their word orders are completely different. Recently,"
W10-1736,P01-1067,0,0.267073,"Missing"
W10-1757,W06-1615,0,0.0749079,"for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsity leads to overfitting. We addressed this by re-casting N-best lists as multitask learning data. Our MT experiments show consistent statistically significant improvements. From the Bayesian view, multitask formulation of N-best"
W10-1757,W09-2201,0,0.0321418,"r better features. Multitask learning is currently an active subfield 381 within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsi"
W10-1757,N09-1025,0,0.167697,"tanabe et al., 2007) defines feature templates based on bilingual word alignments, which lead to extraction of heavilylexicalized features of the form: 2. The input (f ) has high variability (e.g. large vocabulary size), so that features for different inputs are rarely shared. 3. The N-best list output also exhibits high variability (e.g. many different word reorderings). Larger N may improve reranking performance, but may also increase feature sparsity. When the number of features is too large, even popular reranking algorithms such as SVM (Shen et al., 2004) and MIRA (Watanabe et al., 2007; Chiang et al., 2009) may fail. Our goal here is to address this situation. 3 Proposed Reranking Framework h(e, f ) =  1       0 if foreign word “Monsieur” and English word “Mr.” co-occur in e,f otherwise In the following, we first give an intuitive comparison between single vs. multiple task learning (Section 3.1), before presenting the general metaalgorithm (Section 3.2) and particular instantiations (Section 3.3). (2) One can imagine that such features are sparse because it may only fire for input sentences that contain the word “Monsieur”. For all other input sentences, it is an useless, inactive featur"
W10-1757,J07-2003,0,0.0561179,"Missing"
W10-1757,J05-1003,0,0.264845,"f features. 1. We introduce the idea of viewing N-best reranking as a multitask learning problem. This view is particularly apt to any general reranking problem with sparse feature sets. 2. We propose a simple meta-algorithm that first discovers common feature representations across N-bests (via multitask learning) before training a conventional reranker. Thus it is easily applicable to existing systems. 1 Introduction Many natural language processing applications, such as machine translation (MT), parsing, and language modeling, benefit from the N-best reranking framework (Shen et al., 2004; Collins and Koo, 2005; Roark et al., 2007). The advantage of N-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover. In the N-best reranking scenario, the training data consists of sets of hypotheses (i.e. N-best lists) generated by a first-pass system, along with their labels. Given a new N-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list. Existing research have focused on training a single reranker directly on the 3. We demonstrate that"
W10-1757,N09-1068,0,0.0391788,"gularizer to ensure that the learned functions of related tasks are close to each other. The popular ℓ1 /ℓ2 objective can be optimized by various methods, such as boosting (Obozinski et al., 2009) and convex programming (Argyriou et al., 2008). Yet another regularizer is the ℓ1 /ℓ∞ norm (Quattoni et al., 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure i that each task-specific to some average P wi is close parameter, e.g. i ||w − wavg ||2 . If we interpret wavg as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruana, 1997). Another method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f ) + vT · Θ · h(e, f ) (Ando and Zhang, 2005). Θ is a D ′ × D matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by"
W10-1757,W08-0804,0,0.0274275,"res are shared: Wa : » – 4 0 0 4 0 3 3 0 4 4 3 3 → 14 Wb : » – 4 0 3 4 0 3 0 0 4 5 3 0 → 12 2 In MT, evaluation metrics like BLEU do not exactly decompose across sentences, so for some training algorithms this loss is an approximation. [optional] RandomHashing({Hi }) W = MultitaskLearn({(Hi , yi )}) hc = ExtractCommonFeature(W) {Hic } = RemapFeature({Hi }, hc ) wc = ConventionalReranker({(Hic , yi )}) The first step, random hashing, is optional. Random hashing is an effective trick for reducing the dimension of sparse feature sets without suffering losses in fidelity (Weinberger et al., 2009; Ganchev and Dredze, 2008). It works by collapsing random subsets of features. This step can be performed to speed-up multitask learning later. In some cases, the original feature dimension may be so large that hashed representations may be necessary. The next two steps are key. A multitask learning algorithm is run on the N-best lists, and a common feature space shared by all lists is extracted. For example, if one uses the multitask objective of Eq. 5, the result of step 2 is a set of weights W. ExtractCommonFeature(W) then returns the feature id’s (either from original or hashed representation) that receive nonzero"
W10-1757,P09-1114,0,0.0254945,"help discover better features. Multitask learning is currently an active subfield 381 within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfor"
W10-1757,P05-1024,1,0.783566,"engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield 381 within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jo"
W10-1757,N04-1022,0,0.0383443,"Missing"
W10-1757,P06-1096,0,0.0716939,"., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield 381 within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on p"
W10-1757,P05-1012,0,0.149052,", 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield 381 within m"
W10-1757,N04-1021,0,0.102794,"Missing"
W10-1757,P02-1040,0,0.0791554,"Missing"
W10-1757,2009.iwslt-evaluation.1,0,0.0128431,"feature sets, with corresponding feature size and train/test BLEU/PER. All multitask features give statistically significant improvements over the baselines (boldfaced), e.g. Shared Subspace: 29.1 BLEU vs Baseline: 28.6 BLEU. Combinations of multitask features with high frequency features also give significant improvements over the high frequency features alone. method. Recent work by (Chiang et al., 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Ch"
W10-1757,P08-1098,0,0.0306633,"me applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsity leads to overfitting. We addressed this by re-casting N-best lists as multitask learning data. Our MT experiments show con"
W10-1757,N04-1023,0,0.65709,"nvolving millions of features. 1. We introduce the idea of viewing N-best reranking as a multitask learning problem. This view is particularly apt to any general reranking problem with sparse feature sets. 2. We propose a simple meta-algorithm that first discovers common feature representations across N-bests (via multitask learning) before training a conventional reranker. Thus it is easily applicable to existing systems. 1 Introduction Many natural language processing applications, such as machine translation (MT), parsing, and language modeling, benefit from the N-best reranking framework (Shen et al., 2004; Collins and Koo, 2005; Roark et al., 2007). The advantage of N-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover. In the N-best reranking scenario, the training data consists of sets of hypotheses (i.e. N-best lists) generated by a first-pass system, along with their labels. Given a new N-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list. Existing research have focused on training a single reranker directly on the"
W10-1757,P09-1054,0,0.143227,"Missing"
W10-1757,D07-1080,1,0.936069,") is a D-dimensional feature vector, w is the weight vector to be trained, and N (f ) is the set of likely translations of f , i.e. the N-best list. The feature h(e, f ) can be any quantity defined in terms of the sentence pair, such as translation model and language model probabilities. Here we are interested in situations where the feature definitions can be quite sparse. A common methodology in reranking is to first design feature templates based on linguistic intuition and domain knowledge. Then, numerous features are instantiated based on the training data seen. For example, the work of (Watanabe et al., 2007) defines feature templates based on bilingual word alignments, which lead to extraction of heavilylexicalized features of the form: 2. The input (f ) has high variability (e.g. large vocabulary size), so that features for different inputs are rarely shared. 3. The N-best list output also exhibits high variability (e.g. many different word reorderings). Larger N may improve reranking performance, but may also increase feature sparsity. When the number of features is too large, even popular reranking algorithms such as SVM (Shen et al., 2004) and MIRA (Watanabe et al., 2007; Chiang et al., 2009)"
W10-1757,zhang-etal-2004-interpreting,0,0.0226462,"“de”) or special characters (such as numeral symbol and punctuation). These are features that can be expected to be widely applicable, and it is promising that multitask learning is able to recover these from the millions of potential features. 10 3. All three multitask methods obtained features that outperformed the baseline. The BLEU scores are 28.8, 28.9, 29.1 for Unsupervised Feature Selection, Joint Regularization, and Shared Subspace, respectively, which all outperform the 28.6 baseline. All improvements are statistically significant by bootstrap sampling test (1000 samples, p &lt; 0.05) (Zhang et al., 2004). 300 4. Shared Subspace performed the best. We conjecture this is because its feature projection can create new feature combinations that is more expressive than the feature selection used by the two other methods. Bootstrap samples 250 50 0 −0.2 Wabbit 1.2 5 Related Work in NLP Previous reranking work in NLP can be classified into two different research focuses: 1. Engineering better features: In MT, (Och and others, 2004) investigates features extracted from a wide variety of syntactic representations, such as parse tree probability on the outputs. Although their results show that the propo"
W10-1757,W09-0401,0,\N,Missing
W10-1757,P05-1022,0,\N,Missing
W10-1757,W09-0438,0,\N,Missing
W10-1762,J93-2003,0,0.011344,"ated studies on reordering. Section 3 describes the proposed method in detail. Section 4 presents and discusses our experimental results. Finally, we conclude this paper with our thoughts on future studies. 2 Related Work Reordering in SMT can be roughly classiﬁed into two approaches, namely a search in SMT decoding and preprocessing. The former approach is a straightforward way that models reordering in noisy channel translation, and has been studied from the early period of SMT research. Distance-based reordering is a typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007)"
W10-1762,J07-2003,0,0.366382,"et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difﬁculty of searching over an extremely large search space. The preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even a monotone). Several previous studies have proposed syntax-driven reordering based on source-side parse trees. Xia and Our"
W10-1762,P05-1066,0,0.134623,"Missing"
W10-1762,P98-1070,0,0.140627,"ur method can be seen as a variant of tree-to-string translation that focuses only on the clause structure in parse trees and independently translates the clauses. Although previous syntax-based methods can theoretically model this kind of derivation, it is practically difﬁcult to decode long multi-clause sentences as described above. Our approach is also related to sentence simpliﬁcation and is intended to obtain simple and short source sentences for better translation. Kim and Ehara (1994) proposed a rule-based method for splitting long Japanese sentences for Japaneseto-English translation; Furuse et al. (1998) used a syntactic structure to split ill-formed inputs in speech translation. Their splitting approach splits a sentence sequentially to obtain short segments, and does not undertake their reordering. Another related ﬁeld is clause identiﬁcation (Tjong et al., 2001). The proposed method is not limited to a speciﬁc clause identiﬁcation method and any method can be employed, if their clause deﬁnition matches the proposed method where clauses are independently translated. 3 Bilingual source Corpus (Training) target parse & clause segmentation Source Sentences (clause-segmented) word alignment Wor"
W10-1762,P02-1040,0,0.0837809,"est sentences are multi-clause sentences. Training Corpus Type Parallel (no-clause-seg.) Parallel (auto-aligned) (oracle-aligned) Dictionary Development Corpus Type Parallel (oracle-aligned) Test Corpus Type Parallel (clause-seg.) E J E J J E J #words 690,536 942,913 135,698 183,043 183,147 263,175 291,455 #words E 34,417 J 46,480 E J #words 34,433 45,975 decoders employed two language models: a word 5-gram language model from the Japanese sentences in the parallel corpus and a word 4-gram language model from the Japanese entries in the dictionary. The feature weights were optimized for BLEU (Papineni et al., 2002) by MERT, using the development sentences. 4.4 Results Table 3 shows the results in BLEU, Translation Edit Rate (TER) (Snover et al., 2006), and Position-independent Word-error Rate (PER) (Och et al., 2001), obtained with Moses and our hierarchical phrase-based SMT, respectively. Bold face results indicate the best scores obtained with the compared methods (excluding oracles). The proposed method consistently outperformed the baseline. The BLEU improvements with the proposed method over the baseline and comparison methods were statistically signiﬁcant according to the bootstrap sampling test ("
W10-1762,N04-1035,0,0.0349554,"many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difﬁculty of searching over an extremely large search space. The preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even a monotone). Several previous studies have proposed syntax-driven reorderi"
W10-1762,2006.amta-papers.25,0,0.0712603,"Missing"
W10-1762,N04-1014,0,0.0158515,"typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difﬁculty of searching over an extremely large search space. The preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even a monotone). Several previous studies have proposed s"
W10-1762,N04-4026,0,0.0472133,"ur thoughts on future studies. 2 Related Work Reordering in SMT can be roughly classiﬁed into two approaches, namely a search in SMT decoding and preprocessing. The former approach is a straightforward way that models reordering in noisy channel translation, and has been studied from the early period of SMT research. Distance-based reordering is a typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically"
W10-1762,W01-0708,0,0.0411713,"Missing"
W10-1762,D09-1105,0,0.0200396,"nguistically-motivated clause restructuring rules for German-to-English translation; Li et al. (2007) modeled reordering on parse tree nodes by using a maximum entropy model with surface and syntactic features for Chinese-to-English translation; Katz-Brown and Collins (2008) applied a very simple reverse ordering to Japanese-toEnglish translation, which reversed the word order in Japanese segments separated by a few simple cues; Xu et al. (2009) utilized a dependency parser with several hand-labeled precedence rules for reordering English to subject-object-verb order like Korean and Japanese. Tromble and Eisner (2009) proposed another reordering approach based on a linear ordering problem over source words without a linguistically syntactic structure. These preprocessing methods reorder source words close to the target-side order by employing languagedependent rules or statistical reordering models based on automatic word alignment. Although the use of language-dependent rules is a natural and promising way of bridging gaps between languages with large syntactic differences, the rules are usually unsuitable for other language groups. On the other hand, statistical methods can be applied to any language pai"
W10-1762,J97-3002,0,0.192686,"sed SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difﬁculty of searching over an extremely large search space. The preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even a monotone). Several previous studies have proposed syntax-driven reordering based on source-side parse"
W10-1762,N03-1017,0,0.0275575,"ribes the proposed method in detail. Section 4 presents and discusses our experimental results. Finally, we conclude this paper with our thoughts on future studies. 2 Related Work Reordering in SMT can be roughly classiﬁed into two approaches, namely a search in SMT decoding and preprocessing. The former approach is a straightforward way that models reordering in noisy channel translation, and has been studied from the early period of SMT research. Distance-based reordering is a typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be ext"
W10-1762,C04-1073,0,0.0479303,"Missing"
W10-1762,2005.iwslt-1.8,0,0.0209809,"uture studies. 2 Related Work Reordering in SMT can be roughly classiﬁed into two approaches, namely a search in SMT decoding and preprocessing. The former approach is a straightforward way that models reordering in noisy channel translation, and has been studied from the early period of SMT research. Distance-based reordering is a typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering ove"
W10-1762,N09-1028,0,0.052652,"Computational Linguistics McCord (2004) extracted reordering rules automatically from bilingual corpora for English-toFrench translation; Collins et al. (2005) used linguistically-motivated clause restructuring rules for German-to-English translation; Li et al. (2007) modeled reordering on parse tree nodes by using a maximum entropy model with surface and syntactic features for Chinese-to-English translation; Katz-Brown and Collins (2008) applied a very simple reverse ordering to Japanese-toEnglish translation, which reversed the word order in Japanese segments separated by a few simple cues; Xu et al. (2009) utilized a dependency parser with several hand-labeled precedence rules for reordering English to subject-object-verb order like Korean and Japanese. Tromble and Eisner (2009) proposed another reordering approach based on a linear ordering problem over source words without a linguistically syntactic structure. These preprocessing methods reorder source words close to the target-side order by employing languagedependent rules or statistical reordering models based on automatic word alignment. Although the use of language-dependent rules is a natural and promising way of bridging gaps between l"
W10-1762,P01-1067,0,0.0503465,"ce-based reordering is a typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difﬁculty of searching over an extremely large search space. The preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even a monotone). Several previou"
W10-1762,P07-2045,0,0.00356861,"inal symbol s0 with the second clause and obtain the Japanese sentence: watashi wa tom ga kino susume ta zasshi o kat ta . 4 Experiment We conducted the following experiments on the English-to-Japanese translation of research paper abstracts in the medical domain. Such technical documents are logically and formally written, and sentences are often so long and syntactically complex that their translation needs long distance reordering. We believe that the medical domain is suitable as regards evaluating the proposed method. 4.2 Model and Decoder We used two decoders in the experiments, Moses9 (Koehn et al., 2007) and our inhouse hierarchical phrase-based SMT (almost equivalent to Hiero (Chiang, 2007)). Moses used a phrase table with a maximum phrase length of 7, a lexicalized reordering model with msd-bidirectional-fe, and a distortion limit of 1210 . Our hierarchical phrase-based SMT used a phrase table with a maximum rule length of 7 and a window size (Hiero’s Λ) of 12 11 . Both 4.1 Resources Our bilingual resources were taken from the medical domain. The parallel corpus consisted of research paper abstracts in English taken from PubMed4 and the corresponding Japanese translations. The training port"
W10-1762,zhang-etal-2004-interpreting,0,0.0423294,"Missing"
W10-1762,P07-1091,0,0.327459,"ally follows the Penn Treebank II scheme but also includes SINV, SQ, SBAR. See http://www-tsujii.is.s.u-tokyo.ac.jp/enju/enju-manual/enjuoutput-spec.html#correspondence for details. 418 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 418–427, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics McCord (2004) extracted reordering rules automatically from bilingual corpora for English-toFrench translation; Collins et al. (2005) used linguistically-motivated clause restructuring rules for German-to-English translation; Li et al. (2007) modeled reordering on parse tree nodes by using a maximum entropy model with surface and syntactic features for Chinese-to-English translation; Katz-Brown and Collins (2008) applied a very simple reverse ordering to Japanese-toEnglish translation, which reversed the word order in Japanese segments separated by a few simple cues; Xu et al. (2009) utilized a dependency parser with several hand-labeled precedence rules for reordering English to subject-object-verb order like Korean and Japanese. Tromble and Eisner (2009) proposed another reordering approach based on a linear ordering problem ove"
W10-1762,P06-1077,0,0.0402884,"related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003). Along with the advances in phrase-based SMT, lexicalized reordering with a block orientation model was proposed (Tillmann, 2004; Koehn et al., 2005). This kind of reordering is suitable and commonly used in phrase-based SMT. On the other hand, a syntax-based SMT naturally includes reordering in its translation model. A lot of research work undertaken in this decade has used syntactic parsing for linguistically-motivated translation. (Yamada and Knight, 2001; Graehl and Knight, 2004; Galley et al., 2004; Liu et al., 2006). Wu (1997) and Chiang (2007) focus on formal structures that can be extracted from parallel corpora, instead of a syntactic parser trained using treebanks. These syntactic approaches can theoretically model reordering over an arbitrary length, however, long distance reordering still faces the difﬁculty of searching over an extremely large search space. The preprocessing approach employs deterministic reordering so that the following translation process requires only short distance reordering (or even a monotone). Several previous studies have proposed syntax-driven reordering based on source-"
W10-1762,P06-1004,0,0.0185365,"in our corpora. 421 John lost the book that was borrowed ... clause(1) clause(2) p(that |kara) + p(was |kara ) + ... p(John |john ) + p(lost |john ) + ... john John k|fm ) between each Japanese word fm and English clause k. Theoretically, we can simply output the clause id k ′ for each fm by ﬁnding k ′ = arg maxk t(lm = k|fm ). In practice, this may sometimes lead to Japanese clauses that have too many gaps, so we employ a two-stage procedure to extract clauses that are more contiguous. First, we segment the Japanese sentence into K clauses based on a dynamic programming algorithm proposed by Malioutov and Barzilay (2006). We deﬁne an M × M similarity matrix S = [sij ] with sij = exp(−||li −lj ||) where li is (K + i)-th row vector in the label matrix L. sij represents the similarity between the i-th and j-th Japanese words with respect to their clause alignment score distributions; if the score distributions are similar then sij is large. The details of this algorithm can be found in (Malioutov and Barzilay, 2006). The clause segmentation gives us contiguous Japanese clauses f˜1 , f˜2 , ..., f˜K , thus minimizing inter-segment similarity and maximizing intra-segment similarity. Second, we determine the clause"
W10-1762,J08-1002,0,0.0605287,"Missing"
W10-1762,W01-1408,0,0.038533,"Missing"
W10-1762,C98-1067,0,\N,Missing
W10-1762,J08-3004,0,\N,Missing
W12-4207,W08-0336,0,0.0779511,"Missing"
W12-4207,P05-1066,0,0.323609,"Missing"
W12-4207,C10-1043,0,0.0945607,"oached the reordering problem in multiple ways. The most basic idea is preordering (Xia and McCord, 2004; Collins et al., 2005), that is, to do reordering during preprocessing time, where the source side of the training and development data and sentences from a source language that have to be translated are first reordered to ease the training and the translation, respectively. In (Xu et al., 2009), authors used a dependency parser to introduce manually created preordering rules to reorder English sentences when translating into five different SOV(Subject-ObjectVerb) languages. Other authors (Genzel, 2010; Wu et al., 2011) use automatically generated rules induced from parallel data. Tillmann (2004) used a lexical reordering model, and Galley et al. (2004) followed a syntactic-based model. In this work, however, we are centered in the design of manual rules inspired by the Head Finalization (HF) reordering (Isozaki et al., 2010b). HF reordering is one of the simplest methods for preordering that significantly improves word alignments and leads to a better translation quality. Al59 though the method is limited to translation where the target language is head-final, it requires neither training"
W12-4207,D10-1092,1,0.926453,"Missing"
W12-4207,W10-1736,1,0.0700138,"me Tsukada‡ Masaaki Nagata‡ + The Graduate University For Advanced Studies, Tokyo, Japan ‡ NTT Communication Science Laboratories, NTT Corporation + handan@nii.ac.jp, ∗ wuxianchao@baidu.com, † kevinduh@is.naist.jp ‡ {sudoh.katsuhito, tsukada.hajime, nagata.masaaki}@lab.ntt.co.jp Abstract In Statistical Machine Translation, reordering rules have proved useful in extracting bilingual phrases and in decoding during translation between languages that are structurally different. Linguistically motivated rules have been incorporated into Chineseto-English (Wang et al., 2007) and Englishto-Japanese (Isozaki et al., 2010b) translation with significant gains to the statistical translation system. Here, we carry out a linguistic analysis of the Chinese-to-Japanese translation problem and propose one of the first reordering rules for this language pair. Experimental results show substantially improvements (from 20.70 to 23.17 BLEU) when head-finalization rules based on HPSG parses are used, and further gains (to 24.14 BLEU) were obtained using more refined rules. 1 Introduction In state-of-the-art Statistical Machine Translation (SMT) systems, bilingual phrases are the main building blocks for constructing a tra"
W12-4207,N03-1017,0,0.0605813,"ranslation (SMT) systems, bilingual phrases are the main building blocks for constructing a translation given a sentence from a source language. To extract those bilingual phrases from a parallel corpus, the first step is to discover the implicit wordto-word correspondences between bilingual sentences (Brown et al., 1993). Then, a symmetrization matrix is built (Och and Ney, 2004) by using word-to-word alignments, and a wide variety ∗ Now at Baidu Japan Inc. Now at Nara Institute of Science and Technology (NAIST) † of heuristics can be used to extract the bilingual phrases (Zens et al., 2002; Koehn et al., 2003). This method performs relatively well when the source and the target languages have similar word order, as in the case of French, Spanish, and English. However, when translating between languages with very different structures, as in the case of English and Japanese, or Japanese and Chinese, the quality of extracted bilingual phrases and the overall translation quality diminishes. In the latter scenario, a simple but effective strategy to cope with this problem is to reorder the words of sentences in one language so that it resembles the word order of another language (Wu et al., 2011; Isozak"
W12-4207,P07-2045,0,0.0344953,"Missing"
W12-4207,J08-1002,0,0.110732,"h languages with different phrase structures like English and Japanese. Head Finalization is a successful syntax-based reordering method designed to reorder sentences from a head-initial language to resemble the word order in sentences from a headfinal language (Isozaki et al., 2010b). The essence 58 of this rule is to move the syntactic heads to the end of its dependency by swapping child nodes in a phrase structure tree when the head child appears before the dependent child. Isozaki et al. (2010b) proposed a simple method of Head Finalization, by using an HPSG-based deep parser for English (Miyao and Tsujii, 2008) to obtain phrase structures and head information. The score results from several mainstream evaluation methods indicated that the translation quality had been improved; the scores of Word Error Rate (WER) and Translation Edit Rate (TER) (Snover et al., 2006) had especially been greatly reduced. 2.2 Chinese Deep Parsing Syntax-based reordering methods need parsed sentences as input. Isozaki et al. (2010b) used Enju, an HPSG-based deep parser for English, but they also discussed using other types of parsers, such as word dependency parsers and Penn Treebankstyle parsers. However, to use word de"
W12-4207,J03-1002,0,0.0108902,"reebank. Chinese Enju requires segmented and POS-tagged sentences to do parsing. We used the Stanford Chinese segmenter (Chang et al., 2008) and Stanford POStagger (Toutanova et al., 2003) to obtain the segmentation and POS-tagging of the Chinese side of the training, development, and test sets. The baseline system was trained following the instructions of recent SMT evaluation campaigns (Callison-Burch et al., 2010) by using the MT toolkit Moses (Koehn et al., 2007) in its default configuration. Phrase pairs were extracted from symmetrized word alignments and distortions generated by GIZA++ (Och and Ney, 2003) using the combination of heuristics “grow-diagfinal-and” and “msd-bidirectional-fe”. The language model was a 5-gram language model estimated on the target side of the parallel corpora by using the modified Kneser-Ney smoothing (Chen and Goodman, 1999) implemented in the SRILM (Stolcke, 2002) toolkit. The weights of the log-linear combination of feature functions were estimated by using MERT (Och, 2003) on the development set described in Table 6. The effectiveness of the reorderings proposed in Section 3.3 was assessed by using two precision metrics and two error metrics on translation quali"
W12-4207,J04-4002,0,0.081366,"ally improvements (from 20.70 to 23.17 BLEU) when head-finalization rules based on HPSG parses are used, and further gains (to 24.14 BLEU) were obtained using more refined rules. 1 Introduction In state-of-the-art Statistical Machine Translation (SMT) systems, bilingual phrases are the main building blocks for constructing a translation given a sentence from a source language. To extract those bilingual phrases from a parallel corpus, the first step is to discover the implicit wordto-word correspondences between bilingual sentences (Brown et al., 1993). Then, a symmetrization matrix is built (Och and Ney, 2004) by using word-to-word alignments, and a wide variety ∗ Now at Baidu Japan Inc. Now at Nara Institute of Science and Technology (NAIST) † of heuristics can be used to extract the bilingual phrases (Zens et al., 2002; Koehn et al., 2003). This method performs relatively well when the source and the target languages have similar word order, as in the case of French, Spanish, and English. However, when translating between languages with very different structures, as in the case of English and Japanese, or Japanese and Chinese, the quality of extracted bilingual phrases and the overall translation"
W12-4207,P03-1021,0,0.0679623,"2010) by using the MT toolkit Moses (Koehn et al., 2007) in its default configuration. Phrase pairs were extracted from symmetrized word alignments and distortions generated by GIZA++ (Och and Ney, 2003) using the combination of heuristics “grow-diagfinal-and” and “msd-bidirectional-fe”. The language model was a 5-gram language model estimated on the target side of the parallel corpora by using the modified Kneser-Ney smoothing (Chen and Goodman, 1999) implemented in the SRILM (Stolcke, 2002) toolkit. The weights of the log-linear combination of feature functions were estimated by using MERT (Och, 2003) on the development set described in Table 6. The effectiveness of the reorderings proposed in Section 3.3 was assessed by using two precision metrics and two error metrics on translation quality. The first evaluation metric is BLEU (Papineni et al., 2002), a very common accuracy metric in SMT that measures N -gram precision, with a penalty for too short sentences. The second evaluation metric was RIBES (Isozaki et al., 2010a), a recent precision metric used to evaluate translation quality between structurally different languages. It uses notions on rank correlation coefficients and precision"
W12-4207,P02-1040,0,0.0870379,"w-diagfinal-and” and “msd-bidirectional-fe”. The language model was a 5-gram language model estimated on the target side of the parallel corpora by using the modified Kneser-Ney smoothing (Chen and Goodman, 1999) implemented in the SRILM (Stolcke, 2002) toolkit. The weights of the log-linear combination of feature functions were estimated by using MERT (Och, 2003) on the development set described in Table 6. The effectiveness of the reorderings proposed in Section 3.3 was assessed by using two precision metrics and two error metrics on translation quality. The first evaluation metric is BLEU (Papineni et al., 2002), a very common accuracy metric in SMT that measures N -gram precision, with a penalty for too short sentences. The second evaluation metric was RIBES (Isozaki et al., 2010a), a recent precision metric used to evaluate translation quality between structurally different languages. It uses notions on rank correlation coefficients and precision measures. The third evaluation metric is TER (Snover et al., 2006), another error metric that computes the minimum number of edits required to convert translated sentences into its corresponding references. Possible edits include insertion, deletion, subst"
W12-4207,2006.amta-papers.25,0,0.130258,"(Isozaki et al., 2010b). The essence 58 of this rule is to move the syntactic heads to the end of its dependency by swapping child nodes in a phrase structure tree when the head child appears before the dependent child. Isozaki et al. (2010b) proposed a simple method of Head Finalization, by using an HPSG-based deep parser for English (Miyao and Tsujii, 2008) to obtain phrase structures and head information. The score results from several mainstream evaluation methods indicated that the translation quality had been improved; the scores of Word Error Rate (WER) and Translation Edit Rate (TER) (Snover et al., 2006) had especially been greatly reduced. 2.2 Chinese Deep Parsing Syntax-based reordering methods need parsed sentences as input. Isozaki et al. (2010b) used Enju, an HPSG-based deep parser for English, but they also discussed using other types of parsers, such as word dependency parsers and Penn Treebankstyle parsers. However, to use word dependency parsers, they needed an additional heuristic rule to recover phrase structures, and Penn Treebank-style parsers are problematic because they output flat phrase structures (i.e. a phrase may have multiple dependents, which causes a problem of reorderi"
W12-4207,N04-4026,0,0.0537842,"cCord, 2004; Collins et al., 2005), that is, to do reordering during preprocessing time, where the source side of the training and development data and sentences from a source language that have to be translated are first reordered to ease the training and the translation, respectively. In (Xu et al., 2009), authors used a dependency parser to introduce manually created preordering rules to reorder English sentences when translating into five different SOV(Subject-ObjectVerb) languages. Other authors (Genzel, 2010; Wu et al., 2011) use automatically generated rules induced from parallel data. Tillmann (2004) used a lexical reordering model, and Galley et al. (2004) followed a syntactic-based model. In this work, however, we are centered in the design of manual rules inspired by the Head Finalization (HF) reordering (Isozaki et al., 2010b). HF reordering is one of the simplest methods for preordering that significantly improves word alignments and leads to a better translation quality. Al59 though the method is limited to translation where the target language is head-final, it requires neither training data nor fine-tuning. To our knowledge, HF is the best method to reorder languages when translat"
W12-4207,N03-1033,0,0.00850002,"and extended CWMT Chinese-Japanese corpus. Dev. stands for Development, OoV for “Out of Vocabulary” words, K for thousands of elements, and M for millions of elements. Data statistics were collected after tokenizing. methods. Detailed Corpus statistics can be found in Table 6. To parse Chinese sentences, we used Chinese Enju (Yu et al., 2010), an HPSG-based parser trained with the Chinese HPSG treebank converted from Penn Chinese Treebank. Chinese Enju requires segmented and POS-tagged sentences to do parsing. We used the Stanford Chinese segmenter (Chang et al., 2008) and Stanford POStagger (Toutanova et al., 2003) to obtain the segmentation and POS-tagging of the Chinese side of the training, development, and test sets. The baseline system was trained following the instructions of recent SMT evaluation campaigns (Callison-Burch et al., 2010) by using the MT toolkit Moses (Koehn et al., 2007) in its default configuration. Phrase pairs were extracted from symmetrized word alignments and distortions generated by GIZA++ (Och and Ney, 2003) using the combination of heuristics “grow-diagfinal-and” and “msd-bidirectional-fe”. The language model was a 5-gram language model estimated on the target side of the p"
W12-4207,D07-1077,0,0.101287,"uhito Sudoh‡ Xianchao Wu‡∗ Kevin Duh‡† Hajime Tsukada‡ Masaaki Nagata‡ + The Graduate University For Advanced Studies, Tokyo, Japan ‡ NTT Communication Science Laboratories, NTT Corporation + handan@nii.ac.jp, ∗ wuxianchao@baidu.com, † kevinduh@is.naist.jp ‡ {sudoh.katsuhito, tsukada.hajime, nagata.masaaki}@lab.ntt.co.jp Abstract In Statistical Machine Translation, reordering rules have proved useful in extracting bilingual phrases and in decoding during translation between languages that are structurally different. Linguistically motivated rules have been incorporated into Chineseto-English (Wang et al., 2007) and Englishto-Japanese (Isozaki et al., 2010b) translation with significant gains to the statistical translation system. Here, we carry out a linguistic analysis of the Chinese-to-Japanese translation problem and propose one of the first reordering rules for this language pair. Experimental results show substantially improvements (from 20.70 to 23.17 BLEU) when head-finalization rules based on HPSG parses are used, and further gains (to 24.14 BLEU) were obtained using more refined rules. 1 Introduction In state-of-the-art Statistical Machine Translation (SMT) systems, bilingual phrases are th"
W12-4207,I11-1004,1,0.873372,"02; Koehn et al., 2003). This method performs relatively well when the source and the target languages have similar word order, as in the case of French, Spanish, and English. However, when translating between languages with very different structures, as in the case of English and Japanese, or Japanese and Chinese, the quality of extracted bilingual phrases and the overall translation quality diminishes. In the latter scenario, a simple but effective strategy to cope with this problem is to reorder the words of sentences in one language so that it resembles the word order of another language (Wu et al., 2011; Isozaki et al., 2010b). The advantages of this strategy are two fold. The first advantage is at the decoding stage, since it enables the translation to be constructed almost monotonically. The second advantage is at the training stage, since automatically estimated word-to-word alignments are likely to be more accurate and symmetrization matrices reveal more evident bilingual phrases, leading to the extraction of better quality bilingual phrases and cleaner phrase tables. In this work, we focus on Chinese-to-Japanese translation, motivated by the increasing interaction between these two coun"
W12-4207,C04-1073,0,0.304241,"ute “head” indicates which child node is the syntactic head. In this figure, &lt;head=“c4” id=“c3”> means that the node that has id=“c4” is the syntactic head of the node that has id=“c3”. Figure 1: An XML output for a Chinese sentence from Chinese Enju. For clarity, we only draw information related to the phrase structure and the heads. 2.3 Related Work Reordering is a popular strategy for improving machine translation quality when source and target languages are structurally very different. Researchers have approached the reordering problem in multiple ways. The most basic idea is preordering (Xia and McCord, 2004; Collins et al., 2005), that is, to do reordering during preprocessing time, where the source side of the training and development data and sentences from a source language that have to be translated are first reordered to ease the training and the translation, respectively. In (Xu et al., 2009), authors used a dependency parser to introduce manually created preordering rules to reorder English sentences when translating into five different SOV(Subject-ObjectVerb) languages. Other authors (Genzel, 2010; Wu et al., 2011) use automatically generated rules induced from parallel data. Tillmann (2"
W12-4207,N09-1028,0,0.298949,"the phrase structure and the heads. 2.3 Related Work Reordering is a popular strategy for improving machine translation quality when source and target languages are structurally very different. Researchers have approached the reordering problem in multiple ways. The most basic idea is preordering (Xia and McCord, 2004; Collins et al., 2005), that is, to do reordering during preprocessing time, where the source side of the training and development data and sentences from a source language that have to be translated are first reordered to ease the training and the translation, respectively. In (Xu et al., 2009), authors used a dependency parser to introduce manually created preordering rules to reorder English sentences when translating into five different SOV(Subject-ObjectVerb) languages. Other authors (Genzel, 2010; Wu et al., 2011) use automatically generated rules induced from parallel data. Tillmann (2004) used a lexical reordering model, and Galley et al. (2004) followed a syntactic-based model. In this work, however, we are centered in the design of manual rules inspired by the Head Finalization (HF) reordering (Isozaki et al., 2010b). HF reordering is one of the simplest methods for preorde"
W12-4207,C10-2162,0,0.0590977,"Missing"
W12-4207,W11-2907,0,0.172115,"word dependency parsers and Penn Treebankstyle parsers. However, to use word dependency parsers, they needed an additional heuristic rule to recover phrase structures, and Penn Treebank-style parsers are problematic because they output flat phrase structures (i.e. a phrase may have multiple dependents, which causes a problem of reordering within a phrase). Consequently, compared to different types of parsers, Head-Final English performs the best on the basis of English Enju’s parsing result. In this paper, we follow their observation, and use the HPSG-based parser for Chinese (Chinese Enju) (Yu et al., 2011) for Chinese syntactic parsing. Since Chinese Enju is based on the same parsing model as English Enju, it provides rich syntactic information including phrase structures and syntactic/semantic heads. Figure 1 shows an example of an XML output from Chinese Enju for the sentence “wo (I) qu (go to) dongjing (Tokyo) he (and) jingdu (Kyoto).” The label &lt;cons> and &lt;tok> represent the non-terminal nodes and terminal nodes, respectively. Each node is identified by a unique “id” and has several attributes. The attribute “head” indicates which child node is the syntactic head. In this figure, &lt;head=“c4”"
W12-4207,2002.tmi-tutorials.2,0,0.0338415,"atistical Machine Translation (SMT) systems, bilingual phrases are the main building blocks for constructing a translation given a sentence from a source language. To extract those bilingual phrases from a parallel corpus, the first step is to discover the implicit wordto-word correspondences between bilingual sentences (Brown et al., 1993). Then, a symmetrization matrix is built (Och and Ney, 2004) by using word-to-word alignments, and a wide variety ∗ Now at Baidu Japan Inc. Now at Nara Institute of Science and Technology (NAIST) † of heuristics can be used to extract the bilingual phrases (Zens et al., 2002; Koehn et al., 2003). This method performs relatively well when the source and the target languages have similar word order, as in the case of French, Spanish, and English. However, when translating between languages with very different structures, as in the case of English and Japanese, or Japanese and Chinese, the quality of extracted bilingual phrases and the overall translation quality diminishes. In the latter scenario, a simple but effective strategy to cope with this problem is to reorder the words of sentences in one language so that it resembles the word order of another language (Wu"
W12-4207,J93-2003,0,\N,Missing
W12-4207,D08-1076,0,\N,Missing
Y11-1022,W05-0909,0,0.0350627,"human evaluators subjectively evaluate the results of MT systems from the viewpoints of adequacy and fluency. However, two problems in subjective evaluations have been noted. The first is that the time and cost consumption of such evaluations is high. The second is that the evaluations have poor reproducibility due to the difficulty of reaching agreement on the scoring criteria among the evaluators. Thus, in the past decade, evaluation methods that automatically evaluate MT quality based on its similarity to a reference translation have become common (Papineni et al., 2002; Doddington, 2002; Banerjee and Lavie, 2005; Snover, et al., 2006; Melamed et al., 2007; Isozaki et al., 2010; Birch and Osborne, 2011). Error analysis that investigates the strengths and weaknesses of a translation system is required for developing more accurate translation systems. According to the error analysis, system developers improve the translation rules/dictionaries of rule-based MT systems or add bilingual corpora/dictionaries to statistical MT systems. However, all the evaluation methods mentioned that include human subjective evaluation provide less information for error analysis because they give only one score for each d"
Y11-1022,P11-1103,0,0.0215067,"Missing"
Y11-1022,1995.mtsummit-1.35,0,0.254471,"hat include human subjective evaluation provide less information for error analysis because they give only one score for each document or sentence. Thus, evaluation methods have been proposed that present questions to human evaluators asking whether a sentence contains * This work was conducted as an activity of AAMT (Asia-Pacific Association for Machine Translation) working group Copyright 2011 by T. Nagase, H. Tsukada, K. Kotani, N. Hatanaka, and Y. Sakamoto 25th Pacific Asia Conference on Language, Information and Computation, pages 206–215 206 grammatical error(s) or other type of errors (Isahara, 1995; Joans et al., 2007; Uchimoto et al., 2007; Nagase et al., 2009). These question-based evaluation methods have several features that enable the provision of new viewpoints for evaluation, the evaluation of grammatical coverage, and the provision of better metrics for evaluation combined with conventional automatic evaluation metrics. Joans et al. (2007) used the Defense Language Proficiency Test (DLPT), which was originally developed to measure human language skills in their method. Their method enables MT quality to be evaluated from the viewpoint of “comprehension”. Isahara (1995) developed"
Y11-1022,D10-1092,1,0.768069,"the viewpoints of adequacy and fluency. However, two problems in subjective evaluations have been noted. The first is that the time and cost consumption of such evaluations is high. The second is that the evaluations have poor reproducibility due to the difficulty of reaching agreement on the scoring criteria among the evaluators. Thus, in the past decade, evaluation methods that automatically evaluate MT quality based on its similarity to a reference translation have become common (Papineni et al., 2002; Doddington, 2002; Banerjee and Lavie, 2005; Snover, et al., 2006; Melamed et al., 2007; Isozaki et al., 2010; Birch and Osborne, 2011). Error analysis that investigates the strengths and weaknesses of a translation system is required for developing more accurate translation systems. According to the error analysis, system developers improve the translation rules/dictionaries of rule-based MT systems or add bilingual corpora/dictionaries to statistical MT systems. However, all the evaluation methods mentioned that include human subjective evaluation provide less information for error analysis because they give only one score for each document or sentence. Thus, evaluation methods have been proposed t"
Y11-1022,P02-1040,0,0.084365,"on In the machine translation (MT) field, human evaluators subjectively evaluate the results of MT systems from the viewpoints of adequacy and fluency. However, two problems in subjective evaluations have been noted. The first is that the time and cost consumption of such evaluations is high. The second is that the evaluations have poor reproducibility due to the difficulty of reaching agreement on the scoring criteria among the evaluators. Thus, in the past decade, evaluation methods that automatically evaluate MT quality based on its similarity to a reference translation have become common (Papineni et al., 2002; Doddington, 2002; Banerjee and Lavie, 2005; Snover, et al., 2006; Melamed et al., 2007; Isozaki et al., 2010; Birch and Osborne, 2011). Error analysis that investigates the strengths and weaknesses of a translation system is required for developing more accurate translation systems. According to the error analysis, system developers improve the translation rules/dictionaries of rule-based MT systems or add bilingual corpora/dictionaries to statistical MT systems. However, all the evaluation methods mentioned that include human subjective evaluation provide less information for error analysis"
Y11-1022,2006.amta-papers.25,0,0.022888,"vely evaluate the results of MT systems from the viewpoints of adequacy and fluency. However, two problems in subjective evaluations have been noted. The first is that the time and cost consumption of such evaluations is high. The second is that the evaluations have poor reproducibility due to the difficulty of reaching agreement on the scoring criteria among the evaluators. Thus, in the past decade, evaluation methods that automatically evaluate MT quality based on its similarity to a reference translation have become common (Papineni et al., 2002; Doddington, 2002; Banerjee and Lavie, 2005; Snover, et al., 2006; Melamed et al., 2007; Isozaki et al., 2010; Birch and Osborne, 2011). Error analysis that investigates the strengths and weaknesses of a translation system is required for developing more accurate translation systems. According to the error analysis, system developers improve the translation rules/dictionaries of rule-based MT systems or add bilingual corpora/dictionaries to statistical MT systems. However, all the evaluation methods mentioned that include human subjective evaluation provide less information for error analysis because they give only one score for each document or sentence. T"
Y11-1022,N07-1005,1,0.922584,"tion provide less information for error analysis because they give only one score for each document or sentence. Thus, evaluation methods have been proposed that present questions to human evaluators asking whether a sentence contains * This work was conducted as an activity of AAMT (Asia-Pacific Association for Machine Translation) working group Copyright 2011 by T. Nagase, H. Tsukada, K. Kotani, N. Hatanaka, and Y. Sakamoto 25th Pacific Asia Conference on Language, Information and Computation, pages 206–215 206 grammatical error(s) or other type of errors (Isahara, 1995; Joans et al., 2007; Uchimoto et al., 2007; Nagase et al., 2009). These question-based evaluation methods have several features that enable the provision of new viewpoints for evaluation, the evaluation of grammatical coverage, and the provision of better metrics for evaluation combined with conventional automatic evaluation metrics. Joans et al. (2007) used the Defense Language Proficiency Test (DLPT), which was originally developed to measure human language skills in their method. Their method enables MT quality to be evaluated from the viewpoint of “comprehension”. Isahara (1995) developed the JEIDA test set, which contains example"
Y11-1022,N03-2021,0,\N,Missing
