2021.emnlp-main.421,Refocusing on Relevance: Personalization in {NLG},2021,-1,-1,3,0,9576,shiran dudy,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Many NLG tasks such as summarization, dialogue response, or open domain question answering, focus primarily on a source text in order to generate a target response. This standard approach falls short, however, when a user{'}s intent or context of work is not easily recoverable based solely on that source text{--} a scenario that we argue is more of the rule than the exception. In this work, we argue that NLG systems in general should place a much higher level of emphasis on making use of additional context, and suggest that relevance (as used in Information Retrieval) be thought of as a crucial tool for designing user-oriented text-generating tasks. We further discuss possible harms and hazards around such personalization, and argue that value-sensitive design represents a crucial path forward through these challenges."
2021.emnlp-main.472,Frustratingly Simple but Surprisingly Strong: Using Language-Independent Features for Zero-shot Cross-lingual Semantic Parsing,2021,-1,-1,3,0,6817,jingfeng yang,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"The availability of corpora has led to significant advances in training semantic parsers in English. Unfortunately, for languages other than English, annotated data is limited and so is the performance of the developed parsers. Recently, pretrained multilingual models have been proven useful for zero-shot cross-lingual transfer in many NLP tasks. What else does it require to apply a parser trained in English to other languages for zero-shot cross-lingual semantic parsing? Will simple language-independent features help? To this end, we experiment with six Discourse Representation Structure (DRS) semantic parsers in English, and generalize them to Italian, German and Dutch, where there are only a small number of manually annotated parses available. Extensive experiments show that despite its simplicity, adding Universal Dependency (UD) relations and Universal POS tags (UPOS) as model-agnostic features achieves surprisingly strong improvement on all parsers."
2021.codi-main.10,Revisiting Shallow Discourse Parsing in the {PDTB}-3: Handling Intra-sentential Implicits,2021,-1,-1,2,1,2156,zheng zhao,Proceedings of the 2nd Workshop on Computational Approaches to Discourse,0,"In the PDTB-3, several thousand implicit discourse relations were newly annotated within individual sentences, adding to the over 15,000 implicit relations annotated across adjacent sentences in the PDTB-2. Given that the position of the arguments to these intra-sentential implicits is no longer as well-defined as with inter-sentential implicits, a discourse parser must identify both their location and their sense. That is the focus of the current work. The paper provides a comprehensive analysis of our results, showcasing model performance under different scenarios, pointing out limitations and noting future directions."
2020.lrec-1.129,Shallow Discourse Annotation for {C}hinese {TED} Talks,2020,15,0,4,0,16874,wanqiu long,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Text corpora annotated with language-related properties are an important resource for the development of Language Technology. The current work contributes a new resource for Chinese Language Technology and for Chinese-English translation, in the form of a set of TED talks (some originally given in English, some in Chinese) that have been annotated with discourse relations in the style of the Penn Discourse TreeBank, adapted to properties of Chinese text that are not present in English. The resource is currently unique in annotating discourse-level properties of planned spoken monologues rather than of written text. An inter-annotator agreement study demonstrates that the annotation scheme is able to achieve highly reliable results."
2020.law-1.13,Querent Intent in Multi-Sentence Questions,2020,-1,-1,5,0,18507,laurie burchell,Proceedings of the 14th Linguistic Annotation Workshop,0,"Multi-sentence questions (MSQs) are sequences of questions connected by relations which, unlike sequences of standalone questions, need to be answered as a unit. Following Rhetorical Structure Theory (RST), we recognise that different {``}question discourse relations{''} between the subparts of MSQs reflect different speaker intents, and consequently elicit different answering strategies. Correctly identifying these relations is therefore a crucial step in automatically answering MSQs. We identify five different types of MSQs in English, and define five novel relations to describe them. We extract over 162,000 MSQs from Stack Exchange to enable future research. Finally, we implement a high-precision baseline classifier based on surface features."
2020.iwdp-1.8,Bridging Question Answering and Discourse The case of Multi-Sentence Questions,2020,-1,-1,1,1,9578,bonnie webber,Proceedings of the Second International Workshop of Discourse Processing,0,"In human question-answering (QA), questions are often expressed in the form of multiple sentences. One can see this in both spoken QA interactions, when one person asks a question of another, and written QA, such as are found on-line in FAQs and in what are called {''}Community Question-Answering Forums{''}. Computer-based QA has taken the challenge of these {''}multi-sentence questions{''} to be that of breaking them into an appropriately ordered sequence of separate questions, with both the previous questions and their answers serving as context for the next question. This can be seen, for example, in two recent workshops at AAAI called {''}Reasoning for Complex QA{''} [https://rcqa-ws.github.io/program/]. We claim that, while appropriate for some types of {''}multi-sentence questions{''} (MSQs), it is not appropriate for all, because they are essentially different types of discourse. To support this claim, we need to provide evidence that: {\mbox{$\bullet$}} different types of MSQs are answered differently in written or spoken QA between people; {\mbox{$\bullet$}} people can (and do) distinguish these different types of MSQs; {\mbox{$\bullet$}} systems can be made to both distinguish different types of MSQs and provide appropriate answers."
2020.findings-emnlp.203,Reducing Quantity Hallucinations in Abstractive Summarization,2020,-1,-1,3,1,2156,zheng zhao,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"It is well-known that abstractive summaries are subject to hallucination{---}including material that is not supported by the original text. While summaries can be made hallucination-free by limiting them to general phrases, such summaries would fail to be very informative. Alternatively, one can try to avoid hallucinations by verifying that any specific entities in the summary appear in the original text in a similar context. This is the approach taken by our system, Herman. The system learns to recognize and verify quantity entities (dates, numbers, sums of money, etc.) in a beam-worth of abstractive summaries produced by state-of-the-art models, in order to up-rank those summaries whose quantity terms are supported by the original text. Experimental results demonstrate that the ROUGE scores of such up-ranked summaries have a higher Precision than summaries that have not been up-ranked, without a comparable loss in Recall, resulting in higher F1. Preliminary human evaluation of up-ranked vs. original summaries shows people{'}s preference for the former."
2020.emnlp-main.223,{TED}-{CDB}: A Large-Scale {C}hinese Discourse Relation Dataset on {TED} Talks,2020,-1,-1,2,0,16874,wanqiu long,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"As different genres are known to differ in their communicative properties and as previously, for Chinese, discourse relations have only been annotated over news text, we have created the TED-CDB dataset. TED-CDB comprises a large set of TED talks in Chinese that have been manually annotated according to the goals and principles of Penn Discourse Treebank, but adapted to features that are not present in English. It serves as a unique Chinese corpus of spoken discourse. Benchmark experiments show that TED-CDB poses a challenge for state-of-the-art discourse relation classifiers, whose F1 performance on 4-way classification is 60{\%}. This is a dramatic drop of 35{\%} from performance on the news text in the Chinese Discourse Treebank. Transfer learning experiments have been carried out with the TED-CDB for both same-language cross-domain transfer and same-domain cross-language transfer. Both demonstrate that the TED-CDB can improve the performance of systems being developed for languages other than Chinese and would be helpful for insufficient or unbalanced data in other corpora. The dataset and our Chinese annotation guidelines will be made freely available."
2020.codi-1.14,Extending Implicit Discourse Relation Recognition to the {PDTB}-3,2020,-1,-1,3,0,4540,li liang,Proceedings of the First Workshop on Computational Approaches to Discourse,0,"The PDTB-3 contains many more Implicit discourse relations than the previous PDTB-2. This is in part because implicit relations have now been annotated within sentences as well as between them. In addition, some now co-occur with explicit discourse relations, instead of standing on their own. Here we show that while this can complicate the problem of identifying the location of implicit discourse relations, it can in turn simplify the problem of identifying their senses. We present data to support this claim, as well as methods that can serve as a non-trivial baseline for future state-of-the-art recognizers for implicit discourse relations."
W19-4011,A Framework for Annotating {`}Related Works{'} to Support Feedback to Novice Writers,2019,0,0,2,0,24305,arlene casey,Proceedings of the 13th Linguistic Annotation Workshop,0,"Understanding what is expected of academic writing can be difficult for novice writers to assimilate, and recent years have seen several automated tools become available to support academic writing. Our work presents a framework for annotating features of the Related Work section of academic writing, that supports writer feedback."
W19-0411,Ambiguity in Explicit Discourse Connectives,2019,-1,-1,1,1,9578,bonnie webber,Proceedings of the 13th International Conference on Computational Semantics - Long Papers,0,"Discourse connectives are known to be subject to both usage and sense ambiguity, as has already been discussed in the literature. But discourse connectives are no different from other linguistic expressions in being subject to other types of ambiguity as well. Four are illustrated and discussed here."
R19-1021,Classifying Author Intention for Writer Feedback in Related Work,2019,0,0,2,0,24305,arlene casey,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"The ability to produce high-quality publishable material is critical to academic success but many Post-Graduate students struggle to learn to do so. While recent years have seen an increase in tools designed to provide feedback on aspects of writing, one aspect that has so far been neglected is the Related Work section of academic research papers. To address this, we have trained a supervised classifier on a corpus of 94 Related Work sections and evaluated it against a manually annotated gold standard. The classifier uses novel features pertaining to citation types and co-reference, along with patterns found from studying Related Works. We show that these novel features contribute to classifier performance with performance being favourable compared to other similar works that classify author intentions and consider feedback for academic writing."
D19-1462,{GECOR}: An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue,2019,0,0,3,0,20117,jun quan,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Ellipsis and co-reference are common and ubiquitous especially in multi-turn dialogues. In this paper, we treat the resolution of ellipsis and co-reference in dialogue as a problem of generating omitted or referred expressions from the dialogue context. We therefore propose a unified end-to-end Generative Ellipsis and CO-reference Resolution model (GECOR) in the context of dialogue. The model can generate a new pragmatically complete user utterance by alternating the generation and copy mode for each user utterance. A multi-task learning framework is further proposed to integrate the GECOR into an end-to-end task-oriented dialogue. In order to train both the GECOR and the multi-task learning framework, we manually construct a new dataset on the basis of the public dataset CamRest676 with both ellipsis and co-reference annotation. On this dataset, intrinsic evaluations on the resolution of ellipsis and co-reference show that the GECOR model significantly outperforms the sequence-to-sequence (seq2seq) baseline model in terms of EM, BLEU and F1 while extrinsic evaluations on the downstream dialogue task demonstrate that our multi-task learning framework with GECOR achieves a higher success rate of task completion than TSCP, a state-of-the-art end-to-end task-oriented dialogue model."
W18-4710,Discourse Annotation in the {PDTB}: The Next Generation,2018,-1,-1,2,0,4772,rashmi prasad,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,None
P18-1210,Discourse Coherence: Concurrent Explicit and Implicit Relations,2018,0,3,4,1,16894,hannah rohde,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Theories of discourse coherence posit relations between discourse segments as a key feature of coherent text. Our prior work suggests that multiple discourse relations can be simultaneously operative between two segments for reasons not predicted by the literature. Here we test how this joint presence can lead participants to endorse seemingly divergent conjunctions (e.g., BUT and SO) to express the link they see between two segments. These apparent divergences are not symptomatic of participant naivety or bias, but arise reliably from the concurrent availability of multiple relations between segments {--} some available through explicit signals and some via inference. We believe that these new results can both inform future progress in theoretical work on discourse coherence and lead to higher levels of performance in discourse parsing."
L18-1005,Evaluating Machine Translation Performance on {C}hinese Idioms with a Blacklist Method,2018,-1,-1,3,0,4868,yutong shao,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1547,{N}eg{P}ar: A parallel corpus annotated for negation,2018,0,3,3,0,9802,qianchu liu,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
J18-3001,{O}bituary: Aravind {K}. Joshi,2018,-1,-1,1,1,9578,bonnie webber,Computational Linguistics,0,None
D18-1466,Getting to {``}Hearer-old{''}: Charting Referring Expressions Across Time,2018,0,1,3,0,20574,ieva staliunaite,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"When a reader is first introduced to an entity, its referring expression must describe the entity. For entities that are widely known, a single word or phrase often suffices. This paper presents the first study of how expressions that refer to the same entity develop over time. We track thousands of person and organization entities over 20 years of New York Times (NYT). As entities move from hearer-new (first introduction to the NYT audience) to hearer-old (common knowledge) status, we show empirically that the referring expressions along this trajectory depend on the type of the entity, and exhibit linguistic properties related to becoming common knowledge (e.g., shorter length, less use of appositives, more definiteness). These properties can also be used to build a model to predict how long it will take for an entity to reach hearer-old status. Our results reach 10-30{\%} absolute improvement over a majority-class baseline."
W17-6814,Exploring Substitutability through Discourse Adverbials and Multiple Judgments,2017,-1,-1,5,1,16894,hannah rohde,{IWCS} 2017 - 12th International Conference on Computational Semantics - Long papers,0,None
W17-1804,{U}niversal {D}ependencies to Logical Form with Negation Scope,2017,5,1,4,1,9655,federico fancellu,Proceedings of the Workshop Computational Semantics Beyond Events and Roles,0,"Many language technology applications would benefit from the ability to represent negation and its scope on top of widely-used linguistic resources. In this paper, we investigate the possibility of obtaining a first-order logic representation with negation scope marked using \textit{Universal Dependencies}. To do so, we enhance \textit{UDepLambda}, a framework that converts dependency graphs to logical forms. The resulting \textit{UDepLambda$\lnot$ }is able to handle phenomena related to scope by means of an higher-order type theory, relevant not only to negation but also to universal quantification and other complex semantic phenomena. The initial conversion we did for English is promising, in that one can represent the scope of negation also in the presence of more complex phenomena such as universal quantifiers."
W17-1809,Neural Networks for Negation Cue Detection in {C}hinese,2017,2,1,3,0,8890,hangfeng he,Proceedings of the Workshop Computational Semantics Beyond Events and Roles,0,"Negation cue detection involves identifying the span inherently expressing negation in a negative sentence. In Chinese, negative cue detection is complicated by morphological proprieties of the language. Previous work has shown that negative cue detection in Chinese can benefit from specific lexical and morphemic features, as well as cross-lingual information. We show here that they are not necessary: A bi-directional LSTM can perform equally well, with minimal feature engineering. In particular, the use of a character-based model allows us to capture characteristics of negation cues in Chinese using word-embedding information only. Not only does our model performs on par with previous work, further error analysis clarifies what problems remain to be addressed."
E17-4004,Discourse Relations and Conjoined {VP}s: Automated Sense Recognition,2017,13,0,2,0,8857,valentina pyatkin,Proceedings of the Student Research Workshop at the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Sense classification of discourse relations is a sub-task of shallow discourse parsing. Discourse relations can occur both across sentences (\textit{inter-sentential}) and within sentences (\textit{intra-sentential}), and more than one discourse relation can hold between the same units. Using a newly available corpus of discourse-annotated intra-sentential conjoined verb phrases, we demonstrate a sequential classification pipeline for their multi-label sense classification. We assess the importance of each feature used in the classification, the feature scope, and what is lost in moving from gold standard manual parses to the output of an off-the-shelf parser."
E17-2010,"Detecting negation scope is easy, except when it isn{'}t",2017,3,1,3,1,9655,federico fancellu,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Several corpora have been annotated with negation scope{---}the set of words whose meaning is negated by a cue like the word {``}not{''}{---}leading to the development of classifiers that detect negation scope with high accuracy. We show that for nearly all of these corpora, this high accuracy can be attributed to a single fact: they frequently annotate negation scope as a single span of text delimited by punctuation. For negation scopes not of this form, detection accuracy is low and under-sampling the easy training examples does not substantially improve accuracy. We demonstrate that this is partly an artifact of annotation guidelines, and we argue that future negation scope annotation efforts should focus on these more difficult cases."
W16-2345,Findings of the 2016 {WMT} Shared Task on Cross-lingual Pronoun Prediction,2016,20,11,8,0.833333,5894,liane guillou,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"We describe the design, the evaluation setup, and the results of the 2016 WMT shared task on cross-lingual pronoun prediction. This is a classification task in which participants are asked to provi ..."
W16-1704,A Discourse-Annotated Corpus of Conjoined {VP}s,2016,13,12,1,1,9578,bonnie webber,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,"English grammars indicate a variety of relations holding between conjoined VPs. VPs conjoined by and evince such senses as Result, Temporal Sequence and Concession. Although all these senses are ones associated with discourse relations, conjoined VPs have not been fully included in discourse annotation. Because of the value of discourse-annotated corpora for developing approaches to automated sense recognition, we have added their annotation to the Penn Discourse TreeBank. This paper describes how tokens were identified; how the process of span and sense annotation was modified and extended in order to keep the annotation of intra-sentential multi-clausal structures consistent with the rest of the corpus; and what the resulting corpus looks like, in terms of token frequency and common sense patterns."
W16-1707,"Filling in the Blanks in Understanding Discourse Adverbials: Consistency, Conflict, and Context-Dependence in a Crowdsourced Elicitation Task",2016,20,2,6,1,16894,hannah rohde,Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with {ACL} 2016 ({LAW}-X 2016),0,"The semantic relationship between a sentence and its context may be marked explicitly, or left to inference. Rohde et al. (2015) showed that, contrary to common assumptions, this isnxe2x80x99t exclusive or: a conjunction can often be inferred alongside an explicit discourse adverbial. Here we broaden the investigation to a larger set of 20 discourse adverbials by eliciting 28K conjunction completions via crowdsourcing. Our data replicate and extend Rohde et al.xe2x80x99s findings that discourse adverbials do indeed license inferred conjunctions. Further, the diverse patterns observed for the adverbials include cases in which more than one valid connection can be inferred, each one endorsed by a substantial number of participants; such differences in annotation might otherwise be written off as annotator error or bias, or just a low level of inter-annotator agreement. These results will inform future discourse annotation endeavors by revealing where it is necessary to entertain implicit relations and elicit several judgments to fully characterize discourse relationships."
P16-1047,Neural Networks For Negation Scope Detection,2016,16,25,3,1,9655,federico fancellu,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
L16-1629,Inconsistency Detection in Semantic Annotation,2016,18,9,3,0,3242,nora hollenstein,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,Inconsistencies are part of any manually annotated corpus. Automatically finding these inconsistencies and correcting them (even manually) can increase the quality of the data. Past research has focused mainly on detecting inconsistency in syntactic annotation. This work explores new approaches to detecting inconsistency in semantic annotation. Two ranking methods are presented in this paper: a discrepancy ranking and an entropy ranking. Those methods are then tested and evaluated on multiple corpora annotated with multiword expressions and supersense labels. The results show considerable improvements in detecting inconsistency candidates over a random baseline. Possible applications of methods for inconsistency detection are improving the annotation procedure as well as the guidelines and correcting errors in completed annotations.
K16-2001,{C}o{NLL} 2016 Shared Task on Multilingual Shallow Discourse Parsing,2016,35,36,5,0,10294,nianwen xue,Proceedings of the {C}o{NLL}-16 shared task,0,"The CoNLL-2016 Shared Task is the second edition of the CoNLL-2015 Shared Task, now on Multilingual Shallow discourse parsing. Similar to the 2015 task, the goal of the shared task is to identify individual discourse relations that are present in natural language text. Given a natural language text, participating teams are asked to locate the discourse connectives (explicit or implicit) and their arguments as well as predicting the sense of the discourse connectives. Based on the success of the previous year, we continued to ask participants to deploy their systems on TIRA, a web-based platform on which participants can run their systems on the test data for evaluation. This evaluation methodology preserves the integrity of the shared task. We have also made a few changes and additions in the 2016 shared task based on the feedback from 2015. The first is that teams could choose to carry out the task on Chinese texts, or English texts, or both. We have also allowed participants to focus on parts of the shared task (rather than the whole thing) as a typical system requires substantial investment of effort. Finally, we have modified the scorer so that it can report results based on partial matches of the arguments. 23 teams participated in this yearxe2x80x99s shared task, using a wide variety of approaches. In this overview paper, we present the task definition, the training and test sets, and the evaluation protocol and metric used during this shared task. We also summarize the different approaches adopted by the participating teams, and present the evaluation results. The evaluation data sets and the scorer will serve as a benchmark for future research on shallow discourse parsing."
C16-2026,Annotating Discourse Relations with the {PDTB} Annotator,2016,6,2,3,1,24887,alan lee,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"The PDTB Annotator is a tool for annotating and adjudicating discourse relations based on the annotation framework of the Penn Discourse TreeBank (PDTB). This demo describes the benefits of using the PDTB Annotator, gives an overview of the PDTB Framework and discusses the tool{'}s features, setup requirements and how it can also be used for adjudication."
W15-2703,Recovering discourse relations: Varying influence of discourse adverbials,2015,12,2,5,1,16894,hannah rohde,"Proceedings of the First Workshop on Linking Computational Models of Lexical, Sentential and Discourse-level Semantics",0,"Discourse relations are a bridge between sentence-level semantics and discourselevel semantics. They can be signalled explicitly with discourse connectives or conveyed implicitly, to be inferred by a comprehender. The same discourse units can be related in more than one way, signalled by multiple connectives. But multiple connectives arenxe2x80x99t necessary: Multiple relations can be conveyed even when only one connective is explicit. This paper describes the initial phase in a larger experimental study aimed at answering two questions: (1) Given an explicit discourse adverbial, what discourse relation(s) do naive subjects take to be operative, and (2) Can this be predicted on the basis of the explicit adverbial alone, or does it depend instead on other factors?"
W15-2707,Bridging Sentential and Discourse-level Semantics through Clausal Adjuncts,2015,16,2,2,0.796437,4772,rashmi prasad,"Proceedings of the First Workshop on Linking Computational Models of Lexical, Sentential and Discourse-level Semantics",0,"It is in PropBankxe2x80x99s ARGM annotation of clausal adjuncts that sentential semantics meets discourse relation annotation in the Penn Discourse TreeBank. This paper discusses complementarities between the two annotation systems: How PropBank ARGM annotation can be used to seed annotation of additional discourse relations in the PDTB, and how PDTB annotation can be used to refine or enrich PropBank ARGM annotation."
W15-2503,Analysing {P}ar{C}or and its Translations by State-of-the-art {SMT} Systems,2015,11,0,2,1,5894,liane guillou,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"Previous work on pronouns in SMT has focussed on third-person pronouns, treating them all as anaphoric. Little attention has been paid to other uses or other types of pronouns. Believing that further progress requires careful analysis of pronouns as a whole, we have analysed a parallel corpus of annotated English-German texts to highlight some of the problems that hinder progress. We combine this with an assessment of the ability of two state-of-the-art systems to translate different pronoun types."
W15-2516,A Maximum Entropy Classifier for Cross-Lingual Pronoun Prediction,2015,12,4,3,0,33898,dominikus wetzel,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"We present a maximum entropy classifier for cross-lingual pronoun prediction. The features are based on local source- and target-side contexts and antecedent information obtained by a co-reference resolution system. With only a small set of feature types our best performing system achieves an accuracy of 72.31%. According to the shared taskxe2x80x99s official macroaveraged F1-score at 57.07%, we are among the top systems, at position three out of 14. Feature ablation results show the important role of target-side information in general and of the resolved targetside antecedent in particular for predicting the correct classes."
W15-1301,Translating Negation: A Manual Error Analysis,2015,19,6,2,1,9655,federico fancellu,Proceedings of the Second Workshop on Extra-Propositional Aspects of Meaning in Computational Semantics ({E}x{P}ro{M} 2015),0,"Statistical Machine Translation has come a long way improving the translation quality of a range of different linguistic phenomena. With negation however, techniques proposed and implemented for improving translation performance on negation have simply followed from the developersxe2x80x99 beliefs about why performance is worse. These beliefs, however, have never been validated by an error analysis of the translation output. In contrast, the current paper shows that an informative empirical error analysis can be formulated in terms of (1) the set of semantic elements involved in the meaning of negation, and (2) a small set of string-based operations that can characterise errors in the translation of those elements. Results on a Chinese-to-English translation task confirm the robustness of our analysis cross-linguistically and the basic assumptions can inform an automated investigation into the causes of translation errors. Conclusions drawn from this analysis should guide future work on improving the translation of negative sentences."
W15-1003,"Translating Negation: Induction, Search And Model Errors",2015,22,0,2,1,9655,federico fancellu,"Proceedings of the Ninth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Statistical Machine Translation systems show considerably worse performance in translating negative sentences than positive ones (Fancellu and Webber, 2014; Wetzel and Bond, 2012). Various techniques have addressed the problem of translating negation, but their underlying assumptions have never been validated by a proper error analysis. A related paper (Fancellu and Webber, 2015) reports on a manual error analysis of the kinds of errors involved in translating negation. The present paper presents ongoing work to discover their causes by considering which, if any, are induction, search or model errors. We show that standard oracle decoding techniques provide little help due to the locality of negation scope and their reliance on a single reference. We are working to address these weaknesses using a chart analysis based on oracle hypotheses, guided by the negation elements contained in a source span and by how these elements are expected to be translated at each decoding step. Preliminary results show chart analysis is able to give a more in-depth analysis of the above errors and better explains the results of the manual analysis."
Y14-1004,Discourse for Machine Translation.,2014,0,1,1,1,9578,bonnie webber,"Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing",0,None
guillou-etal-2014-parcor,{P}ar{C}or 1.0: A Parallel Pronoun-Coreference Corpus to Support Statistical {MT},2014,27,22,5,1,5894,liane guillou,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present ParCor, a parallel corpus of texts in which pronoun coreference â reduced coreference in which pronouns are used as referring expressions â has been annotated. The corpus is intended to be used both as a resource from which to learn systematic differences in pronoun use between languages and ultimately for developing and testing informed Statistical Machine Translation systems aimed at addressing the problem of pronoun coreference in translation. At present, the corpus consists of a collection of parallel English-German documents from two different text genres: TED Talks (transcribed planned speech), and EU Bookshop publications (written text). All documents in the corpus have been manually annotated with respect to the type and location of each pronoun and, where relevant, its antecedent. We provide details of the texts that we selected, the guidelines and tools used to support annotation and some corpus statistics. The texts in the corpus have already been translated into many languages, and we plan to expand the corpus into these other languages, as well as other genres, in the future."
J14-4007,"Reflections on the {P}enn {D}iscourse {T}ree{B}ank, Comparable Corpora, and Complementary Annotation",2014,77,38,2,0.895013,4772,rashmi prasad,Computational Linguistics,0,"The Penn Discourse Treebank (PDTB) was released to the public in 2008. It remains the largest manually annotated corpus of discourse relations to date. Its focus on discourse relations that are either lexically-grounded in explicit discourse connectives or associated with sentential adjacency has not only facilitated its use in language technology and psycholinguistics but also has spawned the annotation of comparable corpora in other languages and genres.n n Given this situation, this paper has four aims: (1) to provide a comprehensive introduction to the PDTB for those who are unfamiliar with it; (2) to correct some wrong (or perhaps inadvertent) assumptions about the PDTB and its annotation that may have weakened previous results or the performance of decision procedures induced from the data; (3) to explain variations seen in the annotation of comparable resources in other languages and genres, which should allow developers of future comparable resources to recognize whether the variations are relevant to them; and (4) to enumerate and explain relationships between PDTB annotation and complementary annotation of other linguistic phenomena. The paper draws on work done by ourselves and others since the corpus was released."
E14-1017,Structured and Unstructured Cache Models for {SMT} Domain Adaptation,2014,18,9,2,0,20595,annie louis,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present a French to English translation system for Wikipedia biography articles. We use training data from outof-domain corpora and adapt the system for biographies. We propose two forms of domain adaptation. The first biases the system towards words likely in biographies and encourages repetition of words across the document. Since biographies in Wikipedia follow a regular structure, our second model exploits this structure as a sequence of topic segments, where each segment discusses a narrower subtopic of the biography domain. In this structured model, the system is encouraged to use words likely in the current segmentxe2x80x99s topic rather than in biographies as a whole. We implement both systems using cachebased translation techniques. We show that a system trained on Europarl and news can be adapted for biographies with 0.5 BLEU score improvement using our models. Further the structure-aware model outperforms the system which treats the entire document as a single segment."
E14-1063,Applying the semantics of negation to {SMT} through n-best list re-ranking,2014,15,5,2,1,9655,federico fancellu,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Although the performance of SMT systems has improved over a range of different linguistic phenomena, negation has not yet received adequate treatment. Previous works have considered the problem of translating negative data as one of data sparsity (Wetzel and Bond (2012)) or of structural differences between source and target language with respect to the placement of negation (Collins et al. (2005)). This work starts instead from the questions of what is meant by negation and what makes a good translation of negation. These questions have led us to explore the use of semantics of negation in SMT xe2x80x94 specifically, identifying core semantic elements of negation (cue, event and scope) in a source-side dependency parse and reranking hypotheses on the n-best list produced after decoding according to the extent to which an hypothesis realises these elements. The method shows considerable improvement over the baseline as measured by BLEU scores and Stanfordxe2x80x99s entailmentbased MT evaluation metric (Pado et al."
W13-4001,"Discourse Relations, Discourse Structure, Discourse Semantics",2013,0,0,1,1,9578,bonnie webber,Proceedings of the {SIGDIAL} 2013 Conference,0,"It is generally accepted that a discourse connective expresses a semantic and/or pragmatic relation between its matrix sentence or clause and something in the previous discourse. Usually the sense of this relation is expressed as a label, often within a hierarchy of sense labels. But the meaning of these labels may vary from system to system, and the same connective may be assigned different labels in different systems. Given this, we might learn more and make better predictions if (i) sense labels were associated with (some of) their entailments and (ii) connectives were characterized in terms of both their formal properties and their use conditions. Ixe2x80x99ll give examples of both. The above-mentioned predictions tie in with an interesting property of Penn Discourse TreeBank annotation. Annotators were allowed to assign multiple sense labels to a single connective, to imply that all the senses held simultaneously. For those cases where adjacent sentences lacked an intervening connective, annotators were instructed to try to insert one or more connectives that (together) expressed the relation(s) between the sentences. Here too, in many cases, annotators inserted a single connective to which they assigned multiple meanings, Other times they inserted multiple connectives to convey the relation(s) they took as being expressed. Some of this will be shown to make more sense in terms of the entailments and formal properties of the connectives than in terms of any sense labels. Ixe2x80x99ll close by trying to distinguish discourse connectives that are associated with coordinating or subordinating relations between sentences or clauses, which is an feature of discourse structure, from those connectives that simply convey additional relevant semantic or pragmatic content."
W13-3303,Implicitation of Discourse Connectives in (Machine) Translation,2013,13,30,2,0,39466,thomas meyer,Proceedings of the Workshop on Discourse in Machine Translation,0,"Explicit discourse connectives in a source language text are not always translated to comparable words or phrases in the target language. The paper provides a corpus analysis and a method for semi-automatic detection of such cases. Results show that discourse connectives are not translated into comparable forms (or even any form at all), in up to 18% of human reference translations from English to French or German. In machine translation, this happens much less frequently (up to 8% only). Work in progress aims to capture this natural implicitation of discourse connectives in current statistical machine translation models."
W13-0124,What excludes an Alternative in Coherence Relations?,2013,-1,-1,1,1,9578,bonnie webber,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers,0,None
U13-1002,Concurrent Discourse Relations,2013,0,1,1,1,9578,bonnie webber,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"The Penn Discourse Treebank (PDTB) was released to the public in 2008 and remains the largest corpus of manually annotated discourse relations xe2x80x94 both relations that are signaled explicitly (e.g., by a coordinating or subordinating conjunction, or by a discourse adverbial or other construction) and ones that otherwise appear implicit. The Penn Discourse TreeBank also diverges from other discourse-annotated corpora in permitting more than one discourse relation to be annotated as holding concurrently. Annotators could indicate this by assigning multiple sense labels to an explicit connective. Or, in those cases where adjacent sentences had no explicit connective, annotators could indicate concurrent discourse relations by either annotating a single implicit connective that concurrently conveyed multiple senses or annotating multiple implicit connectives, each conveying one of the concurrent relation(s). Subsequent experiments carried out using Mechanical Turk showed that, when a discourse adverbial explicitly signalled a discourse relation, there was often a separate concurrent relation that could be associated with an implicit coordinating or subordinating conjunction. There are different circumstances in which different sets of concurrent discourse relations are taken to hold. I will go through these, and conclude with what I take the implications of this to be for various language technologies, including statistical machine translation. Bonnie Webber. 2013. Concurrent Discourse Relations. In Proceedings of Australasian Language Technology Association Workshop, page 3."
P13-1163,Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation,2013,14,6,8,0,38858,srinivasan janarthanam,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
W12-3205,"Discourse Structure and Computation: Past, Present and Future",2012,105,18,1,1,9578,bonnie webber,Proceedings of the {ACL}-2012 Special Workshop on Rediscovering 50 Years of Discoveries,0,"The discourse properties of text have long been recognized as critical to language technology, and over the past 40 years, our understanding of and ability to exploit the discourse properties of text has grown in many ways. This essay briefly recounts these developments, the technology they employ, the applications they support, and the new challenges that each subsequent development has raised. We conclude with the challenges faced by our current understanding of discourse, and the applications that meeting these challenges will promote."
J12-4007,Book Review: Discourse Processing by Manfred Stede,2012,-1,-1,1,1,9578,bonnie webber,Computational Linguistics,0,None
W11-4603,Invited Paper: Discourse Structures and Language Technologies,2011,50,0,1,1,9578,bonnie webber,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,"I want to tell a story about computational approaches to discourse structure. Like all such stories, it takes some liberty with actual events and times, but I think stories put things into perspective, and make it easier to understand where we are and how we might progress. Part 1 of the story (Section 2) is the past. Here we see early computational work on discourse structure aiming to assign a simple tree structure to a discourse. At issue was what its internal nodes corresponded to. The debate was fierce, and suggestions that other structures might be more appropriate were ignored or subjected to ridicule. The main uses of discourse structure were text generation and summarization, but mostly in small-scale experiments. Part 2 of the story (Section 3) is the present. We now see different types of discourse structure being recognized, though perhaps not always clearly distinguished. An increasing number of credible efforts are aimed at recognizing these structures automatically, though performance on unrestricted text still resembles that of the early days of robust parsing. Generic applications are also beginning to appear, as researchers recognize the value of these structures to tasks of interest to them. Part 3 of the story (Section 4) is the future. We now see the need for a mid-line between approaches hostage to theory and empirical approaches free of theory. An empirical approach underpinned by theory will not only motivate sensible back-off strategies in the face of unseen data, but also enable us to understand how the different discourse structures inter-relate and thereby to exploit their mutual recognition. This should allow more challenging applications, such as improving the performance of statistical machine translation (SMT) through the extended locality of discourse structures and the linguistic phenomena they correlate with."
J11-2004,{S}quibs: Stable Classification of Text Genres,2011,12,28,2,0,43555,philipp petrenz,Computational Linguistics,0,"Every text has at least one topic and at least one genre. Evidence for a text's topic and genre comes, in part, from its lexical and syntactic features-features used in both Automatic Topic Classification and Automatic Genre Classification (AGC). Because an ideal AGC system should be stable in the face of changes in topic distribution, we assess five previously published AGC methods with respect to both performance on the same topic-genre distribution on which they were trained and stability of that performance across changes in topic-genre distribution. Our experiments lead us to conclude that (1) stability in the face of changing topical distributions should be added to the evaluation critera for new approaches to AGC, and (2) Part-of-Speech features should be considered individually when developing a high-performing, stable AGC system for a particular, possibly changing corpus."
P10-5003,"Discourse Structure: Theory, Practice and Use",2010,8,0,1,1,9578,bonnie webber,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,"This tutorial consists of four parts. Part I starts with a brief introduction to different bases for discourse structuring, properties of discourse structure that are relevant to LT, and accessible evidence for discourse structure. For discourse structure to be useful for language technologies, one must be able to automatically recognize or generate with it. Hence, Part II surveys computational approaches to recognizing and generating discourse structure, both manuallyauthored approaches and ones developed through Machine Learning. Part III of the tutorial describes applications of discourse structure recognition and generation in LT, as well as discourse-related resources being made available in English, German, Turkish, Hindi, Czech, Arabic and Chinese. Part IV concludes with a list of future possibilities."
prasad-etal-2010-exploiting,Exploiting Scope for Shallow Discourse Parsing,2010,17,30,3,1,4772,rashmi prasad,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present an approach to automatically identifying the arguments of discourse connectives based on data from the Penn Discourse Treebank. Of the two arguments of connectives, called Arg1 and Arg2, we focus on Arg1, which has proven more challenging to identify. Our approach employs a sentence-based representation of arguments, and distinguishes ''``intra-sentential connectives'''', which take both their arguments in the same sentence, from ''``inter-sentential connectives'''', whose arguments are found in different sentences. The latter are further distinguished by paragraph position into ''``ParaInit'''' connectives, which appear in a paragraph-initial sentence, and ''``ParaNonInit'''' connectives, which appear elsewhere. The paper focusses on predicting Arg1 of Inter-sentential ParaNonInit connectives, presenting a set of scope-based filters that reduce the search space for Arg1 from all the previous sentences in the paragraph to a subset of them. For cases where these filters do not uniquely identify Arg1, coreference-based heuristics are employed. Our analysis shows an absolute 3{\%} performance improvement over the high baseline of 83.3{\%} for identifying Arg1 of Inter-sentential ParaNonInit connectives."
C10-2118,Realization of Discourse Relations by Other Means: Alternative Lexicalizations,2010,21,52,3,1,4772,rashmi prasad,Coling 2010: Posters,0,"Studies of discourse relations have not, in the past, attempted to characterize what serves as evidence for them, beyond lists of frozen expressions, or markers, drawn from a few well-defined syntactic classes. In this paper, we describe how the lexicalized discourse relation annotations of the Penn Discourse Treebank (PDTB) led to the discovery of a wide range of additional expressions, annotated as AltLex (alternative lexicalizations) in the PDTB 2.0. Further analysis of AltLex annotation suggests that the set of markers is open-ended, and drawn from a wider variety of syntactic types than currently assumed. As a first attempt towards automatically identifying discourse relation markers, we propose the use of syntactic paraphrase methods."
P09-1076,Genre distinctions for discourse in the {P}enn {T}ree{B}ank,2009,20,50,1,1,9578,bonnie webber,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Articles in the Penn TreeBank were identified as being reviews, summaries, letters to the editor, news reportage, corrections, wit and short verse, or quarterly profit reports. All but the latter three were then characterised in terms of features manually annotated in the Penn Discourse TreeBank --- discourse connectives and their senses. Summaries turned out to display very different discourse features than the other three genres. Letters also appeared to have some different features. The two main findings involve (1) differences between genres in the senses associated with intra-sentential discourse connectives, inter-sentential discourse connectives and inter-sentential discourse relations that are not lexically marked; and (2) differences within all four genres between the senses of discourse relations not lexically marked and those that are marked. The first finding means that genre should be made a factor in automated sense labelling of non-lexically marked discourse relations. The second means that lexically marked relations provide a poor model for automated sense labelling of relations that are not lexically marked."
W08-1809,Topic Indexing and Retrieval for Factoid {QA},2008,13,2,2,0,41971,kisuh ahn,Coling 2008: Proceedings of the 2nd workshop on Information Retrieval for Question Answering,0,The method of Topic Indexing and Retrieval for QA persented in this paper enables fast and efficent QA for questions with named entity answers. This is achieved by identifying all possible named entity answers in a corpus off-line and gathering all possible evidence for their direct retrieval as answer candidates using standard IR techniques. An evaluation of this method on 377 TREC questions produced a score of 0.342 in Accuracy and 0.413 in Mean Reciprocal Rank (MRR).
prasad-etal-2008-penn,The {P}enn {D}iscourse {T}ree{B}ank 2.0.,2008,23,680,7,1,4772,rashmi prasad,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present the second version of the Penn Discourse Treebank, PDTB-2.0, describing its lexically-grounded annotations of discourse relations and their two abstract object arguments over the 1 million word Wall Street Journal corpus. We describe all aspects of the annotation, including (a) the argument structure of discourse relations, (b) the sense annotation of the relations, and (c) the attribution of discourse relations and each of their arguments. We list the differences between PDTB-1.0 and PDTB-2.0. We present representative statistics for several aspects of the annotation in the corpus."
I08-7009,A Discourse Resource for {T}urkish: Annotating Discourse Connectives in the {METU} Corpus,2008,7,34,2,0,14781,deniz zeyrek,Proceedings of the 6th Workshop on {A}sian Language Resources,0,"This paper describes first steps towards extending the METU Turkish Corpus from a sentence-level language resource to a discourse-level resource by annotating its discourse connectives and their arguments. The project is based on the same principles as the Penn Discourse TreeBank (http://www.seas.upenn.edu/~pdtb) and is supported by TUBITAK, The Scientific and Technological Research Council of Turkey. We first present the goals of the project and the METU Turkish corpus. We then describe how we decided what to take as explicit discourse connectives and the range of syntactic classes they come from. With representative examples of each class, we examine explicit connectives, their linear ordering, and types of syntactic units that can serve as their arguments. We then touch upon connectives with respect to free word order in Turkish and punctuation, as well as the important issue of how much material is needed to specify an argument. We close with a brief discussion of current plans."
W07-1530,Discourse Annotation Working Group Report,2007,0,2,6,0,2824,manfred stede,Proceedings of the Linguistic Annotation Workshop,0,None
W07-1206,Question Answering based on Semantic Roles,2007,11,47,2,0,43582,michael kaisser,{ACL} 2007 Workshop on Deep Linguistic Processing,0,"This paper discusses how lexical resources based on semantic roles (i.e. FrameNet, PropBank, VerbNet) can be used for Question Answering, especially Web Question Answering. Two algorithms have been implemented to this end, with quite different characteristics. We discuss both approaches when applied to each of the resources and a combination of these and give an evaluation. We argue that employing semantic roles can indeed be highly beneficial for a QA system."
W07-1030,Marking time in developmental biology,2007,1,1,2,1,49027,gail sinclair,"Biological, translational, and clinical language processing",0,"In developmental biology, to support reasoning about cause and effect, it is critical to link genetic pathways with processes at the cellular and tissue level that take place beforehand, simultaneously or subsequently. While researchers have worked on resolving with respect to absolute time, events mentioned in medical texts such as clinical narratives (e.g. Zhou et al, 2006), events in developmental biology are primarily resolved relative to other events."
J07-4009,Last Words: Breaking News: Changing Attitudes and Practices,2007,0,3,1,1,9578,bonnie webber,Computational Linguistics,0,"Standard practice in our field has been to announce research results at our annual conference or one of its affiliated meetings such as EMNLP or at the biennial COLING conference. This year, by its submission deadline of 23 January 2007, the ACL Program Committee had received 588 main conference submissions, plus another 52 submissions to the Student Research Workshop, for a total of 640 papers. Similarly, by its subsequent deadline of 26 March 2007, the EMNLP Program Committee had received 398 submissions (excluding ones that were withdrawn or rejected without review). It was estimated that about a third of these (say 130) were the same or minor variations of papers submitted to ACL conference.1 With over 900 separate submissions, one might wonder if all breakthroughs in our field are really made in late fall or winter, just in time for these deadlines. If theyxe2x80x99re not, why is it that these deadlines seem to define when new results are announced? Is there no credit to be gained from really being the first to publish some new method or theory or some clever take on an old one? Or are there no places to publish that will guarantee catching the fieldxe2x80x99s immediate attention (our equivalent of Science, Nature, or YouTube)? In short, why the veritable flood of words crashing up against conference deadlines and the veritable trickle reaching the editorial offices of the significant (and still growing) number of CL/NLP-related journals. A choice is clearly being made by researchers in the field, but is it one that should be encouraged? Could change bring about some better situation? Although our journals and conferences are well-respected (and the latter are also great fun and a major contributor to our sense of community), frustration with both has been heating up over the last year or so, and clear calls for change are in the air. The following is a summary of what I myself believe or have heard others claim to believe, along with some suggestions for possible solutions. I am indebted to discussions with Aravind Joshi, Mark Steedman, Lauri Karttunen, Julia Hockenmeier, Annie Zaenen (co-Editor-in-Chief of Linguistic Issues in Language Technology), John Tait (Executive Editor of Journal of Natural Language Engineering), Kam-Fai Wong and Junxe2x80x99ichi Tsujii (co-Editors-in-Chief of ACM Transactions on Asian Language Information Processing), Shalom Lappin (co-Editor-in-Chief of Research on Language and Computation), and Robert Dale (Editor-in-Chief of this journal, Computational Linguistics), as well as the many comments I have read at the Natural Language Processing blog"
W06-3902,Extracting formal specifications from natural language regulatory documents,2006,-1,-1,4,1,42438,nikhil dinesh,Proceedings of the Fifth International Workshop on Inference in Computational Semantics ({IC}o{S}-5),0,None
W06-0907,Marking Time in Developmental Biology: Annotating Developmental Events and their Links with Molecular Events,2006,-1,-1,2,1,49027,gail sinclair,Proceedings of the Workshop on Annotating and Reasoning about Time and Events,0,None
W06-0305,Annotating Attribution in the {P}enn {D}iscourse {T}ree{B}ank,2006,22,22,5,1,4772,rashmi prasad,Proceedings of the Workshop on Sentiment and Subjectivity in Text,0,"An emerging task in text understanding and generation is to categorize information as fact or opinion and to further attribute it to the appropriate source. Corpus annotation schemes aim to encode such distinctions for NLP applications concerned with such tasks, such as information extraction, question answering, summarization, and generation. We describe an annotation scheme for marking the attribution of abstract objects such as propositions, facts and eventualities associated with discourse relations and their arguments annotated in the Penn Discourse TreeBank. The scheme aims to capture the source and degrees of factuality of the abstract objects. Key aspects of the scheme are annotation of the text spans signalling the attribution, and annotation of features recording the source, type, scopal polarity, and determinacy of attribution."
W05-0305,Attribution and the (Non-)Alignment of Syntactic and Discourse Arguments of Connectives,2005,15,56,6,1,42438,nikhil dinesh,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"The annotations of the Penn Discourse Treebank (PDTB) include (1) discourse connectives and their arguments, and (2) attribution of each argument of each connective and of the relation it denotes. Because the PDTB covers the same text as the Penn TreeBank WSJ corpus, syntactic and discourse annotation can be compared. This has revealed significant differences between syntactic structure and discourse structure, in terms of the arguments of connectives, due in large part to attribution. We describe these differences, an algorithm for detecting them, and finally some experimental results. These results have implications for automating discourse annotation based on syntactic annotation."
W04-2703,Annotating Discourse Connectives and Their Arguments,2004,13,74,4,1,26240,eleni miltsakaki,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,"This paper describes a new, large scale discourse-level annotation project xe2x80x93 the Penn Discourse TreeBank (PDTB). We present an approach to annotating a level of discourse structure that is based on identifying discourse connectives and their arguments. The PDTB is being built directly on top of the Penn TreeBank and Propbank, thus supporting the extraction of useful syntactic and semantic features and providing a richer substrate for the development and evaluation of practical algorithms. We provide a detailed preliminary analysis of inter-annotator agreement xe2x80x93 both the level of agreement and the types of inter-annotator variation."
W04-1212,Classification from Full Text: A Comparison of Canonical Sections of Scientific Papers,2004,4,16,2,1,49027,gail sinclair,Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications ({NLPBA}/{B}io{NLP}),0,"The accelerating growth in biomedical literature has stimulated activity on automated classification of and information extraction from this literature. The work described here attempts to improve on an earlier classification study associating biological articles to GO codes. It demonstrates the need, under particular assumptions, for more access to full text articles and for the use of Part-of-Speech tagging."
W04-0212,Annotation and Data Mining of the {P}enn {D}iscourse {T}ree{B}ank,2004,22,33,4,1,4772,rashmi prasad,Proceedings of the Workshop on Discourse Annotation,0,"The Penn Discourse TreeBank (PDTB) is a new resource built on top of the Penn Wall Street Journal corpus, in which discourse connectives are annotated along with their arguments. Its use of standoff annotation allows integration with a stand-off version of the Penn TreeBank (syntactic structure) and PropBank (verbs and their arguments), which adds value for both linguistic discovery and discourse modeling. Here we describe the PDTB and some experiments in linguistic discovery based on the PDTB alone, as well as on the linked PTB and PDTB corpora."
miltsakaki-etal-2004-penn,The {P}enn {D}iscourse {T}reebank,2004,7,161,4,1,26240,eleni miltsakaki,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes a new discourse-level annotation project xe2x80x93 the Penn Discourse Treebank (PDTB) xe2x80x93 that aims to produce a large-scale corpus in which discourse connectives are annotated, along with their arguments, thus exposing a clearly defined level of discourse structure. The PDTB is being built directly on top of the Penn Treebank and Propbank, thus supporting the extraction of useful syntactic and semantic features and providing a richer substrate for the development and evaluation of practical algorithms. We present a preliminary analysis of inter-annotator agreement xe2x80x93 both the level of agreement and the types of inter-annotator variation."
W03-2608,Anaphoric arguments of discourse connectives: Semantic properties of antecedents versus non-antecedents,2003,6,19,5,1,26240,eleni miltsakaki,Proceedings of the 2003 {EACL} Workshop on The Computational Treatment of Anaphora,0,"We have argued extensively in prior work that discourse connectives can be analyzed as encoding predicate-argument relations whose arguments derived from the interpretation of discourse units. All adverbial connectives we have analyzed to date have expressed binary relations. But they are special in taking one of their two arguments structurally, and the other, anaphorically. As such, interpreting adverbial discourse connectives can be understood as a problem of anaphora resolution. In this paper we study the S-modifying adverbial connective xe2x80x9cinsteadxe2x80x9d and what, in the context, does and does not serve as antecedent for its anaphoric argument. This work extends earlier work investigating syntactic patterns of anaphoric arguments across a range of adverbial discourse connectives and the reliability with which these arguments can be annotated. The current work establishes, for 100 successive corpus instances of xe2x80x9cinsteadxe2x80x9d, lexico-syntactic features of the antecedents of their anaphoric arguments that can be automatically annotated and therefore used to distinguish actual antecedents from potential competitors in the context."
W03-2406,Automatic Multi-Layer Corpus Annotation for Evaluation Question Answering Methods: {CBC}4{K}ids,2003,16,3,3,0,29355,jochen leidner,Proceedings of 4th International Workshop on Linguistically Interpreted Corpora ({LINC}-03) at {EACL} 2003,0,None
W03-0105,Grounding spatial named entities for information extraction and question answering,2003,17,95,3,0,29355,jochen leidner,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Analysis of Geographic References,0,"The task of named entity annotation of unseen text has recently been successfully automated with near-human performance.But the full task involves more than annotation, i.e. identifying the scope of each (continuous) text span and its class (such as place name). It also involves grounding the named entity (i.e. establishing its denotation with respect to the world or a model). The latter aspect has so far been neglected.In this paper, we show how geo-spatial named entities can be grounded using geographic coordinates, and how the results can be visualized using off-the-shelf software. We use this to compare a textual surrogate of a newspaper story, with a visual surrogate based on geographic coordinates."
J03-4002,Anaphora and Discourse Structure,2003,71,190,1,1,9578,bonnie webber,Computational Linguistics,0,"We argue in this article that many common adverbial phrases generally taken to signal a discourse relation between syntactically connected units within discourse structure instead work anaphorically to contribute relational meaning, with only indirect dependence on discourse structure. This allows a simpler discourse structure to provide scaffolding for compositional semantics and reveals multiple ways in which the relational meaning conveyed by adverbial connectives can interact with that associated with discourse structure. We conclude by sketching out a lexicalized grammar for discourse that facilitates discourse interpretation as a product of compositional rules, anaphor resolution, and inference."
W02-0307,Enhanced natural language access to anatomically-indexed data,2002,2,1,2,1,49027,gail sinclair,Proceedings of the {ACL}-02 Workshop on Natural Language Processing in the Biomedical Domain,0,"We describe our use of an existing resource, the Mouse Anatomical Nomenclature, to improve a symbolic interface to anatomically-indexed gene expression data. The goal is to reduce user effort in specifying anatomical structures of interest and increase precision and recall."
W02-0204,A Semantic Account of Adverbials as Discourse Connectives,2002,15,5,2,0,52790,kate forbes,Proceedings of the Third {SIG}dial Workshop on Discourse and Dialogue,0,"We address the question of why certain adverb and preposition phrases are only interpretable with respect to the discourse, and not just their own matrix clause. We show that, in many cases, an adverbial's compositional semantics explains why. We close by reporting on an annotation study aimed at providing specific evidence for how adverbials are interpreted with respect to the discourse."
P99-1006,Discourse Relations: A Structural and Presuppositional Account Using Lexicalised {TAG},1999,19,58,1,1,9578,bonnie webber,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"We show that discourse structure need not bear the full burden of conveying discourse relations by showing that many of them can be explained nonstructurally in terms of the grounding of anaphoric presuppositions (Van der Sandt, 1992). This simplifies discourse structure, while still allowing the realisation of a full range of discourse relations. This is achieved using the same semantic machinery used in deriving clause-level semantics."
W98-1419,Textual Economy Through Close Coupling of Syntax and Semantics,1998,22,0,2,0,7129,matthew stone,Natural Language Generation,0,"We focus on the production of efficient descriptions of objects, actions and events. We define a type of efficiency, textual economy, that exploits the hearer's recognition of inferential links to material elsewhere within a sentence. Textual economy leads to efficient descriptions because the material that supports such inferences has been included to satisfy independent communicative goals, and is therefore overloaded in Pollack's sense. We argue that achieving textual economy imposes strong requirements on the representation and reasoning used in generating sentences. The representation must support the generator's simultaneous consideration of syntax and semantics. Reasoning must enable the generator to assess quickly and reliably at any stage how the hearer will interpret the current sentence, with its (incomplete) syntax and semantics. We show that these representational and reasoning requirements are met in the SPUD system for sentence planning and realization."
W98-0315,Anchoring a {L}exicalized {T}ree-{A}djoining {G}rammar for Discourse,1998,10,58,1,1,9578,bonnie webber,Discourse Relations and Discourse Markers,0,"We here explore a ``fully'' lexicalized Tree-Adjoining Grammar for discourse that takes the basic elements of a (monologic) discourse to be not simply clauses, but larger structures that are anchored on variously realized discourse cues. This link with intra-sentential grammar suggests an account for different patterns of discourse cues, while the different structures and operations suggest three separate sources for elements of discourse meaning: (1) a compositional semantics tied to the basic trees and operations; (2) a presuppositional semantics carried by cue phrases that freely adjoin to trees; and (3) general inference, that draws additional, defeasible conclusions that flesh out what is conveyed compositionally."
W98-0113,Describing discourse semantics,1998,8,30,2,0,850,claire gardent,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,"Descriptions. In recent years, both formal and computational linguistics have been exploiting descriptions of structures where previously the structures themselves were used. The practice started with (Marcus et al., 1983), who demonstrated the value of (syntactic) tree descriptions for near-deterministic incremental parsing. Vijay-Shankar (Vijay-Shankar and Joshi, 1988; Vijay-Shankar, 1992) used descriptions to maintain the monotonicity of syntactic derivations in the framework of Feature-Based Tree Adjoining Grammar. In semantics, both (Muskens, 1997) and (Egg et al., 1997) have shown the value of descriptions as an underspecified representation of scope ambiguities. The current paper further extends the use of descriptions, from individual sentences to discourse, showing their benefit for incremental, near-deterministic discourse processing. In particular, we show that using descriptions to describe the semantic representation of discourse permits: (1) a monotone treatment of local ambiguity; (2) a deterministic treatment of global ambiguity; and (3) a distinction to be made between xe2x80x9csimplexe2x80x9d local ambiguity and xe2x80x9cgarden-pathxe2x80x9d local ambiguity."
P97-1012,Expectations in Incremental Discourse Processing,1997,12,48,2,0,14259,dan cristea,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"The way in which discourse features express connections back to the previous discourse has been described in the literature in terms of adjoining at the right frontier of discourse structure. But this does not allow for discourse features that express expectations about what is to come in the subsequent discourse. After characterizing these expectations and their distribution in text, we show how an approach that makes use of substitution as well as adjoining on a suitably defined right frontier, can be used to both process expectations and constrain discouse processing in general."
A94-1021,Upholding the Maxim of Relevance during Patient-Centered Activities,1994,-1,-1,2,0,25032,abigail gertner,Fourth Conference on Applied Natural Language Processing,0,None
H93-1113,Natural Language Research,1993,-1,-1,4,0,33217,aravind joshi,"{H}uman {L}anguage {T}echnology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993",0,None
P92-1013,Accommodating Context Change,1992,18,9,1,1,9578,bonnie webber,30th Annual Meeting of the Association for Computational Linguistics,1,"Two independent mechanisms of context change have been discussed separately in the literature - context change by entity introduction and context change by event simulation. Here we discuss their integration. The effectiveness of the integration depends in part on a representation of events that captures people's uncertainty about their outcome - in particular, people's incomplete expectations about the changes effected by events. We propose such a representation and a process of accommodation that makes use of it, and discuss our initial implementation of these ideas."
H92-1123,Natural Language Research,1992,-1,-1,4,0,33217,aravind joshi,"Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, {F}ebruary 23-26, 1992",0,None
H91-1103,Natural Language Research,1991,0,0,4,0,33217,aravind joshi,"Speech and Natural Language: Proceedings of a Workshop Held at Pacific Grove, California, {F}ebruary 19-22, 1991",0,None
W90-0125,Narrated Animation: A Case for Generation,1990,5,1,3,0,25231,norman badler,Proceedings of the Fifth International Workshop on Natural Language Generation,0,"Abstract : Our project rests on the belief that computer animation in the form of narrated animated simulations can provide an engaging, effective and flexible medium for instructing agents of varying capabilities to perform tasks that make varying demands in workplaces of varying layout. To this end, we have been designing and implementing an integrated system which combines: animated agents which can demonstrate the behavior to be emulated and automatic generation of appropriate Natural Language narration which can explain what is being done and why."
H90-1099,Natural Language Research,1990,0,0,4,0,33217,aravind joshi,"Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, {P}ennsylvania, June 24-27,1990",0,"The main objective is basic research and system development leading to (1) characterization of information carried by (a) syntax, semantics, and discourse structure, (b) their relation to information carried by intonation, and (c) development of methods for using this information for generation and understanding; (2) development of architectures for integration of utterance planning with lexical, syntactic and intonational choice; (3) development of incremental strategies for using syntactic, semantic, and pragmatic knowledge in understanding and generating language."
C90-2068,Free Adjuncts in Natural Language Instructions,1990,7,21,1,1,9578,bonnie webber,{COLING} 1990 Volume 2: Papers presented to the 13th International Conference on Computational Linguistics,0,"In this paper, we give a brief account of our project Animation from Instructions, the view of instructions it reflects, and the semantics of one construction - the free adjunct - that is common in Natural Language instructions."
H89-2010,Natural Language {I},1989,0,0,1,1,9578,bonnie webber,"Speech and Natural Language: Proceedings of a Workshop Held at Cape Cod, Massachusetts, October 15-18, 1989",0,"Except for the final presentation by Hovy, this session focussed on the use of superficial features of Natural Language in text processing (messages, in the case of the first two presentations, unrestricted text in the case of the second two). This is a very brief summary of a moderator's view of the action."
H89-1035,Natural Language Research,1989,-1,-1,4,0,33217,aravind joshi,"Speech and Natural Language: Proceedings of a Workshop Held at Philadelphia, {P}ennsylvania, {F}ebruary 21-23, 1989",0,None
H89-1037,Elements of a Computational Model of Cooperative Response Generation,1989,16,2,2,0,57794,brant cheikes,"Speech and Natural Language: Proceedings of a Workshop Held at Philadelphia, {P}ennsylvania, {F}ebruary 21-23, 1989",0,"If natural language question-answering (NLQA) systems are to be truly effective and useful, they must respond to queries cooperatively, recognizing and accommodating in their replies a questioner's goals, plans, and needs. This paper concerns the design of cooperative response generation (CRG) systems, NLQA systems that are able to produce integrated cooperative responses. We propose two characteristics of a computational model of cooperative response generation. First, we argue that CRG systems should be able to explicitly reason about and choose among the different response options available to them in a given situation. Second, we suggest that some choices of response content motivate others---that through a process called reflection, respondents detect the need to explain, justify, clarify or otherwise augment information they have already decided to convey."
P88-1014,Discourse Deixis: Reference to Discourse Segments,1988,16,69,1,1,9578,bonnie webber,26th Annual Meeting of the Association for Computational Linguistics,1,"Computational approaches to discourse understanding have a two-part goal: (1) to identify those aspects of discourse understanding that require process-based accounts, and (2) to characterize the processes and data structures they involve. To date, in the area of reference, process-based accounts have been developed for subsequent reference via anaphoric pronouns and reference via definite descriptors. In this paper, I propose and argue for a process-based account of subsequent reference via deictic expressions. A significant feature of this account is that it attributes distinct mental reality to units of text often called discourse segments, a reality that is distinct from that of the entities described therein."
J88-2001,Foreword to Special Issue on Tense and Aspect,1988,-1,-1,1,1,9578,bonnie webber,Computational Linguistics,0,None
J88-2006,Tense as Discourse Anaphor,1988,24,187,1,1,9578,bonnie webber,Computational Linguistics,0,"In this paper, I consider a range of English expressions and show that their context-dependency can be characterized in terms of two properties:1. They specify entities in an evolving model of the discourse that the listener is constructing;2. The particular entity specified depends on another entity in that part of the evolving discourse model that the listener is currently attending to.Such expressions have been called anaphors. I show how tensed clauses share these characteristics, usually just attributed to anaphoric noun phrases. This not only allows us to capture in a simple way the oft-stated but difficult-to-prove intuition that tense is anaphoric, but also contributes to our knowledge of what is needed for understanding narrative text."
T87-1033,Position Paper: Event Reference,1987,4,2,1,1,9578,bonnie webber,Theoretical Issues in Natural Language Processing 3,0,"1. I n t r o d u c t i o n Developing a computational account of event reference requires solution to a number of difficult problems, not least of which is characterizing the phenomenon itself. From a listener's point of view, eveni reference encompasses both the task of building up a structured model of the events and situations underlying a given text and the task of interpreting subsequent references to these events and situations afterwards. A computational approach to these tasks requires at least (1) a characterization of the information that an individual clause may convey about an event or situation; (2) a characterization of explicit clues a text gives as to how the pieces described in individual clauses fit together (assuming, as I do, that this does not rely solely on world knowledge; (3) an account of what the listener does in processing an explicit event reference; (4) a characterization of what events and situations are available for explicit reference; and (5) a procedure for choosing among possible ways of resolving an explicit event reference."
P87-1021,The Interpretation of Tense in Discourse,1987,15,42,1,1,9578,bonnie webber,25th Annual Meeting of the Association for Computational Linguistics,1,This paper gives an account of the role tense plays in the listener's reconstruction of the events and situations a speaker has chosen to describe. Several new ideas are presented: (a) that tense is better viewed by analogy with definite NPs than with pronouns; (b) that a narrative has a temporal focus that grounds the context-dependency of tense; and (c) that focus management heuristics can be used to track the movement of temporal focus.
H86-1005,Research in Natural Language Processing,1986,0,0,5,0,33217,aravind joshi,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"The main objective is to develop robust methods for the understanding and generation of both written and spoken human language, including but not limited to English. Penn is pursuing development of: (1) New mathematical and computational frameworks which are highly constrained, yet adequate to allow a simple, concise description of complex linguistic phenomena. These new frameworks are tested by the explicit encoding within each framework of a wide range of phenomena across a diverse set of human languages. (2) Both statistical and symbolic learning methods which automatically extract and effectively utilize the implicit linguistic knowledge in the Penn Treebank and the corpora of the Linguistic Data Consortium. These techniques have been tested against the performance of the best current methods."
H86-1017,Living Up to Expectations: Computing Expert Responses,1986,8,3,2,0,33217,aravind joshi,"Strategic Computing - Natural Language Workshop: Proceedings of a Workshop Held at Marina del Rey, California, May 1-2, 1986",0,"In cooperative man-machine interaction, it is necessary but not sufficient for a system to respond truthfully and informatively to a user's question. In particular, if the system has reason to believe that its planned response might mislead the user, then it must block that conclusion by modifying its response. This paper focusses on identifying and avoiding potentially misleading responses by acknowledging types of informing behavior usually expected of an expert. We attempt to give a formal account of several types of assertions that should be included in response to questions concerning the achievement of some goal (in addition to the simple answer), lest the questioner otherwise be misled."
P84-1029,Preventing False Inferences,1984,11,33,2,0,33217,aravind joshi,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,None
C82-1066,Taking the Initiative in Natural Language Data Base Interactions: Justifying Why,1982,10,21,1,1,9578,bonnie webber,{C}oling 1982: Proceedings of the {N}inth {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
P81-1021,Some Issues in Parsing and Natural Language Understanding,1981,5,2,2,0,55866,robert bobrow,19th Annual Meeting of the Association for Computational Linguistics,1,Language is a system for encoding and transmitting ideas. A theory that seeks to explain linguistic phenomena in terms of this fact is a functional theory. One that does not misses the point. [10]
P80-1032,Interactive Discourse: Looking to the Future: Panel Chair{'}s Introduction,1980,0,0,1,1,9578,bonnie webber,18th Annual Meeting of the Association for Computational Linguistics,1,None
T78-1006,Description Formation and Discourse Model Synthesis,1978,12,7,1,1,9578,bonnie webber,Theoretical Issues in Natural Language Processing-2,0,"Many researchers in linguistics, psychology, philosophy and artificial intelligence have recently begun to abandon a purely linguistic approach to definite anaphora in favor of a notion of reference into some kind of model of the discourse, cf. Karttunen [1976], Levin & Goldman [1978], Lyons [1978]. Stenning [1975]. My own research on definite anaphora (cf. Webber [1978a&b]) follows this approach, in particular making the following five assumptions:"
J78-3012,Description Formation and Discourse Model Synthesis,1978,12,7,1,1,9578,bonnie webber,American Journal of Computational Linguistics,0,"Many researchers in linguistics, psychology, philosophy and artificial intelligence have recently begun to abandon a purely linguistic approach to definite anaphora in favor of a notion of reference into some kind of model of the discourse, cf. Karttunen [1976], Levin & Goldman [1978], Lyons [1978]. Stenning [1975]. My own research on definite anaphora (cf. Webber [1978a&b]) follows this approach, in particular making the following five assumptions:"
