1997.mtsummit-workshop.9,P97-1016,1,0.776366,"Missing"
1997.mtsummit-workshop.9,J92-1004,1,0.784895,"IL for human language communication systems including multi-lingual machine translation and spoken language dialogue systems. To advocate this view, we describe our method of constructing IL representations in developing our multilingual machine translation system, CCLINC (cf. Tummala et al. 1995, Weinstein et al. 1996, Lee et al. 1997), and give a demonstration of two-way English/Korean translation by CCLINC. At MIT Lincoln Laboratory, we have been developing a multi-lingual machine translation system, called CCLINC. The core of CCLINC consists of the language understanding system (TINA, cf. Seneff 1992) and the language generation system (GENESIS, cf. Glass et al. 1994). The system has been applied to English-to-French, English-to-Korean and Korean-to-English translations. In designing an IL representation, we have been following two developmental strategies: First, simplification of nomenclature. Second, preservation of the predicate/argument structure of the input sentence. These strategies are largely drawn from the experience of applying the language understanding/generation system to spoken language dialogue systems (cf. Zue et al 1996). Simplification of nomenclature provides a very ge"
1997.mtsummit-workshop.9,C96-2119,1,0.876,"Missing"
2005.sigdial-1.15,P04-1009,0,0.0596957,"t only is it costly to collect user data in general, but it is also difficult to influence the user’s behavior so as to enhance the occurrence of appropriate scenarios. It then becomes problematic to define an effective evaluation criterion for conditions that are inherently rare, and, in any case, it requires a period of weeks or months to collect sufficient data for both development and evaluation. An attractive solution is to employ user simulation, both to help develop the system and to provide highly controlled evaluation experiments (Scheffler and Young, 2000, 2001; Eckert et al., 2001; Chung, 2004). Increasingly, researchers in spoken dialogue systems have been exploiting user simulation to aid in system development. For instance, in developing a restaurant domain (Chung, 2004), thousands of dialogues were generated automatically both to evaluate system performance and to produce training data for the recognizer language model. The simulated user consults the system’s response frame to determine an appropriate query for each subsequent turn. In a recent experiment in the flight domain, we were able to locate points of communication breakdown in prior user dialogues, and continue those c"
2005.sigdial-1.15,C02-1147,0,0.0237021,"esults from various simulated user configurations are presented, along with a discussion of how the simulated user facilitates the debugging of dialogue strategies and the discovery of situations unanticipated by the system developer. Keywords: spoken dialogue systems, user simulation, error recovery 1 Introduction Spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources (Gorin et al., 1997; Pieraccini et al., 1997; Dahlb¨ack et al., 1999; Gustafson et al., 1999; Zue et al., 2000; Eckert et al., 2001; Walker et al., 2001; Denecke, 2002; Polifroni and Chung, 2002; Seneff, 2002; Glass and Seneff, 2003; Quast et al., 2003). While the ∗ This research was supported by an industrial consortium supporting the MIT Oxygen Alliance. effectiveness of such systems has improved significantly over the past several years, a critical barrier to widespread deployment remains in the form of communication breakdown at strategic points in the dialogue, often when the user is trying to convey a critical piece of information that the system repeatedly misunderstands. This situation is particularly likely to occur whenever the user is attempting"
2005.sigdial-1.15,W04-3006,1,0.727528,"eloping a restaurant domain (Chung, 2004), thousands of dialogues were generated automatically both to evaluate system performance and to produce training data for the recognizer language model. The simulated user consults the system’s response frame to determine an appropriate query for each subsequent turn. In a recent experiment in the flight domain, we were able to locate points of communication breakdown in prior user dialogues, and continue those conversations with a different error recovery approach, using a synthesizer to generate waveforms for a solicited speak-and-spell subdialogue (Filisko and Seneff, 2004). We report here on a novel approach to user simulation, which exploits an extensive database of preexisting user queries, but recombines the utterances using essentially an example-based template approach. The system deals with gaps in the corpus by splicing in synthetic waveforms for missing words, such as newly introduced rare cities. This allows us to retain the richness of variety in the ways users can pose questions, while introducing in a controlled way rare cities that would require an error recovery subdialogue to be resolved. We can then develop our error recovery strategies in the c"
2005.sigdial-1.15,W03-0707,1,0.816032,"esented, along with a discussion of how the simulated user facilitates the debugging of dialogue strategies and the discovery of situations unanticipated by the system developer. Keywords: spoken dialogue systems, user simulation, error recovery 1 Introduction Spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources (Gorin et al., 1997; Pieraccini et al., 1997; Dahlb¨ack et al., 1999; Gustafson et al., 1999; Zue et al., 2000; Eckert et al., 2001; Walker et al., 2001; Denecke, 2002; Polifroni and Chung, 2002; Seneff, 2002; Glass and Seneff, 2003; Quast et al., 2003). While the ∗ This research was supported by an industrial consortium supporting the MIT Oxygen Alliance. effectiveness of such systems has improved significantly over the past several years, a critical barrier to widespread deployment remains in the form of communication breakdown at strategic points in the dialogue, often when the user is trying to convey a critical piece of information that the system repeatedly misunderstands. This situation is particularly likely to occur whenever the user is attempting to supply a named entity from a large or open vocabulary set. For"
2005.sigdial-1.7,N04-4006,0,0.0610034,"Missing"
2005.sigdial-1.7,W04-3218,0,0.047676,"Missing"
2005.sigdial-1.7,N03-2003,0,0.0367472,"Missing"
2005.sigdial-1.7,P04-1009,1,0.934402,"evaluating dialogue strategies (Lopez-Cozar et al., 2003; Lin and Lee, 2001; Araki and Doshita, 1996; Hone and Baber, 1995). The method described here uses simulations as one method for pre-selecting training utterances to shape the training corpus statistics. 3 Approach Figure 1 illustrates the multiple steps proposed in this paper. We begin with generating an initial seed corpus in our target domain; examples are given in a Boston restaurant information system. This domain data (13,000 sentences) was obtained by running the dialogue system in simulated user mode, as previously described in (Chung, 2004). The simulations utilized a stochastic user model that, from the system reply frame, determined a user response, represented as a key-value (KV) string. From the KV representation, the system generated user utterances System Response Dialogue System User Query User Simulator User Model User: System: Key−Value String Formal Generation Generation Rules User: System: Figure 2: A schematic showing the process of generating synthetic data by the formal generation method from a key-value representation using user simulation. by way of formal generation rules (Baptist, 2000). The technique of induci"
2005.sigdial-1.7,W04-2314,0,0.0585054,"Missing"
2005.sigdial-1.7,J92-1004,1,0.483495,"Missing"
2006.amta-papers.24,N03-1017,0,0.00499491,"tences (speech transcriptions), which we do not want the SMT system to capture in its translation models. English Rules English Grammar English Sentence Language Generation Language Interlingua Understanding Bilingual Corpus Language Generation Chinese Rules Figure 1: Schematic of technique to automatically generate a synthetic bilingual corpus, for training a statistical translation system. Once this bilingual corpus is prepared, it can be used to train a statistical machine translation (SMT) system. For this we made use of a state-of-theart phrase-based MT system developed by Philipp Koehn (Koehn et al., 2003; Koehn, 2004). 3.2 Formal Translation In parallel, we have developed a linguistic method to translate the generated Chinese corpus back into English. We can use the English grammar rules as a reference to generate comparable Chinese grammar rules, such that there is considerable uniformity in the resulting meaning representations. Ideally, the two languages would produce an identical “interlingua” for sentences with equivalent meaning, and the generation rules would be agnostic to the input language. Our interlingual representation, in contrast to many other interlingual approaches, captures"
2006.amta-papers.24,koen-2004-pharaoh,0,0.019129,"n detailing our experimental results, we conclude with a discussion of related research and a look to the future. 3 Approach 3.1 Phrase-based SMT Given a corpus of English sentences within the flight domain and a reasonably high quality Englishto-Chinese translation system (Wang and Seneff, 2006b), we can easily generate a parallel EnglishChinese corpus, which can be used to train a statistical machine translation (SMT) system. This allows us to quickly develop a reverse Chinese-to-English translation capability, using publicly available SMT tools for training and decoding (Och and Ney, 2003; Koehn, 2004). As illustrated in Figure 1, we can automatically generate a corpus of English-Chinese pairs from the same interlingual representation by parsing our English corpus and then paraphrasing each utterance into both English and Chinese. It is our belief that the English paraphrase is preferred over the original English sentence because it is likely to be more consistent with the Chinese paraphrase. Furthermore, the English paraphrases usually remove disfluencies present in the original sentences (speech transcriptions), which we do not want the SMT system to capture in its translation models. Eng"
2006.amta-papers.24,P98-1116,0,0.00905462,"rkhi, 2000; Rayner and Carter, 1997), probably due to the existence of large English speech corpora obtained from spoken dialogue systems (such as ATIS and the Darpa funded Commmunicator Program). (Rayner and Carter, 1997) advocate combining rule-based and statistical methods to achieve robust and efficient performance within a linguistically motivated framework. Their system translates from English into Swedish and French, and uses statistical methods for word-sense disambiguation. They argue for utilizing expertise to develop generic grammar rules covering the core linguistic constructions (Langkilde and Knight, 1998) were pioneers in introducing the idea of using a linguistic generation system to overgenerate a set of candidate hypotheses for later selection by a statistical evaluation. Their Nitrogen language generation system processes from an underspecified semantic input, which they call an “AMR” (abstract meaning represention). It outputs a word graph representing a very large list of alternative realizations of the syntactic sugar missing from the AMR. An n-gram language model then selects the most plausible realization. As in our work, they generate both singular and plural forms of underspecified"
2006.amta-papers.24,J03-1002,0,0.00282882,"pus. After a section detailing our experimental results, we conclude with a discussion of related research and a look to the future. 3 Approach 3.1 Phrase-based SMT Given a corpus of English sentences within the flight domain and a reasonably high quality Englishto-Chinese translation system (Wang and Seneff, 2006b), we can easily generate a parallel EnglishChinese corpus, which can be used to train a statistical machine translation (SMT) system. This allows us to quickly develop a reverse Chinese-to-English translation capability, using publicly available SMT tools for training and decoding (Och and Ney, 2003; Koehn, 2004). As illustrated in Figure 1, we can automatically generate a corpus of English-Chinese pairs from the same interlingual representation by parsing our English corpus and then paraphrasing each utterance into both English and Chinese. It is our belief that the English paraphrase is preferred over the original English sentence because it is likely to be more consistent with the Chinese paraphrase. Furthermore, the English paraphrases usually remove disfluencies present in the original sentences (speech transcriptions), which we do not want the SMT system to capture in its translati"
2006.amta-papers.24,A00-2026,0,0.0768196,"a set of “keyword rules” map semantic and syntactic roles to grammatical constructs. However, because their representation is missing explicit syntactic information, the hypothesized syntactic organization is encapsulated in the (alternative) rules rather than directly in the AMR. Their notion of an “AMR recasting rule” is similar to our corrective rule rewrite mechanism, and allows an original AMR to be cast into related AMR’s. 7 Related Research A number of projects have involved language translation in the flight domain, particularly involving spoken language translation (Gao et al., 2002; Ratnaparkhi, 2000; Rayner and Carter, 1997), probably due to the existence of large English speech corpora obtained from spoken dialogue systems (such as ATIS and the Darpa funded Commmunicator Program). (Rayner and Carter, 1997) advocate combining rule-based and statistical methods to achieve robust and efficient performance within a linguistically motivated framework. Their system translates from English into Swedish and French, and uses statistical methods for word-sense disambiguation. They argue for utilizing expertise to develop generic grammar rules covering the core linguistic constructions (Langkilde"
2006.amta-papers.24,W00-0303,1,0.78795,"ction with the system. In this languagelearning mode, the student would be able to obtain translation assistance at any time over the course of a dialogue, by simply speaking a sentence in their native language with equivalent meaning. The system is then tasked with the challenging requirement to provide a fluent translation of their utterance. Two application domains where we have invested considerable previous effort, both towards multilingual dialogue interaction and towards translation assistance between English and Chinese, are the weather domain (Zue et al., 2000) and the flight domain (Seneff and Polifroni, 2000). We have previously reported on various strategies for achieving high quality and enhancing coverage and robustness for bidirectional speech translation in the weather domain (Wang and Seneff, 2006a; Lee and Seneff, 2005) and for translation from English to Chinese in the flight domain (Wang and Seneff, 2006b). This paper is focused on the specific (new) task of translating from Chinese to English in the flight domain. We have found in general, as might be expected, that the flight domain is considerably more difficult than the weather domain, due to the much larger number of attributes that"
2006.amta-papers.24,J92-1004,1,0.422595,"ed Chinese corpus back into English. We can use the English grammar rules as a reference to generate comparable Chinese grammar rules, such that there is considerable uniformity in the resulting meaning representations. Ideally, the two languages would produce an identical “interlingua” for sentences with equivalent meaning, and the generation rules would be agnostic to the input language. Our interlingual representation, in contrast to many other interlingual approaches, captures both syntactic and semantic information within a hierarchical structure. Through the device of a trace mechanism (Seneff, 1992) we are able to achieve a strong degree of parallelism in the meaning representations derived from both languages. For example, wh-marked NP’s in English are restored to their deep-structure location in the clause, as are temporals and locatives in Chinese. Figure 2 shows examples of the interlingual meaning representation automatically derived from a parse analysis for an English sentence and a Chinese sentence of equivalent meaning. As seen in the figure, syntactic structure is encoded in the hierarchy, with structural “frames” representing three principal linguistic categories: “{c }” = cla"
2006.amta-papers.24,C98-1112,0,\N,Missing
2007.sigdial-1.21,P02-1048,0,0.0734518,"tude. (4) Phone Number The POI’s phone number. (5) URL Link to a webpage with more information about the object. (6) Description A brief description of the POI. Our currently deployed version of City Browser uses these generic database capabilities to provide access to a database of museums. The architecture also accommodates the subway station databases for providing public transportation information, the geographical database of cities, streets, and neighborhoods, as well as the existing restaurant database. 2.1 Comparison to Similar Systems The most similar system we are aware of is MATCH (Johnston et al., 2002), which provided extensive multimodal capabilities for accessing urban information. There is significant overlap between City Browser and MATCH. For instance, both provide multimodal access to restaurant and public transit information. A major feature of the MATCH system which is lacking in City Browser is handwriting recognition; we have not concentrated on this modality, as we do not currently assume our users will have access to a pen-based interface. Another similar interface is AdApt (Gustafson et al., 2000), which provides apartment rental information in downtown Stockholm. To the best o"
2008.amta-papers.21,2007.mtsummit-papers.29,0,0.0387042,"wo types of MT systems, a number of researchers have been trying to incorporate syntax information into statistical systems. [Yamada and Knight, 2001] performed tree-tostring translation to directly transform the sourcelanguage parse tree into the target-language string. [Zhang et al., 2007] modeled statistical phrase reordering based on the source-language parse tree. [Wang et al., 2007] reordered the tree nodes using hand-coded linguistic rules. [Zhang, Zen and Rey, 2007] applied shallow parsing on the source side, and automatically extracted chunk reordering rules based on word alignment. [Habash, 2007] adopted a similar idea, but used source-language dependencies to extract the reordering rules. Another system that adopts an approach that is similar to ours is the system by [Simard et al, 2007]. They first translated the sentences using rule-based MT, then used 3 Two-Stage Translation English STAGE I English Grammar Language Understanding Zhonglish Generation Rules Language Generation Zhonglish w/ tags STAGE II PreTranslated Prases Statistical MT Chinese w/ tags Restore Tags into Words Chinese Figure 1. Framework of the system Figure 1 shows the framework of our system. We separate the tra"
2008.amta-papers.21,P07-2045,0,0.0063622,"of producing high quality translations when the input is within a limited domain [Wang and Seneff, 2006]. Their system uses a parser to process the input sentence into a meaning representation, and then a rule-based language generator to generate the target sentence string. The same paradigm applies to the translation game system in the hobby and schedule domain [Chao et al., 2007]. These systems produce highly accurate translations, but they only work on very limited domains. A typical example of a purely statistical MT system is the phrase-based statistical machine translation system MOSES [Koehn et al., 2007]. It learns a phrase table as well as a translation model from the training corpus. This system has been used in many tasks, but usually it requires millions of training utterances from a parallel corpus to train a good model. Besides the above two types of MT systems, a number of researchers have been trying to incorporate syntax information into statistical systems. [Yamada and Knight, 2001] performed tree-tostring translation to directly transform the sourcelanguage parse tree into the target-language string. [Zhang et al., 2007] modeled statistical phrase reordering based on the source-la"
2008.amta-papers.21,W06-1606,0,0.0789203,"Missing"
2008.amta-papers.21,J92-1004,1,0.141648,"irst&quot; } :pred {p buy :topic {q trace_object :quantifier &quot;def&quot; :noun &quot;book&quot; } :mode &quot;past&quot; :pred {p temporal :topic {q rel_date :name &quot;yesterday&quot; }}}}} :pred {p trace_pred :trace &quot;where&quot; } } } Stage I: English-Zhonglish Translation Language Understanding Figure 2. Linguistic frame for input sentence “Where did you put the book I bought yesterday.” In the language understanding step, the input sentence is parsed and converted into a “linguistic frame,” a hierarchical meaning representation that encodes both syntactic structure and semantic knowledge but discards temporal order. We use the TINA [Seneff, 1992] system, which utilizes a context-free grammar to define allowable patterns, augmented with a probability model to help select among ambiguous parses, and a feature passing mechanism to deal with movement and agreement constraints. After parsing, a separate step converts the parse tree into a linguistic frame. This is accomplished by visiting all nodes in the parse tree in a top-down left-to-right path, and building up the linguistic frame incrementally by consulting a simple mapping table. An example of the output linguistic frame, for the sentence, &quot;Where did you put the book I bought yeste"
2008.amta-papers.21,W00-0303,1,0.745568,"d system can produce better results. In terms of domain and language, many of the previous work has been applied to written corpora. Only a few have focused on the spoken domain [Shen et al, 2007; Carpuat and Wu, 2007]. Although many researchers have been working on translation from Chinese into English, far less research has been devoted to the reverse direction. 2 Previous Research There are a few systems that use purely linguistic machine translation. Examples include the dialogue interaction and translation assistance systems in the weather domain [Zue et al., 2000] and the flight domain [Seneff and Polifroni, 2000]. Wang and Seneff have shown that a formal parsegenerate method is capable of producing high quality translations when the input is within a limited domain [Wang and Seneff, 2006]. Their system uses a parser to process the input sentence into a meaning representation, and then a rule-based language generator to generate the target sentence string. The same paradigm applies to the translation game system in the hobby and schedule domain [Chao et al., 2007]. These systems produce highly accurate translations, but they only work on very limited domains. A typical example of a purely statistical"
2008.amta-papers.21,W07-0728,0,0.0642538,"directly transform the sourcelanguage parse tree into the target-language string. [Zhang et al., 2007] modeled statistical phrase reordering based on the source-language parse tree. [Wang et al., 2007] reordered the tree nodes using hand-coded linguistic rules. [Zhang, Zen and Rey, 2007] applied shallow parsing on the source side, and automatically extracted chunk reordering rules based on word alignment. [Habash, 2007] adopted a similar idea, but used source-language dependencies to extract the reordering rules. Another system that adopts an approach that is similar to ours is the system by [Simard et al, 2007]. They first translated the sentences using rule-based MT, then used 3 Two-Stage Translation English STAGE I English Grammar Language Understanding Zhonglish Generation Rules Language Generation Zhonglish w/ tags STAGE II PreTranslated Prases Statistical MT Chinese w/ tags Restore Tags into Words Chinese Figure 1. Framework of the system Figure 1 shows the framework of our system. We separate the translation process into two stages. In the first stage, the linguistic method is used to perform structural reconstruction. The source sentence, which in our experiment is in English, is parsed into"
2008.amta-papers.21,D07-1077,0,0.108746,"Missing"
2008.amta-papers.21,P01-1067,0,0.172325,"systems produce highly accurate translations, but they only work on very limited domains. A typical example of a purely statistical MT system is the phrase-based statistical machine translation system MOSES [Koehn et al., 2007]. It learns a phrase table as well as a translation model from the training corpus. This system has been used in many tasks, but usually it requires millions of training utterances from a parallel corpus to train a good model. Besides the above two types of MT systems, a number of researchers have been trying to incorporate syntax information into statistical systems. [Yamada and Knight, 2001] performed tree-tostring translation to directly transform the sourcelanguage parse tree into the target-language string. [Zhang et al., 2007] modeled statistical phrase reordering based on the source-language parse tree. [Wang et al., 2007] reordered the tree nodes using hand-coded linguistic rules. [Zhang, Zen and Rey, 2007] applied shallow parsing on the source side, and automatically extracted chunk reordering rules based on word alignment. [Habash, 2007] adopted a similar idea, but used source-language dependencies to extract the reordering rules. Another system that adopts an approach t"
2008.amta-papers.21,D07-1056,0,0.0144335,"he phrase-based statistical machine translation system MOSES [Koehn et al., 2007]. It learns a phrase table as well as a translation model from the training corpus. This system has been used in many tasks, but usually it requires millions of training utterances from a parallel corpus to train a good model. Besides the above two types of MT systems, a number of researchers have been trying to incorporate syntax information into statistical systems. [Yamada and Knight, 2001] performed tree-tostring translation to directly transform the sourcelanguage parse tree into the target-language string. [Zhang et al., 2007] modeled statistical phrase reordering based on the source-language parse tree. [Wang et al., 2007] reordered the tree nodes using hand-coded linguistic rules. [Zhang, Zen and Rey, 2007] applied shallow parsing on the source side, and automatically extracted chunk reordering rules based on word alignment. [Habash, 2007] adopted a similar idea, but used source-language dependencies to extract the reordering rules. Another system that adopts an approach that is similar to ours is the system by [Simard et al, 2007]. They first translated the sentences using rule-based MT, then used 3 Two-Stage T"
2008.amta-papers.21,D07-1007,0,0.0236398,"tence limits its algorithm to only penalize 222 [8th AMTA conference, Hawaii, 21-25 October 2008] tical MT systems. The sentences contain a large percentage of wh-questions, and the corpus is much smaller than typical news corpora, which will cause the statistical MT system to face severe sparse data problems. statistical MT as an automatic post-editing layer. All this research has shown that a hybrid system can produce better results. In terms of domain and language, many of the previous work has been applied to written corpora. Only a few have focused on the spoken domain [Shen et al, 2007; Carpuat and Wu, 2007]. Although many researchers have been working on translation from Chinese into English, far less research has been devoted to the reverse direction. 2 Previous Research There are a few systems that use purely linguistic machine translation. Examples include the dialogue interaction and translation assistance systems in the weather domain [Zue et al., 2000] and the flight domain [Seneff and Polifroni, 2000]. Wang and Seneff have shown that a formal parsegenerate method is capable of producing high quality translations when the input is within a limited domain [Wang and Seneff, 2006]. Their sys"
2008.amta-papers.21,W07-0401,0,0.0596752,"Missing"
2008.amta-papers.21,2007.iwslt-1.8,0,\N,Missing
2008.amta-papers.21,zhang-etal-2004-interpreting,0,\N,Missing
2008.amta-papers.21,2007.iwslt-1.14,0,\N,Missing
C96-2119,H89-1034,0,0.356877,"and the lexicon. Concerning the problem involving mtknown constructions, we could easily generalize the gramram: to extend its coverage. However, both of these sohltions are t)roblematic. Ilandling the unknown word problem by increasing the size of the lexicon is not that straightforward given that most unknown words are open class items such as nouns, verbs, adjectives and adverbs. In addition, one can not generMize the grammar without side effects. Due to the highly telegraphic nature of the MUC-II data, generMizing tile grammar will increase the ambiguity of an input sentence greatly, of. (Grishman, 1989). :) tIence, we need alternative solutions to deal with unknown words and unknown constructions. Tile most desirM3le solution is to (i) leave the current grammar intact since it eifieiently parses even highly telegral)hic messages, and (ii) tackle unknown words and unknown constructions by the same mechanism. A potential solution to the unknown word problem is to: Do part of speeeh tagging and replace unknown words with their parts-of-speech, and bootstrap the parts-of:speech (instead of the actual words) to the analysis grammar. The unknown words would be replaced in the sentence string with"
C96-2119,J92-1004,1,0.898098,"Missing"
C96-2119,A94-1016,0,\N,Missing
C96-2119,C94-1020,0,\N,Missing
D09-1017,P04-1035,0,0.193438,"egree of sentiment for joint adjectives and quantifiers/qualifiers. The proposed sentiment prediction model takes modifying adverbs and negations as universal scales on strength of sentiment, and conducts cumulative calculation on the degree of sentiment for the associated adjective. With this model, we can provide not only qualitative textual summarization such as “good food” and “bad service”, but also a numerical scoring of sentiment, i.e., “how good the food is” and “how bad the service is.” 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). Specifically, aspect rating as an interesting topic has also been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006). Recently, Baccianella et. al. (2009) conducted a study on multi-facet rating of product reviews with special emphasis on how to generate vectorial representations of the text by means of POS tagging, sentiment analysis, and feature selection for ordinal regression learning. Titov and McDonald (2008b) proposed a joint model"
D09-1017,P08-1031,0,0.0535684,"lso been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006). Recently, Baccianella et. al. (2009) conducted a study on multi-facet rating of product reviews with special emphasis on how to generate vectorial representations of the text by means of POS tagging, sentiment analysis, and feature selection for ordinal regression learning. Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors. Branavan et al. (2008) proposed a method for leveraging unstructured annotations in product reviews to infer semantic document properties, by clustering user annotations into semantic properties and tying the induced clusters to hidden topics in the text. 3 System Overview Our review summarization task is to extract sets of descriptor-topic pairs (e.g., “excellent service”) from a set of reviews (e.g., for a particular restaurant), and to cluster the extracted phrases into representative aspects on a set of dimensions (e.g., “food”, “service” and “atmosphere”). Driven by this motivation, we propose a three-stage sy"
D09-1017,P05-1015,0,0.301449,"Missing"
D09-1017,E06-1039,0,0.024338,"icular product or service as assistance. Yet, valuable as they are, free-style reviews contain much noisy data and are tedious to read through in order to reach an overall conclusion. Thus, we conducted this study to automatically process and evaluate product reviews in order to generate both numerical evaluation and textual summaries of users’ opinions, with the ultimate goal of adding value to real systems such as a restaurant-guide dialogue system. Sentiment summarization has been well studied in the past decade (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004a, 2004b; Carenini et al., 2006; Liu et al., 2007). The polarity of users’ sentiments in each segment of review texts is extracted, and the polarities of individual sentiments are aggregated among all the sentences/segments of texts to give a numerical scaling on sentiment orientation. Most of the work done for sentiment analysis so far has employed shallow parsing features such as part-of-speech tagging. Frequent adjectives and nouns/noun phrases are extracted as opinion words and representative product features. However, the linguistic structure of the sentence is usually not taken into consideration. High level linguisti"
D09-1017,W02-1011,0,0.0172487,"n provide grassroots contributions to users interested in a particular product or service as assistance. Yet, valuable as they are, free-style reviews contain much noisy data and are tedious to read through in order to reach an overall conclusion. Thus, we conducted this study to automatically process and evaluate product reviews in order to generate both numerical evaluation and textual summaries of users’ opinions, with the ultimate goal of adding value to real systems such as a restaurant-guide dialogue system. Sentiment summarization has been well studied in the past decade (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004a, 2004b; Carenini et al., 2006; Liu et al., 2007). The polarity of users’ sentiments in each segment of review texts is extracted, and the polarities of individual sentiments are aggregated among all the sentences/segments of texts to give a numerical scaling on sentiment orientation. Most of the work done for sentiment analysis so far has employed shallow parsing features such as part-of-speech tagging. Frequent adjectives and nouns/noun phrases are extracted as opinion words and representative product features. However, the linguistic structure of the se"
D09-1017,H05-1043,0,0.135916,"antifiers/qualifiers. The proposed sentiment prediction model takes modifying adverbs and negations as universal scales on strength of sentiment, and conducts cumulative calculation on the degree of sentiment for the associated adjective. With this model, we can provide not only qualitative textual summarization such as “good food” and “bad service”, but also a numerical scoring of sentiment, i.e., “how good the food is” and “how bad the service is.” 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). Specifically, aspect rating as an interesting topic has also been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006). Recently, Baccianella et. al. (2009) conducted a study on multi-facet rating of product reviews with special emphasis on how to generate vectorial representations of the text by means of POS tagging, sentiment analysis, and feature selection for ordinal regression learning. Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified"
D09-1017,esuli-sebastiani-2006-sentiwordnet,0,0.00582808,"ere 4.8 outdoor patio not bad meal, Food 4.1 quite authentic food not great place, Place 2.8 very smoky restaurant so high bill, high cost, Price 2.2 not cheap price To calculate the numerical degree of sentiment, there are three major problems to solve: 1) how to associate numerical scores with textual sentiment; 2) whether to calculate sentiment scores for adjectives and adverbs jointly or separately; 3) 164 whether to treat negations as special cases or in the same way as modifying adverbs. There have been studies on building sentiment lexicons to define the strength of sentiment of words. Esuli and Sebastiani (2006) constructed a lexical resource, SentiWordNet, a WordNet-like lexicon emphasizing sentiment orientation of words and providing numerical scores of how objective, positive and negative these words are. However, lexicon-based methods can be tedious and inefficient and may not be accurate due to the complex cross-relations in dictionaries like WordNet. Instead, our primary approach to sentiment scoring is to make use of collective data such as user ratings. In product reviews collected from online forums, the format of a review entry often consists of three parts: pros/cons, free-style text and u"
D09-1017,W06-3808,0,0.107492,"ated adjective. With this model, we can provide not only qualitative textual summarization such as “good food” and “bad service”, but also a numerical scoring of sentiment, i.e., “how good the food is” and “how bad the service is.” 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). Specifically, aspect rating as an interesting topic has also been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006). Recently, Baccianella et. al. (2009) conducted a study on multi-facet rating of product reviews with special emphasis on how to generate vectorial representations of the text by means of POS tagging, sentiment analysis, and feature selection for ordinal regression learning. Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors. Branavan et al. (2008) proposed a method for leveraging unstructured annotations in product reviews to"
D09-1017,P06-2063,0,0.0617259,"s modifying adverbs and negations as universal scales on strength of sentiment, and conducts cumulative calculation on the degree of sentiment for the associated adjective. With this model, we can provide not only qualitative textual summarization such as “good food” and “bad service”, but also a numerical scoring of sentiment, i.e., “how good the food is” and “how bad the service is.” 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). Specifically, aspect rating as an interesting topic has also been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006). Recently, Baccianella et. al. (2009) conducted a study on multi-facet rating of product reviews with special emphasis on how to generate vectorial representations of the text by means of POS tagging, sentiment analysis, and feature selection for ordinal regression learning. Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of"
D09-1017,P08-1036,0,0.245431,"calculation on the degree of sentiment for the associated adjective. With this model, we can provide not only qualitative textual summarization such as “good food” and “bad service”, but also a numerical scoring of sentiment, i.e., “how good the food is” and “how bad the service is.” 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). Specifically, aspect rating as an interesting topic has also been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006). Recently, Baccianella et. al. (2009) conducted a study on multi-facet rating of product reviews with special emphasis on how to generate vectorial representations of the text by means of POS tagging, sentiment analysis, and feature selection for ordinal regression learning. Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors. Branavan et al. (2008) proposed a method for leve"
D09-1017,P02-1053,0,0.00647922,"which in return provide grassroots contributions to users interested in a particular product or service as assistance. Yet, valuable as they are, free-style reviews contain much noisy data and are tedious to read through in order to reach an overall conclusion. Thus, we conducted this study to automatically process and evaluate product reviews in order to generate both numerical evaluation and textual summaries of users’ opinions, with the ultimate goal of adding value to real systems such as a restaurant-guide dialogue system. Sentiment summarization has been well studied in the past decade (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004a, 2004b; Carenini et al., 2006; Liu et al., 2007). The polarity of users’ sentiments in each segment of review texts is extracted, and the polarities of individual sentiments are aggregated among all the sentences/segments of texts to give a numerical scaling on sentiment orientation. Most of the work done for sentiment analysis so far has employed shallow parsing features such as part-of-speech tagging. Frequent adjectives and nouns/noun phrases are extracted as opinion words and representative product features. However, the linguistic"
D09-1017,H05-2017,0,\N,Missing
D09-1017,D07-1035,1,\N,Missing
D09-1017,N07-1038,0,\N,Missing
H01-1032,J92-1004,1,\N,Missing
H01-1041,P95-1036,0,0.0880578,"order permutations are possible in reality, (ii) frequent omissions of subjects and objects, and (iii) the strict verb finality, [10]. Due to the free word order and argument omissions, the first word of an input sentence can be many way ambiguous --- it can be a part of a subject, an object, and any other post-positional phrases.2 The ambiguity introduced by the first input word grows rapidly as the parser processes subsequent input words. Verbs, which usually play a crucial role in reducing the ambiguity in English by the subcategorization frame information, are not available until the end, [1,3,11]. Our solution to the ambiguity problem lies in a novel grammar writing technique, which reduces the ambiguity of the first input word. We hypothesize that (i) the initial symbol in the grammar (i.e. Sentence) always starts with the single category generic_np, the grammatical function (subject, object) of which is undetermined. This ensures that the ambiguity of the first input word is reduced to the number of different ways the category generic_np can be rewritten. (ii) The grammatical function of the generic_np is determined after the parser processes the following case marker via a trace me"
H01-1041,P97-1003,0,0.0390878,"order permutations are possible in reality, (ii) frequent omissions of subjects and objects, and (iii) the strict verb finality, [10]. Due to the free word order and argument omissions, the first word of an input sentence can be many way ambiguous --- it can be a part of a subject, an object, and any other post-positional phrases.2 The ambiguity introduced by the first input word grows rapidly as the parser processes subsequent input words. Verbs, which usually play a crucial role in reducing the ambiguity in English by the subcategorization frame information, are not available until the end, [1,3,11]. Our solution to the ambiguity problem lies in a novel grammar writing technique, which reduces the ambiguity of the first input word. We hypothesize that (i) the initial symbol in the grammar (i.e. Sentence) always starts with the single category generic_np, the grammatical function (subject, object) of which is undetermined. This ensures that the ambiguity of the first input word is reduced to the number of different ways the category generic_np can be rewritten. (ii) The grammatical function of the generic_np is determined after the parser processes the following case marker via a trace me"
H01-1041,1994.amta-1.7,0,0.032421,"Translingual Information System 2. ROBUST PARSING, MEANING REPRESENTATION, AND AUTOMATED GRAMMAR ACQUISITION ∗ 1 This work was sponsored by the Defense Advanced Research Project Agency under the contract number F19628-00-C-0002. Opinions, interpretations, conclusions, and recommendations are those of the authors and are not necessarily endorsed by the United States Air Force. For other approaches to Korean-to-English translation, the readers are referred to Korean-to-English translation by Egedi, Palmer, Park and Joshi 1994, a transfer-based approach using synchronous tree adjoining grammar, [5], and Dorr 1997, a small-scale interlingua-based approach, using Jackendoff’s lexical conceptual structure as the interlingua, [4]. 1.1 Robust Parsing The CCLINC parsing module, TINA [16], implements the topdown chart parsing and the best-first search techniques, driven by context free grammars rules compiled into a recursive transition network augmented by features, [8]. The following properties of Korean induce a great degree of ambiguity in the grammar: (i) relatively free word order for arguments --- given a sentence with three arguments, subject, object, indirect object, all 6 logical wor"
H01-1041,P97-1016,1,0.933119,"order permutations are possible in reality, (ii) frequent omissions of subjects and objects, and (iii) the strict verb finality, [10]. Due to the free word order and argument omissions, the first word of an input sentence can be many way ambiguous --- it can be a part of a subject, an object, and any other post-positional phrases.2 The ambiguity introduced by the first input word grows rapidly as the parser processes subsequent input words. Verbs, which usually play a crucial role in reducing the ambiguity in English by the subcategorization frame information, are not available until the end, [1,3,11]. Our solution to the ambiguity problem lies in a novel grammar writing technique, which reduces the ambiguity of the first input word. We hypothesize that (i) the initial symbol in the grammar (i.e. Sentence) always starts with the single category generic_np, the grammatical function (subject, object) of which is undetermined. This ensures that the ambiguity of the first input word is reduced to the number of different ways the category generic_np can be rewritten. (ii) The grammatical function of the generic_np is determined after the parser processes the following case marker via a trace me"
H01-1041,J93-2004,0,0.0242594,"Missing"
H01-1041,J92-1004,1,0.7189,"NTIC FRAMES SEMANTIC FRAMES (COMMON (COMMON COALITION COALITION LANGUAGE) LANGUAGE) GENERATION GENERATION GENERATION GENERATION OTHER LANGUAGES 1. SYSTEM OVERVIEW The CCLINC The CCLINC Korean-to-English translation system is a component of the CCLINC Translingual Information System, the focus languages of which are English and Korean, [11,17]. Translingual Information System Structure is given in Figure 1. Given the input text or speech, the language understanding system parses the input, and transforms the parsing output into a language neutral meaning representation called a semantic frame, [16,17]. The semantic frame  the key properties of which will be discussed in Section 2.3  becomes the input to the generation system. The generation system produces the target to the generation system, the semantic frame can be utilized for other applications such as translingual information extraction and Figure 1. Structure CCLINC Translingual Information System 2. ROBUST PARSING, MEANING REPRESENTATION, AND AUTOMATED GRAMMAR ACQUISITION ∗ 1 This work was sponsored by the Defense Advanced Research Project Agency under the contract number F19628-00-C-0002. Opinions, interpretations, conclusions,"
H89-1026,H89-1026,1,0.0511959,"er with their subject but not their object. GAPS The mechanism to deal with gaps involves four special types of grammar nodes, identified as generators, activators, blockers, and absorbers. Generators are parse nodes whose grammatical category allows them to fill the current-focus slot with the subparse returned to them by their children. The current-focus is passed on to right-siblings and their descendents, but not to parents, and thus effectively reaches nodes that 1 Some modification of t h i s s c h e m e will be n e c e s s a r y w h e n the input s t r e a m is n o t deterministic. See [4] for a discussion of these very i m p o r t a n t issues r e g a r d i n g scoring in a best-first search. 2 W h i c h article, the object of the verb ""read,"" h a s been pulled out of place and moved to t h e front of t h e question. 171 are c-commanded by the generator and its descendents [5,6]. Activators are nodes that move the currentfocus into the float-object slot. They also require that the float-object be absorbed somewhere among their descendants. Blockers (such as SUBJECT) are nodes that block the transmission of the float-object to their children. Finally, absorbers are allowed to u"
H89-1026,J86-3002,0,0.0853219,", which would be subsetted for a particular task by simply providing it with a set of example sentences within that task. The issue of semantic analysis has not yet been dealt with properly within TINA. We were able to achieve significant perplexity reduction by defining some semantically restricted classes, particularly within noun phrases, but this is probably not the appropriate way to represent semantic constraint. I would rather see semantic filters introduced through co-occurrence data on syntactic pairs like Adjective-Noun and Subject-Verb, adopting methods similar to those proposed in [10,11]. 3in the case of T I N A , all words u p to t h e c u r r e n t word w i t h i n each s e nt e nc e a re r e l e v a n t . 176 At the time a set of word candidates is proposed to the acoustic matcher of a recognizer, all of thc constraint available from the restrictive influence of syntax, semantics, and phonology should have already been applied. The syntactic parse tree of TINA can be used to express other constraints ranging from acoustic-phonetic to semantic and pragmatic. The syntactic node would contain slots for various kinds of constraint information - syntactic filters such as person"
H89-1026,H89-1027,1,0.837887,"f parsable sentences, but when a sentence fails to parse there is no recourse except human intervention to provide new rules. One possibility is to generate some new rules automatically by applying meta-rules similar to those used in the Unification framework, as in the generation of passive voice forms for verbs. Berwick's research in the area of automatic language acquisition [12] represents an important effort along these lines as well, and it is likely that some of his ideas could be extended to apply in TINA's framework. We plan to integrate TINA with the SUMMIT speech recognition system [13] shortly. Two important issues are 1) how to combine the scores for the recognition component and the predictive component of the grammar, and 2) how to take advantage of appropriate pruning strategies to prevent an explosive search problem. In the case of the first problem, we would need to modify the mechanism for using path probabilities in TINA, in order to deal with the nondeterministic nature of the acoustic evidence. With regard to the second problem, each parse node in the tree can prune all but the best-scoring equivalent path by maintaining a record of all solutions returned to it by"
H89-1027,H89-1026,1,0.790081,"scribes those parts of our system dealing with acoustic segmentation, phonetic classification, and lexical access, and documents its current performance on the DARPA Resource Management task [1]. SYSTEM DESCRIPTION There are three major components in the SUMMIT system, as illustrated in Figure 1. The first component transforms the speech signal into an acoustic-phonetic description. The second expands a set of baseform pronunciations into a lexical network. The final component provides natural language constraints. Our preliminary efforts in natural langauge are described in a companion paper [2]. The acoustic-phonetic and lexical components will be discussed in more detail in the following sections. Signal Lexicon Higher-Level Linguistic Knowledge Lexical Expansion Language Modeling 1 Signal Representation I Acoustic segmentation Feature Extraction & Phoneme Recognition I ,I 1oder, I 1 Decoded Utterance Figure 1: The major components of the SUMMIT system. ACOUSTIC-PHONETIC REPRESENTATION The phonetic recognition subsystem of SUMMIT takes as input the speech signal and produces as output of phonetic labels with scores indicating the system&apos;s confidence in the segments and in the accur"
H89-2008,H89-2018,1,0.612237,"always utter grammatically well-formed sentences during a spoken dialogue. Over the past six months, we have constructed the skeleton of a spoken language system. The purpose of this paper is to describe the various components of this system. In related activities, we have collected a sizeable spontaneous speech database, and have used the data for analyses, system training and evaluation. The collection and analysis of the spontaneous speech database, and the preliminary evaluation of our spoken language system are described in two companion papers that appear elsewhere in these proceedings [1,2]. TASK DESCRIPTION In order to explore issues related to a fully-interactive spoken language system, we have selected a task in which the system knows about the physical environment of a specific geographical area as well as certain objects inside this area, and can provide assistance on how to get from one location to another within this area. The system, which we call VOYAGER, currently focuses on the the city of Cambridge, Massachusetts, between MIT and Harvard University, as shown in Figure 1. It can answer a number of different types of questions about certain hotels, restaurants, hospita"
H89-2008,H89-2022,1,0.523132,"always utter grammatically well-formed sentences during a spoken dialogue. Over the past six months, we have constructed the skeleton of a spoken language system. The purpose of this paper is to describe the various components of this system. In related activities, we have collected a sizeable spontaneous speech database, and have used the data for analyses, system training and evaluation. The collection and analysis of the spontaneous speech database, and the preliminary evaluation of our spoken language system are described in two companion papers that appear elsewhere in these proceedings [1,2]. TASK DESCRIPTION In order to explore issues related to a fully-interactive spoken language system, we have selected a task in which the system knows about the physical environment of a specific geographical area as well as certain objects inside this area, and can provide assistance on how to get from one location to another within this area. The system, which we call VOYAGER, currently focuses on the the city of Cambridge, Massachusetts, between MIT and Harvard University, as shown in Figure 1. It can answer a number of different types of questions about certain hotels, restaurants, hospita"
H89-2008,H89-1027,1,0.851944,"usly reported. SPEECH RECOGNITION COMPONENT The first component of VOYAGER uses the SUMMIT speech recognition system developed in our group. SUMMIT places heavy emphasis on the extraction of phonetic information from the speech signal. It achieves speech recognition by explicitly detecting acoustic landmarks in the signal in order to facilitate acousticphonetic feature extraction. The system can be trained automatically, since it does not rely on extensive knowledge engineering. The design philosophy, implementation, and evaluation of the SUMMIT system have been described in detail previously [4]. As a result, we will only report in this paper modifications to the system since the last workshop. These include the development of a new module for lexical expansion via 52 phonological rules, and a new corrective training procedure. Lexical Expansion The original SUMMIT system used a phonological expansion capability provided to us by SRI [6]. Within the last year, however, we have decided to rewrite this part of the system in order to establish increased flexibility and speed. The new version, named MARBLE, offers several new properties. A canonic set of phonemes is represented by a set"
H89-2008,H89-1026,1,0.869519,"ech recognition and natural language components are not as yet fully integrated, we currently use a word-pair language model with a perplexity of 22 to constrain the search space. NATURAL LANGUAGE COMPONENT In the context of a spoken language system, the natural language component should perform two critical functions: 1) to provide constraint for the recognizer component, and 2) to provide an interpretation of the meaning of the sentence to the back end. Our natural language system, TINA, was specifically designed to meet these two needs. The basic design of TINA has been described elsewhere [7], and therefore will only be briefly mentioned here. Instead, we would like to focus on the issue of how to incorporate semantics into the parses. We have found that an enrichment of the parse tree with semantically loaded categories at the lower levels leads to both improved word predictions and a relatively straightforward interface with the back end. General Description The grammar is entered as a set of simple context-free rules which are automatically converted to a 53 shared network structure. The nodes in the network are augmented with constraint filters (both syntactic and semantic) th"
H89-2018,H89-2008,1,0.612917,"of the city of Cambridge, Massachusetts, between MIT and Harvard University, and can deal with several distinct concepts including directions, distance and time of travel between objects, relationships such as &quot;nearest,&quot; and simple properties such as phone numbers or types of food served. VOYAQErt also has a limited amount of discourse knowledge which enables it to respond to queries such as: &quot;How do I get there?&quot; It can also deal with certain clarification fragments such as: &quot;The bank in Harvard Square.&quot; A detailed description of the VOYAGER system can be found elsewhere in these proceedings [1]. VOYAGER is made up of three components. The first component, the SUMMIT speech recognition system [2], converts the speech signal into a set of word hypotheses. The natural language component, TINA [3], provides a linguistic interpretation of the set of words. The parse tree generated by TINA is translated into a query language form, which is used to produce a response. Currently VOYAGER can generate responses in the form of text, graphics, and synthetic speech. The back end is an enhanced version of a direction assistance program developed by Jim Davis of MIT's Media Laboratory [4]. *This r"
H89-2018,H89-1027,1,0.84152,"distinct concepts including directions, distance and time of travel between objects, relationships such as &quot;nearest,&quot; and simple properties such as phone numbers or types of food served. VOYAQErt also has a limited amount of discourse knowledge which enables it to respond to queries such as: &quot;How do I get there?&quot; It can also deal with certain clarification fragments such as: &quot;The bank in Harvard Square.&quot; A detailed description of the VOYAGER system can be found elsewhere in these proceedings [1]. VOYAGER is made up of three components. The first component, the SUMMIT speech recognition system [2], converts the speech signal into a set of word hypotheses. The natural language component, TINA [3], provides a linguistic interpretation of the set of words. The parse tree generated by TINA is translated into a query language form, which is used to produce a response. Currently VOYAGER can generate responses in the form of text, graphics, and synthetic speech. The back end is an enhanced version of a direction assistance program developed by Jim Davis of MIT's Media Laboratory [4]. *This research was supported by DARPAunder Contract N00014-89-J-1332, monitoredthrough the Officeof Naval Rese"
H89-2018,H89-1026,1,0.885551,"uch as &quot;nearest,&quot; and simple properties such as phone numbers or types of food served. VOYAQErt also has a limited amount of discourse knowledge which enables it to respond to queries such as: &quot;How do I get there?&quot; It can also deal with certain clarification fragments such as: &quot;The bank in Harvard Square.&quot; A detailed description of the VOYAGER system can be found elsewhere in these proceedings [1]. VOYAGER is made up of three components. The first component, the SUMMIT speech recognition system [2], converts the speech signal into a set of word hypotheses. The natural language component, TINA [3], provides a linguistic interpretation of the set of words. The parse tree generated by TINA is translated into a query language form, which is used to produce a response. Currently VOYAGER can generate responses in the form of text, graphics, and synthetic speech. The back end is an enhanced version of a direction assistance program developed by Jim Davis of MIT's Media Laboratory [4]. *This research was supported by DARPAunder Contract N00014-89-J-1332, monitoredthrough the Officeof Naval Research. lWe looselyuse the terra spontaneous speech to mean the speech produced by a person &quot;on the fl"
H89-2018,H89-2022,1,\N,Missing
H89-2022,H89-2008,1,0.522185,"hould be able to benefit from hands-on experience with applying some candidate performance measures to working systems. The purpose of this paper is to document our experience with the preliminary evaluation of the VOYAGEa system currently under development at MIT, so that we may contribute to the evolutionary process of defining the appropriate evaluation measures. VOYAGER is a speech understanding system that can provide information and navigational assistance for a geographical area within the city of Cambridge, Massachusetts. The components of the system are described in a companion paper [2]. To evaluate VOYAGER we made use of a spontaneous speech database that we have recently collected consisting of nearly 10,000 sentences from 100 speakers. The database is described in another companion paper [3]. E V A L U A T I O N ISSUES We believe that spoken language systems should be evaluated along several dimensions. First, the accuracy of the system and its various modules should be documented. Thus, for example, one can measure a given system&apos;s phonetic, word, and sentence accuracy, as well as linguistic and task completion accuracy. Second, one must measure the coverage and habitabi"
H89-2022,H89-2018,1,0.600561,"he VOYAGEa system currently under development at MIT, so that we may contribute to the evolutionary process of defining the appropriate evaluation measures. VOYAGER is a speech understanding system that can provide information and navigational assistance for a geographical area within the city of Cambridge, Massachusetts. The components of the system are described in a companion paper [2]. To evaluate VOYAGER we made use of a spontaneous speech database that we have recently collected consisting of nearly 10,000 sentences from 100 speakers. The database is described in another companion paper [3]. E V A L U A T I O N ISSUES We believe that spoken language systems should be evaluated along several dimensions. First, the accuracy of the system and its various modules should be documented. Thus, for example, one can measure a given system&apos;s phonetic, word, and sentence accuracy, as well as linguistic and task completion accuracy. Second, one must measure the coverage and habitability of the system. This can be applied to the lexicon, the language model, and the application back-end. Third, the system&apos;s flexibility must be established. For *This research was supported by DARPAunder Contra"
H89-2022,H89-1027,1,0.861742,"Missing"
H89-2022,H89-1026,1,0.872671,"Missing"
H90-1028,W89-0222,1,0.885214,"ire sentence has been processed and the history frames have been merged, an IDIL[2] 1 query is then constructed from the completely specified frame. We had initially constructed the query &quot;on the fly,&quot; but we found that this led to much complexity at the end because of discourse effects that would require last minute alterations on the restrictions in the query. An Example As in the VOYAGER domain, we have taken the viewpoint that the parse tree contains semantically loaded nodes at the lower levels, and these are in fact the only semantic information that is used by the interface between TINA[3] and the back-end. The presence of certain nodes within specified positions in the hierarchy triggers the execution of particular functions whose action is typically to update slots in a semantic representation or event frame. The event frame is passed as the first argument to each new function that is called, and the final event, frame then has in place all of the appropriate information to be extracted from the sentence. We will illustrate how the ATIS system converts a sentence into an event frame by walking through a single example. Consider the sentence, &quot;Show me the flights on September"
H90-1028,H89-2018,1,0.91661,"ely occur. In addition, there were no sentence fragments and no sentences using indirect speech such as &quot;I want to go....&quot; For instance, the sentence &quot;Show me the flights,&quot; gives a perplexity reduction from 300 to 5 with the use of probabilities, reflecting the fact that this is a very common form. *A word-pair grammar would give a further increase in perplexity. For Voyager the perplexity increased from 28 to 73 when long-distance constraints were ignored. Data Collection We have performed a preliminary data collection session, using a procedure that mimics closely the one we used for VOYAGER[4]. We told subjects to pretend they were a traveler planning a trip. Their task was to work together with the system to select particular flights that would meet their requirements. They could book the selected flights, with the understanding that booking in real use means recording the relevant information so that a travel agent could complete the task. We reminded them of the types of information the system contains (meals, fares, times, etc.). The wizard&apos;s task was a simple one of typing in verbatim (minus false starts) what the user said. The system answered as well as it could, and identif"
H90-1028,H89-2008,1,0.912862,"eaving before 3:00 p.m. serving lunch,&quot; prior to displaying the table. We are hoping that the user will be less inclined to speak &quot;computerese&quot; if the computer behaves a little more like a person. General Description Knowledge Representation Our conception of an ATIS system is somewhat different from the one defined by the common task. First, we would like a domain that is sufficiently restrictive that we could hope to cover most sentences spoken with high probability. That is, it should be easy for the user to understand the limits of the We made a major paradigm shift in moving from VOYAGER [5] to hTm in terms of back-end function operations, one that was necessitated by the fact that the database should be accessed only once, after all restrictions are in place. Within VOYAGER, low-level functions would access the database di130 rectly, passing on sets of objects to be filtered by later lowlevel functions. Thus, for example the (restaurant) function returns the set of all restaurants, which might later be subsetted by the (serve) function to include, for example, only restaurants serving Chinese food. In ATIS, low level functions typically fill slots in an event frame with appropri"
H90-1043,H89-2027,0,0.0300984,"ere a number of incremental improvements in the word-pair grammar, pronunciation networks, and the backend capabilities. S R / N L Integration In our initial implementation of VOYAGER, the integration of speech and natural language components was accomplished by obtaining the best word sequence from the recognizer and passing that word sequence to the natural language system. Modifying the speech recognition component to produce a list of the top scoring word sequences provides a convenient means for increasing the level of integration of the speech recognition and natural language components [2]. In this way, the natural language system can be run successively on each of the word sequences to find the highest scoring sequence that passes the natural language constraints. Two-stage N-Best search Previously, to produce the top scoring word sequence, our speech recognition system used Viterbi search [4,10]. This algorithm provides an efficient search for the top word sequence but does not directly provide the top N word sequences. Others have chosen to modify this search by keeping track of the top N word sequences at each point in the search [2]. We also 206 use a modification of Viter"
H90-1043,H90-1004,0,0.583699,"to the end for each lexical node at each point in time. If the constraints we use in the Viterbi search to compute the best score to the end are a subset of the full natural language constraints, this estimate of the best score to the end is guaranteed to be an upper bound on best score to the end given the full constraints. The A* search allows a large amount of flexibility in when to apply the natural language constraints. For example, we can wait until we have entire sentence hypotheses before applying the full natural language constraints. This turns the A* search into an N-best algorithm [3] and allows us to compare it directly to the other N-best algorithms. We computed processing time and memory use for our implementation of this algorithm and plotted it in Figure 1. For the top 1 word sequence, this algorithm requires about the same amount of resources as our implementation of Viterbi search and the amount of resources increases approximately linearly with N at least for small N. We have begun to perform experiments to determine which natural language constraints to apply at an earlier stage of the A* search. There is a tradeoff between the cost of applying the constraint and"
H90-1043,H90-1028,1,0.874308,"language model. This method was quite successful. TINA can generate 100,000 sentences in an overnight run, and the resulting wordpair language model had a perplexity of only 73 with a single missed word-pair in the test set. W e therefore decided to incorporate this word-pair language model into the recognizer. Increased Coverage As we have described previously [9], the command generation component translates the natural language parse to a functional form that is evaluated by the system. This component has been made more flexible, in part due to our experience with developing an ATIS system [6]. We have extended the capabilities of the back-end functions to handle more complex manipulations. Some of these changes were motivated by an examination of our training data. In other cases, we 208 were interested in knowing if our framework could handle manipulations commonly used in other database query systems. For this reason we included conjunction and negation, even though they are rarely used by subjects (except by those with a natural language processing background!). As a result of these modifications, the system is now capable of handling queries such as ""Show me the Chinese or Jap"
H90-1043,H90-1074,1,0.770402,"rformance by incorporating some form of explicit rejection criterion. Currently we reject an utterance based on the number of word strings that fail to produce a response (by choosing an upper bound on N in the N-Best search). If we used a more explicit rejection criterion (by taking into account the scores of the top N word strings for example) we may be able to decrease the ratio of incorrect response to correct responses. There have been a number of developments in the speech recognition components that we intend to incorporate into the VOYAGER system. These are discussed in more detail in [7]. We would like to begin exploring dynamic adaptation of the natural language constraints. For example, we would like to increase the objects in VOYAGER's database to a much more complete set. In our current implementation, this would increase the perplexity of the speech recognition and result in poor performance. However, if we limit the vocabulary based on the discourse history, it is likely that we can make large increases in the size of the VOYAGER domain without Summary/Future Plans The evaluations show that compared to passing only the top scoring word string to the natural language sys"
H90-1043,H89-2018,1,0.854641,"tion will run in real time in the present hardware configuration. When combined with lexical access, the entire system will run in approximately 3 times real time on a Sun4/330 and in approximately 2 times real time on a Sun 4/490. Ethemet I Su.u..4/~O • Data Capture [ SPARCeS~t, ion I • Auditory Modelling * Natural Language • Phonetic Recognition * Response Generation • Lex:[cal Access F i g u r e 2: This figure shows the current hardware configuration of the VOYAGER, system. Evaluations At the October 1989 DARPA meeting, we presented a number of evaluations of our initial version of VOYAGER [8] and we have used the same test set to measure the effects of the changes made since that time. To measure the effects of multiple sentence hypotheses, we allowed the system evaluated in [8] to produce the top N word sequences rather than the highest scoring word sequence. Its performance is plotted as a function of N in Figure 3. For each utterance, we therefore the current representation could be run on up to 40 different processors. The dendrogram computation is difficult to divide among processors, but fortunately it runs in under real time on a single DSP32C. The computation of acoustic m"
H90-1043,H89-2008,1,0.851767,"cessary because, when semantic matches are required, generation usually picks the wrong path and aborts on constraint failure. As a consequence, paths with traces are rarely visited by the generator and may not show up in our word-pair language model. This method was quite successful. TINA can generate 100,000 sentences in an overnight run, and the resulting wordpair language model had a perplexity of only 73 with a single missed word-pair in the test set. W e therefore decided to incorporate this word-pair language model into the recognizer. Increased Coverage As we have described previously [9], the command generation component translates the natural language parse to a functional form that is evaluated by the system. This component has been made more flexible, in part due to our experience with developing an ATIS system [6]. We have extended the capabilities of the back-end functions to handle more complex manipulations. Some of these changes were motivated by an examination of our training data. In other cases, we 208 were interested in knowing if our framework could handle manipulations commonly used in other database query systems. For this reason we included conjunction and neg"
H90-1043,H89-1027,1,0.826421,"izer and passing that word sequence to the natural language system. Modifying the speech recognition component to produce a list of the top scoring word sequences provides a convenient means for increasing the level of integration of the speech recognition and natural language components [2]. In this way, the natural language system can be run successively on each of the word sequences to find the highest scoring sequence that passes the natural language constraints. Two-stage N-Best search Previously, to produce the top scoring word sequence, our speech recognition system used Viterbi search [4,10]. This algorithm provides an efficient search for the top word sequence but does not directly provide the top N word sequences. Others have chosen to modify this search by keeping track of the top N word sequences at each point in the search [2]. We also 206 use a modification of Viterbi search to produce the top N word sequences. In our algorithm, we first use Viterbi search to compute the best partial paths both arriving and leaving each lexical node at each point in time. The algorithm then successively extracts the next best complete path by searching through the precomputed matrix of part"
H90-1074,H89-1027,1,\N,Missing
H90-1074,H89-2018,1,\N,Missing
H91-1014,H91-1072,1,0.875379,"Missing"
H91-1014,H91-1010,0,0.118809,"Missing"
H91-1014,H91-1071,1,0.837088,", particularly the back-end component that transforms the parse tree into a representation that can be used to maintain discourse, generate confirmation messages, and produce SQL queries for accessing the OAG database. We have also connected the SUMMIT speech recognizer to our ATIS system, so that it can now accept verbal input. Recognition Component The speech recognition configuration is similar to the one used in the VOYAGERsystem and is based on the SUMMIT system [6]. For the ATIS task, we used 76 context-independent phone models trained on speaker-independent data collected at TI and MIT [3]. There were 1284 TI sentences (read and spontaneous versions of 642 sentences) and 1146 spontaneous sentences taken from the MIT training corpus. The lexicon was derived from the vocabulary used by the ATIS natural language component and consisted of 577 words. In order to provide some conservative natural language constraints, the speech recognition component used a generalized word-pair grammar derived from the speech training data augmented with a large number of additional sentences pooled from all available sources of nTIS related text material. The wordpair grammar was generated by pars"
H91-1014,H91-1070,1,0.897645,"e M I T ATIS S y s t e m 1 Stephanie Seneff, James Glass, David Goddeau, David Goodine, Lynette Hirschman, Hong Leung, Michael Phillips, Joseph Polifroni, and Victor Zue Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology Cambridge, Massachusetts 02139 ABSTRACT have collected over the past few months [3]. Aspects of the system involving discourse and dialogue are based on similar principles as before, but has been modified to reflect the new semantic representations. A detailed description of our discourse model can be found in a companion paper [4]. This paper represents a status report on the MIT ATIS system. The most significant new achievement is that we now have a speech-input mode. It is based on the MIT SUMMITsystem using context independent phone models, and includes a word-pair grammar with perplexity 92 (on the June-90 test set). In addition, we have completely redesigned the back-end component, in order to emphasize portability and extensibility. The parser now produces an intermediate semantic frame representation, which serves as the focal point for all back-end operations, such as history management, text generation, and SQ"
H91-1014,H90-1028,1,0.809974,"tem that are tied to a particular domain are now entered through a set of tables associated with a small artificial language for decoding them. We have also improved the display of the database table, making it considerably easier for a subject to comprehend the information given. We report here on the results of the official DARPA February-91 evaluation, as well as on results of an evaluation on data collected at MIT, for both speech input and text input. SYSTEM DESCRIPTION In this section we will describe those aspects of the system that have changed significantly since our report last June [5]. The most significant change has been the incorporation of the speech recognition component. We begin by describing the recognizer configuration and the interface mechanism we are currently using. In the natural language component, the parser and grammar remain unchanged, except for augmentations to improve coverage. However, we have completely redesigned the component that translates from a parse tree to executable SQL queries, and the component that generates verbal responses. Both of these areas are described here in more detail. INTRODUCTION Speech In June 1990, we reported on the initial"
H91-1014,H90-1043,1,0.88538,"in the first round of DARPA common evaluation using text input [5]. Since then, a number of changes have been made to our system, particularly the back-end component that transforms the parse tree into a representation that can be used to maintain discourse, generate confirmation messages, and produce SQL queries for accessing the OAG database. We have also connected the SUMMIT speech recognizer to our ATIS system, so that it can now accept verbal input. Recognition Component The speech recognition configuration is similar to the one used in the VOYAGERsystem and is based on the SUMMIT system [6]. For the ATIS task, we used 76 context-independent phone models trained on speaker-independent data collected at TI and MIT [3]. There were 1284 TI sentences (read and spontaneous versions of 642 sentences) and 1146 spontaneous sentences taken from the MIT training corpus. The lexicon was derived from the vocabulary used by the ATIS natural language component and consisted of 577 words. In order to provide some conservative natural language constraints, the speech recognition component used a generalized word-pair grammar derived from the speech training data augmented with a large number of"
H91-1014,H90-1074,1,\N,Missing
H91-1070,H91-1014,1,0.895401,"s the present status of the discourse and dialogue models within the MIT AWlS system. After describing the models, we will illustrate some of the system's capabilities by way of an example. We then describe our preliminary attempts at collecting data in a booking mode, for which we hive included a complete dialogue elicited from one of our subjects. Finally, potential implications for improvemeats in speech recognition are discussed. MODELLING METHOD OLOGY The back-end component of the MIT ATm system has been completely redesigned since last June [5]. The main system is described in detail in [4], and will only be briefly 354 anaphoric reference such as &quot;it&quot; or &quot;these flights.&quot; Instead, individual modifiers are inherited unless new modifiers override their inheritance. History elements are stored in the standard frame format, and inheritance of a modifier usually amounts to simply inserting it into the appropriate frame of the new sentence. Frame format : [name ~ype key1: va3.uel key2:value2 °.,] F r a,me : [veri~y clause ~opic: [ f l i g h t qset number: 22] predicate: [serve predicate theme': [&quot;dinner&quot; reference ref~ype: meal]]] Figure 1: Frame representation resulting from analysis"
H91-1070,H90-1028,1,0.833794,"user expectations too high. This paper describes the present status of the discourse and dialogue models within the MIT AWlS system. After describing the models, we will illustrate some of the system's capabilities by way of an example. We then describe our preliminary attempts at collecting data in a booking mode, for which we hive included a complete dialogue elicited from one of our subjects. Finally, potential implications for improvemeats in speech recognition are discussed. MODELLING METHOD OLOGY The back-end component of the MIT ATm system has been completely redesigned since last June [5]. The main system is described in detail in [4], and will only be briefly 354 anaphoric reference such as &quot;it&quot; or &quot;these flights.&quot; Instead, individual modifiers are inherited unless new modifiers override their inheritance. History elements are stored in the standard frame format, and inheritance of a modifier usually amounts to simply inserting it into the appropriate frame of the new sentence. Frame format : [name ~ype key1: va3.uel key2:value2 °.,] F r a,me : [veri~y clause ~opic: [ f l i g h t qset number: 22] predicate: [serve predicate theme': [&quot;dinner&quot; reference ref~ype: meal]]] Figure"
H91-1070,H91-1071,1,\N,Missing
H91-1070,J86-3001,0,\N,Missing
H91-1071,H90-1023,0,0.0295014,"Missing"
H91-1071,H90-1030,0,0.0561258,"Missing"
H91-1071,H90-1029,0,0.0223773,"Missing"
H91-1071,H90-1021,0,0.050844,"Missing"
H91-1071,H89-2018,1,\N,Missing
H91-1071,H90-1020,0,\N,Missing
H91-1071,H91-1070,1,\N,Missing
H91-1071,H89-2017,0,\N,Missing
H91-1072,H90-1053,0,0.0234353,"a probability estimate for the next word given the preceding word sequence. We feel that a next-word probability is much more appropriate than a rule-production probability for incorporating into a tightly coupled system, since it leads to a simple definition of the total score for the next word as the weighted sum of the language model probability and the acoustic probability. While rule-production probabilities can in fact be generated from the probabilities we provide, they will not, in general, agree with the probabilities as determined by a procedure such as the inside/outside algorithm [6,2]. ARCHITECTURE The VOYAGER system consists of the TINA natural language understanding system and the s u MMIT speech recognition system. These components will only be described briefly here, as they are more fully documented in [7,9,10]. TINA combines a general English syntax at the top level with a semantic grammar framework at lower levels, to provide an interleaved syntax/semantics analysis that minimizes perplexity. As a result, most sentences in TINA have only one parse. TINA uses a best-first heuristic search in parsing, storing alternate candidate parse paths while it pursues the most p"
H91-1072,H89-1012,0,0.027674,"e obvious solution is to bring linguistic knowledge to bear. One way is to take the best acoustic candidate and use a flexible, semantically-based phrase-spotting system to assign a meaning to the sequence of words [8]. This provides a robust interface which can ignore many recognition errors and abandons the notion of a linguistically well-formed overall sentence. It almost always produces some interpretation. However, since it adds no real linguistic constraints, it may produce many false positives (misinterpretation of the input ) . A second possiblity which has been explored at some sites [1] is to have the recognizer produce a word lattice, with (acoustic) transition probabilities between words. The language system can then search this lattice for the best candidate. or with a tighter coupling in which active partial theories dynamically prune the set of allowable next-word candidates during the search. TRAINING PARSE PROBABILITIES Another approach, which is the baseline for these experiments, uses an N-best interface between the recognizer and the language understanding system. In this interface, the recognizer produces sentence hypotheses in decreasing order of acoustic score."
H91-1072,H89-1026,1,0.864332,"eads to a simple definition of the total score for the next word as the weighted sum of the language model probability and the acoustic probability. While rule-production probabilities can in fact be generated from the probabilities we provide, they will not, in general, agree with the probabilities as determined by a procedure such as the inside/outside algorithm [6,2]. ARCHITECTURE The VOYAGER system consists of the TINA natural language understanding system and the s u MMIT speech recognition system. These components will only be described briefly here, as they are more fully documented in [7,9,10]. TINA combines a general English syntax at the top level with a semantic grammar framework at lower levels, to provide an interleaved syntax/semantics analysis that minimizes perplexity. As a result, most sentences in TINA have only one parse. TINA uses a best-first heuristic search in parsing, storing alternate candidate parse paths while it pursues the most promising (most probable) path. In addition, the grammar is trainable from instances of parse trees, as described in the next section. The SUMMIT system transforms a speech waveform into a segment lattice. Features are extracted for each"
H91-1072,H89-1027,1,0.837446,"eads to a simple definition of the total score for the next word as the weighted sum of the language model probability and the acoustic probability. While rule-production probabilities can in fact be generated from the probabilities we provide, they will not, in general, agree with the probabilities as determined by a procedure such as the inside/outside algorithm [6,2]. ARCHITECTURE The VOYAGER system consists of the TINA natural language understanding system and the s u MMIT speech recognition system. These components will only be described briefly here, as they are more fully documented in [7,9,10]. TINA combines a general English syntax at the top level with a semantic grammar framework at lower levels, to provide an interleaved syntax/semantics analysis that minimizes perplexity. As a result, most sentences in TINA have only one parse. TINA uses a best-first heuristic search in parsing, storing alternate candidate parse paths while it pursues the most promising (most probable) path. In addition, the grammar is trainable from instances of parse trees, as described in the next section. The SUMMIT system transforms a speech waveform into a segment lattice. Features are extracted for each"
H91-1072,H91-1014,1,0.879605,"Missing"
H91-1072,H90-1027,0,\N,Missing
H92-1005,H90-1022,0,0.037099,"tween these systems: there were significant differences in ability to complete the task, number of queries required to complete the task, and score (as computed through a log file evaluation) between the robust and the non-robust modes. INTRODUCTION For the first two years of the DARPA Spoken Language Program, common evaluation in the ATIS d o m a i n has been performed solely with the C o m m o n Answer Specification (CAS) protocol [4], whereby a system&apos;s performance is determined by comparing its output, expressed as a set of database tuples, with one or more predetermined reference answers [1]. The CAS protocol has the advantage that system evaluation can be carried out automatically, once the principles for generating the reference answers have been established and a corpus has been annotated accordingly. Since direct comparison across systems can be performed relatively easily with this procedure, we have been able to achieve cross fertilization of research ideas, leading to rapid research progress. 1This research was s u p p o r t e d by D A R P A u n d e r Contract N000] 4-89-J-1332, monitored t h r o u g h the Office of Naval Research. 28 QUERY 1: PLEASE LIST THE FLIGHT FROM P"
H92-1005,H91-1071,1,0.818696,"arry out end-to-end evaluation, i.e., evaluation of overall task completion effectiveness, we must be able to determine precisely the task being solved, the correct answer(s), and when t h e s u b j e c t is done. Once these factors have been specified, we can then compute some candidate measures and see if any of them are appropriate for characterizing end-to-end system performance. While true measures of system performance will require a (near) real-time spoken language system, we felt that some preliminary experiments could be conducted within the context of our ATIS data collection effort [3,2]. In our data collection paradigm, a typist types in the subject&apos;s queries verbatim, after removing disfluencies. All subsequent processing is done automatically by the system. To collect data for end-to-end evaluation, we modified our standard data collection procedure slightly, by adding a specific scenario which has a unique answer. For this scenario, the subjects were asked to report the answer explicitly. As a preliminary experiment, we used two simple scenarios. In one of them, subjects were asked to determine 29 II Measurements I[ Mean [Std. Dev. I[ Total ~ of Queries Used 4.8 1.6 # of"
H92-1005,H92-1060,1,\N,Missing
H92-1005,H92-1003,1,\N,Missing
H92-1016,H90-1016,0,0.0449197,"Missing"
H92-1016,H91-1011,1,0.766755,"(labelled as B G + P L R ) shows that further reduction in error rate is possible by incorporating the PLR. P L R is incorporated by using the parse score in place of the bigram score to reorder the 50 Nbest outputs produced by the recognizer. The sentence error rate is reduced more than the word error rate, presumably due to the fact that P L R can deal with some of the long distance constraints better than the bigram. Context-Dependent Modelling At the last DARPA meeting we first described our work towards accounting for contextual effects on the phonetic modelling component of S U M M I T [5]. We proposed using regression tree analysis to find the contex3 T h i s is r o u g h l y equivalent to p a r s i n g t h e word s t r i n g as a seq u e n c e of f r a g m e n t s r a t h e r t h a n as a c o m p l e t e sentence. 86 tual factors that provided the greatest reduction in the distortion of our phonetic models. In an initial experiment, regression tree analysis was used to form a set of context-specific models for each phonetic unit. However, we found that we were able to obtain the best performance by using the regression trees to independently learn a context-normalization fact"
H92-1016,H92-1003,1,0.839497,"Missing"
H92-1016,H91-1071,1,0.869573,"Missing"
H92-1016,H91-1014,1,0.711669,"at MIT. Some 9,711 utterances in this pool were designated as training material, and an additional 1,595 utterances were set aside as a development set for independent evaluation. To facilitate a meaningful comparison, all the experiments described in this section are performed on the October '91 ""dry-run"" test set, containing some 362 utterances collected at BBN, CMU, MIT, and SRI. The experiments that we conducted are summarized in Table 1, and will be described in this section. In order to monitor progress internally, we also ran the same test set through our system as reported a year ago [8]. Our February '91 system had a vocabulary of 577 words. T h a t system constrained the N - b e s t search with the use of a word-pair g r a m m a r with a perplexity of 92. The N - b e s t outputs were subsequently resorted using our natural language component TINA. It was trained on some 2400 utterances collected at T I and MIT. The recognition performance of t h a t system on the October '91 ""dry-run"" test set, with and without the word-pair language model, is shown in the first two rows of Table 1 (labelled as AW and WP, respectively). Lexicon With the availability of a larger amount of tr"
H92-1016,H92-1060,1,\N,Missing
H92-1060,H90-1047,0,0.0265458,"anism through a breakdown of the performance of robustly parsed vs. fully parsed sentences on the October &apos;91 &quot;dry-run&quot; test set. It was clear that the robust parser allowed us to answer many more questions correctly, as over a third of the sentences were not covered by the grammar. We also report here on the performance of the system on the February &apos;92 test sentences, and discuss some issues with regard to the evaluation methodology. INTRODUCTION Current approaches to the language understanding aspect of spoken language systems tend to fall into two categories. In syntax-driven formulations [1,4,10], a complete syntactic analysis is performed which attempts to account for all words in an utterance. While providing strong linguistic constraints to the speech recognition component and a useful structure for further linguistic analysis, such an approach can break down in the presence of unknown words, novel linguistic constructs, recognition errors, and some spontaneous speech events such as false starts. In contrast, semantic-driven approaches [2,5,9] tend to derive their understanding by spotting key words and phrases in the utterance. While this approach can potentially provide better co"
H92-1060,H91-1034,0,0.0772305,"approaches to the language understanding aspect of spoken language systems tend to fall into two categories. In syntax-driven formulations [1,4,10], a complete syntactic analysis is performed which attempts to account for all words in an utterance. While providing strong linguistic constraints to the speech recognition component and a useful structure for further linguistic analysis, such an approach can break down in the presence of unknown words, novel linguistic constructs, recognition errors, and some spontaneous speech events such as false starts. In contrast, semantic-driven approaches [2,5,9] tend to derive their understanding by spotting key words and phrases in the utterance. While this approach can potentially provide better coverage and deal with ill-formed sentences, it provides less constraint for the speech recognizer, and may not be able to adequately interpret complex linguistic constructs. This paper describes our efforts to develop a language understanding component that combines the advantages of both of these approaches. Our strategy has been to 1This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Officeof Naval Research. 299 re"
H92-1060,H91-1021,0,0.0594397,"anism through a breakdown of the performance of robustly parsed vs. fully parsed sentences on the October &apos;91 &quot;dry-run&quot; test set. It was clear that the robust parser allowed us to answer many more questions correctly, as over a third of the sentences were not covered by the grammar. We also report here on the performance of the system on the February &apos;92 test sentences, and discuss some issues with regard to the evaluation methodology. INTRODUCTION Current approaches to the language understanding aspect of spoken language systems tend to fall into two categories. In syntax-driven formulations [1,4,10], a complete syntactic analysis is performed which attempts to account for all words in an utterance. While providing strong linguistic constraints to the speech recognition component and a useful structure for further linguistic analysis, such an approach can break down in the presence of unknown words, novel linguistic constructs, recognition errors, and some spontaneous speech events such as false starts. In contrast, semantic-driven approaches [2,5,9] tend to derive their understanding by spotting key words and phrases in the utterance. While this approach can potentially provide better co"
H92-1060,H91-1020,0,0.0249683,"approaches to the language understanding aspect of spoken language systems tend to fall into two categories. In syntax-driven formulations [1,4,10], a complete syntactic analysis is performed which attempts to account for all words in an utterance. While providing strong linguistic constraints to the speech recognition component and a useful structure for further linguistic analysis, such an approach can break down in the presence of unknown words, novel linguistic constructs, recognition errors, and some spontaneous speech events such as false starts. In contrast, semantic-driven approaches [2,5,9] tend to derive their understanding by spotting key words and phrases in the utterance. While this approach can potentially provide better coverage and deal with ill-formed sentences, it provides less constraint for the speech recognizer, and may not be able to adequately interpret complex linguistic constructs. This paper describes our efforts to develop a language understanding component that combines the advantages of both of these approaches. Our strategy has been to 1This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Officeof Naval Research. 299 re"
H92-1060,H90-1020,0,0.0239953,"Missing"
H92-1060,J92-1004,1,0.756134,"ces, it provides less constraint for the speech recognizer, and may not be able to adequately interpret complex linguistic constructs. This paper describes our efforts to develop a language understanding component that combines the advantages of both of these approaches. Our strategy has been to 1This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Officeof Naval Research. 299 relax the constraint that the syntactic analysis must account for all of the words in an utterance. Our current implementation is a two stage process. In the first step, our parser [7] searches for a complete linguistic analysis. Failing that, constraints of the parser are relaxed to permit the recovery of parsable phrases and clauses within the sentence. These fragments are fused together using a mechanism that closely resembles our discourse history mechanism [8]. Thus the robust parser is able to leverage off of existing components to a large degree. ROBUST PARSING MECHANISM The natural language component of the MIT ATIS system makes use of a semantic frame representation of the meaning which serves as the input for database access, spoken response generation, and histor"
H92-1060,H91-1070,1,0.793805,"has been to 1This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Officeof Naval Research. 299 relax the constraint that the syntactic analysis must account for all of the words in an utterance. Our current implementation is a two stage process. In the first step, our parser [7] searches for a complete linguistic analysis. Failing that, constraints of the parser are relaxed to permit the recovery of parsable phrases and clauses within the sentence. These fragments are fused together using a mechanism that closely resembles our discourse history mechanism [8]. Thus the robust parser is able to leverage off of existing components to a large degree. ROBUST PARSING MECHANISM The natural language component of the MIT ATIS system makes use of a semantic frame representation of the meaning which serves as the input for database access, spoken response generation, and history management. The frame design is flexible enough to be readily Jextended to other domains. Domain-dependent aspects of the system are entered mainly through table-driven mechanisms that seek certain patterns in the frame, with very little explicit programming required. Because the se"
H92-1060,H90-1027,0,0.0295837,"approaches to the language understanding aspect of spoken language systems tend to fall into two categories. In syntax-driven formulations [1,4,10], a complete syntactic analysis is performed which attempts to account for all words in an utterance. While providing strong linguistic constraints to the speech recognition component and a useful structure for further linguistic analysis, such an approach can break down in the presence of unknown words, novel linguistic constructs, recognition errors, and some spontaneous speech events such as false starts. In contrast, semantic-driven approaches [2,5,9] tend to derive their understanding by spotting key words and phrases in the utterance. While this approach can potentially provide better coverage and deal with ill-formed sentences, it provides less constraint for the speech recognizer, and may not be able to adequately interpret complex linguistic constructs. This paper describes our efforts to develop a language understanding component that combines the advantages of both of these approaches. Our strategy has been to 1This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Officeof Naval Research. 299 re"
H92-1060,H92-1005,1,0.869457,"Missing"
H92-1060,H91-1015,0,\N,Missing
H94-1037,H90-1020,0,0.079663,"Missing"
H94-1037,H93-1003,0,0.0165873,"ormation, such as flight schedules from one city to another, obtained from a small relational database excised from the Official Airline Guide. By requiring that all system developers use the same database, it has been possible to compare the performance of various spoken language systems based on their ability to extract the correct information from the database, using a set of prescribed training and test data, and a set of interpretation guidelines. Indeed, periodic common evaluations have occurred at regular intervals, and steady performance improvements have been observed for all systems [2, 3, 4]. While the ATIS task has been instrumental in the development of technologies that can understand spontaneously generated verbal queries in a limited domain, it 1This research was supported by ARPA under Contract N0001489-J-1332, monitored through the Office of Naval Research. 2The authors are listed in reversed alphabetical order. does have some shortcomings. First, the current common evaluation focuses on the correctness of the information extracted from the database without any regard to the system&apos;s side of the interchange (e.g., clarification queries and helpful suggestions). Thus it has"
H94-1037,H89-1027,1,0.856684,"Missing"
H94-1037,J92-1004,1,0.853058,"Missing"
H94-1037,H93-1009,0,0.0130462,"entations. Our view on the appropriate structural units of a semantic frame has evolved over time. Our present view is that all major constituents in a sentence can be classified as one of only three distinct categories, which we label as [clause], [topic], and [ p r e d i c a t e ] . Thus, verbs, adjectives, prepositions and modifier nouns are all considered to be predicates. Furthermore, grammatical constituents such as ""subject"" and ""direct object"" are not explicitly marked in the semantic frame. We have applied this new formalism successfully across several languages in our VOYAGER domain [10], and we are also using it in P E G A S U S . An example semantic frame for the sentence, ""Is there a United flight connecting in Denver,"" is shown in Figure 2. 202 System Manager During the design phase of our project, we made a commitment not to alter the interface and protocols of EAASY SABRE. W e see no benefit, nor do we feel competent, in making changes to a proven system used by many users. In fact, PEGASUS&apos;s interface to EAASY SABRE is identical to that of a user on a PC or a travel agent EAASY SABRE cannot distinguish between a user speaking a natural utterance (such as ""I want to go"
H94-1037,H91-1070,1,0.90177,"Like a travel agent, PEGASUS needs to know the source, destination, and date before it can provide the flight information. The user utilized additional constraints to narrow down the choices before settling on a particular flight. It took two exchanges to arrive at the appropriate fare, and three more to book the return flight. The entire booking took nine exchanges, and lasted approximately 5 minutes. Note that a large fraction of the time is spent waiting for EAASY SABRE to respond. The dialogue component of PEGASUS is significantly more complicated than t h a t of the original ATIS system [11]. This is in large part due to the fact that it must monitor not only the user&apos;s dialogue state and the degree of completion of the booking, but also the state of the EAASY SABRE system. For instance, it must preprocess fare restrictions, warning the user of limits imposed on return dates for restricted fares, screening selected fares for possible constraint failure, and confirming availability on selected flights before attempting to issue bookings. Otherwise, the EAASY SABRE system would invoke a complex subdialogue which we wish to avoid. The system keeps a record of the most recently displ"
H94-1037,H92-1016,1,\N,Missing
H94-1037,H94-1011,0,\N,Missing
H94-1037,H91-1014,1,\N,Missing
H94-1037,H92-1004,0,\N,Missing
H94-1055,H94-1055,1,0.0512143,"Missing"
H94-1055,H89-2036,0,0.225546,"Missing"
H94-1055,J92-1004,1,0.822931,"er word. Another noteworthy detail is the special [M-ONSET] category, which signifies that the letter &apos;c&apos; should belong to the root &quot;-dic-&quot;,2 but has. become a moved onset of the next syllable due to syllabification principles such as the Maximal Onset Principle and the Stress Resyllabification Principle. a THE PARSING ALGORITHM We are adopting a technique that represents a cross between explicit rule-driven strategies and strictly datadriven approaches. About 100 generalized context-free rules, such as those illustrated in Table 1 are written by hand, and training words are parsed using TINA [9], according to their marked linguistic specifications. The parse trees of format as show in Figure 1 are then used 2According to Webster&apos;s N e w World Dictionary, the root of &quot;dedicated&quot; is &quot;-dic-&quot;, which is derived from the Latin word &quot;dicare&apos;. 3The Maximal Onset Principle states that the number of consonants in the onset position should be maximized when phonotactic and morphological constraints permit, and Stress Resyllabification refers to maximizing the number of consonants in stressed syllables. We created a framework which describes the spelling and pronunciation of English words using"
J92-1004,H89-1012,0,0.0152636,"interface using speech require an ""understanding"" of the intended message. In fact, to be truly effective, m a n y potential applications d e m a n d that the system carry on a dialog with the user, using its knowledge base and information gleaned from previous sentences to achieve proper response generation. Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project. Representative systems are described in Boisen et al. (1989), De Mattia and Giachin (1989), Niedermair (1989), Niemann (1990), and Young (1989). Spoken Language Systems Group, Laboratory for Computer Science,MIT, Cambridge MA 02139 ~This research was supported by DARPAunder Contract N00014-89-J-1332, monitored through the Office of Naval Research. 1 Speech understanding research flourished in the U.S. in the 1970s under DARPAsponsorship. While ""understanding"" was one of the original goals, none of the systems really placed any emphasis on this aspect of the problem. 2 We will use the term ""speech understanding systems"" and ""spoken language systems"" int"
J92-1004,J86-3002,0,0.0166758,"mode, i.e., if the semantic restrictions fail, the node dies. This strategy seems to be adequate for the limited domains that we have worked with thus far, but they will probably be inadequate for more complex domains. In principle, one could parse a large set of sentences with semantics turned off, collecting the semantic conditions that occurred at each node of interest. Then the system could propose to a human expert a set of filters for each node, based on its observations, and the human could make the final decision on whether to accept the proposals. This approach resembles the work by Grishman et al. (1986) and Hirschman et al. (1975) on selectional restrictions. The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences. There is obviously a great deal more work to be done in this important area. 3. E v a l u a t i o n M e a s u r e s This section addresses some performance measures for a grammar, including coverage, portability, perplexity, and trainability. Perplexity, roughly defined as the geometric mean of the number of alternative word hypotheses that may follow each word in the sentence, is of particular con"
J92-1004,H89-1017,0,0.015184,"truly effective, m a n y potential applications d e m a n d that the system carry on a dialog with the user, using its knowledge base and information gleaned from previous sentences to achieve proper response generation. Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project. Representative systems are described in Boisen et al. (1989), De Mattia and Giachin (1989), Niedermair (1989), Niemann (1990), and Young (1989). Spoken Language Systems Group, Laboratory for Computer Science,MIT, Cambridge MA 02139 ~This research was supported by DARPAunder Contract N00014-89-J-1332, monitored through the Office of Naval Research. 1 Speech understanding research flourished in the U.S. in the 1970s under DARPAsponsorship. While ""understanding"" was one of the original goals, none of the systems really placed any emphasis on this aspect of the problem. 2 We will use the term ""speech understanding systems"" and ""spoken language systems"" interchangeably. (~) 1992 Associationfor Computational Linguistics Computational Lingu"
J92-1004,H89-1027,1,\N,Missing
J92-1004,H89-2018,1,\N,Missing
J92-1004,H91-1014,1,\N,Missing
mcgraw-etal-2010-collecting,hastie-etal-2002-automatic,0,\N,Missing
mcgraw-etal-2010-collecting,D08-1027,0,\N,Missing
mcgraw-etal-2010-collecting,H93-1004,0,\N,Missing
mcgraw-etal-2010-collecting,N10-1024,0,\N,Missing
mcgraw-etal-2010-collecting,2007.sigdial-1.21,1,\N,Missing
mcgraw-etal-2010-collecting,2007.sigdial-1.23,0,\N,Missing
mcgraw-etal-2010-collecting,kaisser-lowe-2008-creating,0,\N,Missing
N03-1005,J96-3003,0,\N,Missing
N03-1005,J00-2003,0,\N,Missing
N07-1059,2001.mtsummit-papers.68,0,0.026296,"erated using formal generation rules. man tutor. A central focus of this paper is to address the challenging problem of automatically assessing the appropriateness of a student’s translation. At first glance, our task appears to share much in common with machine translation (MT) evaluation (Hovy et al., 2002). Indeed, both are trying to assess the quality of the translation output, whether it is produced by a computer or by a foreign language student. Nevertheless, there also exist several fundamental distinctions. Automatic MT evaluation methods, as represented by the well-known Bleu metric (Papineni et al., 2001), assume the availability of human reference translations. The algorithms typically compare MT outputs with reference translations with the goal of producing a quality indicator (on a numeric scale) that correlates with human judgement. In contrast, our algorithm operates in the absence of human generated reference translations1 . Furthermore, our application requires the evaluation algorithm to make accept/reject decisions on each individual translation, in the same way as a language tutor determines whether a translation is acceptable or not. While our task is more demanding, it is made poss"
N07-1059,2006.amta-papers.24,1,0.838127,"eps track of how many turns a user takes to complete all the sentences in a game session, and rewards good performance by advancing the student towards higher difficulty levels. A convenient “help” button allows the student to request a translation of the current game sentence, to help them overcome gaps in their knowledge of the linguistic constructs or the vocabulary. The student can also type any English sentences within the domain to obtain a reference translation. The system utilizes an interlingua-based bidirectional translation capability, described in detail in (Wang and Seneff, 2006; Seneff et al., 2006). Both Chinese and English sentences are parsed into a common meaning representation, which we loosely refer to as an “interlingua,” from which paraphrases in both languages can be automatically generated using formal generation rules. man tutor. A central focus of this paper is to address the challenging problem of automatically assessing the appropriateness of a student’s translation. At first glance, our task appears to share much in common with machine translation (MT) evaluation (Hovy et al., 2002). Indeed, both are trying to assess the quality of the translation output, whether it is pro"
N07-1059,J92-1004,1,0.660354,"th the speech recognition system. 2.1 Parsing Our framework depends strongly on an ability to parse both the English and Chinese sentences into a common interlingual meaning representation. Parsing is critical both for producing the two paraphrases of the student’s utterance and for judging the quality of their provided translation. Both English and Chinese grammars are needed to analyze the source and target sides of each translation pair. The grammars have been carefully constructed so that meaning representations derived from both languages are as similar as feasible. We utilized a parser (Seneff, 1992) that is based on an enhanced probabilistic context-free grammar (PCFG), which captures dependencies beyond context-free rules by conditioning on the external left-context parse categories when predicting the first child of each parent node. While we use a specific grammar for analyzing flight domain sentences, we emphasize domain portability of the grammar by using mainly syntactic information in the majority of the parse tree rules. Semantics are introduced near the terminals, mostly involving adjectives, verbs, nouns and proper noun classes. Rules for general semantic concepts such as dates"
N07-1059,P02-1040,0,\N,Missing
N07-2039,J00-2003,0,0.0605816,"Missing"
N07-2039,J96-3003,0,0.0807534,"Missing"
N07-2039,N03-1005,1,\N,Missing
N07-4007,N07-1059,1,\N,Missing
N07-4007,J92-1004,1,\N,Missing
N10-1008,P08-1031,0,0.014401,"lective opinions. If there exists a systematic framework that harvests these reviews from general users, extracts the essence from the reviews and presents it appropriately in human-computer conversations, then we can enable dialogue systems to behave like a human shopping assistant, a travel agent, or a local friend who tells you where to find the best restaurant. Summarization from online reviews, therefore, plays an important role for such dialogue systems. There have been previous studies on review analysis for text-based summarization systems (Mei et al., 2007; Titov and McDonald, 2008a; Branavan et al., 2008). Mixture models and topic models are used to predict the underlying topics of each document and generate a phrase-level summary. An aspect rating on each facet is also automatically 64 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 64–72, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics learned with statistical models (Snyder and Barzilay, 2007; Titov and McDonald, 2008b; Baccianella et al., 2009). These approaches are all very effective, and the review databases generated are well presented. So the f"
N10-1008,E06-1039,0,0.0343993,"Missing"
N10-1008,2007.sigdial-1.21,1,0.611042,"Missing"
N10-1008,N06-1026,0,0.0191801,"ical if-else decision problem’ in human cognition, where decision tree algorithms can fit well. Figure 6 shows a partial simplified decision tree learned from our model, which can give an intuitive idea of the decision tree models. 6 Related Work Sentiment classification and opinion mining have been well studied for years. Most studies have focused on text-based systems, such as documentlevel sentiment classification and sentence-level opinion aggregation (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005; Wilson et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). There was a study conducted by Carenini et al. in 2006, which proposed a combination of a sentence extraction-based approach and a language generation-based approach for summarizing evaluative arguments. In our work, we utilize a lowerlevel phrase-based extraction approach, which utilizes high level linguistic features and syntactic structure to capture phrase patterns. There was also a study on using reviews to generate a dictionary of mappings between semantic representations and realizations of concepts for dialogue systems (Higashinaka et al., 2006; Higashinaka, 2007). They also used the"
N10-1008,D09-1017,1,0.853737,"re produced by our system and the actual dialogue was an illustration of system capacities). Therefore, the task of developing recommendation dialogue systems is decomposed into three problems: 1) how to extract context-related phrases, both coarse-grained and fine-grained, from online reviews; 2) how to select a representative set from the extracted phrases to create an informative yet concise dialogue-oriented summary database; 3) how to generate human-friendly dialogue responses from the review summary database. To tackle these problems, we propose a threelevel framework. In previous work (Liu and Seneff, 2009), we explored the first level by proposing a linguistic parse-and-paraphrase paradigm for review phrase extraction. In this paper, we address the second problem: dialogue-oriented review summary generation. We propose an automatic approach to classifying high/low informative phrases using statistical models. Experiments conducted on a restaurant-domain dataset indicate that the proposed approach can predict phrase labels consistently with human judgment and can generate high-quality review summaries for dialogue purposes. The rest of the paper is organized as follows: Section 2 gives an overvi"
N10-1008,W02-1011,0,0.0179263,"and continuous value features. Also, as the phrase classification task is very subjective, it is very similar to a ‘hierarchical if-else decision problem’ in human cognition, where decision tree algorithms can fit well. Figure 6 shows a partial simplified decision tree learned from our model, which can give an intuitive idea of the decision tree models. 6 Related Work Sentiment classification and opinion mining have been well studied for years. Most studies have focused on text-based systems, such as documentlevel sentiment classification and sentence-level opinion aggregation (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005; Wilson et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). There was a study conducted by Carenini et al. in 2006, which proposed a combination of a sentence extraction-based approach and a language generation-based approach for summarizing evaluative arguments. In our work, we utilize a lowerlevel phrase-based extraction approach, which utilizes high level linguistic features and syntactic structure to capture phrase patterns. There was also a study on using reviews to generate a dictionary of mappings between semantic repr"
N10-1008,H05-1043,0,0.0652751,"sification task is very subjective, it is very similar to a ‘hierarchical if-else decision problem’ in human cognition, where decision tree algorithms can fit well. Figure 6 shows a partial simplified decision tree learned from our model, which can give an intuitive idea of the decision tree models. 6 Related Work Sentiment classification and opinion mining have been well studied for years. Most studies have focused on text-based systems, such as documentlevel sentiment classification and sentence-level opinion aggregation (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005; Wilson et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). There was a study conducted by Carenini et al. in 2006, which proposed a combination of a sentence extraction-based approach and a language generation-based approach for summarizing evaluative arguments. In our work, we utilize a lowerlevel phrase-based extraction approach, which utilizes high level linguistic features and syntactic structure to capture phrase patterns. There was also a study on using reviews to generate a dictionary of mappings between semantic representations and realizations of concepts for dialogue systems (H"
N10-1008,N07-1038,0,0.0151855,"for such dialogue systems. There have been previous studies on review analysis for text-based summarization systems (Mei et al., 2007; Titov and McDonald, 2008a; Branavan et al., 2008). Mixture models and topic models are used to predict the underlying topics of each document and generate a phrase-level summary. An aspect rating on each facet is also automatically 64 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 64–72, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics learned with statistical models (Snyder and Barzilay, 2007; Titov and McDonald, 2008b; Baccianella et al., 2009). These approaches are all very effective, and the review databases generated are well presented. So the first thought for developing a recommendation dialogue system is to use such a categorized summary in a table-lookup fashion. For example, a dialogue system for restaurant recommendations can look up a summary table as exemplified in Table 1, and generate a response utterance from each row: “Restaurant A has good service and bad food; restaurant B has good service and good food; restaurant C has great service and nice atmosphere; restaur"
N10-1008,P08-1036,0,0.0963816,"ive recommendations and collective opinions. If there exists a systematic framework that harvests these reviews from general users, extracts the essence from the reviews and presents it appropriately in human-computer conversations, then we can enable dialogue systems to behave like a human shopping assistant, a travel agent, or a local friend who tells you where to find the best restaurant. Summarization from online reviews, therefore, plays an important role for such dialogue systems. There have been previous studies on review analysis for text-based summarization systems (Mei et al., 2007; Titov and McDonald, 2008a; Branavan et al., 2008). Mixture models and topic models are used to predict the underlying topics of each document and generate a phrase-level summary. An aspect rating on each facet is also automatically 64 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 64–72, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics learned with statistical models (Snyder and Barzilay, 2007; Titov and McDonald, 2008b; Baccianella et al., 2009). These approaches are all very effective, and the review databases generated are"
N10-1008,P02-1053,0,0.0100635,"ated ontology) and continuous value features. Also, as the phrase classification task is very subjective, it is very similar to a ‘hierarchical if-else decision problem’ in human cognition, where decision tree algorithms can fit well. Figure 6 shows a partial simplified decision tree learned from our model, which can give an intuitive idea of the decision tree models. 6 Related Work Sentiment classification and opinion mining have been well studied for years. Most studies have focused on text-based systems, such as documentlevel sentiment classification and sentence-level opinion aggregation (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005; Wilson et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). There was a study conducted by Carenini et al. in 2006, which proposed a combination of a sentence extraction-based approach and a language generation-based approach for summarizing evaluative arguments. In our work, we utilize a lowerlevel phrase-based extraction approach, which utilizes high level linguistic features and syntactic structure to capture phrase patterns. There was also a study on using reviews to generate a dictionary of mappings be"
N10-1008,H05-1044,0,0.00725448,"jective, it is very similar to a ‘hierarchical if-else decision problem’ in human cognition, where decision tree algorithms can fit well. Figure 6 shows a partial simplified decision tree learned from our model, which can give an intuitive idea of the decision tree models. 6 Related Work Sentiment classification and opinion mining have been well studied for years. Most studies have focused on text-based systems, such as documentlevel sentiment classification and sentence-level opinion aggregation (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005; Wilson et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006). There was a study conducted by Carenini et al. in 2006, which proposed a combination of a sentence extraction-based approach and a language generation-based approach for summarizing evaluative arguments. In our work, we utilize a lowerlevel phrase-based extraction approach, which utilizes high level linguistic features and syntactic structure to capture phrase patterns. There was also a study on using reviews to generate a dictionary of mappings between semantic representations and realizations of concepts for dialogue systems (Higashinaka et al., 20"
N10-1008,H05-2017,0,\N,Missing
N10-1008,P06-1034,0,\N,Missing
O09-4001,H05-1103,0,0.0125542,"Missing"
O09-4001,J92-1004,1,0.119188,"Missing"
O09-4001,2008.amta-papers.21,1,0.859885,"Missing"
O09-4001,J90-1003,0,\N,Missing
O09-4001,N04-1024,0,\N,Missing
O09-4001,C04-1020,0,\N,Missing
P08-1021,W07-1604,0,0.189277,"ed to verbs are among the most frequent categories. Table 2 shows some sentences with these errors. A system that automatically detects and corrects misused verb forms would be both an educational and practical tool for students of English. It may also potentially improve the performance of machine translation and natural language generation systems, especially when the source and target languages employ very different verb systems. Research on automatic grammar correction has been conducted on a number of different parts-ofspeech, such as articles (Knight and Chander, 1994) and prepositions (Chodorow et al., 2007). Errors in verb forms have been covered as part of larger systems such as (Heidorn, 2000), but we believe that their specific research challenges warrant more detailed examination. We build on the basic approach of templatematching on parse trees in two ways. To improve recall, irregularities in parse trees caused by verb form errors are considered; to improve precision, n-gram counts are utilized to filter proposed corrections. We start with a discussion on the scope of our 174 Proceedings of ACL-08: HLT, pages 174–182, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Lin"
P08-1021,P97-1003,0,0.0433905,"ities are introduced by the other primary verbs2 . The verb “have” can function as an auxiliary in the perfect aspect (EDperf ) as well as a main verb. The versatile “do” can serve as “do”support or add emphasis (BASEdo ), or simply act as a main verb. 3.2 Automatic Parsing The ambiguities discussed above may be expected to cause degradation in automatic parsing performance. In other words, sentences containing verb form errors are more likely to yield an “incorrect” parse tree, sometimes with significant differences. For example, the sentence “My father is *work in the laboratory” is parsed (Collins, 1997) as: This is work not play. (main verb) (S (NP My father) (VP is (NP work)) (PP in the laboratory)) My father is working in the lab. (INGprog ) A solution is worked out. (EDpass ) These different roles clearly affect the forms required for the verbs (if any) that follow. Dis176 2 The abbreviations ’s (is or has) and ’d (would or had) compound the ambiguities. The progressive form “working” is substituted with its bare form, which happens to be also a noun. The parser, not unreasonably, identifies “work” as a noun. Correcting the verb form error in this sentence, then, necessitates considering"
P08-1021,A97-1004,0,0.03598,"Implications on our evaluation procedure are discussed in §5.4. 5.3 Evaluation Metric For each verb in the input sentence, a change in verb form may be hypothesized. There are five possible outcomes for this hypothesis, as enumerated in Table 4. To penalize “false alarms”, a strict definition is used for false positives — even when the hypothesized correction yields a good sentence, it is still considered a false positive so long as the original sentence is acceptable. It can sometimes be difficult to determine which words should be considered verbs, as they are not 4 Obtained by segmenting (Reynar and Ratnaparkhi, 1997) the interviewee turns, and discarding sentences with only one word. The HKUST corpus was processed likewise. 5 Specifically, those tagged with the “v fml”, “v fin” (covering auxiliary agreement and complementation) and “v agr” (subject-verb agreement) types; those with semantic errors (see §2.1), i.e. “v tns” (tense), are excluded. 6 Provided by Prof. John Milton, personal communication. 178 clearly demarcated in our evaluation corpora. We will thus apply the outcomes in Table 4 at the sentence level; that is, the output sentence is considered a true positive only if the original sentence con"
P08-1021,P03-2026,0,\N,Missing
P97-1016,J92-1004,1,0.815183,"nstances of phrases with omission, cf. (Grishman, 1989), as in (1). This introduces a greater degree of syntactic ambiguities than for texts without any omitted element, thereby posing a new challenge to parsing. (1) TU-95 destroyed 220 nm. (~ An aircraft TU-95 was destroyed at 220 nautical miles) Syntactic ambiguity and the resultant misparse induced by such an omission often leads to a mistranslation in a machine translation system, such as the one described in (Weinstein et ai., 1996), which is depicted in Figure 1. The system depicted in Figure 1 has a language understanding module TINA, (Seneff, 1992), and a language generation module LANGUAGE GENERATION GENESIS Figure 1: An Interlingua-Based E n g li s h - t o - K o r e a n Machine Translation S y s t e m GENESIS, (Glass, Polifroni and SeneR', 1994), at the core. The semantic frame is an intermediate meaning representation which is directly derived from the parse tree andbecomes .the input to the generation system. The hierarchical structure of the parse tree is preserved in the semantic frame, and therefore a misparse of the input sentence leads to a mistranslation. Suppose that the sentence (1) is misparsed as an active rather than a pa"
P97-1016,C96-2119,1,0.886576,"Missing"
P97-1016,J95-4004,0,\N,Missing
P97-1016,H89-1034,0,\N,Missing
polifroni-seneff-2000-galaxy,J92-1004,1,\N,Missing
W00-0303,J92-1004,1,0.812502,"elect the flights of their trip. When the flight plan is completed, the system takes the initiative to offer to price and email the itinerary. Finally, the system asks the user a few questions to help determine user satisfaction. The overall system makes use of the GALAXYarchitecture [Seneffet al (1999)], which consists of a number of specialized servers that communicate with one another via a central programmable hub. An audio server captures the user&apos;s speech via a Dialogic board, and transmits the waveform to the speech recognizer [Glass et al (1996)]. The language understanding component [Seneff (1992)] parses a word graph produced by the recognizer and delivers a semantic frame, encoding the meaning of the utterance, to the discourse component. The output of the discourse component [Seneff (1996)] is the framein-context, which is transformed into a flattened Eform (electronic form) by the generation server. This E-form is delivered to the turn manager, and provides the initial settings of the dialogue state. The turn manager consults the dialogue control table to decide which operations to perform, and typically engages in a module-to-module subdialogue to retrieve tables from the database"
W03-0707,N03-1005,1,0.564415,"come a reality, a number of specific technology goals must be met. First and foremost, it is essential to develop tools that will enable rapid configuration of dialogue systems in new domains of knowledge, guided mainly from domain-dependent information sources. Our efforts in generic dialogue development represent a strong initiative toward that goal (Polifroni and Chung, 2002). Secondly, we need to be able to support incremental update of vocabularies and language models for speech recognition and understanding, in essentially instantaneous time (Schalkwyk et al., 2003; Seneff et al., 1998; Chung et al., 2003). This would allow great flexibility within a single dialogue where the user might ask about a named entity that is not yet known to the system. Third, while we can make use of a large lexical resource for pronunciation modeling, we must have available as well a high-performance letter-to-sound capability, integrating multiple knowledge sources such as a Web page, a spoken name, a spoken spelling of the name, and/or a key-padded name (Chung and Seneff, 2002). Fourth, we need to have intelligent knowledge acquisition systems, capable of populating a database from Web sources, and extracting and"
W03-0707,W00-0303,1,0.845498,"t some of these, with pointers to the literature for an in-depth description. SpeechBuilder: Over the past few years, we have been developing a set of utilities that would enable research results to be migrated directly into application development (Glass and Weinstein, 2001). Our goal is to enable natural, mixed-initiative interfaces similar to those now created manually by a relatively small group of expert developers. We make no distinction between the technology components of SpeechBuilder and those of our most sophisticated dialogue systems, such as the Mercury flight reservation domain (Seneff and Polifroni, 2000). SpeechBuilder employs a Web-based interface where developers type in the specifics of their domain, guided by forms and pull-down menus. Components such as recognition vocabulary, parse rules, and semantic mappings are created automatically from example sentences entered by the developer. In several recent short courses, naive developers have been able to implement a new domain and converse with it on the telephone in a matter of hours. Language Modelling: Patchwork Grammars A serious limitation in today’s technology to immediate deployment of a new system is the chicken-and-egg problem of t"
W04-3006,W03-0707,1,0.745127,"keypad entry with that of a “speak-and-spell” entry. A novelty of our work is the introduction of a speech synthesizer to simulate the user, which facilitates development and evaluation of our proposed strategy. We have found that the speak-and-spell strategy is quite effective in simulation mode, but it remains to be tested in real user dialogues. 1 Introduction Spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources (Eckert et al., 1997; Gorin et al., 1997; Dahlback et al., 1999; Zue et al., 2000; Walker et al., 2001; Glass and Seneff, 2003; Pieraccini et al., 1997; Quast et al., 2003; J. Gustafson, 1999; Polifroni and Chung, 2002; Denecke, 2002; Seneff, 2002; Zue and Glass, 2000). While the effectiveness of such systems ∗ This research was supported by an industrial consortium supporting the MIT Oxygen Alliance. has improved significantly over the past several years, a critical barrier to widespread deployment remains in the form of communication breakdown at strategic points in the dialogue, often when the user is trying to convey a critical piece of information that the system repeatedly misunderstands. This paper focuses on"
W04-3006,W00-0303,1,0.447864,"t perceives there to be a communication breakdown. The second aspect of the problem, error recovery, is also challenging. The system may persist in misunderstanding repeated spoken renditions of the same named entity, unless a substantially different tactic can be adopted to assure higher communicative success. The remainder of the paper is organized as follows. Section 2 motivates why we think this is an interesting and important problem. In Sections 3 and 4, we describe the error detection and recovery strategies that have been adopted in our MERCURY flight reservation system (Seneff, 2002; Seneff and Polifroni, 2000), and we provide an analysis of the degree to which error recovery was successful, specifically for the case of entering a source or destination city name. The approach used was to solicit a keypad entry of the city in cases where the system detected a communication breakdown. We have analyzed a set of 172 cases where keypad entry of a city was solicited. One of the observations was that users were often not very receptive to the idea of switching into keypad mode to map the spelling of the city to a numeric code. Whether this is the result of cognitive overload, confusion, or some other reaso"
W04-3006,N03-1005,1,0.924996,"however, since we were unable to interview users to identify why they chose not to use the keypad. Motivated by the apparent need for a more intuitive error recovery strategy, we describe in Sections 5 and 6 a set of experiments that explore an alternative approach whereby the user is instead asked to speak and spell the problematic city name. We have recently developed the capability to utilize a pronounced version of a word to greatly enhance the accuracy of a letter recognition task, and have successfully integrated this technology into a personal name enrollment task (Seneff et al., 2003; Chung et al., 2003). Our interest here was in evaluating whether a similar technique would be useful for the error recovery problem. It is difficult, however, to develop and perfect an algorithm involving multiple recognition passes, that is only triggered sporadically in user conversations. Hence, we discuss a novel approach to system development based on simulating the completion of user dialogues beginning at the point where the system had detected a communication breakdown. In other words, we utilize a speech synthesizer to produce a speak-and-spell waveform that is solicited in lieu of the keypad entry in t"
W04-3006,C02-1147,0,0.149482,"zer to simulate the user, which facilitates development and evaluation of our proposed strategy. We have found that the speak-and-spell strategy is quite effective in simulation mode, but it remains to be tested in real user dialogues. 1 Introduction Spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources (Eckert et al., 1997; Gorin et al., 1997; Dahlback et al., 1999; Zue et al., 2000; Walker et al., 2001; Glass and Seneff, 2003; Pieraccini et al., 1997; Quast et al., 2003; J. Gustafson, 1999; Polifroni and Chung, 2002; Denecke, 2002; Seneff, 2002; Zue and Glass, 2000). While the effectiveness of such systems ∗ This research was supported by an industrial consortium supporting the MIT Oxygen Alliance. has improved significantly over the past several years, a critical barrier to widespread deployment remains in the form of communication breakdown at strategic points in the dialogue, often when the user is trying to convey a critical piece of information that the system repeatedly misunderstands. This paper focuses on the specific two-stage problem of error detection and subsequent recovery, in a situation where the user is"
W08-0801,P07-1048,0,0.0579195,"Missing"
W08-0801,J92-1004,1,0.674037,"Missing"
W08-0801,N07-2039,1,0.923845,"t-free grammar to generate a supplemental corpus of synthetic utterances. The corpus is used to train probabilities for the natural language parsing grammar (described immediately below), which in turn is used to derive a class ngram language model (Seneff et al., 2003). Classes in the language model which correspond to contents of the database are marked as dynamic, and are populated at runtime from the database (Chung et al., 2004; Hetherington, 2005). Database entries are heuristically normalized into spoken forms. Pronunciations not in our 150,000 word lexicon are automatically generated (Seneff, 2007). Parser Grammar The TINA parser uses a probabilistic context-free grammar enhanced with support for wh-movement and grammatical agreement constraints. We have developed a generic syntactic grammar by examining hundreds of thousands of utterances collected from real user interactions with various existing dialogue systems. In addition, we have developed libraries which parse and interpret common semantic classes like dates, times, and numbers. The grammar and semantic libraries provide good coverage for spoken dialogue systems in database-query domains. To build a grammar for a new domain, a d"
W10-4316,2007.sigdial-1.21,1,0.843552,"ities, we can define pattern selection algorithms (e.g., always select the pattern with the highest probability for each topic; or rotates among different patterns from high to low probabilities), and generate response utterances based on the selected patterns. The only domain-dependent part of this approach is the selection of the seeds. The other steps all depend on generic linguistic structures and are domainindependent. Thus, this probabilistic method can be easily applied to generic domains for customizing language generation. 4 A web-based multimodal spoken dialogue system, CityBrowser (Gruenstein and Seneff, 2007), developed in our group, can provide users with information about various landmarks such as the address of a museum, or the opening hours of a restaurant. To evaluate our proposed approaches, we enhanced the system with a review-summary database generated from a review corpus that we harvested from a review publishing web site (www.citysearch.com), which contains 137,569 reviews on 24,043 restaurants. We utilize the platform of Amazon Mechanical Turk (AMT) to conduct a series of user studies. To understand what types of queries the system might potentially be handling, we first conducted an A"
W10-4316,P02-1048,0,0.0327946,"the restaurant domain is shown in Figure 2. Here, we use these ―summary lists‖ (e.g., ―:food‖, ―:atmosphere‖) as well as aspect ratings (e.g., ―:food_rating‖) to address two types of recommendation inquires: ―featurespecific‖ (e.g., asking for a restaurant that serves good martinis or authentic seafood spaghetti), and ―quality-based‖ (e.g., looking for restaurants with good food quality or nice ambiance). Spoken dialogue systems are presently available for many purposes, such as flight reservations (Seneff and Polifroni, 2000), telephone calls routing (Gorin et al., 1997), and subway lookup (Johnston et al., 2002). Recently, we have been exploring a next generation of intelligent dialogue systems, which can behave like a human agent and provide proactive assistance and selective recommendations (e.g., highly-rated restaurants or hotels) to users. To enhance dialogue systems with intelligent services, we have to let the system ―grow‖ reliable knowledge and intelligence. Luckily, there has recently been an explosive growth in the availability of public review sites (e.g., yelp.com, tripadvisor.com, etc.) which make a perfect resource for gathering collective opinions. In this paper, we will explore how t"
W10-4316,D09-1017,1,0.91846,"t both quality-based opinion inquiry and feature-specific entity search. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations. Figure 1. A real conversation with our recommendation dialogue system in the restaurant domain (‗U‘ is the user and ‗S‘ is the system). 2 1 Introduction Dialogue Management In our previous work (Liu and Seneff, 2009; Liu et al., 2010) we proposed an approach to extracting representative phrases and creating aspect ratings from public reviews. An example of an enhanced database entry in the restaurant domain is shown in Figure 2. Here, we use these ―summary lists‖ (e.g., ―:food‖, ―:atmosphere‖) as well as aspect ratings (e.g., ―:food_rating‖) to address two types of recommendation inquires: ―featurespecific‖ (e.g., asking for a restaurant that serves good martinis or authentic seafood spaghetti), and ―quality-based‖ (e.g., looking for restaurants with good food quality or nice ambiance). Spoken dialogue s"
W10-4316,N10-1008,1,0.796519,"pinion inquiry and feature-specific entity search. We propose a probabilistic language generation approach to automatically creating recommendations in spoken natural language from the text-based opinion summaries. A user study in the restaurant domain shows that the proposed approaches can effectively generate reliable and helpful recommendations in human-computer conversations. Figure 1. A real conversation with our recommendation dialogue system in the restaurant domain (‗U‘ is the user and ‗S‘ is the system). 2 1 Introduction Dialogue Management In our previous work (Liu and Seneff, 2009; Liu et al., 2010) we proposed an approach to extracting representative phrases and creating aspect ratings from public reviews. An example of an enhanced database entry in the restaurant domain is shown in Figure 2. Here, we use these ―summary lists‖ (e.g., ―:food‖, ―:atmosphere‖) as well as aspect ratings (e.g., ―:food_rating‖) to address two types of recommendation inquires: ―featurespecific‖ (e.g., asking for a restaurant that serves good martinis or authentic seafood spaghetti), and ―quality-based‖ (e.g., looking for restaurants with good food quality or nice ambiance). Spoken dialogue systems are presentl"
W10-4316,mcgraw-etal-2010-collecting,1,0.821235,"urk (AMT) to conduct a series of user studies. To understand what types of queries the system might potentially be handling, we first conducted an AMT task by collecting restaurant inquiries from general users. Through this AMT task, 250 sentences were collected and a set of generic templates encoding the language patterns of these sentences was carefully extracted. Then 10,000 sentences were automatically created from these templates for language model training for the speech recognizer. To evaluate the quality of recommendations, we presented the system to real users via customized AMT API (McGraw et al., 2010) and gave each subject a set of assignments to fulfill. Each assignment is a scenario of finding a particular restaurant, as shown in Figure 6. The user can talk to the system via a microphone and ask for restaurant recommendations. We also gave each user a questionnaire for a subjective evaluation and asked them to rate the system on different aspects. Through this AMT task we collected 58 sessions containing 270 utterances (4.6 utterances per session on average) and 34 surveys. The length of the utterances varies significantly, from ―Thank you‖ to ―Restaurants along Brattle Street in Cambrid"
W10-4316,W00-0306,0,0.0861088,"Missing"
W10-4316,H01-1055,0,0.0283333,"ntries into natural language utterances. Most spoken dialogue systems use predefined templates to generate responses. However, manually defining templates for each specific linguistic pattern is tedious and non-scalable. For example, given a restaurant with ―nice jazz music, best breakfast spot, great vibes‖, three templates have to be edited for three different topics (e.g., ―<restaurant> plays <adjective> music‖; ―<restaurant> is <adjective> breakfast spot‖; ―<restaurant> has <adjective> vibes‖). To avoid the human effort involved in the task, corpus-based approaches (Oh and Rudnicky, 2000; Rambow et al., 2001) have been developed for more efficient language generation. In this paper, we propose a corpus-based probabilistic approach which can automatically learn the linguistic patterns (e.g., predicate-topic relationships) from a corpus and generate natural sentences by probabilistically selecting the best-matching pattern for each topic. The proposed approach consists of three stages: 1) plant seed topics in the context-free grammar; 2) identify semantic structures associated with the seeds; 3) extract association pairs of linguistic patterns and the seeds, and calculate the probability of each ass"
W10-4316,W00-0303,1,0.675421,"s and creating aspect ratings from public reviews. An example of an enhanced database entry in the restaurant domain is shown in Figure 2. Here, we use these ―summary lists‖ (e.g., ―:food‖, ―:atmosphere‖) as well as aspect ratings (e.g., ―:food_rating‖) to address two types of recommendation inquires: ―featurespecific‖ (e.g., asking for a restaurant that serves good martinis or authentic seafood spaghetti), and ―quality-based‖ (e.g., looking for restaurants with good food quality or nice ambiance). Spoken dialogue systems are presently available for many purposes, such as flight reservations (Seneff and Polifroni, 2000), telephone calls routing (Gorin et al., 1997), and subway lookup (Johnston et al., 2002). Recently, we have been exploring a next generation of intelligent dialogue systems, which can behave like a human agent and provide proactive assistance and selective recommendations (e.g., highly-rated restaurants or hotels) to users. To enhance dialogue systems with intelligent services, we have to let the system ―grow‖ reliable knowledge and intelligence. Luckily, there has recently been an explosive growth in the availability of public review sites (e.g., yelp.com, tripadvisor.com, etc.) which make a"
W10-4317,P06-1024,0,0.0289191,"to complete the specified goal. The user is viewed as another knowledge source. The dialogue manager finds the next action by a mixture of rule-based reasoning and a simple statistical model. Implementation in the flight-reservation domain demonstrates that the framework enables the developer to easily build a conversational dialogue system. 1 2 Related Work In recent years, statistical methods have gained popularity in dialogue system research. Partially Observable Markov decision processes have been the focus of a number of papers (Levin, Pieraccini, & Eckert, 1997; Scheffler & Young, 2001; Frampton & Lemon, 2006; Williams & Young, 2007). These approaches turn the dialogue interaction strategy into an optimization problem. The dialogue manager selects actions prescribed by the policy that maximizes the reward function (Lemon & Pietquin, 2007). This machine learning formulation of the problem automates system development, thus freeing the developers from hand-coded rules. Other researchers have continued research on rule-based frameworks, in part because they are easier to control and maintain. One common approach is to allow developers to specify the tasks, either using a conditioned sequential script"
W10-4317,W02-0209,0,0.0340413,"nteraction strategy into an optimization problem. The dialogue manager selects actions prescribed by the policy that maximizes the reward function (Lemon & Pietquin, 2007). This machine learning formulation of the problem automates system development, thus freeing the developers from hand-coded rules. Other researchers have continued research on rule-based frameworks, in part because they are easier to control and maintain. One common approach is to allow developers to specify the tasks, either using a conditioned sequential script (Zue, et al., 2000; Seneff, 2002), or using a task hierarchy (Hochberg, Kambhatla, & Roukos, 2002). In (Bohus & Rudnicky, 2003)’s work, a tree of dialogue agents, each of which handles different dialogue actions, is specified to control the dialogue progress. The knowledge has also been specified either by first order logic (Bühler & Minker, 2005) or ontology information (Milward & Beveridge, 2004). Introduction Conversational systems can be classified into two distinct classes: goal-directed and casual chatting. For goal-directed systems, the system is usually more “knowledgeable” than the user, and it attempts to satisfy user-specified goals. The system’s conversational strategies seek"
W10-4317,J95-3001,0,0.0709273,"ach of which handles different dialogue actions, is specified to control the dialogue progress. The knowledge has also been specified either by first order logic (Bühler & Minker, 2005) or ontology information (Milward & Beveridge, 2004). Introduction Conversational systems can be classified into two distinct classes: goal-directed and casual chatting. For goal-directed systems, the system is usually more “knowledgeable” than the user, and it attempts to satisfy user-specified goals. The system’s conversational strategies seek the most efficient path to reach closure and end the conversation (Smith, Hipp, & Biermann, 1995). An essential commonality among different goal-directed applications is that, at the end of a successful conversation, the system presents the user with a “goal” entity, be it a flight itinerary, a route path, or a shopping order. Different conversations result from different properties of the goal entities and different constraints set by the knowledge sources. The properties define the necessary and/or relevant information, such as flight numbers in the flight itinerary. Constraints specify the means to obtain such information. For examples fields “source”, “destination” and “date” are req"
W15-3814,W13-2001,0,0.0348375,"embedding is a collective name for a set of language modelling and feature learning techniques, by which words in a vocabulary 2 2.1 Methods and results BioNLP GENIA task A series of efforts has been initiated to evaluate the available solutions and investigate potentials in event extraction technologies. Among them, the 121 Proceedings of the 2015 Workshop on Biomedical Natural Language Processing (BioNLP 2015), pages 121–126, c Beijing, China, July 30, 2015. 2015 Association for Computational Linguistics periments, we use LibSVM as the implementation of SVM. BioNLP Shared Tasks (BioNLP-ST) [7] have been consistently conducted since 2009 and attracted community-wide support. BioNLP-ST GENIA task is a core task and had the third edition in 2013. The task gradually increased its difficulties and complexities, for example, by upgrading from abstract-only text to full-text articles and subsuming co-reference tasks. In the latest GENIA 2013 task, EVEX achieves the best performance (F-score: 50.97; recall: 45.44; precision: 58.03) [8]. Our system achieves a comparable result with a higher precision (Fscore 47.33; recall: 37.14; precision: 65.21). 2.2 2.3 Word embedding for trigger and arg"
W15-3814,W11-1805,1,\N,Missing
W15-3814,W13-2002,0,\N,Missing
