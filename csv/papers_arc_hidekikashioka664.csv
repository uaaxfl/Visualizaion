C12-1173,Factored Language Model based on Recurrent Neural Network,2012,32,21,6,1,4600,youzheng wu,Proceedings of {COLING} 2012,0,"Among various neural network language models (NNLMs), recurrent neural network-based language models (RNNLMs) are very competitive in many cases. Most current RNNLMs only use one single feature stream, i.e., surface words. However, previous studies proved that language models with additional linguistic information achieve better performance. In this study, we extend RNNLM by explicitly integrating additional linguistic information, including morphological, syntactic, or semantic factors. Our proposed RNNLM is called a factored RNNLM that is expected to enhance RNNLMs. A number of experiments are carried out that show the factored RNNLM improves the performance for all considered tasks: consistent perplexity and word error rate (WER) reductions. In the Penn Treebank corpus, the relative improvements over n-gram LM and RNNLM are 29.0% and 13.0%, respectively. In the IWSLT-2011 TED ASR test set, absolute WER reductions over RNNLM and n-gram LM reach 0.63 and 0.73 points. Title and Abstract in another language (Chinese) a axe2x80xa2xe2x80x9dxefxbfxbd xc2xb2d{{O Oxc2xa3aOUUn n"
2012.iwslt-papers.11,Factored recurrent neural network language model in {TED} lecture transcription,2012,24,7,6,1,4600,youzheng wu,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"In this study, we extend recurrent neural network-based language models (RNNLMs) by explicitly integrating morphological and syntactic factors (or features). Our proposed RNNLM is called a factored RNNLM that is expected to enhance RNNLMs. A number of experiments are carried out on top of state-of-the-art LVCSR system that show the factored RNNLM improves the performance measured by perplexity and word error rate. In the IWSLT TED test data sets, absolute word error rate reductions over RNNLM and n-gram LM are 0.4â¼0.8 points."
2012.iwslt-evaluation.2,The {NICT} {ASR} system for {IWSLT}2012,2012,12,5,8,0,43804,hitoshi yamamoto,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes our automatic speech recognition (ASR) system for the IWSLT 2012 evaluation campaign. The target data of the campaign is selected from the TED talks, a collection of public speeches on a variety of topics spoken in English. Our ASR system is based on weighted finite-state transducers and exploits an combination of acoustic models for spontaneous speech, language models based on n-gram and factored recurrent neural network trained with effectively selected corpora, and unsupervised topic adaptation framework utilizing ASR results. Accordingly, the system achieved 10.6{\%} and 12.0{\%} word error rate for the tst2011 and tst2012 evaluation set, respectively."
I11-1020,Improving Related Entity Finding via Incorporating Homepages and Recognizing Fine-grained Entities,2011,35,0,4,1,4600,youzheng wu,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"This paper describes experiments on the TREC entity track that studies retrieval of homepages representing entities relevant to a query. Many studies have focused on extracting entities that match the given coarse-grained types such as organizations, persons, locations by using a named entity recognizer, and employing language model techniques to calculate similarities between query and supporting snippets of entities from which entities are extracted to rank the entities. This paper proposes three improvements over baseline, i.e., 1) incorporating homepages of entities to supplement supporting snippets, 2) recognizing fine-grained named entities to filter out or negatively reward extracted entities that do not match the specified fine-grained types of entities such as a university, airline, author, and 3) adopting a dependency tree-based similarity method to improve language model techniques. Our experiments demonstrate that the proposed approaches can significantly improve performance, for instance, the absolute improvements of nDCG@R and P@1 scores are 8.4%, and 27.5%."
I11-1107,Answering Complex Questions via Exploiting Social {Q}{\\&}{A} Collection,2011,21,2,4,1,4600,youzheng wu,Proceedings of 5th International Joint Conference on Natural Language Processing,0,None
2011.iwslt-evaluation.2,The {NICT} {ASR} system for {IWSLT}2011,2011,8,0,7,0,41936,kazuhiko abe,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper, we describe NICT{'}s participation in the IWSLT 2011 evaluation campaign for the ASR Track. To recognize spontaneous speech, we prepared an acoustic model trained by more spontaneous speech corpora and a language model constructed with text corpora distributed by the organizer. We built the multi-pass ASR system by adapting the acoustic and language models with previous ASR results. The target speech was selected from talks on the TED (Technology, Entertainment, Design) program. Here, a large reduction in word error rate was obtained by the speaker adaptation of the acoustic model with MLLR. Additional improvement was achieved not only by adaptation of the language model but also by parallel usage of the baseline and speaker-dependent acoustic models. Accordingly, the final WER was reduced by 30{\%} from the baseline ASR for the distributed test set."
2011.iwslt-evaluation.22,Investigation of the effects of {ASR} tuning on speech translation performance,2011,13,5,4,0,41939,paul dixon,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper we describe some of our recent investigations into ASR and SMT coupling issues from an ASR perspective. Our study was motivated by several areas: Firstly, to understand how standard ASR tuning procedures effect the SMT performance and whether it is safe to perform this tuning in isolation. Secondly, to investigate how vocabulary and segmentation mismatches between the ASR and SMT system effect the performance. Thirdly, to uncover any practical issues that arise when using a WFST based speech decoder for tight coupling as opposed to a more traditional tree-search decoding architecture. On the IWSLT07 Japanese-English task we found that larger language model weights only helped the SMT performance when the ASR decoder was tuned in a sub-optimal manner. When we considered the performance with suitable wide beams that ensured the ASR accuracy had converged we observed the language model weight had little influence on the SMT BLEU scores. After the construction of the phrase table the actual SMT vocabulary can be less than the training data vocabulary. By reducing the ASR lexicon to only cover the words the SMT system could accept, we found this lead to an increase in the ASR error rates, however the SMT BLEU scores were nearly unchanged. From a practical point of view this is a useful result as it means we can significantly reduce the memory footprint of the ASR system. We also investigated coupling WFST based ASR to a simple WFST based translation decoder and found it was crucial to perform phrase table expansion to avoid OOV problems. For the WFST translation decoder we describe a semiring based approach for optimizing the log-linear weights."
W10-4339,Modeling Spoken Decision Making Dialogue and Optimization of its Dialogue Strategy,2010,7,9,5,1,38434,teruhisa misu,Proceedings of the {SIGDIAL} 2010 Conference,0,"This paper presents a spoken dialogue framework that helps users in making decisions. Users often do not have a definite goal or criteria for selecting from a list of alternatives. Thus the system has to bridge this knowledge gap and also provide the users with an appropriate alternative together with the reason for this recommendation through dialogue. We present a dialogue state model for such decision making dialogue. To evaluate this model, we implement a trial sightseeing guidance system and collect dialogue data. Then, we optimize the dialogue strategy based on the state model through reinforcement learning with a natural policy gradient approach using a user simulator trained on the collected dialogue corpus."
kamiya-etal-2010-construction,Construction of Back-Channel Utterance Corpus for Responsive Spoken Dialogue System Development,2010,7,2,4,0,45096,yuki kamiya,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In spoken dialogues, if a spoken dialogue system does not respond at all during userÂs utterances, the user might feel uneasy because the user does not know whether or not the system has recognized the utterances. In particular, back-channel utterances, which the system outputs as voices such as ÂyeahÂ and Âuh huhÂ in English have important roles for a driver in in-car speech dialogues because the driver does not look owards a listener while driving. This paper describes construction of a back-channel utterance corpus and its analysis to develop the system which can output back-channel utterances at the proper timing in the responsive in-car speech dialogue. First, we constructed the back-channel utterance corpus by integrating the back-channel utterances that four subjects provided for the driverÂs utterances in 60 dialogues in the CIAIR in-car speech dialogue corpus. Next, we analyzed the corpus and revealed the relation between back-channel utterance timings and information on bunsetsu, clause, pause and rate of speech. Based on the analysis, we examined the possibility of detecting back-channel utterance timings by machine learning technique. As the result of the experiment, we confirmed that our technique achieved as same detection capability as a human."
ohtake-etal-2010-dialogue,Dialogue Acts Annotation for {NICT} {K}yoto Tour Dialogue Corpus to Construct Statistical Dialogue Systems,2010,15,6,4,1,35675,kiyonori ohtake,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper introduces a new corpus of consulting dialogues designed for training a dialogue manager that can handle consulting dialogues through spontaneous interactions from the tagged dialogue corpus. We have collected more than 150 hours of consulting dialogues in the tourist guidance domain. We are developing the corpus that consists of speech, transcripts, speech act (SA) tags, morphological analysis results, dependency analysis results, and semantic content tags. This paper outlines our taxonomy of dialogue act (DA) annotation that can describe two aspects of an utterance: the communicative function (SA), and the semantic content of the utterance. We provide an overview of the Kyoto tour dialogue corpus and a preliminary analysis using the DA tags. We also show a result of a preliminary experiment for SA tagging via Support Vector Machines (SVMs). We introduce the current states of the corpus development In addition, we mention the usage of our corpus for the spoken dialogue system that is being developed."
W09-3405,Annotating Dialogue Acts to Construct Dialogue Systems for Consulting,2009,16,11,4,1,35675,kiyonori ohtake,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper introduces a new corpus of consulting dialogues, which is designed for training a dialogue manager that can handle consulting dialogues through spontaneous interactions from the tagged dialogue corpus. We have collected 130 h of consulting dialogues in the tourist guidance domain. This paper outlines our taxonomy of dialogue act annotation that can describe two aspects of an utterances: the communicative function (speech act), and the semantic content of the utterance. We provide an overview of the Kyoto tour guide dialogue corpus and a preliminary analysis using the dialogue act tags."
D07-1004,Learning Unsupervised {SVM} Classifier for Answer Selection in Web Question Answering,2007,17,11,4,1,4600,youzheng wu,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Previous machine learning techniques for answer selection in question answering (QA) have required question-answer training pairs. It has been too expensive and labor-intensive, however, to collect these training pairs. This paper presents a novel unsupervised support vector machine (USVM) classifier for answer selection, which is independent of language and does not require hand-tagged training pairs. The key ideas are the following: 1. unsupervised learning of training data for the classifier by clustering web search results; and 2. selecting the correct answer from the candidates by classifying the question. The comparative experiments demonstrate that the proposed approach significantly outperforms the retrieval-based model (Retrieval-M), the supervised SVM classifier (S-SVM), and the pattern-based model (Pattern-M) for answer selection. Moreover, the cross-model comparison showed that the performance ranking of these models was: U-SVM > PatternM > S-SVM > Retrieval-M."
P06-1022,Dependency Parsing of {J}apanese Spoken Monologue Based on Clause Boundaries,2006,21,8,3,0.833333,16789,tomohiro ohno,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Spoken monologues feature greater sentence length and structural complexity than do spoken dialogues. To achieve high parsing performance for spoken monologues, it could prove effective to simplify the structure by dividing a sentence into suitable language units. This paper proposes a method for dependency parsing of Japanese monologues based on sentence segmentation. In this method, the dependency parsing is executed in two stages: at the clause level and the sentence level. First, the dependencies within a clause are identified by dividing a sentence into clauses and executing stochastic dependency parsing for each clause. Next, the dependencies over clause boundaries are identified stochastically, and the dependency structure of the entire sentence is thus completed. An experiment using a spoken monologue corpus shows this method to be effective for efficient dependency parsing of Japanese monologue sentences."
ohno-etal-2006-syntactically,A Syntactically Annotated Corpus of {J}apanese Spoken Monologue,2006,8,4,3,0.833333,16789,tomohiro ohno,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Recently, monologue data such as lecture and commentary by professionals have been considered as valuable intellectual resources, and have been gathering attention. On the other hand, in order to use these monologue data effectively and efficiently, it is necessary for the monologue data not only just to be accumulated but also to be structured. This paper describes the construction of a Japanese spoken monologue corpus in which dependency structure is given to each utterance. Spontaneous monologue includes a lot of very long sentences composed of two or more clauses. In these sentences, there may exist the subject or the adverb common to multi-clauses, and it may be considered that the subject or adverb depend on multi-predicates. In order to give the dependency information in a real fashion, our research allows that a bunsetsu depends on multiple bunsetsus."
2006.iwslt-papers.8,Development of client-server speech translation system on a multi-lingual speech communication platform,2006,11,7,4,0,48707,tohru shimizu,Proceedings of the Third International Workshop on Spoken Language Translation: Papers,0,"This paper describes a client-server speech-to-speech translation system developed on a multi-lingual speech communication platform. This platform enables easy assembly of speech communication system from the corresponding software modules (e.g. speech recognition, spoken language machine-translation, speech synthesis). This client-server speech translation system is designed for use at mobile terminals. Terminals and servers are connected via a 3G public mobile phone networks, and speech translation services are available at various places with thin client. This system realizes hands-free communication and robustness for real use of speech translation in noisy environments. A microphone array and new noise suppression technique improves speech recognition performance, and a corpus-based approach enables wide coverage, robustness and portability to new languages and domains. Recent evaluation of the overall system showed that the utterance correctness of speech recognition output achieved 83%, and more than 88% of the utterances are correctly translated for Japanse-English and JapaneseChinese."
W05-1204,Training Data Modification for {SMT} Considering Groups of Synonymous Sentences,2005,11,0,1,1,43805,hideki kashioka,Proceedings of the {ACL} Workshop on Empirical Modeling of Semantic Equivalence and Entailment,0,"Generally speaking, statistical machine translation systems would be able to attain better performance with more training sets. Unfortunately, well-organized training sets are rarely available in the real world. Consequently, it is necessary to focus on modifying the training set to obtain high accuracy for an SMT system. If the SMT system trained the translation model, the translation pair would have a low probability when there are many variations for target sentences from a single source sentence. If we decreased the number of variations for the translation pair, we could construct a superior translation model. This paper describes the effects of modification on the training corpus when consideration is given to synonymous sentence groups. We attempt three types of modification: compression of the training set, replacement of source and target sentences with a selected sentence from the synonymous sentence group, and replacement of the sentence on only one side with the selected sentence from the synonymous sentence group. As a result, we achieve improved performance with the replacement of source-side sentences."
I05-4003,Corpus-oriented Acquisition of {C}hinese Grammar,2005,7,0,2,0,10073,yan zhang,Proceedings of the Fifth Workshop on {A}sian Language Resources ({ALR}-05) and First Symposium on {A}sian Language Resources Network ({ALRN}),0,"The acquisition of grammar from a corpus is a challenging task in the preparation of a knowledge bank. In this paper, we discuss the extraction of Chinese grammar oriented to a restricted corpus. First, probabilistic context-free grammars (PCFG) are extracted automatically from the Penn Chinese Treebank and are regarded as the baseline rules. Then a corpusoriented grammar is developed by adding specific information including head information from the restricted corpus. Then, we describe the peculiarities and ambiguities, particularly between the phrases xe2x80x9cPPxe2x80x9d and xe2x80x9cVPxe2x80x9d in the extracted grammar. Finally, the parsing results of the utterances are used to evaluate the extracted grammar."
2005.mtsummit-posters.15,Word Alignment Viewer for Long Sentences,2005,-1,-1,1,1,43805,hideki kashioka,Proceedings of Machine Translation Summit X: Posters,0,"An aligned corpus is an important resource for developing machine translation systems. We consider suitable units for constructing the translation model through observing an aligned parallel corpus. We examine the characteristics of the aligned corpus. Long sentences are especially difficult for word alignment because the sentences can become very complicated. Also, each (source/target) word has a higher possibility to correspond to the (target/source) word. This paper introduces an alignment viewer a developer can use to correct alignment information. We discuss using the viewer on a patent parallel corpus because sentences in patents are often long and complicated."
2005.mtsummit-papers.29,Probabilistic Model for Example-based Machine Translation,2005,-1,-1,3,0.833333,165,eiji aramaki,Proceedings of Machine Translation Summit X: Papers,0,"Example-based machine translation (EBMT) systems, so far, rely on heuristic measures in retrieving translation examples. Such a heuristic measure costs time to adjust, and might make its algorithm unclear. This paper presents a probabilistic model for EBMT. Under the proposed model, the system searches the translation example combination which has the highest probability. The proposed model clearly formalizes EBMT process. In addition, the model can naturally incorporate the context similarity of translation examples. The experimental results demonstrate that the proposed model has a slightly better translation quality than state-of-the-art EBMT systems."
kashioka-2004-grouping,Grouping Synonymous Sentences from a Parallel Corpus,2004,4,3,1,1,43805,hideki kashioka,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Abstract Recently, natural language processing researches have focused on data or processing techniques for paraphrasing. Unfortunately, however, we have little data for paraphrasing. There are some research reports on collecting synonymous expressions with parallel corpus, though no suitable corpus for collecting a set of paraphrases is yet available. Therefore, we obtain a few variations of expression in paraphrase sets when we tried to apply this method with a parallel corpus. In this paper, we propose a grouping method based on the basic idea of grouping synonymous sentences related to the translation recursively, and decompose incorrect groups using the DMdecomposition algorithm. The incorrect groups include expressions that cannot be paraphrased because some words or expressions have different meanings in different situations. We discuss our method and experimental results with respect to BTEC, which is a multilingual parallel corpus."
W03-1503,Construction and Analysis of {J}apanese-{E}nglish Broadcast News Corpus with Named Entity Tags,2003,12,3,2,1,36676,tadashi kumano,Proceedings of the {ACL} 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,0,"We are aiming to acquire named entity (NE) translation knowledge from nonparallel, content-aligned corpora, by utilizing NE extraction techniques. For this research, we are constructing a Japanese-English broadcast news corpus with NE tags. The tags represent not only NE class information but also coreference information within the same monolingual document and between corresponding Japanese-English document pairs. Analysis of about 1,100 annotated article pairs has shown that if NE occurrence information, such as classes, number of occurrence and occurrence order, is given for each language, it may provide a good clue for corresponding NEs across languages."
W03-0312,Word Selection for {EBMT} based on Monolingual Similarity and Translation Confidence,2003,12,9,3,0.833333,165,eiji aramaki,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"We propose a method of constructing an example-based machine translation (EBMT) system that exploits a content-aligned bilingual corpus. First, the sentences and phrases in the corpus are aligned across the two languages, and the pairs with high translation confidence are selected and stored in the translation memory. Then, for a given input sentences, the system searches for fitting examples based on both the monolingual similarity and the translation confidence of the pair, and the obtained results are then combined to generate the translation. Our experiments on translation selection showed the accuracy of 85% demonstrating the basic feasibility of our approach."
2003.mtsummit-papers.29,Building a parallel corpus for monologues with clause alignment,2003,-1,-1,1,1,43805,hideki kashioka,Proceedings of Machine Translation Summit IX: Papers,0,"Many studies have been reported in the domain of speech-to-speech machine translation systems for travel conversation use. Therefore, a large number of travel domain corpora have become available in recent years. From a wider viewpoint, speech-to-speech systems are required for many purposes other than travel conversation. One of these is monologues (e.g., TV news, lectures, technical presentations). However, in monologues, sentences tend to be long and complicated, which often causes problems for parsing and translation. Therefore, we need a suitable translation unit, rather than the sentence. We propose the clause as a unit for translation. To develop a speech-to-speech machine translation system for monologues based on the clause as the translation unit, we need a monologue parallel corpus with clause alignment. In this paper, we describe how to build a Japanese-English monologue parallel corpus with clauses aligned, and discuss the features of this corpus."
takao-etal-2002-comparing,Comparing and Extracting Paraphrasing Words with 2-Way Bilingual Dictionaries,2002,2,3,3,0,51316,kazutaka takao,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
kashioka-2002-translation,Translation Unit Concerning Timing of Simultaneous Translation,2002,1,4,1,1,43805,hideki kashioka,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper discusses and proposes a translation unit for simultaneous translation using a machine translation (MT) system. Monologues, such as lectures or broadcast news, are used as the target of simultaneous speech translation. To date, a lot of research on speech translation has dealt with dialogues, especially travel conversations. Most of the speech translation systems in MT have treated a sentence as a translation unit. In the ATR travel conversation database, sentence length is less than 10 words on average. Therefore, most of the sentences are simple and almost all of the utterances are constructed in one or two sentences. However, the sentences of monologues are longer than travel dialogues. They have over 30 words (as in xe2x80x9cASU-wo-YOMU,xe2x80x9d a TV news commentary program) on average, and most of the sentences are complex or compound. Accordingly, it is difficult to treat a sentence as a translation unit for monologues, and thus an appropriate translation unit needs to be found. Considering this, we hypothesized that an adequate translation unit of speech translation systems relates to the translation unit of a human simultaneous translator. Therefore, we collected simultaneous translation data from lectures by human translators and investigated the characteristics of monologues and simultaneous translation."
S01-1023,{ATR}-{SLT} System for {SENSEVAL}-2 {J}apanese Translation Task,2001,1,0,2,1,36676,tadashi kumano,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"We propose a translation selection system based on the vector space model.n n When each translation candidate of a word is given as a pair of expressions containing the word and its translation, selecting the translation of the word can be considered equivalent to selecting the expression having the most similar context among candidate expressions. The proposed method expresses the context information in context vectors constructed from content words co-occurring with the target word. Context vectors represent detailed information composed of lexical attributes (word forms, semantic codes, etc.) and syntactic relations (syntactic dependency, etc.) of the co-occurring words.n n We tested the proposed method with the Senseval-2 Japanese translation task. Precision/recall was 45.8% to the gold standard in the experiment with the evaluation set."
2001.mtsummit-papers.68,An automatic evaluation method for machine translation using two-way {MT},2001,0,4,2,1,44876,shoichi yokoyama,Proceedings of Machine Translation Summit VIII,0,"Evaluation of machine translation is one of the most important issues in this field. We have already proposed a quantitative evaluation of machine translation system. The method was roughly that an example sentence in Japanese is machine translated into English, and then into Japanese using several systems, and that the comparison of output Japanese sentences with the original Japanese sentence is done for the word identification, the correctness of the modification, the syntactic dependency, and the parataxis. By calculating the score, we could quantitatively evaluate the English machine translation. However, the extraction of word identification etc. was done by human, and the fact affects the correctness of evaluation. In order to solve this problem, we developed an automatic evaluation system. We report the detail of the system in this paper.."
kashioka-shirai-2000-automatically,Automatically Expansion of Thesaurus Entries with a Different Thesaurus,2000,0,0,1,1,43805,hideki kashioka,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,None
A00-1006,Translation using Information on Dialogue Participants,2000,10,7,3,1,42063,setsuo yamada,Sixth Applied Natural Language Processing Conference,0,"This paper proposes a way to improve the translation quality by using information on dialogue participants that is easily obtained from outside the translation component. We incorporated information on participants' social roles and genders into transfer rules and dictionary entries. An experiment with 23 unseen dialogues demonstrated a recall of 65% and a precision of 86%. These results showed that our simple and easy-to-implement method is effective, and is a key technology enabling smooth conversation with a dialogue translation system."
1999.mtsummit-1.32,Applying {TDMT} to abstracts on science and technology,1999,-1,-1,1,1,43805,hideki kashioka,Proceedings of Machine Translation Summit VII,0,"In this paper, we discuss applying a translation model, ``Transfer Driven Machine Translation'' (TDMT), to document abstracts on science and technology. TDMT, a machine translation model, was developed by ATR-ITL to deal with dialogues in the travel domain. ATR-ITL has reported that the TDMT system efficiently translates multi-lingual spoken-dialogs. However, little is known about the ability of TDMT to translate written text translations; therefore, we examined TDMT with written text from English to Japanese, especially abstracts on science and technology produced by the Japan Science and Technology Corporation (JST). The experimental results show that TDMT can derive written text translation."
1999.mtsummit-1.34,Solutions to problems inherent in spoken-language translation: the {ATR}-{MATRIX} approach,1999,8,39,5,0.517624,129,eiichiro sumita,Proceedings of Machine Translation Summit VII,0,"ATR has built a multi-language speech translation system called ATR-MATRIX. It consists of a spoken-language translation subsystem, which is the focus of this paper, together with a highly accurate speech recognition subsystem and a high-definition speech synthesis subsystem. This paper gives a road map of solutions to the problems inherent in spoken-language translation. Spoken-language translation systems need to tackle difficult problems such as ungrammaticality. contextual phenomena, speech recognition errors, and the high-speeds required for real-time use. We have made great strides towards solving these problems in recent years. Our approach mainly uses an example-based translation model called TDMT. We have added the use of extra-linguistic information, a decision tree learning mechanism, and methods dealing with recognition errors."
1999.mtsummit-1.43,Study on evaluation of {WWW} {MT} systems,1999,-1,-1,6,0,51170,shinichiro miyazawa,Proceedings of Machine Translation Summit VII,0,"Compared with off-line machine translation (MT). MT for the WWW has more evaluation factors such as translation accuracy of text, interpretation of HTML tags, consistency with various protocols and browsers, and translation speed for net surfing. Moreover, the speed of technical innovation and its practical application is fast, including the appearance of new protocols. Improvement of MT software for the WWW will enable the sharing of information from around the world and make a great deal of contribution to mankind. Despite the importance of general evaluation studies on MT software for the WWW. it appears that such studies have not yet been conducted. Since MT for the WWW will be a critical factor for future international communication, its study and evaluation is an important theme. This study aims at standardized evaluation of MT for the WWW. and suggests an evaluation method focusing on unique aspects of the WWW independent of text. This evaluation method has a wide range of aptitude without depending on specific languages. Twenty-four items specific to the WWW were actually evaluated with regard to six MT software for the WWW. This study clarified various issues which should be improved in the future regarding MT software for the WWW and issues on evaluation technology of MT on the Internet."
1999.mtsummit-1.84,Quantitative evaluation of machine translation using two-way {MT},1999,-1,-1,7,1,44876,shoichi yokoyama,Proceedings of Machine Translation Summit VII,0,"One of the most important issues in the field of machine translation is evaluation of the translated sentences. This paper proposes a quantitative method of evaluation for machine translation systems. The method is as follows. First, an example sentence in Japanese is machine translated into English using several Japanese-English machine translation systems. Second, the output English sentences are machine translated into Japanese using several English-Japanese machine translation systems (different from the Japanese-English machine translation systems). Then, each output Japanese sentence is compared with the original Japanese sentence in terms of word identification, correctness of the modification, syntactic dependency, and parataxes. An average score is calculated, and this becomes the total evaluation of the machine translation of the sentence. From this two-way machine translation and the calculation of the score, we can quantitatively evaluate the English machine translation. For the present study, we selected 100 Japanese sentences from the abstracts of scientific articles. Each of these sentences has an English translation which was performed by a human. Approximately half of these sentences are evaluated and the results are given. In addition, a comparison of human and machine translations is also performed and the trade-off between the two methods of translation is discussed."
P98-1020,Trigger-Pair Predictors in Parsing and Tagging,1998,18,6,3,0,49916,ezra black,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"In this article, we apply to natural language parsing and tagging the device of trigger-pair predictors, previously employed exclusively within the field of language modelling for speech recognition. Given the task of predicting the correct rule to associate with a parse-tree node, or the correct tag to associate with a word of text, and assuming a particular class of parsing or tagging model, we quantify the information gain realized by taking account of rule or tag trigger-pair predictors, i.e. pairs consisting of a triggering rule or tag which has already occurred in the document being processed, together with a specific triggered rule or tag whose probability of occurrence within the current sentence we wish to estimate. This information gain is shown to be substantial. Further, by utilizing trigger pairs taken from the same general sort of document as is being processed (e.g. same subject matter or same discourse type)---as opposed to predictors derived from a comprehensive general set of English texts---we can significantly increase this information gain."
P98-1108,Use of Mutual Information Based Character Clusters in Dictionary-less Morphological Analysis of {J}apanese,1998,10,9,1,1,43805,hideki kashioka,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"For languages whose character set is very large and whose orthography does not require spacing between words, such as Japanese, tokenizing and part-of-speech tagging are often the difficult parts of any morphological analysis. For practical systems to tackle this problem, uncontrolled heuristics are primarily used. The use of information on character sorts, however, mitigates this difficulty. This paper presents our method of incorporating character clustering based on mutual information into Decision-Tree Dictionary-less morphological analysis. By using natural classes, we have confirmed that our morphological analyzer has been significantly improved in both tokenizing and tagging Japanese text."
C98-1020,Trigger-Pair Predictors in Parsing and Tagging,1998,18,6,3,0,49916,ezra black,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"In this article, we apply to natural language parsing and tagging the device of trigger-pair predictors, previously employed exclusively within the field of language modelling for speech recognition. Given the task of predicting the correct rule to associate with a parse-tree node, or the correct tag to associate with a word of text, and assuming a particular class of parsing or tagging model, we quantify the information gain realized by taking account of rule or tag trigger-pair predictors, i.e. pairs consisting of a triggering rule or tag which has already occurred in the document being processed, together with a specific triggered rule or tag whose probability of occurrence within the current sentence we wish to estimate. This information gain is shown to be substantial. Further, by utilizing trigger pairs taken from the same general sort of document as is being processed (e.g. same subject matter or same discourse type)---as opposed to predictors derived from a comprehensive general set of English texts---we can significantly increase this information gain."
C98-1104,Use of Mutual Information Based Character Clusters in Dictionary-less Morphological Analysis of {J}apanese,1998,10,9,1,1,43805,hideki kashioka,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"For languages whose character set is very large and whose orthography does not require spacing between words, such as Japanese, tokenizing and part-of-speech tagging are often the difficult parts of any morphological analysis. For practical systems to tackle this problem, uncontrolled heuristics are primarily used. The use of information on character sorts, however, mitigates this difficulty. This paper presents our method of incorporating character clustering based on mutual information into Decision-Tree Dictionary-less morphological analysis. By using natural classes, we have confirmed that our morphological analyzer has been significantly improved in both tokenizing and tagging Japanese text."
W97-0105,"Probabilistic Parsing of Unrestricted {E}nglish Text, With a Highly-Detailed Grammar",1997,15,3,3,0,49916,ezra black,Fifth Workshop on Very Large Corpora,0,"Summary A grammar-based probabilistic parser is described, and experimental results are presented for the parser as trained and tested on a 676,000-word, highly varied treebank of unrestricted English text. Probabilistic decision trees are utilized as a means of prediction, and a grammar with about 3000 semantic-and-syntactic tags, and 1100 non-terminal node labels suppl/es detailed lingzdstic information. Further such data is supplied for prediction purposes by thousands of questions about raw words, expres~ sions, and the sentence as a whole. The rich/n.formation base used for parse prediction allows the system to parse in a domain-general, totally--open-vocabulary setting, and to output highly-detailed semantic as well as syntactic information for sentences proccessed. Finally, a statistical procedure is described for converting less-detailed into more--detailed treebank, for use in increasing parser accuracy via much larger training treeb~.nlc~."
C96-1020,Beyond Skeleton Parsing: Producing a Comprehensive Large-Scale General-{E}nglish Treebank With Full Grammatical Analysis,1996,15,27,3,0,49916,ezra black,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"A treebank is a body of natural language text which has been grammatically annotated by hand, in terms of some previously-established scheme of grammatical analysis. Treebanks have been used within the field of natural language processing as a source of training data for statistical part og speech taggers (Black et al., 1992; Brill, 1994; Merialdo, 1994; Weischedel et al., 1993) and for statistical parsers (Black et al., 1993; Brill, 1993; aelinek et al., 1994; Magerman, 1995; Magerman and Marcus, 1991). In this article, we present the AT'R/Lancaster 7'reebauk of American English, a new resource tbr natural-language-, processing research, which has been prepared by Lancaster University (UK)'s Unit for Computer Research on the English Language, according to specifications provided by ATR (Japan)'s Statistical Parsing Group. First we provide a static description, with (a) a discussion of the mode of selection and initial processing of text for inclusion in the treebank, and (b) an explanation of the scheme of grammatical annotation we then apply to the text. Sec.ond, we supply a process description of the treebank, in which we detail the physical and computational mechanisms by which we have created it. Finally, we lay out plans for the further development of this new treebank. All of the features of the ATR/Lancaster Treebank that are described below represent a radical departure from extant large-scale (Eyes and Leech, 1993; Garside and McEnery, 1993; Marcus et al., 1993) treebanks. We have chosen in this article to present our treebank in some detail, rather than to compare and contrast it with other treebanks. But the major differences between this and earlier treebanks can easily be grasped via a corn-"
