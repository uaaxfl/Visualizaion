2011.mtsummit-papers.28,P05-1033,0,0.676099,"atures many of which have led to the improved performance for Hiero. However, it seems that all the syntactic constituent features cannot efficiently work together in the Hiero optimized by MERT. In this paper, we propose a more general soft syntactic constraint model based on discriminative classifiers for each constituent type and integrate all of them into the translation model with a unified form. The experimental results show that our method significantly improves the performance on the NIST05 Chinese-toEnglish translation task. 1 Introduction Hierarchical phrase-based translation model (Chiang, 2005) is a compromise of two popular translation models: syntax based model and phrase based model. It is a formal syntax grammar(Chiang, 2005; Wu, 1997), which does not take linguistic analysis into account when compared with other pure syntax systems (Liu et al., 2006;Yamada and Knight, 2001;Galley et al., 2006). It promises to improve the performance by adding syntax information to phrase based as well as formal syntax based translation models. Chiang (2005) first introduced syntax knowledge into the hierarchical phrase based model. To make the model sensitive to the syntax structure, a constitu"
2011.mtsummit-papers.28,N09-1025,0,0.0381264,"ffort to improve performance for hierarchical phrase-based machine translation by employing linguistic knowledge. Some of the work which is closely related with ours is reviewed in this section. As presented previously, our work generalizes heavily from (Marton and Resnik, 2008). Besides exploring the soft syntactic constraints on hierarchical phrase model, ours investigates a way to make all the SSC models work together efficiently. (Stein et al., 2010) focuses on the syntactic constraint not only via the constituent parse but also via the dependency parse tree of source or target sentence. (Chiang et al., 2009; Chiang, 2010) similarly define many syntactic features including both source and target sides but integrated them into translation model by MIRA algorithm to optimize their weights. Their work proposes the heuristic syntactic features, while ours employ the discriminative syntactic models. Zollmann and Venugopal (2006) use a constituent parse tree of target to provide constraints on the synchronous rules. They refine 258 the translation grammar with the syntactic constituent types, while ours integrates syntactic knowledge as a sub-model. The idea to design the labels of our SSC models is bo"
2011.mtsummit-papers.28,P10-1146,0,0.084852,"ormance for hierarchical phrase-based machine translation by employing linguistic knowledge. Some of the work which is closely related with ours is reviewed in this section. As presented previously, our work generalizes heavily from (Marton and Resnik, 2008). Besides exploring the soft syntactic constraints on hierarchical phrase model, ours investigates a way to make all the SSC models work together efficiently. (Stein et al., 2010) focuses on the syntactic constraint not only via the constituent parse but also via the dependency parse tree of source or target sentence. (Chiang et al., 2009; Chiang, 2010) similarly define many syntactic features including both source and target sides but integrated them into translation model by MIRA algorithm to optimize their weights. Their work proposes the heuristic syntactic features, while ours employ the discriminative syntactic models. Zollmann and Venugopal (2006) use a constituent parse tree of target to provide constraints on the synchronous rules. They refine 258 the translation grammar with the syntactic constituent types, while ours integrates syntactic knowledge as a sub-model. The idea to design the labels of our SSC models is bought from their"
2011.mtsummit-papers.28,P10-2002,1,0.708011,"der a prior distribution of all GCLs. We define the following feature: Ԅୗୗେ ሺሻ ൌ ൫൫ ሺሻ൯  כୋେሺ୰ሻ ሺ ൌ ͳȁሺ ሺሻ൯ሺͳͲሻǡ where ൫ ሺሻ൯ is a prior probability for GCLs and it isestimated by M.L.E. in the training examples. The ୗୗେ ሺሻ can be described as follows: ୗୗେ ሺሻ ൌ  ൫ ሺሻ൯  כୋେሺ୰ሻ ሺ ൌ ͳȁ൫ ሺሻ൯ሺͳͳሻǤ ୰אୢ It is a Bayes-style combination. 5 5.1 Training SSCModels Training instances Unlike training models for ordinary classification tasks, our training instances are not available obviously because they are latent and by-product for machine translation. Cui et al. (2010) presented an efficient method to acquire training instances for rule selection model. Different from their method, ours is based on the derivations of the source sentence. Bilingual parsing (Wu, 1997) is a very efficient way to get the latent derivation for source language. In order to speed up the bilingual parsing, we limit the phrase table for each source sentence in the training data. When running bilingual parser for each source sentence, we just use the rules extracted from it and its reference during rule extraction step. Although our method will prune some derivations which can derive"
2011.mtsummit-papers.28,P06-1121,0,0.0605476,"s for each constituent type and integrate all of them into the translation model with a unified form. The experimental results show that our method significantly improves the performance on the NIST05 Chinese-toEnglish translation task. 1 Introduction Hierarchical phrase-based translation model (Chiang, 2005) is a compromise of two popular translation models: syntax based model and phrase based model. It is a formal syntax grammar(Chiang, 2005; Wu, 1997), which does not take linguistic analysis into account when compared with other pure syntax systems (Liu et al., 2006;Yamada and Knight, 2001;Galley et al., 2006). It promises to improve the performance by adding syntax information to phrase based as well as formal syntax based translation models. Chiang (2005) first introduced syntax knowledge into the hierarchical phrase based model. To make the model sensitive to the syntax structure, a constituent feature was integrated into the translation model with the soft constraint method. It was defined as follows: it gains 1 for rules whose source side respect syntactic phrase boundary in the parse tree, and 0 otherwise. However, it did not achieve statistically significant improvement in the experiment. Ma"
2011.mtsummit-papers.28,C08-1041,0,0.470529,"Missing"
2011.mtsummit-papers.28,D10-1014,0,0.0218127,"rly define many syntactic features including both source and target sides but integrated them into translation model by MIRA algorithm to optimize their weights. Their work proposes the heuristic syntactic features, while ours employ the discriminative syntactic models. Zollmann and Venugopal (2006) use a constituent parse tree of target to provide constraints on the synchronous rules. They refine 258 the translation grammar with the syntactic constituent types, while ours integrates syntactic knowledge as a sub-model. The idea to design the labels of our SSC models is bought from their work. Huang et al. (2010) decorate the syntax structure into the non-terminal in hierarchical rules as a feature vector. During decoding time, they calculate the similarity between the syntax of the source side and the rules used to derive translations, and then they add the similarity measure to translation model as an additional feature. Their work differs from ours in that they don’t directly use the syntax knowledge to calculate the additional feature score, but use it to derive a latent syntactic distribution. He et al.(2008) and Cui et al.(2010) employ the syntax knowledge as some of features to construct rule s"
2011.mtsummit-papers.28,N03-1017,0,0.0579851,"Missing"
2011.mtsummit-papers.28,W04-3250,0,0.525542,"Missing"
2011.mtsummit-papers.28,P06-1077,0,0.0457671,"model based on discriminative classifiers for each constituent type and integrate all of them into the translation model with a unified form. The experimental results show that our method significantly improves the performance on the NIST05 Chinese-toEnglish translation task. 1 Introduction Hierarchical phrase-based translation model (Chiang, 2005) is a compromise of two popular translation models: syntax based model and phrase based model. It is a formal syntax grammar(Chiang, 2005; Wu, 1997), which does not take linguistic analysis into account when compared with other pure syntax systems (Liu et al., 2006;Yamada and Knight, 2001;Galley et al., 2006). It promises to improve the performance by adding syntax information to phrase based as well as formal syntax based translation models. Chiang (2005) first introduced syntax knowledge into the hierarchical phrase based model. To make the model sensitive to the syntax structure, a constituent feature was integrated into the translation model with the soft constraint method. It was defined as follows: it gains 1 for rules whose source side respect syntactic phrase boundary in the parse tree, and 0 otherwise. However, it did not achieve statistically"
2011.mtsummit-papers.28,P00-1056,0,0.0727833,"L Size GCL Size to train our SSC models; IP 0.09M LIP/R 2.98M x Syntactic features, which are the general VP 0.59M LVP 0.36M constituent labels defined in section 2.1 for NP 0.95M LVP/R 2.31M the spans of r and the nonterminal symbols LIP 1.15M NP/R 0.62M in the source side. IP/R 0.94M LNP/R 1.06M x Parts-of-speech (POS) features, which are the POS of the words immediately to Table 1ˊThe distribution of the training examples for the left and right of ߙ and those of the partial general constituent labels. boundary words covered by the nonterminal symbols in the source side. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., x Length features, which are the length of sub-phrases covered by the nonterminal 2003) to obtain the word alignment for each sentence pair. Then, we employ Stanford parser symbols in the source side. (Klein and Manning, 2003) to generate the parse In fact, our models can be extended to include tree for the source side of the data. We acquire other features, especially those in the target side. In about 15.85M training examples among which are order to compare our models with the work of 6.81M positive and 9.04M negative examples Marton"
2011.mtsummit-papers.28,P02-1038,0,0.159763,"ǡୣሻ ୰אୢ ሺǡ ሻ denotes the set of synchronous derivation trees with (f,e) as their leaves, and d is a derivation member in ሺǡ ሻ . In decoding step, it is intractable to find the extract solution as (1), since the number of elements in ሺǡ ሻ is exponential. In fact, one can approximate the optimal solution via MAP: ො ൌ  ቀୢאୈሺሻ ሺሻቁሺ͵ሻ  ሺሻ denotes the derivation set which can induce f in the source side and ሺሻ denotes the target translation corresponding to derivation d. In hierarchical phrase translation, the rule probability can be represented as the log-linear (Och and Ney, 2002) combination of some feature functions: ሺሻ ൌ ς୧ Ԅ୧  ሺሻ ሺͶሻ, ǡ Ԅ୧ is a feature function, and ɉ୧ is its feature weight and it can be optimized via MERT (Och, 2003) on the development set. The features (Koehn et al.,2003; Chiang, 2005) can be taken as following: x the phrase translation probability ሺȽȁɀሻǡ ሺɀȁȽሻ; x the lexical weights  ሺȽȁɀሻǡ  ሺɀȁȽሻ; x a penalty for hierarchical rules; x a penalty for glue rules; x a word penalty; x language model. The decoding process is similar as the monolingual CKY parse and it can be considered as the transduction of source language into t"
2011.mtsummit-papers.28,P03-1021,0,0.0301372,"extract solution as (1), since the number of elements in ሺǡ ሻ is exponential. In fact, one can approximate the optimal solution via MAP: ො ൌ  ቀୢאୈሺሻ ሺሻቁሺ͵ሻ  ሺሻ denotes the derivation set which can induce f in the source side and ሺሻ denotes the target translation corresponding to derivation d. In hierarchical phrase translation, the rule probability can be represented as the log-linear (Och and Ney, 2002) combination of some feature functions: ሺሻ ൌ ς୧ Ԅ୧  ሺሻ ሺͶሻ, ǡ Ԅ୧ is a feature function, and ɉ୧ is its feature weight and it can be optimized via MERT (Och, 2003) on the development set. The features (Koehn et al.,2003; Chiang, 2005) can be taken as following: x the phrase translation probability ሺȽȁɀሻǡ ሺɀȁȽሻ; x the lexical weights  ሺȽȁɀሻǡ  ሺɀȁȽሻ; x a penalty for hierarchical rules; x a penalty for glue rules; x a word penalty; x language model. The decoding process is similar as the monolingual CKY parse and it can be considered as the transduction of source language into target language. 3 3.1 Discriminative Soft Syntactic Constraint Models Soft Syntactic Constraints For different syntactic categories (e.g. NP), Marton and Resnik (2008) defined"
2011.mtsummit-papers.28,2010.amta-papers.8,0,0.0320368,"ty BLEU-4 27.70 28.35* Table 4ˊThe translation effect of unifying methods for MaxEnt based SSC models on MT NIST05 test set. 7 Related Work There has been much effort to improve performance for hierarchical phrase-based machine translation by employing linguistic knowledge. Some of the work which is closely related with ours is reviewed in this section. As presented previously, our work generalizes heavily from (Marton and Resnik, 2008). Besides exploring the soft syntactic constraints on hierarchical phrase model, ours investigates a way to make all the SSC models work together efficiently. (Stein et al., 2010) focuses on the syntactic constraint not only via the constituent parse but also via the dependency parse tree of source or target sentence. (Chiang et al., 2009; Chiang, 2010) similarly define many syntactic features including both source and target sides but integrated them into translation model by MIRA algorithm to optimize their weights. Their work proposes the heuristic syntactic features, while ours employ the discriminative syntactic models. Zollmann and Venugopal (2006) use a constituent parse tree of target to provide constraints on the synchronous rules. They refine 258 the translat"
2011.mtsummit-papers.28,J97-3002,0,0.0733194,"rk together in the Hiero optimized by MERT. In this paper, we propose a more general soft syntactic constraint model based on discriminative classifiers for each constituent type and integrate all of them into the translation model with a unified form. The experimental results show that our method significantly improves the performance on the NIST05 Chinese-toEnglish translation task. 1 Introduction Hierarchical phrase-based translation model (Chiang, 2005) is a compromise of two popular translation models: syntax based model and phrase based model. It is a formal syntax grammar(Chiang, 2005; Wu, 1997), which does not take linguistic analysis into account when compared with other pure syntax systems (Liu et al., 2006;Yamada and Knight, 2001;Galley et al., 2006). It promises to improve the performance by adding syntax information to phrase based as well as formal syntax based translation models. Chiang (2005) first introduced syntax knowledge into the hierarchical phrase based model. To make the model sensitive to the syntax structure, a constituent feature was integrated into the translation model with the soft constraint method. It was defined as follows: it gains 1 for rules whose source"
2011.mtsummit-papers.28,P06-1066,0,0.125386,"se constituent type models can work together efficiently. Although (Marton and Resnik 2008) did not give the experiments to support the positive answer, as presented previously, Chiang (2005) provided the evidence that their constituent models could not work together. (Chiang et al.,2008) thought one of its reasons is the limitation of MERT(Och,2003) with many features. We think there are two other reasons in addition to their suggestion. On the one hand, their models are heuristic, and they are not sensitive for other features such as boundary word information. However, in the previous work (Xiong et al., 2006), these features were shown to be helpful for the translation model. On the other hand, uniform combination of all the constituent models may cause a model bias, since some constituent types happen more often than others. In this paper, we will address the question above. First, a discriminative soft constraint model is proposed for each syntactic constituent type. The model can be integrated with much context information. We consider several classifiers with different accuracy to construct soft constraint models, and our aim is to study the effect of the 253 accuracy of the classifiers on the"
2011.mtsummit-papers.28,P09-1036,0,0.0295341,"Missing"
2011.mtsummit-papers.28,P01-1067,0,0.075868,"iscriminative classifiers for each constituent type and integrate all of them into the translation model with a unified form. The experimental results show that our method significantly improves the performance on the NIST05 Chinese-toEnglish translation task. 1 Introduction Hierarchical phrase-based translation model (Chiang, 2005) is a compromise of two popular translation models: syntax based model and phrase based model. It is a formal syntax grammar(Chiang, 2005; Wu, 1997), which does not take linguistic analysis into account when compared with other pure syntax systems (Liu et al., 2006;Yamada and Knight, 2001;Galley et al., 2006). It promises to improve the performance by adding syntax information to phrase based as well as formal syntax based translation models. Chiang (2005) first introduced syntax knowledge into the hierarchical phrase based model. To make the model sensitive to the syntax structure, a constituent feature was integrated into the translation model with the soft constraint method. It was defined as follows: it gains 1 for rules whose source side respect syntactic phrase boundary in the parse tree, and 0 otherwise. However, it did not achieve statistically significant improvement"
2011.mtsummit-papers.28,W06-3119,0,0.0594281,"Missing"
2011.mtsummit-papers.65,W10-1756,0,0.0133859,"test set because of a small number of features (Li and Eisner, 2009b) or a sparse feature of the non-terminal rule which only includes language model probability. In total, MR&DA on HG outperform baseline (incremental IHMM) using Cube Prunning up to +1.47 in BLEU score. 5.3 Third-Pass HG Decoding Firstly, the n-gram features are extracted from incremental TER and IHMM model via second-pass decoding. Then, we mix both n-grams on one of HG. Finally, we can search the HG during thirdpass decoding. Model Incremental TER Incremental IHMM NIST06 39.99 40.50 A unified framework (Pauls et al., 2009, Arun et al., 2010) was employed in MBR training and decoding. However, their methods aren’t based on the HG. In this paper, we present a unified framework of training and decoding on HG. On the other hand, there are several research on HG based decoding (Li et al., 2009a; Kumar et al., 2009; Denero et al., 2009), which use the n-gram probability to further improve the performance of the single system. In this paper, we compare three n-gram probability. In the view of HG mixture, our method is most similar to the mixture model based on HG in SMT. Duan et al. (2010) proposed a two-pass parameter optimization: fir"
2011.mtsummit-papers.65,J07-2003,0,0.0504719,"pment and test set) than incremental TER. We compare each-pass decoding of system combination based on HG. We report performance using incremental IHMM (Li et al., 2009) during first two-pass decoding. The components of mixture model in last-pass decoding are incremental TER and incremental IHMM. 1 The input of system combination is the same as Li et al. (2009). 574 5.1 First-pass HG Decoding During first-pass decoding, HG decoding with stack size 500 outperform the baseline (incremental IHMM) by +0.28 and +0.57 BLEU point on development and test set. Incremental IHMM model use Cube Prunning (Chiang 2007) and HG decoding use Cube Growing (Huang and Chiang 2007). Mixing model mixes the output of incremental IHMM and HG decoding model. Model Inc IHMM HG Decoding Mixing NIST06 39.34 39.47 39.62 NIST08 32.82 33.02 33.39 n-gram model 1-5gram_1+wp 1-5gram_2+wp 1-5gram_3+wp NIST06 40.28 39.97 39.91 NIST08 33.98 33.99 33.95 Table 3: The quality of second-pass decoding on the development and test set Table 2: The result of first-pass HG decoding on the development and test set 5.2 formance of three types of n-gram probability can be obtained when the setting is Vi+1-5gram_1+wp. It obtains +1.19 and +1."
2011.mtsummit-papers.65,P09-1064,0,0.0342338,"oding Firstly, the n-gram features are extracted from incremental TER and IHMM model via second-pass decoding. Then, we mix both n-grams on one of HG. Finally, we can search the HG during thirdpass decoding. Model Incremental TER Incremental IHMM NIST06 39.99 40.50 A unified framework (Pauls et al., 2009, Arun et al., 2010) was employed in MBR training and decoding. However, their methods aren’t based on the HG. In this paper, we present a unified framework of training and decoding on HG. On the other hand, there are several research on HG based decoding (Li et al., 2009a; Kumar et al., 2009; Denero et al., 2009), which use the n-gram probability to further improve the performance of the single system. In this paper, we compare three n-gram probability. In the view of HG mixture, our method is most similar to the mixture model based on HG in SMT. Duan et al. (2010) proposed a two-pass parameter optimization: first for n-gram probability weight for each system; second for mixture model weight whose number is the same as the number of system. DeNero et al. (2010) employed one-pass training for tuning the weight of n-gram posterior and model score, and don’t achieve the best tuning effect of each search"
2011.mtsummit-papers.65,N10-1141,0,0.0622202,"r each incoming hyperedge 6: initialize the quantities b ( wn ) and b of hyperedge e 7: b = p(e)hIant(v) 8: b (wn ) p(e) u ( I ant (v)  I ant (v) (wn )) 9: 10: 11: 12: 13: 14: if wnęe c(wn) += p(e|H) c(h(wn)) += p(e|H) Iv(wn) += b else I v ( wn )  b  b ( wn ) 15: ሺݓ ሻ ൌ 16: ݍሺݓ ሻ ൌ ሺ௪ ሻ ሺሺ௪ ሻሻ ூ ሺ௪ ሻ ூ 3.2 17: return n-gram model score p(wn) 18: n-gram count expectation c(wn) 19: n-gram posterior probability q(wn) üüüüüüüüüüüüüüüüüüüü Figure 3: the Computation of N-gram Model/Count Expectation/Posterior 3.1 tion of n-gram count, n-gram posterior (Kumar et al. 2009; DeNero et al., 2010) that is the ratio of ngram inside score and regular inside score of root. This algorithm1 can in principle compute ngram model, count expectation and posterior probability on HG. For each hypernode, we track four quantities: (1) the regular inside scores Iv that sum the scores of all derivations rooted at v and can be computed by inside recursion procedure; (2) n-gram inside scores Iv (wn) that sum the scores of all derivations rooted at v that contain ngram wn; (3) soft count c(wn) and c(h(wn)) that sum the posterior probabilities of all hyperedges introducing wn or h(wn) into HG. For each h"
2011.mtsummit-papers.65,C10-1036,0,0.0189412,"40.50 A unified framework (Pauls et al., 2009, Arun et al., 2010) was employed in MBR training and decoding. However, their methods aren’t based on the HG. In this paper, we present a unified framework of training and decoding on HG. On the other hand, there are several research on HG based decoding (Li et al., 2009a; Kumar et al., 2009; Denero et al., 2009), which use the n-gram probability to further improve the performance of the single system. In this paper, we compare three n-gram probability. In the view of HG mixture, our method is most similar to the mixture model based on HG in SMT. Duan et al. (2010) proposed a two-pass parameter optimization: first for n-gram probability weight for each system; second for mixture model weight whose number is the same as the number of system. DeNero et al. (2010) employed one-pass training for tuning the weight of n-gram posterior and model score, and don’t achieve the best tuning effect of each search space on model score. There are two major differences between our approach and above two approaches. Firstly, our model has three-pass training phase. Secondly, we have many weights for every n-gram probability and Vitebi score in each involved component mo"
2011.mtsummit-papers.65,D09-1115,0,0.0164445,"ich can significantly outperform sentence-level re-ranking methods and phrase-level combination (Rosti et. al., 2007). During constructing CN, word alignment between skeleton/backbone and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second problem, joint optimization (He and Toutanova, 2009) integrated CN construction and decoding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment"
2011.mtsummit-papers.65,P08-2021,0,0.0132356,"Rosti et al. 2007) for wordlevel combination is a widely adopted approach for combining SMT output, which can significantly outperform sentence-level re-ranking methods and phrase-level combination (Rosti et. al., 2007). During constructing CN, word alignment between skeleton/backbone and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second problem, joint optimization (He and Toutanova, 2009) integrated CN construction and decoding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al"
2011.mtsummit-papers.65,P09-1019,0,0.329372,"., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many natural language processing areas, would the technology still be efficient in system combination? (2) Models in SMT exhibit"
2011.mtsummit-papers.65,D08-1011,0,0.0181817,"al systems (Matusov et. al., 2006; Rosti et. al., 2007). Confusion network (CN) (Matusov et al. 2006 and Rosti et al. 2007) for wordlevel combination is a widely adopted approach for combining SMT output, which can significantly outperform sentence-level re-ranking methods and phrase-level combination (Rosti et. al., 2007). During constructing CN, word alignment between skeleton/backbone and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second problem, joint optimization (He and Toutanova, 2009) integrated CN construct"
2011.mtsummit-papers.65,D09-1125,0,0.0185308,"ed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second problem, joint optimization (He and Toutanova, 2009) integrated CN construction and decoding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as t"
2011.mtsummit-papers.65,W05-1506,0,0.272784,"Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many natural language processing areas, would the technology still be efficient in system combination? (2) Models in SMT exhibit spurious ambiguous (Li et al. 2009).We can resolve it by using the reestimation of n-gram probability o"
2011.mtsummit-papers.65,P07-1019,0,0.0196488,"mpare each-pass decoding of system combination based on HG. We report performance using incremental IHMM (Li et al., 2009) during first two-pass decoding. The components of mixture model in last-pass decoding are incremental TER and incremental IHMM. 1 The input of system combination is the same as Li et al. (2009). 574 5.1 First-pass HG Decoding During first-pass decoding, HG decoding with stack size 500 outperform the baseline (incremental IHMM) by +0.28 and +0.57 BLEU point on development and test set. Incremental IHMM model use Cube Prunning (Chiang 2007) and HG decoding use Cube Growing (Huang and Chiang 2007). Mixing model mixes the output of incremental IHMM and HG decoding model. Model Inc IHMM HG Decoding Mixing NIST06 39.34 39.47 39.62 NIST08 32.82 33.02 33.39 n-gram model 1-5gram_1+wp 1-5gram_2+wp 1-5gram_3+wp NIST06 40.28 39.97 39.91 NIST08 33.98 33.99 33.95 Table 3: The quality of second-pass decoding on the development and test set Table 2: The result of first-pass HG decoding on the development and test set 5.2 formance of three types of n-gram probability can be obtained when the setting is Vi+1-5gram_1+wp. It obtains +1.19 and +1.41 BLEU score on the development and test set respectivel"
2011.mtsummit-papers.65,P08-1067,0,0.0226696,"oding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many"
2011.mtsummit-papers.65,P09-1066,0,0.0992258,"e and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second problem, joint optimization (He and Toutanova, 2009) integrated CN construction and decoding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hy"
2011.mtsummit-papers.65,P09-1067,0,0.136782,"e and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second problem, joint optimization (He and Toutanova, 2009) integrated CN construction and decoding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hy"
2011.mtsummit-papers.65,D09-1005,0,0.0705847,"; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many natural language processing areas, would the technology"
2011.mtsummit-papers.65,P09-1065,0,0.0179254,"in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many natural language processing areas, would the technology still be efficient in system"
2011.mtsummit-papers.65,E06-1005,0,0.195268,"re compare two training procedures: minimum error training (MERT) on n-best and MR&DA on HG. The unified training and decoding approaches of HG based system combination outperform baseline using conventional Cube Prunning on Chinese-toEnglish benchmark corpus NIST08 test set. 1 Figure 1: The pipeline of three-pass training and decoding for HG generation, HG reranking and HG model mixture Introduction System combination has been proven that consensus translations are usually better than the translations of individual systems (Matusov et. al., 2006; Rosti et. al., 2007). Confusion network (CN) (Matusov et al. 2006 and Rosti et al. 2007) for wordlevel combination is a widely adopted approach for combining SMT output, which can significantly outperform sentence-level re-ranking methods and phrase-level combination (Rosti et. al., 2007). During constructing CN, word alignment between skeleton/backbone and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignme"
2011.mtsummit-papers.65,D08-1022,0,0.0213444,"and decoding into a decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many"
2011.mtsummit-papers.65,D09-1147,0,0.0168134,"same performance on test set because of a small number of features (Li and Eisner, 2009b) or a sparse feature of the non-terminal rule which only includes language model probability. In total, MR&DA on HG outperform baseline (incremental IHMM) using Cube Prunning up to +1.47 in BLEU score. 5.3 Third-Pass HG Decoding Firstly, the n-gram features are extracted from incremental TER and IHMM model via second-pass decoding. Then, we mix both n-grams on one of HG. Finally, we can search the HG during thirdpass decoding. Model Incremental TER Incremental IHMM NIST06 39.99 40.50 A unified framework (Pauls et al., 2009, Arun et al., 2010) was employed in MBR training and decoding. However, their methods aren’t based on the HG. In this paper, we present a unified framework of training and decoding on HG. On the other hand, there are several research on HG based decoding (Li et al., 2009a; Kumar et al., 2009; Denero et al., 2009), which use the n-gram probability to further improve the performance of the single system. In this paper, we compare three n-gram probability. In the view of HG mixture, our method is most similar to the mixture model based on HG in SMT. Duan et al. (2010) proposed a two-pass paramet"
2011.mtsummit-papers.65,P07-1040,0,0.450899,"procedures: minimum error training (MERT) on n-best and MR&DA on HG. The unified training and decoding approaches of HG based system combination outperform baseline using conventional Cube Prunning on Chinese-toEnglish benchmark corpus NIST08 test set. 1 Figure 1: The pipeline of three-pass training and decoding for HG generation, HG reranking and HG model mixture Introduction System combination has been proven that consensus translations are usually better than the translations of individual systems (Matusov et. al., 2006; Rosti et. al., 2007). Confusion network (CN) (Matusov et al. 2006 and Rosti et al. 2007) for wordlevel combination is a widely adopted approach for combining SMT output, which can significantly outperform sentence-level re-ranking methods and phrase-level combination (Rosti et. al., 2007). During constructing CN, word alignment between skeleton/backbone and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 200"
2011.mtsummit-papers.65,2006.amta-papers.25,0,0.0230242,"at consensus translations are usually better than the translations of individual systems (Matusov et. al., 2006; Rosti et. al., 2007). Confusion network (CN) (Matusov et al. 2006 and Rosti et al. 2007) for wordlevel combination is a widely adopted approach for combining SMT output, which can significantly outperform sentence-level re-ranking methods and phrase-level combination (Rosti et. al., 2007). During constructing CN, word alignment between skeleton/backbone and hypothesis and skeleton selection are two key issues in this approach. To solve first issue, Translation Error Rate (TER) 570 (Snover et al., 2006) based alignment was proposed in Sim et al. (2007); IHMM (He et al., 2008) got the better alignment using source language as pivot language; ITG-based alignment (Karakos et al., 2008) uses the ITG constrain during constructing CN; lattice-based system combination (Feng et al., 2009) normalized the alignment between the skeleton and the hypothesis into the lattice without breaking the phrase structure; incremental strategy (Rosti et al., 2008; Li et al., 2009) was added into the monolingual alignment algorithm including TER and IHMM in order to avoid pairwise alignment error. To solve second pr"
2011.mtsummit-papers.65,P06-2101,0,0.029268,"alue and weight; length function ሺǡ ǡ ሻ is the length of a derivation of each model in system combination. I is the number of system, and N is n-gram number. If we have two models of system combination and use the 5-gram probability model, we have 2*5+2+1=13 mixture factor numbers. The optimization of mixture factor is at third-pass training and third-pass decoding. We initially construct the hypergraph bottom-up. After the construction, we use lazy Algorithm 3 (Huang and Chiang, 2005) to generate k-best translations in three-pass decoding. 4 MR Training on HG To overcome the overfitting, Smith and Eisner (2006) smoothed the risk function by DA to ensure the search space is as large as possible before objective function achieves the optimal weight. The objective function can be defined as follow: L RH ( pO ,T )  T  EH ( pO ,T ) (3) 5 We use NIST MT06 data set including 1099 sentences as the development set and NIST MT08 data set including 1357 sentences from both newswire and web-data genres as the test set. To save computation effort, the result on the development and test set are reported in case-insensitive BLEU score. The above system generates the 10best of every sentence as input of system co"
2011.mtsummit-papers.65,C10-1123,0,0.015831,"decoder without skeleton selection; multiple CNs was first proposed in (Matusov et al.2006; Rosti et al., 2007), and was implemented via combining several different hypothesis alignment metrics (Du and Way, 2009). However, there are few works about training and decoding for system combination. Tranditional nbest training method train feature weights at limited hypothesis space and propogate the errors to target translation. These errors will severely hurt the translation quanlity. To alleviate such error, a HG was applied to many areas, such as translation rule extraction (Mi and Huang, 2008; Tu et al., 2010), model training (Li and Eisner, 2009b), decoding (Liu et al., 2009; Li et al., 2009a; Kumar et al., 2009; DeNero et al., 2009) in the field of machine translation, constituent parsing (Huang and Chiang, 2005). Overall, HG gives large search space for training and decoding which is expected to avoid the search error caused by the imprecision parameter estimation and early prunning. This paper introduces HG into system combination and explores to address three problems: (1) Since the HG technology gives better performance than conventional training and decoding method in many natural language p"
2012.iwslt-evaluation.8,P07-2045,0,0.0234432,"Missing"
2012.iwslt-evaluation.8,P11-1064,0,0.0553348,"Missing"
2012.iwslt-evaluation.8,P02-1038,0,0.282278,"Missing"
2012.iwslt-evaluation.8,P03-1021,0,0.0580619,"Missing"
2012.iwslt-evaluation.8,P02-1040,0,0.0934086,"Missing"
2012.iwslt-evaluation.8,N03-1033,0,0.0126533,"Missing"
2012.iwslt-evaluation.8,J03-1002,0,\N,Missing
2012.iwslt-evaluation.8,takezawa-etal-2002-toward,0,\N,Missing
2012.iwslt-evaluation.8,I05-3027,0,\N,Missing
2020.acl-main.324,N19-1388,0,0.065454,"e attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe et al., 2018; Lample et al., 2018a) has been proposed, using a combination of divers"
2020.acl-main.324,D18-1549,0,0.307174,"UNMT performance. Our experiments on a dataset with English translated to and from twelve other languages (including three language families and six language branches) show remarkable results, surpassing strong unsupervised individual baselines while achieving promising performance between non-English language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs. 1 Introduction Recently, neural machine translation (NMT) has been adapted to the unsupervised scenario in which NMT is trained without any bilingual data. Unsupervised NMT (UNMT) (Artetxe et al., 2018; Lample et al., 2018a) requires only monolingual corpora. UNMT achieves remarkable results by using a combination of diverse mechanisms (Lample et al., 2018b) such as an initialization with bilingual word embeddings, denoising auto-encoder (Vincent et al., 2010), back-translation (Sennrich et al., 2016a), and shared latent representation. More recently, Lample and Conneau (2019) achieves better UNMT performance by introducing the pretrained language model. However, conventional UNMT can only translate between a single language pair and cannot produce translation results for multiple language"
2020.acl-main.324,W19-5301,0,0.0735941,"Missing"
2020.acl-main.324,C18-1263,0,0.0276317,"e pairs. The other columns show results from Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe et al., 2018; Lample et a"
2020.acl-main.324,P15-1166,0,0.0246013,"7.58 25.05 14.09 9.75 25.84 10.90 23.80 10.07 13.09 28.82 12.41 15.79 19.57 27.59 16.62 11.05 28.56 12.77 25.25 10.92 14.33 32.38 14.78 15.47 19.28 26.79 15.62 10.57 27.78 12.03 25.52 11.11 14.33 31.28 13.83 15.93 20.00 27.80 17.21 11.58 28.62 13.12 25.98 11.22 15.17 32.43 15.30 Average 15.61 17.15 19.13 18.63 19.53 Table 5: The +FT column shows BLEU scores from further training of the MUNMT and LBKD model on the English to non-English language pairs. The other columns show results from Table 2. 7 Related Work Multilingual NMT has attracted much attention in the machine translation community. Dong et al. (2015) first extended NMT from the translation of a single language pair to multiple language pairs, using a shared encoder and multiple decoders and 3532 Corpus SM MUNMT +FT LBKD +FT Cs-En De-En Es-En Et-En Fi-En Fr-En Hu-En It-En Lt-En Lv-En Ro-En Tr-En 20.62 21.31 25.53 19.48 7.62 25.86 14.48 24.33 1.72 0.95 28.52 12.99 20.09 21.95 25.37 19.60 7.19 25.41 14.54 24.77 14.04 14.90 28.38 15.65 21.50 22.41 26.24 21.61 8.06 26.30 15.99 25.54 15.27 15.57 29.61 18.47 21.25 22.81 26.59 21.31 7.80 26.48 15.34 25.35 15.84 15.33 30.18 17.35 22.17 23.07 26.78 22.61 8.34 26.76 16.07 25.86 16.86 15.87 30.39 19."
2020.acl-main.324,N16-1101,0,0.0218044,"15.99 25.54 15.27 15.57 29.61 18.47 21.25 22.81 26.59 21.31 7.80 26.48 15.34 25.35 15.84 15.33 30.18 17.35 22.17 23.07 26.78 22.61 8.34 26.76 16.07 25.86 16.86 15.87 30.39 19.48 Average 16.95 19.32 20.55 20.47 21.19 Table 6: The +FT column shows BLEU scores from further training of the MUNMT and LBKD model on the non-English to English language pairs. The other columns show results from Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) an"
2020.acl-main.324,R19-1050,0,0.0409383,"Missing"
2020.acl-main.324,N16-1162,0,0.0752553,"Missing"
2020.acl-main.324,Q17-1024,0,0.0420139,"Missing"
2020.acl-main.324,P07-2045,0,0.00631129,"n of the MUNMT and LBUNMT models, respectively, after encoding M j (Xi1 ) generated by the previous MUNMT model in the L1 → Lj direction. X j (M 1 (Xij )) and LB j (M 1 (Xij )) denote the softened Lj sentence probability distribution of the MUNMT and LBUNMT models, respectively, after encoding M 1 (Xij ) generated by the previous MUNMT model in the Lj → L1 direction. 5 5.1 Experiments Datasets To establish an MUNMT system, we considered 13 languages from WMT monolingual news crawl datasets: Cs, De, En, Es, Et, Fi, Fr, Hu, It, Lt, Lv, Ro, and Tr. For preprocessing, we used the Moses tokenizer (Koehn et al., 2007). For cleaning, we only applied the Moses script clean-corpus-n.perl to remove lines in the monolingual data containing more than 50 words. We then used a shared vocabulary for all languages, with 80,000 sub-word tokens based on BPE (Sennrich et al., 2016b). The statistics of the data are presented in Table 1. For Cs,De,En, we randomly extracted 50M monolingual news crawl data after cleaning; For other languages, we used all news crawl data after cleaning as shown in Table 1. Language Cs De En Es Et Fi Fr Hu It Lt Lv Ro Tr Sentences Words Sub-words 50.00M 50.00M 50.00M 36.33M 3.00M 15.31M 50.0"
2020.acl-main.324,C18-1054,0,0.023553,"ing of the MUNMT and LBKD model on the non-English to English language pairs. The other columns show results from Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem o"
2020.acl-main.324,W18-6309,0,0.0284044,"ns show results from Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe et al., 2018; Lample et al., 2018a) has be"
2020.acl-main.324,W19-5330,1,0.703395,") concatenated two bilingual corpora as one monolingual corpus, and used monolingual embedding pretraining in the initialization step, to achieve remarkable results with some similar language pairs. Lample and Conneau (2019) achieved better UNMT performance by introducing a pretrained language model. Sun et al. (2019, 2020) proposed to train UNMT with cross-lingual language representation agreement, to further improve UNMT performance. Moreover, an unsupervised translation task that evaluated in the WMT19 news translation task (Barrault et al., 2019) attracted many researchers to participate (Marie et al., 2019; Li et al., 2019). For Multilingual UNMT, Xu et al. (2019) exploited multiple auxiliary languages for jointly boosting UNMT models via the Polygon-Net framework. Sen et al. (2019) proposed an MUNMT scheme that jointly trains multiple languages with a shared encoder and multiple decoders. In contrast with their use of multiple decoders, we have constructed a simpler MUNMT model with one encoder and one decoder. Further, we have extended the four or five languages used in their work to thirteen languages, for training our MUNMT model. 8 Conclusion and Future Work In this paper, we have introduc"
2020.acl-main.324,D18-1039,0,0.0403498,"LBKD model on the non-English to English language pairs. The other columns show results from Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs tra"
2020.acl-main.324,P18-1006,0,0.0664673,"(2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe et al., 2018; Lample et al., 2018a) has been proposed, using a combination of diverse mechanisms such as initialization with bilingual word embeddings, denoising autoencoder (Vincent et al., 2010), back-translation (Sennrich et al., 2016a), and shared latent representation. Lample et al. (2018b) concatenated two bilingual corpora as one monolingual corpus, and used monolingual embedding pr"
2020.acl-main.324,P19-1117,0,0.0411944,"rom Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe et al., 2018; Lample et al., 2018a) has been proposed, using"
2020.acl-main.324,W18-6327,0,0.027368,"nglish to English language pairs. The other columns show results from Table 3. multiple attention mechanisms, for each language. Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe e"
2020.acl-main.324,P19-1297,0,0.455981,"mple and Conneau (2019) achieves better UNMT performance by introducing the pretrained language model. However, conventional UNMT can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time (Wang et al., 2020). Multilingual UNMT (MUNMT) translating multiple languages at the same time can save substantial training time and resources. Moreover, the performance of MUNMT in similar languages can promote each other. Research on MUNMT has been limited and there are only a few pioneer studies. For example, Xu et al. (2019) and Sen et al. (2019) proposed a multilingual scheme that jointly trains multiple languages with multiple decoders. However, the performance of their MUNMT is much worse than our re-implemented individual baselines (shown in Tables 2 and 3) and the scale of their study is modest (i.e., 4-5 languages). In this paper, we empirically introduce an unified framework to translate among thirteen languages (including three language families and six language branches) using a single encoder and single decoder, making use of multilingual data to improve UNMT for all languages. On the basis of these empirical findings, we pr"
2020.acl-main.324,P18-1005,0,0.0216021,"bulary. The entire training of UNMT needs to consider back-translation between the two languages and their respective denoising processes. In summary, the entire UNMT model can be optimized by minimizing: Lall = LD + LB . 3 Denoising Auto-encoder LD = 2.3 2.4 A cross-lingual masked language model, which can encode two monolingual sentences into a shared latent space, is first trained. The pretrained crosslingual encoder is then used to initialize the whole UNMT model (Lample and Conneau, 2019). Compared with previous bilingual embedding pretraining (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019), this pretraining can provide much more crosslingual information, causing the UNMT model to achieve better performance and faster convergence. 2.2 where {C(Xi1 )} and {C(Xi2 )} are noisy sentences. PL1 →L1 and PL2 →L2 denote the reconstruction probability in language L1 and L2 , respectively. 3.1 (3) Multilingual UNMT (MUNMT) Multilingual Pretraining Motivated by Lample and Conneau (2019), we construct a multilingual masked language model, using a single encoder. For each language, the language model is trained by encoding the masked input and revertin"
2020.acl-main.324,P16-1009,0,0.571282,"language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs. 1 Introduction Recently, neural machine translation (NMT) has been adapted to the unsupervised scenario in which NMT is trained without any bilingual data. Unsupervised NMT (UNMT) (Artetxe et al., 2018; Lample et al., 2018a) requires only monolingual corpora. UNMT achieves remarkable results by using a combination of diverse mechanisms (Lample et al., 2018b) such as an initialization with bilingual word embeddings, denoising auto-encoder (Vincent et al., 2010), back-translation (Sennrich et al., 2016a), and shared latent representation. More recently, Lample and Conneau (2019) achieves better UNMT performance by introducing the pretrained language model. However, conventional UNMT can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time (Wang et al., 2020). Multilingual UNMT (MUNMT) translating multiple languages at the same time can save substantial training time and resources. Moreover, the performance of MUNMT in similar languages can promote each other. Research on MUNMT has been limited and there are only a"
2020.acl-main.324,P16-1162,0,0.832951,"language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs. 1 Introduction Recently, neural machine translation (NMT) has been adapted to the unsupervised scenario in which NMT is trained without any bilingual data. Unsupervised NMT (UNMT) (Artetxe et al., 2018; Lample et al., 2018a) requires only monolingual corpora. UNMT achieves remarkable results by using a combination of diverse mechanisms (Lample et al., 2018b) such as an initialization with bilingual word embeddings, denoising auto-encoder (Vincent et al., 2010), back-translation (Sennrich et al., 2016a), and shared latent representation. More recently, Lample and Conneau (2019) achieves better UNMT performance by introducing the pretrained language model. However, conventional UNMT can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time (Wang et al., 2020). Multilingual UNMT (MUNMT) translating multiple languages at the same time can save substantial training time and resources. Moreover, the performance of MUNMT in similar languages can promote each other. Research on MUNMT has been limited and there are only a"
2020.acl-main.324,P19-1119,1,0.531451,"to consider back-translation between the two languages and their respective denoising processes. In summary, the entire UNMT model can be optimized by minimizing: Lall = LD + LB . 3 Denoising Auto-encoder LD = 2.3 2.4 A cross-lingual masked language model, which can encode two monolingual sentences into a shared latent space, is first trained. The pretrained crosslingual encoder is then used to initialize the whole UNMT model (Lample and Conneau, 2019). Compared with previous bilingual embedding pretraining (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019), this pretraining can provide much more crosslingual information, causing the UNMT model to achieve better performance and faster convergence. 2.2 where {C(Xi1 )} and {C(Xi2 )} are noisy sentences. PL1 →L1 and PL2 →L2 denote the reconstruction probability in language L1 and L2 , respectively. 3.1 (3) Multilingual UNMT (MUNMT) Multilingual Pretraining Motivated by Lample and Conneau (2019), we construct a multilingual masked language model, using a single encoder. For each language, the language model is trained by encoding the masked input and reverting it with this encoder. This pretrained m"
2020.acl-main.324,D19-1089,0,0.0734585,"Missing"
2020.acl-main.324,P19-1583,0,0.0192416,"Luong et al. (2016) translated multiple source languages to multiple target languages using a combination of multiple encoders and multiple decoders. Firat et al. (2016) used a shared attention mechanism but multiple encoders and decoders for each language. Ha et al. (2016) and Johnson et al. (2017) proposed a simpler method to use one encoder and one decoder to translate between multiple languages. Recently, many methods (Lakew et al., 2018; Platanios et al., 2018; Sachan and Neubig, 2018; Blackwood et al., 2018; Lu et al., 2018; Wang et al., 2019a; Aharoni et al., 2019; Wang et al., 2019b; Wang and Neubig, 2019) have been proposed to boost multilingual NMT performance. In particular, Tan et al. proposed a knowledge distillation method (Tan et al., 2019b) and a language clustering method (Tan et al., 2019a) to improve the performance of multilingual NMT. Ren et al. (2018) propose a triangular architecture to tackle the problem of low-resource pairs translation by introducing another rich language. To further tackle the problem of low-resource pairs translation, UNMT (Artetxe et al., 2018; Lample et al., 2018a) has been proposed, using a combination of diverse mechanisms such as initialization with bil"
2020.acl-main.324,W19-5325,0,\N,Missing
2020.acl-main.380,P07-1034,0,\N,Missing
2020.acl-main.380,D14-1162,0,\N,Missing
2020.acl-main.380,N16-2013,0,\N,Missing
2020.acl-main.380,S18-2005,0,\N,Missing
2020.acl-main.380,D17-1323,0,\N,Missing
2020.autosimtrans-1.2,P17-4012,0,0.0519902,"d as the optimization function to train our model, which has a learning rate of 0.0001 and a mini-batch size of 8. The hyper-parameters λst , λ1 and λ2 are 0.5, 0.0001 and 10 respectively. And the train frequency of the ST model is 5 times then the discriminator. We used the BLEU (Papineni et al., 2002) metric to evaluate our ST models. We try five settings on Speech Translation. The Pipeline model cascades an ASR and an MT model. For the ASR model, we use an end-to-end speech recognition model similar to LAS and trained on CCMT 2019-BSTC. For the MT model, we use open source toolkit OpenNMT (Klein et al., 2017) to train an NMT model. The end-to-end model (described in section 2) does not make any use of source language transcripts. The pre-trained model is the same as the end-to-end model, but its encoder is initialized with a pre-trained ASR model. And the pretrained ASR model is trained using Aishell (Bu et al., 2017), a 178 hours Chinese Mandarin speech corpus, which has the same language as our chosen speech translation corpus. The multitask model is a one-to-many method, where the ASR and ST tasks share an encoder. The Adversarial Training is the approach proposed in this paper. 3.3 the best re"
2020.autosimtrans-1.2,2020.iwslt-1.8,0,0.274171,"Missing"
2020.autosimtrans-1.2,P02-1040,0,0.11526,"512 units to predict words in the vocabulary. For the discriminator model, we use a linear layer with 128 units at the bottom of the model. Then, using 2 layers onedimensional CNN, from bottom to top, the window size is 2, the stride is 1, and the window size is 3, the stride is 1. Adam (Kingma and Ba, 2014) was used as the optimization function to train our model, which has a learning rate of 0.0001 and a mini-batch size of 8. The hyper-parameters λst , λ1 and λ2 are 0.5, 0.0001 and 10 respectively. And the train frequency of the ST model is 5 times then the discriminator. We used the BLEU (Papineni et al., 2002) metric to evaluate our ST models. We try five settings on Speech Translation. The Pipeline model cascades an ASR and an MT model. For the ASR model, we use an end-to-end speech recognition model similar to LAS and trained on CCMT 2019-BSTC. For the MT model, we use open source toolkit OpenNMT (Klein et al., 2017) to train an NMT model. The end-to-end model (described in section 2) does not make any use of source language transcripts. The pre-trained model is the same as the end-to-end model, but its encoder is initialized with a pre-trained ASR model. And the pretrained ASR model is trained u"
2020.autosimtrans-1.2,N16-1109,0,0.355097,"Missing"
2020.ccl-1.102,D14-1179,0,0.0343802,"Missing"
2020.ccl-1.102,N19-1423,0,0.0409894,"Missing"
2020.ccl-1.102,W18-3002,0,0.102466,", u2 , ..., uN }, where N is the number of utterances in the dialogue, ui = {w1 , w2 , ..., wL } represents the ith(1 ≤ i ≤ N ) utterance in the dialogue that consists of L words, our goal is to analyze the emotion of each utterance in the dialogue. To solve this task, we propose a hierarchical model CAN-GRU and extend three variants, CAN-GRUA, CAN-biGRU and CANbiGRUA(illustrated in Fig. 1). 3.2 Text Feature Extraction In this section, we discuss the first layer of the model. Like (Poria et al., 2017), we use convolutional neural network to extract the features of the utterance. Inspired by (Gao et al., 2018), in order to capture the contextual information of long text effectively, we use convolutional self-attention network(CAN) instead of traditional CNN network. Proceedings of the 19th China National Conference on Computational Linguistics, pages 1101-1111, Hainan, China, October 30 - Novermber 1, 2020. (c) Technical Committee on Computational Linguistics, Chinese Information Processing Society of China 02 0 Computational Linguistics L2 Figure 1: The architecture of our proposed CAN-biGRUA. In the first layer, convolutional neural network and self-attention mechanism are used to extract text fe"
2020.ccl-1.102,D19-1015,0,0.0262627,"erances by LSTM. Considering inter-speaker dependency relations, conversational memory network(CMN)(Hazarika et al., 2018b) has been proposed to model the speaker-based emotion using memory network and summarize task-specific details by attention mechanisms. ICON(Hazarika et al., 2018a) improves the CMN, it hierarchically models the self-speaker emotion and inter-speaker emotion into global memories. DialogueRNN(Majumder et al., 2019) uses emotion GRU and global GRU to model inter-party relation, and uses party GRU to model relation between two sequential states of the same party. DialogueGCN(Ghosal et al., 2019) improves DialogueRNN by graph convolutional network, and it can hold richer context relevant to emotion. However, these models may be too complex for small textual dialogue datasets. In this paper, we study on the EmotionX Challenge(Hsu and Ku, 2018), Dialogue Emotion Recognition Challenge, which aims to recognize the emotion of each utterance in dialogues. According to the overview of this task, the best team(Khosla, 2018) proposes a CNN-DCNN auto encoder based model, which includes a convolutional encoder and a deconvolutional decoder. The second place team(Luo et al., 2018) mainly uses BiL"
2020.ccl-1.102,D18-1280,0,0.0153324,"ng-range contextual information. Later, attention mechanism(Bahdanau et al., 2015) is proposed to solve this problem. Recently, self-attention(Vaswani et al., 2017) is widely used since it can solve the long-term dependence problem of text effectively. Recent years, more and more researchers focus on emotion recognition in conversation. This task aims to recognize the emotion of each utterance in dialogues. bcLSTM(Poria et al., 2017) extracts textual features by CNN and model the sequence of utterances by LSTM. Considering inter-speaker dependency relations, conversational memory network(CMN)(Hazarika et al., 2018b) has been proposed to model the speaker-based emotion using memory network and summarize task-specific details by attention mechanisms. ICON(Hazarika et al., 2018a) improves the CMN, it hierarchically models the self-speaker emotion and inter-speaker emotion into global memories. DialogueRNN(Majumder et al., 2019) uses emotion GRU and global GRU to model inter-party relation, and uses party GRU to model relation between two sequential states of the same party. DialogueGCN(Ghosal et al., 2019) improves DialogueRNN by graph convolutional network, and it can hold richer context relevant to emot"
2020.ccl-1.102,N18-1193,0,0.0208552,"ng-range contextual information. Later, attention mechanism(Bahdanau et al., 2015) is proposed to solve this problem. Recently, self-attention(Vaswani et al., 2017) is widely used since it can solve the long-term dependence problem of text effectively. Recent years, more and more researchers focus on emotion recognition in conversation. This task aims to recognize the emotion of each utterance in dialogues. bcLSTM(Poria et al., 2017) extracts textual features by CNN and model the sequence of utterances by LSTM. Considering inter-speaker dependency relations, conversational memory network(CMN)(Hazarika et al., 2018b) has been proposed to model the speaker-based emotion using memory network and summarize task-specific details by attention mechanisms. ICON(Hazarika et al., 2018a) improves the CMN, it hierarchically models the self-speaker emotion and inter-speaker emotion into global memories. DialogueRNN(Majumder et al., 2019) uses emotion GRU and global GRU to model inter-party relation, and uses party GRU to model relation between two sequential states of the same party. DialogueGCN(Ghosal et al., 2019) improves DialogueRNN by graph convolutional network, and it can hold richer context relevant to emot"
2020.ccl-1.102,W18-3507,0,0.304819,"19) uses emotion GRU and global GRU to model inter-party relation, and uses party GRU to model relation between two sequential states of the same party. DialogueGCN(Ghosal et al., 2019) improves DialogueRNN by graph convolutional network, and it can hold richer context relevant to emotion. However, these models may be too complex for small textual dialogue datasets. In this paper, we study on the EmotionX Challenge(Hsu and Ku, 2018), Dialogue Emotion Recognition Challenge, which aims to recognize the emotion of each utterance in dialogues. According to the overview of this task, the best team(Khosla, 2018) proposes a CNN-DCNN auto encoder based model, which includes a convolutional encoder and a deconvolutional decoder. The second place team(Luo et al., 2018) mainly uses BiLSTM with a self-attentive architecture on the top for the classiffication. The third place team(Saxena et al., 2018) proposes a hierarchical network based on attention models and conditional random fields(CRF). For a meaningful comparison, we use the same dataset and metric as the challenge in our study. 3 3.1 Method Task Definition Given a dialogue dia = {u1 , u2 , ..., uN }, where N is the number of utterances in the dialo"
2020.ccl-1.102,D14-1181,0,0.0034927,"mputational Linguistics speaker Phoebe Rachel Wayne Joey Gary Chandler Gary Chandler utterance Can I tell you a little secret? Yeah! Hey Joey, I want to talk to you. Yeah? Hey Chandler, what are you doing here? Gary, I’m here to report a crime. Yeah? It is a crime that you and I don’t spend more time together. emotion neutral joy neutral neutral suprise neutral suprise neutral Table 1: The word ’Yeah’ expresses different emotions in the different contexts. CC L2 02 0 work(Hochreiter and Schmidhuber, 1997), Gated Recurrent Unit Network(Cho et al., 2014) and textual Convolutional Neural Network(Kim, 2014). However, these models don’t perform well when the texts are too long, because it’s hard to capture the long-range contextual information. Later, attention mechanism(Bahdanau et al., 2015) is proposed to solve this problem. Recently, self-attention(Vaswani et al., 2017) is widely used since it can solve the long-term dependence problem of text effectively. Recent years, more and more researchers focus on emotion recognition in conversation. This task aims to recognize the emotion of each utterance in dialogues. bcLSTM(Poria et al., 2017) extracts textual features by CNN and model the sequence"
2020.ccl-1.102,W18-3506,0,0.0713314,"DialogueGCN(Ghosal et al., 2019) improves DialogueRNN by graph convolutional network, and it can hold richer context relevant to emotion. However, these models may be too complex for small textual dialogue datasets. In this paper, we study on the EmotionX Challenge(Hsu and Ku, 2018), Dialogue Emotion Recognition Challenge, which aims to recognize the emotion of each utterance in dialogues. According to the overview of this task, the best team(Khosla, 2018) proposes a CNN-DCNN auto encoder based model, which includes a convolutional encoder and a deconvolutional decoder. The second place team(Luo et al., 2018) mainly uses BiLSTM with a self-attentive architecture on the top for the classiffication. The third place team(Saxena et al., 2018) proposes a hierarchical network based on attention models and conditional random fields(CRF). For a meaningful comparison, we use the same dataset and metric as the challenge in our study. 3 3.1 Method Task Definition Given a dialogue dia = {u1 , u2 , ..., uN }, where N is the number of utterances in the dialogue, ui = {w1 , w2 , ..., wL } represents the ith(1 ≤ i ≤ N ) utterance in the dialogue that consists of L words, our goal is to analyze the emotion of each"
2020.ccl-1.102,D14-1162,0,0.0833501,"tion sadness neutral 498 6530 514 9855 others 5006 2133 Table 2: Statistics of the datasets. 4.2 Evaluation Metric We use the unweighted accuracy(UWA) as the evaluation metric instead of the weighted accuracy(WA), the same as the challenge. This is because WA is easily influced by the large proportion of neutral emotion and UWA can help to make a meaningful comparision. c c X 1X ai , W A = weighti ai c (20) i=1 02 i=1 0 UWA = Where ai is the accuracy of class i and weighti is the percentage of the class i. 4.3 Experimental Setting Baselines CC 4.4 L2 We use 300-dimensional pre-trained GloVe2 (Pennington et al., 2014) word-embeddings which is trained from web data. We use three distinct convolution filters of sizes 3, 4, and 5 respectively, each having 100 feature maps. The dimension of the hidden states of the GRU is set to 300. We use adam(Kingma and Ba, 2015) optimizer and set the initial learning rate as 1.0 × 10−4 . The learning rate is halved every 20 epochs during training. Dropout probability is set to 0.3. In experiments, we compare our proposed model with the following models. CNN-DCNN: The winner of EmotionX Challenge(Khosla, 2018). The model contains a convolutional encoder and a deconvolutiona"
2020.ccl-1.102,D15-1303,0,0.0257801,"an important component of human intelligence, emotional intelligence is defined as the ability to perceive, integrate, understand and regulate emotions(Mayer et al., 2008). Emotion is the essential difference between human and machine, so emotion understanding is an important research direction of artificial intelligence. As the most common way for people to communicate in daily life, dialogue contains a wealth of emotions. Recognising the emotions in the conversation is of great significance in intelligent customer service, medical systems, education systems and other aspects. According to (Poria et al., 2015), textual features usually contain more emotional information than video or audio features, so we focus on the emotion analysis of dialogue text and aims to recognize the emotion of each utterrance in dialogues. There are some challenges in this task. First, the length of an utterance may be too long, making it difficult to capture contextual information. Furthermore, a dialogue usually contains lots of utterances, therefore, it’s hard to grasp long-term contextual relations between utterances. Second, the same word may express different emotions in different contexts. For example, in Table 1,"
2020.ccl-1.102,P17-1081,0,0.310515,"twork(Cho et al., 2014) and textual Convolutional Neural Network(Kim, 2014). However, these models don’t perform well when the texts are too long, because it’s hard to capture the long-range contextual information. Later, attention mechanism(Bahdanau et al., 2015) is proposed to solve this problem. Recently, self-attention(Vaswani et al., 2017) is widely used since it can solve the long-term dependence problem of text effectively. Recent years, more and more researchers focus on emotion recognition in conversation. This task aims to recognize the emotion of each utterance in dialogues. bcLSTM(Poria et al., 2017) extracts textual features by CNN and model the sequence of utterances by LSTM. Considering inter-speaker dependency relations, conversational memory network(CMN)(Hazarika et al., 2018b) has been proposed to model the speaker-based emotion using memory network and summarize task-specific details by attention mechanisms. ICON(Hazarika et al., 2018a) improves the CMN, it hierarchically models the self-speaker emotion and inter-speaker emotion into global memories. DialogueRNN(Majumder et al., 2019) uses emotion GRU and global GRU to model inter-party relation, and uses party GRU to model relatio"
2020.coling-main.248,D19-1606,0,0.0611816,"Missing"
2020.coling-main.248,2020.tacl-1.5,0,0.0175406,"is not obvious, we didn’t apply this method. 3.2 Results and Analysis In this section, we present the experimental results and make some analysis. The extractive reading comprehension task is usually evaluated with two metrics: exact match(EM) and F1, both metrics are the higher the better. EM checks whether the answer extracted by the model are exactly the same as the correct answer. F1 does not require the predicted result to be exactly the same as the correct answer, it measures the degree of word overlap at token level. All the results are shown in Table 2. model soft label human SpanBERT(Joshi et al., 2020) TASE-RoBERTa(Segal et al., 2019) ALBERT(Lan et al., 2020) not used ALBERT(reproduced) not used label smoothing word overlapping distribution prediction SQuAD 2.0 EM F1 NewsQA EM F1 QUOREF EM F1 86.8 85.7 87.4 86.9 86.9 87.2 87.6 46.5 63.7 64.0 64.1 65.0 86.8 79.4 85.5 86.3 86.8 87.4 89.5 88.7 90.2 90.0 90.1 90.2 90.4 69.4 73.6 74.0 74.0 74.5 74.7 93.4 85.0 89.4 90.4 90.9 91.0 Table 2: Results of ALBERT-xxlarge with different data augmentation on SQuAD 2.0,NewsQA and QUOREF datasets From Table 2, we can find that the performance of the reproduced ALBERT has a small gap with the original paper."
2020.coling-main.248,P18-2124,0,0.0207048,"he next iterations, we select different parts to decode, until all samples in T have predicted label, i.e. T 0 = {(x, y 0 )|y 0 = Fi (x)}. Since F is trained on a large-scale data set {T2 , T3 , . . . , Tn }, the predicted distribution q 0 can be considered as composed all the Q&A patterns in {T2 , T3 , . . . , Tn }. Thus, the potentially correct candidate answers (the Q&A patterns that appeared in the training set, to be more precise) will have higher probability, which will become a more informative guidance for the MRC model. 3 3.1 Experiment Experimental Settings This paper uses SQuAD 2.0(Rajpurkar et al., 2018), NewsQA(Trischler et al., 2017), QUOREF(Dasigi et al., 2019) in the experiments. NewsQA is gathered from CNN articles, and the others are from English Wikipedia. But QUOREF is more focused on coreference resolution. SQuAD 2.0 and NewsQA both contain unanswerable questions, while QUOREF doesn’t. The size of these datasets is shown in Table 1. paragraphs Q&A pairs Avg. Q&A pairs for a paragraph Avg. len of paragraphs Avg. len of answer spans has answer Q&A pairs no answer Q&A pairs SQuAD 2.0 NewsQA QUOREF 19035 130319 6.85 116.6 3.16 86821 43498 12107 102769 8.49 616.2 4.04 80901 21868 3771 193"
2020.coling-main.248,W17-2623,0,0.0310308,"fferent parts to decode, until all samples in T have predicted label, i.e. T 0 = {(x, y 0 )|y 0 = Fi (x)}. Since F is trained on a large-scale data set {T2 , T3 , . . . , Tn }, the predicted distribution q 0 can be considered as composed all the Q&A patterns in {T2 , T3 , . . . , Tn }. Thus, the potentially correct candidate answers (the Q&A patterns that appeared in the training set, to be more precise) will have higher probability, which will become a more informative guidance for the MRC model. 3 3.1 Experiment Experimental Settings This paper uses SQuAD 2.0(Rajpurkar et al., 2018), NewsQA(Trischler et al., 2017), QUOREF(Dasigi et al., 2019) in the experiments. NewsQA is gathered from CNN articles, and the others are from English Wikipedia. But QUOREF is more focused on coreference resolution. SQuAD 2.0 and NewsQA both contain unanswerable questions, while QUOREF doesn’t. The size of these datasets is shown in Table 1. paragraphs Q&A pairs Avg. Q&A pairs for a paragraph Avg. len of paragraphs Avg. len of answer spans has answer Q&A pairs no answer Q&A pairs SQuAD 2.0 NewsQA QUOREF 19035 130319 6.85 116.6 3.16 86821 43498 12107 102769 8.49 616.2 4.04 80901 21868 3771 19345 5.13 326.0 1.47 19345 0 Table"
2020.coling-main.374,D18-1549,0,0.0786934,"e the robustness of the UNMT based systems. First of all, we clearly defined two types of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios. 1 Introduction Recently, unsupervised neural machine translation (UNMT) has attracted great interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019; Sun et al., 2020b). Typically, UNMT relies solely on monolingual corpora rather than bilingual parallel data in supervised neural machine translation (SNMT) to model translations between the source language and target language and has achieved remarkable results on several translation tasks (Conneau and Lample, 2019). However, previous work only focus on how to build stateof-the-art UNMT systems on the clean data and ignore the robustness of UNMT on the noisy data. In the real-world scenario, there often exists"
2020.coling-main.374,P18-1163,0,0.0194499,"put sentences, for example, word character misspelling, replacement, or word position misordering, etc. The translation model is sensitive to these perturbations, leading to various errors even the perturbations are small. The existing neural translation system, which lacks of robustness, is difficult to be widely applied to the noisy-data scenario (denoted as noisy scenario in the following sections). Therefore, the robustness of neural translation system is not only worthy of being studied, but also very essential in the real-world scenarios. The robustness of SNMT (Belinkov and Bisk, 2018; Cheng et al., 2018; Cheng et al., 2019; Karpukhin et al., 2019) has been well-studied. However, most previous work only focus on the effect of the word substitution for translation performance, and ignore the effect of word order for translation performance. Moreover, the noisy robustness of UNMT is much more difficult since the noisy input data may be relieved in some degree by the SNMT due to its supervised check in training. Currently, there is no study considering the noisy robustness of the UNMT. In this paper, we first define two types of noises which cover the noise types mentioned above, i.e., word nois"
2020.coling-main.374,P19-1425,0,0.025815,"xample, word character misspelling, replacement, or word position misordering, etc. The translation model is sensitive to these perturbations, leading to various errors even the perturbations are small. The existing neural translation system, which lacks of robustness, is difficult to be widely applied to the noisy-data scenario (denoted as noisy scenario in the following sections). Therefore, the robustness of neural translation system is not only worthy of being studied, but also very essential in the real-world scenarios. The robustness of SNMT (Belinkov and Bisk, 2018; Cheng et al., 2018; Cheng et al., 2019; Karpukhin et al., 2019) has been well-studied. However, most previous work only focus on the effect of the word substitution for translation performance, and ignore the effect of word order for translation performance. Moreover, the noisy robustness of UNMT is much more difficult since the noisy input data may be relieved in some degree by the SNMT due to its supervised check in training. Currently, there is no study considering the noisy robustness of the UNMT. In this paper, we first define two types of noises which cover the noise types mentioned above, i.e., word noise and word order noi"
2020.coling-main.374,P18-2006,0,0.0213336,"ask of WMT19 by combining UNMT and unsupervised statistical machine translation. However, previous work only focuses on how to build state-of-the-art UNMT systems and ignore the robustness of UNMT on the noisy data. In this paper, we propose adversarial training methods with denoising process in UNMT training to improve the robustness of the UNMT systems. Moreover, our proposed methods could improve the UNMT performance even in clean scenarios. Actually, Belinkov and Bisk (2018) pointed out that synthetic and natural noise both influenced the translation performance. Belinkov and Bisk (2018), Ebrahimi et al. (2018), and Karpukhin et al. (2019) designed character-level noise, which affects the spelling of a single word, to improve the model robustness. Meanwhile, both textual and phonetic embeddings were used to improve the robustness of SNMT to homophone noises (Liu et al., 2019). Adversarial examples, generated by gradient-based method, attacked the translation model to improve the robustness of SNMT (Cheng et al., 2019). In contrast with this work, we applied adversarial perturbation to the denoising training of UNMT , instead of translation training, to enhance the learning ability of UNMT model. 424"
2020.coling-main.374,D17-1215,0,0.08645,"Missing"
2020.coling-main.374,D19-5506,0,0.0949022,"er misspelling, replacement, or word position misordering, etc. The translation model is sensitive to these perturbations, leading to various errors even the perturbations are small. The existing neural translation system, which lacks of robustness, is difficult to be widely applied to the noisy-data scenario (denoted as noisy scenario in the following sections). Therefore, the robustness of neural translation system is not only worthy of being studied, but also very essential in the real-world scenarios. The robustness of SNMT (Belinkov and Bisk, 2018; Cheng et al., 2018; Cheng et al., 2019; Karpukhin et al., 2019) has been well-studied. However, most previous work only focus on the effect of the word substitution for translation performance, and ignore the effect of word order for translation performance. Moreover, the noisy robustness of UNMT is much more difficult since the noisy input data may be relieved in some degree by the SNMT due to its supervised check in training. Currently, there is no study considering the noisy robustness of the UNMT. In this paper, we first define two types of noises which cover the noise types mentioned above, i.e., word noise and word order noise. Then we empirically ∗"
2020.coling-main.374,P07-2045,0,0.00911683,"nal embedding (Position AT), and the combination of word and positional adversarial training (Both AT), all of which enrich robust information via adversarial perturbation. 5 Experiments 5.1 Datasets We considered two language pairs to do simulated experiments on the Fr↔En and German(De)↔En translation tasks. We used 50 million sentences from WMT monolingual news crawl datasets for each language. To make our experiments comparable with previous work (Conneau and Lample, 2019), we reported results on newstest2014 for Fr↔En and newstest2016 for De↔En. For preprocessing, we used Moses tokenizer (Koehn et al., 2007)1 for all languages. For cleaning, we only applied the Moses script clean-corpus-n.perl to remove lines in the monolingual data containing more than 50 tokens. For BPE (Sennrich et al., 2016b), we used a shared vocabulary for every language pair with 60K subword tokens based on BPE. 5.2 UNMT Settings We used a transformer-based XLM toolkit2 and followed settings of Conneau and Lample (2019) for UNMT: 6 layers for the encoder and the decoder. The dimension of hidden layers was set to 1024. The Adam optimizer (Kingma and Ba, 2015) was used to optimize the model parameters. The initial learning r"
2020.coling-main.374,P19-1291,0,0.0385075,"Missing"
2020.coling-main.374,W19-5330,1,0.743883,"noisy input. 6 Related Work Recently, UNMT (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019) that relies solely on monolingual corpora in each language via bilingual word embedding initialization, denoising auto-encoder, back-translation and sharing latent representations. More recently, Conneau and Lample (2019) and Song et al. (2019) introduced the pretrained cross-lingual language model to achieve state-of-the-art UNMT performance. Sun et al. (2020a) extended UNMT to the multilingual UNMT training on a large scale of European languages. Marie et al. (2019) won the first place in the unsupervised translation task of WMT19 by combining UNMT and unsupervised statistical machine translation. However, previous work only focuses on how to build state-of-the-art UNMT systems and ignore the robustness of UNMT on the noisy data. In this paper, we propose adversarial training methods with denoising process in UNMT training to improve the robustness of the UNMT systems. Moreover, our proposed methods could improve the UNMT performance even in clean scenarios. Actually, Belinkov and Bisk (2018) pointed out that synthetic and natural noise both influenced t"
2020.coling-main.374,D18-1050,0,0.0202074,"ut with different level of noise was 22.76 BLEU scores more in average for the word noise scenario, and 24.09 BLEU scores more in average for the word order noise scenario, compared with the UNMT system. These further demonstrate that our proposed Both AT mechanism is robust and can effectively alleviate the impact of two types of noise on translation performance. 5.5 Evaluation on MTNT dataset To better assess the effectiveness of our proposed adversarial training methods, we investigated the performance of UNMT with Both AT framework on the MTNT dataset, which is a noisy dataset proposed by Michel and Neubig (2018). The detailed statistics of MTNT data set is presented as shown in Table 3. To make our experiments comparable with previous work (Michel and Neubig, 2018; Zhou et al., 2019), we used the same MTNT parallel training data to fine-tune our proposed +Both AT system and used sacreBLEU (Post, 2018) to evaluate the translation performance. Corpus en-fr fr-en Training set Valid set Test set 36,058 852 1,020 19,161 886 1,022 Methods en-fr fr-en Michel and Neubig (2018) +Fine-tuning Zhou et al. (2019) +Fine-tuning 21.77 29.73 n/a n/a 23.27 30.29 24.50 31.70 31.60 39.00 33.80 41.30 +Both AT +Fine-tunin"
2020.coling-main.374,W18-6319,0,0.0183283,"e impact of two types of noise on translation performance. 5.5 Evaluation on MTNT dataset To better assess the effectiveness of our proposed adversarial training methods, we investigated the performance of UNMT with Both AT framework on the MTNT dataset, which is a noisy dataset proposed by Michel and Neubig (2018). The detailed statistics of MTNT data set is presented as shown in Table 3. To make our experiments comparable with previous work (Michel and Neubig, 2018; Zhou et al., 2019), we used the same MTNT parallel training data to fine-tune our proposed +Both AT system and used sacreBLEU (Post, 2018) to evaluate the translation performance. Corpus en-fr fr-en Training set Valid set Test set 36,058 852 1,020 19,161 886 1,022 Methods en-fr fr-en Michel and Neubig (2018) +Fine-tuning Zhou et al. (2019) +Fine-tuning 21.77 29.73 n/a n/a 23.27 30.29 24.50 31.70 31.60 39.00 33.80 41.30 +Both AT +Fine-tuning Table 3: Statistics of MTNT data set. Table 4: BLEU score on the En-Fr MTNT test set. As shown in Table 4, Our proposed +Both AT system significantly outperformed the previous work(Michel and Neubig, 2018; Zhou et al., 2019) by approximately 10 BLEU scores. The performance of our proposed sys"
2020.coling-main.374,P16-1009,0,0.166098,"e the model learning ability by introducing noise in the form of random token deleting and swapping in this input sentence. The denoising auto-encoder, which encodes a noisy version and reconstructs it with the decoder in the same language, acts as a language model during UNMT training. It is optimized by minimizing the objective function: LD = |X| X − log PL1 →L1 (Xi |C(Xi )) + |Y | X − log PL2 →L2 (Yi |C(Yi )), (2) i=1 i=1 where {C(Xi )} and {C(Yi )} are noisy sentences. PL1 →L1 and PL2 →L2 denote the reconstruction probability in the language L1 and L2 , respectively. Back-translation: It (Sennrich et al., 2016a) is adapted to train a translation system across different languages based on monolingual corpora. The pseudo-parallel sentence pairs {(YM (Xi ), Xi )} and {(XM (Yi ), Yi )} produced by the model at the previous iteration would be used to train the new translation model. The UNMT model would be improved through iterative back-translation. Therefore, the back-translation probability would be optimized by minimizing LB = |X| X − log PL2 →L1 (Xi |YM (Xi )) + i=1 |Y | X − log PL1 →L2 (Yi |XM (Yi )), (3) i=1 where PL1 →L2 and PL2 →L1 denote the translation probability across the two languages. Sh"
2020.coling-main.374,P16-1162,0,0.368756,"e the model learning ability by introducing noise in the form of random token deleting and swapping in this input sentence. The denoising auto-encoder, which encodes a noisy version and reconstructs it with the decoder in the same language, acts as a language model during UNMT training. It is optimized by minimizing the objective function: LD = |X| X − log PL1 →L1 (Xi |C(Xi )) + |Y | X − log PL2 →L2 (Yi |C(Yi )), (2) i=1 i=1 where {C(Xi )} and {C(Yi )} are noisy sentences. PL1 →L1 and PL2 →L2 denote the reconstruction probability in the language L1 and L2 , respectively. Back-translation: It (Sennrich et al., 2016a) is adapted to train a translation system across different languages based on monolingual corpora. The pseudo-parallel sentence pairs {(YM (Xi ), Xi )} and {(XM (Yi ), Yi )} produced by the model at the previous iteration would be used to train the new translation model. The UNMT model would be improved through iterative back-translation. Therefore, the back-translation probability would be optimized by minimizing LB = |X| X − log PL2 →L1 (Xi |YM (Xi )) + i=1 |Y | X − log PL1 →L2 (Yi |XM (Yi )), (3) i=1 where PL1 →L2 and PL2 →L1 denote the translation probability across the two languages. Sh"
2020.coling-main.374,P19-1119,1,0.906137,"s of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios. 1 Introduction Recently, unsupervised neural machine translation (UNMT) has attracted great interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019; Sun et al., 2020b). Typically, UNMT relies solely on monolingual corpora rather than bilingual parallel data in supervised neural machine translation (SNMT) to model translations between the source language and target language and has achieved remarkable results on several translation tasks (Conneau and Lample, 2019). However, previous work only focus on how to build stateof-the-art UNMT systems on the clean data and ignore the robustness of UNMT on the noisy data. In the real-world scenario, there often exists noises or perturbations in the input sentences, for example, word character missp"
2020.coling-main.374,2020.acl-main.324,1,0.900456,"ining sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios. 1 Introduction Recently, unsupervised neural machine translation (UNMT) has attracted great interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019; Sun et al., 2020b). Typically, UNMT relies solely on monolingual corpora rather than bilingual parallel data in supervised neural machine translation (SNMT) to model translations between the source language and target language and has achieved remarkable results on several translation tasks (Conneau and Lample, 2019). However, previous work only focus on how to build stateof-the-art UNMT systems on the clean data and ignore the robustness of UNMT on the noisy data. In the real-world scenario, there often exists noises or perturbations in the input sentences, for example, word character misspelling, replacemen"
2020.coling-main.374,P18-1005,0,0.100191,"First of all, we clearly defined two types of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios. 1 Introduction Recently, unsupervised neural machine translation (UNMT) has attracted great interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Sun et al., 2019; Sun et al., 2020b). Typically, UNMT relies solely on monolingual corpora rather than bilingual parallel data in supervised neural machine translation (SNMT) to model translations between the source language and target language and has achieved remarkable results on several translation tasks (Conneau and Lample, 2019). However, previous work only focus on how to build stateof-the-art UNMT systems on the clean data and ignore the robustness of UNMT on the noisy data. In the real-world scenario, there often exists noises or perturbations in the input sent"
2020.coling-main.374,W19-5368,0,0.0186829,"with the UNMT system. These further demonstrate that our proposed Both AT mechanism is robust and can effectively alleviate the impact of two types of noise on translation performance. 5.5 Evaluation on MTNT dataset To better assess the effectiveness of our proposed adversarial training methods, we investigated the performance of UNMT with Both AT framework on the MTNT dataset, which is a noisy dataset proposed by Michel and Neubig (2018). The detailed statistics of MTNT data set is presented as shown in Table 3. To make our experiments comparable with previous work (Michel and Neubig, 2018; Zhou et al., 2019), we used the same MTNT parallel training data to fine-tune our proposed +Both AT system and used sacreBLEU (Post, 2018) to evaluate the translation performance. Corpus en-fr fr-en Training set Valid set Test set 36,058 852 1,020 19,161 886 1,022 Methods en-fr fr-en Michel and Neubig (2018) +Fine-tuning Zhou et al. (2019) +Fine-tuning 21.77 29.73 n/a n/a 23.27 30.29 24.50 31.70 31.60 39.00 33.80 41.30 +Both AT +Fine-tuning Table 3: Statistics of MTNT data set. Table 4: BLEU score on the En-Fr MTNT test set. As shown in Table 4, Our proposed +Both AT system significantly outperformed the previo"
2020.coling-main.374,W18-6401,0,\N,Missing
2020.coling-main.374,N19-1120,0,\N,Missing
2020.coling-main.374,W19-5301,0,\N,Missing
2020.coling-main.510,D17-1181,0,0.0649095,"Missing"
2020.coling-main.510,P17-1152,0,0.228905,"urther proposes a hybrid attention scheme which includes an instance-level attention and a feature-level attention, where the former is used to highlight the crucial support sentences in calculating the prototype, and the latter is to select more efficient features when calculating distances. MLMAN Different from the Proto and Proto-HATT, MLMAN encodes each query and the supporting set in an interactive way by considering their matching information on multiple levels. At local level, the representations of an instance and a supporting set are matched following the sentence matching framework (Chen et al., 2017b) and aggregated by max and average pooling. At instance level, the matching degree is first calculated via a multi-layer perception (MLP). Then, taking the matching degrees as weights, the instances in a supporting set are aggregated to obtain the class prototype for final classification. BERT-PAIR This model is based on the sentence classification model in BERT. The sentence to be classified is first paired with all the supporting instances, and then each pair is concatenated to a sequence. BERT takes this sequence as input and returns a relevance score, which is used to measure whether the"
2020.coling-main.510,P19-1012,0,0.0489319,"Missing"
2020.coling-main.510,D19-1649,0,0.305434,"ng the relations with insufficient instances. Therefore, making the RC models capable of identifying relations with few training instances becomes a crucial challenge. Inspired by the success of few-shot learning methods in the computer vision community (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016) and some other natural language processing tasks (Chen et al., 2016; Qin et al., 2020; Zhou et al., 2019), Han et al. (2018) first introduce the few-shot learning to RC task and propose the FewRel dataset. Recently, many works focus on this task and achieve remarkable performance (Gao et al., 2019a; Snell et al., 2017; Ye and Ling, 2019). Previous few-shot relation classifiers perform well on sentences with only one relation of a single entity pair. However, in real natural language, a sentence usually jointly describes multiple relations of different entity pairs. Since these relations usually keep high co-occurrence in the same context, previous few-shot RC models struggle to distinguish them with few annotated instances. For example, Table 1 shows three instances from the FewRel dataset, where each sentence describes multiple relations with corresponding keyphrases highlighted (colo"
2020.coling-main.510,D18-1514,0,0.25064,"on between two specified entities in a sentence. Previous supervised approaches on this task heavily depend on human-annotated data, which limit their performance on classifying the relations with insufficient instances. Therefore, making the RC models capable of identifying relations with few training instances becomes a crucial challenge. Inspired by the success of few-shot learning methods in the computer vision community (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016) and some other natural language processing tasks (Chen et al., 2016; Qin et al., 2020; Zhou et al., 2019), Han et al. (2018) first introduce the few-shot learning to RC task and propose the FewRel dataset. Recently, many works focus on this task and achieve remarkable performance (Gao et al., 2019a; Snell et al., 2017; Ye and Ling, 2019). Previous few-shot relation classifiers perform well on sentences with only one relation of a single entity pair. However, in real natural language, a sentence usually jointly describes multiple relations of different entity pairs. Since these relations usually keep high co-occurrence in the same context, previous few-shot RC models struggle to distinguish them with few annotated i"
2020.coling-main.510,P19-1135,0,0.0302267,"/oPos” CAT and w/o relative position and the syntax position bring significant improvements. In addition, compared with our full model, the performance of “w/o CAT” proves that the CAT help to decouple the confusing relations. 4 Related Work Few-shot Relation Classification Relation classification (RC) aims to identify the semantic relation between two entities in a sentence, which is the basis of many natural language processing task, such as question answering (Yu et al., 2017) and knowledge graph completion (Shang et al., 2019). It has attracted more and more attention over past few years (Jia et al., 2019; Feng et al., 2018; Vinyals et al., 2018; Adel and Sch¨utze, 2017; Yang et al., 2016a). Previous supervised approaches on this task heavily rely on labeled data for training, that limits their ability to classify the relations with insufficient instances. To address this problem, Han et al. (2018) first introduce few-shot learning to RC task, which has been proved effective in the computer vision community and has many applications (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016). Earlier works on few-shot RC are based on the widely used model prototypical network (Snell et al."
2020.coling-main.510,2020.acl-main.512,0,0.0425707,"re-trained LM BERT (Devlin et al., 2018) to few-shot RC, and their work shows that BERT brings significant improvements on classification performance. Furthermore, the approach proposed by Soares et al. (2019) are also based on BERT and achieve the state-of-art result on the few-shot RC task. Syntactic Relation Previous RC models usually use the relative position information to identify which words are the entities in a sentence, e.g., Zeng et al. (2015b). In addition, the syntax information of the sentences is proved useful in many natural language processing tasks (Fale´nska and Kuhn, 2019; Ma et al., 2020; Chen et al., 2017a). Inspired by Yang et al. (2016b), which adopt the dependency parse tree for RC (Ma et al., 2020), we also introduce the dependency relation as another type of position to emphasize the specific entities, and propose a novel application of the syntax positions. 5 Conclusions In this paper, we propose CTEG equipped with two novel mechanisms, namely the Entity-Guided Attention (EGA) and the Confusion-Aware Training (CAT), to address the relation confusion problem in few-shot relation classification (RC). We conduct extensive experiments on benchmark dataset FewRel, and exper"
2020.coling-main.510,P09-1113,0,0.13173,"d attention (EGA) and confusion-aware training (CAT) through the ablation studies in Section 3.4. In order to more intuitively and clearly show the role of EGA and CAT, we show their visualized examples in case study in Section 3.5. Furthermore, we verify that our model is capable of addressing the relation confusion problem to some extent in Section 3.6. 3.1 Implementation Details Dataset The FewRel dataset (Han et al., 2018) contains 100 relations, which are split up into 64 for training, 16 for validation and 20 for testing. Each relation has 700 instances generated by distant supervision (Mintz et al., 2009). All the instances are annotated with a specified entity pair. Settings The dimension of word embedding is set to 768 for consistency with the base model of BERT (Devlin et al., 2018). The max length of the input is set to 100. Following BERT, the layer number M of the transformer encoder with EGA is 12, and all parameters in it is initialized with the pretrained BERT model. The relative position and syntactic relation embedding dimensions are both set to 50, and the transformer encoder for obtaining entity-guided gates is set up with hidden size as 230, head number of self-attention as 2. In"
2020.coling-main.510,P19-1279,0,0.0191409,"on community and has many applications (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016). Earlier works on few-shot RC are based on the widely used model prototypical network (Snell et al., 2017; Ye and Ling, 2019). Recently, the pre-trained language models (LM) has shown significant power in many natural language processing tasks. To this end, Gao et al. (2019c) adopt the most representative pre-trained LM BERT (Devlin et al., 2018) to few-shot RC, and their work shows that BERT brings significant improvements on classification performance. Furthermore, the approach proposed by Soares et al. (2019) are also based on BERT and achieve the state-of-art result on the few-shot RC task. Syntactic Relation Previous RC models usually use the relative position information to identify which words are the entities in a sentence, e.g., Zeng et al. (2015b). In addition, the syntax information of the sentences is proved useful in many natural language processing tasks (Fale´nska and Kuhn, 2019; Ma et al., 2020; Chen et al., 2017a). Inspired by Yang et al. (2016b), which adopt the dependency parse tree for RC (Ma et al., 2020), we also introduce the dependency relation as another type of position to e"
2020.coling-main.510,D18-1250,0,0.0221617,"and the syntax position bring significant improvements. In addition, compared with our full model, the performance of “w/o CAT” proves that the CAT help to decouple the confusing relations. 4 Related Work Few-shot Relation Classification Relation classification (RC) aims to identify the semantic relation between two entities in a sentence, which is the basis of many natural language processing task, such as question answering (Yu et al., 2017) and knowledge graph completion (Shang et al., 2019). It has attracted more and more attention over past few years (Jia et al., 2019; Feng et al., 2018; Vinyals et al., 2018; Adel and Sch¨utze, 2017; Yang et al., 2016a). Previous supervised approaches on this task heavily rely on labeled data for training, that limits their ability to classify the relations with insufficient instances. To address this problem, Han et al. (2018) first introduce few-shot learning to RC task, which has been proved effective in the computer vision community and has many applications (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016). Earlier works on few-shot RC are based on the widely used model prototypical network (Snell et al., 2017; Ye and Ling, 2019). Recently, the"
2020.coling-main.510,D16-1007,0,0.330763,"vements. In addition, compared with our full model, the performance of “w/o CAT” proves that the CAT help to decouple the confusing relations. 4 Related Work Few-shot Relation Classification Relation classification (RC) aims to identify the semantic relation between two entities in a sentence, which is the basis of many natural language processing task, such as question answering (Yu et al., 2017) and knowledge graph completion (Shang et al., 2019). It has attracted more and more attention over past few years (Jia et al., 2019; Feng et al., 2018; Vinyals et al., 2018; Adel and Sch¨utze, 2017; Yang et al., 2016a). Previous supervised approaches on this task heavily rely on labeled data for training, that limits their ability to classify the relations with insufficient instances. To address this problem, Han et al. (2018) first introduce few-shot learning to RC task, which has been proved effective in the computer vision community and has many applications (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016). Earlier works on few-shot RC are based on the widely used model prototypical network (Snell et al., 2017; Ye and Ling, 2019). Recently, the pre-trained language models (LM) has shown"
2020.coling-main.510,P19-1277,0,0.48141,"ances. Therefore, making the RC models capable of identifying relations with few training instances becomes a crucial challenge. Inspired by the success of few-shot learning methods in the computer vision community (Vinyals et al., 2016; Sung et al., 2017; Santoro et al., 2016) and some other natural language processing tasks (Chen et al., 2016; Qin et al., 2020; Zhou et al., 2019), Han et al. (2018) first introduce the few-shot learning to RC task and propose the FewRel dataset. Recently, many works focus on this task and achieve remarkable performance (Gao et al., 2019a; Snell et al., 2017; Ye and Ling, 2019). Previous few-shot relation classifiers perform well on sentences with only one relation of a single entity pair. However, in real natural language, a sentence usually jointly describes multiple relations of different entity pairs. Since these relations usually keep high co-occurrence in the same context, previous few-shot RC models struggle to distinguish them with few annotated instances. For example, Table 1 shows three instances from the FewRel dataset, where each sentence describes multiple relations with corresponding keyphrases highlighted (colored) as evidence. When specified two enti"
2020.coling-main.510,D15-1203,0,0.314328,"inspired by the success of pre-trained language models, our approaches are based on BERT (Devlin et al., 2018), which has been proved effective especially for few-shot learning tasks. Specifically, the backbone of the encoder of our model is a transformer equipped with the proposed EGA which guides the calculation of self-attention distributions by weighting the attention logits with entity-guided gates. The gates are used to measure the relevance between each word and the given two entities. Two types of information for each word are used to calculate its gate. One is the relative position (Zeng et al., 2015a) information, which is the relative distance between a word and an entity in the input sequence. The other is syntactic relation which is proposed in this paper, defined as the dependency relations between each word and the entities. Based on these information, the entity-guided gates in EGA are able to select those important words and control the contribution of each word in self-attention. We also propose CAT to explicitly force the model to asynchronously learn the classification from an instance to its true relation and its confusing relation. After each training step, the CAT first sele"
2020.semeval-1.145,P19-1239,0,0.0966102,"deo and text at feature level, and then perform sentiment classification on the video dataset. Dobrisek et al. (2013) use decision-level fusion to merge audio and video. Designed a multimodal emotion recognition system. Wollmer et al. (2013)focus on the task of automatically analyzing a speaker’s sentiment in on-line videos contain movie reviews, using a mixed feature model to merge audio, video and text. Truong and Lauw (2019) use pictures to extract effective text information for sentiment classification. Xu et al. (2019) researched aspect-level sentiment classification of images and texts. Cai et al. (2019) extract image attributes features, which help the multimodal models for photo-text sarcasm detection. Zadeh et al. (2017) mix single-mode, dual-mode and triple-modal feature information to identify emotion in the comment video. However, none of these research work uses a pre-trained model based on Transformers, but the pre-trained model has proved its effectiveness in many works, so we decided to use BERT instead of LSTM this time. We participated in sub-task a, which is to judge the emotions of memes, and we only used the data provided by the competition organizer (Sharma et al., 2020). In o"
2020.semeval-1.145,D19-1387,0,0.0279252,"ictures. It focuses is not just the fusion of text and picture information, so we gave it up early. However, the prediction results of HFM and TFNet are not as good as the single-modal model too. By observing the data set , We found that the meme dataset (Sharma et al., 2020) of SemEval-2020 Task8 has a feature, that is the understanding of meme is very dependent on the alignment of text segment and image regions. But neither HFM nor TFNet focuses on it. So we later designed a model to align the picture and the text. We divide the text into sentences and get the features of sentences by BERT (Liu and Lapata, 2019). Then we get the 7x7 image regions through ResNet-101. At last, performing attention operations on the images regions by sentences. But the actual effect is not good, which is worse than HFM and TFNet. We found that in many cases, a text is only divided into one sentence, so we consider that it may be the sentence level division is too rough. We guess that the use of phrase level or word level division may achieve better results, but we have not designed a suitable model. So in the end we did not use the multimodal model. we can see that the result of using text alone is better than using pic"
2021.acl-short.99,D19-1418,0,0.0282943,"6.9 3.8 49.1 44.2 72.1 69.6 56.2 51.7 89.1 77.4 Table 3: Results of five runs for training BERT on MNLI with model selection via target domain dev set SST-2 -5.1 / 67.2 -2.0 / 77.5 -7.2 / 64.6 +1.6 / 54.8 - / 10.0 +0.4 / 82.7 +0.3 / 90.0 +0.5 / 90.6 +2.7 / 84.9 - / 25.0 -13.5 / 75.9 +0.6 / 94.5 -9.5 / 82.3 -6.4 / 84.4 - / 50.0 training. We experiment with three schemes on the MNLI data to see whether they could lead to better generalization of zero-shot classification: (1) Data augmentation with syntactic transformations (Min et al., 2020)8 , denoted as DA, (2) Instance reweighting following Clark et al. (2019) that reweights each example with one minus the probability a bias-only model assigns the correct label, denoted as RW, and (3) The bias product method (Clark et al., 2019) that ensembles a bias-only model via a product of experts, denoted as BP, which is essentially the same as its concurrent work via fitting the residual of the biased models (He et al., 2019). There exist additional solutions with richer details such as multi-task learning (Tu et al., 2020) where proper auxiliary tasks could be identified to improve robustness. We plan to explore more in this line in our more extensive futur"
2021.acl-short.99,P19-1554,0,0.022524,"ining to detect pairwise coherence. In this way, NSP could serve as a non-trivial, strong alternative baseline for zero-shot text classification scenarios where the target labels are semantically more concrete (e.g., topics) or more frequently appeared (e.g., words expressing sentiment). In such scenarios, fine-tuning on limited NLI data could weaken the semantic coherence acquired from the raw BERT pre-trained on generic-domain corpora, especially now that fine-tuned models have utilized many spurious lexical cooccurrence features as shown in many similar sentence pair classification models (Feng et al., 2019; Niven and Kao, 2019), possibly due to the inherent lexical bias from the current NLI datasets collected from crowd workers. 6 Readers who are curious about more details on this problem can refer to our qualitative analysis in the Appendix which could hopefully help establish 6 Some readers might guess that other NLI datasets collected via a more careful process (Jiang and de Marneffe, 2019; Eisenschlos et al., 2021) might partially mitigate the bias appearing from crowdsourced annotation, but this does not mean that such better intended datasets can be free from statistically biased lexical"
2021.acl-short.99,N19-1423,0,0.0174185,"al., 2016; Raffel et al., 2020, inter alia). Text classification is then reduced to textual entailment by setting ∗ Work during internship at Microsoft Research Asia. the input sentence as the premise and simultaneously casting the candidate label into a hypothesis sentence using pre-defined templates or lexical definitions from WordNet. Once we have any pretrained NLI models at hand, zero-shot text classification under any specified label space is enabled for free without the need to collect annotated data. With contextualized representation based on pretrained language models such as BERT (Devlin et al., 2019), NLI performance has been drastically improved. Promising empirical results have been shown on various text classification benchmarks that vary across topic classification, emotion classification, and situation classification, outperforming earlier standard approaches (Chang et al., 2008) or simple scoring schemes derived from distributional similarity (Mikolov et al., 2013). However, such generality is conceptually contradictory with the specificity of text classification in many practical scenarios. In this opinion piece, we conduct extended analysis on the recent attempts (Yin et al., 2019"
2021.acl-short.99,2021.naacl-main.71,0,0.0273999,"urious about more details on this problem can refer to our qualitative analysis in the Appendix which could hopefully help establish 6 Some readers might guess that other NLI datasets collected via a more careful process (Jiang and de Marneffe, 2019; Eisenschlos et al., 2021) might partially mitigate the bias appearing from crowdsourced annotation, but this does not mean that such better intended datasets can be free from statistically biased lexical distributions with coincidental cooccurrences that could be utilized by our strong data-fitting models during fine-tuning (Geirhos et al., 2020; Du et al., 2021). Our additional results described in the Appendix do not seem to be promising on this direction towards better NLI data. a slightly better sense on the behavioral difference introduced by NLI fine-tuning. On the other hand, fine-tuning on NLI data might seem to be marginally helpful for more abstract cases such as emotion and situation typing, but the performance metrics are in fact pathetically disappointing across all systems. 2.2.2 How stable are these NLI models? Apart from the obvious difference caused by different training data, there underlies a more serious concern: the discrepancy be"
2021.acl-short.99,2021.naacl-main.32,0,0.061666,"Missing"
2021.acl-short.99,2021.acl-long.295,0,0.0187162,"use the English news data from (Zhang et al., 2015) that consists of four types of articles: World, Sports, Business, Sci/Tech. SST-2 : The Stanford Sentiment Treebank dataset3 processed by Socher et al. (2013) for sentiment polarity classification with binary labels (positive and negative). 1 Another reason for not studying on this setting is that the split of development set and test set in (Yin et al., 2019) contain the same label space, which is flawed to be used for any claim on the performance of “unseen labels”. 2 https://github.com/snipsco/snips-nlu 3 For SST-2 we follow Zhang et al. (2021) and Gao et al. (2021) to use the development set from GLUE for testing. • ESA: Representing the text and label in the Wikipedia concept vector space. Using the implementation5 from Chang et al. (2008). Moreover, due to the obvious variance in performance for models trained on different NLI datasets, we are also tempted to check how much the performance might degrade when given no NLI data at all for fine-tuning. This corresponds to naively using a raw BERT model which has been pre-trained for next sentence prediction (NSP). For consistency, we use the same premises and hypotheses as the deleg"
2021.acl-short.99,2020.blackboxnlp-1.16,0,0.0274167,"alization performance as measured by the early-stopping dev set performance. Results are listed in Table 2, where the absolute differences between the worst and the best are large, especially on classifying topic or intent. We observe even worse trends on other smaller NLI datasets (see Appendix). These results are consistent with recent studies within the scope of NLI reporting that BERT instances which achieve similar performance metrics on standard NLI datasets could have huge variance in out-ofdistribution generalization or linguistic stress testing (McCoy et al., 2020; Zhou et al., 2020; Geiger et al., 2020), while providing another instance of the underspecification problem in modern machine learning (D’Amour et al., 2020). As a verification, we also try to tune the models for different development sets that better characterize the generalization behavior for zero-shot 788 Dataset MNLI dev set Yahoo Emotion Situation AGNews SST-2 Snips Average Std Min Max Model 90.5 39.0 18.1 16.2 63.7 68.6 74.1 0.3 10.5 2.0 1.5 11.0 2.0 3.9 90.0 26.9 15.7 14.5 50.0 66.1 68.4 90.8 50.2 20.5 18.7 77.7 70.9 77.6 NSP(Reverse) RTE FEVER MNLI Random classification. We reorganize the splitted development set and the t"
2021.acl-short.99,D18-1352,0,0.0257113,", and currently more robust NLI methods might not help. Our observations reveal implicit but massive difficulties in building a usable zero-shot text classifier based on text entailment models. Given the difficulty of NLI data collection that aims at out-ofdomain generalization or transfer learning (Bowman et al., 2020), we question the feasibility of this setup in the current progress of language technology. Before significant progress in language understanding and reasoning, it seems more promising to consider alternative schemes built on explicit external knowledge (Zellers and Choi, 2017; Rios and Kavuluru, 2018; Zhang et al., 2019) or more crafted usage of pre-trained models that hopefully have captured more comprehensive semantic coverage and better compositionality from large corpora or grounded texts (Meng et al., 2020; Brown et al., 2020; Radford et al., 2021). This study also implies the huge difficulty for benchmarking zero-shot text classification without any further restriction on the task setting. The three datasets used by Yin et al. (2019) were originally intended for diverse coverage but are not sufficient to draw consistent conclusions as we have shown. We suggest future studies on zero"
2021.acl-short.99,2021.acl-long.170,0,0.0320111,"e three datasets used by Yin et al. (2019) were originally intended for diverse coverage but are not sufficient to draw consistent conclusions as we have shown. We suggest future studies on zero-shot text classification either conduct experiments over even more diverse classification scenarios to verify any claimed generality, or directly focus on more specific task settings and verify claims within a smaller but clearer scope such as zero-shot intent classification or zero-shot situation typing for more reliable results with less instability, and perhaps based on more carefully curated data (Rogers, 2021). 790 References Laura-Ana-Maria Bostan and Roman Klinger. 2018. An analysis of annotated corpora for emotion classification in text. In Proceedings of the 27th International Conference on Computational Linguistics, pages 2104–2119, Santa Fe, New Mexico, USA. Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632–642, Lisbon, Portugal. Samuel R. Bowman, Jennimaria Palomaki, Livio Baldini Soares, and"
2021.acl-short.99,N18-1179,0,0.025859,"l., 2019) that ensembles a bias-only model via a product of experts, denoted as BP, which is essentially the same as its concurrent work via fitting the residual of the biased models (He et al., 2019). There exist additional solutions with richer details such as multi-task learning (Tu et al., 2020) where proper auxiliary tasks could be identified to improve robustness. We plan to explore more in this line in our more extensive future study. 2.2.3 Is more robust NLI helpful? Previous studies have raised concerns on that the current NLI models heavily rely on spurious lexical overlap patterns (Sanchez et al., 2018; Naik et al., 2018; McCoy et al., 2019, inter alia). For analytical purposes, we randomly permute the tokens of each input instance to see how much the predictions might change. Results shown in Table 4 suggest that shuffling the input tokens does not affect the model performance by much, which is consistent with similar recent findings (Gupta et al., 2021; Sinha et al., 2021). This reveals a concern that all these models might just predict with shallow lexical patterns that may not be robust for more semantically abstractive input instances. There have been a few recent attempts trying to re"
2021.acl-short.99,2021.acl-long.569,0,0.0415985,"to explore more in this line in our more extensive future study. 2.2.3 Is more robust NLI helpful? Previous studies have raised concerns on that the current NLI models heavily rely on spurious lexical overlap patterns (Sanchez et al., 2018; Naik et al., 2018; McCoy et al., 2019, inter alia). For analytical purposes, we randomly permute the tokens of each input instance to see how much the predictions might change. Results shown in Table 4 suggest that shuffling the input tokens does not affect the model performance by much, which is consistent with similar recent findings (Gupta et al., 2021; Sinha et al., 2021). This reveals a concern that all these models might just predict with shallow lexical patterns that may not be robust for more semantically abstractive input instances. There have been a few recent attempts trying to remove the shallow overlap bias for NLI model 7 AGNews Table 4: Results of shuffling perturbation. In each cell: the change of accuracy after input shuffling, followed by the percentage of examples where the predictions do not change. All these results are reported as the average score of five different random shuffles. Table 2: Results of five runs of BERT fine-tuned on MNLI and"
2021.acl-short.99,D17-1099,0,0.0121989,"d by text classification, and currently more robust NLI methods might not help. Our observations reveal implicit but massive difficulties in building a usable zero-shot text classifier based on text entailment models. Given the difficulty of NLI data collection that aims at out-ofdomain generalization or transfer learning (Bowman et al., 2020), we question the feasibility of this setup in the current progress of language technology. Before significant progress in language understanding and reasoning, it seems more promising to consider alternative schemes built on explicit external knowledge (Zellers and Choi, 2017; Rios and Kavuluru, 2018; Zhang et al., 2019) or more crafted usage of pre-trained models that hopefully have captured more comprehensive semantic coverage and better compositionality from large corpora or grounded texts (Meng et al., 2020; Brown et al., 2020; Radford et al., 2021). This study also implies the huge difficulty for benchmarking zero-shot text classification without any further restriction on the task setting. The three datasets used by Yin et al. (2019) were originally intended for diverse coverage but are not sufficient to draw consistent conclusions as we have shown. We sugge"
2021.findings-acl.144,P19-1279,0,0.0185916,"ly related to the relation between entity pairs. However, this approach destroys the original document structure, which is weak in modeling the reasoning between two entities for the DocRE task. Therefore, we use the self-attention mechanism (Vaswani et al., 2017) to learn a document-level context representation (DLCRep) cn for one mention based on the vectorized input document D: hnj K )V, cn = softmax( √ dmodel (8) where cn ∈ Rd2 and {K, V} are key and value matrices that are transformed from the vectorized input document D using a linear layer. Here, inspired by relation learning (Baldini Soares et al., 2019), we use the hidden state of the head word in one mention or one sentence to denote them for simplicity. 3.3 Modeling of Reasoning Paths In this section, we use the concatenation operation to model the reasoning step on the reasoning path, thereby modeling the deﬁned reasoning paths 1656 in Section 2.1 as the corresponding reasoning representations as follows: 1) For the intra-sentence reasoning path, both HGCReps and DLCReps of two mentions are concatenated in turn as a reasoning representation: αij = [gms1 : gms1 : cms1 : cms1 ], i j i j 4 4.1 (9) 2) For the logical reasoning path, both HGCR"
2021.findings-acl.144,2020.acl-main.338,0,0.0467067,"Missing"
2021.findings-acl.144,D19-1498,0,0.0503522,"ional facts on the test set. 4.2 Dev Ign F1 F1 Existing DocRE Systems GCNN† 46.22 51.52 45.94 52.15 EoG† 45.17 51.44 GAT† AGGCN† 46.29 52.47 48.82 55.17 LSR∗ GAIN∗ 53.05 55.29 54.27 56.22 HeterGSAN-Rec∗ BERT∗base 54.16 Two-Phase BERT∗base 54.42 52.43 59.00 LSR+BERT∗base 59.14 61.22 GAIN+BERT∗base HeterGSAN-Rec+BERT∗base 58.13 60.18 ATLOP-BERT∗base 59.22 61.09 Our DocRE Systems DRN 54.61 56.49 DRN+BERTbase 59.33 61.39 Methods Baseline Systems We reported the results of the recent graphbased DocRE methods as the comparison systems: GAT (Veliˇckovi´c et al., 2018), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), AGGCN (Guo et al., 2019), LSR (Nan et al., 2020), GAIN (Zeng et al., 2020), and HeterGASNRec(Xu et al., 2021). Moreover, pre-trained models like BERT (Devlin et al., 2019) has been shown impressive result on the DocRE task. Therefore, we also reported state-of-the-art graphbased DocRE models with pre-trained BERTbase model, including Two-Phase+BERTbase (Wang et al., 2019), LSR+BERTbase (Nan et al., 2020), GAIN+BERTbase (Zeng et al., 2020), HeterGASN-Rec+BERTbase (Xu et al., 2021), and ATLOP-BERTbase (Zhou et al., 2021). 4.3 the existing best ATLOP+BERT model (F1 61.30) in terms of F1, which"
2021.findings-acl.144,N19-1423,0,0.013903,"7 56.22 HeterGSAN-Rec∗ BERT∗base 54.16 Two-Phase BERT∗base 54.42 52.43 59.00 LSR+BERT∗base 59.14 61.22 GAIN+BERT∗base HeterGSAN-Rec+BERT∗base 58.13 60.18 ATLOP-BERT∗base 59.22 61.09 Our DocRE Systems DRN 54.61 56.49 DRN+BERTbase 59.33 61.39 Methods Baseline Systems We reported the results of the recent graphbased DocRE methods as the comparison systems: GAT (Veliˇckovi´c et al., 2018), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), AGGCN (Guo et al., 2019), LSR (Nan et al., 2020), GAIN (Zeng et al., 2020), and HeterGASNRec(Xu et al., 2021). Moreover, pre-trained models like BERT (Devlin et al., 2019) has been shown impressive result on the DocRE task. Therefore, we also reported state-of-the-art graphbased DocRE models with pre-trained BERTbase model, including Two-Phase+BERTbase (Wang et al., 2019), LSR+BERTbase (Nan et al., 2020), GAIN+BERTbase (Zeng et al., 2020), HeterGASN-Rec+BERTbase (Xu et al., 2021), and ATLOP-BERTbase (Zhou et al., 2021). 4.3 the existing best ATLOP+BERT model (F1 61.30) in terms of F1, which is a new state-of-the-art result on the DocRE dataset. 1 https://competitions.codalab.org/ competitions/20717 49.59 49.48 47.36 48.89 52.15 52.66 53.27 56.97 59.00 57.12 59."
2021.findings-acl.144,P19-1024,0,0.0132325,"Ign F1 F1 Existing DocRE Systems GCNN† 46.22 51.52 45.94 52.15 EoG† 45.17 51.44 GAT† AGGCN† 46.29 52.47 48.82 55.17 LSR∗ GAIN∗ 53.05 55.29 54.27 56.22 HeterGSAN-Rec∗ BERT∗base 54.16 Two-Phase BERT∗base 54.42 52.43 59.00 LSR+BERT∗base 59.14 61.22 GAIN+BERT∗base HeterGSAN-Rec+BERT∗base 58.13 60.18 ATLOP-BERT∗base 59.22 61.09 Our DocRE Systems DRN 54.61 56.49 DRN+BERTbase 59.33 61.39 Methods Baseline Systems We reported the results of the recent graphbased DocRE methods as the comparison systems: GAT (Veliˇckovi´c et al., 2018), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), AGGCN (Guo et al., 2019), LSR (Nan et al., 2020), GAIN (Zeng et al., 2020), and HeterGASNRec(Xu et al., 2021). Moreover, pre-trained models like BERT (Devlin et al., 2019) has been shown impressive result on the DocRE task. Therefore, we also reported state-of-the-art graphbased DocRE models with pre-trained BERTbase model, including Two-Phase+BERTbase (Wang et al., 2019), LSR+BERTbase (Nan et al., 2020), GAIN+BERTbase (Zeng et al., 2020), HeterGASN-Rec+BERTbase (Xu et al., 2021), and ATLOP-BERTbase (Zhou et al., 2021). 4.3 the existing best ATLOP+BERT model (F1 61.30) in terms of F1, which is a new state-of-the-art"
2021.findings-acl.144,2020.acl-main.141,0,0.085333,"https://github.com/xwjim/DRN. 1 Figure 1: An example of different reasoning types. Different reasoning types have different reasoning processing. Introduction Document-level relation extraction (DocRE) aims to extract relations among entities within a document which requires multiple reasoning skills (i.e., pattern recognition, logical reasoning, coreference reasoning, and common-sense reasoning) (Yao et al., 2019). Generally, the input document is constructed as a structural graph-based on syntactic trees, coreference or heuristics to represent relation information between all entity pairs (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021). Thus, graph neural networks are applied to the constructed structural graph to model these reasoning skills. After performing multi-hop graph convolution, the feature representations of two entities are concatenated to recognize their relation by the classiﬁer, achieving state-of-the-art performance in the DocRE task (Zeng et al., 2020; Xu et al., 2021). However, it is yet to be seen whether modeling these reasoning skills implicitly is competitive with the intuitive reasoning skills between one entity pair in this document. Figure 1 shows four kinds of r"
2021.findings-acl.144,Q17-1008,0,0.0187343,"019; Zhu et al., 2019). A large-scale general-purpose dataset for DocRE constructed from Wikipedia articles has been proposed in (Yao et al., 2019), which has advanced the DocRE a lot. Most approaches on DocRE are based on document graphs, which were introduced by Quirk and Poon. Speciﬁcally, they use words as nodes and construct a homogenous graph using syntax parsing tools and a graph neural network is used to capture the document information. This document graph provides a uniﬁed way of extracting the features for entity pairs. Later work extends the idea by improving neural architectures (Peng et al., 2017; Verga et al., 2018; Gupta et al., 2019) or adding more types of edges (Christopoulou et al., 2019). In the Christopoulou et al.’s work, the author construct the graph which contains different granularities (sentence, mention, entity) through co-occurrence and heuristic rule to model the graph without external tools. More recent most of the approach (Christopoulou et al., 2019; Zeng et al., 2020; Xu et al., 2021) constructs heterogeneous graph through co-occurrence and heuristic rule to model the graph without external tools. In the (Zeng et al., 2020) constructed double graphs in different g"
2021.findings-acl.144,E17-1110,0,0.0191806,"Wang et al., 2016; Sorokin and Gurevych, 2017; Feng et al., 2018; Song et al., 2019; Wei et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical domain (Quirk and Poon, 2017; Gupta et al., 2019; Zhang et al., 2018; Christopoulou et al., 2019; Zhu et al., 2019). A large-scale general-purpose dataset for DocRE constructed from Wikipedia articles has been proposed in (Yao et al., 2019), which has advanced the DocRE a lot. Most approaches on DocRE are based on document graphs, which were introduced by Quirk and Poon. Speciﬁcally, they use words as nodes and construct a homogenous graph using syntax parsing tools and a graph neural network is used to capture the document information. This document graph provides a uniﬁed way of extracting the features for entity pairs"
2021.findings-acl.144,P19-1423,0,0.0155884,"number of extracted relational facts on the test set. 4.2 Dev Ign F1 F1 Existing DocRE Systems GCNN† 46.22 51.52 45.94 52.15 EoG† 45.17 51.44 GAT† AGGCN† 46.29 52.47 48.82 55.17 LSR∗ GAIN∗ 53.05 55.29 54.27 56.22 HeterGSAN-Rec∗ BERT∗base 54.16 Two-Phase BERT∗base 54.42 52.43 59.00 LSR+BERT∗base 59.14 61.22 GAIN+BERT∗base HeterGSAN-Rec+BERT∗base 58.13 60.18 ATLOP-BERT∗base 59.22 61.09 Our DocRE Systems DRN 54.61 56.49 DRN+BERTbase 59.33 61.39 Methods Baseline Systems We reported the results of the recent graphbased DocRE methods as the comparison systems: GAT (Veliˇckovi´c et al., 2018), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), AGGCN (Guo et al., 2019), LSR (Nan et al., 2020), GAIN (Zeng et al., 2020), and HeterGASNRec(Xu et al., 2021). Moreover, pre-trained models like BERT (Devlin et al., 2019) has been shown impressive result on the DocRE task. Therefore, we also reported state-of-the-art graphbased DocRE models with pre-trained BERTbase model, including Two-Phase+BERTbase (Wang et al., 2019), LSR+BERTbase (Nan et al., 2020), GAIN+BERTbase (Zeng et al., 2020), HeterGASN-Rec+BERTbase (Xu et al., 2021), and ATLOP-BERTbase (Zhou et al., 2021). 4.3 the existing best ATLOP+BERT model"
2021.findings-acl.144,D19-1020,0,0.012169,",respectively As a result, Task2 was used to predict the relation “{publication date}” between {“Superman”} and {“May 26,2002”} correctly. Meanwhile, the selection of Task2 is consistent with the groundtruth logical reasoning type. Moreover, the above reasoning processing is also similar to the entity pair {“The Eminem show”} and {“Eminem”} with three reasoning types. 5 Related Work Early research efforts on relation extraction concentrate on predicting the relation between two entities with a sentence (Zeng et al., 2014, 2015; Wang et al., 2016; Sorokin and Gurevych, 2017; Feng et al., 2018; Song et al., 2019; Wei et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical domain (Quirk and Poon, 2017; Gupta et al., 2019; Zhang et al., 2018; Christopoulou et al.,"
2021.findings-acl.144,D17-1188,0,0.0202839,"Task3, and their scores are 1.7604, and 0.2841,respectively As a result, Task2 was used to predict the relation “{publication date}” between {“Superman”} and {“May 26,2002”} correctly. Meanwhile, the selection of Task2 is consistent with the groundtruth logical reasoning type. Moreover, the above reasoning processing is also similar to the entity pair {“The Eminem show”} and {“Eminem”} with three reasoning types. 5 Related Work Early research efforts on relation extraction concentrate on predicting the relation between two entities with a sentence (Zeng et al., 2014, 2015; Wang et al., 2016; Sorokin and Gurevych, 2017; Feng et al., 2018; Song et al., 2019; Wei et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical domain (Quirk and Poon, 2017; Gupta et al., 2019; Zhan"
2021.findings-acl.144,N18-1080,0,0.0176894,"19). A large-scale general-purpose dataset for DocRE constructed from Wikipedia articles has been proposed in (Yao et al., 2019), which has advanced the DocRE a lot. Most approaches on DocRE are based on document graphs, which were introduced by Quirk and Poon. Speciﬁcally, they use words as nodes and construct a homogenous graph using syntax parsing tools and a graph neural network is used to capture the document information. This document graph provides a uniﬁed way of extracting the features for entity pairs. Later work extends the idea by improving neural architectures (Peng et al., 2017; Verga et al., 2018; Gupta et al., 2019) or adding more types of edges (Christopoulou et al., 2019). In the Christopoulou et al.’s work, the author construct the graph which contains different granularities (sentence, mention, entity) through co-occurrence and heuristic rule to model the graph without external tools. More recent most of the approach (Christopoulou et al., 2019; Zeng et al., 2020; Xu et al., 2021) constructs heterogeneous graph through co-occurrence and heuristic rule to model the graph without external tools. In the (Zeng et al., 2020) constructed double graphs in different granularity to captur"
2021.findings-acl.144,P16-1123,0,0.0612563,"Missing"
2021.findings-acl.144,2020.acl-main.136,0,0.0428481,"result, Task2 was used to predict the relation “{publication date}” between {“Superman”} and {“May 26,2002”} correctly. Meanwhile, the selection of Task2 is consistent with the groundtruth logical reasoning type. Moreover, the above reasoning processing is also similar to the entity pair {“The Eminem show”} and {“Eminem”} with three reasoning types. 5 Related Work Early research efforts on relation extraction concentrate on predicting the relation between two entities with a sentence (Zeng et al., 2014, 2015; Wang et al., 2016; Sorokin and Gurevych, 2017; Feng et al., 2018; Song et al., 2019; Wei et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical domain (Quirk and Poon, 2017; Gupta et al., 2019; Zhang et al., 2018; Christopoulou et al., 2019; Zhu et al., 2"
2021.findings-acl.144,P19-1074,0,0.189757,"thereby recognizing their relation. Experimental results show that our method outperforms the previous state-of-theart performance on the large-scale DocRE dataset. The code is publicly available at https://github.com/xwjim/DRN. 1 Figure 1: An example of different reasoning types. Different reasoning types have different reasoning processing. Introduction Document-level relation extraction (DocRE) aims to extract relations among entities within a document which requires multiple reasoning skills (i.e., pattern recognition, logical reasoning, coreference reasoning, and common-sense reasoning) (Yao et al., 2019). Generally, the input document is constructed as a structural graph-based on syntactic trees, coreference or heuristics to represent relation information between all entity pairs (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021). Thus, graph neural networks are applied to the constructed structural graph to model these reasoning skills. After performing multi-hop graph convolution, the feature representations of two entities are concatenated to recognize their relation by the classiﬁer, achieving state-of-the-art performance in the DocRE task (Zeng et al., 2020; Xu et al., 2021). However"
2021.findings-acl.144,P19-1128,0,0.0123133,"et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical domain (Quirk and Poon, 2017; Gupta et al., 2019; Zhang et al., 2018; Christopoulou et al., 2019; Zhu et al., 2019). A large-scale general-purpose dataset for DocRE constructed from Wikipedia articles has been proposed in (Yao et al., 2019), which has advanced the DocRE a lot. Most approaches on DocRE are based on document graphs, which were introduced by Quirk and Poon. Speciﬁcally, they use words as nodes and construct a homogenous graph using syntax parsing tools and a graph neural network is used to capture the document information. This document graph provides a uniﬁed way of extracting the features for entity pairs. Later work extends the idea by improving neural architectures (Peng et al., 2017; Ver"
2021.findings-acl.144,D15-1203,0,0.0960531,"Missing"
2021.findings-acl.144,C14-1220,0,0.0226775,"2”}, there are reasoning paths for Task2 and Task3, and their scores are 1.7604, and 0.2841,respectively As a result, Task2 was used to predict the relation “{publication date}” between {“Superman”} and {“May 26,2002”} correctly. Meanwhile, the selection of Task2 is consistent with the groundtruth logical reasoning type. Moreover, the above reasoning processing is also similar to the entity pair {“The Eminem show”} and {“Eminem”} with three reasoning types. 5 Related Work Early research efforts on relation extraction concentrate on predicting the relation between two entities with a sentence (Zeng et al., 2014, 2015; Wang et al., 2016; Sorokin and Gurevych, 2017; Feng et al., 2018; Song et al., 2019; Wei et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical d"
2021.findings-acl.144,2020.emnlp-main.127,0,0.26733,"m/xwjim/DRN. 1 Figure 1: An example of different reasoning types. Different reasoning types have different reasoning processing. Introduction Document-level relation extraction (DocRE) aims to extract relations among entities within a document which requires multiple reasoning skills (i.e., pattern recognition, logical reasoning, coreference reasoning, and common-sense reasoning) (Yao et al., 2019). Generally, the input document is constructed as a structural graph-based on syntactic trees, coreference or heuristics to represent relation information between all entity pairs (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021). Thus, graph neural networks are applied to the constructed structural graph to model these reasoning skills. After performing multi-hop graph convolution, the feature representations of two entities are concatenated to recognize their relation by the classiﬁer, achieving state-of-the-art performance in the DocRE task (Zeng et al., 2020; Xu et al., 2021). However, it is yet to be seen whether modeling these reasoning skills implicitly is competitive with the intuitive reasoning skills between one entity pair in this document. Figure 1 shows four kinds of reasoning skills for"
2021.findings-acl.144,D18-1244,0,0.0165438,"2017; Feng et al., 2018; Song et al., 2019; Wei et al., 2020). These approaches do not consider interactions across mentions and ignore relations expressed across sentence boundaries. The semantics of a document context is coherent and a part of relation can only be extracted among sentences. However, as large amounts of relationships are expressed by multiple sentences, recent 1660 work starts to explore document-level relation extraction. People begin to consider the relation between disease and chemicals in the entire document of biomedical domain (Quirk and Poon, 2017; Gupta et al., 2019; Zhang et al., 2018; Christopoulou et al., 2019; Zhu et al., 2019). A large-scale general-purpose dataset for DocRE constructed from Wikipedia articles has been proposed in (Yao et al., 2019), which has advanced the DocRE a lot. Most approaches on DocRE are based on document graphs, which were introduced by Quirk and Poon. Speciﬁcally, they use words as nodes and construct a homogenous graph using syntax parsing tools and a graph neural network is used to capture the document information. This document graph provides a uniﬁed way of extracting the features for entity pairs. Later work extends the idea by improvi"
2021.findings-acl.144,2020.acl-main.667,0,0.0605234,"Missing"
2021.naacl-main.311,D18-1549,0,0.0207702,"adequate training corpus for one language. In this paper, we first define and analyze the unbalanced training data scenario for UNMT. Based on this scenario, we propose UNMT self-training mechanisms to train a robust UNMT system and improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems. 1 Introduction Recently, unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has attracted a high level of interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Wu et al., 2019; Sun et al., 2019, 2020b). With the help of cross-lingual language model pretraining (Lample and Conneau, 2019; Song et al., 2019; Sun et al., 2020a), the denoising auto-encoder (Vincent et al., 2010), and backtranslation (Sennrich et al., 2016a), UNMT has achieved remarkable results in several translation tasks. However, in real-world scenarios, in contrast to the many large corpora available for high-resource languages such as English and French, massive monolingual corpora do not exist for some extremely low-re"
2021.naacl-main.311,P07-2045,0,0.0126746,"gual WMT news crawl datasets3 for each language. For the high-resource languages En and Fr, we randomly extracted 50M sentences. For the low-resource languages Ro and Et, we used all available monolingual news crawl training data. To make our experiments comparable with previous work (Lample and Conneau, 2019), we report the results on newstest2014 for Fr–En, newstest2016 for Ro–En, and newstest2018 for Et–En. Language En Fr Ro Et Sentences Words 50.00M 50.00M 8.92M 3.00M 1.15B 1.19B 207.07M 51.39M Table 2: Statistics of the monolingual corpora. For preprocessing, we used the Moses tokenizer (Koehn et al., 2007). To clean the data, we only applied the Moses script clean-corpus-n.perl to remove lines from the monolingual data containing more than 50 words. We used a shared vocabulary for all language pairs, with 60,000 subword tokens based on BPE (Sennrich et al., 2016b). learning rate was 0.0001, β1 = 0.9, and β2 = 0.98. We trained a specific cross-lingual language model for each different training dataset. The language model was used to initialize the full parameters of the UNMT system. Eight V100 GPUs were used to train all UNMT models. We used the casesensitive 4-gram BLEU score computed by the mu"
2021.naacl-main.311,P16-1009,0,0.302263,"hat the proposed methods substantially outperform conventional UNMT systems. 1 Introduction Recently, unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has attracted a high level of interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Wu et al., 2019; Sun et al., 2019, 2020b). With the help of cross-lingual language model pretraining (Lample and Conneau, 2019; Song et al., 2019; Sun et al., 2020a), the denoising auto-encoder (Vincent et al., 2010), and backtranslation (Sennrich et al., 2016a), UNMT has achieved remarkable results in several translation tasks. However, in real-world scenarios, in contrast to the many large corpora available for high-resource languages such as English and French, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian. Data size (sentences) En-Fr Fr-En 50M En and 50M Fr (Baseline) 25M En and 25M Fr 50M En and 2M Fr 2M En and 50M Fr 2M En and 2M Fr 36.63 36.59 31.01 31.84 30.91 34.38 34.34 31.06 30.21 29.86 Table 1: UNMT performance (BLEU score) for different training data sizes on En–Fr language pairs. T"
2021.naacl-main.311,P16-1162,0,0.856645,"hat the proposed methods substantially outperform conventional UNMT systems. 1 Introduction Recently, unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has attracted a high level of interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Wu et al., 2019; Sun et al., 2019, 2020b). With the help of cross-lingual language model pretraining (Lample and Conneau, 2019; Song et al., 2019; Sun et al., 2020a), the denoising auto-encoder (Vincent et al., 2010), and backtranslation (Sennrich et al., 2016a), UNMT has achieved remarkable results in several translation tasks. However, in real-world scenarios, in contrast to the many large corpora available for high-resource languages such as English and French, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian. Data size (sentences) En-Fr Fr-En 50M En and 50M Fr (Baseline) 25M En and 25M Fr 50M En and 2M Fr 2M En and 50M Fr 2M En and 2M Fr 36.63 36.59 31.01 31.84 30.91 34.38 34.34 31.06 30.21 29.86 Table 1: UNMT performance (BLEU score) for different training data sizes on En–Fr language pairs. T"
2021.naacl-main.311,P95-1026,0,0.892071,"∗ (Y |X) logPM U (X|Y ) logPM U (Y |X), U ∗ (X|Y ) (1) where P (X) and P (Y ) are the empirical data distribution from monolingual corpora {X}, {Y }, and PM U (Y |X) and PM U (X|Y ) are the conditional distributions generated by the UNMT model. In ∗ addition, M U denotes the model at the previous iteration for generating new pseudo-parallel sentence pairs to update the UNMT model. Self-training proposed by Scudder (1965), is a semi-supervised approach that utilizes unannotated data to create better models. Self-training has been successfully applied to many natural language processing tasks (Yarowsky, 1995; McClosky et al., 2006; Zhang and Zong, 2016; He et al., 2020). Recently, He et al. (2020) empirically found that noisy self-training could improve the performance of supervised machine translation and synthetic data could play a positive role, even as a target. 4 Self-training Mechanism for UNMT Based on these previous empirical findings and analyses, we propose a self-training mechanism to generate synthetic training data for UNMT to alleviate poor performance in the unbalanced training data scenario. The synthetic data increases the diversity of low-resource language data, further enhancin"
2021.naacl-main.311,D16-1160,0,0.0127253,", U ∗ (X|Y ) (1) where P (X) and P (Y ) are the empirical data distribution from monolingual corpora {X}, {Y }, and PM U (Y |X) and PM U (X|Y ) are the conditional distributions generated by the UNMT model. In ∗ addition, M U denotes the model at the previous iteration for generating new pseudo-parallel sentence pairs to update the UNMT model. Self-training proposed by Scudder (1965), is a semi-supervised approach that utilizes unannotated data to create better models. Self-training has been successfully applied to many natural language processing tasks (Yarowsky, 1995; McClosky et al., 2006; Zhang and Zong, 2016; He et al., 2020). Recently, He et al. (2020) empirically found that noisy self-training could improve the performance of supervised machine translation and synthetic data could play a positive role, even as a target. 4 Self-training Mechanism for UNMT Based on these previous empirical findings and analyses, we propose a self-training mechanism to generate synthetic training data for UNMT to alleviate poor performance in the unbalanced training data scenario. The synthetic data increases the diversity of low-resource language data, further enhancing the performance of the translation, even 3"
2021.naacl-main.311,P19-1119,1,0.628784,"raining data scenario for UNMT. Based on this scenario, we propose UNMT self-training mechanisms to train a robust UNMT system and improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems. 1 Introduction Recently, unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has attracted a high level of interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Wu et al., 2019; Sun et al., 2019, 2020b). With the help of cross-lingual language model pretraining (Lample and Conneau, 2019; Song et al., 2019; Sun et al., 2020a), the denoising auto-encoder (Vincent et al., 2010), and backtranslation (Sennrich et al., 2016a), UNMT has achieved remarkable results in several translation tasks. However, in real-world scenarios, in contrast to the many large corpora available for high-resource languages such as English and French, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian. Data size (sentences) En-Fr Fr-En 50M En and 50M Fr (Baseline)"
2021.naacl-main.311,2020.acl-main.324,1,0.817815,"improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems. 1 Introduction Recently, unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has attracted a high level of interest in the machine translation community (Artetxe et al., 2018; Lample et al., 2018a; Yang et al., 2018; Lample et al., 2018b; Wu et al., 2019; Sun et al., 2019, 2020b). With the help of cross-lingual language model pretraining (Lample and Conneau, 2019; Song et al., 2019; Sun et al., 2020a), the denoising auto-encoder (Vincent et al., 2010), and backtranslation (Sennrich et al., 2016a), UNMT has achieved remarkable results in several translation tasks. However, in real-world scenarios, in contrast to the many large corpora available for high-resource languages such as English and French, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian. Data size (sentences) En-Fr Fr-En 50M En and 50M Fr (Baseline) 25M En and 25M Fr 50M En and 2M Fr 2M En and 50M Fr 2M En and 2M Fr 36.63 36.59 31.01 31.84 30.91 34.38 34.34 31.06 30.21 29.86 Ta"
2021.naacl-main.311,N19-1120,0,0.040071,"Missing"
2021.semeval-1.117,P17-1080,0,0.0285271,"d an ensemble method with obvious improvement. The BiLSTM network has a strong ability to capture long-term dependencies of the input sequence for sequence labeling task (Huang et al., 2015). We tried to add BiLSTM layer after transformer. But this resulted in overfitting, and the training speed was greatly reduced. We also tried to combine the information from word embedding with the information from the deep layer. It is proved that, in the machine translation task, the low layers of the network are more focused on lexical information, while deeper layers pay more attention to word meaning (Belinkov et al., 2017). In toxic spans detection task, we consider the information from the lower layers to be important. So we concatenate the word embedding layer with the output of ERNIE, but this didn’t work. 5 Conclusion and Future Work The paper describes our system at SemEval-2021 Task 5, which integrating Transformer and CRF for Toxic Spans Detection task. It is shown that, in this task, using ERNIE as pre-trained model achieves better performance in Transformer-CRF architecture. We convert the character-level sequence labeling task into token-level, and prove the importance of preprocessing method. We also"
2021.semeval-1.117,2021.semeval-1.6,0,0.0153426,"e disambiguation, an approach to detect hate speech in online text is presented (Warner and Hirschberg, 2012), which uses template-based strategy to generate features and an SVM classifier to identify whether the text is toxic or not. In SemEval-2020 Task 12 (Zampieri et al., 2020) and SemEval-2019 Task 6 (Zampieri et al., 2019), which also related to offensive statements, ∗ Equal contribution. † Corresponding author. transformer-based methods were the most popular approaches for their great advantages in learning word representations in context. In Semeval-2021 task 5: Toxic Spans Detection (Pavlopoulos et al., 2021), the organizers use posts from the publicly available Civil Comments dataset (Borkan et al., 2019), which already comprises post-level toxicity annotations. After manual annotation, character-level annotation results are obtained, which are the toxic spans we need to locate. The task extends the prior work by identifying spans that make a text toxic, which can better explain why posts are offensive rather than just giving a system-generated unexplained toxicity score. We model the task as a sequence labeling task because toxic spans are contextually influenced. Our model is in Transformer-CRF"
2021.semeval-1.117,W12-2103,0,0.0626786,"king 3rd for the official evaluation. 1 Introduction With the prosperity of the Internet, it is easier and easier for people to get information and publish their opinions online. However, sometimes users’ opinions can be offensive to others. Because toxic posts will have a negative impact on the network environment, and manual identification is timeconsuming and expensive, automatic detection of these behaviors has attracted researchers’ attention. After adapting the hate-speech problem to the problem of word sense disambiguation, an approach to detect hate speech in online text is presented (Warner and Hirschberg, 2012), which uses template-based strategy to generate features and an SVM classifier to identify whether the text is toxic or not. In SemEval-2020 Task 12 (Zampieri et al., 2020) and SemEval-2019 Task 6 (Zampieri et al., 2019), which also related to offensive statements, ∗ Equal contribution. † Corresponding author. transformer-based methods were the most popular approaches for their great advantages in learning word representations in context. In Semeval-2021 task 5: Toxic Spans Detection (Pavlopoulos et al., 2021), the organizers use posts from the publicly available Civil Comments dataset (Borka"
2021.semeval-1.117,S19-2010,0,0.0224716,"ive to others. Because toxic posts will have a negative impact on the network environment, and manual identification is timeconsuming and expensive, automatic detection of these behaviors has attracted researchers’ attention. After adapting the hate-speech problem to the problem of word sense disambiguation, an approach to detect hate speech in online text is presented (Warner and Hirschberg, 2012), which uses template-based strategy to generate features and an SVM classifier to identify whether the text is toxic or not. In SemEval-2020 Task 12 (Zampieri et al., 2020) and SemEval-2019 Task 6 (Zampieri et al., 2019), which also related to offensive statements, ∗ Equal contribution. † Corresponding author. transformer-based methods were the most popular approaches for their great advantages in learning word representations in context. In Semeval-2021 task 5: Toxic Spans Detection (Pavlopoulos et al., 2021), the organizers use posts from the publicly available Civil Comments dataset (Borkan et al., 2019), which already comprises post-level toxicity annotations. After manual annotation, character-level annotation results are obtained, which are the toxic spans we need to locate. The task extends the prior w"
C02-1003,P95-1033,0,0.346537,"the next section, a bilingual language model is introduced. Then, a bilingual parsing method supervised by English parsing is proposed in section 2. Based on the bilingual parsing, Chinese bracketing knowlege is extracted in section 3. The evaluation and discussion are given in section 4. We conclude with discussion of future work. 1 A bilingual language model – ITG Wu (1997) has proposed a bilingual language model called Inversion Transduction Grammar (ITG), which can be used to parse bilingual sentence pairs simultaneously. We will give a brief description here. For details please refer to (Wu 1995, Wu 1997). The Inversion Transduction Grammar is a bilingual context-free grammar that generates two matched output languages (referred to as L1 and L2). It also differs from standard context-free grammars in that the ITG allows right-hand side production in two directions: straight or inverted. The following examples are two ITG productions: C -> [A B] C -> <A B> Each nonterminal symbol stands for a pair of matched strings. For example, the nonterminal A stands for the string-pair (A1, A2). A1 is a sub-string in L1, and A2 is A1’s corresponding translation in L2. Similarly, (B1, B2) denotes"
C02-1003,J97-3002,0,0.898238,"results. The main idea of the method is that we may acquire knowledge for a language lacking a rich collection of resources and tools from a second language that is full of them. The rest of this paper is organized as follows : In the next section, a bilingual language model is introduced. Then, a bilingual parsing method supervised by English parsing is proposed in section 2. Based on the bilingual parsing, Chinese bracketing knowlege is extracted in section 3. The evaluation and discussion are given in section 4. We conclude with discussion of future work. 1 A bilingual language model – ITG Wu (1997) has proposed a bilingual language model called Inversion Transduction Grammar (ITG), which can be used to parse bilingual sentence pairs simultaneously. We will give a brief description here. For details please refer to (Wu 1995, Wu 1997). The Inversion Transduction Grammar is a bilingual context-free grammar that generates two matched output languages (referred to as L1 and L2). It also differs from standard context-free grammars in that the ITG allows right-hand side production in two directions: straight or inverted. The following examples are two ITG productions: C -> [A B] C -> <A B> Eac"
C02-1003,1993.iwpt-1.3,0,0.13968,"Missing"
C02-1003,O96-2006,0,\N,Missing
C02-1003,J93-2004,0,\N,Missing
C02-1003,P97-1003,0,\N,Missing
C02-1003,J00-2004,0,\N,Missing
C02-1003,O01-2004,1,\N,Missing
C02-1057,2001.mtsummit-papers.25,0,0.293303,"Missing"
C02-1057,2001.mtsummit-papers.67,0,0.0972107,"-occurrence and so on as indicators of translation quality. Brew C (1994) compares human rankings and automatic measures to decide the translation quality, whose criteria involve word frequency, POS tagging distribution and other text features. Another type of evaluation method involves comparison of the translation result with human translations. Yokoyama (2001) proposed a two-way MT based evaluation method, which compares output Japanese sentences with the original Japanese sentence for the word identification, the correctness of the modification, the syntactic dependency and the parataxis. Yasuda (2001) evaluates the translation output by measuring the similarity between the translation output and translation answer candidates from a parallel corpus. Akiba (2001) uses multiple edit distances to automatically rank machine translation output by translation examples. Another path of machine translation evaluation is based on test suites. Yu (1993) designs a test suite consisting of sentences with various test points. Guessoum (2001) proposes a semi-automatic evaluation method of the grammatical coverage machine translation systems via a database of unfolded grammatical structures. Koh (2001) de"
C02-1057,2001.mtsummit-papers.68,0,0.060773,"Missing"
C02-1057,2001.mtsummit-papers.3,0,\N,Missing
C02-1057,bohan-etal-2000-evaluating,0,\N,Missing
C02-1057,2001.mtsummit-papers.35,0,\N,Missing
C02-1057,H94-1019,0,\N,Missing
C02-1057,C00-1055,0,\N,Missing
C04-1104,P91-1027,0,0.0556205,"nerated by means of linguistic heuristic information and filtered via statistical methods. Evaluation on the acquisition of 20 multi-pattern verbs shows that our experiment achieved the similar precision and recall with former researches. Besides, simple application of the acquired lexicon to a PCFG parser indicates great potentialities of subcategorization information in the fields of NLP. Credits This research is sponsored by National Natural Science Foundation (Grant No. 60373101 and 603750 19), and High-Tech Research and Development Program (Grant No. 2002AA117010-09). Introduction Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective subcategorization information specified both in the field of traditional linguistics and that of computational linguistics. As for the former, subcategory theories illustrating the syntactic behaviors of verbal predicates are now much more systemically improved, e.g. (Korhonen 2001). And for auto-acquisition and relevant application, researchers have made great achievements not only in English, e.g. (Briscoe and Carroll 1997), (Korhonen 2003), but also in many other languages, such as Germany (Schult"
C04-1104,J93-2002,0,0.703304,"Missing"
C04-1104,A97-1052,0,0.544317,"gh-Tech Research and Development Program (Grant No. 2002AA117010-09). Introduction Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective subcategorization information specified both in the field of traditional linguistics and that of computational linguistics. As for the former, subcategory theories illustrating the syntactic behaviors of verbal predicates are now much more systemically improved, e.g. (Korhonen 2001). And for auto-acquisition and relevant application, researchers have made great achievements not only in English, e.g. (Briscoe and Carroll 1997), (Korhonen 2003), but also in many other languages, such as Germany (Schulte im Walde 2002), Czech (Sarkar and Zeman 2000), and Portuguese (Gamallo et. al 2002). However, relevant theoretical researches on Chinese verbs are generally limited to case grammar, valency, some semantic computation theories, and a few papers on manual acquisition or prescriptive designment of syntactic patterns. Due to irrelevant initial motivations, syntactic and semantic generalizabilities of the consequent outputs are not in such a harmony that satisfies the description granularity for SCF (Han and Zhao 2004). T"
C04-1104,W02-0905,0,0.46107,"Missing"
C04-1104,P03-1009,0,0.0837542,"ment Program (Grant No. 2002AA117010-09). Introduction Since (Brent 1991) there have been a considerable amount of researches focusing on verb lexicons with respective subcategorization information specified both in the field of traditional linguistics and that of computational linguistics. As for the former, subcategory theories illustrating the syntactic behaviors of verbal predicates are now much more systemically improved, e.g. (Korhonen 2001). And for auto-acquisition and relevant application, researchers have made great achievements not only in English, e.g. (Briscoe and Carroll 1997), (Korhonen 2003), but also in many other languages, such as Germany (Schulte im Walde 2002), Czech (Sarkar and Zeman 2000), and Portuguese (Gamallo et. al 2002). However, relevant theoretical researches on Chinese verbs are generally limited to case grammar, valency, some semantic computation theories, and a few papers on manual acquisition or prescriptive designment of syntactic patterns. Due to irrelevant initial motivations, syntactic and semantic generalizabilities of the consequent outputs are not in such a harmony that satisfies the description granularity for SCF (Han and Zhao 2004). The only auto-acqu"
C04-1104,P02-1029,0,0.0986094,"e have been a considerable amount of researches focusing on verb lexicons with respective subcategorization information specified both in the field of traditional linguistics and that of computational linguistics. As for the former, subcategory theories illustrating the syntactic behaviors of verbal predicates are now much more systemically improved, e.g. (Korhonen 2001). And for auto-acquisition and relevant application, researchers have made great achievements not only in English, e.g. (Briscoe and Carroll 1997), (Korhonen 2003), but also in many other languages, such as Germany (Schulte im Walde 2002), Czech (Sarkar and Zeman 2000), and Portuguese (Gamallo et. al 2002). However, relevant theoretical researches on Chinese verbs are generally limited to case grammar, valency, some semantic computation theories, and a few papers on manual acquisition or prescriptive designment of syntactic patterns. Due to irrelevant initial motivations, syntactic and semantic generalizabilities of the consequent outputs are not in such a harmony that satisfies the description granularity for SCF (Han and Zhao 2004). The only auto-acquisition work for Chinese SCF made by (Han and Zhao 2004) describes the pred"
C04-1104,C00-2100,0,0.634205,"erable amount of researches focusing on verb lexicons with respective subcategorization information specified both in the field of traditional linguistics and that of computational linguistics. As for the former, subcategory theories illustrating the syntactic behaviors of verbal predicates are now much more systemically improved, e.g. (Korhonen 2001). And for auto-acquisition and relevant application, researchers have made great achievements not only in English, e.g. (Briscoe and Carroll 1997), (Korhonen 2003), but also in many other languages, such as Germany (Schulte im Walde 2002), Czech (Sarkar and Zeman 2000), and Portuguese (Gamallo et. al 2002). However, relevant theoretical researches on Chinese verbs are generally limited to case grammar, valency, some semantic computation theories, and a few papers on manual acquisition or prescriptive designment of syntactic patterns. Due to irrelevant initial motivations, syntactic and semantic generalizabilities of the consequent outputs are not in such a harmony that satisfies the description granularity for SCF (Han and Zhao 2004). The only auto-acquisition work for Chinese SCF made by (Han and Zhao 2004) describes the predefinition of 152 general frames"
C04-1104,dorr-etal-2000-chinese,0,\N,Missing
C04-1104,H91-1067,0,\N,Missing
C08-1130,I05-3009,0,0.18405,"Missing"
C08-1130,J04-1004,0,0.338088,"Missing"
C08-1130,W02-1407,0,0.390796,"Missing"
C08-1130,C02-1125,0,0.511096,"Missing"
C08-1130,P07-2018,0,0.0627672,"Missing"
C08-1130,W03-1704,0,0.897926,"Missing"
C08-1130,W93-0104,0,0.0852044,"Missing"
C08-1130,W01-0513,0,0.115009,"gy, Harbin Institute of Technology, Harbin 150001, China tjzhao@mtlab.hit.edu .cn extraction is an essential task in domain knowledge acquisition which can be used for lexicon update, domain ontology construction, etc. Term extraction involves two steps. The first step extracts candidates by unithood calculation to qualify a string as a valid term. The second step verifies them through termhood measures (Kageura and Umino, 1996) to validate their domain specificity. Existing techniques extract term candidates mainly by two kinds of statistic based measures including internal association (e.g. Schone and Jurafsky, 2001) and context dependency (e.g. Sornlertlamvanich et al., 2000). These techniques are also used in Chinese term candidate extraction (e.g. Luo and Sun, 2003; Ji and Lu, 2007). Domain dependent features of domain terms are used in a weighted manner to identify term boundaries. However, these algorithms always face the dilemma that fewer features are not enough to identify terms from non-terms whereas more features lead to more conflicts among selected features in a specific instance. Most term verification techniques use features on the difference in distribution of a term occurred within a domai"
C08-1130,C00-2116,0,0.353401,"tjzhao@mtlab.hit.edu .cn extraction is an essential task in domain knowledge acquisition which can be used for lexicon update, domain ontology construction, etc. Term extraction involves two steps. The first step extracts candidates by unithood calculation to qualify a string as a valid term. The second step verifies them through termhood measures (Kageura and Umino, 1996) to validate their domain specificity. Existing techniques extract term candidates mainly by two kinds of statistic based measures including internal association (e.g. Schone and Jurafsky, 2001) and context dependency (e.g. Sornlertlamvanich et al., 2000). These techniques are also used in Chinese term candidate extraction (e.g. Luo and Sun, 2003; Ji and Lu, 2007). Domain dependent features of domain terms are used in a weighted manner to identify term boundaries. However, these algorithms always face the dilemma that fewer features are not enough to identify terms from non-terms whereas more features lead to more conflicts among selected features in a specific instance. Most term verification techniques use features on the difference in distribution of a term occurred within a domain and across domains, such as TF-IDF (Salton and McGill, 1983"
C08-1141,E06-1032,0,0.273045,"phenomena to provide diagnostic evaluation. The effectiveness of our approach for diagnostic evaluation is verified through experiments on various types of MT systems. 1 Introduction Automatic MT evaluation is a crucial issue for MT system developers. The state-of-the-art methods for automatic MT evaluation are using an n-gram based metric represented by BLEU (Papineni et al., 2002) and its variants. Ever since its invention, the BLEU score has been a widely accepted benchmark for MT system evaluation. Nevertheless, the research community has been aware of the deficiencies of the BLEU metric (Callison-Burch et al., 2006). For instance, BLEU fails to sufficiently capture the vitality of natural languages: all grams of a sentence are © 2008. Licensed under the Creative Commons AttributionNoncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. treated equally ignoring their linguistic significance; only consecutive grams are considered ignoring the skipped grams of certain linguistic relations; candidate translation gets acknowledged only if it uses exactly the same lexicon as the reference ignoring the variation in lexical choice. Furthermore, BL"
C08-1141,A00-2019,0,0.0155641,"Missing"
C08-1141,W04-3250,0,0.149378,"Missing"
C08-1141,P04-1077,0,0.0226721,"uding 3,200 pairs of sentences containing 6 classes of check-points. Their check-points were manually constructed by human experts, therefore it will be costly to build new test corpus while the check-points in our approach are constructed automatically. Another limitation of their work is that only binary score is used for credits while we use n-gram matching rate which provides a broader coverage of different levels of matching. There are many recent work motivated by ngram based approach. (Callison-Burch et al., 2006) criticized the inadequate accuracy of evaluation at the sentence level. (Lin and Och, 2004) used longest common subsequence and skipbigram statistics. (Banerjee and Lavie, 2005) calculated the scores by matching the unigrams on the surface forms, stemmed forms and senses. (Liu et al., 2005) used syntactic features and unlabeled head-modifier dependencies to evaluate MT quality, outperforming BLEU on sentence level correlations with human judgment. (Gimenez and Marquez, 2007) showed that linguistic features at more abstract levels such as dependency relation may provide more reliable system rankings. (Yang et al., 2007) formulates MT evaluation as a ranking problems leading to greate"
C08-1141,W05-0904,0,0.0285694,"Missing"
C08-1141,J03-1002,0,0.00842467,"Missing"
C08-1141,P02-1040,0,0.0750984,"Missing"
C08-1141,W00-1212,1,0.735942,"Missing"
C08-1141,P03-1054,0,0.00524886,"Missing"
C08-1141,W07-0738,0,\N,Missing
C08-1141,W05-0909,0,\N,Missing
C10-2025,C08-1005,0,0.0879333,"rne, 2004) decoding over n-best list finds a translation that has lowest expected loss with all the other hypotheses, and it shows that improvement over the Maximum a Posteriori (MAP) decoding. Several word-based methods (Rosti et al., 2007a; Sim et al., 2007) have also been proposed. Usually, these methods take n-best list from different SMT systems as inputs, and construct a confusion network for second-pass decoding. There are also a lot of research work to advance the confusion network construction by finding better alignment between the skeleton and the other hypotheses (He et al., 2008; Ayan et al., 2008). Typically, all the approaches above only use full hypotheses but have no access to the PHS information. In this paper, we present hybrid decoding — a novel statistical machine translation (SMT) decoding paradigm using multiple SMT systems. In our work, in addition to component SMT systems, system combination method is also employed in generating partial translation hypotheses throughout the decoding process, in which smaller hypotheses generated by each component decoder and hypotheses combination are used in the following decoding steps to generate larger hypotheses. Experimental results on"
C10-2025,P06-1121,0,0.0535726,"es word alignment information. However, in hybrid decoding, it is quite time-consuming and impractical to conduct word alignment like GIZA++ for each span. Fortunately, unit hypotheses word alignment can be obtained from the model training process, which is shown in Figure 2. We devise a heuristic approach for PHS alignment that leverages the translation derivations from the sub-phrases. The derivation information ultimately comes from the phrase table in phrase-based systems (Koehn et al., 2003; Xiong et al., 2006) or the rule table in syntactic-based systems (Chiang, 2007; Liu et al., 2007; Galley et al., 2006). The derivation is built in a phrase-based system as follows. For example, we have two phrase where string “m-n”means the mth word in the source phrase is aligned to the nth word in the target phrase. When combining the two phrases for generating “我们 的 经济 利益”, we obtain the translation hypothesis as “our economic interests”and also integrate the alignment fragment to get “0-0 1-0 2-1 3-2”. The case is similar in syntactic-based system for non-terminal substitution, which we will not discuss further here. Next, we introduce the skeleton-to-hypothesis word alignment algorithm in detail. With th"
C10-2025,N03-1017,0,0.0544342,"Missing"
C10-2025,P02-1040,0,0.0893694,"Suppose we have n individual decoders. The ranking function Fn of the nth decoder can be written as: Fn (e) = m X λn,i hn,i (f, e) (2) i=1 Figure 3: Algorithm for skeleton-to-hypothesis alignment Subroutines UNION(A,B) GETALIGN(S,align) tial in confusion network construction. The simplest way is to use the top-1 PHS from any individual decoder with the best performance under some criteria. However, this cannot always lead to better performance on some evaluation metrics (Rosti et al., 2007a). An alternative would be MBR method with some loss function such as TER (Snover et al., 2006) or BLEU (Papineni et al., 2002). We show the experimental results of two skeleton selection methods for PHS combination in Section 3. Description the union of set A and set B get the words aligned to S based on align similarity between w1 and w2 , we use edit distance here align w1 with w2 Table 1: Description for subroutines Due to the variety of the word order in nbest outputs, skeleton selection becomes essenwhere each hn,i (f, e) is a feature function of the nth decoder, and λn,i is the corresponding feature weight. m is the number of features in each decoder. The final result of hybrid decoder is the top1 translation f"
C10-2025,P00-1056,0,\N,Missing
C10-2025,E06-1005,0,\N,Missing
C10-2025,P07-1089,0,\N,Missing
C10-2025,P09-1066,1,\N,Missing
C10-2025,P06-1066,0,\N,Missing
C10-2025,P07-1040,0,\N,Missing
C10-2025,N04-1022,0,\N,Missing
C10-2025,D07-1056,1,\N,Missing
C10-2025,P09-1065,0,\N,Missing
C10-2025,P03-1021,0,\N,Missing
C10-2025,P05-1033,0,\N,Missing
C10-2025,N07-1029,0,\N,Missing
C10-2025,J97-3002,0,\N,Missing
C10-2025,D08-1011,0,\N,Missing
C10-2025,W04-3250,0,\N,Missing
C10-2025,J07-2003,0,\N,Missing
C10-2076,P98-1013,0,0.118461,"hieved by using the SVM classifier with both the basic features and the combined features. Experimental results on Chinese Proposition Bank (CPB) show that the method outperforms the traditional constituent-based or dependency-based SRL methods. 1 Introduction Semantic role labeling (SRL) is a major method in current semantic analysis which is important to NLP applications. The SRL task is to identify semantic roles (or arguments) of each predicate and then label them with their functional tags, such as 'Arg0' and 'ArgM' in PropBank (Palmer et al., 2005), or 'Agent' and 'Patient' in FrameNet (Baker et al., 1998). The significance of syntactic analysis in SRL has been proven by (Gildea and Palmer, 2002; Punyakanok et al., 2005), and syntactic parsing has been applied by almost all current studies. In terms of syntactic representations, the SRL approaches are mainly divided into three categories: constituent-based, chunkbased and dependency-based. Constituentbased SRL has been studied intensively with satisfactory results. Chunk-based SRL has been found to be less effective than the constituent-based by (Punyakanok et al., 2005). In recent years, the dependency-based SRL has been greatly promoted by th"
C10-2076,P09-1005,0,0.106569,"ed use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to select effective combined features using both constituent-based and dependency-based features to make full use of two syntactic views. 2 Related Work In recent years, many advances have been made on SRL using singular syntactic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues, 2008; Zhao et al., 2009), and CCG (Chen and Rambow, 2003; Boxwell et al, 2009). However, there are few studies on the use of multiple syntactic views. We briefly review the relevant studies of SRL using multiple syntactic views as follows. Pradhan et al. (2005) built three semantic role labelers using constituent, dependency and chunk syntactic views, and then heuristically combined them at the output level. The method was further improved in Pradhan et al. (2008) which trains two semantic role labelers for constituents and dependency separately, and then uses the output of the two systems as additional features in another labeler using chunk parsing. The result shows a"
C10-2076,W03-1006,0,0.0264139,"work, we exploit combined use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to select effective combined features using both constituent-based and dependency-based features to make full use of two syntactic views. 2 Related Work In recent years, many advances have been made on SRL using singular syntactic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues, 2008; Zhao et al., 2009), and CCG (Chen and Rambow, 2003; Boxwell et al, 2009). However, there are few studies on the use of multiple syntactic views. We briefly review the relevant studies of SRL using multiple syntactic views as follows. Pradhan et al. (2005) built three semantic role labelers using constituent, dependency and chunk syntactic views, and then heuristically combined them at the output level. The method was further improved in Pradhan et al. (2008) which trains two semantic role labelers for constituents and dependency separately, and then uses the output of the two systems as additional features in another labeler using chunk parsi"
C10-2076,D08-1034,0,0.035678,"Missing"
C10-2076,J02-3001,0,0.53152,"g several combined features each of which is composed by two single features (Xue and Palmer, 2004; Toutanova et al., 2005; Zhao et al., 2009). Thus, in this work, we exploit combined use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to select effective combined features using both constituent-based and dependency-based features to make full use of two syntactic views. 2 Related Work In recent years, many advances have been made on SRL using singular syntactic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues, 2008; Zhao et al., 2009), and CCG (Chen and Rambow, 2003; Boxwell et al, 2009). However, there are few studies on the use of multiple syntactic views. We briefly review the relevant studies of SRL using multiple syntactic views as follows. Pradhan et al. (2005) built three semantic role labelers using constituent, dependency and chunk syntactic views, and then heuristically combined them at the output level. The method was further improved in Pradhan et al. (2008) which trains two semantic role la"
C10-2076,P02-1031,0,0.0182034,"es. Experimental results on Chinese Proposition Bank (CPB) show that the method outperforms the traditional constituent-based or dependency-based SRL methods. 1 Introduction Semantic role labeling (SRL) is a major method in current semantic analysis which is important to NLP applications. The SRL task is to identify semantic roles (or arguments) of each predicate and then label them with their functional tags, such as 'Arg0' and 'ArgM' in PropBank (Palmer et al., 2005), or 'Agent' and 'Patient' in FrameNet (Baker et al., 1998). The significance of syntactic analysis in SRL has been proven by (Gildea and Palmer, 2002; Punyakanok et al., 2005), and syntactic parsing has been applied by almost all current studies. In terms of syntactic representations, the SRL approaches are mainly divided into three categories: constituent-based, chunkbased and dependency-based. Constituentbased SRL has been studied intensively with satisfactory results. Chunk-based SRL has been found to be less effective than the constituent-based by (Punyakanok et al., 2005). In recent years, the dependency-based SRL has been greatly promoted by the CoNLL shared tasks on semantic parsing (Hajic et al., 2009). However, there is not much r"
C10-2076,C04-1186,0,0.101237,"Palmer, 2004; Toutanova et al., 2005; Zhao et al., 2009). Thus, in this work, we exploit combined use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to select effective combined features using both constituent-based and dependency-based features to make full use of two syntactic views. 2 Related Work In recent years, many advances have been made on SRL using singular syntactic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues, 2008; Zhao et al., 2009), and CCG (Chen and Rambow, 2003; Boxwell et al, 2009). However, there are few studies on the use of multiple syntactic views. We briefly review the relevant studies of SRL using multiple syntactic views as follows. Pradhan et al. (2005) built three semantic role labelers using constituent, dependency and chunk syntactic views, and then heuristically combined them at the output level. The method was further improved in Pradhan et al. (2008) which trains two semantic role labelers for constituents and dependency separately, and then uses the outpu"
C10-2076,D08-1008,0,0.0809213,"outanova et al., 2005; Zhao et al., 2009). Thus, in this work, we exploit combined use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to select effective combined features using both constituent-based and dependency-based features to make full use of two syntactic views. 2 Related Work In recent years, many advances have been made on SRL using singular syntactic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues, 2008; Zhao et al., 2009), and CCG (Chen and Rambow, 2003; Boxwell et al, 2009). However, there are few studies on the use of multiple syntactic views. We briefly review the relevant studies of SRL using multiple syntactic views as follows. Pradhan et al. (2005) built three semantic role labelers using constituent, dependency and chunk syntactic views, and then heuristically combined them at the output level. The method was further improved in Pradhan et al. (2008) which trains two semantic role labelers for constituents and dependency separately, and then uses the output of the two systems as addi"
C10-2076,P03-1056,0,0.0401976,"ween the z-score of the combined (1) IntraDist f ( D pos , Dneg ) i i i i 668 all approach, in which six SVMs will be trained to separate each semantic type from the remaining types. We divide the corpus into three parts: the first 99 documents (chtb_001.fid to chtb_099.fid) serve as the test data, the last 32 documents (chtb_900.fid to chtb_931.fid) serve as the development data and the left 629 documents (chtb_100.fid to chtb_899.fid) serve as the training data. We use the SVM-Light Toolkit version 6.02 (Joachims, 1999) for the implementation of SVM, and use the Stanford Parser version 1.6 (Levy and Manning, 2003) as the constituent parser and the constituent-to-dependency converter. In classifications, we employ the linear kernel for SVM and set the regularization parameter to the default value which is the reciprocal of the average Euclidean norm of training data. The performance metrics are: accuracy (A), precision (P), recall (R) and F-score (F). feature and its two corresponding basic features as given in (9). I ( f ab ) = Z ( f ab ) − Max ( Z ( f a ), Z ( f b ) ) (9) Finally, the combined feature with a negative I ( f ab ) value is eliminated. Then, we will rank the combined features in terms of"
C10-2076,de-marneffe-etal-2006-generating,0,0.0151111,"Missing"
C10-2076,D09-1143,0,0.0228418,"is extremely high. Hacioglu (2004) proposed a SRL method to combine constituent and dependency syntactic views where the dependency parses are ob-tained through automatic mapping of constitu-ent parses. It uses the constituent parses to get candidates and then, the dependency parses to label them. Boxwell et al. (2009) proposed a SRL method using features of three syntactic views: 666 CCG, CFG and dependency. It primarily uses CCG-based features associated with 4 CFGbased and 2 dependency-based features. The combination of these syntactic views leads to a substantial performance improvement. Nguyen et al. (2009) proposed a composite kernel based on both constituent and dependency syntactic views and achieved a significant improvement in a relation extraction application. 3 Design Principle and Basic Features Compared to related work, the proposed method integrates the constituent and dependency views in a collaborative manner. First, we define a basic feature set containing features from constituent and dependency syntactic views. Then, to make better use of two syntactic views, we introduce a statistical method to select effective combined features from the basic feature set. Finally we use both the"
C10-2076,J05-1004,0,0.112907,"features which are composed by the basic features. SRL is achieved by using the SVM classifier with both the basic features and the combined features. Experimental results on Chinese Proposition Bank (CPB) show that the method outperforms the traditional constituent-based or dependency-based SRL methods. 1 Introduction Semantic role labeling (SRL) is a major method in current semantic analysis which is important to NLP applications. The SRL task is to identify semantic roles (or arguments) of each predicate and then label them with their functional tags, such as 'Arg0' and 'ArgM' in PropBank (Palmer et al., 2005), or 'Agent' and 'Patient' in FrameNet (Baker et al., 1998). The significance of syntactic analysis in SRL has been proven by (Gildea and Palmer, 2002; Punyakanok et al., 2005), and syntactic parsing has been applied by almost all current studies. In terms of syntactic representations, the SRL approaches are mainly divided into three categories: constituent-based, chunkbased and dependency-based. Constituentbased SRL has been studied intensively with satisfactory results. Chunk-based SRL has been found to be less effective than the constituent-based by (Punyakanok et al., 2005). In recent year"
C10-2076,P05-1072,0,0.256083,"Missing"
C10-2076,J08-2006,0,0.0192923,"ic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues, 2008; Zhao et al., 2009), and CCG (Chen and Rambow, 2003; Boxwell et al, 2009). However, there are few studies on the use of multiple syntactic views. We briefly review the relevant studies of SRL using multiple syntactic views as follows. Pradhan et al. (2005) built three semantic role labelers using constituent, dependency and chunk syntactic views, and then heuristically combined them at the output level. The method was further improved in Pradhan et al. (2008) which trains two semantic role labelers for constituents and dependency separately, and then uses the output of the two systems as additional features in another labeler using chunk parsing. The result shows an improvement to each labeler alone. A possible reason for the improvement is that the errors caused by different syntactic parsers are compensated. Yet, the features of different syntactic views can hardly complement each other in labeling. And the complexity of using multiple syntactic parsers is extremely high. Hacioglu (2004) proposed a SRL method to combine constituent and dependenc"
C10-2076,W05-0639,0,0.0461083,"Missing"
C10-2076,P05-1073,0,0.105942,"ng methods to predict the semantic labels. The method also involves two classification phases: semantic role identification (SRI) and semantic role classification (SRC). In addition, a heuristicbased pruning preprocessing (Xue and Palmer, 2004) is used to filter out a lot of apparently inappropriate constituents at the beginning. 665 Coling 2010: Poster Volume, pages 665–673, Beijing, August 2010 And it has been widely reported that, in feature-based SRL, the performance can be improved by adding several combined features each of which is composed by two single features (Xue and Palmer, 2004; Toutanova et al., 2005; Zhao et al., 2009). Thus, in this work, we exploit combined use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to select effective combined features using both constituent-based and dependency-based features to make full use of two syntactic views. 2 Related Work In recent years, many advances have been made on SRL using singular syntactic view, such as constituent (Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Surdeanu et al., 2007), dependency (Hacioglu, 2004; Johansson and Nugues,"
C10-2076,W04-3212,0,0.414605,"ntroduces a novel method for Chinese SRL utilizing both constituent-based and dependency-based features. The method takes constituent as the basic unit of argument and adopts the labeling of PropBank. It follows the prevalent feature-based SRL methods to first turn predicate-argument pairs into flat structures by well-defined linguistic features, and then uses machine learning methods to predict the semantic labels. The method also involves two classification phases: semantic role identification (SRI) and semantic role classification (SRC). In addition, a heuristicbased pruning preprocessing (Xue and Palmer, 2004) is used to filter out a lot of apparently inappropriate constituents at the beginning. 665 Coling 2010: Poster Volume, pages 665–673, Beijing, August 2010 And it has been widely reported that, in feature-based SRL, the performance can be improved by adding several combined features each of which is composed by two single features (Xue and Palmer, 2004; Toutanova et al., 2005; Zhao et al., 2009). Thus, in this work, we exploit combined use of both constituentbased and dependency-based features in addition to using features of singular types of syntactic view. We propose a statistical method to"
C10-2076,J08-2004,0,0.0140941,"improve the feature-based SRL method. system (Liu et al. 2007) which uses 19 basic The complexity of the method will not increase features, 10 combined features and also the significantly compared to the method using ME classifier. Third, the 'Che' (Che, 2008) sys- one syntactic view as we use a constituent-totem use a hybrid convolution tree kernel to dependency conversion rather than additional directly measure the similarity between two dependency parsing. The effectiveness of the constituent structures. Fourth, the 'Xue2' sys- method has been proven by the experiments on tem described in (Xue, 2008), which is similar CPB using SVM classifier with linear kernel. to 'Xue1' on basic framework, but using a new feature set. The 'Xue2' system evaluates the Acknowledgments SRL of the verbal predicates and the nominal- This work is supported by the Key Program of ized predicates separately, and offers no con- National Natural Science Foundation of China solidated evaluation in (Xue, 2008). So in the under Grant No. 60736014, the Key Project of comparison, we refer to its performance on the the National High Technology Research and verbal predicates and the nominalized predi- Development Program"
C10-2076,D09-1004,0,0.179281,"Missing"
C10-2076,N07-1070,0,\N,Missing
C10-2076,C98-1013,0,\N,Missing
C10-2076,W09-1201,0,\N,Missing
C10-2076,N04-1030,0,\N,Missing
C10-2086,J97-3002,0,0.313212,"Missing"
C10-2086,J98-4004,0,0.399118,"d of phrasal/constituent level model. In our model, with the help of the alignment and the head-modifier dependency based relationship in the source side, the reordering type of each target word with alignment in source side is identified as one of pre-defined reordering types. With these reordering types, the reordering of phrase in translation is estimated on word level. 748 Coling 2010: Poster Volume, pages 748–756, Beijing, August 2010 Fig 1. An Constituent based Parse Tree 2 Baseline ing capacity of the translation model. Instead of directly employing the parse tree fragments (Bod, 1992; Johnson, 1998) in reordering rules (Huang and Knight, 2006; Liu 2006; Zhang and Jiang 2008), we make a mapping from trees to ebest = argmaxe p ( e |f ) pLM ( e ) ωlength(e) (1) sets of head-modifier dependency relations (Collins 1996 ) which can be obtained from the where p(e|f) can be computed using phrase constituent based parse tree with the help of translation model, distortion model and lexical head rules ( Bikel, 2004 ). reordering model. pLM(e) can be computed using the language model. ωlength(e) is word penalty 3.1 Head-modifier Relation model. Among the above models, there are three According to Kl"
C10-2086,2006.amta-papers.8,0,0.0359001,"Missing"
C10-2086,J07-2003,0,0.119531,"Missing"
C10-2086,P06-1077,0,0.0454593,"Missing"
C10-2086,P01-1067,0,0.0775597,"uccessfully applied to SMT to improve translation performance. Research in applying syntax information to SMT has been carried out in two aspects. On the one hand, the syntax knowledge is employed by directly integrating the syntactic structure into the translation rules i.e. syntactic translation rules. On this perspective, the word order of the target translation is modeled by the syntax structure explicitly. Chiang (2005), Wu (1997) and Xiong (2006) learn the syntax rules using the formal grammars. While more research is conducted to learn syntax rules with the help of linguistic analysis (Yamada and Knight, 2001; Graehl and Knight, 2004). However, there are some challenges to these models. Firstly, the linguistic analysis is far from perfect. Most of these methods require an off-the-shelf parser to generate syntactic structure, which makes the translation results sensitive to the parsing errors to some extent. To tackle this problem, n-best parse trees and parsing forest (Mi and Huang, 2008; Zhang, 2009) are proposed to relieve the error propagation brought by linguistic analysis. Secondly, some phrases which violate the boundary of linguistic analysis are also useful in these models ( DeNeefe et al."
C10-2086,P08-1114,0,0.0221605,"To tackle this problem, n-best parse trees and parsing forest (Mi and Huang, 2008; Zhang, 2009) are proposed to relieve the error propagation brought by linguistic analysis. Secondly, some phrases which violate the boundary of linguistic analysis are also useful in these models ( DeNeefe et al., 2007; Cowan et al. 2006). Thus, a tradeoff needs to be found between linguistic sense and formal sense. On the other hand, instead of using syntactic translation rules, some previous work attempts to learn the syntax knowledge separately and then integrated those knowledge to the original constraint. Marton and Resnik (2008) utilize the language linguistic analysis that is derived from parse tree to constrain the translation in a soft way. By doing so, this approach addresses the challenges brought by linguistic analysis through the log-linear model in a soft way. Starting from the state-of-the-art phrase based model Moses ( Koehn e.t. al, 2007), we propose a head-modifier relation based reordering model and use the proposed model as a soft syntax constraint in the phrase-based translation framework. Compared with most of previous soft constraint models, we study the way to utilize the constituent based parse tre"
C10-2086,P08-1066,0,0.0281483,"Missing"
C10-2086,P03-1054,0,0.0259913,"8) in reordering rules (Huang and Knight, 2006; Liu 2006; Zhang and Jiang 2008), we make a mapping from trees to ebest = argmaxe p ( e |f ) pLM ( e ) ωlength(e) (1) sets of head-modifier dependency relations (Collins 1996 ) which can be obtained from the where p(e|f) can be computed using phrase constituent based parse tree with the help of translation model, distortion model and lexical head rules ( Bikel, 2004 ). reordering model. pLM(e) can be computed using the language model. ωlength(e) is word penalty 3.1 Head-modifier Relation model. Among the above models, there are three According to Klein and Manning (2003) and reordering-related components: language model, Collins (1999), there are two shortcomings in nlexical reordering model and distortion model. ary Treebank grammar. Firstly, the grammar is The language model can reorder the local target too coarse for parsing. The rules in different words within a fixed window in an implied way. context always have different distributions. SeThe lexical reordering model and distortion condly, the rules learned from training corpus reordering model tackle the reordering problem cannot cover the rules in testing set. Currently, the state-of-the-art parsing al"
C10-2086,P96-1025,0,0.203111,"ide is identified as one of pre-defined reordering types. With these reordering types, the reordering of phrase in translation is estimated on word level. 748 Coling 2010: Poster Volume, pages 748–756, Beijing, August 2010 Fig 1. An Constituent based Parse Tree 2 Baseline ing capacity of the translation model. Instead of directly employing the parse tree fragments (Bod, 1992; Johnson, 1998) in reordering rules (Huang and Knight, 2006; Liu 2006; Zhang and Jiang 2008), we make a mapping from trees to ebest = argmaxe p ( e |f ) pLM ( e ) ωlength(e) (1) sets of head-modifier dependency relations (Collins 1996 ) which can be obtained from the where p(e|f) can be computed using phrase constituent based parse tree with the help of translation model, distortion model and lexical head rules ( Bikel, 2004 ). reordering model. pLM(e) can be computed using the language model. ωlength(e) is word penalty 3.1 Head-modifier Relation model. Among the above models, there are three According to Klein and Manning (2003) and reordering-related components: language model, Collins (1999), there are two shortcomings in nlexical reordering model and distortion model. ary Treebank grammar. Firstly, the grammar is The l"
C10-2086,P96-1021,0,0.0531225,"stituents in parse tree. Chiang(2005), Marton and Resnik(2008) explored the constituent match/violation in hiero; Xiong (2009 a) added constituent parse tree based linguistic analysis into BTG model; Xiong (2009 b) added source dependency structure to BTG; Zhang(2009) added tree-kernel to BTG model. All these studies show promising results. Making soft constrain is an easy and 755 efficient way in adding linguistic analysis into formal sense SMT model. In modeling the reordering, most of previous studies are on phrase level. In Moses, the lexical reordering is modeled on adjacent phrases. In (Wu, 1996; Xiong, 2006), the reordering is also modeled on adjacent translated phrases. In hiero, the reordering is modeled on the segments of the unmotivated translation rules. The tree-tostring models (Yamada et al. 2001; Liu et al.2006) are model on phrases with syntax representations. All these studies show excellent performance, while there are few studies on word level model in recent years. It is because, we consider, the alignment in word level model is complex which limits the reordering capacity of word level models. However, our work exploits a new direction in reordering that, by utilizing"
C10-2086,P06-1066,0,0.0524097,"Missing"
C10-2086,P09-1036,1,0.886552,"Missing"
C10-2086,2009.mtsummit-posters.25,1,0.792708,"Missing"
C10-2086,P07-2045,0,0.00524484,"Missing"
C10-2086,N03-1017,0,0.0551136,"Missing"
C10-2086,W06-1628,0,0.0343592,"Missing"
C10-2086,N04-1014,0,\N,Missing
C10-2086,koen-2004-pharaoh,0,\N,Missing
C10-2086,D08-1022,0,\N,Missing
C10-2086,J02-1005,0,\N,Missing
C10-2086,J03-4003,0,\N,Missing
C10-2086,P09-1020,1,\N,Missing
C10-2086,P08-1064,1,\N,Missing
C10-2086,P08-2038,1,\N,Missing
C10-2086,P05-1033,0,\N,Missing
C10-2086,D07-1079,0,\N,Missing
C10-2086,P00-1056,0,\N,Missing
C10-2175,P07-1111,0,0.0287965,"Missing"
C10-2175,P09-1035,0,0.0879121,"Missing"
C10-2175,P06-2003,0,0.0335086,"Missing"
C10-2175,W05-0909,0,0.161374,"Missing"
C10-2175,E06-1032,0,0.0616036,"Missing"
C10-2175,W07-0738,0,0.0359518,"Missing"
C10-2175,I08-1042,0,0.050271,"Missing"
C10-2175,P03-1054,0,0.00555934,"Missing"
C10-2175,P04-1077,0,0.148674,"Missing"
C10-2175,niessen-etal-2000-evaluation,0,0.21254,"Missing"
C10-2175,W06-3112,0,0.0419574,"Missing"
C10-2175,W07-0714,0,0.462946,"Missing"
C10-2175,P02-1040,0,0.0818322,"Missing"
C10-2175,W07-0707,0,0.0315761,"Missing"
C10-2175,W09-0402,0,0.0540264,"Missing"
C10-2175,W05-0904,0,0.589594,"Missing"
C10-2175,2006.amta-papers.25,0,0.101418,"Missing"
C10-2175,N07-1006,0,0.0264202,"Missing"
C10-2175,2007.tmi-papers.15,0,0.564511,"Missing"
C10-2175,N03-2021,0,\N,Missing
C10-2175,P08-1007,0,\N,Missing
C10-2175,P05-1035,0,\N,Missing
C10-2175,C04-1046,0,\N,Missing
C12-2071,N12-1047,0,0.0686776,"U optimizes the expected BLEU, a loss more approximate towards Corpus-BLEU compared with the generalized hinge loss, and it utilizes the projection distance metric instead of L2 as with MIRA. Further, ELBUU is a MERT-like batch mode which ultraconservatively updates the weight with all training examples, but MIRA is an online one which updates with each example (Watanabe et al., 2007) or parts of examples (Chiang et al., 2008). The batch mode has some advantages over online mode: more accurate sentence-wise BLEU towards Corpus-BLEU (Watanabe, 2012) and more promising experimental performance (Cherry and Foster, 2012). Additionally, our method is similar to (Liu et al., 2012). However, the main difference is that ours is a global training method instead of a local training method. 4 Experiments and Results 4.1 Experimental Setting We conduct our translation experiments on two language pairs: Chinese-to-English and Spanishto-English. For the Chinese-to-English task, the training data is FBIS corpus consisting of about 240k sentence pairs; the development set is NIST02 evaluation data; the test set NIST05 is used as the development test set for tuning hyperparameter λ in Eq. 6; and the test datasets are NIST"
C12-2071,D08-1024,0,0.588794,"mize Eq. 3. Motivated by (Och, 2003; Smith and Eisner, 2006; Zens et al., 2007), we use the expected loss to substitute the direct loss in Eq. 3 and we obtain the objective function as follows: d(W, Wk ) + n X λX n i=1 e∈ci Losser r or (ri ; e)Pα (e |f i ; W ), with Pα (e |f i ; W ) = P exp[αW · h( f i , e)] e′ ∈c i exp[αW · h( f i , e′ )] (4) , where α &gt; 0 is a real number, each h( f i , e) is a feature vector, and d is a distance metric defined on a pair of weights. Losser r or (ri ; e) in Eq. 4 is a sentence-wise direct loss, and in this paper we used a variant of sentence BLEU proposed by Chiang et al. (2008) which smoothes BLEU statistics with pseudo-document. 3.2 Distance Metric Based on Projection Euclidean distance ( L2 norm) is usually employed as in MIRA (Watanabe et al., 2007; Chiang et al., 2008). In this section we will specifically investigate another metric for ultraconservative update in SMT. In log-linear based translation models, since the decoding strategy is the maximal posterior probability, the translation results are the same for the weight W and its positive multiplication (see Eq. 2). Therefore, for a translation decoder, we wish that the distance of two weights satisfies the"
C12-2071,P11-2031,0,0.031614,"EU. Proceedings of COLING 2012: Posters, pages 723–732, COLING 2012, Mumbai, December 2012. 723 1 Introduction Minimum error rate training (Och, 2003), MERT, is an important component of statistical machine translation (SMT), and it has been the most popular method for tuning parameters for SMT systems. One of its major contributions is the use of an evaluation metric, such as BLEU (Papineni et al., 2002), as a direct loss function during its optimization procedure by interchanging decoding and optimization steps in each round. While MERT is successful in practice, it is known to be unstable (Clark et al., 2011). At the optimization step in each round, MERT tries to repeatedly optimize a loss function defined by the k-best candidate lists. Since new k-best lists are generated and merged with the previously generated lists at each round, the optimization objective function may change drastically between two adjacent rounds (Pauls et al., 2009), and the optimized weights of these two rounds may also be far from each other. Motivated by the above observation, this paper investigates a new tuning approach under the kbest lists framework, instead of the lattices or hypergraphs framework as Macherey et al."
C12-2071,W02-1001,0,0.0637373,"ng corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments, the translation performances are measured by the case-insensitive BLEU4 metric (Papineni et al., 2002) and we use mteval-v13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). 3 At the end of tuning, we average the weights as (Collins, 2002). The norm of the averaged weight may nolonger be equal to 1, but it is irrelevant for testing, see discussion in Section 3.2. 728 Methods MERT ELBUU dev06(Dev) 28.85 28.67 test08 19.68 20.23 test09 21.36 21.72 test10 23.35 23.90+ test11 23.65 24.18+ Table 2: Comparison of two tuning methods, MERT and ELBUU, on Spanish-to-English translation tasks. + means the ELBUU method is significantly better than MERT with confidence p &lt; 0.05. Distance metrics L2 Projection NIST02(Dev) 29.95 30.06 NIST03 27.09 27.36 NIST04 29.65 29.89 NIST05 26.79 27.03 NIST06 25.98 26.30 NIST08 19.54 19.79 Table 3: Compa"
C12-2071,W04-3250,0,0.0518064,", test10, test11. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments, the translation performances are measured by the case-insensitive BLEU4 metric (Papineni et al., 2002) and we use mteval-v13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). 3 At the end of tuning, we average the weights as (Collins, 2002). The norm of the averaged weight may nolonger be equal to 1, but it is irrelevant for testing, see discussion in Section 3.2. 728 Methods MERT ELBUU dev06(Dev) 28.85 28.67 test08 19.68 20.23 test09 21.36 21.72 test10 23.35 23.90+ test11 23.65 24.18+ Table 2: Comparison of two tuning methods, MERT and ELBUU, on Spanish-to-English translation tasks. + means the ELBUU method is significantly better than MERT with confidence p &lt; 0.05. Distance metrics L2 Projection NIST02(Dev) 29.95 30.06 NIST03 27.09 27.36 NIST04 29.65 29.89 NIST"
C12-2071,P07-2045,0,0.0187117,"test10 23.35 23.90+ test11 23.65 24.18+ Table 2: Comparison of two tuning methods, MERT and ELBUU, on Spanish-to-English translation tasks. + means the ELBUU method is significantly better than MERT with confidence p &lt; 0.05. Distance metrics L2 Projection NIST02(Dev) 29.95 30.06 NIST03 27.09 27.36 NIST04 29.65 29.89 NIST05 26.79 27.03 NIST06 25.98 26.30 NIST08 19.54 19.79 Table 3: Comparison of two distance metrics L2 and projection on Chinese-to-English translation tasks. The translation system is a phrase-based translation model (Koehn et al., 2003) and we use the open source toolkit MOSES (Koehn et al., 2007) as its implementation. In the experiments, the default setting is used for MOSES. The baseline tuning method is the standard algorithm MERT and the k-best-list size is set as 100 for tuning. For ELBUU, we empirically set α = 3.0 as (Och, 2003), η = 1, ε = 10−5 , K = 20, and we do not tune them further. We tune λ on NIST05 with λ = 1.0 for the Chinese-to-English translation tasks and we do not tune it again for the Spanish-to-English translation tasks. 4.2 Results Table 1 and Table 2 give the main results of ELBUU compared with the baseline MERT on Chinese-to-English and Spanish-to-English tra"
C12-2071,N03-1017,0,0.175345,"sk, the training data is FBIS corpus consisting of about 240k sentence pairs; the development set is NIST02 evaluation data; the test set NIST05 is used as the development test set for tuning hyperparameter λ in Eq. 6; and the test datasets are NIST03, NIST04, NIST05, NIST06, and NIST08. For the Spanish-to-English task, all the datasets are from WMT2011: the training data is the first 200k sentence pairs of Europarl corpus; the development set is dev06; and the test datasets are test07, test08,test09, test10, test11. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments, the translation performances are measured by the case-insensitive BLEU4 metric (Papineni et al., 2002) and we use mteval-v13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). 3 At the end of tuning, we average the weights as (Collins, 2002). The norm of the averaged weight m"
C12-2071,P09-1019,0,0.0699435,"imization step in each round, MERT tries to repeatedly optimize a loss function defined by the k-best candidate lists. Since new k-best lists are generated and merged with the previously generated lists at each round, the optimization objective function may change drastically between two adjacent rounds (Pauls et al., 2009), and the optimized weights of these two rounds may also be far from each other. Motivated by the above observation, this paper investigates a new tuning approach under the kbest lists framework, instead of the lattices or hypergraphs framework as Macherey et al. (2008) and Kumar et al. (2009), to achieve a more stable loss function between optimization steps. We propose an expected loss-based ultraconservative update method, in which an expected loss is minimized using an ultraconservative update strategy (Crammer and Singer, 2003; Crammer et al., 2006). In the optimization step, we iteratively learn the weight which should not only minimize the error rates as in MERT but also not be far from the weight learned at the previous optimization step. Instead of using the L2 in Euclidean space to describe the distances between the two weights as in the Margin Infused Relaxed Algorithm ("
C12-2071,D12-1037,1,0.833347,"pus-BLEU compared with the generalized hinge loss, and it utilizes the projection distance metric instead of L2 as with MIRA. Further, ELBUU is a MERT-like batch mode which ultraconservatively updates the weight with all training examples, but MIRA is an online one which updates with each example (Watanabe et al., 2007) or parts of examples (Chiang et al., 2008). The batch mode has some advantages over online mode: more accurate sentence-wise BLEU towards Corpus-BLEU (Watanabe, 2012) and more promising experimental performance (Cherry and Foster, 2012). Additionally, our method is similar to (Liu et al., 2012). However, the main difference is that ours is a global training method instead of a local training method. 4 Experiments and Results 4.1 Experimental Setting We conduct our translation experiments on two language pairs: Chinese-to-English and Spanishto-English. For the Chinese-to-English task, the training data is FBIS corpus consisting of about 240k sentence pairs; the development set is NIST02 evaluation data; the test set NIST05 is used as the development test set for tuning hyperparameter λ in Eq. 6; and the test datasets are NIST03, NIST04, NIST05, NIST06, and NIST08. For the Spanish-to-"
C12-2071,D08-1076,0,0.0578676,"k et al., 2011). At the optimization step in each round, MERT tries to repeatedly optimize a loss function defined by the k-best candidate lists. Since new k-best lists are generated and merged with the previously generated lists at each round, the optimization objective function may change drastically between two adjacent rounds (Pauls et al., 2009), and the optimized weights of these two rounds may also be far from each other. Motivated by the above observation, this paper investigates a new tuning approach under the kbest lists framework, instead of the lattices or hypergraphs framework as Macherey et al. (2008) and Kumar et al. (2009), to achieve a more stable loss function between optimization steps. We propose an expected loss-based ultraconservative update method, in which an expected loss is minimized using an ultraconservative update strategy (Crammer and Singer, 2003; Crammer et al., 2006). In the optimization step, we iteratively learn the weight which should not only minimize the error rates as in MERT but also not be far from the weight learned at the previous optimization step. Instead of using the L2 in Euclidean space to describe the distances between the two weights as in the Margin Inf"
C12-2071,P03-1021,0,0.678266,"ative update, in which the combination of an expected task loss and the distance from the parameters in the previous round are minimized with a variant of gradient descent. Experiments on test datasets of both Chinese-to-English and Spanish-toEnglish translation show that our method can achieve improvements over MERT under the Moses system. KEYWORDS: statistical machine translation; tuning; minimum error rate training; ultraconservative update; expected BLEU. Proceedings of COLING 2012: Posters, pages 723–732, COLING 2012, Mumbai, December 2012. 723 1 Introduction Minimum error rate training (Och, 2003), MERT, is an important component of statistical machine translation (SMT), and it has been the most popular method for tuning parameters for SMT systems. One of its major contributions is the use of an evaluation metric, such as BLEU (Papineni et al., 2002), as a direct loss function during its optimization procedure by interchanging decoding and optimization steps in each round. While MERT is successful in practice, it is known to be unstable (Clark et al., 2011). At the optimization step in each round, MERT tries to repeatedly optimize a loss function defined by the k-best candidate lists."
C12-2071,P00-1056,0,0.0906742,"o-English and Spanishto-English. For the Chinese-to-English task, the training data is FBIS corpus consisting of about 240k sentence pairs; the development set is NIST02 evaluation data; the test set NIST05 is used as the development test set for tuning hyperparameter λ in Eq. 6; and the test datasets are NIST03, NIST04, NIST05, NIST06, and NIST08. For the Spanish-to-English task, all the datasets are from WMT2011: the training data is the first 200k sentence pairs of Europarl corpus; the development set is dev06; and the test datasets are test07, test08,test09, test10, test11. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments, the translation performances are measured by the case-insensitive BLEU4 metric (Papineni et al., 2002) and we use mteval-v13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). 3 At the end of tuning, we average th"
C12-2071,P02-1040,0,0.0924311,"lish translation show that our method can achieve improvements over MERT under the Moses system. KEYWORDS: statistical machine translation; tuning; minimum error rate training; ultraconservative update; expected BLEU. Proceedings of COLING 2012: Posters, pages 723–732, COLING 2012, Mumbai, December 2012. 723 1 Introduction Minimum error rate training (Och, 2003), MERT, is an important component of statistical machine translation (SMT), and it has been the most popular method for tuning parameters for SMT systems. One of its major contributions is the use of an evaluation metric, such as BLEU (Papineni et al., 2002), as a direct loss function during its optimization procedure by interchanging decoding and optimization steps in each round. While MERT is successful in practice, it is known to be unstable (Clark et al., 2011). At the optimization step in each round, MERT tries to repeatedly optimize a loss function defined by the k-best candidate lists. Since new k-best lists are generated and merged with the previously generated lists at each round, the optimization objective function may change drastically between two adjacent rounds (Pauls et al., 2009), and the optimized weights of these two rounds may"
C12-2071,D09-1147,0,0.193527,"s the use of an evaluation metric, such as BLEU (Papineni et al., 2002), as a direct loss function during its optimization procedure by interchanging decoding and optimization steps in each round. While MERT is successful in practice, it is known to be unstable (Clark et al., 2011). At the optimization step in each round, MERT tries to repeatedly optimize a loss function defined by the k-best candidate lists. Since new k-best lists are generated and merged with the previously generated lists at each round, the optimization objective function may change drastically between two adjacent rounds (Pauls et al., 2009), and the optimized weights of these two rounds may also be far from each other. Motivated by the above observation, this paper investigates a new tuning approach under the kbest lists framework, instead of the lattices or hypergraphs framework as Macherey et al. (2008) and Kumar et al. (2009), to achieve a more stable loss function between optimization steps. We propose an expected loss-based ultraconservative update method, in which an expected loss is minimized using an ultraconservative update strategy (Crammer and Singer, 2003; Crammer et al., 2006). In the optimization step, we iterative"
C12-2071,P06-2101,0,0.28711,"ain the following objective function:  n  d(W, Wk ) + λLosser r or ri ; ˆe( f i ; W ) i=1 , (3) where d(W, Wk ) is a distance function of a pair of weights and it is used to penalize a weight far away from Wk . Losser r or is the objective function of MERT as defined in Eq. 1. λ ≥ 0 is the regularization penalty. When λ → ∞ Eq. 3 goes back to the objective function of MERT. 725 Because the first term d in Eq. 3 is not piecewise linear in respect to W , the exact line search routine in MERT does not hold anymore. Generally, it is not easy to directly minimize Eq. 3. Motivated by (Och, 2003; Smith and Eisner, 2006; Zens et al., 2007), we use the expected loss to substitute the direct loss in Eq. 3 and we obtain the objective function as follows: d(W, Wk ) + n X λX n i=1 e∈ci Losser r or (ri ; e)Pα (e |f i ; W ), with Pα (e |f i ; W ) = P exp[αW · h( f i , e)] e′ ∈c i exp[αW · h( f i , e′ )] (4) , where α &gt; 0 is a real number, each h( f i , e) is a feature vector, and d is a distance metric defined on a pair of weights. Losser r or (ri ; e) in Eq. 4 is a sentence-wise direct loss, and in this paper we used a variant of sentence BLEU proposed by Chiang et al. (2008) which smoothes BLEU statistics with ps"
C12-2071,N12-1026,1,0.836237,". However, there are also some differences between them. ELBUU optimizes the expected BLEU, a loss more approximate towards Corpus-BLEU compared with the generalized hinge loss, and it utilizes the projection distance metric instead of L2 as with MIRA. Further, ELBUU is a MERT-like batch mode which ultraconservatively updates the weight with all training examples, but MIRA is an online one which updates with each example (Watanabe et al., 2007) or parts of examples (Chiang et al., 2008). The batch mode has some advantages over online mode: more accurate sentence-wise BLEU towards Corpus-BLEU (Watanabe, 2012) and more promising experimental performance (Cherry and Foster, 2012). Additionally, our method is similar to (Liu et al., 2012). However, the main difference is that ours is a global training method instead of a local training method. 4 Experiments and Results 4.1 Experimental Setting We conduct our translation experiments on two language pairs: Chinese-to-English and Spanishto-English. For the Chinese-to-English task, the training data is FBIS corpus consisting of about 240k sentence pairs; the development set is NIST02 evaluation data; the test set NIST05 is used as the development test se"
C12-2071,D07-1080,1,0.957646,"ction as follows: d(W, Wk ) + n X λX n i=1 e∈ci Losser r or (ri ; e)Pα (e |f i ; W ), with Pα (e |f i ; W ) = P exp[αW · h( f i , e)] e′ ∈c i exp[αW · h( f i , e′ )] (4) , where α &gt; 0 is a real number, each h( f i , e) is a feature vector, and d is a distance metric defined on a pair of weights. Losser r or (ri ; e) in Eq. 4 is a sentence-wise direct loss, and in this paper we used a variant of sentence BLEU proposed by Chiang et al. (2008) which smoothes BLEU statistics with pseudo-document. 3.2 Distance Metric Based on Projection Euclidean distance ( L2 norm) is usually employed as in MIRA (Watanabe et al., 2007; Chiang et al., 2008). In this section we will specifically investigate another metric for ultraconservative update in SMT. In log-linear based translation models, since the decoding strategy is the maximal posterior probability, the translation results are the same for the weight W and its positive multiplication (see Eq. 2). Therefore, for a translation decoder, we wish that the distance of two weights satisfies the following property: the smaller the distance between them is, the more similar the translation results decoded with them are. However, L2 norm does not satisfy this property. In"
C12-2071,D07-1055,0,0.083524,"ive function:  n  d(W, Wk ) + λLosser r or ri ; ˆe( f i ; W ) i=1 , (3) where d(W, Wk ) is a distance function of a pair of weights and it is used to penalize a weight far away from Wk . Losser r or is the objective function of MERT as defined in Eq. 1. λ ≥ 0 is the regularization penalty. When λ → ∞ Eq. 3 goes back to the objective function of MERT. 725 Because the first term d in Eq. 3 is not piecewise linear in respect to W , the exact line search routine in MERT does not hold anymore. Generally, it is not easy to directly minimize Eq. 3. Motivated by (Och, 2003; Smith and Eisner, 2006; Zens et al., 2007), we use the expected loss to substitute the direct loss in Eq. 3 and we obtain the objective function as follows: d(W, Wk ) + n X λX n i=1 e∈ci Losser r or (ri ; e)Pα (e |f i ; W ), with Pα (e |f i ; W ) = P exp[αW · h( f i , e)] e′ ∈c i exp[αW · h( f i , e′ )] (4) , where α &gt; 0 is a real number, each h( f i , e) is a feature vector, and d is a distance metric defined on a pair of weights. Losser r or (ri ; e) in Eq. 4 is a sentence-wise direct loss, and in this paper we used a variant of sentence BLEU proposed by Chiang et al. (2008) which smoothes BLEU statistics with pseudo-document. 3.2 D"
C14-1108,P06-1067,0,0.0317284,"problem of reordering source language into the word order of the target language remains a central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both te"
C14-1108,J07-2003,0,0.649224,"first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both terminals (words) and nonterminals (sub-phrases). The order of terminals and nonterminal are specified by the rule. For This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 1144 Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1144–1153, Dublin, Ireland, August 23-29 2014. example"
C14-1108,D08-1089,0,0.57593,"ic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both terminals (words) and nonterminals (sub-phrases). The order of terminals and nonterminal are specified by the"
C14-1108,C10-1050,0,0.44024,"nsistency in Moses between training and decoding. Here we would like to note that phrase based orientation depends on phrase segmentation. For example, in Figure 1, the orientation of phrase “this is” with respect to next phrase could be either:  D, if we think the next phrase is “the lower reach of ” which is what Figure 1 shows.  or S, if the next phrase is “the lower reach of the yellow river” which can compose a legal phrase pair with “huanghe xiayou” according to the standard phrase pair extraction algorithm. 1150 The decision to adopt word-based orientation makes our work similar with Hayashi et al. (2010) who proposed a word-based reordering model for HPB system. The difference between our work and Hayashi et al. (2010) is: they adopt the reordering model proposed by Tromble and Eisner (2009) for the preprocessing approach, while we borrow the idea of lexicalized reordering models which are originally proposed for phrase-based machine translation. 5 5.1 Experiments Experimental settings Our baseline system is re-implementation of Hiero, a hierarchical phrase-based system (Chiang, 2007). Besides the standard features of a HPB model, there are six reordering features in our reordering model whic"
C14-1108,C08-1041,0,0.126231,"29 2014. example, the translation rule <X xiayou, the lower reach of X > specifies that the translation of sub phrase X before “xiayou” should be put after “the lower reach of”. One problem with the HPB model is that the application of a rule is independent of the actual sub phrase. For example, the rule <X xiayou, the lower reach of X > will always swap the translation of X and “xiayou”, no matter what is covered by X. This is an over-generalization problem. Much work has been done to solve this issue. For example, Zollmann and Venugopal (2006) annotate non-terminals by syntactic categories. He et al. (2008) proposes maximum entropy models which combine rich context information for selecting translation rules during decoding. Huang et al. (2010) automatically induce a set of latent syntactic categories to annotate nonterminals. These works alleviate the overgeneralization problem by considering the content of X. In this paper, we try to solve it from an alternative view by modeling whether the phrases covered by X prefer the order specified by the rule. This has led us to borrow the lexicalized reordering model from the phrase-based model for the HPB model. We propose a novel lexicalized reorderi"
C14-1108,W05-1507,0,0.0354703,"ine translation, the problem of reordering source language into the word order of the target language remains a central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous g"
C14-1108,D10-1014,0,0.0157829,"hould be put after “the lower reach of”. One problem with the HPB model is that the application of a rule is independent of the actual sub phrase. For example, the rule <X xiayou, the lower reach of X > will always swap the translation of X and “xiayou”, no matter what is covered by X. This is an over-generalization problem. Much work has been done to solve this issue. For example, Zollmann and Venugopal (2006) annotate non-terminals by syntactic categories. He et al. (2008) proposes maximum entropy models which combine rich context information for selecting translation rules during decoding. Huang et al. (2010) automatically induce a set of latent syntactic categories to annotate nonterminals. These works alleviate the overgeneralization problem by considering the content of X. In this paper, we try to solve it from an alternative view by modeling whether the phrases covered by X prefer the order specified by the rule. This has led us to borrow the lexicalized reordering model from the phrase-based model for the HPB model. We propose a novel lexicalized reordering model for hierarchical phrase-based translation and achieved a 0.6-1.2 BLEU point improvements for Chinese-English translation over a str"
C14-1108,W13-2258,0,0.237941,"r internal structure. For example, in Figure 1, suppose nonterminal X1 is not the root node and the orientation probability of X1 will condition on “zhe, xiayou, this, river”. In this paper, we will consider how the words covered by the nonterminal X1 are reordered. Rather than using “xiayou” as a feature to determine the orientation of X1 with respect to the next phrase, we think the immediately translated source word “huanghe” could be more informative through it is not on the boundary of X1 , since “huanghe” is the exact starting point from where we search for the next phrase to translate. Huck et al. (2013) proposed a very effective phrase orientation model for HPB translation. The model is also based on nonterminal. They extracted phrase orientation probabilities from word-aligned training data for use with hierarchical phrase inventories, and scored orientations in hierarchical decoding. 2.2 Path-based lexicalized reordering model The most recent related work is Nguyen and Vogel (2013). They map a HPB derivation into a discontinuous phrase-based translation path in the following two steps: 1) Represent each rule as a sequence of phrase pairs and non-terminals. 2) The rules’ sequences are used"
C14-1108,P07-2045,0,0.00826616,"central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both terminals (words) and nonterminals (sub-phrases). The order of terminals and nonter"
C14-1108,P06-1090,0,0.0287036,"anguage into the word order of the target language remains a central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both terminals (words) and n"
C14-1108,P13-1156,0,0.275902,"the immediately translated source word “huanghe” could be more informative through it is not on the boundary of X1 , since “huanghe” is the exact starting point from where we search for the next phrase to translate. Huck et al. (2013) proposed a very effective phrase orientation model for HPB translation. The model is also based on nonterminal. They extracted phrase orientation probabilities from word-aligned training data for use with hierarchical phrase inventories, and scored orientations in hierarchical decoding. 2.2 Path-based lexicalized reordering model The most recent related work is Nguyen and Vogel (2013). They map a HPB derivation into a discontinuous phrase-based translation path in the following two steps: 1) Represent each rule as a sequence of phrase pairs and non-terminals. 2) The rules’ sequences are used to find the corresponding phrase-based path of a HPB derivation and calculate the phrase-based reordering features. Figure 2. The phrase-based path of the derivation in Figure 1. 1145 A phrase-based path is the sequence of phrase pairs, whose source sides covers the source sentences and whose target sides generated the target sentences from left to right. For example, the phrase-based"
C14-1108,P00-1056,0,0.144249,"ectively. They are integrated into the log-linear model of the HPB system. The Minimum Error Rate Training (MERT) (Och, 2003) algorithm is adopted to tune feature weights for translation systems. We test our reordering model on a Chinese-English translation task. The NIST evaluation set MT06 was used as our development set to tune the feature weights, and the test data are MT04, MT 05 and MT08. We first conduct experiments by using the FBIS parallel training corpus, and then further test the effect of our method on a large scale parallel training corpus. Word alignment is performed by GIZA++ (Och and Ney, 2000) in both directions with the default setting. The language model is a 4-gram model trained with the Xinhua portion of LDC English Gigaword Version 3.0 and the English part of the bilingual training data. Translation performances are measured with case-insensitive BLEU4 score (Papineni et al., 2002). 5.2 Experimental results on FBIS corpus We first conduct experiments by using the FBIS parallel corpus to train the model of both the baseline and our lexicalized reordering model. After pre-processing, the statistics of FBIS corpus is shown in table 1. Chinese English #sentences 128832 128832 #wor"
C14-1108,J04-4002,0,0.219684,"rectly on synchronous rules. For each target phrase contained in a rule, we calculate its orientation probability conditioned on the rule. We test our model on both small and large scale data. On NIST machine translation test sets, our reordering model achieved a 0.6-1.2 BLEU point improvements for Chinese-English translation over a strong baseline hierarchical phrase-based system. 1 Introduction In statistical machine translation, the problem of reordering source language into the word order of the target language remains a central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reord"
C14-1108,P03-1021,0,0.111575,"ner (2009) for the preprocessing approach, while we borrow the idea of lexicalized reordering models which are originally proposed for phrase-based machine translation. 5 5.1 Experiments Experimental settings Our baseline system is re-implementation of Hiero, a hierarchical phrase-based system (Chiang, 2007). Besides the standard features of a HPB model, there are six reordering features in our reordering model which are M, S and D with respect to the previous and next phrase respectively. They are integrated into the log-linear model of the HPB system. The Minimum Error Rate Training (MERT) (Och, 2003) algorithm is adopted to tune feature weights for translation systems. We test our reordering model on a Chinese-English translation task. The NIST evaluation set MT06 was used as our development set to tune the feature weights, and the test data are MT04, MT 05 and MT08. We first conduct experiments by using the FBIS parallel training corpus, and then further test the effect of our method on a large scale parallel training corpus. Word alignment is performed by GIZA++ (Och and Ney, 2000) in both directions with the default setting. The language model is a 4-gram model trained with the Xinhua"
C14-1108,P02-1040,0,0.0916478,"s used as our development set to tune the feature weights, and the test data are MT04, MT 05 and MT08. We first conduct experiments by using the FBIS parallel training corpus, and then further test the effect of our method on a large scale parallel training corpus. Word alignment is performed by GIZA++ (Och and Ney, 2000) in both directions with the default setting. The language model is a 4-gram model trained with the Xinhua portion of LDC English Gigaword Version 3.0 and the English part of the bilingual training data. Translation performances are measured with case-insensitive BLEU4 score (Papineni et al., 2002). 5.2 Experimental results on FBIS corpus We first conduct experiments by using the FBIS parallel corpus to train the model of both the baseline and our lexicalized reordering model. After pre-processing, the statistics of FBIS corpus is shown in table 1. Chinese English #sentences 128832 128832 #words 3016570 3922816 Table 1. The statistics of FBIS corpus Table 2 summarizes the translation performance. The first row shows the results of baseline HPB system, and the second row shows the results when we integrated our lexicalized reordering model (LRM). We get 1.2, 0.8 and 0.7 BLEU point improv"
C14-1108,N04-4026,0,0.184029,"Missing"
C14-1108,D09-1105,0,0.113438,"ase “this is” with respect to next phrase could be either:  D, if we think the next phrase is “the lower reach of ” which is what Figure 1 shows.  or S, if the next phrase is “the lower reach of the yellow river” which can compose a legal phrase pair with “huanghe xiayou” according to the standard phrase pair extraction algorithm. 1150 The decision to adopt word-based orientation makes our work similar with Hayashi et al. (2010) who proposed a word-based reordering model for HPB system. The difference between our work and Hayashi et al. (2010) is: they adopt the reordering model proposed by Tromble and Eisner (2009) for the preprocessing approach, while we borrow the idea of lexicalized reordering models which are originally proposed for phrase-based machine translation. 5 5.1 Experiments Experimental settings Our baseline system is re-implementation of Hiero, a hierarchical phrase-based system (Chiang, 2007). Besides the standard features of a HPB model, there are six reordering features in our reordering model which are M, S and D with respect to the previous and next phrase respectively. They are integrated into the log-linear model of the HPB system. The Minimum Error Rate Training (MERT) (Och, 2003)"
C14-1108,2011.mtsummit-papers.43,0,0.115615,"has led us to borrow the lexicalized reordering model from the phrase-based model for the HPB model. We propose a novel lexicalized reordering model for hierarchical phrase-based translation and achieved a 0.6-1.2 BLEU point improvements for Chinese-English translation over a strong HPB baseline system. 2 Related work In this section, we briefly review two types of related work which are a nonterminal-based lexicalized reordering models and a path-based lexicalized reordering model. Both of them calculate the orientation for HPB translation. 2.1 Nonterminal-based lexicalized reordering models Xiao et al. (2011) proposed an orientation model for HPB translation. The orientation probability of a derivation is calculated as the product of orientation probabilities of all nonterminals except the root. In order to define the relative orders of nonterminals and their adjacent phrase, they expand the alignment in a rule to include both terminals and nonterminals. There may be multiple ways to segment a rule into phrases; they use the maximum adjacent phrase similar to Galley and Manning (2008). They significantly outperformed the HPB system on both Chinese-English and German-English translation. Xiao et al"
C14-1108,P06-1066,0,0.0289271,"order of the target language remains a central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both terminals (words) and nonterminals (sub-phr"
C14-1108,W06-3108,0,0.131425,"language remains a central research topic. Statistical phrase-based translation models (Och and Ney, 2004; Koehn et al., 2003) are good at local reordering, or the reordering of words within the phrase, since the order is specified by phrasal translations. However, phrase-based models remain weak at long-distance reordering, or the reordering of the phrases. To improve the reordering of the phrases, two types of models have been developed. The first one is lexicalized reordering models (Tillman, 2004; Huang et al., 2005; Al-Onaizan and Papineni, 2006; Nagata et al., 2006; Xiong et al., 2006; Zens and Ney, 2006; Koehn et al., 2007; Galley and Manning, 2008; Cherry et al., 2012) which predict reordering by taking advantage of lexical the next phrase are D and S respectively, as shown in Figure 1. Such a model is simple and effective, and has become a standard component of phrase-based systems such as MOSES. Figure 1. Phrase orientations for Chinese-English translation. The other is a hierarchical phrase-based (HPB) translation model (Chiang, 2007) based on synchronous grammar. In the HPB model, a synchronous grammar rule may contain both terminals (words) and nonterminals (sub-phrases). The order of"
C14-1108,W06-3119,0,0.0423035,"al Linguistics: Technical Papers, pages 1144–1153, Dublin, Ireland, August 23-29 2014. example, the translation rule <X xiayou, the lower reach of X > specifies that the translation of sub phrase X before “xiayou” should be put after “the lower reach of”. One problem with the HPB model is that the application of a rule is independent of the actual sub phrase. For example, the rule <X xiayou, the lower reach of X > will always swap the translation of X and “xiayou”, no matter what is covered by X. This is an over-generalization problem. Much work has been done to solve this issue. For example, Zollmann and Venugopal (2006) annotate non-terminals by syntactic categories. He et al. (2008) proposes maximum entropy models which combine rich context information for selecting translation rules during decoding. Huang et al. (2010) automatically induce a set of latent syntactic categories to annotate nonterminals. These works alleviate the overgeneralization problem by considering the content of X. In this paper, we try to solve it from an alternative view by modeling whether the phrases covered by X prefer the order specified by the rule. This has led us to borrow the lexicalized reordering model from the phrase-based"
C14-1108,W12-3125,0,\N,Missing
C14-1210,W09-2307,0,0.162431,"gaword Version 3.0 and the English part of the bilingual training data. Feature weights are tuned with the minimum error rate training algorithm (Och, 2003).Translation performance is measured with case-insensitive BLEU4 score (Papineni et al., 2002). All the Chinese sentences in the training set, development set and test set are parsed by an in-house developed dependency parser based on shift-reduce algorithm (Zhang and Nivre, 2011). There are 45 named grammatical relations plus a default relation representing unknown cases. The detailed descriptions about dependency parsing are explained in Chang et al. (2009). 5.2 Experimental Results on FBIS Corpus We first conduct experiments by using the FBIS parallel corpus to train the model of both the baseline and the soft dependency matching model. Table 2 shows the statistics of FBIS corpus after the preprocessing. 2233 Chinese English #sentences 128,832 128,832 #words 3,016,570 3,922,816 Table 2. The statistics of FBIS corpus The evaluation results over FBIS corpus are reported in Table 3. The first row shows the results of baseline, the next three rows show the effect of three features respectively and the last row gives the result when all features are"
C14-1210,P08-1009,0,0.0373898,"Missing"
C14-1210,J07-2003,0,0.881897,"translate a sentence, the dependency knowledge is used to compute the syntactic structural consistency of the rule against the dependency tree of the sentence. We characterize the structure consistency by three features and integrate them into the standard SMT log-linear model to guide the translation process. Our method is evaluated on multiple Chinese-to-English machine translation test sets. The experimental results show that our soft matching model achieves 0.7-1.4 BLEU points improvements over a strong baseline of an in-house implemented HPB translation system. 1 Introduction HPB model (Chiang, 2007) is widely used and has consistently delivered state-of-the-art performance. This model extends the phrase-based model (Koehn et al., 2003) by using the formal synchronous grammar to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical trans"
C14-1210,D11-1079,0,0.0167224,"and that between the rule and its context. Both above related work and our work need parse the source sentence to get syntactic context before decoding. There are also some methods incorporating syntax information without the need of online parsing the source sentences (Zollmann and Venugopal, 2006; Shen et al, 2009; Chiang, 2010). They parse the training data to label the non-terminals with syntactic tags. During the bottom-up decoding, the tags are used to model the substitution of non-terminals in a soft way (Shen et al, 2009; Chiang, 2010) or in a hard way (Zollmann and Venugopal, 2006). Gao et al. (2011) derive soft constraints from the source dependency parsing for the HPB translation. They focus on the relative order of each dependent word and its head word after translation, while our method models whether the dependency information of a rule matches the context or not. Our work utilizes contextual information around translation rules. In this sense, it is similar to He et al. (2008) and Liu et al. (2008). The main difference between their work and our work is that they leverage lexical context for rule selection while we focus on the syntactic contextual information. 3 Hierarchical Phrase"
C14-1210,C08-1041,0,0.017156,"with syntactic tags. During the bottom-up decoding, the tags are used to model the substitution of non-terminals in a soft way (Shen et al, 2009; Chiang, 2010) or in a hard way (Zollmann and Venugopal, 2006). Gao et al. (2011) derive soft constraints from the source dependency parsing for the HPB translation. They focus on the relative order of each dependent word and its head word after translation, while our method models whether the dependency information of a rule matches the context or not. Our work utilizes contextual information around translation rules. In this sense, it is similar to He et al. (2008) and Liu et al. (2008). The main difference between their work and our work is that they leverage lexical context for rule selection while we focus on the syntactic contextual information. 3 Hierarchical Phrase based Machine Translation Our model proposed in this paper is an extension of the HPB model (Chiang, 2007). Formally, HPB model is a weighted synchronous context free grammar. It employs a generalization of the standard plain phrase extraction approach in order to acquire the synchronous rules of the grammar directly from word-aligned parallel text. Rules have the form of: where X is a"
C14-1210,2006.amta-papers.8,0,0.0356325,"phrase-based model (Koehn et al., 2003) by using the formal synchronous grammar to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical translations, lots of syntax-based models have been proposed by Galley et al. (2004), Liu et al. (2006), Huang et al. (2006), Mi et al. (2008), Shen et al. (2008), Xie et al. (2011), Zhang et al. (2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been muc"
C14-1210,D10-1014,0,0.688855,"Missing"
C14-1210,D13-1053,0,0.358716,"ecial efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by incorporating syntax information. Marton and Resnik (2008) leverage linguistic constituents to constrain the decoding softly. Some work go further to augment the non-terminals in HPB rules with syntactic tags which depend on the syntactic structure covered by the non-terminals (Zollmann and Venugopal, 2006; Chiang, 2010; Li et al., 2012; Huang et al., 2013). For example, given below HPB rules (1-4), the source non-terminal X could be refined into NP or PP as shown in rules (5-8) respectively. (1) <借 了 X, borrowed X> (3) <X1 借 了 X2, borrowed X2 X1> (2) <借 了 X, lent X> (4) <X1 借 了 X2, X1 borrowed X2> (5) <借了 NP, borrowed X> (7) <PP 借了 NP, borrow X2 X1> (6) <借了 NP, lent X> (8) <NP 借了 NP, X1 lent X2> Although augmenting the non-terminals with syntactic tags in these methods achieved better results for HPB model, they have limitations that the syntax information on the non-terminals are not discrimThis work is licenced under a Creative Commons Attrib"
C14-1210,P00-1056,0,0.147529,"PB rule is extended into the form of and the score is calculated by: ∑ where the additional three features are defined in Section 4.3, , and are corresponding feature weights. We test our soft dependency matching model on a Chinese-English translation task. The NIST06 evaluation data was used as our development set to tune the feature weights, and NIST04, NIST05 and NIST08 evaluation data are our test sets. We first conduct experiments by using the FBIS parallel corpus, and then further test the performance of our method on a large scale training corpus. Word alignment is performed by GIZA++ (Och and Ney, 2000) in both directions with the default setting. 4-gram language model is trained over the Xinhua portion of LDC English Gigaword Version 3.0 and the English part of the bilingual training data. Feature weights are tuned with the minimum error rate training algorithm (Och, 2003).Translation performance is measured with case-insensitive BLEU4 score (Papineni et al., 2002). All the Chinese sentences in the training set, development set and test set are parsed by an in-house developed dependency parser based on shift-reduce algorithm (Zhang and Nivre, 2011). There are 45 named grammatical relations"
C14-1210,P03-1021,0,0.120898,"rd-aligned parallel text. Rules have the form of: where X is a nonterminal, and are both strings of terminals and non-terminals from source and target side respectively, and ∼ is a one-to-one correspondence between nonterminal occurrences in and . Associated with each rule is a set of feature functions with the form . These feature functions are combined into a log-linear model. When a rule is applied during SMT decoding, its score is calculated as: ∑ where is the weight associated with feature function . The feature weights are typically optimized using minimum error rate training algorithm (Och, 2003). 4 Soft Dependency Matching Model In order to incorporate syntactic knowledge to refine both the word ordering and word sense disambiguation for HPB model, we propose a soft dependency matching model (SDMM). It extends HPB rule into a form which is named as SDMM rule: where RDT(rule’s dependency triples) is a set of dependency triples defined on source string . Each element in RDT is a triple representing dependency knowledge in the form: {m-h-l} where m and h are the dependent and head respectively, l is the label of the dependency relation type. m and h could be any of terminals, non-termin"
C14-1210,N03-1017,0,0.0567749,"dency tree of the sentence. We characterize the structure consistency by three features and integrate them into the standard SMT log-linear model to guide the translation process. Our method is evaluated on multiple Chinese-to-English machine translation test sets. The experimental results show that our soft matching model achieves 0.7-1.4 BLEU points improvements over a strong baseline of an in-house implemented HPB translation system. 1 Introduction HPB model (Chiang, 2007) is widely used and has consistently delivered state-of-the-art performance. This model extends the phrase-based model (Koehn et al., 2003) by using the formal synchronous grammar to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical translations, lots of syntax-based models have been proposed by Galley et al. (2004), Liu et al. (2006), Huang et al. (2006), Mi et al. (2008),"
C14-1210,W12-3128,0,0.0242719,"Missing"
C14-1210,P06-1077,0,0.057462,"model extends the phrase-based model (Koehn et al., 2003) by using the formal synchronous grammar to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical translations, lots of syntax-based models have been proposed by Galley et al. (2004), Liu et al. (2006), Huang et al. (2006), Mi et al. (2008), Shen et al. (2008), Xie et al. (2011), Zhang et al. (2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010"
C14-1210,P08-1114,0,0.0791107,"(2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by incorporating syntax information. Marton and Resnik (2008) leverage linguistic constituents to constrain the decoding softly. Some work go further to augment the non-terminals in HPB rules with syntactic tags which depend on the syntactic structure covered by the non-terminals (Zollmann and Venugopal, 2006; Chiang, 2010; Li et al., 2012; Huang et al., 2013). For example, given below HPB rules (1-4), the source non-terminal X could be refined into NP or PP as shown in rules (5-8) respectively. (1) <借 了 X, borrowed X> (3) <X1 借 了 X2, borrowed X2 X1> (2) <借 了 X, lent X> (4) <X1 借 了 X2, X1 borrowed X2> (5) <借了 NP, borrowed X> (7) <PP 借了 NP, borrow X2 X1>"
C14-1210,D08-1022,0,0.0554861,"Missing"
C14-1210,P02-1040,0,0.0917171,"nd NIST08 evaluation data are our test sets. We first conduct experiments by using the FBIS parallel corpus, and then further test the performance of our method on a large scale training corpus. Word alignment is performed by GIZA++ (Och and Ney, 2000) in both directions with the default setting. 4-gram language model is trained over the Xinhua portion of LDC English Gigaword Version 3.0 and the English part of the bilingual training data. Feature weights are tuned with the minimum error rate training algorithm (Och, 2003).Translation performance is measured with case-insensitive BLEU4 score (Papineni et al., 2002). All the Chinese sentences in the training set, development set and test set are parsed by an in-house developed dependency parser based on shift-reduce algorithm (Zhang and Nivre, 2011). There are 45 named grammatical relations plus a default relation representing unknown cases. The detailed descriptions about dependency parsing are explained in Chang et al. (2009). 5.2 Experimental Results on FBIS Corpus We first conduct experiments by using the FBIS parallel corpus to train the model of both the baseline and the soft dependency matching model. Table 2 shows the statistics of FBIS corpus af"
C14-1210,P08-1066,0,0.026789,"by using the formal synchronous grammar to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical translations, lots of syntax-based models have been proposed by Galley et al. (2004), Liu et al. (2006), Huang et al. (2006), Mi et al. (2008), Shen et al. (2008), Xie et al. (2011), Zhang et al. (2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by"
C14-1210,D09-1008,0,0.366391,"resent the syntactic variation of translation rules in the form of distribution. The main difference is that they annotate non-terminals with head POS tags while we use dependency triples (over both terminals and non-terminals) to explicitly represent both the dependency relations inside the rule, and that between the rule and its context. Both above related work and our work need parse the source sentence to get syntactic context before decoding. There are also some methods incorporating syntax information without the need of online parsing the source sentences (Zollmann and Venugopal, 2006; Shen et al, 2009; Chiang, 2010). They parse the training data to label the non-terminals with syntactic tags. During the bottom-up decoding, the tags are used to model the substitution of non-terminals in a soft way (Shen et al, 2009; Chiang, 2010) or in a hard way (Zollmann and Venugopal, 2006). Gao et al. (2011) derive soft constraints from the source dependency parsing for the HPB translation. They focus on the relative order of each dependent word and its head word after translation, while our method models whether the dependency information of a rule matches the context or not. Our work utilizes contextu"
C14-1210,2010.amta-papers.8,0,0.029154,"Liu et al. (2006), Huang et al. (2006), Mi et al. (2008), Shen et al. (2008), Xie et al. (2011), Zhang et al. (2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by incorporating syntax information. Marton and Resnik (2008) leverage linguistic constituents to constrain the decoding softly. Some work go further to augment the non-terminals in HPB rules with syntactic tags which depend on the syntactic structure covered by the non-terminals (Zollmann and Venugopal, 2006; Chiang, 2010; Li et al., 2012; Huang et al., 2013). For example, given below HPB rules (1-4), the source non-terminal X could be refined into NP or PP as shown in rules (5-8) respectively. (1) <借 了 X, borrowed X> (3) <X1 借 了 X2, borr"
C14-1210,J97-3002,0,0.019268,"eved promising results on various language pairs. One problem of these methods is that exactly matching syntactic constraints cannot always guarantee a good translation, and violating syntactic structure does not always induce a poor translation. It could be more reasonable if the credit and penalty is learnt from the parallel training data. In this work, we learn this kind of constrain knowledge directly from the syntactic structures over the training corpus. Xiong et al. (2009) present a method that automatically learns syntactic constraints from training data for the ITG based translation (Wu, 1997; Xiong et al., 2006). They utilize the syntactic constraints to estimates the extent to which a span is bracketable. Though the effect was demonstrated on the ITG based model, the method is also applicable to the HPB model. The main difference between Xiong et al. (2009) and our work is that we try to estimate the structural consistency of each rule 2228 against the source syntax tree. For rules which are same in the source side but different in the target side, our method will distinguish the inconsistency degree for different rules. While, for such rules, Xiong et al. (2009) will give a sam"
C14-1210,D11-1020,0,0.0180229,"synchronous grammar to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical translations, lots of syntax-based models have been proposed by Galley et al. (2004), Liu et al. (2006), Huang et al. (2006), Mi et al. (2008), Shen et al. (2008), Xie et al. (2011), Zhang et al. (2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by incorporating synta"
C14-1210,P06-1066,0,0.0356965,"sing results on various language pairs. One problem of these methods is that exactly matching syntactic constraints cannot always guarantee a good translation, and violating syntactic structure does not always induce a poor translation. It could be more reasonable if the credit and penalty is learnt from the parallel training data. In this work, we learn this kind of constrain knowledge directly from the syntactic structures over the training corpus. Xiong et al. (2009) present a method that automatically learns syntactic constraints from training data for the ITG based translation (Wu, 1997; Xiong et al., 2006). They utilize the syntactic constraints to estimates the extent to which a span is bracketable. Though the effect was demonstrated on the ITG based model, the method is also applicable to the HPB model. The main difference between Xiong et al. (2009) and our work is that we try to estimate the structural consistency of each rule 2228 against the source syntax tree. For rules which are same in the source side but different in the target side, our method will distinguish the inconsistency degree for different rules. While, for such rules, Xiong et al. (2009) will give a same score which will be"
C14-1210,P09-1036,0,0.0164889,"credit if it respects the parse tree but may incur a cost if it violates a constituent boundary. The soft constrain based methods achieved promising results on various language pairs. One problem of these methods is that exactly matching syntactic constraints cannot always guarantee a good translation, and violating syntactic structure does not always induce a poor translation. It could be more reasonable if the credit and penalty is learnt from the parallel training data. In this work, we learn this kind of constrain knowledge directly from the syntactic structures over the training corpus. Xiong et al. (2009) present a method that automatically learns syntactic constraints from training data for the ITG based translation (Wu, 1997; Xiong et al., 2006). They utilize the syntactic constraints to estimates the extent to which a span is bracketable. Though the effect was demonstrated on the ITG based model, the method is also applicable to the HPB model. The main difference between Xiong et al. (2009) and our work is that we try to estimate the structural consistency of each rule 2228 against the source syntax tree. For rules which are same in the source side but different in the target side, our meth"
C14-1210,W06-3119,0,0.609439,"ference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by incorporating syntax information. Marton and Resnik (2008) leverage linguistic constituents to constrain the decoding softly. Some work go further to augment the non-terminals in HPB rules with syntactic tags which depend on the syntactic structure covered by the non-terminals (Zollmann and Venugopal, 2006; Chiang, 2010; Li et al., 2012; Huang et al., 2013). For example, given below HPB rules (1-4), the source non-terminal X could be refined into NP or PP as shown in rules (5-8) respectively. (1) <借 了 X, borrowed X> (3) <X1 借 了 X2, borrowed X2 X1> (2) <借 了 X, lent X> (4) <X1 借 了 X2, X1 borrowed X2> (5) <借了 NP, borrowed X> (7) <PP 借了 NP, borrow X2 X1> (6) <借了 NP, lent X> (8) <NP 借了 NP, X1 lent X2> Although augmenting the non-terminals with syntactic tags in these methods achieved better results for HPB model, they have limitations that the syntax information on the non-terminals are not discrimT"
C14-1210,P08-1064,0,0.0171028,"r to well capture the recursiveness of language during translation. In a formal synchronous grammar, the syntactic unit could be any sequence of contiguous terminals and non-terminals, which may not necessarily satisfy the linguistic constraints. HPB model is powerful to cover any format of translation pairs, but it might introduce ungrammatical rules and produce poor quality translations. To generate grammatical translations, lots of syntax-based models have been proposed by Galley et al. (2004), Liu et al. (2006), Huang et al. (2006), Mi et al. (2008), Shen et al. (2008), Xie et al. (2011), Zhang et al. (2008), etc. In these models, the syntactic units should be compatible with the syntactic structure of either the source sentence or the target sentence. These approaches can generate more grammatical translations by capturing the structural difference between language pairs. However, these models need special efforts to capture non-syntactic translation knowledge to improve the translation performance. It is desired to combine the advantages of syntax-based models and the HPB model (Stein et al., 2010). There has been much work trying to improve HPB model by incorporating syntax information. Marton"
C14-1210,P11-2033,0,0.0160391,"corpus. Word alignment is performed by GIZA++ (Och and Ney, 2000) in both directions with the default setting. 4-gram language model is trained over the Xinhua portion of LDC English Gigaword Version 3.0 and the English part of the bilingual training data. Feature weights are tuned with the minimum error rate training algorithm (Och, 2003).Translation performance is measured with case-insensitive BLEU4 score (Papineni et al., 2002). All the Chinese sentences in the training set, development set and test set are parsed by an in-house developed dependency parser based on shift-reduce algorithm (Zhang and Nivre, 2011). There are 45 named grammatical relations plus a default relation representing unknown cases. The detailed descriptions about dependency parsing are explained in Chang et al. (2009). 5.2 Experimental Results on FBIS Corpus We first conduct experiments by using the FBIS parallel corpus to train the model of both the baseline and the soft dependency matching model. Table 2 shows the statistics of FBIS corpus after the preprocessing. 2233 Chinese English #sentences 128,832 128,832 #words 3,016,570 3,922,816 Table 2. The statistics of FBIS corpus The evaluation results over FBIS corpus are report"
C16-1171,W06-1615,0,0.0266588,"desire word embeddings to be generalized well across different languages. For example, given embedding of English context words {the, cats, on, the, mat}, cross-lingual models should not only be able to predict that the current word can be sits in English, but also be able to predict it can be assis in French. Similarly, given embeddings of French context words {le, chat, est, sur, ma}, cross-lingual models should be able to predict both sits and assis. Such desire bears a strong resemblance to the problem of domain adaptation which is well-studied in the field of natural language processing (Blitzer et al., 2006; Daume III, 2007). We apply the theory on domain adaptation which can learn cross-domain features to the task of learning cross-lingual features(word embeddings). Before we detail the proposed framework for unsupervised cross-lingual representation learning, we briefly introduce methods in domain adaptation. 1820 ms , vs x1 monolingual data from source language W O h Lm , Lv Monolingual data in source language x2 M W monolingual data from source language mt , vt W Monolingual data in target language xc Figure 3: Bi-lingual representation learning is achieved by matching the distribution of th"
C16-1171,P07-1033,0,0.037914,"Missing"
C16-1171,D12-1025,0,0.145818,"Missing"
C16-1171,P15-1081,0,0.130524,"Missing"
C16-1171,E14-1049,0,0.227091,"stributed representations have the property that similar words are represented by similar vectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferr"
C16-1171,P15-1119,0,0.030406,"hi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferring knowledge from high-resource languages to low-resource languages (Guo et al., 2015), etc. However, all these cross-lingual models require some form of cross-lingual supervision such as seed lexicon,word-level alignments, sentence-level alignments and document-level alignments. Reliance on supervision might limit the development and application of cross-lingual representations. In this paper, we proposed a distribution based model to learn bilingual word embeddings from monolingual data. The This work is licensed under a Creative Commons Attribution 4.0 International Licence. http://creativecommons.org/licenses/by/4.0/ Licence details: 1818 Proceedings of COLING 2016, the 26t"
C16-1171,P14-1006,0,0.0351571,"s have the property that similar words are represented by similar vectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferring knowledge from high-res"
C16-1171,C12-1089,0,0.011899,"vectors referred to as word embeddings learned from raw text. Distributed representations have the property that similar words are represented by similar vectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing"
C16-1171,W15-1521,0,0.138097,"esented by similar vectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferring knowledge from high-resource languages to low-resource language"
C16-1171,P12-1017,0,0.012304,"treated as a negative sample and the probability of predicting ysn given xs is minimized. Different from the CBOW model, we also randomly sample a few words from the target vocabulary and minimize the probability of predicting each selected target word ytn given xs . Such bilingual negative sampling(BNS) procedure may introduce noises if the sampled target word ytn just happens to be the translation of the source word ys . But, statistically such chance is quite small given the big vocabulary size of large scale text. To further reduce such chance, we apply word frequency based diagonal beam (Nuhn et al., 2012) to constrain the BNS. Intuitively, the translation of a high frequency word should also be a frequent word, and vice-versa. Nuhn et al. (2012) use diagonal beam to select translation candidates, in this paper we apply it to filter out possible translations. We sort both source and target words by their frequency. Let r(ys ) and r(yt ) be the frequency rank of a source/target word. To avoid selecting ytn which is the translation of ys , we require that the frequency rank of the sampled target word ytn should satisfy: n V t r(yt ) − r(ys ) &gt; BS (16) Vs where BS is the beam size. Similarly, we a"
C16-1171,J03-1002,0,0.0424941,"rmed on plain raw text, we leave the use of syntactic relations for future work. The word embeddings used by MonoGiza are trained with word2vec. For all word embeddings in both word2vec and our model, the dimensionality is 50. 4.2 French to English Decipherment Data The datasets in our English to French experiments are publicly-available Europarl data2 . From the English-French Europarl parallel data, we select the first half of English sentences and the second half French sentences respectively as non-parallel corpora for decipherment experiments. To evaluate the decipherment, we use Giza++ (Och and Ney, 2003) to align the Europarl parallel data to build a dictionary. All texts are tokenized by scripts from www.statmt.org. Table 1 lists the sizes of monolingual and parallel data used in this experiment. Decipherment In order to make all results comparable, results for all methods reported here were obtained using the same nonparallel corpora. λm and λv were set to 0.2 and 0.1 respectively. The number of negative samples from both source and target side for each word are 5. The beam size of BNS was set to 1000. We use default values for all other hyper parameters in word2vec and MonoGiza. Table 2 sh"
C16-1171,D14-1162,0,0.103846,"shared vector space. We demonstrate the utility of the learned embeddings on the task of finding word-to-word translations from monolingual corpora. Our model achieved encouraging performance on data in both related languages and substantially different languages. 1 Introduction Learning word vector representations based on neural network is now a ubiquitous technique in natural language processing tasks and applications. Tremendous advances have been brought by distributed representations to the state-of-the-art methods (Bengio et al., 2003; Collobert and Weston, 2008; Mikolov et al., 2013a; Pennington et al., 2014). In these models, words are represented by dense real-valued low-dimensional vectors referred to as word embeddings learned from raw text. Distributed representations have the property that similar words are represented by similar vectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved i"
C16-1171,P13-1036,0,0.0447045,"Missing"
C16-1171,P15-2093,0,0.0553404,"ectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferring knowledge from high-resource languages to low-resource languages (Guo et al., 201"
C16-1171,P16-1157,0,0.0115556,"ization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferring knowledge from high-resource languages to low-resource languages (Guo et al., 2015), etc. However, all these cross-lingual models"
C16-1171,P15-2118,0,0.248664,"Missing"
C16-1171,P14-1011,0,0.0159441,"mation (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word similarity (Zhang et al., 2016) and transferring knowledge from high-resource languages to low-resource languages (Guo et al., 2015), etc. However, all these cross-lingual models require some form of cross-lingual supervision such as seed lexicon,word-level alignments, sentence-level alignments and document-level alignments. Reliance on supervision might limit the development and application of cross-lingual representations. In this paper, we proposed a distribution based model to learn bilingual word embeddings from monolingual data. The This work is licensed un"
C16-1171,D13-1141,0,0.0178557,"ord embeddings learned from raw text. Distributed representations have the property that similar words are represented by similar vectors and thus can achieve better generalization. Such representations are usually learned from monolingual data and therefore might not be generalized well across different languages. In order to learn useful syntactic and semantic features that are invariant to languages, several models for learning cross-lingual representations have been proposed and achieved impressive effects by incorporating cross-lingual distributional information (Klementiev et al., 2012; Zou et al., 2013; Chandar et al., 2014; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Gouws et al., 2015; Luong et al., 2015; Shi et al., 2015; Vuli´c and Moens, 2015; Upadhyay et al., 2016). In the cross-lingual settings, similar representations are desired for words denoting similar concepts in different languages (e.g., the embeddings of the English word computer and the French word ordinateur should be similar). Cross-lingual representations are especially useful for many natural language processing tasks such as machine translation (Zou et al., 2013; Zhang et al., 2014), computing cross-lingual word"
C16-1236,P14-1133,0,0.0265941,"Missing"
C16-1236,Q15-1039,0,0.0714069,"Missing"
C16-1236,D13-1160,0,0.40406,": Sum of CNN scores between context pattern and binding Path for each entity constraint Po : Sum of embedding similarities between superlative phrase and binding Path for each ordinal constraint Table 3: Features and their description. 5 Experiment We introduce experiment part on these aspects. We first introduce the settings of our experiments, especially the three data sets containing question/answer (QA) pairs. On these data sets, the results of our method are given, and based on the results we analyze drawbacks. 5.1 Set Up System Components We use the entire Freebase dump which is same as Berant et al. (2013) and host it with Virtuoso engine11 . Besides, an entity linker (Yang and Chang, 2015), the Stanford NER (Finkel et al., 2005), and an in-house implementation of shift-reduce dependency parser (Zhang and Nivre, 2011) with Stanford dependency (De Marneffe et al., 2006) which is used in detecting temporal clause are adopted in this work. Data Sets We evaluate our approach on three data sets. (i) ComplexQuestions (CompQ): It is a new data set which includes 2100 QA pairs released by this work with the details in Section 2. (ii) WebQuestions (WebQ): It contains 3778 QA pairs on training set and 20"
C16-1236,D14-1067,0,0.0389445,"Missing"
C16-1236,de-marneffe-etal-2006-generating,0,0.0293992,"Missing"
C16-1236,P15-1026,1,0.872928,"Missing"
C16-1236,P05-1045,0,0.460005,"contain any word in this word set, we simply remove it. This is intuitive, as WebQuestions and SimpleQuestions are our training data, and we only consider queries that can be covered by the training data as query candidates. Last, we classify the remaining queries based on the following rules: (1) If a question contains at least two non-overlap entities, then it belongs in the Multi-Entity category; (2) If a question contains a type phrase that comes from Freebase, then it belongs in the Type category; (3) If a question contains a time expression detected by an Named Entity Recognizer (NER) (Finkel et al., 2005), then it belongs in the Explicit Temporal category; (4) If a question contains keywords “when”, “before”, “after” and “during” in the middle, then it belongs in the Implicit Temporal category; (5) If a question contains ordinal number or superlative phrase from WordNet (Miller, 1995), then it belongs in the Ordinal category; (6) If a question starts with “how many”, or includes “number of” or “count of”, then it belongs in the Aggregation category. Note, a multi-constraint question may contain multiple types of constraints. We show constraint types, examples, and distributions in Table 1. Ten"
C16-1236,Q14-1030,0,0.032321,"Missing"
C16-1236,Q16-1010,0,0.0299673,"Missing"
C16-1236,P16-1220,0,0.269382,"Missing"
C16-1236,P15-1049,0,0.115534,"of x in ascending order, return the nth one Return the number of entity set x. Table 2: Functional predicates defined in this work. query set, which contains 20,999,951 distinct 5W1H questions2 that satisfy the following two rules: (i) each query should not contain pronouns (e.g., ‘you’, ‘my’, etc.), as questions with such words are usually non-factual questions, and (ii) each query’s length is between 7 and 20, as short queries seldom contain multi-constraints, and long queries are usually difficult to answer. Then, we further sample 10 percent of questions, and use an entity linking method (Yang and Chang, 2015) to detect entities. If no entity can be detected from a query, we simply remove it. Next, both WebQuestions and SimpleQuestions are used to extract a set of words, without considering stop words and entity words. If a query does not contain any word in this word set, we simply remove it. This is intuitive, as WebQuestions and SimpleQuestions are our training data, and we only consider queries that can be covered by the training data as query candidates. Last, we classify the remaining queries based on the following rules: (1) If a question contains at least two non-overlap entities, then it b"
C16-1236,D14-1071,1,0.685243,"Missing"
C16-1236,P14-1090,0,0.15918,"Missing"
C16-1236,N15-3014,0,0.14959,"Missing"
C16-1236,P14-2105,0,0.0197143,"vertices, and x denotes the answer. For example, the basic query graph B in Figure 2 can be represented as hUnited States, officials-y0 -holder, xi. To measure the quality of each basic query graph constructed, we leverage a convolutional neural network (CNN)-based model that is similar to (Gao et al., 2015; Shen et al., 2014b; Shen et al., 2014a; Yih et al., 2015) to calculate the similarity between question and the path of the basic query graph. We will describe the training resource in Section 4.4. 4.2 Constraint Detection and Binding Basic query graph is fit for single relation questions (Yih et al., 2014; Bordes et al., 2015), but not suffices to express a question with multiple constraints, such as the question in Figure 2. Hence, we propose to use constraints to restrict the answer set by adding them into the basic query graph.Adding a constraint contains two steps: Constraint Detection and Constraint Binding. We explain how to add each of the six kinds of constraints respectively in the following parts. Entity Constraint Entity constraint is designed to understand entities and relations which are often expressed by noun phrases and verb phrases. A constraint with an entity as its constant"
C16-1236,P15-1128,0,0.706817,"s, variable &lt; Equal vertices y0 and x, and two edges officials and holder. {C1 , C2 , C3 } is an ordered con?3 ?2 ?1 1 MaxAtN straint sequence detected based on the question, where C1 = hPresident,Equal,y1 i, C2 = h2000,&lt;,y2 i, C3 = h1,MaxAtN,y2 i. By adding ? C1 , C2 , C3 in order, we can construct the MulCG United States officials ?0 holder ? in Figure 2. Note, different constraint order can result in different MulCGs. We will introduce Figure 2: MulCG for question “Who was the first how to generate a MulCG in Section 4. president of United States after 2000?” Compared to the stage graph in Yih et al. (2015), our MulCG has the following two differences: (1) Entity constraints can be added beyond single KB fact, while stage graph only considers entities that connect to the CVT node of a single KB fact as constraints. (2) Non-entity constraints are defined and handled in a systematic way, while stage graph only considers limited non-entity constraints, i.e., type and gender. 4 Our Approach Problem Formalization Given a MulCQ Q and a KB K, the question is parsed into a set of MulCGs H(Q). For each MulCG G ∈ H(Q), a feature vector F(Q, G) is extracted and the one with the highest 5 If p contains two"
C16-1236,P11-2033,0,0.0142789,"nd their description. 5 Experiment We introduce experiment part on these aspects. We first introduce the settings of our experiments, especially the three data sets containing question/answer (QA) pairs. On these data sets, the results of our method are given, and based on the results we analyze drawbacks. 5.1 Set Up System Components We use the entire Freebase dump which is same as Berant et al. (2013) and host it with Virtuoso engine11 . Besides, an entity linker (Yang and Chang, 2015), the Stanford NER (Finkel et al., 2005), and an in-house implementation of shift-reduce dependency parser (Zhang and Nivre, 2011) with Stanford dependency (De Marneffe et al., 2006) which is used in detecting temporal clause are adopted in this work. Data Sets We evaluate our approach on three data sets. (i) ComplexQuestions (CompQ): It is a new data set which includes 2100 QA pairs released by this work with the details in Section 2. (ii) WebQuestions (WebQ): It contains 3778 QA pairs on training set and 2032 on test set which is released by Berant et al. (2013). The questions are collected from query log and the answers are manually labeled based on Freebase. (iii) SimpleQuestions (SimpQ): Each question in SimpleQuest"
C16-1236,P14-1091,1,\N,Missing
D12-1037,P08-1024,0,0.14643,"mprovements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method. 1 (1) e Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due"
D12-1037,D08-1024,0,0.623546,"introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al., 2010), there are some shortcomings in this pipeline. Firstly, on the d"
D12-1037,P05-1033,0,0.0879558,"r experiments the translation perfunction (5), the optimization algorithm MERT can formances are measured by case-insensitive BLEU4 not be applied for this question since the exact line metric (Papineni et al., 2002) and we use mtevalsearch routine does not hold here. Motivated by v13a.pl as the evaluation tool. The significance test(Och, 2003; Smith and Eisner, 2006), we approxi- ing is performed by paired bootstrap re-sampling mate the Error in (5) by the expected loss, and then (Koehn, 2004). We use an in-house developed hierarchical derive the following function: phrase-based translation (Chiang, 2005) as our baseK λ XX 1 2 kW −Wb k + Error(rj ; e)Pα (e|fj ; W ), line system, and we denote it as In-Hiero. To ob2 K tain satisfactory baseline performance, we tune Inj=1 e (6) Hiero system for 5 times using MERT, and then se406 Methods Global method Local method Steps Decoding Retrieval Local training Seconds 2.0 +0.6 +0.3 NIST02 NIST05 27.07 27.75+ 27.85+ NIST06 26.32 27.88+ 27.99+ NIST08 19.03 20.84+ 21.08+ Table 3: The performance comparison of local training methods (MBUU and EBUU) and a global method (MERT). NIST05 is the set used to tune λ for MBUU and EBUU, and NIST06 and NIST08 are test"
D12-1037,D11-1004,0,0.149234,"e global method. 1 (1) e Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al., 2010), there are"
D12-1037,P10-1064,0,0.0295431,"Missing"
D12-1037,2005.eamt-1.19,0,0.0784023,"arns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One of the advantages is that it can adapt the weights for each of the test sentences. Our method resorts to some translation examples, which is similar as example-based translation or translation memory (Watanabe and Sumita, 2003; He et al., 2010; Ma et al., 2011). Instead of using translation examples to construct translation rules for enlarging the decoding space, we employed them 409 to discriminatively learn local weights. Similar to (Hildebrand et al., 2005; L¨u et al., 2007), our method also employes IR methods to retrieve examples for a given test set. Their methods utilize the retrieved examples to acquire translation model and can be seen as the adaptation of translation model. However, ours uses the retrieved examples to tune the weights and thus can be considered as the adaptation of tuning. Furthermore, since ours does not change the translation model which needs to run GIZA++ and it incrementally trains local weights, our method can be applied for online translation service. 7 Conclusion and Future Work This paper proposes a novel local"
D12-1037,D11-1125,0,0.403742,"or statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al., 2010), there are some shortcomings in this pipeline. Firstly, on the document level, the performance of th"
D12-1037,N03-1017,0,0.114511,"Missing"
D12-1037,P07-2045,0,0.014159,".75+ 27.85+ NIST06 26.32 27.88+ 27.99+ NIST08 19.03 20.84+ 21.08+ Table 3: The performance comparison of local training methods (MBUU and EBUU) and a global method (MERT). NIST05 is the set used to tune λ for MBUU and EBUU, and NIST06 and NIST08 are test sets. + means the local method is significantly better than MERT with p &lt; 0.05. lect the best-performing one as our baseline for the following experiments. As Table 1 indicates, our baseline In-Hiero is comparable to the phrase-based MT (Moses) and the hierarchical phrase-based MT (Moses hier) implemented in Moses, an open source MT toolkit2 (Koehn et al., 2007). Both of these systems are with default setting. All three systems are trained by MERT with 100 best candidates. To compare the local training method in Algorithm 2, we use a standard global training method, MERT, as the baseline training method. We do not compare with Algorithm 1, in which retraining is performed for each input sentence, since retraining for the whole test set is impractical given that each sentence-wise retraining may take some hours or even days. Therefore, we just compare Algorithm 2 with MERT. 5.2 Runtime Results To run the Algorithm 2, we tune the baseline weight Wb on"
D12-1037,W04-3250,0,0.0660269,"h modified Kneser-Ney smoothing (Chen and Goodrj . Due to the existence of L2 norm in objective man, 1998). In our experiments the translation perfunction (5), the optimization algorithm MERT can formances are measured by case-insensitive BLEU4 not be applied for this question since the exact line metric (Papineni et al., 2002) and we use mtevalsearch routine does not hold here. Motivated by v13a.pl as the evaluation tool. The significance test(Och, 2003; Smith and Eisner, 2006), we approxi- ing is performed by paired bootstrap re-sampling mate the Error in (5) by the expected loss, and then (Koehn, 2004). We use an in-house developed hierarchical derive the following function: phrase-based translation (Chiang, 2005) as our baseK λ XX 1 2 kW −Wb k + Error(rj ; e)Pα (e|fj ; W ), line system, and we denote it as In-Hiero. To ob2 K tain satisfactory baseline performance, we tune Inj=1 e (6) Hiero system for 5 times using MERT, and then se406 Methods Global method Local method Steps Decoding Retrieval Local training Seconds 2.0 +0.6 +0.3 NIST02 NIST05 27.07 27.75+ 27.85+ NIST06 26.32 27.88+ 27.99+ NIST08 19.03 20.84+ 21.08+ Table 3: The performance comparison of local training methods (MBUU and EB"
D12-1037,C10-1075,0,0.091706,"009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al., 2010), there are some shortcomings in this pipeline. Firstly, on the document level, the performance of these methods is dependent on the choice of a development set, which may potentially lead to an unstable translation performance for testing. As referred in our experiment, the BLEU points on NIST08 are 402 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural c Language Learning, pages 402–411, Jeju Island, Korea, 12–14 July 2012. 2012 Association for Computational Linguistics  1, 0  h ( f 1 , e11 )  h ( f 1 , e12 )  2,0  h("
D12-1037,D07-1036,0,0.0396223,"Missing"
D12-1037,P11-1124,0,0.197989,"Missing"
D12-1037,P00-1056,0,0.0922694,"Missing"
D12-1037,P02-1038,0,0.282749,"method to address these two problems. Unlike a global training method, such as MERT, in which a single weight is learned and used for all the input sentences, we perform training and testing in one step by learning a sentencewise weight for each input sentence. We propose efficient incremental training methods to put the local training into practice. In NIST Chinese-to-English translation tasks, our local training method significantly outperforms MERT with the maximal improvements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method. 1 (1) e Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007;"
D12-1037,P03-1021,0,0.66567,"meanwhile its efficiency is comparable to that of the global method. 1 (1) e Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and un"
D12-1037,P02-1040,0,0.0913028,"e eˆ(fj ; W ) is defined in Equation (1), and tence pair. We train a 4-gram language model on Error(rj , e) is the sentence-wise minus BLEU (Pa- the Xinhua portion of the English Gigaword corpineni et al., 2002) of a candidate e with respect to pus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodrj . Due to the existence of L2 norm in objective man, 1998). In our experiments the translation perfunction (5), the optimization algorithm MERT can formances are measured by case-insensitive BLEU4 not be applied for this question since the exact line metric (Papineni et al., 2002) and we use mtevalsearch routine does not hold here. Motivated by v13a.pl as the evaluation tool. The significance test(Och, 2003; Smith and Eisner, 2006), we approxi- ing is performed by paired bootstrap re-sampling mate the Error in (5) by the expected loss, and then (Koehn, 2004). We use an in-house developed hierarchical derive the following function: phrase-based translation (Chiang, 2005) as our baseK λ XX 1 2 kW −Wb k + Error(rj ; e)Pα (e|fj ; W ), line system, and we denote it as In-Hiero. To ob2 K tain satisfactory baseline performance, we tune Inj=1 e (6) Hiero system for 5 times usi"
D12-1037,D09-1147,0,0.080957,"arable to that of the global method. 1 (1) e Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li"
D12-1037,2003.mtsummit-papers.54,1,0.859025,"nd the incremental training in line 5 of Algorithm 2. 3 Acquiring Training Examples In line 4 of Algorithm 2, to retrieve training examples for the sentence ti , we first need a metric to retrieve similar translation examples. We assume that the metric satisfy the property: more similar the test sentence and translation examples are, the better translation result one obtains when decoding the test sentence with the weight trained on the translation examples. The metric we consider here is derived from an example-based machine translation. To retrieve translation examples for a test sentence, (Watanabe and Sumita, 2003) defined a metric based on the combination of edit distance and TF-IDF (Manning and Sch¨utze, 1999) as follows: dist(f1 , f2 ) = θ × edit-dist(f1 , f2 )+ (1 − θ) × tf-idf(f1 , f2 ), (2) where θ(0 ≤ θ ≤ 1) is an interpolation weight, fi (i = 1, 2) is a word sequence and can be also considered as a document. In this paper, we extract similar examples from training data. Like examplebased translation in which similar source sentences have similar translations, we assume that the optimal translation weights of the similar source sentences are closer. 4 Incremental Training Based on Ultraconservati"
D12-1037,D07-1080,1,0.964911,"tion Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al., 2010), there are some shortcomings in this pipel"
D12-1037,N09-2006,0,0.20149,"ts efficiency is comparable to that of the global method. 1 (1) e Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: where f and e (e0 ) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al., 2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al., 2009; Galley and Quirk, 2011), margin (Watanabe et al., 2007; Chiang et al., 2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of"
D12-1037,C08-1074,0,\N,Missing
D13-1050,P05-1074,0,0.0485877,"nodes (s source phrases and p pivot phrases) to represent the translation graph. (6) A =  gij  ( s + p )×( s + p ) where gij is the i,j-th elements of matrix A. We can split the matrix A into 4 sub-matrixes: 0 s×s Asp  (7) A=  A 0 ps p × p   where the sub-matrix Asp = [ pik ]s× p represents the translation probabilities from source to pivot language, and Aps represents the similar meaning. Take 3 steps walks as an example: Step1: 0 s×s Asp  A=   Aps 0 p× p  Step2:  Asp × Aps A2 =   0 p× s 4.3  Aps × Asp  Step3: 0 s× s  A3 =   Aps × Asp × Aps analogous to paraphrasing (Bannard and Callison-Burch, 2005). For the example shown in figure 1 as an example, the hidden relation between “很可口 henkekou” and “非常好吃 feichanghaochi” can be found through Step 2. 3. The third step describes the following procedure: S-P-S’-P’. An extended source-pivot phrase table is generated by 3-step random walks. Compared with the initial phrase table in Step1, although the number of phrases is not increased, the relations between phrase pairs are increased and more translation rules can be obtained. Still for the example in Figure 1 , the hidden relation between “很可口 henkekou” and “really delicious” can be generated in"
D13-1050,I11-1154,0,0.0328767,"Missing"
D13-1050,I11-1153,0,0.02207,"ly, they can be classified into 3 kinds of methods: Transfer Method: Within the transfer framework (Utiyama and Isahara, 2007; Wang et al., 2008; Costa-jussà et al., 2011), a source sentence is first translated to n pivot sentences via a sourcepivot translation system, and then each pivot sentence is translated to m target sentences via a pivot-target translation system. At each step (source to pivot and pivot to target), multiple translation outputs will be generated, thus a minimum Bayesrisk system combination method is often used to select the optimal sentence (González-Rubio et al., 2011; Duh et al., 2011). A problem with the transfer method is that it needs to decode twice. On one 525 hand, the time cost is doubled; on the other hand, the translation error of the source-pivot translation system will be transferred to the pivot-target translation. Synthetic Method: A synthetic method creates a synthetic source-target corpus using source-pivot translation model or pivot-target translation model (Utiyama et al., 2008; Wu and Wang, 2009). For example, we can translate each pivot sentence in the pivot-target corpus to source language with a pivot-source model, and then combine the translated source"
D13-1050,2005.mtsummit-papers.11,0,0.217955,"Missing"
D13-1050,C00-2163,0,0.176928,"Missing"
D13-1050,N07-1061,0,0.224847,"ional pivot-based method, triangulation method. The remainder of this paper is organized as follows. In section 2, we describe the related work. We review the triangulation method for pivotbased machine translation in section 3. Section 4 describes the random walk models. In section 5 and section 6, we describe the experiments and analyze the performance, respectively. Section 7 gives a conclusion of the paper. 2 Related Work Several methods have been proposed for pivotbased translation. Typically, they can be classified into 3 kinds of methods: Transfer Method: Within the transfer framework (Utiyama and Isahara, 2007; Wang et al., 2008; Costa-jussà et al., 2011), a source sentence is first translated to n pivot sentences via a sourcepivot translation system, and then each pivot sentence is translated to m target sentences via a pivot-target translation system. At each step (source to pivot and pivot to target), multiple translation outputs will be generated, thus a minimum Bayesrisk system combination method is often used to select the optimal sentence (González-Rubio et al., 2011; Duh et al., 2011). A problem with the transfer method is that it needs to decode twice. On one 525 hand, the time cost is dou"
D13-1050,2008.iwslt-evaluation.18,1,0.886415,"Missing"
D13-1050,P09-1018,1,0.897372,"ranslation outputs will be generated, thus a minimum Bayesrisk system combination method is often used to select the optimal sentence (González-Rubio et al., 2011; Duh et al., 2011). A problem with the transfer method is that it needs to decode twice. On one 525 hand, the time cost is doubled; on the other hand, the translation error of the source-pivot translation system will be transferred to the pivot-target translation. Synthetic Method: A synthetic method creates a synthetic source-target corpus using source-pivot translation model or pivot-target translation model (Utiyama et al., 2008; Wu and Wang, 2009). For example, we can translate each pivot sentence in the pivot-target corpus to source language with a pivot-source model, and then combine the translated source sentence with the target sentence to obtain a synthetic source-target corpus, and vice versa. However, it is difficult to build a high quality translation system with a corpus created by a machine translation system. Triangulation Method: The triangulation method obtains source-target model by combining source-pivot and pivot-target translation models (Wu and Wang, 2007; Cohn and Lapata 2007), which has been shown to work better tha"
D13-1050,D07-1103,0,\N,Missing
D13-1050,P02-1040,0,\N,Missing
D13-1050,P07-1108,1,\N,Missing
D13-1050,P07-2045,0,\N,Missing
D13-1050,2008.iwslt-evaluation.11,0,\N,Missing
D13-1050,N03-1017,0,\N,Missing
D13-1050,P09-2031,1,\N,Missing
D13-1050,W04-3250,0,\N,Missing
D14-1174,2008.iwslt-papers.1,0,0.0679481,"mental results on Europarl data and web data show that our method leads to significant improvements over the baseline systems. 1 Introduction Statistical Machine Translation (SMT) relies on large bilingual parallel data to produce high quality translation results. Unfortunately, for some language pairs, large bilingual corpora are not readily available. To alleviate the parallel data scarceness, a conventional solution is to introduce a “bridge” language (named pivot language) to connect the source and target language (de Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007; Bertoldi et al., 2008; Paul et al., 2011; El Kholy et al., 2013; Zahabi et al., 2013), where there are large amounts of source-pivot and pivot-target parallel corpora. Among various pivot-based approaches, the triangulation method (Cohn and Lapata, 2007; Wu and Wang, 2007) is a representative work in * pivot-based machine translation. The approach proposes to build a source-target phrase table by merging the source-pivot and pivot-target phrase table. One of the key issues in this method is to estimate the translation probabilities for the generated source-target phrase pairs. Conventionally, the probabilities are"
D14-1174,P07-1092,0,0.593184,"igh quality translation results. Unfortunately, for some language pairs, large bilingual corpora are not readily available. To alleviate the parallel data scarceness, a conventional solution is to introduce a “bridge” language (named pivot language) to connect the source and target language (de Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007; Bertoldi et al., 2008; Paul et al., 2011; El Kholy et al., 2013; Zahabi et al., 2013), where there are large amounts of source-pivot and pivot-target parallel corpora. Among various pivot-based approaches, the triangulation method (Cohn and Lapata, 2007; Wu and Wang, 2007) is a representative work in * pivot-based machine translation. The approach proposes to build a source-target phrase table by merging the source-pivot and pivot-target phrase table. One of the key issues in this method is to estimate the translation probabilities for the generated source-target phrase pairs. Conventionally, the probabilities are estimated by multiplying the posterior probabilities of source-pivot and pivottarget phrase pairs. However, it has been shown that the generated probabilities are not accurate enough (Cui et al., 2013). One possible reason may lie"
D14-1174,I11-1154,0,0.515643,"t translation model. See Figure 2. (b) and (c) for further illustration. 1666 The remainder of this paper is organized as follows. In Section 2, we describe the related work. We introduce the co-occurrence count method in Section 3, and the mixed model in Section 4. In Section 5 and Section 6, we describe and analyze the experiments. Section 7 gives a conclusion of the paper. 2 Related Work Several methods have been proposed for pivotbased translation. Typically, they can be classified into 3 kinds as follows: Transfer Method: The transfer method (Utiyama and Isahara, 2007; Wang et al., 2008; Costa-jussà et al., 2011) connects two translation systems: a source-pivot MT system and a pivottarget MT system. Given a source sentence, (1) the source-pivot MT system translates it into the pivot language, (2) and the pivot-target MT system translates the pivot sentence into the target sentence. During each step (source to pivot and pivot to target), multiple translation outputs will be generated, thus a minimum Bayes-risk system combination method is often used to select the optimal sentence (González-Rubio et al., 2011; Duh et al., 2011). The problem with the transfer method is that it needs to decode twice. On o"
D14-1174,I11-1153,0,0.0607625,"Missing"
D14-1174,P11-1127,0,0.0142768,"s as follows: Transfer Method: The transfer method (Utiyama and Isahara, 2007; Wang et al., 2008; Costa-jussà et al., 2011) connects two translation systems: a source-pivot MT system and a pivottarget MT system. Given a source sentence, (1) the source-pivot MT system translates it into the pivot language, (2) and the pivot-target MT system translates the pivot sentence into the target sentence. During each step (source to pivot and pivot to target), multiple translation outputs will be generated, thus a minimum Bayes-risk system combination method is often used to select the optimal sentence (González-Rubio et al., 2011; Duh et al., 2011). The problem with the transfer method is that it needs to decode twice. On one hand, the time cost is doubled; on the other hand, the translation error of the source-pivot translation system will be transferred to the pivot-target translation. Synthetic Method: It aims to create a synthetic source-target corpus by: (1) translate the pivot part in source-pivot corpus into target language with a pivot-target model; (2) translate the pivot part in pivot-target corpus into source language with a pivot-source model; (3) combine the source sentences with translated target sentenc"
D14-1174,N03-1017,0,0.372818,"the co-occurrence count of source-target phrase pairs to estimate phrase translation probabilities more precisely. Different from the triangulation method, which merges the source-pivot and pivot-target phrase pairs after training the translation model, we propose to merge the source-pivot and pivot-target phrase pairs immediately after the phrase extraction step, and estimate the co-occurrence count of the source-pivot-target phrase pairs. Finally, we compute the translation probabilities according to the estimated co-occurrence counts, using the standard training method in phrase-based SMT (Koehn et al., 2003). As Figure 1. (b) shows, the This work was done when the first author was visiting Baidu. 1665 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1665–1675, c October 25-29, 2014, Doha, Qatar. 2014 Association for Computational Linguistics (a) the triangulation method (b) the co-occurrence count method Figure 1: An example of probability space evolution in pivot translation. Standard ST corpus Large SP corpus Large PT corpus Standard ST corpus Large SP corpus Phrase Extraction Phrase Extraction Phrase Extraction SP phrase pairs PT phrase pair"
D14-1174,W04-3250,0,0.269372,"Missing"
D14-1174,2005.mtsummit-papers.11,0,0.294746,"Missing"
D14-1174,2010.iwslt-papers.12,0,0.0373385,"Missing"
D14-1174,C00-2163,0,0.0997045,"parison of different merging methods on out-of-domain test set. 5 Experiments on Europarl Corpus Our first experiment is carried out on Europarl1 corpus, which is a multi-lingual corpus including 21 European languages (Koehn, 2005). In our work, we perform translations among French (fr), German (de) and Spanish (es). Due to the richness of available language resources, we choose English (en) as the pivot language. Table 1 summarized the statistics of training data. For the language model, the same monolingual data extracted from the Europarl are used. The word alignment is obtained by GIZA++ (Och and Ney, 2000) and the heuristics “growdiag-final” refinement rule (Koehn et al., 2003). Our translation system is an in-house phrasebased system analogous to Moses (Koehn et al., 2007). The baseline system is the triangulation method (Wu and Wang, 2007), including an interpolated model which linearly interpolate the direct and pivot translation model. 1 http://www.statmt.org/europarl We use WMT082 as our test data, which contains 2000 in-domain sentences and 2051 out-ofdomain sentences with single reference. The translation results are evaluated by caseinsensitive BLEU-4 metric (Papineni et al., 2002). The"
D14-1174,W11-2601,0,0.017343,"arl data and web data show that our method leads to significant improvements over the baseline systems. 1 Introduction Statistical Machine Translation (SMT) relies on large bilingual parallel data to produce high quality translation results. Unfortunately, for some language pairs, large bilingual corpora are not readily available. To alleviate the parallel data scarceness, a conventional solution is to introduce a “bridge” language (named pivot language) to connect the source and target language (de Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007; Bertoldi et al., 2008; Paul et al., 2011; El Kholy et al., 2013; Zahabi et al., 2013), where there are large amounts of source-pivot and pivot-target parallel corpora. Among various pivot-based approaches, the triangulation method (Cohn and Lapata, 2007; Wu and Wang, 2007) is a representative work in * pivot-based machine translation. The approach proposes to build a source-target phrase table by merging the source-pivot and pivot-target phrase table. One of the key issues in this method is to estimate the translation probabilities for the generated source-target phrase pairs. Conventionally, the probabilities are estimated by multi"
D14-1174,I11-1091,0,0.0343951,"Missing"
D14-1174,P02-1040,0,0.0885743,"Missing"
D14-1174,E12-1015,0,0.0948513,"Missing"
D14-1174,P07-2050,0,0.0731859,"Missing"
D14-1174,N07-1061,0,0.872022,"ce-pivot and pivot-target phrase pairs. Experimental results on Europarl data and web data show that our method leads to significant improvements over the baseline systems. 1 Introduction Statistical Machine Translation (SMT) relies on large bilingual parallel data to produce high quality translation results. Unfortunately, for some language pairs, large bilingual corpora are not readily available. To alleviate the parallel data scarceness, a conventional solution is to introduce a “bridge” language (named pivot language) to connect the source and target language (de Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007; Bertoldi et al., 2008; Paul et al., 2011; El Kholy et al., 2013; Zahabi et al., 2013), where there are large amounts of source-pivot and pivot-target parallel corpora. Among various pivot-based approaches, the triangulation method (Cohn and Lapata, 2007; Wu and Wang, 2007) is a representative work in * pivot-based machine translation. The approach proposes to build a source-target phrase table by merging the source-pivot and pivot-target phrase table. One of the key issues in this method is to estimate the translation probabilities for the generated source-target phrase pa"
D14-1174,2008.iwslt-evaluation.11,0,0.0527301,"Missing"
D14-1174,P07-1108,1,0.954596,"hrase pairs. Experimental results on Europarl data and web data show that our method leads to significant improvements over the baseline systems. 1 Introduction Statistical Machine Translation (SMT) relies on large bilingual parallel data to produce high quality translation results. Unfortunately, for some language pairs, large bilingual corpora are not readily available. To alleviate the parallel data scarceness, a conventional solution is to introduce a “bridge” language (named pivot language) to connect the source and target language (de Gispert and Marino, 2006; Utiyama and Isahara, 2007; Wu and Wang, 2007; Bertoldi et al., 2008; Paul et al., 2011; El Kholy et al., 2013; Zahabi et al., 2013), where there are large amounts of source-pivot and pivot-target parallel corpora. Among various pivot-based approaches, the triangulation method (Cohn and Lapata, 2007; Wu and Wang, 2007) is a representative work in * pivot-based machine translation. The approach proposes to build a source-target phrase table by merging the source-pivot and pivot-target phrase table. One of the key issues in this method is to estimate the translation probabilities for the generated source-target phrase pairs. Conventionally"
D14-1174,P09-1018,1,0.899443,"one hand, the time cost is doubled; on the other hand, the translation error of the source-pivot translation system will be transferred to the pivot-target translation. Synthetic Method: It aims to create a synthetic source-target corpus by: (1) translate the pivot part in source-pivot corpus into target language with a pivot-target model; (2) translate the pivot part in pivot-target corpus into source language with a pivot-source model; (3) combine the source sentences with translated target sentences or/and combine the target sentences with translated source sentences (Utiyama et al., 2008; Wu and Wang, 2009). However, it is difficult to build a high quality translation system with a corpus created by a machine translation system. Triangulation Method: The triangulation method obtains source-target phrase table by merging source-pivot and pivot-target phrase table entries with identical pivot language phrases and multiplying corresponding posterior probabilities (Wu and Wang, 2007; Cohn and Lapata, 2007), which has been shown to work better than the other pivot approaches (Utiyama and Isahara, 2007). A problem of this approach is that the probability space of the source-target phrase pairs is non-"
D14-1174,2008.iwslt-evaluation.18,1,\N,Missing
D14-1174,P07-2045,0,\N,Missing
D14-1174,C08-2032,0,\N,Missing
D14-1174,P13-2057,0,\N,Missing
D14-1174,I13-1167,0,\N,Missing
D14-1174,P13-2073,0,\N,Missing
D14-1174,2009.mtsummit-papers.7,0,\N,Missing
D17-1304,W09-2307,0,0.0166967,"annotation vectors H and dependency annotation vectors D. The current context vector csi and cdi are compute by eq.(4), respectively: J X … CNN yi-1 … Figure 2: SDRNMT-1 for the i-th time step. csi = … … x7 CNN ci … x6 VU2 ? i,1 ? i,1 ? ? i,2 i,2 … i,J x5 U2=&lt;x3, x1, x4, x7 , ε&gt; CNN d1 x4 (14) Experiment Setting up We carry out experiments on Chinese-to-English translation. The training dataset consists of 1.42M 2 λ can be tuned according to a subset FBIS of training data and be set as 0.6 in the experiments. sentence pairs extract from LDC corpora.3 We use the Stanford dependency parser (Chang et al., 2009) to generate the dependency tree for Chinese. We choose the NIST 2002 (MT02) and the NIST 2003-2008 (MT03-08) datasets as the validation set and test sets, respectively. Case-insensitive 4gram NIST BLEU score (Papineni et al., 2002) is used as an evaluation metric, and signtest (Collins et al., 2005) is as statistical significance test. The baseline systems include the standard Phrase-Based Statistical Machine Translation (PBSMT) implemented in Moses (Koehn et al., 2007) and the standard Attentional NMT (AttNMT) (Bahdanau et al., 2014), where only source word representation is utilized. We als"
D17-1304,P05-1066,0,0.206266,"Experiment Setting up We carry out experiments on Chinese-to-English translation. The training dataset consists of 1.42M 2 λ can be tuned according to a subset FBIS of training data and be set as 0.6 in the experiments. sentence pairs extract from LDC corpora.3 We use the Stanford dependency parser (Chang et al., 2009) to generate the dependency tree for Chinese. We choose the NIST 2002 (MT02) and the NIST 2003-2008 (MT03-08) datasets as the validation set and test sets, respectively. Case-insensitive 4gram NIST BLEU score (Papineni et al., 2002) is used as an evaluation metric, and signtest (Collins et al., 2005) is as statistical significance test. The baseline systems include the standard Phrase-Based Statistical Machine Translation (PBSMT) implemented in Moses (Koehn et al., 2007) and the standard Attentional NMT (AttNMT) (Bahdanau et al., 2014), where only source word representation is utilized. We also compare with a state-of-the-art syntax enhanced NMT method (Sennrich and Haddow, 2016). For a fair comparison, we only utilize dependency information for (Sennrich and Haddow, 2016), called Sennrich-deponly. We try our best to re-implement the baseline methods on Nematus toolkit 4 (Sennrich et al.,"
D17-1304,P14-1129,0,0.0116576,"or VUj for Uj . In our experiment, the output of the output layer is 1 × d-dimension vector. It should be noted that the dependency unit is similar to the source dependency feature of Sennrich and Haddow (2016) and the SDR is the same to the source-side representation of Chen et al. (2017). In comparison with Sennrich and Haddow (2016), who concatenate the source dependency labels and word together to enhance the Encoder of NMT, we adapt a separate attention mechanism together with a CNN dependency Encoder. Compared with Chen et al. (2017), which expands the famous neural network joint model (Devlin et al., 2014) with source dependency information to improve the phrase pair translation probability estimation for SMT, we focus on source dependency information to enhance attention probability estimation and to learn corresponding dependency context and RNN hidden state for improving translation. 4 NMT with SDR In this section, we propose two novel NMT models SDRNMT-1 and SDRNMT-2, both of which can make use of source dependency information SDR to enhance Encoder and Decoder of NMT. 4.1 greatly tackle the sparsity issues associated with large dependency units. Motivated by (Sennrich and Haddow, 2016), we"
D17-1304,P16-1078,0,0.0619476,"h translation task show that our method achieves 1.6 BLEU improvements on average over a strong NMT system. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Sutskever et al., 2014) relies heavily on source representations, which encode implicitly semantic information of source words by neural networks (Mikolov et al., 2013a,b). Recently, several research works have been proposed to learn richer source representation, such as multisource information (Zoph and Knight, 2016; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; Hadiwinoto et al., 2016; Chen et al., 2017; Hadiwinoto and Ng, 2017). I"
D17-1304,P17-2012,0,0.0146372,"ovements on average over a strong NMT system. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Sutskever et al., 2014) relies heavily on source representations, which encode implicitly semantic information of source words by neural networks (Mikolov et al., 2013a,b). Recently, several research works have been proposed to learn richer source representation, such as multisource information (Zoph and Knight, 2016; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; Hadiwinoto et al., 2016; Chen et al., 2017; Hadiwinoto and Ng, 2017). In NMT, there has been a quite recent preliminary exploration (S"
D17-1304,N16-1101,0,0.0209728,"cially on long sentences. Empirical results on NIST Chinese-toEnglish translation task show that our method achieves 1.6 BLEU improvements on average over a strong NMT system. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Sutskever et al., 2014) relies heavily on source representations, which encode implicitly semantic information of source words by neural networks (Mikolov et al., 2013a,b). Recently, several research works have been proposed to learn richer source representation, such as multisource information (Zoph and Knight, 2016; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; H"
D17-1304,D14-1176,0,0.0464241,"Missing"
D17-1304,P17-1177,0,0.0492407,"achieves 1.6 BLEU improvements on average over a strong NMT system. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Sutskever et al., 2014) relies heavily on source representations, which encode implicitly semantic information of source words by neural networks (Mikolov et al., 2013a,b). Recently, several research works have been proposed to learn richer source representation, such as multisource information (Zoph and Knight, 2016; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; Hadiwinoto et al., 2016; Chen et al., 2017; Hadiwinoto and Ng, 2017). In NMT, there has been a quite recent pr"
D17-1304,D13-1176,0,0.0524365,"successfully introduced into statistical machine translation. However, there are only a few preliminary attempts for Neural Machine Translation (NMT), such as concatenating representations of source word and its dependency label together. In this paper, we propose a novel attentional NMT with source dependency representation to improve translation performance of NMT, especially on long sentences. Empirical results on NIST Chinese-toEnglish translation task show that our method achieves 1.6 BLEU improvements on average over a strong NMT system. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Sutskever et al., 2014) relies heavily on source representations, which encode implicitly semantic information of source words by neural networks (Mikolov et al., 2013a,b). Recently, several research works have been proposed to learn richer source representation, such as multisource information (Zoph and Knight, 2016; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency"
D17-1304,W15-4906,0,0.0209798,"6; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; Hadiwinoto et al., 2016; Chen et al., 2017; Hadiwinoto and Ng, 2017). In NMT, there has been a quite recent preliminary exploration (Sennrich and Haddow, 2016), in which vector representations of source word and its dependency label are simply concatenated as source input, achieving state-ofthe-art performance in NMT (Bojar et al., 2016). In this paper, we propose a novel NMT with source dependency representation to improve translation performance. Compared with the simple approach of vector concatenation, we learn the Source Dependency Representation (SDR) to compute dependency context vect"
D17-1304,P07-2045,0,0.0114868,"data and be set as 0.6 in the experiments. sentence pairs extract from LDC corpora.3 We use the Stanford dependency parser (Chang et al., 2009) to generate the dependency tree for Chinese. We choose the NIST 2002 (MT02) and the NIST 2003-2008 (MT03-08) datasets as the validation set and test sets, respectively. Case-insensitive 4gram NIST BLEU score (Papineni et al., 2002) is used as an evaluation metric, and signtest (Collins et al., 2005) is as statistical significance test. The baseline systems include the standard Phrase-Based Statistical Machine Translation (PBSMT) implemented in Moses (Koehn et al., 2007) and the standard Attentional NMT (AttNMT) (Bahdanau et al., 2014), where only source word representation is utilized. We also compare with a state-of-the-art syntax enhanced NMT method (Sennrich and Haddow, 2016). For a fair comparison, we only utilize dependency information for (Sennrich and Haddow, 2016), called Sennrich-deponly. We try our best to re-implement the baseline methods on Nematus toolkit 4 (Sennrich et al., 2017). For all NMT systems, we limit the source and target vocabularies to 30K, and the maximum sentence length is 80. The word embedding dimension is 620,5 and the hidden l"
D17-1304,P17-1064,0,0.0668486,"that our method achieves 1.6 BLEU improvements on average over a strong NMT system. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Sutskever et al., 2014) relies heavily on source representations, which encode implicitly semantic information of source words by neural networks (Mikolov et al., 2013a,b). Recently, several research works have been proposed to learn richer source representation, such as multisource information (Zoph and Knight, 2016; Firat et al., 2016), and particularly source syntactic information (Eriguchi et al., 2016; Li et al., 2017; Huadong et al., 2017; Eriguchi et al., 2017), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; Hadiwinoto et al., 2016; Chen et al., 2017; Hadiwinoto and Ng, 2017). In NMT, there has"
D17-1304,P02-1040,0,0.11802,"? i,1 ? ? i,2 i,2 … i,J x5 U2=&lt;x3, x1, x4, x7 , ε&gt; CNN d1 x4 (14) Experiment Setting up We carry out experiments on Chinese-to-English translation. The training dataset consists of 1.42M 2 λ can be tuned according to a subset FBIS of training data and be set as 0.6 in the experiments. sentence pairs extract from LDC corpora.3 We use the Stanford dependency parser (Chang et al., 2009) to generate the dependency tree for Chinese. We choose the NIST 2002 (MT02) and the NIST 2003-2008 (MT03-08) datasets as the validation set and test sets, respectively. Case-insensitive 4gram NIST BLEU score (Papineni et al., 2002) is used as an evaluation metric, and signtest (Collins et al., 2005) is as statistical significance test. The baseline systems include the standard Phrase-Based Statistical Machine Translation (PBSMT) implemented in Moses (Koehn et al., 2007) and the standard Attentional NMT (AttNMT) (Bahdanau et al., 2014), where only source word representation is utilized. We also compare with a state-of-the-art syntax enhanced NMT method (Sennrich and Haddow, 2016). For a fair comparison, we only utilize dependency information for (Sennrich and Haddow, 2016), called Sennrich-deponly. We try our best to re-"
D17-1304,E17-3017,0,0.043072,"Missing"
D17-1304,W16-2209,0,0.149106,"), thus improving the performance of NMT. In this paper, we enhance source representations by dependency information, which can capture source long-distance dependency constraints for word prediction. Actually, source dependency information has been shown greatly effective in ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. Statistical Machine Translation (SMT) (Garmash and Monz, 2014; Kazemi et al., 2015; Hadiwinoto et al., 2016; Chen et al., 2017; Hadiwinoto and Ng, 2017). In NMT, there has been a quite recent preliminary exploration (Sennrich and Haddow, 2016), in which vector representations of source word and its dependency label are simply concatenated as source input, achieving state-ofthe-art performance in NMT (Bojar et al., 2016). In this paper, we propose a novel NMT with source dependency representation to improve translation performance. Compared with the simple approach of vector concatenation, we learn the Source Dependency Representation (SDR) to compute dependency context vectors and alignment matrices in a more sophisticated manner, which has the potential to make full use of source dependency information. To this end, we create a de"
D17-1304,N16-1004,0,0.0215619,"Missing"
D17-1304,W16-2301,0,\N,Missing
D19-1570,P18-1060,0,0.0269909,"thods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized and explored by Recht et al. (2018, 2019); Werpachowski et al. (2019), and is especially notorious for language generation tasks (Chaganty et al., 2018; Hashimoto et al., 2019) where the evaluation metrics, e.g. BLEU (Papineni et al., 2001), are extrinsic and heavily relies on the reference provided. Therefore, we ask a fundamental question: what benefits, which are more consistent across different DA methods and translation tasks, can DA in general obtain? A direct answer to the above question is to use generalization gap (Kawaguchi et al., 2018) defined by the difference between population risk and empirical risk. This measure does not rely on any specific test set, accurately depicts generalization but is intractable to compute. So recent"
D19-1570,P16-1185,0,0.0948154,"Missing"
D19-1570,D18-1045,0,0.143239,"eriments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized and explored by Recht et al. (2018, 2019); Werpachowski et a"
D19-1570,P17-2090,0,0.404575,"lead to findings with relatively low variance. Extensive experiments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized"
D19-1570,D18-1040,0,0.371581,"latively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized and explored by Recht et al. (2018, 2019); Werpachowski et al. (2019), and is especi"
D19-1570,N19-1169,0,0.0176147,"ir test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized and explored by Recht et al. (2018, 2019); Werpachowski et al. (2019), and is especially notorious for language generation tasks (Chaganty et al., 2018; Hashimoto et al., 2019) where the evaluation metrics, e.g. BLEU (Papineni et al., 2001), are extrinsic and heavily relies on the reference provided. Therefore, we ask a fundamental question: what benefits, which are more consistent across different DA methods and translation tasks, can DA in general obtain? A direct answer to the above question is to use generalization gap (Kawaguchi et al., 2018) defined by the difference between population risk and empirical risk. This measure does not rely on any specific test set, accurately depicts generalization but is intractable to compute. So recently, many theorists have p"
D19-1570,D16-1139,0,0.0633063,"Missing"
D19-1570,N19-4007,0,0.041402,"Missing"
D19-1570,N19-4009,0,0.026019,"T ). 1 Under the AUG model, the training objective becomes: JAUG = Ex,y⇠q(X,Y |T ) [log p✓ (y|x)]. En)De Baseline 38.38 (5) 38.88 (6) 17.25 (6) 26.19 (4) RAML +0.22 (3) +0.67 (3) +0.23 (4) -0.16 (6) SO +0.01 (4) +0.62 (4) +0.02 (5) -0.15 (5) 2.2 ST -0.13 (6) +0.46 (5) +1.51 (2) +0.83 (2) TA +0.62 (2) +1.13 (1) +2.41 (1) +1.01 (1) BT +0.82 (1) +0.99 (2) +1.06 (3) +0.39 (3) Settings and Main Performance Settings By carefully controlling the above two factors, we conduct fair and extensive experiments with Transformer (Vaswani et al., 2017) on four translation tasks for five DA methods. Fairseq (Ott et al., 2019) is used as our codebase. We use standard benchmarks IWSLT17 En-Fr, WMT19 ZhEn, WMT19 En-De, where we train both translation directions on the IWSLT corpus. The five DA methods are briefly summarized as follows: • RAML: reward-augmented maximum likelihood training, which augment the target-side with a sampling distribution P (Y |Y ⇤ ) concentrated around Y ⇤ (Norouzi et al., 2016). (2) • Switchout (SO): similar to RAML, but also adds the some kind of augmentation to the source-side (Wang et al., 2018). • Self-training (ST): fix the source-side, uses an forward NMT model to generate the target-"
D19-1570,2001.mtsummit-papers.68,0,0.0198772,"xhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized and explored by Recht et al. (2018, 2019); Werpachowski et al. (2019), and is especially notorious for language generation tasks (Chaganty et al., 2018; Hashimoto et al., 2019) where the evaluation metrics, e.g. BLEU (Papineni et al., 2001), are extrinsic and heavily relies on the reference provided. Therefore, we ask a fundamental question: what benefits, which are more consistent across different DA methods and translation tasks, can DA in general obtain? A direct answer to the above question is to use generalization gap (Kawaguchi et al., 2018) defined by the difference between population risk and empirical risk. This measure does not rely on any specific test set, accurately depicts generalization but is intractable to compute. So recently, many theorists have proposed either non-vacuous generalization bound (Dziugaite and R"
D19-1570,P16-1009,0,0.481577,"heoretic advances in deep learning, the paper understands DA from two perspectives towards the generalization ability of a model: input sensitivity and prediction margin, which are defined independent of specific test set thereby may lead to findings with relatively low variance. Extensive experiments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work"
D19-1570,P16-1162,0,0.45957,"heoretic advances in deep learning, the paper understands DA from two perspectives towards the generalization ability of a model: input sensitivity and prediction margin, which are defined independent of specific test set thereby may lead to findings with relatively low variance. Extensive experiments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work"
D19-1570,D16-1160,0,0.217106,"test set thereby may lead to findings with relatively low variance. Extensive experiments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemm"
D19-1570,D13-1117,0,0.0521142,"Missing"
D19-1570,D18-1100,0,0.343546,"relatively low variance. Extensive experiments show that relatively consistent benefits across five DA methods and four translation tasks are achieved regarding both perspectives. 1 Introduction Data Augmentation (DA) is a training paradigm that has been proved to be very effective in many modalities (Park et al., 2019; Perez and Wang, 2017; Sennrich et al., 2016a), especially for classification (Perez and Wang, 2017). In structured domain, Neural Machine Translation (NMT) is the frontier of DA research (Sennrich et al., 2016a; Norouzi et al., 2016; Zhang and Zong, 2016; Fadaee et al., 2017; Wang et al., 2018; Zhang et al., 2019; Edunov et al., 2018; Fadaee and Monz, 2018). However, by investigating a variety of DA methods, we find that their test performance across different translation tasks does not exhibit consistent improvement, and this phenomenon can be initially observed in (Wang et al., 2018) as well. The reason might be the evaluation ⇤ Work done at Tencent AI Lab. metric on a specific test set when compared to the whole data population, which generates all possible data, has large variance so that leads to the inconsistency. This evaluation dilemma is also recognized and explored by Rec"
I05-2003,J93-2003,0,\N,Missing
I05-2003,C04-1069,0,\N,Missing
I13-1032,D08-1024,0,0.179727,"grouping via OSCAR to overcome these pitfalls. Our feature grouping is implemented within an online learning framework and thus it is efficient for a large scale (both for features and examples) of learning in our scenario. Experiment results on IWSLT translation tasks show that the proposed method significantly outperforms the state of the art tuning methods. 1 Introduction Since the introduction of log-linear based SMT (Och and Ney, 2002), tuning has been a hot topic. Various methods have been explored: their objectives are either error rates (Och, 2003), hinge loss (Watanabe et al., 2007; Chiang et al., 2008) or ranking loss (Hopkins and May, 2011), and they are either batch training or online training methods. In this paper, we consider tuning translation models with a large number of features such as lexical, n-gram level and rule level features, where the number of features is largely greater than the number of bilingual sentences. Practically, existing tuning methods such as PRO and MIRA might This joint work was done while the first author visited NICT. be applied in our scenario, however, they will suffer from some pitfalls as well, which have been less investigated in previous works. One of"
I13-1032,P05-1033,0,0.0461075,"n is attributed to the Eq.5 in (Zhong and Kwok, 2011). pairs. Test sets 2003, 2004 and 2008 are used as the development set, development test (devtest) set and test set, respectively; and all of them contain 16 references. A 5-gram language model is trained on the training data with the SRILM toolkit, and word alignment is obtained with GIZA++. In our experiments, the translation performances are measured by the case-insensitive BLEU4 metric. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline decoder, and we use the state of the art tuning methods MERT and PRO as our comparison methods4 . Based on our in-house decoder, we implement three translation models with different feature sets: default features (default); default features plus rule id features (+id) ; and default features plus group features of rule id (+group). On the IWSLT training data, the number of rule id features is 500K, i.e. d = 500K, which is significantly greater than the number of bilingual sentences 30K. Our proposed tuning method is with the following setting by tuning on the dev-test set: λ1 ="
I13-1032,D11-1125,0,0.0685367,"pitfalls. Our feature grouping is implemented within an online learning framework and thus it is efficient for a large scale (both for features and examples) of learning in our scenario. Experiment results on IWSLT translation tasks show that the proposed method significantly outperforms the state of the art tuning methods. 1 Introduction Since the introduction of log-linear based SMT (Och and Ney, 2002), tuning has been a hot topic. Various methods have been explored: their objectives are either error rates (Och, 2003), hinge loss (Watanabe et al., 2007; Chiang et al., 2008) or ranking loss (Hopkins and May, 2011), and they are either batch training or online training methods. In this paper, we consider tuning translation models with a large number of features such as lexical, n-gram level and rule level features, where the number of features is largely greater than the number of bilingual sentences. Practically, existing tuning methods such as PRO and MIRA might This joint work was done while the first author visited NICT. be applied in our scenario, however, they will suffer from some pitfalls as well, which have been less investigated in previous works. One of pitfalls is that these features are so"
I13-1032,W04-3250,0,0.0161007,"on tasks, whose training data consists of about 30K bilingual sentence 3 The reason is attributed to the Eq.5 in (Zhong and Kwok, 2011). pairs. Test sets 2003, 2004 and 2008 are used as the development set, development test (devtest) set and test set, respectively; and all of them contain 16 references. A 5-gram language model is trained on the training data with the SRILM toolkit, and word alignment is obtained with GIZA++. In our experiments, the translation performances are measured by the case-insensitive BLEU4 metric. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline decoder, and we use the state of the art tuning methods MERT and PRO as our comparison methods4 . Based on our in-house decoder, we implement three translation models with different feature sets: default features (default); default features plus rule id features (+id) ; and default features plus group features of rule id (+group). On the IWSLT training data, the number of rule id features is 500K, i.e. d = 500K, which is significantly greater than the number of bilingual sentences 30K. Our propo"
I13-1032,C10-1075,0,0.259742,"er-fitting occurs. One practice is to tune translation models on a larger tuning set, such as the entire training data (Xiao et al., 2011; Simianer et al., 2012), in the hope that more features would be included during tuning. However, tuning robust weights for translation models has additional requirements to a tuning set. Firstly, multiple reference translations in the tuning data are helpful for better tuning, especially when testing data contains multiple reference translations. Secondly, the closeness between the tuning set and a test set is also important for better testing performance (Li et al., 2010). These requirements can explain why tuning on the training data leads to unsatisfactory performance on the IWSLT translation task, as will be shown in our experiments later. Therefore, enlarging a tuning set is not always a sufficient solution for robust tuning, since it would be impractical to create a large scale tuning set with these requirements. We propose a novel tuning method by grouping a large number of features to leverage the above pitfalls. Instead of directly taking the large number of atomic features into translation model, we firstly learn their group structure on the training"
I13-1032,P02-1038,0,0.1062,"a result, we face an over-fitting problem, which limits the generalization abilities of the learned models. Based on our analysis, we propose a novel method based on feature grouping via OSCAR to overcome these pitfalls. Our feature grouping is implemented within an online learning framework and thus it is efficient for a large scale (both for features and examples) of learning in our scenario. Experiment results on IWSLT translation tasks show that the proposed method significantly outperforms the state of the art tuning methods. 1 Introduction Since the introduction of log-linear based SMT (Och and Ney, 2002), tuning has been a hot topic. Various methods have been explored: their objectives are either error rates (Och, 2003), hinge loss (Watanabe et al., 2007; Chiang et al., 2008) or ranking loss (Hopkins and May, 2011), and they are either batch training or online training methods. In this paper, we consider tuning translation models with a large number of features such as lexical, n-gram level and rule level features, where the number of features is largely greater than the number of bilingual sentences. Practically, existing tuning methods such as PRO and MIRA might This joint work was done whi"
I13-1032,P03-1021,0,0.104864,"sis, we propose a novel method based on feature grouping via OSCAR to overcome these pitfalls. Our feature grouping is implemented within an online learning framework and thus it is efficient for a large scale (both for features and examples) of learning in our scenario. Experiment results on IWSLT translation tasks show that the proposed method significantly outperforms the state of the art tuning methods. 1 Introduction Since the introduction of log-linear based SMT (Och and Ney, 2002), tuning has been a hot topic. Various methods have been explored: their objectives are either error rates (Och, 2003), hinge loss (Watanabe et al., 2007; Chiang et al., 2008) or ranking loss (Hopkins and May, 2011), and they are either batch training or online training methods. In this paper, we consider tuning translation models with a large number of features such as lexical, n-gram level and rule level features, where the number of features is largely greater than the number of bilingual sentences. Practically, existing tuning methods such as PRO and MIRA might This joint work was done while the first author visited NICT. be applied in our scenario, however, they will suffer from some pitfalls as well, wh"
I13-1032,P02-1040,0,0.0863901,"atomic features into translation model, we firstly learn their group structure on the training data to alleviate their serious sparsity. Then, we tune the translation model consisting of grouped features on a multi-reference development set to ensure robust tuning. Unlike unsupervised clustering methods such as k-means (MacQueen, 1967) for feature clustering, we group the features with the OSCAR (Octagonal Shrinkage and Clustering Algorithm for Regression) method (Bondell and Reich, 2008), which directly relates the objective of feature grouping to translation evaluation metrics such as BLEU (Papineni et al., 2002) and thus grouped features are optimized with respect to BLEU. Due to the large number of features and large number of training examples, efficient grouping is not simple. We apply the online gradient projection method under the FOBOS (forwardbackward splitting) framework (Duchi and Singer, 2009) to accelerate feature grouping. We employ a large number of features by treating each translation rule in a synchronous-CFG as a single feature. Experiments on IWSLT Chineseto-English translation tasks show that, with the help of grouping these features, our method can overcome the above pitfalls and"
I13-1032,P12-1002,0,0.0603095,"pitfalls as well, which have been less investigated in previous works. One of pitfalls is that these features are so sparse that many features which are potentially useful for a test set may not be included in a given tuning set, and many useless features for testing will be over tuned on the developement set meanwhile. As a result, the generalization abilities of features are limited due to the mismatch between the testing data and the tuning data, and over-fitting occurs. One practice is to tune translation models on a larger tuning set, such as the entire training data (Xiao et al., 2011; Simianer et al., 2012), in the hope that more features would be included during tuning. However, tuning robust weights for translation models has additional requirements to a tuning set. Firstly, multiple reference translations in the tuning data are helpful for better tuning, especially when testing data contains multiple reference translations. Secondly, the closeness between the tuning set and a test set is also important for better testing performance (Li et al., 2010). These requirements can explain why tuning on the training data leads to unsatisfactory performance on the IWSLT translation task, as will be sh"
I13-1032,P09-1054,0,0.0310359,"t features setting. Its main reason, as presented in Section 1, may be that multiple references and closeness5 of tuning sets are much helpful for translation tasks. Further, the id features do not achieve improvements and even decreases 0.9 BLEU scores when tuned on the development set, due to its serious sparsity. However, after grouping id features, the groups learned by our method can alleviate the feature sparsity and thus significantly obtain gains of 0.7 BLEU scores over default feature setting. Further, we implement another tuning method6 for comparison, i.e. L1 regularization method (Tsuruoka et al., 2009) based on the ranking loss L(W ) defined in Eq.1. We tune the translation 4 Both of them are derived from the Moses toolkit: http://www.statmt.org/moses/. 5 If the tuning set and test set are close enough or identically distributed, it is possible to get gains by sparse discriminative features without using feature grouping(Chiang et al., 2009). 6 It is similar to dtrain implemented in the cdec toolkit: http://cdec-decoder.org/, except that it does not use the distributed learning framework. Methods Tuning set Feature set MERT PRO PRO PRO L1 L1 OSCAR dev dev train dev train dev – default defau"
I13-1032,D07-1080,1,0.803531,"method based on feature grouping via OSCAR to overcome these pitfalls. Our feature grouping is implemented within an online learning framework and thus it is efficient for a large scale (both for features and examples) of learning in our scenario. Experiment results on IWSLT translation tasks show that the proposed method significantly outperforms the state of the art tuning methods. 1 Introduction Since the introduction of log-linear based SMT (Och and Ney, 2002), tuning has been a hot topic. Various methods have been explored: their objectives are either error rates (Och, 2003), hinge loss (Watanabe et al., 2007; Chiang et al., 2008) or ranking loss (Hopkins and May, 2011), and they are either batch training or online training methods. In this paper, we consider tuning translation models with a large number of features such as lexical, n-gram level and rule level features, where the number of features is largely greater than the number of bilingual sentences. Practically, existing tuning methods such as PRO and MIRA might This joint work was done while the first author visited NICT. be applied in our scenario, however, they will suffer from some pitfalls as well, which have been less investigated in"
I13-1032,D11-1081,0,0.367302,"ll suffer from some pitfalls as well, which have been less investigated in previous works. One of pitfalls is that these features are so sparse that many features which are potentially useful for a test set may not be included in a given tuning set, and many useless features for testing will be over tuned on the developement set meanwhile. As a result, the generalization abilities of features are limited due to the mismatch between the testing data and the tuning data, and over-fitting occurs. One practice is to tune translation models on a larger tuning set, such as the entire training data (Xiao et al., 2011; Simianer et al., 2012), in the hope that more features would be included during tuning. However, tuning robust weights for translation models has additional requirements to a tuning set. Firstly, multiple reference translations in the tuning data are helpful for better tuning, especially when testing data contains multiple reference translations. Secondly, the closeness between the tuning set and a test set is also important for better testing performance (Li et al., 2010). These requirements can explain why tuning on the training data leads to unsatisfactory performance on the IWSLT transla"
I13-1032,N09-1025,0,\N,Missing
I13-1128,P02-1040,0,0.087697,"Missing"
I13-1128,W08-0336,0,0.0291583,"Missing"
I13-1128,P11-2071,0,0.0454951,"Missing"
I13-1128,P10-1064,0,0.045945,"Missing"
I13-1128,P03-1021,0,0.0971049,"Missing"
I13-1128,W99-0604,0,0.293756,"Missing"
I13-1128,J82-2005,0,0.757727,"Missing"
I13-1128,P11-1124,0,0.0288371,"Missing"
I13-1128,2009.mtsummit-papers.14,0,0.106923,"Missing"
I13-1128,2010.jec-1.4,0,\N,Missing
I17-1002,P05-1066,0,0.210454,"Missing"
I17-1002,P16-2058,0,0.0359599,"Missing"
I17-1002,W04-3208,0,0.0171983,"the OOV’s semantic information. Second, we also extend the contextaware smoothing method to in-vocabulary words, which enhances encoder and decoder of NMT by more effectively utilizing context information by the learned CAR. To this end, we proposed two unique neural networks to learn the contextaware representation for each word depending on its context words in a fixed-size window. We then design four NMT models with CAR to improve translation performance by smoothing the encoder and decoder. Related Work In traditional SMT, there are many research works to improve the translations of OOVs. Fung and Cheung (2004) and Shao and Ng (2004) adopte comparable corpora and web resources to extract translations for each unknown word. Marton et al. (2009) and Mirkin et al. (2009) applied paraphrase model and entailment rules to replace unknown words with in-vocabulary synonyms before translation. A series of works (Knight and Graehl, 1997; Jiang et al., 2007; Al-Onaizan and Knight, 2002) utilized transliteration and web mining techniques with external monolingual/bilingual corpora, comparable data and the web resource to find the translation of the unknown words. Nearly most of the related PBSMT researches focu"
I17-1002,P15-1001,0,0.0317148,"n 5 reports the experimental results obtained in the Chineseto-English task. Finally, we conclude the contributions of the paper and discuss the further work in Section 6. 12 proposed method can smooth the representation of word and reduce the unk’s negative effect in attention model, context annotations and decoding hidden states, thus improving the performance of NMT. these methods improved the translation of OOV, they must learn external bilingual dictionary information in advance. From the point of vocabulary size, many works tried to use a large vocabulary size, thus covering more words. Jean et al. (2015) proposed a method based on importance sampling that allowed NMT model to use a very large target vocabulary for relieving the OOV phenomenon in NMT, which are only designed to reduce the computational complexity in training, not for decoding. Arthur et al. (2016) introduced discrete translation lexicons into NMT to imrpove the translations of these low-frequency words. Mi et al. (2016) proposed a vocabulary manipulation approach by limiting the number of vocabulary being predicted by each batch or sentence, to reduce both the training and the decoding complexity. These methods focused on the"
I17-1002,P02-1051,0,0.0320588,"a fixed-size window. We then design four NMT models with CAR to improve translation performance by smoothing the encoder and decoder. Related Work In traditional SMT, there are many research works to improve the translations of OOVs. Fung and Cheung (2004) and Shao and Ng (2004) adopte comparable corpora and web resources to extract translations for each unknown word. Marton et al. (2009) and Mirkin et al. (2009) applied paraphrase model and entailment rules to replace unknown words with in-vocabulary synonyms before translation. A series of works (Knight and Graehl, 1997; Jiang et al., 2007; Al-Onaizan and Knight, 2002) utilized transliteration and web mining techniques with external monolingual/bilingual corpora, comparable data and the web resource to find the translation of the unknown words. Nearly most of the related PBSMT researches focused on finding the correct translation of the unknown words with external resources and ignored the negative effect for other words. Compared with PBSMT, due to high computational cost, NMT has a more limited vocabulary size and severe OOV phenomenon. The existing PBSMT methods that used external resources to translate unknown words for SMT are hard to be directly intro"
I17-1002,D16-1162,0,0.0215161,"ect in attention model, context annotations and decoding hidden states, thus improving the performance of NMT. these methods improved the translation of OOV, they must learn external bilingual dictionary information in advance. From the point of vocabulary size, many works tried to use a large vocabulary size, thus covering more words. Jean et al. (2015) proposed a method based on importance sampling that allowed NMT model to use a very large target vocabulary for relieving the OOV phenomenon in NMT, which are only designed to reduce the computational complexity in training, not for decoding. Arthur et al. (2016) introduced discrete translation lexicons into NMT to imrpove the translations of these low-frequency words. Mi et al. (2016) proposed a vocabulary manipulation approach by limiting the number of vocabulary being predicted by each batch or sentence, to reduce both the training and the decoding complexity. These methods focused on the translation of OOV itself and ignored the other negative effect caused by the OOV, such as the translations of the words around the OOV. 3 Context-Aware Representation Intuitively, when one understands natural language sentence, especially including polysemy words"
I17-1002,D13-1176,0,0.372214,"representation of unk. To alleviate this problem, we propose a novel contextaware smoothing method to dynamically learn a sentence-specific vector for each word (including OOV words) depending on its local context words in a sentence. The learned context-aware representation is integrated into the NMT to improve the translation performance. Empirical results on NIST Chinese-to-English translation task show that the proposed approach achieves 1.78 BLEU improvements on average over a strong attentional NMT, and outperforms some existing systems. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015), has shown prominent performances in comparison with the conventional Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003). In NMT, a source sentence is converted into a vector representation by an RNN called encoder, then another RNN ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. 11 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 11–20, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP x1 x2 x3 x4 xu … xJ v1"
I17-1002,P97-1017,0,0.104382,"each word depending on its context words in a fixed-size window. We then design four NMT models with CAR to improve translation performance by smoothing the encoder and decoder. Related Work In traditional SMT, there are many research works to improve the translations of OOVs. Fung and Cheung (2004) and Shao and Ng (2004) adopte comparable corpora and web resources to extract translations for each unknown word. Marton et al. (2009) and Mirkin et al. (2009) applied paraphrase model and entailment rules to replace unknown words with in-vocabulary synonyms before translation. A series of works (Knight and Graehl, 1997; Jiang et al., 2007; Al-Onaizan and Knight, 2002) utilized transliteration and web mining techniques with external monolingual/bilingual corpora, comparable data and the web resource to find the translation of the unknown words. Nearly most of the related PBSMT researches focused on finding the correct translation of the unknown words with external resources and ignored the negative effect for other words. Compared with PBSMT, due to high computational cost, NMT has a more limited vocabulary size and severe OOV phenomenon. The existing PBSMT methods that used external resources to translate u"
I17-1002,P07-2045,0,0.0134503,"Missing"
I17-1002,P09-1089,0,0.0223355,"effectively utilizing context information by the learned CAR. To this end, we proposed two unique neural networks to learn the contextaware representation for each word depending on its context words in a fixed-size window. We then design four NMT models with CAR to improve translation performance by smoothing the encoder and decoder. Related Work In traditional SMT, there are many research works to improve the translations of OOVs. Fung and Cheung (2004) and Shao and Ng (2004) adopte comparable corpora and web resources to extract translations for each unknown word. Marton et al. (2009) and Mirkin et al. (2009) applied paraphrase model and entailment rules to replace unknown words with in-vocabulary synonyms before translation. A series of works (Knight and Graehl, 1997; Jiang et al., 2007; Al-Onaizan and Knight, 2002) utilized transliteration and web mining techniques with external monolingual/bilingual corpora, comparable data and the web resource to find the translation of the unknown words. Nearly most of the related PBSMT researches focused on finding the correct translation of the unknown words with external resources and ignored the negative effect for other words. Compared with PBSMT, due to"
I17-1002,N03-1017,0,0.0655639,"cal context words in a sentence. The learned context-aware representation is integrated into the NMT to improve the translation performance. Empirical results on NIST Chinese-to-English translation task show that the proposed approach achieves 1.78 BLEU improvements on average over a strong attentional NMT, and outperforms some existing systems. 1 Introduction Neural Machine Translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015), has shown prominent performances in comparison with the conventional Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003). In NMT, a source sentence is converted into a vector representation by an RNN called encoder, then another RNN ∗ Kehai Chen was an internship research fellow at NICT when conducting this work. † Corresponding author. 11 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 11–20, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP x1 x2 x3 x4 xu … xJ v1 v2 v3 v4 vu … vJ 1 2 3 5 … J 4 … They are beating each other for a dispute x1 x2 x3 v1 v2 v3 1 2 3 (a) … Attention α x4 x5 … v4 v5 … vJ 5 … J 4 xJ … Decoder Encoder Trg2 Encoder Src1 他们 想 通过 打"
I17-1002,P02-1040,0,0.100942,"Missing"
I17-1002,E17-3017,0,0.069622,"Missing"
I17-1002,P16-1100,0,0.0170641,"y, suppose there is a source language sentence, {x1 , x2 , . . . , xj , . . . , xJ }. If the context window is set as 2n (n = 2), the context of each word xi is defined as its historical n words and future n words: Recently, many works exploited the granularity translation unit from words to smaller subwords or characters. Sennrich et al. (2016) introduced a simpler and more effective approach to encode rare and unknown words as sequences of subword units by Byte Pair Encoding (Gage, 1994). This is based on the intuition that various word classes are translatable via smaller units than words. Luong and Manning (2016) segmented the known words into character sequence, and learned the unknown word representation by characterlevel recurrent neural networks, thus achieving open vocabulary NMT. Li et al. (2016) replaced OOVs with in-vocabulary words by semantic similarity to reduce the negative effect for words around the OOVs. Costa-juss`a and Fonollosa (2016) presented a character-based NMT, in which character-level embeddings were in combination with convolutional and highway layers to replace the standard lookup-based word representations. These methods extended the vocabulary to a larger or unlimited voca"
I17-1002,P16-1162,0,0.370792,"presentation (CAR) for each word. 3.1 Feedforward Context-of-Words Model Inspired by the representation learning of word (Bengio et al., 2003), the proposed FCWM includes an input layer, a projection layer, and a non-linear output layer, as shown in Figure 2 (a). Specifically, suppose there is a source language sentence, {x1 , x2 , . . . , xj , . . . , xJ }. If the context window is set as 2n (n = 2), the context of each word xi is defined as its historical n words and future n words: Recently, many works exploited the granularity translation unit from words to smaller subwords or characters. Sennrich et al. (2016) introduced a simpler and more effective approach to encode rare and unknown words as sequences of subword units by Byte Pair Encoding (Gage, 1994). This is based on the intuition that various word classes are translatable via smaller units than words. Luong and Manning (2016) segmented the known words into character sequence, and learned the unknown word representation by characterlevel recurrent neural networks, thus achieving open vocabulary NMT. Li et al. (2016) replaced OOVs with in-vocabulary words by semantic similarity to reduce the negative effect for words around the OOVs. Costa-juss"
I17-1002,P15-1002,0,0.0275471,"d the translation of the unknown words. Nearly most of the related PBSMT researches focused on finding the correct translation of the unknown words with external resources and ignored the negative effect for other words. Compared with PBSMT, due to high computational cost, NMT has a more limited vocabulary size and severe OOV phenomenon. The existing PBSMT methods that used external resources to translate unknown words for SMT are hard to be directly introduced into NMT, because of NMT’s soft-alignment mechanism (Bahdanau et al., 2015). To relieve the negative effect of unknown words for NMT, Luong et al. (2015) proposed a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence, and to translate every OOV in a post-processing step using a external bilingual dictionary. Although The remainder of the paper is organized as follows. Section 2 introduces the related work in the NMT. Section 3 presents two novel neural models to learn the CAR for each word. Section 4 integrates the CAR into the NMT by using smoothing strategies. Section 5 reports the experimental results obtained in the Chineseto-Engl"
I17-1002,C04-1089,0,0.0293475,"ion. Second, we also extend the contextaware smoothing method to in-vocabulary words, which enhances encoder and decoder of NMT by more effectively utilizing context information by the learned CAR. To this end, we proposed two unique neural networks to learn the contextaware representation for each word depending on its context words in a fixed-size window. We then design four NMT models with CAR to improve translation performance by smoothing the encoder and decoder. Related Work In traditional SMT, there are many research works to improve the translations of OOVs. Fung and Cheung (2004) and Shao and Ng (2004) adopte comparable corpora and web resources to extract translations for each unknown word. Marton et al. (2009) and Mirkin et al. (2009) applied paraphrase model and entailment rules to replace unknown words with in-vocabulary synonyms before translation. A series of works (Knight and Graehl, 1997; Jiang et al., 2007; Al-Onaizan and Knight, 2002) utilized transliteration and web mining techniques with external monolingual/bilingual corpora, comparable data and the web resource to find the translation of the unknown words. Nearly most of the related PBSMT researches focused on finding the corr"
I17-1002,D09-1040,0,0.0346227,"nd decoder of NMT by more effectively utilizing context information by the learned CAR. To this end, we proposed two unique neural networks to learn the contextaware representation for each word depending on its context words in a fixed-size window. We then design four NMT models with CAR to improve translation performance by smoothing the encoder and decoder. Related Work In traditional SMT, there are many research works to improve the translations of OOVs. Fung and Cheung (2004) and Shao and Ng (2004) adopte comparable corpora and web resources to extract translations for each unknown word. Marton et al. (2009) and Mirkin et al. (2009) applied paraphrase model and entailment rules to replace unknown words with in-vocabulary synonyms before translation. A series of works (Knight and Graehl, 1997; Jiang et al., 2007; Al-Onaizan and Knight, 2002) utilized transliteration and web mining techniques with external monolingual/bilingual corpora, comparable data and the web resource to find the translation of the unknown words. Nearly most of the related PBSMT researches focused on finding the correct translation of the unknown words with external resources and ignored the negative effect for other words. Co"
I17-1002,P16-2021,0,0.0221027,"oved the translation of OOV, they must learn external bilingual dictionary information in advance. From the point of vocabulary size, many works tried to use a large vocabulary size, thus covering more words. Jean et al. (2015) proposed a method based on importance sampling that allowed NMT model to use a very large target vocabulary for relieving the OOV phenomenon in NMT, which are only designed to reduce the computational complexity in training, not for decoding. Arthur et al. (2016) introduced discrete translation lexicons into NMT to imrpove the translations of these low-frequency words. Mi et al. (2016) proposed a vocabulary manipulation approach by limiting the number of vocabulary being predicted by each batch or sentence, to reduce both the training and the decoding complexity. These methods focused on the translation of OOV itself and ignored the other negative effect caused by the OOV, such as the translations of the words around the OOV. 3 Context-Aware Representation Intuitively, when one understands natural language sentence, especially including polysemy words or OOVs, one often inferences the meaning of these words depending on its context words. Context plays an important role in"
L16-1466,P98-1013,0,0.179619,"s corpus is that having a bilingual semantic corpus with refined semantic role information is expected to bring significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropB"
L16-1466,P13-2074,0,0.0152896,"tes the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006) in our treebank to reduce span-crossing, and then t"
L16-1466,W05-0620,0,0.0423719,"Missing"
L16-1466,2007.tmi-papers.10,0,0.0892051,"Missing"
L16-1466,J02-3001,0,0.199086,"are the two most commonly used semantic resources in Semantic Role Labeling (SRL) and SMT tasks. FrameNet is based on a theory of meaning called Frame Semantics (Fillmore, 1982). The basic idea is that the meanings of most words can best be understood on the basis of their semantic frames, which describe the types of events, relations, and the participants involved. In FrameNet, most sentences are selected manually from British National Corpus and then assigned with their associated frames based on the frame semantics theory. FrameNet was first adopted in the SRL task by Gildea and Jurafsky (Gildea and Jurafsky, 2002). However it has not been widely used in SMT tasks. On the other hand, PropBank has been widely used in both SRL and SMT since CoNLL-2005 (Carreras and M`arquez, 2005). It annotates the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Re"
L16-1466,W00-1205,0,0.569462,"information is expected to bring significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropBank are the two most commonly used semantic resources in Semantic Role Labeling"
L16-1466,C10-1081,0,0.123286,"quez, 2005). It annotates the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006) in our treebank to re"
L16-1466,J93-2004,0,0.0536242,"Missing"
L16-1466,W04-2705,0,0.0359129,"ng significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropBank are the two most commonly used semantic resources in Semantic Role Labeling (SRL) and SMT tasks. FrameNet"
L16-1466,J05-1004,0,0.0875404,"gual semantic corpus with refined semantic role information is expected to bring significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropBank are the two most commonly us"
L16-1466,P06-1055,0,0.226841,"Missing"
L16-1466,1995.tmi-1.27,1,0.192568,"Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006) in our treebank to reduce span-crossing, and then transform the DST into its corresponding case tree. Also, we label all the tree nodes of the DST (not only nouns and verbs but also clauses, adjectives, adverbs, interjections, etc.) with our semantic case labels. We tailor the Sinica case set (Huang et al., 2000) to share the same case set in both Chinese and English case trees, an"
L16-1466,2009.eamt-1.30,0,0.0244656,"(Carreras and M`arquez, 2005). It annotates the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006)"
N13-1063,P09-1056,0,0.0156231,"nce it is impossible to obtain sufficient labeled data for all NLP tasks. In these situations semisupervised learning can help to make use of both labeled data and easy-to-obtain unlabeled data. The semi-supervised framework that is widely applied to NLP is to first learn word representations, which are feature vectors of lexical items, from unlabeled data and then plug them into a supervised system. These methods are very effective in utilizing large-scale unlabeled data and have successfully improved performances of state-ofthe-art supervised systems on a variety of tasks (Koo et al., 2008; Huang and Yates, 2009; Täckström et al., 2012). With the development of neural language models (NLM) (Bengio et al., 2003; Mnih and Hinton, 2009), recently researchers become interested in word representations (also called word embeddings) learned by these models. Word embeddings are dense low dimensional real-valued vectors. They are composed of some latent features, which are expected to capture useful syntactic and semantic properties. Word embeddings are usually served as the first layer in deep learning systems for NLP (Collobert and Weston, 2008; Socher et al., 2011a, 2011b) and help these systems perform co"
N13-1063,P08-1068,0,0.500648,"data sparsity, since it is impossible to obtain sufficient labeled data for all NLP tasks. In these situations semisupervised learning can help to make use of both labeled data and easy-to-obtain unlabeled data. The semi-supervised framework that is widely applied to NLP is to first learn word representations, which are feature vectors of lexical items, from unlabeled data and then plug them into a supervised system. These methods are very effective in utilizing large-scale unlabeled data and have successfully improved performances of state-ofthe-art supervised systems on a variety of tasks (Koo et al., 2008; Huang and Yates, 2009; Täckström et al., 2012). With the development of neural language models (NLM) (Bengio et al., 2003; Mnih and Hinton, 2009), recently researchers become interested in word representations (also called word embeddings) learned by these models. Word embeddings are dense low dimensional real-valued vectors. They are composed of some latent features, which are expected to capture useful syntactic and semantic properties. Word embeddings are usually served as the first layer in deep learning systems for NLP (Collobert and Weston, 2008; Socher et al., 2011a, 2011b) and help t"
N13-1063,N12-1052,0,0.0123376,"Missing"
N13-1063,P10-1040,0,0.886975,"s) learned by these models. Word embeddings are dense low dimensional real-valued vectors. They are composed of some latent features, which are expected to capture useful syntactic and semantic properties. Word embeddings are usually served as the first layer in deep learning systems for NLP (Collobert and Weston, 2008; Socher et al., 2011a, 2011b) and help these systems perform comparably with the state-of-the-art models based on handcrafted features. They also have been directly added as features to the state-of-the-art models of chunking and NER, and have achieved significant improvements (Turian et al. 2010). Although the direct usage of continuous embeddings has been proved to be an effective method for enhancing the state-of-the-art supervised models, it has some disadvantages, which made them be out-performed by simpler Brown cluster features (Turian et al, 2010) and made them computationally complicated. Firstly, embeddings of rare words are insufficiently trained since they are only updated few times and are close to their random initial values. As shown in (Turian et al, 2010), this is the main reason that models with embedding features made more errors than those with Brown cluster feature"
N13-1063,D07-1096,0,\N,Missing
N13-1063,D11-1014,0,\N,Missing
N13-1063,P05-1045,0,\N,Missing
N19-1046,D18-1036,0,0.0671355,"Missing"
N19-1046,W18-5451,0,0.0291084,"sistent improvements (up to +1.3 BLEU) compared to the state-of-the-art translation model. 1 apple … cola … dog … wolf … 4 0000 0001 0100 0111 3 000 of … in … 010 001 depth task 1100 1101 rice … cat … 4 run … 011 110 111 3 is … 2 00 01 10 11 2 Structural HR HR 1 x, y?< 0 1 1 root Figure 1: The structural hierarchical regularization framework. On the left is a 4-layer NMT decoder; on the right is a hierarchical clustering tree and the treeinduced relative tasks at every tree depth. to understand the hidden representations through the lens of a few linguistic tasks, while Ding et al. (2017) and Strobelt et al. (2018) propose appealing visualization approaches to understand NMT models including the representation of hidden layers. However, employing the analyses to motivate new methods for better translation, the ultimate goal of understanding NMT, is not achieved in these works. In our paper, we aim at understanding the hidden representation of NMT from an alternative viewpoint, and particularly we propose simple yet effective methods to improve the translation performance based on our understanding. We start from a fundamental question: what are the characteristics of the hidden representation for better"
N19-1046,P18-2104,0,0.0318354,"wledge about part-of-speech and semantic tags at different layers. Unlike those works that employ one or two linguistic tasks, we instead construct plenty of artificial tasks without any human annotations to analyze the hidden representations. This makes our approach more general and may potentially lead to less biased conclusions. Based on our understanding of the hidden representations, we further develop simple methods to improve NMT through representation regularization. Many works regularize NMT with lexical knowledge such as BOW (Weng et al., 2017) and morphology (Niehues and Cho, 2017; Zaremoodi et al., 2018), or syntactic knowledge (Kiperwasser and Ballesteros, 2018; Eriguchi et al., 2017). One significant difference is that we take into account the structure among plenty of artificial tasks and design a well motivated regularization term to encourage the structural consistency of tasks, which further improves NMT performance. In addition, our coarse-to-fine way to select tasks for regularization is also inspired by recent works using a coarse-to-fine mechanism for learning better word embeddings in NMT (Zhang et al., 2018) and predicting intermediate solutions for semantic parsing (Dong and Lapa"
N19-1205,P15-1033,0,0.0276095,"training Ja–En models, and (2) LDC,5 which contains about 1.2M sentence pairs, for training En–Ch and Ch–En models. To tackling the problem of memory consumption, sentences longer than 150 were filtered out, so that models can be trained successfully. Chinese sentences were segmented by the Stanford segmentation tool.6 For Japanese sentences, we followed the preprocessing steps recommended in WAT 2017.7 The test set is a concatenation of NIST MT 2003, 2004, and 2005. Constituent trees are generated by the parser of Kitaev and Klein (2018)8 , and dependency trees are generated by the parser of Dyer et al. (2015)9 . Note that although we only used syntactic information of English in our experiments, our method is also applicable to other languages. We implemented our method on OpenNMT10 (Klein et al., 2017), and used the Transformer as our baseline. As far as we know, there are no previous studies on using syntactic informations in the Transformer. The vocabulary sizes for all languages are 50, 000. Both the encoder and decoder have 6 layers. The dimensions of hidden vectors and word embeddings are 512. The multi-head attention has 5 LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07,"
N19-1205,P16-1078,0,0.0191314,", and +1.0 (Ch–En) BLEU). 1 Introduction In recent years, neural machine translation (NMT) has been developing rapidly and has become the de facto approach for machine translation. To improve the performance of the conventional NMT models (Sutskever et al., 2014; Bahdanau et al., 2014), one effective approach is to incorporate syntactic information into the encoder and/or decoder of the baseline model. Based on how the syntactic information is represented, there are two categories of syntactic NMT methods: (1) those that use treestructured neural networks (NNs) to represent syntax structures (Eriguchi et al., 2016; Hashimoto and Tsuruoka, 2017), and (2) those that use linear-structured NNs to represent linearized syntax structures (Li et al., 2017; Ma et al., 2017, 2018). For the first category, there is a direct corresponding relationship between the syntactic structure and the NN structure, but the complexity of NN structures usually makes training in∗ Corresponding author efficient. In contrast, for the second category, syntactic structures are linearized and represented using linear-structured recurrent neural networks (RNNs), but the linearized sequence can generally be quite long and therefore tr"
N19-1205,D16-1026,0,0.0365324,"Missing"
N19-1205,D18-1162,0,0.0255237,"Missing"
N19-1205,W16-2209,0,0.0925436,"sent a constituent tree as a sequence whose length is identical to the number of words in the sentence (almost) without losing syntactic information. However, there are no previous studies that use NSD in NMT. Moreover, as demonstrated by our experiments, using NSD in NMT is far from straightforward, so we propose five strategies and verify the effects empirically. The strategies are summarized below. • Extend NSD to dependency trees, which is inspired by the dependency language model (Shen et al., 2010). • Use NSDs as input sequences1 , where an NSD is regarded as a linguistic input feature (Sennrich and Haddow, 2016). • Use NSDs as output sequences, where the NMT and prediction of the NSD are simultaneously trained through multi-task learning (Firat et al., 2016). • Use NSD as positional encoding (PE), which is a syntactic extension of the PE of the Transformer (Vaswani et al., 2017). 1 Throughout this paper, ”input” means the input of an encoder or a decoder rather than the input of the NMT model (i.e., only source sentences), and ”output” is similar. • Add a loss function for NSD to achieve distance-aware training (Shen et al., 2018). 2 S S’ VP Neural Syntactic Distance (NSD) VP The NSD was firstly prop"
N19-1205,D17-1012,0,0.0351546,"Missing"
N19-1205,J10-4005,0,0.0369885,"constituent parsing (Shen et al., 2018; G´omez-Rodr´ıguez and Vilares, 2018). NSD makes it possible to represent a constituent tree as a sequence whose length is identical to the number of words in the sentence (almost) without losing syntactic information. However, there are no previous studies that use NSD in NMT. Moreover, as demonstrated by our experiments, using NSD in NMT is far from straightforward, so we propose five strategies and verify the effects empirically. The strategies are summarized below. • Extend NSD to dependency trees, which is inspired by the dependency language model (Shen et al., 2010). • Use NSDs as input sequences1 , where an NSD is regarded as a linguistic input feature (Sennrich and Haddow, 2016). • Use NSDs as output sequences, where the NMT and prediction of the NSD are simultaneously trained through multi-task learning (Firat et al., 2016). • Use NSD as positional encoding (PE), which is a syntactic extension of the PE of the Transformer (Vaswani et al., 2017). 1 Throughout this paper, ”input” means the input of an encoder or a decoder rather than the input of the NMT model (i.e., only source sentences), and ”output” is similar. • Add a loss function for NSD to achie"
N19-1205,P18-1249,0,0.02509,"op 100K sentence pairs for training En–Ja models and top 1M sentence pairs for training Ja–En models, and (2) LDC,5 which contains about 1.2M sentence pairs, for training En–Ch and Ch–En models. To tackling the problem of memory consumption, sentences longer than 150 were filtered out, so that models can be trained successfully. Chinese sentences were segmented by the Stanford segmentation tool.6 For Japanese sentences, we followed the preprocessing steps recommended in WAT 2017.7 The test set is a concatenation of NIST MT 2003, 2004, and 2005. Constituent trees are generated by the parser of Kitaev and Klein (2018)8 , and dependency trees are generated by the parser of Dyer et al. (2015)9 . Note that although we only used syntactic information of English in our experiments, our method is also applicable to other languages. We implemented our method on OpenNMT10 (Klein et al., 2017), and used the Transformer as our baseline. As far as we know, there are no previous studies on using syntactic informations in the Transformer. The vocabulary sizes for all languages are 50, 000. Both the encoder and decoder have 6 layers. The dimensions of hidden vectors and word embeddings are 512. The multi-head attention"
N19-1205,P17-4012,0,0.0361245,"tered out, so that models can be trained successfully. Chinese sentences were segmented by the Stanford segmentation tool.6 For Japanese sentences, we followed the preprocessing steps recommended in WAT 2017.7 The test set is a concatenation of NIST MT 2003, 2004, and 2005. Constituent trees are generated by the parser of Kitaev and Klein (2018)8 , and dependency trees are generated by the parser of Dyer et al. (2015)9 . Note that although we only used syntactic information of English in our experiments, our method is also applicable to other languages. We implemented our method on OpenNMT10 (Klein et al., 2017), and used the Transformer as our baseline. As far as we know, there are no previous studies on using syntactic informations in the Transformer. The vocabulary sizes for all languages are 50, 000. Both the encoder and decoder have 6 layers. The dimensions of hidden vectors and word embeddings are 512. The multi-head attention has 5 LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08, and LDC2005T06. 6 https://nlp.stanford.edu/software/ stanford-segmenter-2017-06-09.zip 7 http://lotus.kuee.kyoto-u.ac.jp/WAT/ WAT2017/baseline/dataPreparationJE.html 8 https://github.com"
N19-1205,P17-1064,0,0.0196163,"acto approach for machine translation. To improve the performance of the conventional NMT models (Sutskever et al., 2014; Bahdanau et al., 2014), one effective approach is to incorporate syntactic information into the encoder and/or decoder of the baseline model. Based on how the syntactic information is represented, there are two categories of syntactic NMT methods: (1) those that use treestructured neural networks (NNs) to represent syntax structures (Eriguchi et al., 2016; Hashimoto and Tsuruoka, 2017), and (2) those that use linear-structured NNs to represent linearized syntax structures (Li et al., 2017; Ma et al., 2017, 2018). For the first category, there is a direct corresponding relationship between the syntactic structure and the NN structure, but the complexity of NN structures usually makes training in∗ Corresponding author efficient. In contrast, for the second category, syntactic structures are linearized and represented using linear-structured recurrent neural networks (RNNs), but the linearized sequence can generally be quite long and therefore training efficiency is still a problem. Although using a shorter sequence may improve the efficiency, some syntactic information is lost."
N19-1205,I17-1003,0,0.0192217,"he depth of the LCA. 4 dS (wn ) and dG (wn ) are undefined in both of the original papers. We give the definitions here to enable the use of NSD in NMT later. NP d d d S G R NP PRP VBZ VBG NN . She enjoys playing tennis . 4 1 1 2 3 2 1 4 1 3 2 -2 5 0 -2 Figure 1: Example of different NSDs. This example is from Shen et al. (2018). # d D She enjoys playing tennis . -1 2 1 1 3 Figure 2: Example of dependency NSDs. “#” is the root. Dependency labels are omitted. 3 Strategies to improve NMT with NSD 3.1 Dependency NSD There are many previous studies on using dependency trees to improve NMT (Nguyen Le et al., 2017; Wu et al., 2017). Therefore, we extend NSD to dependency trees. Formally, the dependency NSD between two nodes is defined as follows: dD (wi ) = i − h(i), (4) where h(i) is the index of the head of wi , and we let the index of root be 0. Note that dD (wi ) can be either positive or negative, representing the directional information. Figure 2 gives an example. 3.2 NSDs as Input Sequences It is easy to see that for w = (w1 , . . . , wn ), the lengths of dS , dG , dR and dD are all n. Denoting the NSD sequence as d = (d1 , . . . , dn ), we can see that di ∈ Z, i ∈ [1, n], so we can obtain a seq"
N19-1205,P02-1040,0,0.103502,"0.1 (Srivastava et al., 2014). The number of training epochs was fixed to 50, and we used the model which performs the best on the development set for testing. As for optimization, we used the Adam optimizer (Kingma and Ba, 2014), with β1 = 0.9, β2 = 0.998, and  = 10−9 . Warmup and decay strategy for learning rate of Vaswani et al. (2017) are also used, with 8, 000 warmup steps. We also used the label smoothing strategy (Szegedy et al., 2016) with ls = 0.1. 4.2 Experimental Results Table 1 compares the effects of the strategies. We evaluate the proposed strategies using characterlevel BLEU (Papineni et al., 2002) for Chinese and Japanese, and case-insensitive BLEU for English. Comparison of different NSDs. The first five rows of Table 1 compare the results of using different NSDs. When NSD was used at the source side (En–Ja/En–Ch), all kinds of NSDs improved translation performance. This indicates that NSD can be regarded as a useful linguistic feature to improve NMT. In contrast, when NSD was used at the target side (Ja–En/Ch–En), dS and dG hurt the performance. This is because the values of dS and dG are volatile. A tiny change of syntactic structure often causes a big change of dS and dG . Since th"
N19-1205,P18-1108,0,0.300875,"or efficient. In contrast, for the second category, syntactic structures are linearized and represented using linear-structured recurrent neural networks (RNNs), but the linearized sequence can generally be quite long and therefore training efficiency is still a problem. Although using a shorter sequence may improve the efficiency, some syntactic information is lost. We propose a method of using syntactic information in NMT that overcomes the disadvantages of both methods. The basis of our method is the neural syntactic distance (NSD), a recently proposed concept used for constituent parsing (Shen et al., 2018; G´omez-Rodr´ıguez and Vilares, 2018). NSD makes it possible to represent a constituent tree as a sequence whose length is identical to the number of words in the sentence (almost) without losing syntactic information. However, there are no previous studies that use NSD in NMT. Moreover, as demonstrated by our experiments, using NSD in NMT is far from straightforward, so we propose five strategies and verify the effects empirically. The strategies are summarized below. • Extend NSD to dependency trees, which is inspired by the dependency language model (Shen et al., 2010). • Use NSDs as input"
N19-1205,P17-1065,0,0.0341685,"CA. 4 dS (wn ) and dG (wn ) are undefined in both of the original papers. We give the definitions here to enable the use of NSD in NMT later. NP d d d S G R NP PRP VBZ VBG NN . She enjoys playing tennis . 4 1 1 2 3 2 1 4 1 3 2 -2 5 0 -2 Figure 1: Example of different NSDs. This example is from Shen et al. (2018). # d D She enjoys playing tennis . -1 2 1 1 3 Figure 2: Example of dependency NSDs. “#” is the root. Dependency labels are omitted. 3 Strategies to improve NMT with NSD 3.1 Dependency NSD There are many previous studies on using dependency trees to improve NMT (Nguyen Le et al., 2017; Wu et al., 2017). Therefore, we extend NSD to dependency trees. Formally, the dependency NSD between two nodes is defined as follows: dD (wi ) = i − h(i), (4) where h(i) is the index of the head of wi , and we let the index of root be 0. Note that dD (wi ) can be either positive or negative, representing the directional information. Figure 2 gives an example. 3.2 NSDs as Input Sequences It is easy to see that for w = (w1 , . . . , wn ), the lengths of dS , dG , dR and dD are all n. Denoting the NSD sequence as d = (d1 , . . . , dn ), we can see that di ∈ Z, i ∈ [1, n], so we can obtain a sequence of embedding"
O01-2004,P91-1022,0,0.082527,"Missing"
O01-2004,P93-1001,0,0.0434082,"Missing"
O01-2004,C94-2119,0,0.0380266,"Missing"
O01-2004,W09-4205,0,0.062288,"Missing"
O01-2004,C92-2101,0,0.061944,"Missing"
O01-2004,C00-1075,0,0.0265163,"Missing"
O01-2004,J93-2004,0,0.0354613,"Missing"
O01-2004,P98-2139,0,0.0592392,"Missing"
O01-2004,1997.tmi-1.13,0,0.107408,"Missing"
O01-2004,C96-1040,0,0.0598061,"Missing"
O01-2004,P98-2212,0,0.0382456,"Missing"
O01-2004,1993.tmi-1.25,0,0.14908,"Missing"
O01-2004,C00-2131,0,0.0446209,"Missing"
O01-2004,P95-1033,0,0.55593,"Missing"
O01-2004,J97-3002,0,0.330471,"Missing"
O01-2004,W00-1211,1,0.841686,"Missing"
O01-2004,W97-0119,0,\N,Missing
O01-2004,J93-2003,0,\N,Missing
O01-2004,1995.tmi-1.28,0,\N,Missing
O01-2004,J97-2004,0,\N,Missing
O01-2004,P00-1050,0,\N,Missing
O01-2004,W95-0106,0,\N,Missing
O06-3001,A97-1052,0,0.113532,"Missing"
O06-3001,W02-0905,0,0.0394985,"Missing"
O06-3001,C04-1104,1,0.888643,"Missing"
O06-3001,P03-1009,0,0.0461139,"Missing"
O06-3001,J93-2004,0,\N,Missing
O06-3001,W04-1107,0,\N,Missing
O06-3001,W96-0213,0,\N,Missing
O06-3001,W00-0729,0,\N,Missing
O06-3001,W02-1808,0,\N,Missing
O06-3001,W01-0706,0,\N,Missing
O06-3001,C00-2100,0,\N,Missing
O06-3001,C04-1030,0,\N,Missing
O06-3001,W00-1201,0,\N,Missing
O06-3001,C86-1155,0,\N,Missing
O06-3001,W03-1025,0,\N,Missing
O06-3001,C94-2178,0,\N,Missing
O06-3001,J96-1002,0,\N,Missing
O06-3001,J93-2002,0,\N,Missing
O06-3001,W00-0726,0,\N,Missing
O06-3001,W00-0731,0,\N,Missing
O06-3001,1995.tmi-1.21,0,\N,Missing
O06-3001,P01-1043,0,\N,Missing
O06-3001,P03-1063,0,\N,Missing
O06-3001,P02-1055,0,\N,Missing
O06-3001,P05-1048,0,\N,Missing
O06-3001,P00-1015,0,\N,Missing
O06-3001,P02-1029,0,\N,Missing
O06-3001,P05-1064,0,\N,Missing
O06-3001,1999.mtsummit-1.37,0,\N,Missing
O06-3001,O02-2002,0,\N,Missing
O06-3001,O05-2006,0,\N,Missing
O06-3001,W00-0730,0,\N,Missing
P06-2043,A97-1052,0,0.107903,"Missing"
P06-2043,C04-1104,1,0.76935,"subcategorized verbal lexicons have proved to be crucially important for many tasks of natural language processing, such as probabilistic parsers (Korhonen, 2001, 2002) and verb classifications (Schulte im Walde, 2002; Korhonen, 2003). Since Brent (1993) a considerable amount of research focusing on large-scaled automatic acquisition of subcategorization frames (SCF) has met with some success not only in English but also in many other languages, including German (Schulte im Walde, 2002), Spanish (Chrupala, 2003), Czech (Sarkar and Zeman, 2000), Portuguese (Gamallo et. al, 2002), and Chinese (Han et al, 2004). The general objective of this research is to acquire from a given corpus the SCF types and numbers for predicate verbs. Two typiXingshang Fu Institute of Computational Linguistics Heilongjiang University Harbin City 150080 China fxs@hlju.edu.cn cal steps during the process of automatic acquisition are hypothesis generation and selection. Usually based on heuristic rules, the first step generates SCF hypotheses for involved verbs; and the second selects reliable ones via statistical methods, such as BHT (binomial hypothesis testing), LLR (log likelihood ratio) and MLE (maximum likelihood esti"
P06-2043,P03-1009,0,0.0156408,"lexicon much more practical for further manual proofreading and other NLP uses. 1 Introduction Subcategorization is the process that further classifies a syntactic category into its subsets. Chomsky (1965) defines the function of strict subcategorization features as appointing a set of constraints that dominate the selection of verbs and other arguments in deep structure. Large subcategorized verbal lexicons have proved to be crucially important for many tasks of natural language processing, such as probabilistic parsers (Korhonen, 2001, 2002) and verb classifications (Schulte im Walde, 2002; Korhonen, 2003). Since Brent (1993) a considerable amount of research focusing on large-scaled automatic acquisition of subcategorization frames (SCF) has met with some success not only in English but also in many other languages, including German (Schulte im Walde, 2002), Spanish (Chrupala, 2003), Czech (Sarkar and Zeman, 2000), Portuguese (Gamallo et. al, 2002), and Chinese (Han et al, 2004). The general objective of this research is to acquire from a given corpus the SCF types and numbers for predicate verbs. Two typiXingshang Fu Institute of Computational Linguistics Heilongjiang University Harbin City 1"
P06-2043,C00-2100,0,0.0233439,"inate the selection of verbs and other arguments in deep structure. Large subcategorized verbal lexicons have proved to be crucially important for many tasks of natural language processing, such as probabilistic parsers (Korhonen, 2001, 2002) and verb classifications (Schulte im Walde, 2002; Korhonen, 2003). Since Brent (1993) a considerable amount of research focusing on large-scaled automatic acquisition of subcategorization frames (SCF) has met with some success not only in English but also in many other languages, including German (Schulte im Walde, 2002), Spanish (Chrupala, 2003), Czech (Sarkar and Zeman, 2000), Portuguese (Gamallo et. al, 2002), and Chinese (Han et al, 2004). The general objective of this research is to acquire from a given corpus the SCF types and numbers for predicate verbs. Two typiXingshang Fu Institute of Computational Linguistics Heilongjiang University Harbin City 150080 China fxs@hlju.edu.cn cal steps during the process of automatic acquisition are hypothesis generation and selection. Usually based on heuristic rules, the first step generates SCF hypotheses for involved verbs; and the second selects reliable ones via statistical methods, such as BHT (binomial hypothesis tes"
P06-2043,J87-3002,0,\N,Missing
P06-2043,W02-0905,0,\N,Missing
P06-2043,J93-2002,0,\N,Missing
P06-2043,P02-1029,0,\N,Missing
P07-1087,P00-1037,0,0.0497676,"nly local information but also global information in a document in case restoration. Spelling error correction can be formalized as a classification problem. Golding and Roth (1996) propose using the Winnow algorithm to address the issue. The problem can also be formalized as that of data conversion using the source channel model. The source model can be built as an n-gram language model and the channel model can be constructed with confusing words measured by edit distance. Brill and Moore, Church and Gale, and Mayes et al. have developed different techniques for confusing words calculation (Brill and Moore, 2000; Church and Gale, 1991; Mays et al., 1991). Sproat et al. (1999) have investigated normalization of non-standard words in texts, including numbers, abbreviations, dates, currency amounts, and acronyms. They propose a taxonomy of nonstandard words and apply n-gram language models, decision trees, and weighted finite-state transducers to the normalization. 3 Text Normalization In this paper we define text normalization at three levels: paragraph, sentence, and word level. The subtasks at each level are listed in Table 1. For example, at the paragraph level, there are two subtasks: extra line-br"
P07-1087,P03-1020,0,0.337923,"ils using two machine-learning based methods: Conditional Random Fields and Perceptron for learning HMMs. See also (Carvalho and Cohen, 2004). Tang et al. (2005) propose a cascaded approach for email data cleaning by employing Support Vector Machines and rules. Their method can detect email headers, signatures, program codes, and extra line breaks in emails. See also (Wong et al., 2007). Palmer and Hearst (1997) propose using a Neural Network model to determine whether a period in a sentence is the ending mark of the sentence, an abbreviation, or both. See also (Mikheev, 2000; Mikheev, 2002). Lita et al. (2003) propose employing a language modeling approach to address the case restoration problem. They define four classes for word casing: all letters in lower case, first letter in uppercase, all letters in upper case, and mixed case, and formalize the problem as assigning class labels to words in natural language texts. Mikheev (2002) proposes using not only local information but also global information in a document in case restoration. Spelling error correction can be formalized as a classification problem. Golding and Roth (1996) propose using the Winnow algorithm to address the issue. The proble"
P07-1087,J02-3002,0,0.0262953,"cognition in emails using two machine-learning based methods: Conditional Random Fields and Perceptron for learning HMMs. See also (Carvalho and Cohen, 2004). Tang et al. (2005) propose a cascaded approach for email data cleaning by employing Support Vector Machines and rules. Their method can detect email headers, signatures, program codes, and extra line breaks in emails. See also (Wong et al., 2007). Palmer and Hearst (1997) propose using a Neural Network model to determine whether a period in a sentence is the ending mark of the sentence, an abbreviation, or both. See also (Mikheev, 2000; Mikheev, 2002). Lita et al. (2003) propose employing a language modeling approach to address the case restoration problem. They define four classes for word casing: all letters in lower case, first letter in uppercase, all letters in upper case, and mixed case, and formalize the problem as assigning class labels to words in natural language texts. Mikheev (2002) proposes using not only local information but also global information in a document in case restoration. Spelling error correction can be formalized as a classification problem. Golding and Roth (1996) propose using the Winnow algorithm to address t"
P07-1087,H05-1056,0,0.0346425,"zation is usually viewed as an engineering issue and is addressed in an ad-hoc manner. Much of the previous work focuses on processing texts in clean form, not texts in informal form. Also, prior work mostly focuses on processing one type or a small number of types of errors, whereas this paper deals with many different types of errors. Clark (2003) has investigated the problem of preprocessing noisy texts for natural language processing. He proposes identifying token boundaries and sentence boundaries, restoring cases of words, and correcting misspelled words by using a source channel model. Minkov et al. (2005) have investigated the problem of named entity recognition in informally in689 putted texts. They propose improving the performance of personal name recognition in emails using two machine-learning based methods: Conditional Random Fields and Perceptron for learning HMMs. See also (Carvalho and Cohen, 2004). Tang et al. (2005) propose a cascaded approach for email data cleaning by employing Support Vector Machines and rules. Their method can detect email headers, signatures, program codes, and extra line breaks in emails. See also (Wong et al., 2007). Palmer and Hearst (1997) propose using a N"
P07-1087,J97-2002,0,\N,Missing
P09-2032,J07-2003,0,0.332352,"ferent grammars, we describes a synthetic synchronous grammar (SSG), which tentatively in this paper, integrates a synchronous context-free grammar (SCFG) and a synchronous tree sequence substitution grammar (STSSG) for statistical machine translation. The experimental results on NIST MT05 Chinese-to-English test set show that the SSG based translation system achieves significant improvement over three baseline systems. 1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007; Zhang et al., 2008). The grammar formalism determines the intrinsic capacities and computational efficiency of the SMT systems. To evaluate the capacity of a grammar formalism, two factors, i.e. generative power and expressive power are usually considered (Su and Chang, 1990). The generative power refers to the ability to generate the strings of the language, and the expressive power to the ability to describe the same language with fewer or no extra ambiguities. For the current synchronous grammars based SMT, to some extent, the generalization ability of the grammar rules (the usability of"
P09-2032,P06-1121,0,0.0292268,"the strengths of different grammars, we describes a synthetic synchronous grammar (SSG), which tentatively in this paper, integrates a synchronous context-free grammar (SCFG) and a synchronous tree sequence substitution grammar (STSSG) for statistical machine translation. The experimental results on NIST MT05 Chinese-to-English test set show that the SSG based translation system achieves significant improvement over three baseline systems. 1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007; Zhang et al., 2008). The grammar formalism determines the intrinsic capacities and computational efficiency of the SMT systems. To evaluate the capacity of a grammar formalism, two factors, i.e. generative power and expressive power are usually considered (Su and Chang, 1990). The generative power refers to the ability to generate the strings of the language, and the expressive power to the ability to describe the same language with fewer or no extra ambiguities. For the current synchronous grammars based SMT, to some extent, the generalization ability of the grammar rules (the"
P09-2032,N04-1022,0,0.0960631,"Missing"
P09-2032,P06-1077,0,0.0708956,"Missing"
P09-2032,J97-3002,0,0.0230068,"ted. Aiming at combining the strengths of different grammars, we describes a synthetic synchronous grammar (SSG), which tentatively in this paper, integrates a synchronous context-free grammar (SCFG) and a synchronous tree sequence substitution grammar (STSSG) for statistical machine translation. The experimental results on NIST MT05 Chinese-to-English test set show that the SSG based translation system achieves significant improvement over three baseline systems. 1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007; Zhang et al., 2008). The grammar formalism determines the intrinsic capacities and computational efficiency of the SMT systems. To evaluate the capacity of a grammar formalism, two factors, i.e. generative power and expressive power are usually considered (Su and Chang, 1990). The generative power refers to the ability to generate the strings of the language, and the expressive power to the ability to describe the same language with fewer or no extra ambiguities. For the current synchronous grammars based SMT, to some extent, the generalizatio"
P09-2032,zhang-etal-2004-interpreting,0,0.079825,"Missing"
P09-2032,P08-1064,1,0.919665,"s, we describes a synthetic synchronous grammar (SSG), which tentatively in this paper, integrates a synchronous context-free grammar (SCFG) and a synchronous tree sequence substitution grammar (STSSG) for statistical machine translation. The experimental results on NIST MT05 Chinese-to-English test set show that the SSG based translation system achieves significant improvement over three baseline systems. 1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007; Zhang et al., 2008). The grammar formalism determines the intrinsic capacities and computational efficiency of the SMT systems. To evaluate the capacity of a grammar formalism, two factors, i.e. generative power and expressive power are usually considered (Su and Chang, 1990). The generative power refers to the ability to generate the strings of the language, and the expressive power to the ability to describe the same language with fewer or no extra ambiguities. For the current synchronous grammars based SMT, to some extent, the generalization ability of the grammar rules (the usability of the rules for the new"
P09-2032,P03-2041,0,\N,Missing
P09-2054,I05-3009,0,0.374292,"Missing"
P09-2054,C08-1130,1,0.621394,"Missing"
P10-2002,C08-1041,0,0.496023,"selection for hypothesis generation, including both source-side rule selection and targetside rule selection where the source-side rule determines what part of source words to be translated and the target-side rule provides one of the candidate translations of the source-side rule. Improper rule selections may result in poor translations. There is some related work about the hierarchical rule selection. In the original work (Chiang, 2005), the target-side rule selection is analogous to the model in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more rich contexts to guide the source-side rule selection. (Marton and Resnik, 2008; Xiong et al., 2009) explore the source syntactic information to reward exact matching structu"
P10-2002,N03-1017,0,0.0859175,"ngzhou}@microsoft.com Abstract proper rule selection for hypothesis generation, including both source-side rule selection and targetside rule selection where the source-side rule determines what part of source words to be translated and the target-side rule provides one of the candidate translations of the source-side rule. Improper rule selections may result in poor translations. There is some related work about the hierarchical rule selection. In the original work (Chiang, 2005), the target-side rule selection is analogous to the model in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more rich contexts to guide the source-side rule selection. (Marton and Resnik, 2008; Xiong et al., 2009) explore the source syntactic infor"
P10-2002,D08-1010,0,0.286273,"othesis generation, including both source-side rule selection and targetside rule selection where the source-side rule determines what part of source words to be translated and the target-side rule provides one of the candidate translations of the source-side rule. Improper rule selections may result in poor translations. There is some related work about the hierarchical rule selection. In the original work (Chiang, 2005), the target-side rule selection is analogous to the model in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more rich contexts to guide the source-side rule selection. (Marton and Resnik, 2008; Xiong et al., 2009) explore the source syntactic information to reward exact matching structure rules or punish"
P10-2002,P07-1089,0,0.0312973,"Missing"
P10-2002,P06-1077,0,0.112862,"ctical SMT systems with the log-linear model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics vious methods. Our proposed joint probability model"
P10-2002,W06-1606,0,0.0274999,"with the log-linear model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics vious methods. Our proposed joint probability model is factored into fou"
P10-2002,P08-1114,0,0.322519,"del in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more rich contexts to guide the source-side rule selection. (Marton and Resnik, 2008; Xiong et al., 2009) explore the source syntactic information to reward exact matching structure rules or punish crossing structure rules. All the previous work mainly focused on either source-side rule selection task or target-side rule selection task rather than both of them together. The separation of these two tasks, however, weakens the high interrelation between them. In this paper, we propose to integrate both source-side and target-side rule selection in a unified model. The intuition is that the joint selection of source-side and target-side rules is more reliable as it conducts the"
P10-2002,P08-1023,0,0.023425,"model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics vious methods. Our proposed joint probability model is factored into four sub-models that"
P10-2002,P02-1040,0,0.0820023,"e instances for both CBSM and CBTM is 4.68M, while the training size of constructed negative instances is 3.74M and 3.03M respectively. Following (Setiawan et al., 2009), we identify function words as the 128 most frequent words in the corpus. The interpolation weights are set to θ = 0.75 and ϕ = 0.70. The 5-gram language model is trained over the English portion of FBIS corpus plus Xinhua portion of the Gigaword corpus. The development data is from NIST 2005 evaluation data and the test data is from NIST 2006 and NIST 2008 evaluation data. The evaluation metric is the case-insensitive BLEU4 (Papineni et al., 2002). Statistical significance in BLEU score differences is tested by paired bootstrap re-sampling (Koehn, 2004). 4.2 NIST 2006 0.3025 0.3061 0.3089 0.3141 As shown in Table 1, all the methods outperform the baseline because they have extra models to guide the hierarchical rule selection in some ways which might lead to better translation. Apparently, our method also performs better than the other two approaches, indicating that our method is more effective in the hierarchical rule selection as both source-side and target-side rules are selected together. 4.3 Effect of sub-models Due to the space"
P10-2002,N07-1051,0,0.0342946,"d 5. Length features, which are the length of sub-phrases covered by source nonterminals. 4 4.1 Experiments NIST 2008 0.2200 0.2254 0.2253 0.2318 Table 1: Comparison results, our method is significantly better than the baseline, as well as the other two approaches (p < 0.01) Experiment setting We implement a hierarchical phrase-based system similar to the Hiero (Chiang, 2005) and evaluate our method on the Chinese-to-English translation task. Our bilingual training data comes from FBIS corpus, which consists of around 160K sentence pairs where the source data is parsed by the Berkeley parser (Petrov and Klein, 2007). The ME training toolkit, developed by (Zhang, 2006), is used to train our CBSM and CBTM. The training size of constructed positive instances for both CBSM and CBTM is 4.68M, while the training size of constructed negative instances is 3.74M and 3.03M respectively. Following (Setiawan et al., 2009), we identify function words as the 128 most frequent words in the corpus. The interpolation weights are set to θ = 0.75 and ϕ = 0.70. The 5-gram language model is trained over the English portion of FBIS corpus plus Xinhua portion of the Gigaword corpus. The development data is from NIST 2005 evalu"
P10-2002,J96-1002,0,0.0681035,"e the system performance significantly. 2 the monolingual source side of the training corpus. CFSM is used to capture how likely the sourceside rule is linguistically motivated or has the corresponding target-side counterpart. For CBSM, it can be naturally viewed as a classification problem where each distinct source-side rule is a single class. However, considering the huge number of classes may cause serious data sparseness problem and thereby degrade the classification accuracy, we approximate CBSM by a binary classification problem which can be solved by the maximum entropy (ME) approach (Berger et al., 1996) as follows: Ps (α|C) ≈ Ps (υ|α, C) P exp[ i λi hi (υ, α, C)] P =P 0 υ 0 exp[ i λi hi (υ , α, C)] Hierarchical Rule Selection Model Following (Chiang, 2005), hα, γi is used to represent a synchronous context free grammar (SCFG) rule extracted from the training corpus, where α and γ are the source-side and target-side rule respectively. Let C be the context of hα, γi. Formally, our joint probability model of hierarchical rule selection is described as follows: P (α, γ|C) = P (α|C)P (γ|α, C) where υ ∈ {0, 1} is the indicator whether the source-side rule is applied during decoding, υ = 1 when the"
P10-2002,P05-1034,0,0.0418459,"d can be easily incorporated into the practical SMT systems with the log-linear model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics vious methods"
P10-2002,P05-1033,0,0.339463,"stitute of Technology, Harbin, China {cuilei,tjzhao}@mtlab.hit.edu.cn ‡ Microsoft Research Asia, Beijing, China {dozhang,muli,mingzhou}@microsoft.com Abstract proper rule selection for hypothesis generation, including both source-side rule selection and targetside rule selection where the source-side rule determines what part of source words to be translated and the target-side rule provides one of the candidate translations of the source-side rule. Improper rule selections may result in poor translations. There is some related work about the hierarchical rule selection. In the original work (Chiang, 2005), the target-side rule selection is analogous to the model in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more r"
P10-2002,N09-1025,0,0.0381803,"ilingual training corpus, among which we assume hrs , rti i is extracted from the sentence pair hs, ti. Then, we construct hυ = 1, C(rs ), C(rti )i 3.2 Context-based features for ME training ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM. These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work (He et al., 2008; Gimpel and Smith, 2008; Marton and Resnik, 2008; Chiang et al., 2009; Setiawan et al., 2009; Shen et al., 2009; Xiong et al., 2009): 1. Function word features, which indicate whether the hierarchical source-side/targetside rule strings and sub-phrases covered by non-terminals contain function words that are often important clues of predicting syntactic structures. 1 Because the aligned target words are not contiguous and ”cooperation” is aligned to the word outside the source-side rule. 8 2. POS features, which are POS tags of the boundary source words covered by nonterminals. We compare our method with the baseline and some typical approaches listed in Table"
P10-2002,P08-1066,0,0.0351936,"The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics vious methods. Our proposed joint probability model is factored into four sub-models that can be further clas"
P10-2002,P06-1121,0,0.115919,"rporated into the practical SMT systems with the log-linear model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics vious methods. Our proposed joint"
P10-2002,D09-1008,0,0.0917229,"ume hrs , rti i is extracted from the sentence pair hs, ti. Then, we construct hυ = 1, C(rs ), C(rti )i 3.2 Context-based features for ME training ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM. These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work (He et al., 2008; Gimpel and Smith, 2008; Marton and Resnik, 2008; Chiang et al., 2009; Setiawan et al., 2009; Shen et al., 2009; Xiong et al., 2009): 1. Function word features, which indicate whether the hierarchical source-side/targetside rule strings and sub-phrases covered by non-terminals contain function words that are often important clues of predicting syntactic structures. 1 Because the aligned target words are not contiguous and ”cooperation” is aligned to the word outside the source-side rule. 8 2. POS features, which are POS tags of the boundary source words covered by nonterminals. We compare our method with the baseline and some typical approaches listed in Table 1 where XP+ denotes the approach in (Marto"
P10-2002,W08-0302,0,0.0163984,"ed from multiple distinct sentence pairs in the bilingual training corpus, among which we assume hrs , rti i is extracted from the sentence pair hs, ti. Then, we construct hυ = 1, C(rs ), C(rti )i 3.2 Context-based features for ME training ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM. These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work (He et al., 2008; Gimpel and Smith, 2008; Marton and Resnik, 2008; Chiang et al., 2009; Setiawan et al., 2009; Shen et al., 2009; Xiong et al., 2009): 1. Function word features, which indicate whether the hierarchical source-side/targetside rule strings and sub-phrases covered by non-terminals contain function words that are often important clues of predicting syntactic structures. 1 Because the aligned target words are not contiguous and ”cooperation” is aligned to the word outside the source-side rule. 8 2. POS features, which are POS tags of the boundary source words covered by nonterminals. We compare our method with the baselin"
P10-2002,P09-1037,0,0.121053,"didate translations of the source-side rule. Improper rule selections may result in poor translations. There is some related work about the hierarchical rule selection. In the original work (Chiang, 2005), the target-side rule selection is analogous to the model in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more rich contexts to guide the source-side rule selection. (Marton and Resnik, 2008; Xiong et al., 2009) explore the source syntactic information to reward exact matching structure rules or punish crossing structure rules. All the previous work mainly focused on either source-side rule selection task or target-side rule selection task rather than both of them together. The separation of these two tasks, however, weakens"
P10-2002,J97-3002,0,0.020514,"edicting syntactic structures. 1 Because the aligned target words are not contiguous and ”cooperation” is aligned to the word outside the source-side rule. 8 2. POS features, which are POS tags of the boundary source words covered by nonterminals. We compare our method with the baseline and some typical approaches listed in Table 1 where XP+ denotes the approach in (Marton and Resnik, 2008) and TOFW (topological ordering of function words) stands for the method in (Setiawan et al., 2009). As (Xiong et al., 2009)’s work is based on phrasal SMT system with bracketing transduction grammar rules (Wu, 1997) and (Shen et al., 2009)’s work is based on the string-to-dependency SMT model, we do not implement these two related work due to their different models from ours. We also do not compare with (He et al., 2008)’s work due to its less practicability of integrating numerous sub-models. 3. Syntactic features, which are the constituent constraints of hierarchical source-side rules exactly matching or crossing syntactic subtrees. 4. Rule format features, which are nonterminal positions and orders in sourceside/target-side rules. This feature interacts between source and target components since it sh"
P10-2002,P06-1066,0,0.0365012,"e selection of hierarchical rules. The proposed model is estimated based on four sub-models where the rich context knowledge from both source and target sides is leveraged. Our method can be easily incorporated into the practical SMT systems with the log-linear model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research A"
P10-2002,P09-1036,0,0.177282,"-based SMT system such as Pharaoh (Koehn et al., 2003). Extending this work, (He et al., 2008; Liu et al., 2008) integrate rich context information of non-terminals to predict the target-side rule selection. Different from the above work where the probability distribution of source-side rule selection is uniform, (Setiawan et al., 2009) proposes to select sourceside rules based on the captured function words which often play an important role in word reordering. There is also some work considering to involve more rich contexts to guide the source-side rule selection. (Marton and Resnik, 2008; Xiong et al., 2009) explore the source syntactic information to reward exact matching structure rules or punish crossing structure rules. All the previous work mainly focused on either source-side rule selection task or target-side rule selection task rather than both of them together. The separation of these two tasks, however, weakens the high interrelation between them. In this paper, we propose to integrate both source-side and target-side rule selection in a unified model. The intuition is that the joint selection of source-side and target-side rules is more reliable as it conducts the search in a larger sp"
P10-2002,P01-1067,0,0.112783,"s is leveraged. Our method can be easily incorporated into the practical SMT systems with the log-linear model framework. The experimental results show that our method can yield significant improvements in performance. 1 Introduction Hierarchical phrase-based model has strong expression capabilities of translation knowledge. It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008). In hierarchical phrase-based SMT systems, due to the flexibility of rule matching, a huge number of hierarchical rules could be automatically learnt from bilingual training corpus (Chiang, 2005). SMT decoders are forced to face the challenge of ∗ This work was finished while the first author visited Microsoft Research Asia as an intern. 6 Proceedings of the ACL 2010 Conference Short Papers, pages 6–11, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Lingu"
P10-2002,W04-3250,0,\N,Missing
P11-1016,H05-1045,0,0.0392263,"Missing"
P11-1016,C10-2028,0,0.835958,"Missing"
P11-1016,W06-0301,0,0.119207,"Missing"
P11-1016,H05-1066,0,0.0223227,"Missing"
P11-1016,P04-1035,0,0.0542744,"sentiments of tweets using SVM classifiers with abstract features. The training data is collected from the outputs of three existing Twitter sentiment classification web sites. As mentioned above, these approaches work in a target-independent way, and so need to be adapted for target-dependent sentiment classification. 3 Approach Overview The problem we address in this paper is targetdependent sentiment classification of tweets. So the input of our task is a collection of tweets containing the target and the output is labels assigned to each of the tweets. Inspired by (Barbosa and Feng, 2010; Pang and Lee, 2004), we design a three-step approach in this paper: 1. Subjectivity classification as the first step to decide if the tweet is subjective or neutral about the target; 2. Polarity classification as the second step to decide if the tweet is positive or negative about the target if it is classified as subjective in Step 1; 3. Graph-based optimization as the third step to further boost the performance by taking the related tweets into consideration. In each of the first two steps, a binary SVM classifier is built to perform the classification. To train the classifiers, we use SVM-Light 6 with a linea"
P11-1016,W02-1011,0,0.0397246,"timent target as a query, and search for tweets containing positive or negative sentiments towards the target. The problem needing to be addressed can be formally named as Target-dependent Sentiment Classification of Tweets; namely, given a query, classifying the sentiments of the tweets as positive, negative or neutral according to whether they contain positive, negative or neutral sentiments about that query. Here the query serves as the target of the sentiments. The state-of-the-art approaches for solving this problem, such as (Go et al., 2009 5 ; Barbosa and Feng, 2010), basically follow (Pang et al., 2002), who utilize machine learning based classifiers for the sentiment classification of texts. However, their classifiers actually work in a target-independent way: all the features used in the classifiers are independent of the target, so the sentiment is decided no matter what the target is. Since (Pang et al., 2002) (or later research on sentiment classification Abstract Sentiment analysis on Twitter data has attracted much attention recently. In this paper, we focus on target-dependent Twitter sentiment classification; namely, given a query, we classify the sentiments of the tweets as positiv"
P11-1016,J01-4004,0,0.0118864,"ependent sentiment classification. In addition to the noun phrases including the target, we further expand the extended target set with the following three methods: 1. Adding mentions co-referring to the target as new extended targets. It is common that people use definite or demonstrative noun phrases or pronouns referring to the target in a tweet and express sentiments directly on them. For instance, in “Oh, Jon Stewart. How I love you so.”, the author expresses a positive sentiment to “you” which actually refers to “Jon Stewart”. By using a simple co-reference resolution tool adapted from (Soon et al., 2001), we add all the mentions referring to the target into the extended target set. 2. Identifying the top K nouns and noun phrases which have the strongest association with the target. Here, we use Pointwise Mutual Information (PMI) to measure the association. PMI ( w, t )  log   Target-dependent Features Target-dependent sentiment classification needs to distinguish the expressions describing the target from other expressions. In this paper, we rely on the syntactic parse tree to satisfy this need. Specifically, for any word stem wi in a tweet which has one of the following relations with the"
P11-1016,P02-1053,0,0.026769,"e Lakers, we can confidently classify this tweet as positive. The remainder of this paper is structured as follows. In Section 2, we briefly summarize related work. Section 3 gives an overview of our approach. We explain the target-dependent and contextaware approaches in detail in Sections 4 and 5 respectively. Experimental results are reported in Section 6 and Section 7 concludes our work. 2 Related Work In recent years, sentiment analysis (SA) has become a hot topic in the NLP research community. A lot of papers have been published on this topic. 2.1 2.3 Target-independent SA Specifically, Turney (2002) proposes an unsupervised method for classifying product or movie reviews as positive or negative. In this method, sentimental phrases are first selected from the reviews according to predefined part-of-speech patterns. Then the semantic orientation score of each phrase is calculated according to the mutual information values between the phrase and two predefined seed words. Finally, a review is classified based on the average semantic orientation of the sentimental phrases in the review. In contrast, (Pang et al., 2002) treat the sentiment classification of movie reviews simply as a special c"
P11-1016,H05-1044,0,0.209257,"Missing"
P11-1016,D12-1110,0,\N,Missing
P11-1016,J11-2001,0,\N,Missing
P11-1016,P03-1054,0,\N,Missing
P11-1016,C10-2005,0,\N,Missing
P11-1016,N10-1120,0,\N,Missing
P11-1016,P11-2008,0,\N,Missing
P11-1016,P97-1023,0,\N,Missing
P13-1078,1997.tmi-1.19,0,0.396779,"Missing"
P13-1078,D08-1024,0,0.0472501,"runing method as the log-linear model. 4 Algorithm 1 Mini-batch conjugate subgradient Input: θ1 , T , CGIter, batch-size, k-best-list 1: for all t such that 1 ≤ t ≤ T do 2: Sample mini-batch preference pairs with size batch-size from k-best-list 3: Calculate some quantities for CG, e.g. training objective Obj, subgradient ∆, according to Eq. (6) defined over the sampled preference pairs 4: θt+1 = CG(θt , Obj, ∆, CGIter) 5: end for Output: θT +1 Training Method 4.1 Training Objective For the log-linear model, there are various tuning methods, e.g. MERT (Och, 2003), MIRA (Watanabe et al., 2007; Chiang et al., 2008), PRO (Hopkins and May, 2011) and so on, which iteratively optimize a weight such that, after re-ranking a k-best list of a given development set with this weight, the loss of the resulting 1-best list is minimal. In the extreme, if the k-best list consists only of a pair of translations hhe∗ , d∗ i, he0 , d0 ii, the desirable weight should satisfy the assertion: if the BLEU score of e∗ is greater than that of e0 , then the model score of he∗ , d∗ i with this weight will be also greater than that of he0 , d0 i. In this paper, a pair he∗ , e0 i for a source sentence f is called as a preference"
P13-1078,P05-1033,0,0.522224,"ng; we also propose pre-training and post-training methods to avoid poor local minima. The biggest contribution of this paper is that it goes beyond the log-linear model and proposes a non-linear translation model instead of re-ranking model (Duh and Kirchhoff, 2008; Sokolov et al., 2012). On both Chinese-to-English and Japanese-toEnglish translation tasks, experiment results show that our model can leverage the shortcomings suffered by the log-linear model, and thus achieves significant improvements over the log-linear based translation. 2 a collection of synchronous rules for Hiero grammar (Chiang, 2005), or phrase pairs in Moses (Koehn et al., 2007); h(f, e, d) = (h1 (f, e, d), h2 (f, e, d), · · · , hK (f, e, d))> is a K-dimensional feature vector defined on the tuple hf, e, di; W = (w1 , w2 , · · · , wK )> is a Kdimensional weight vector of h, i.e., the parameters of the model, and it can be tuned by the toolkit MERT (Och, 2003). Different from Brown’s generative model (Brown et al., 1993), the loglinear model does not assume strong independency holds, and allows arbitrary features to be integrated into the model easily. In other words, it can transform complex language translation into fea"
P13-1078,J07-2003,0,0.830393,", e.g. the decoding efficiency, into account in SMT. Decoding in SMT is considered as the expansion of translation states and it is handled by a heuristic search (Koehn, 2004a). In the search procedure, frequent computation of the model score is needed for the search heuristic function, which will be challenged by the decoding efficiency for the neural network based translation model. Further, decoding with non-local (or state-dependent) features, such as a language model, is also a problem. Actually, even for the (log-) linear model, efficient decoding with the language model is not trivial (Chiang, 2007). In this paper, we propose a variant of neural networks, i.e. additive neural networks (see Section 3 for details), for SMT. It consists of two components: a linear component which captures nonlocal (or state dependent) features and a non-linear component (i.e., neural nework) which encodes loMost statistical machine translation (SMT) systems are modeled using a loglinear framework. Although the log-linear model achieves success in SMT, it still suffers from some limitations: (1) the features are required to be linear with respect to the model itself; (2) features cannot be further interprete"
P13-1078,P11-2031,0,0.0314142,") as 10 and 30, and M axIter as 16 and 20 in Algorithm 2, for Chinese-to-English and Japanese-to-English tasks, respectively. Although there are several parameters in AdNN which may limit its practicability, according to many of our internal studies, most parameters are insensitive to AdNN except λ and M axIter, which are common in other tuning toolkits such as MIRA and can be tuned5 on a development test dataset. Since both MERT and PRO tuning toolkits involve randomness in their implementations, all BLEU scores reported in the experiments are the average of five tuning runs, as suggested by Clark et al. (2011) for fairer comparisons. For AdNN, we report the averaged scores of five post-training runs, but both pre-training and training are performed only once. 5.2 NIST08 17.42+ 18.33+ 18.20+ 19.42 test4 23.68+ 23.66+ 24.03+ 24.45 Table 2: The BLEU comparisons between AdNNHiero-E and Log-linear translation models on the Chinese-to-English and Japanese-to-English tasks. + means the comparison is significant over AdNN-Hiero-E with p &lt; 0.05. these features are not dependent on the translation states, they are computed and saved to memory when loading the translation model. During decoding, we just look"
P13-1078,W09-0438,0,0.0124299,"computational times for the features in  the hidden units, i.e. σ M · h0 (r) + B . Since 5 For easier tuning, we tuned these two parameters on a given development test set without post-training in Algorithm 2. 797 Chinese-to-English NIST05 NIST06 L-Hiero 25.57+ 25.27+ 25.93 AdNN-Hiero-E 26.37 AdNN-Hiero-D 26.21 26.07 Japanese-to-English test2 test3 L-Hiero 24.38 25.55 AdNN-Hiero-E 25.14+ 26.32+ AdNN-Hiero-D 24.42 25.46 model (Bengio et al., 2003); POS, Chunking, NER, and SRL (Collobert and Weston, 2008); Parsing (Collobert and Weston, 2008; Socher et al., 2011); and Machine transliteration (Deselaers et al., 2009). Our work is, of course, highly motivated by these works. Unlike these works, we propose a variant neural network, i.e. additive neural networks, starting from SMT itself and taking both of the model definition and its inference (decoding) together into account. Our variant of neural network, AdNN, is highly related to both additive models (Buja et al., 1989) and generalized additive neural networks (Potts, 1999; Waal and Toit, 2007), in which an additive term is either a linear model or a neural network. Unlike additive models and generalized additive neural networks, our model is decomposab"
P13-1078,P08-2010,0,0.66897,", Taro Watanabe2 , Eiichiro Sumita2 , Tiejun Zhao1 1 School of Computer Science and Technology Harbin Institute of Technology (HIT), Harbin, China 2 National Institute of Information and Communication Technology (NICT) 3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan {lmliu |tjzhao}@mtlab.hit.edu.cn {taro.watanabe |eiichiro.sumita}@nict.go.jp Abstract On the one hand, features are required to be linear with respect to the objective of the translation model (Nguyen et al., 2007), but it is not guaranteed that the potential features be linear with the model. This induces modeling inadequacy (Duh and Kirchhoff, 2008), in which the translation performance may not improve, or may even decrease, after one integrates additional features into the model. On the other hand, it cannot deeply interpret its surface features, and thus can not efficiently develop the potential of these features. What may happen is that a feature p does initially not improve the translation performance, but after a nonlinear operation, e.g. log(p), it does. The reason is not because this feature is useless but the model does not efficiently interpret and represent it. Situations such as this confuse explanations for feature designing,"
P13-1078,D11-1125,0,0.0808631,"near model. 4 Algorithm 1 Mini-batch conjugate subgradient Input: θ1 , T , CGIter, batch-size, k-best-list 1: for all t such that 1 ≤ t ≤ T do 2: Sample mini-batch preference pairs with size batch-size from k-best-list 3: Calculate some quantities for CG, e.g. training objective Obj, subgradient ∆, according to Eq. (6) defined over the sampled preference pairs 4: θt+1 = CG(θt , Obj, ∆, CGIter) 5: end for Output: θT +1 Training Method 4.1 Training Objective For the log-linear model, there are various tuning methods, e.g. MERT (Och, 2003), MIRA (Watanabe et al., 2007; Chiang et al., 2008), PRO (Hopkins and May, 2011) and so on, which iteratively optimize a weight such that, after re-ranking a k-best list of a given development set with this weight, the loss of the resulting 1-best list is minimal. In the extreme, if the k-best list consists only of a pair of translations hhe∗ , d∗ i, he0 , d0 ii, the desirable weight should satisfy the assertion: if the BLEU score of e∗ is greater than that of e0 , then the model score of he∗ , d∗ i with this weight will be also greater than that of he0 , d0 i. In this paper, a pair he∗ , e0 i for a source sentence f is called as a preference pair for f . Following PRO, w"
P13-1078,P02-1040,0,0.103298,"ts are called test1, test2, test3 and test4, respectively. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. Using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing, we train a 4-gram language model for the Chinese-toEnglish task on the Xinhua portion of the English Gigaword corpus and a 4-gram language model for the Japanese-to-English task on the target side of its training data. In our experiments, the translation performances are measured by case-sensitive BLEU4 metric4 (Papineni et al., 2002). The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004b). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) for our baseline system, which shares the similar setting as Hiero (Chiang, 2005), e.g. beam-size=100, kbest-size=100, and is denoted as L-Hiero to emphasize its log-linear model. We tune L-Hiero with two methods MERT and PRO implemented in the Moses toolkit. On the same experiment settings, the performance of L-Hiero is comparable Training Algorithm Algorithm 2 Training Algorithm Input: M axIter, a dev set, parameters (e.g. λ"
P13-1078,N03-1017,0,0.050145,"(news domain) with about 240k sentence pairs; the development set is the NIST02 evaluation data; the development test set is NIST05; and the test datasets are NIST06, and NIST08. For the Japanese-to-English task, the training data with 300k sentence pairs is from the NTCIR-patent task (Fujii et al., 2010); the development set, development test set, and two test sets are averagely extracted from a given development set with 4000 sentences, and these four datasets are called test1, test2, test3 and test4, respectively. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. Using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing, we train a 4-gram language model for the Chinese-toEnglish task on the Xinhua portion of the English Gigaword corpus and a 4-gram language model for the Japanese-to-English task on the target side of its training data. In our experiments, the translation performances are measured by case-sensitive BLEU4 metric4 (Papineni et al., 2002). The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004b). We use an in-house developed hierarchical phr"
P13-1078,P07-2045,0,0.00938653,"-training methods to avoid poor local minima. The biggest contribution of this paper is that it goes beyond the log-linear model and proposes a non-linear translation model instead of re-ranking model (Duh and Kirchhoff, 2008; Sokolov et al., 2012). On both Chinese-to-English and Japanese-toEnglish translation tasks, experiment results show that our model can leverage the shortcomings suffered by the log-linear model, and thus achieves significant improvements over the log-linear based translation. 2 a collection of synchronous rules for Hiero grammar (Chiang, 2005), or phrase pairs in Moses (Koehn et al., 2007); h(f, e, d) = (h1 (f, e, d), h2 (f, e, d), · · · , hK (f, e, d))> is a K-dimensional feature vector defined on the tuple hf, e, di; W = (w1 , w2 , · · · , wK )> is a Kdimensional weight vector of h, i.e., the parameters of the model, and it can be tuned by the toolkit MERT (Och, 2003). Different from Brown’s generative model (Brown et al., 1993), the loglinear model does not assume strong independency holds, and allows arbitrary features to be integrated into the model easily. In other words, it can transform complex language translation into feature engineering: it can achieve high translati"
P13-1078,C12-2104,0,0.00594537,"model or a neural network. Unlike additive models and generalized additive neural networks, our model is decomposable with respect to translation rules rather than its component variables considering the decoding efficiency of machine translation; and it allows its additive terms of neural networks to share the same parameters for a compact structure to avoid sparsity. The idea of the neural network in machine translation has already been pioneered in previous works. Casta˜no et al. (1997) introduced a neural network for example-based machine translation. In particular, Son et al. (2012) and Schwenk (2012) employed a neural network to model the phrase translation probability on the rule level hα, γi instead of the bilingual sentence level hf, ei as in Eq. (5), and thus they did not go beyond the log-linear model for SMT. There are also works which exploit non-linear models in SMT. Duh and Kirchhoff (2008) proposed a boosting re-ranking algorithm using MERT as a week learner to improve the model’s expressive abilities; Sokolov et al. (2012) similarly proposed a boosting re-ranking method from the ranking perspective rather than the classification perspective. Instead of considering the reranking"
P13-1078,koen-2004-pharaoh,0,0.192436,"fter a nonlinear operation, e.g. log(p), it does. The reason is not because this feature is useless but the model does not efficiently interpret and represent it. Situations such as this confuse explanations for feature designing, since it is unclear whether such a feature contributes to a translation or not. A neural network (Bishop, 1995) is a reasonable method to overcome the above shortcomings. However, it should take constraints, e.g. the decoding efficiency, into account in SMT. Decoding in SMT is considered as the expansion of translation states and it is handled by a heuristic search (Koehn, 2004a). In the search procedure, frequent computation of the model score is needed for the search heuristic function, which will be challenged by the decoding efficiency for the neural network based translation model. Further, decoding with non-local (or state-dependent) features, such as a language model, is also a problem. Actually, even for the (log-) linear model, efficient decoding with the language model is not trivial (Chiang, 2007). In this paper, we propose a variant of neural networks, i.e. additive neural networks (see Section 3 for details), for SMT. It consists of two components: a li"
P13-1078,W04-3250,0,0.540761,"fter a nonlinear operation, e.g. log(p), it does. The reason is not because this feature is useless but the model does not efficiently interpret and represent it. Situations such as this confuse explanations for feature designing, since it is unclear whether such a feature contributes to a translation or not. A neural network (Bishop, 1995) is a reasonable method to overcome the above shortcomings. However, it should take constraints, e.g. the decoding efficiency, into account in SMT. Decoding in SMT is considered as the expansion of translation states and it is handled by a heuristic search (Koehn, 2004a). In the search procedure, frequent computation of the model score is needed for the search heuristic function, which will be challenged by the decoding efficiency for the neural network based translation model. Further, decoding with non-local (or state-dependent) features, such as a language model, is also a problem. Actually, even for the (log-) linear model, efficient decoding with the language model is not trivial (Chiang, 2007). In this paper, we propose a variant of neural networks, i.e. additive neural networks (see Section 3 for details), for SMT. It consists of two components: a li"
P13-1078,2012.amta-papers.17,0,0.553532,"presenting each word as a feature vector (Collobert and Weston, 2008). Because of the thousands of parameters and the non-convex objective in our model, efficient training is not simple. We propose an efficient training methodology: we apply the mini-batch conjugate sub-gradient algorithm (Le et al., 2011) to accelerate the training; we also propose pre-training and post-training methods to avoid poor local minima. The biggest contribution of this paper is that it goes beyond the log-linear model and proposes a non-linear translation model instead of re-ranking model (Duh and Kirchhoff, 2008; Sokolov et al., 2012). On both Chinese-to-English and Japanese-toEnglish translation tasks, experiment results show that our model can leverage the shortcomings suffered by the log-linear model, and thus achieves significant improvements over the log-linear based translation. 2 a collection of synchronous rules for Hiero grammar (Chiang, 2005), or phrase pairs in Moses (Koehn et al., 2007); h(f, e, d) = (h1 (f, e, d), h2 (f, e, d), · · · , hK (f, e, d))> is a K-dimensional feature vector defined on the tuple hf, e, di; W = (w1 , w2 , · · · , wK )> is a Kdimensional weight vector of h, i.e., the parameters of the m"
P13-1078,N12-1005,0,0.0332495,"erm is either a linear model or a neural network. Unlike additive models and generalized additive neural networks, our model is decomposable with respect to translation rules rather than its component variables considering the decoding efficiency of machine translation; and it allows its additive terms of neural networks to share the same parameters for a compact structure to avoid sparsity. The idea of the neural network in machine translation has already been pioneered in previous works. Casta˜no et al. (1997) introduced a neural network for example-based machine translation. In particular, Son et al. (2012) and Schwenk (2012) employed a neural network to model the phrase translation probability on the rule level hα, γi instead of the bilingual sentence level hf, ei as in Eq. (5), and thus they did not go beyond the log-linear model for SMT. There are also works which exploit non-linear models in SMT. Duh and Kirchhoff (2008) proposed a boosting re-ranking algorithm using MERT as a week learner to improve the model’s expressive abilities; Sokolov et al. (2012) similarly proposed a boosting re-ranking method from the ranking perspective rather than the classification perspective. Instead of consid"
P13-1078,W07-0710,0,0.699181,"Missing"
P13-1078,P10-1040,0,0.0218209,"ine σ as a multilayer neural network. Again for the example shown in Figure 1, the model score defined in Eq. (5) for the pair he2 , d2 i can be represented as follows: because they empirically perform well in the loglinear model. For the local feature vector h0 in Eq (5), we employ word embedding features as described in the following subsection. 3.3 Word Embedding features for AdNN Word embedding can relax the sparsity introduced by the lexicalization in NLP, and it improves the systems for many tasks such as language model, named entity recognition, and parsing (Collobert and Weston, 2008; Turian et al., 2010; Collobert, 2011). Here, we propose embedding features for rules in SMT by combining word embeddings. Firstly, we will define the embedding for the source side α of a rule r : X → hα, γi. Let VS be the vocabulary in the source language with size |VS |; Rn×|VS |be the word embedding matrix, each column of which is the word embedding (ndimensional vector) for the corresponding word in VS ; and maxSource be the maximal length of α for all rules. We further assume that the α for all rules share the same length as maxSource; otherwise, we add maxSource − |α |words “N U LL” to the end of α to obtai"
P13-1078,P00-1056,0,0.0517744,"Chinese-to-English task, the training data is the FBIS corpus (news domain) with about 240k sentence pairs; the development set is the NIST02 evaluation data; the development test set is NIST05; and the test datasets are NIST06, and NIST08. For the Japanese-to-English task, the training data with 300k sentence pairs is from the NTCIR-patent task (Fujii et al., 2010); the development set, development test set, and two test sets are averagely extracted from a given development set with 4000 sentences, and these four datasets are called test1, test2, test3 and test4, respectively. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al., 2003) to obtain the word alignment for each sentence pair. Using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing, we train a 4-gram language model for the Chinese-toEnglish task on the Xinhua portion of the English Gigaword corpus and a 4-gram language model for the Japanese-to-English task on the target side of its training data. In our experiments, the translation performances are measured by case-sensitive BLEU4 metric4 (Papineni et al., 2002). The significance testing is performed by paired bootstrap re-samplin"
P13-1078,P02-1038,0,0.904636,"a neural network is not trivial, especially when taking the decoding efficiency into consideration. In this paper, we propose a variant of a neural network, i.e. additive neural networks, for SMT to go beyond the log-linear translation model. In addition, word embedding is employed as the input to the neural network, which encodes each word as a feature vector. Our model outperforms the log-linear translation models with/without embedding features on Chinese-to-English and Japanese-to-English translation tasks. 1 Introduction Recently, great progress has been achieved in SMT, especially since Och and Ney (2002) proposed the log-linear model: almost all the stateof-the-art SMT systems are based on the log-linear model. Its most important advantage is that arbitrary features can be added to the model. Thus, it casts complex translation between a pair of languages as feature engineering, which facilitates research and development for SMT. Regardless of how successful the log-linear model is in SMT, it still has some shortcomings. This joint work was done while the first author visited NICT. 791 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 791–801, c Sof"
P13-1078,D07-1080,1,0.791639,"rch strategy and cube pruning method as the log-linear model. 4 Algorithm 1 Mini-batch conjugate subgradient Input: θ1 , T , CGIter, batch-size, k-best-list 1: for all t such that 1 ≤ t ≤ T do 2: Sample mini-batch preference pairs with size batch-size from k-best-list 3: Calculate some quantities for CG, e.g. training objective Obj, subgradient ∆, according to Eq. (6) defined over the sampled preference pairs 4: θt+1 = CG(θt , Obj, ∆, CGIter) 5: end for Output: θT +1 Training Method 4.1 Training Objective For the log-linear model, there are various tuning methods, e.g. MERT (Och, 2003), MIRA (Watanabe et al., 2007; Chiang et al., 2008), PRO (Hopkins and May, 2011) and so on, which iteratively optimize a weight such that, after re-ranking a k-best list of a given development set with this weight, the loss of the resulting 1-best list is minimal. In the extreme, if the k-best list consists only of a pair of translations hhe∗ , d∗ i, he0 , d0 ii, the desirable weight should satisfy the assertion: if the BLEU score of e∗ is greater than that of e0 , then the model score of he∗ , d∗ i with this weight will be also greater than that of he0 , d0 i. In this paper, a pair he∗ , e0 i for a source sentence f is c"
P13-1078,P10-1076,0,0.011635,"ural network to model the phrase translation probability on the rule level hα, γi instead of the bilingual sentence level hf, ei as in Eq. (5), and thus they did not go beyond the log-linear model for SMT. There are also works which exploit non-linear models in SMT. Duh and Kirchhoff (2008) proposed a boosting re-ranking algorithm using MERT as a week learner to improve the model’s expressive abilities; Sokolov et al. (2012) similarly proposed a boosting re-ranking method from the ranking perspective rather than the classification perspective. Instead of considering the reranking task in SMT, Xiao et al. (2010) employed a boosting method for the system combination in SMT. Unlike their post-processing models (either a re-ranking or a system combination model) in SMT, we propose a non-linear translation model which can be easily incorporated into the existing SMT framework. NIST08 18.33+ 19.42 19.54 test4 23.66 24.45+ 23.73 Table 3: The effect of different feature setting on AdNN model. + means the comparison is significant over AdNN-Hiero-D with p &lt; 0.05. both test sets. In addition, to investigate the effect of different feature settings on AdNN, we alternatively design another setting for h0 in Eq."
P13-1078,J93-2003,0,\N,Missing
P13-1078,P03-1021,0,\N,Missing
P13-1079,W07-0403,0,0.0221244,"n adaption, a classifier-based method and a feature-based method have been proposed. Classification-based methods must at least add an explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012)."
P13-1079,P05-1033,0,0.0914726,"ethod in each phrase table update. achieve at least comparable results to batch training methods, with a significantly less computational overhead. The rest of the paper is organized as follows. In Section 2, we introduce related work. In section 3, we briefly describe the translation model with phrasal ITGs and Pitman-Yor process. In section 4, we explain our hierarchical combination approach and give experiment results in section 5. We conclude the paper in the last section. 2 Related Work Bilingual phrases are cornerstones for phrasebased SMT systems (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) and existing translation systems often get ‘crowd-sourced’ improvements (Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using a succinct data"
P13-1079,P11-2031,0,0.0169713,"tences respectively. We employ Moses, an open-source toolkit for our experiment (Koehn et al., 2007). SRILM Toolkit (Stolcke, 2002) is employed to train 4-gram language models on the Xinhua portion of Gigaword corpus, while for the IWLST2012 data set, only its training set is used. We use batch-MIRA (Cherry and Foster, 2012) to tune the weight for each feature and translation quality is evaluated by the case-insensitive BLEU-4 metric (Papineni et al., 2002). The BLEU scores reported in this paper are the average of 5 independent runs of independent batch-MIRA weight training, as suggested by (Clark et al., 2011). al., 2011). Extracted phrase pairs are linearly combined by averaging the feature values. 3. GIZA-batch: Instead of splitting into each domain, the data set is merged as a single corpus and then a heuristic GZA-based phrase extraction is performed, similar as GIZA-linear. 4. Pialign-batch: Similar to the GIZA-batch, a single model is estimated from a single, merged corpus. Since pialign cannot handle large data, we did not experiment on the largest LDC data set. 5. Pialign-adaptive: Alignment and phrase pairs extraction are same to Pialign-batch, while translation probabilities are estimated"
P13-1079,P08-2007,0,0.01791,"ods must at least add an explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012). ITG is a synchronous grammar formalism which analyzes bilingual text by introducing inverted rules, and each IT"
P13-1079,W07-0717,0,0.0271745,"slation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using a succinct data structure with a interpolation technique (Levenberg and Osborne, 2009; Levenberg et al., 2011). In the case of the previous work on translation modeling, mixed methods have been investigated for domain adaptation in SMT by adding domain information as additional labels to the original phrase table (Foster and Kuhn, 2007). Under this framework, the training data is first divided into several parts, and phase pairs are extracted with some sub-domain features. Then all the phrase pairs and features are tuned together with different weights during decoding. As a way to choose the right domain for the domain adaption, a classifier-based method and a feature-based method have been proposed. Classification-based methods must at least add an explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified"
P13-1079,N10-1028,0,0.0143001,"explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012). ITG is a synchronous grammar formalism which analyzes bilingual text by introducing inverted rules, and each ITG derivation corresponds"
P13-1079,N03-1017,0,0.0141628,"phrase extraction method in each phrase table update. achieve at least comparable results to batch training methods, with a significantly less computational overhead. The rest of the paper is organized as follows. In Section 2, we introduce related work. In section 3, we briefly describe the translation model with phrasal ITGs and Pitman-Yor process. In section 4, we explain our hierarchical combination approach and give experiment results in section 5. We conclude the paper in the last section. 2 Related Work Bilingual phrases are cornerstones for phrasebased SMT systems (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) and existing translation systems often get ‘crowd-sourced’ improvements (Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using"
P13-1079,P07-2045,0,0.00605503,"h and Pialign-adaptive were not run on the largest data set. the feature values. Pialign is used with default parameters. The parameter ’samps’ is set to 5, which indicates 5 samples are generated for a sentence pair. The IWSLT data consists of roughly 2, 000 sentences and 3, 000 sentences each from the HIT and BTEC for development purposes, and the test data consists of 1, 000 sentences. For the FBIS and LDC task, we used NIST MT 2002 and 2004 for development and testing purposes, consisting of 878 and 1, 788 sentences respectively. We employ Moses, an open-source toolkit for our experiment (Koehn et al., 2007). SRILM Toolkit (Stolcke, 2002) is employed to train 4-gram language models on the Xinhua portion of Gigaword corpus, while for the IWLST2012 data set, only its training set is used. We use batch-MIRA (Cherry and Foster, 2012) to tune the weight for each feature and translation quality is evaluated by the case-insensitive BLEU-4 metric (Papineni et al., 2002). The BLEU scores reported in this paper are the average of 5 independent runs of independent batch-MIRA weight training, as suggested by (Clark et al., 2011). al., 2011). Extracted phrase pairs are linearly combined by averaging the featu"
P13-1079,P08-1024,0,0.0181494,"a feature-based method have been proposed. Classification-based methods must at least add an explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012). ITG is a synchronous grammar formalism whi"
P13-1079,D07-1090,0,0.0188054,"Related Work Bilingual phrases are cornerstones for phrasebased SMT systems (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) and existing translation systems often get ‘crowd-sourced’ improvements (Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using a succinct data structure with a interpolation technique (Levenberg and Osborne, 2009; Levenberg et al., 2011). In the case of the previous work on translation modeling, mixed methods have been investigated for domain adaptation in SMT by adding domain information as additional labels to the original phrase table (Foster and Kuhn, 2007). Under this framework, the training data is first divided into several parts, and phase pairs are extracted with some sub-domain features. Then all the phrase pairs"
P13-1079,D09-1079,0,0.025601,"‘crowd-sourced’ improvements (Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using a succinct data structure with a interpolation technique (Levenberg and Osborne, 2009; Levenberg et al., 2011). In the case of the previous work on translation modeling, mixed methods have been investigated for domain adaptation in SMT by adding domain information as additional labels to the original phrase table (Foster and Kuhn, 2007). Under this framework, the training data is first divided into several parts, and phase pairs are extracted with some sub-domain features. Then all the phrase pairs and features are tuned together with different weights during decoding. As a way to choose the right domain for the domain adaption, a classifier-based method and a feature-based me"
P13-1079,N12-1047,0,0.0243501,"IWSLT data consists of roughly 2, 000 sentences and 3, 000 sentences each from the HIT and BTEC for development purposes, and the test data consists of 1, 000 sentences. For the FBIS and LDC task, we used NIST MT 2002 and 2004 for development and testing purposes, consisting of 878 and 1, 788 sentences respectively. We employ Moses, an open-source toolkit for our experiment (Koehn et al., 2007). SRILM Toolkit (Stolcke, 2002) is employed to train 4-gram language models on the Xinhua portion of Gigaword corpus, while for the IWLST2012 data set, only its training set is used. We use batch-MIRA (Cherry and Foster, 2012) to tune the weight for each feature and translation quality is evaluated by the case-insensitive BLEU-4 metric (Papineni et al., 2002). The BLEU scores reported in this paper are the average of 5 independent runs of independent batch-MIRA weight training, as suggested by (Clark et al., 2011). al., 2011). Extracted phrase pairs are linearly combined by averaging the feature values. 3. GIZA-batch: Instead of splitting into each domain, the data set is merged as a single corpus and then a heuristic GZA-based phrase extraction is performed, similar as GIZA-linear. 4. Pialign-batch: Similar to the"
P13-1079,N10-1062,0,0.0176112,"lassifier-based or featurebased method, the performance of current domain adaptive phrase extraction methods is more sensitive to the development set selection. Usually the domain similar to a given development data is usually assigned higher weights. Incremental learning in which new parallel sentences are incrementally updated to the training data is employed for SMT. Compared to traditional frequent batch oriented methods, an online EM algorithm and active learning are applied to phrase pair extraction and achieves almost comparable translation performance with less computational overhead (Levenberg et al., 2010; Gonz´alezRubio et al., 2011). However, their methods usually require numbers of hyperparameters, such as mini-batch size, step size, or human judgment to determine the quality of phrases, and still rely on a heuristic phrase extraction method in each phrase table update. achieve at least comparable results to batch training methods, with a significantly less computational overhead. The rest of the paper is organized as follows. In Section 2, we introduce related work. In section 3, we briefly describe the translation model with phrasal ITGs and Pitman-Yor process. In section 4, we explain ou"
P13-1079,I08-2089,0,0.0241935,"al phrases are cornerstones for phrasebased SMT systems (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) and existing translation systems often get ‘crowd-sourced’ improvements (Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using a succinct data structure with a interpolation technique (Levenberg and Osborne, 2009; Levenberg et al., 2011). In the case of the previous work on translation modeling, mixed methods have been investigated for domain adaptation in SMT by adding domain information as additional labels to the original phrase table (Foster and Kuhn, 2007). Under this framework, the training data is first divided into several parts, and phase pairs are extracted with some sub-domain features. Then all the phrase pairs and features are tuned tog"
P13-1079,W11-2122,0,0.0170791,"(Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incrementally updated by using a succinct data structure with a interpolation technique (Levenberg and Osborne, 2009; Levenberg et al., 2011). In the case of the previous work on translation modeling, mixed methods have been investigated for domain adaptation in SMT by adding domain information as additional labels to the original phrase table (Foster and Kuhn, 2007). Under this framework, the training data is first divided into several parts, and phase pairs are extracted with some sub-domain features. Then all the phrase pairs and features are tuned together with different weights during decoding. As a way to choose the right domain for the domain adaption, a classifier-based method and a feature-based method have been proposed."
P13-1079,P12-1048,0,0.0787144,"done while the first author visited NICT. 802 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 802–810, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics by a feature set to potentially reflect the domain information. The similarity calculated by a information retrieval system between the training subset and the test set is used as a feature for each parallel sentence (Lu et al., 2007). Monolingual topic information is taken as a new feature for a domain adaptive translation model and tuned on the development set (Su et al., 2012). Regardless of underlying methods, either classifier-based or featurebased method, the performance of current domain adaptive phrase extraction methods is more sensitive to the development set selection. Usually the domain similar to a given development data is usually assigned higher weights. Incremental learning in which new parallel sentences are incrementally updated to the training data is employed for SMT. Compared to traditional frequent batch oriented methods, an online EM algorithm and active learning are applied to phrase pair extraction and achieves almost comparable translation pe"
P13-1079,P06-1124,0,0.0502351,"is a synchronous grammar formalism which analyzes bilingual text by introducing inverted rules, and each ITG derivation corresponds to the alignment of a sentence pair (Wu, 1997). Translation probabilities of ITG phrasal align803 ments can be estimated in polynomial time by slightly limiting word reordering (DeNero and Klein, 2008).  More formally, P he, f i; θx , θt are the probability of phrase pairs he, f i, which is parameterized by a phrase pair distribution θt and a symbol distribution θx . θx is a Dirichlet prior, and θt is estimated with the Pitman-Yor process (Pitman and Yor, 1997; Teh, 2006), which is expressed as  θt ∼ P Y d, s, Pdac (1) where d is the discount parameter, s is the strength parameter, and , and Pdac is a prior probability which acts as a fallback probability when a phrase pair is not in the model. Under this model, the probability for a phrase pair found in a bilingual corpus hE, F i can be represented by the following equation using the Chinese restaurant process (Teh, 2006):  P hei , fi i; hE, F i = Figure 1: A word alignment (a), and its hierarchical derivation (b). c. If x = IN V , follow a similar process as b, but concatenate f1 and f2 in reverse order he"
P13-1079,D07-1036,0,0.0197915,"keeps growing. Consequently, how to effectively use those data and improve translation performance becomes a challenging issue. This joint work was done while the first author visited NICT. 802 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 802–810, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics by a feature set to potentially reflect the domain information. The similarity calculated by a information retrieval system between the training subset and the test set is used as a feature for each parallel sentence (Lu et al., 2007). Monolingual topic information is taken as a new feature for a domain adaptive translation model and tuned on the development set (Su et al., 2012). Regardless of underlying methods, either classifier-based or featurebased method, the performance of current domain adaptive phrase extraction methods is more sensitive to the development set selection. Usually the domain similar to a given development data is usually assigned higher weights. Incremental learning in which new parallel sentences are incrementally updated to the training data is employed for SMT. Compared to traditional frequent ba"
P13-1079,2012.amta-papers.18,0,0.0920973,"on a large data set, and it requires us to re-train every time new training data is available. Even if we can handle the large computation cost, improvement is not guaranteed every time we perform batch tuning on the newly updated training data obtained from divergent domains. Traditional domain adaption methods for SMT are also not adequate in this scenario. Most of them have been proposed in order to make translation systems perform better for resource-scarce domains when most training data comes from resourcerich domains, and ignore performance on a more generic domain without domain bias (Wang et al., 2012). As an alternative, incremental learning may resolve the gap by incrementally adding data sentence-by-sentence into the training data. Since SMT systems trend to employ very large scale training data for translation knowledge extraction, updating several sentence pairs each time will be annihilated in the existing corpus. This paper proposes a new phrase table combination method. First, phrase pairs are extracted from each domain without interfering with other domains. In particular, we employ the nonparametric Bayesian phrasal inversion transduction grammar (ITG) of Neubig et al. (2011) to p"
P13-1079,P11-1064,1,0.92446,"bias (Wang et al., 2012). As an alternative, incremental learning may resolve the gap by incrementally adding data sentence-by-sentence into the training data. Since SMT systems trend to employ very large scale training data for translation knowledge extraction, updating several sentence pairs each time will be annihilated in the existing corpus. This paper proposes a new phrase table combination method. First, phrase pairs are extracted from each domain without interfering with other domains. In particular, we employ the nonparametric Bayesian phrasal inversion transduction grammar (ITG) of Neubig et al. (2011) to perform phrase table extraction. Second, extracted phrase tables are combined as if they are drawn from a hierarchical Pitman-Yor process, in which the phrase tables represented as tables in the Chinese restaurant process (CRP) are hierarchically chained by treating each of the previously learned phrase tables as prior to the current one. Thus, we can easily update the chain of phrase tables by appending the newly extracted phrase table and by treating the chain of the previous ones as its prior. Experiment results indicate that our method can achieve better translation performance when th"
P13-1079,J97-3002,0,0.0172822,"ence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012). ITG is a synchronous grammar formalism which analyzes bilingual text by introducing inverted rules, and each ITG derivation corresponds to the alignment of a sentence pair (Wu, 1997). Translation probabilities of ITG phrasal align803 ments can be estimated in polynomial time by sli"
P13-1079,P12-1018,1,0.903351,"(Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012). ITG is a synchronous grammar formalism which analyzes bilingual text by introducing inverted rules, and each ITG derivation corresponds to the alignment of a sentence pair (Wu, 1997). Translation probabilities of ITG phrasal align803 ments can be estimated in polynomial time by slightly limiting word reordering (DeNero and Klein, 2008).  More formally, P he, f i; θx , θt are the probability of phrase pairs he, f i, which is parameterized by a phrase pair distribution θt and a symbol distribution θx . θx is a Dirichlet prior, and θt is estimated with the Pitman-Yor process (Pitman and Yor, 1"
P13-1079,2007.mtsummit-papers.68,0,0.0386744,"ining data is first divided into several parts, and phase pairs are extracted with some sub-domain features. Then all the phrase pairs and features are tuned together with different weights during decoding. As a way to choose the right domain for the domain adaption, a classifier-based method and a feature-based method have been proposed. Classification-based methods must at least add an explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a m"
P13-1079,P08-1012,0,0.0167267,"er-based method and a feature-based method have been proposed. Classification-based methods must at least add an explicit label to indicate which domain the current phrase pair comes from. This is traditionally done with an automatic domain classifier, and each input sentence is classified into its corresponding domain (Xu et al., 2007). As an alternative to the classification-based approach, Wang et al. (2012) employed a featurebased approach, in which phrase pairs are enriched 3 Phrase Pair Extraction with Unsupervised Phrasal ITGs Recently, phrase alignment with ITGs (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2008) and parameter estimation with Gibbs sampling (DeNero and Klein, 2008; Blunsom and Cohn, 2010) are popular. Here, we employ a method proposed by Neubig et al. (2011), which uses parametric Bayesian inference with the phrasal ITGs (Wu, 1997). It can achieve comparable translation accuracy with a much smaller phrase table than the traditional GIZA++ and heuristic phrase extraction methods. It has also been proved successful in adjusting the phrase length granularity by applying character-based SMT with more sophisticated inference (Neubig et al., 2012). ITG is a synchronou"
P13-1079,J03-1002,0,0.00573107,"phrase pair would be boosted by the fallback probabilities. Pitman-Yor process is also employed in n-gram language models which are hierarchically represented through the hierarchical Pitman-Yor process with switch priors to integrate different domains in all the levels (Wood and Teh, 2009). Our work incrementally combines the models from different domains by directly employing the hierarchical process through the base measures. 5 Corpus HIT BTEC Domain 1 Domain 2 Domain 3 Domain 4 Domain 5 News News Magazine Magazine Finance 1. GIZA-linear: Phase pairs are extracted in each domain by GIZA++ (Och and Ney, 2003) and the ”grow-diag-final-and” method with a maximum length 7. The phrase tables from various domains are linearly combined by averaging the feature values. 2. Pialign-linear: Similar to GIZA-linear, but we employed the phrasal ITG method described in Section 3 using the pialign toolkit 3 (Neubig et Experiment 1 http://code.google.com/p/plda/ In particular, they come from LDC catalog number: LDC2002E18, LDC2002E58, LDC2003E14, LDC2005E47, LDC2006E26, in this order. 3 http://www.phontron.com/pialign/ 2 We evaluate the proposed approach on the Chinese-to-English translation task with three data"
P13-1079,J04-4002,0,0.0224078,"rely on a heuristic phrase extraction method in each phrase table update. achieve at least comparable results to batch training methods, with a significantly less computational overhead. The rest of the paper is organized as follows. In Section 2, we introduce related work. In section 3, we briefly describe the translation model with phrasal ITGs and Pitman-Yor process. In section 4, we explain our hierarchical combination approach and give experiment results in section 5. We conclude the paper in the last section. 2 Related Work Bilingual phrases are cornerstones for phrasebased SMT systems (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2005) and existing translation systems often get ‘crowd-sourced’ improvements (Levenberg et al., 2010). A number of approaches have been proposed to make use of the full potential of the available parallel sentences from various domains, such as domain adaptation and incremental learning for SMT. The translation model and language model are primary components in SMT. Previous work proved successful in the use of large-scale data for language models from diverse domains (Brants et al., 2007; Schwenk and Koehn, 2008). Alternatively, the language model is incremental"
P13-1079,P02-1040,0,0.0878579,"ata consists of 1, 000 sentences. For the FBIS and LDC task, we used NIST MT 2002 and 2004 for development and testing purposes, consisting of 878 and 1, 788 sentences respectively. We employ Moses, an open-source toolkit for our experiment (Koehn et al., 2007). SRILM Toolkit (Stolcke, 2002) is employed to train 4-gram language models on the Xinhua portion of Gigaword corpus, while for the IWLST2012 data set, only its training set is used. We use batch-MIRA (Cherry and Foster, 2012) to tune the weight for each feature and translation quality is evaluated by the case-insensitive BLEU-4 metric (Papineni et al., 2002). The BLEU scores reported in this paper are the average of 5 independent runs of independent batch-MIRA weight training, as suggested by (Clark et al., 2011). al., 2011). Extracted phrase pairs are linearly combined by averaging the feature values. 3. GIZA-batch: Instead of splitting into each domain, the data set is merged as a single corpus and then a heuristic GZA-based phrase extraction is performed, similar as GIZA-linear. 4. Pialign-batch: Similar to the GIZA-batch, a single model is estimated from a single, merged corpus. Since pialign cannot handle large data, we did not experiment on"
P13-2056,P11-1061,0,0.169857,"ai Yu2 1 School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China {yumo,tjzhao,ylbai}@mtlab.hit.edu.cn 2 Baidu Inc., Beijing, China {tianhao,yudianhai}@baidu.com Abstract that target language has to be similar to source language. Otherwise the performance will degrade especially when the orders of phrases between source and target languages differ a lot. Another common type of projection methods map labels from resource-rich language sentences to resource-scarce ones in a parallel corpus using word alignment information (Yarowsky et al., 2001; Hwa et al., 2005; Das and Petrov, 2011). We refer them as projection based on word alignments in this paper. Compared to other types of projection methods, this type of methods is more robust to syntactic differences between languages since it trained models on the target side thus following the topology of the target language. This paper aims to build an accurate projection method with strong generality to various pairs of languages, even when the languages are from different families and are typologically divergent. As far as we know, only a few works focused on this topic (Xia and Lewis 2007; T¨ackstr¨om et al., 2013). We adopte"
P13-2056,P10-1002,0,0.0616785,"Missing"
P13-2056,D11-1006,0,0.0535494,"languages. Unfortunately, it is impossible to build sufficient labeled data for all tasks in all languages. To address NLP tasks in resource-scarce languages, cross-lingual projection methods were proposed, which make use of existing resources in resource-rich language (also called source language) to help NLP tasks in resource-scarce language (also named as target language). There are several types of projection methods. One intuitive and effective method is to build a common feature space for all languages, so that the model trained on one language could be directly used on other languages (McDonald et al., 2011; T¨ackstr¨om et al., 2012). We call it direct projection, which becomes very popular recently. The main limitation of these methods is 312 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 312–317, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics Firstly, we introduce Brown clusters of target language to make the projection models cover broader cases. Brown clustering is a kind of word representations, which assigns word with similar functions to the same cluster. They can be efficiently learned on large-scale unla"
P13-2056,N12-1052,0,0.0481418,"Missing"
P13-2056,N13-1126,0,0.0726683,"Missing"
P13-2056,I05-3027,0,0.0449224,"projection of POS tagging, we used the test set of CTB. Since English and Chinese have different annotation standards, labels in the two languages were converted to the universal POS tag set (Petrov et al., 2011; Das and Petrov, 2011) so that the labels between the source and target languages were consistent. The universal tag set made the task of POS tagging easier since the fine-grained types are no more cared. The Brown clusters were trained on Chinese Wikipedia. The bodies of all articles are retained to induce 1000 clusters using the algorithm in (Liang, 2005) . Stanford word segmentor (Tseng et al., 2005) was used for Chinese word segmentation. When English Brown clusters were in need, we trained the word clusters on the tokenized English Wikipedia. We chose LDC2003E14 as the parallel corpus, which contains about 200,000 sentences. GIZA++ (Och and Ney, 2000) was used to generate word alignments. It is easier to obtain similar amount of parallel sentences between English and minor languages, making the conclusions more general for problems of projection in real applications. 3.2 avg Prec 47.48 71.6 63.96 73.44 avg Rec 28.12 37.84 46.59 47.63 avg F1 33.91 47.66 53.75 56.60 Table 2: Performances"
P13-2056,N07-1057,0,0.0251259,"ky et al., 2001; Hwa et al., 2005; Das and Petrov, 2011). We refer them as projection based on word alignments in this paper. Compared to other types of projection methods, this type of methods is more robust to syntactic differences between languages since it trained models on the target side thus following the topology of the target language. This paper aims to build an accurate projection method with strong generality to various pairs of languages, even when the languages are from different families and are typologically divergent. As far as we know, only a few works focused on this topic (Xia and Lewis 2007; T¨ackstr¨om et al., 2013). We adopted the projection method based on word alignments since it is less affected by language differences. However, such methods also have some disadvantages. Firstly, the models trained on projected data could only cover words and cases appeared in the target side of parallel corpus, making it difficult to generalize to test data in broader domains. Secondly, the performances of these methods are limited by the accuracy of word alignments, especially when words between two languages are not one-one aligned. So the obtained labeled data contains a lot of noises,"
P13-2056,H01-1035,0,0.0665547,"Tiejun Zhao1 Yalong Bai1 Hao Tian2 Dianhai Yu2 1 School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China {yumo,tjzhao,ylbai}@mtlab.hit.edu.cn 2 Baidu Inc., Beijing, China {tianhao,yudianhai}@baidu.com Abstract that target language has to be similar to source language. Otherwise the performance will degrade especially when the orders of phrases between source and target languages differ a lot. Another common type of projection methods map labels from resource-rich language sentences to resource-scarce ones in a parallel corpus using word alignment information (Yarowsky et al., 2001; Hwa et al., 2005; Das and Petrov, 2011). We refer them as projection based on word alignments in this paper. Compared to other types of projection methods, this type of methods is more robust to syntactic differences between languages since it trained models on the target side thus following the topology of the target language. This paper aims to build an accurate projection method with strong generality to various pairs of languages, even when the languages are from different families and are typologically divergent. As far as we know, only a few works focused on this topic (Xia and Lewis 2"
P13-2056,J92-4003,0,\N,Missing
P13-2056,petrov-etal-2012-universal,0,\N,Missing
P13-2070,1993.eamt-1.1,0,0.438537,"Missing"
P13-2070,J03-1002,0,0.0172917,"Missing"
P13-2070,2010.iwslt-papers.7,1,0.585967,"Missing"
P13-2070,P11-2010,0,0.0396112,"Missing"
P13-2070,W12-4404,0,0.0551276,"Missing"
P13-2070,P11-2094,0,0.0189162,"ods have been proposed, such as the supervised language model-based approach of (Li et al., 2007), and the unsupervised approach of (Huang et al., 2005) that used a bottom-up clustering algorithm. (Li et al., 2007) proposed a supervised transliteration model which classifies names based on their origins and genders using a language model; it switches between transliteration models based on the input. (Hagiwara et al., 2011) tackled the issue by using an unsupervised method based on the EM algorithm to perform a soft classification. Recently, non-parametric Bayesian models (Finch et al., 2010; Huang et al., 2011; Hagiwara et al., 2012) have attracted much attention in the transliteration field. In comparison to many of the previous alignment models (Li et al., 2004; Jiampojamarn et al., 2007; Berg-Kirkpatrick et al., 2011), the nonparametric Bayesian models allow unconstrained monotonic many-to-many alignment and are able to overcome the inherent over-fitting problem. Until now most of the previous work (Li et al., 2007; Hagiwara et al., 2011) is either affected by the multi-origins factor, or has issues with overfitting. (Hagiwara et al., 2012) took these two factors into consideration, but their ap"
P13-2070,W09-3504,0,0.0286643,"Missing"
P13-2070,J98-4003,0,0.247889,"Missing"
P13-2070,P07-2045,0,0.00456523,"rned by sampling its value. Following (Blunsom et al., 2009) we used a vague gamma prior Γ(10−4 , 104 ), and sampled new values from a log-normal distribution whose mean was the value of the parameter, and variance was 0.3. We used the Metropolis-Hastings algorithm to determine whether this new sample would be accepted. The parameters λs and λt in Equation 4 were set to λs = 4 and λt = 1. We compare our alignment model with GIZA++ (Och et al., 2003) and the Bayesian bilingual alignment model (BBAM). We employ two decoding models: a phrase-based machine translation decoder (specifically Moses (Koehn et al., 2007)), and the DirecTL decoder (Jiampojamarn et al., 2009). They are based on different decoding strategies and optimization targets, and therefore make the comparison more comprehensive. For the Moses decoder, we applied the grow-diag-final-and heuristic algorithm to extract the phrase table, and tuned the parameters using the BLEU metric. Corpora EO ECJ-O Multi-O Corpus Scale Training Development 32,681 3,267 32,500 3,250 33,291 3,328 #(Clusters) Testing 3,267 3,250 3,328 #(Targets) Model cDPMM GIZA++ BBAM cDPMM EO 5.8 14.43 6.06 9.32 ECJ-O 9.5 5.35 2.45 3.45 Multi-O 14.3 6.62 2.91 4.28 Table 3:"
P13-2070,P04-1021,0,0.0726859,"sed a bottom-up clustering algorithm. (Li et al., 2007) proposed a supervised transliteration model which classifies names based on their origins and genders using a language model; it switches between transliteration models based on the input. (Hagiwara et al., 2011) tackled the issue by using an unsupervised method based on the EM algorithm to perform a soft classification. Recently, non-parametric Bayesian models (Finch et al., 2010; Huang et al., 2011; Hagiwara et al., 2012) have attracted much attention in the transliteration field. In comparison to many of the previous alignment models (Li et al., 2004; Jiampojamarn et al., 2007; Berg-Kirkpatrick et al., 2011), the nonparametric Bayesian models allow unconstrained monotonic many-to-many alignment and are able to overcome the inherent over-fitting problem. Until now most of the previous work (Li et al., 2007; Hagiwara et al., 2011) is either affected by the multi-origins factor, or has issues with overfitting. (Hagiwara et al., 2012) took these two factors into consideration, but their approach still operates within an EM framework and model order selection by hand is necessary prior to training. Introduction Machine transliteration methods"
P13-2070,P07-1016,0,0.12454,"re model for clustering, and a set of multinomial Dirichlet process models that perform bilingual alignment independently for each cluster. The experimental results show that our method considerably outperforms conventional alignment models. 1 “Kim Jong-il/金正恩” (Korea), “Kana Gaski/金崎” (Japan), “Haw King/霍金” (England), “Jin yong/金庸’ (China). The same Chinese character “金” should be aligned to different romanized character sequences: “Kim”, “Kana”, “King”, “Jin”. To address this issue, many name classification methods have been proposed, such as the supervised language model-based approach of (Li et al., 2007), and the unsupervised approach of (Huang et al., 2005) that used a bottom-up clustering algorithm. (Li et al., 2007) proposed a supervised transliteration model which classifies names based on their origins and genders using a language model; it switches between transliteration models based on the input. (Hagiwara et al., 2011) tackled the issue by using an unsupervised method based on the EM algorithm to perform a soft classification. Recently, non-parametric Bayesian models (Finch et al., 2010; Huang et al., 2011; Hagiwara et al., 2012) have attracted much attention in the transliteration f"
P13-2070,P09-1012,0,0.217435,"rst generate an infinite number of clusters, choose one, then generate a transliteration pair using the parameters that describe the cluster. The basic sampling unit of the cDPMM for the clustering process is a transliteration pair, but the basic sampling unit for BBAM is a TU. In order to integrate the two processes in a single model we treat a transliteration pair as a sequence of TUs generated by a BBAM model. The BBAM generates a sequence (a transliteration pair) based on the joint source-channel model (Li et al., 2004). We use a blocked version of a Gibbs sampler to train each BBAM (see (Mochihashi et al., 2009) for details of this process). 2.1 Terminology In this paper, we concentrate on the alignment process for transliteration. The proposed cDPMM segments a bilingual corpus of transliteration pairs into bilingual character sequence-pairs. We will call these sequence-pairs Transliteration Units (TUs). We denote the source and target of n a TU as sm 1 = ⟨s1 , ..., sm ⟩ and t1 = ⟨t1 , ..., tn ⟩ respectively, where si (ti ) is a single character in source (target) language. We use the same notation (s, t) = (⟨s1 , ..., sm ⟩, ⟨t1 , ..., tn ⟩) to denote a transliteration pair, which we can write as n x"
P13-2070,P00-1037,0,\N,Missing
P13-2070,N07-1047,0,\N,Missing
P13-2070,P09-1088,0,\N,Missing
P13-2070,W12-4401,0,\N,Missing
P13-2070,W12-4402,0,\N,Missing
P13-2070,D11-1029,0,\N,Missing
P14-1091,D13-1161,0,0.148238,"rd to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 2013) have alleviated such issues using question-answer pairs as weak supervision, but still with the shortcoming of using limited lexical triggers to link NL phrases to predicates. Poon (2013) has proposed an unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs heavily depends on dependency parsing results. Besides, the KB used (ATIS) is limited as well. Kwiatkowski et al. (2013) use Wiktionary and a limited manual lexicon to map POS tags to a set of predefined CCG lexical categories, which aims to reduce the need for learning lexicon from training data. But it still needs human efforts to define lexical categories, which usually can not cover all the semantic phenomena. 4 4.1 Experiment Data Sets Following Berant et al. (2013), we use the same subset of WEBQUESTIONS (3,778 questions) as the development set (Dev) for weight tuning in MERT, and use the other part of WEBQUESTIONS (2,032 questions) as the test set (Test). Table 1 shows the statistics of this data set. Da"
P14-1091,D11-1039,0,0.0142537,"d over derivations, and minimum error rate training is used to tune feature weights based on a set of question-answer pairs. Compared to a KB-QA system using a state-of-the-art semantic parser, our method achieves better results. 1 Introduction Knowledge-based question answering (KB-QA) computes answers to natural language (NL) questions based on existing knowledge bases (KBs). Most previous systems tackle this task in a cascaded manner: First, the input question is transformed into its meaning representation (MR) by an independent semantic parser (Zettlemoyer and Collins, 2005; Mooney, 2007; Artzi and Zettlemoyer, 2011; Liang et al., 2011; Cai and Yates, ∗ This work was finished while the author was visiting Microsoft Research Asia. 967 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 967–976, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Hanks, Film.Actor.Film, Forrest Gumpi62 and hForrest Gump, Film.Film.Director, Robert Zemeckisi60 are three ordered formal triples corresponding to the three translation steps in Figure 1. We define the task of transforming question spans into formal triples as question translation."
P14-1091,P11-1060,0,0.199678,"um error rate training is used to tune feature weights based on a set of question-answer pairs. Compared to a KB-QA system using a state-of-the-art semantic parser, our method achieves better results. 1 Introduction Knowledge-based question answering (KB-QA) computes answers to natural language (NL) questions based on existing knowledge bases (KBs). Most previous systems tackle this task in a cascaded manner: First, the input question is transformed into its meaning representation (MR) by an independent semantic parser (Zettlemoyer and Collins, 2005; Mooney, 2007; Artzi and Zettlemoyer, 2011; Liang et al., 2011; Cai and Yates, ∗ This work was finished while the author was visiting Microsoft Research Asia. 967 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 967–976, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics Hanks, Film.Actor.Film, Forrest Gumpi62 and hForrest Gump, Film.Film.Director, Robert Zemeckisi60 are three ordered formal triples corresponding to the three translation steps in Figure 1. We define the task of transforming question spans into formal triples as question translation. A denotes one final"
P14-1091,P13-5002,0,0.0191882,"Missing"
P14-1091,J13-2005,0,0.357304,"and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an answer to a given question can be rewritten into that question through a sequence of stochastic operations. Compared to the above two MT-motivated QA work, our method uses MT methodology to translate questions to answers directly. 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011) require manually annotated logical forms as supervision, and are hard to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 2013) have alleviated such issues using question-answer pairs as weak supervision, but still with the shortcoming of using limited lexical triggers to link NL phrases to predicates. Poon (2013) has proposed an unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs heavily depends on dependency parsing results. Besides, the KB used (ATIS) is limited as well. Kwiatkowski et al. (2013) use Wiktionary and a limited manual lexicon to map POS tags to a set of predefined CCG lexical categories, which aims to reduce th"
P14-1091,D13-1160,0,0.380905,"unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs heavily depends on dependency parsing results. Besides, the KB used (ATIS) is limited as well. Kwiatkowski et al. (2013) use Wiktionary and a limited manual lexicon to map POS tags to a set of predefined CCG lexical categories, which aims to reduce the need for learning lexicon from training data. But it still needs human efforts to define lexical categories, which usually can not cover all the semantic phenomena. 4 4.1 Experiment Data Sets Following Berant et al. (2013), we use the same subset of WEBQUESTIONS (3,778 questions) as the development set (Dev) for weight tuning in MERT, and use the other part of WEBQUESTIONS (2,032 questions) as the test set (Test). Table 1 shows the statistics of this data set. Data Set WEBQUESTIONS Berant et al. (2013) have not only enlarged the KB used for Freebase (Google, 2013), but also used a bigger lexicon trigger set extracted by the open IE method (Lin et al., 2012) for NL phrases to predicates linking. In comparison, our method has further advantages: (1) Question answering and semantic parsing are performed in an join"
P14-1091,W12-3016,0,0.0735886,"t it still needs human efforts to define lexical categories, which usually can not cover all the semantic phenomena. 4 4.1 Experiment Data Sets Following Berant et al. (2013), we use the same subset of WEBQUESTIONS (3,778 questions) as the development set (Dev) for weight tuning in MERT, and use the other part of WEBQUESTIONS (2,032 questions) as the test set (Test). Table 1 shows the statistics of this data set. Data Set WEBQUESTIONS Berant et al. (2013) have not only enlarged the KB used for Freebase (Google, 2013), but also used a bigger lexicon trigger set extracted by the open IE method (Lin et al., 2012) for NL phrases to predicates linking. In comparison, our method has further advantages: (1) Question answering and semantic parsing are performed in an joint way under a unified framework; (2) A robust method is proposed to map NL questions to their formal triple queries, which trades off the mapping quality by using question patterns and relation expressions in a cascaded way; and (3) We use domain independent feature set which allowing us to use a relatively small number of question-answer pairs to tune model parameters. # Questions 5,810 # Words 6.7 Table 1: Statistics of evaluation set. #"
P14-1091,P13-1042,0,0.508703,"Missing"
P14-1091,P03-1021,0,0.0585009,"sing is used to parse each input question, and answers of the span covered by each CYK cell are considered the translations of that cell; unlike MT, which uses offline-generated translation tables to translate source phrases into target translations, a semantic parsing-based question translation method is used to translate each span into its answers on-the-fly, based on question patterns and relation expressions. The final answers can be obtained from the root cell. Derivations generated during such a translation procedure are modeled by a linear model, and minimum error rate training (MERT) (Och, 2003) is used to tune feature weights based on a set of question-answer pairs. Figure 1 shows an example: the question director of movie starred by Tom Hanks is translated to one of its answers Robert Zemeckis by three main steps: (i) translate director of to director of ; (ii) translate movie starred by Tom Hanks to one of its answers Forrest Gump; (iii) translate director of Forrest Gump to a final answer Robert Zemeckis. Note that the updated question covered by Cell[0, 6] is obtained by combining the answers to question spans covered by Cell[0, 1] and Cell[2, 6]. The contributions of this work"
P14-1091,J10-3005,0,0.00981963,"contain answers. Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an answer to a given question can be rewritten into that question through a sequence of stochastic operations. Compared to the above two MT-motivated QA work, our method uses MT methodology to translate questions to answers directly. 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011) require manually annotated logical forms as supervision, and are hard to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 2013) have alleviated such issues using question-answer pairs as weak supervision, but still with the shortcoming of using limited lexical triggers to link NL phrases to predicates. Poon (2013) has proposed an unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs heavily depends on dependency parsing results. Besides, the KB used (ATIS) is limited as well. Kwiatkowski et al. (2013) use Wiktionary and a limited manual lexicon to map POS tags to a set of predefined CCG lexical categories, wh"
P14-1091,P13-1092,0,0.0834723,"hastic operations. Compared to the above two MT-motivated QA work, our method uses MT methodology to translate questions to answers directly. 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011) require manually annotated logical forms as supervision, and are hard to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 2013) have alleviated such issues using question-answer pairs as weak supervision, but still with the shortcoming of using limited lexical triggers to link NL phrases to predicates. Poon (2013) has proposed an unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs heavily depends on dependency parsing results. Besides, the KB used (ATIS) is limited as well. Kwiatkowski et al. (2013) use Wiktionary and a limited manual lexicon to map POS tags to a set of predefined CCG lexical categories, which aims to reduce the need for learning lexicon from training data. But it still needs human efforts to define lexical categories, which usually can not cover all the semantic phenomena. 4 4.1 Experiment Data"
P14-1091,P03-1003,0,0.0535075,"rsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Zettlemoyer and Collins, 2007; Wong and Mooney, • hQP count (·), which counts the number of triples in D that are generated by QP-based question translation method. • hRE count (·), which counts the number of triples in D that are generated by RE-based question translation method. 5 The static rank score of an entity represents a general indicator of the overall quality of that entity. 972 best translations, which are used for finding similar sentences in the document collection that probably contain answers. Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an answer to a given question can be rewritten into that question through a sequence of stochastic operations. Compared to the above two MT-motivated QA work, our method uses MT methodology to translate questions to answers directly. 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011) require manually annotated logical forms as supervision, and are hard to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 201"
P14-1091,N06-1056,0,0.0739044,"osition component. ref ˆ ˆ M Err(Aref i , Ai ; λ1 ) = 1 − δ(Ai , Ai ) ˆ where δ(Aref i , Ai ) is an indicator function which equals 1 when Aˆi is included in the reference set Aref i , and 0 otherwise. • htriple (·), which counts the number of triples in D, whose predicates are not N ull. 3 • htripleweight (·), which P sums the scores of all triples {ti } in D as ti ∈D ti .score. Comparison with Previous Work Our work intersects with two research directions: semantic parsing and question answering. Some previous works on semantic parsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Zettlemoyer and Collins, 2007; Wong and Mooney, • hQP count (·), which counts the number of triples in D that are generated by QP-based question translation method. • hRE count (·), which counts the number of triples in D that are generated by RE-based question translation method. 5 The static rank score of an entity represents a general indicator of the overall quality of that entity. 972 best translations, which are used for finding similar sentences in the document collection that probably contain answers. Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explai"
P14-1091,W12-0103,0,0.0349442,"Missing"
P14-1091,P07-1121,0,0.270694,"Missing"
P14-1091,D11-1142,0,0.016949,"Missing"
P14-1091,P13-1158,0,0.0557123,"of formal triples T . Each triple t ∈ T is in the form of {esbj , p, eobj }, where esbj ’s mention3 occurs in Q, p is a predicate that denotes the meaning expressed by the context of esbj in Q, eobj is an answer to Q retrieved from KB using a triple query q = {esbj , p, ?}. Note that if no predicate p or answer eobj can be generated, {Q, N ull, Q} will be returned as a special triple, which sets eobj to be Q itself, and p to be N ull. This makes sure the un-answerable spans can be passed on to the higher-level operations. Question translation assumes each span Q is a single-relation question (Fader et al., 2013). Such assumption simplifies the efforts of semantic parsing to the minimum question units, while leaving the capability of handling multiple-relation questions (Figure 1 gives one such example) to the outer CYK-parsing based translation procedure. Two question translation methods are presented in the rest of this subsection, which are based on question patterns and relation expressions respectively. 2.3.1 Question Pattern-based Translation A question pattern QP includes a pattern string QP pattern , which is composed of words and a slot 3 For simplicity, a cleaned entity dictionary dumped fro"
P14-1091,D07-1071,0,0.0608809,"ˆ ˆ M Err(Aref i , Ai ; λ1 ) = 1 − δ(Ai , Ai ) ˆ where δ(Aref i , Ai ) is an indicator function which equals 1 when Aˆi is included in the reference set Aref i , and 0 otherwise. • htriple (·), which counts the number of triples in D, whose predicates are not N ull. 3 • htripleweight (·), which P sums the scores of all triples {ti } in D as ti ∈D ti .score. Comparison with Previous Work Our work intersects with two research directions: semantic parsing and question answering. Some previous works on semantic parsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Zettlemoyer and Collins, 2007; Wong and Mooney, • hQP count (·), which counts the number of triples in D that are generated by QP-based question translation method. • hRE count (·), which counts the number of triples in D that are generated by RE-based question translation method. 5 The static rank score of an entity represents a general indicator of the overall quality of that entity. 972 best translations, which are used for finding similar sentences in the document collection that probably contain answers. Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an"
P14-1091,D10-1119,0,0.079168,"lation method. 5 The static rank score of an entity represents a general indicator of the overall quality of that entity. 972 best translations, which are used for finding similar sentences in the document collection that probably contain answers. Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an answer to a given question can be rewritten into that question through a sequence of stochastic operations. Compared to the above two MT-motivated QA work, our method uses MT methodology to translate questions to answers directly. 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011) require manually annotated logical forms as supervision, and are hard to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 2013) have alleviated such issues using question-answer pairs as weak supervision, but still with the shortcoming of using limited lexical triggers to link NL phrases to predicates. Poon (2013) has proposed an unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs"
P14-1091,D11-1140,0,0.0182397,"c rank score of an entity represents a general indicator of the overall quality of that entity. 972 best translations, which are used for finding similar sentences in the document collection that probably contain answers. Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an answer to a given question can be rewritten into that question through a sequence of stochastic operations. Compared to the above two MT-motivated QA work, our method uses MT methodology to translate questions to answers directly. 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011) require manually annotated logical forms as supervision, and are hard to extend resulting parsers from limited domains, such as GEO, JOBS and ATIS, to open domains. Recent works (Clarke and Lapata, 2010; Liang et al., 2013) have alleviated such issues using question-answer pairs as weak supervision, but still with the shortcoming of using limited lexical triggers to link NL phrases to predicates. Poon (2013) has proposed an unsupervised method by adopting groundedlearning to leverage the database for indirect supervision. But transformation from NL questions to MRs heavily depends on dependen"
P15-1048,J92-4003,0,0.16594,"inear model for both models (6) and (7) to score a parsing tree as: X Score(T ) = φ(action) · ~λ action Where φ(action) is the feature vector extracted from partial hypothesis T for a certain action and ~λ is the weight vector. φ(action) · ~λ calculates the score of a certain transition action. The score of a parsing tree T is the sum of action scores. In addition to the basic features introduced in (Zhang and Nivre, 2011) that are defined over bag of words and POS-tags as well as tree-based context, our models also integrate three classes of new features combined with Brown cluster features (Brown et al., 1992) that relate to the rightto-left transition-based parsing procedure as detailed below. Simple repetition function • δI (a, b): A logic function which indicates whether a and b are identical. great X Syntax-based repetition function Figure 3: An example of UT model, where ‘N’ means the word is a fluent word and ‘X’ means it is disfluent. Words with italic font are Reparandums. 3.3 Training and decoding • δL (a, b): A logic function which indicates whether a is a left child of b. • δR (a, b): A logic function which indicates whether a is a right child of b. A binary classifier transition-based m"
P15-1048,N01-1016,0,0.830252,"Missing"
P15-1048,W02-1001,0,0.136275,", p0 ); unigrams δL (w0 , ws );δL (p0 , ps ); δR (w0 , ws );δR (p0 , ps ); NI (w0 , ws );NI (p0 , ps ); N# (w0..2 , ws );N# (p0..2 , ps ); Function δI (ws , w0 )δI (ps , p0 ); bigrams δL (w0 , ws )δL (p0 , ps ); δR (w0 , ws )δR (p0 , ps ); NI (w0 , ws )NI (p0 , ps ); N# (w0..2 , ws )N# (p0..2 , ps ); δI (ws , w0 )ws c; δI (ws , w0 )w0 c; Function ws w0 δI (ws , w0 ); trigrams ws w0 δI (ps , p0 ); Table 1: Feature templates designed for disfluency detection and dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 4.1 Experiments Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development"
P15-1048,de-marneffe-etal-2006-generating,0,0.019972,"Missing"
P15-1048,P08-2027,0,0.0244163,"am-search decoder to combine multiple models such as M3 N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfluencies. Miller and Schuler (2008) used a right corner transform of syntax trees to produce a syntactic tree with speech repairs. But their performance was not as good as labeling models. There exist two methods published recently which are similar to ours. Rasooli and Tetreault (2013) designed a joint model for both disfluency detection and dependency parsing. They regarded the two tasks as a two step classifications. Honnibal and Johnson (2014) presented a new joint model by extending the original transition actions with a new “Edit” transition. They achieved the state-of-theart performance on both disfluency detection and p"
P15-1048,N09-2028,0,0.381295,"“you know”) and repairs. To identify and remove disfluencies, straightforward rules can be designed to tackle the former four classes of disfluencies since they often belong to a closed set. However, the repair type disfluency poses particularly more There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3 N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disflu495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguis"
P15-1048,N13-1102,0,0.883224,"repairs. To identify and remove disfluencies, straightforward rules can be designed to tackle the former four classes of disfluencies since they often belong to a closed set. However, the repair type disfluency poses particularly more There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3 N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disflu495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics encies (Honnibal"
P15-1048,Q14-1011,0,0.390168,"u, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disflu495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics encies (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013). These methods can jointly perform dependency parsing and disfluency detection. But in these methods, great efforts are made to distinguish normal words from disfluent words as decisions cannot be made imminently from left to right, leading to inefficient implementation as well as performance loss. In this paper, we propose detecting disfluencies using a right-to-left transition-based dependency parsing (R2L parsing), where the words are consumed from right to left to build the parsing tree based on which the current word is predicted to be either disfluent or no"
P15-1048,D13-1013,0,0.553101,"Missing"
P15-1048,C14-1138,0,0.0180684,"ure work, we will try to add new classes of features to further improve performance by capturing the property of disfluencies. We would also like to make an end-to-end MT test over transcribed speech texts with disfluencies removed based on the method proposed in this paper. Recently, the max-margin markov networks (M3 N) based model has achieved great improvement in this task. Qian and Liu (2013) presented a multi-step learning method using weighted M3 N model for disfluency detection. They showed that M3 N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3 N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disf"
P15-1048,D08-1059,0,0.215322,"RightArc : Links the front of the queue to the top of the stack and, removes the front of the queue and pushes it to the stack. The choice of each transition action during parsing is scored by a generalized perceptron (Collins, 496 2002) which can be trained over a rich set of nonlocal features. In decoding, beam search is performed to search the optimal sequence of transition actions. As each word must be pushed to the stack once and popped off once, the number of actions needed to parse a sentence is always 2 ∗ N , where N is the length of the sentence. Transition-based dependency parsing (Zhang and Clark, 2008) can be performed in either a leftto-right or a right-to-left way, both of which have a performance that is comparable as illustrated in Section 4. However, when they are applied to disfluency detection, their behaviors are very different due to the disfluency structure constraint. We prove that right-to-left transition-based parsing is more efficient than left-to-right transition-based parsing for disfluency detection. 3 As both the dependency tree and the disfluency tags are generated word by word, we decompose formula (3) into: (D∗ , T ∗ ) = argmax(D,T ) i=1 × P (di |W1i , T1i ) (5) n Y (D∗"
P15-1048,H05-1030,0,0.0216575,"es can be designed to tackle the former four classes of disfluencies since they often belong to a closed set. However, the repair type disfluency poses particularly more There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3 N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disflu495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics encies (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013). These methods"
P15-1048,P11-2033,0,0.292641,"ord “did” is obviously disfluent. Unlike UT model, the BCT will not link the word “did” to any word. Instead only a virtual link will add it to the virtual root. 3.4 In practice, we use the same linear model for both models (6) and (7) to score a parsing tree as: X Score(T ) = φ(action) · ~λ action Where φ(action) is the feature vector extracted from partial hypothesis T for a certain action and ~λ is the weight vector. φ(action) · ~λ calculates the score of a certain transition action. The score of a parsing tree T is the sum of action scores. In addition to the basic features introduced in (Zhang and Nivre, 2011) that are defined over bag of words and POS-tags as well as tree-based context, our models also integrate three classes of new features combined with Brown cluster features (Brown et al., 1992) that relate to the rightto-left transition-based parsing procedure as detailed below. Simple repetition function • δI (a, b): A logic function which indicates whether a and b are identical. great X Syntax-based repetition function Figure 3: An example of UT model, where ‘N’ means the word is a fluent word and ‘X’ means it is disfluent. Words with italic font are Reparandums. 3.3 Training and decoding •"
P15-1048,N06-2019,0,0.843419,"d that M3 N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3 N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfluencies. Miller and Schuler (2008) used a right corner transform of syntax trees to produce a syntactic tree with speech repairs. But their performance was not as good as labeling models. There exist two methods published recently which are similar to ours. Rasooli and Tetreault (2013) designed a joint model for both disfluency detection and dependency parsing. They regarded the two tasks as a two step classifications. Honnibal and Johnson (2014) presented a new joint model by extending the original tr"
P15-1048,P06-1071,0,0.023487,"to tackle the former four classes of disfluencies since they often belong to a closed set. However, the repair type disfluency poses particularly more There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3 N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disflu495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics encies (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013). These methods can jointly perform d"
P15-1048,P13-1074,1,0.851961,"i is the partial tree after word wi is consumed, di is the disfluency tag of wi . We simplify the joint optimization in a cascaded way with two different forms (5) and (6). n Y ∗ ∗ P (T1i |W1i , T1i−1 ) (D , T ) = argmax(D,T ) Model ∗ P (di , T1i |W1i , T1i−1 ) i=1 Our method 3.1 n Y argmaxD P (D1n |W1n ) Here, P (T1i |.) is the parsing model, and P (di |.) is the disfluency model used to predict the disluency tags on condition of the contexts of partial trees that have been built. In (5), the parsing model is calculated first, followed by the calculation of the disfluency model. Inspired by (Zhang et al., 2013), we associate the disfluency tags to the transition actions so that the calculation of P (di |W1i , T1i ) can be omitted as di can be inferred from the partial tree T1i . We then get ∗ ∗ (D , T ) = argmax(D,T ) n Y P (di , T1i |W1i , T1i−1 ) i=1 (1) The dependency parsing tree is introduced into model (1) to guide detection. The rewritten formula is shown below: X D∗ = argmaxD P (D1n , T |W1n ) (2) (7) Where the parsing and disfluency detection are unified into one model. We refer to this model as the Unified Transition(UT) model. While in (6), the disfluency model is calculated first, follow"
P15-1048,P11-1071,0,0.224498,"ork In practice, disfluency detection has been extensively studied in both speech processing field and natural language processing field. Noisy channel models have been widely used in the past to detect 501 previous work but also achieve significantly higher performance on disfluency detection as well as dependency parsing. disfluencies. Johnson and Charniak (2004) proposed a TAG-based noisy channel model where the TAG model was used to find rough copies. Thereafter, a language model and MaxEnt reranker were added to the noisy channel model by Johnson et al. (2004). Following their framework, Zwarts and Johnson (2011) extended this model using minimal expected f-loss oriented nbest reranking with additional corpus for language model training. 6 Conclusion and Future Work In this paper, we propose a novel approach for disfluency detection. Our models jointly perform parsing and disfluency detection from right to left by integrating a rich set of disfluency features which can yield parsing structure and difluency tags at the same time with linear complexity. The algorithm is easy to implement without complicated backtrack operations. Experiential results show that our approach outperforms the baselines on th"
P15-1048,J93-2004,0,0.0501048,"(p0 , ps ); NI (w0 , ws )NI (p0 , ps ); N# (w0..2 , ws )N# (p0..2 , ps ); δI (ws , w0 )ws c; δI (ws , w0 )w0 c; Function ws w0 δI (ws , w0 ); trigrams ws w0 δI (ps , p0 ); Table 1: Feature templates designed for disfluency detection and dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 4.1 Experiments Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development sets. We use the Stanford dependency converter (De Marneffe 4.2 4.2.1 Experimental results Performance of disfluency detection on English Swtichboard corpus The evaluation results of both disfluency detection and parsing accuracy are"
P15-1048,P05-1012,0,0.235242,"Missing"
P15-1048,P04-1005,0,\N,Missing
P18-1061,P15-2136,1,0.953154,"nh,mingzhou}@microsoft.com Abstract Sentence scoring aims to assign an importance score to each sentence, and has been broadly studied in many previous works. Feature-based methods are popular and have proven effective, such as word probability, TF*IDF weights, sentence position and sentence length features (Luhn, 1958; Hovy and Lin, 1998; Ren et al., 2017). Graph-based methods such as TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004) measure sentence importance using weighted-graphs. In recent years, neural network has also been applied to sentence modeling and scoring (Cao et al., 2015a; Ren et al., 2017). For the second step, sentence selection adopts a particular strategy to choose content sentence by sentence. Maximal Marginal Relevance (Carbonell and Goldstein, 1998) based methods select the sentence that has the maximal score and is minimally redundant with sentences already included in the summary. Integer Linear Programming based methods (McDonald, 2007) treat sentence selection as an optimization problem under some constraints such as summary length. Submodular functions (Lin and Bilmes, 2011) have also been applied to solving the optimization problem of finding the"
P18-1061,P16-1046,0,0.136097,"a sentence. Sentence selection is based on the scores of 655 sidering the DUC tasks have byte length limit for summaries. In this work, we adopt the CNN/Daily Mail dataset to train the neural network model, which does not have this length limit. To prevent the tendency of choosing longer sentences, we use ROUGE F1 as the evaluation function r(·), and set the length limit l as a fixed number of sentences. Therefore, the proposed model is trained to learn a scoring function g(·) of the ROUGE F1 gain, specifically: a two-level attention mechanism to measure the contextual relations of sentences. Cheng and Lapata (2016) propose treating document summarization as a sequence labeling task. They first encode the sentences in the document and then classify each sentence into two classes, i.e., extraction or not. Nallapati et al. (2017) propose a system called SummaRuNNer with more features, which also treat extractive document summarization as a sequence labeling task. The two works are both in the separated paradigm, as they first assign a probability of being extracted to each sentence, and then select sentences according to the probability until reaching the length limit. Ren et al. (2016) train two neural ne"
P18-1061,W09-1802,0,0.104755,"these methods, the input document is represented as a connected graph. The vertices represent the sentences, and the edges between vertices have attached weights that show the similarity of the two sentences. The score of a sentence is the importance of its corresponding vertex, which can be computed using graph algorithms. Machine learning techniques are also widely used for better sentence modeling and importance estimation. Kupiec et al. (1995) use a Naive Bayes classifier to learn feature combinations. Conroy and O’leary (2001) further use a Hidden Markov Model in document summarization. Gillick and Favre (2009) find that using bigram features consistently yields better performance than unigrams or trigrams for ROUGE (Lin, 2004) measures. Carbonell and Goldstein (1998) proposed the Maximal Marginal Relevance (MMR) method as a heuristic in sentence selection. Systems using MMR select the sentence which has the maximal score and is minimally redundant with previous selected sentences. McDonald (2007) treats sentence selection as an optimization problem under some constraints such as summary length. Therefore, he uses Integer Linear Programming (ILP) to solve this optimization problem. Sentence selectio"
P18-1061,P84-1044,0,0.585141,"Missing"
P18-1061,X98-1026,0,0.345759,"Summarization by Jointly Learning to Score and Select Sentences Qingyu Zhou†∗, Nan Yang‡ , Furu Wei‡ , Shaohan Huang‡ , Ming Zhou‡ , Tiejun Zhao† † Harbin Institute of Technology, Harbin, China ‡ Microsoft Research, Beijing, China {qyzhou,tjzhao}@hit.edu.cn {nanya,fuwei,shaohanh,mingzhou}@microsoft.com Abstract Sentence scoring aims to assign an importance score to each sentence, and has been broadly studied in many previous works. Feature-based methods are popular and have proven effective, such as word probability, TF*IDF weights, sentence position and sentence length features (Luhn, 1958; Hovy and Lin, 1998; Ren et al., 2017). Graph-based methods such as TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004) measure sentence importance using weighted-graphs. In recent years, neural network has also been applied to sentence modeling and scoring (Cao et al., 2015a; Ren et al., 2017). For the second step, sentence selection adopts a particular strategy to choose content sentence by sentence. Maximal Marginal Relevance (Carbonell and Goldstein, 1998) based methods select the sentence that has the maximal score and is minimally redundant with sentences already included in the summary"
P18-1061,D14-1162,0,0.0899533,"Missing"
P18-1061,W04-1013,0,0.342842,"ertices have attached weights that show the similarity of the two sentences. The score of a sentence is the importance of its corresponding vertex, which can be computed using graph algorithms. Machine learning techniques are also widely used for better sentence modeling and importance estimation. Kupiec et al. (1995) use a Naive Bayes classifier to learn feature combinations. Conroy and O’leary (2001) further use a Hidden Markov Model in document summarization. Gillick and Favre (2009) find that using bigram features consistently yields better performance than unigrams or trigrams for ROUGE (Lin, 2004) measures. Carbonell and Goldstein (1998) proposed the Maximal Marginal Relevance (MMR) method as a heuristic in sentence selection. Systems using MMR select the sentence which has the maximal score and is minimally redundant with previous selected sentences. McDonald (2007) treats sentence selection as an optimization problem under some constraints such as summary length. Therefore, he uses Integer Linear Programming (ILP) to solve this optimization problem. Sentence selection can also be seen as finding the optimal subset of sentences in a document. Lin and Bilmes (2011) propose using submod"
P18-1061,C16-1004,1,0.938489,"entence selection adopts a particular strategy to choose content sentence by sentence. Maximal Marginal Relevance (Carbonell and Goldstein, 1998) based methods select the sentence that has the maximal score and is minimally redundant with sentences already included in the summary. Integer Linear Programming based methods (McDonald, 2007) treat sentence selection as an optimization problem under some constraints such as summary length. Submodular functions (Lin and Bilmes, 2011) have also been applied to solving the optimization problem of finding the optimal subset of sentences in a document. Ren et al. (2016) train two neural networks with handcrafted features. One is used to rank sentences, and the other one is used to model redundancy during sentence selection. In this paper, we present a neural extractive document summarization (N EU S UM) framework which jointly learns to score and select sentences. Different from previous methods that treat sentence scoring and sentence selection as two tasks, our method integrates the two steps into one endto-end trainable model. Specifically, N EU S UM is a neural network model without any handcrafted features that learns to identify the relative importance"
P18-1061,P11-1052,0,0.101239,"years, neural network has also been applied to sentence modeling and scoring (Cao et al., 2015a; Ren et al., 2017). For the second step, sentence selection adopts a particular strategy to choose content sentence by sentence. Maximal Marginal Relevance (Carbonell and Goldstein, 1998) based methods select the sentence that has the maximal score and is minimally redundant with sentences already included in the summary. Integer Linear Programming based methods (McDonald, 2007) treat sentence selection as an optimization problem under some constraints such as summary length. Submodular functions (Lin and Bilmes, 2011) have also been applied to solving the optimization problem of finding the optimal subset of sentences in a document. Ren et al. (2016) train two neural networks with handcrafted features. One is used to rank sentences, and the other one is used to model redundancy during sentence selection. In this paper, we present a neural extractive document summarization (N EU S UM) framework which jointly learns to score and select sentences. Different from previous methods that treat sentence scoring and sentence selection as two tasks, our method integrates the two steps into one endto-end trainable mo"
P18-1061,P17-1099,0,0.785313,"bel the sentences in a given document similar to Nallapati et al. (2017). Specifically, we construct training data by maximizing the ROUGE-2 F1 score. Since it is computationally expensive to find the global optimal combination of sentences, we employ a greedy approach. Given a document with n sentences, we n enumerate the candidates  from 1-combination 1 n to n-combination n . We stopsearching if the n highest ROUGE-2  F1 score in k is less than the n best one in k−1 . Table 1 shows the data statistics of the CNN/Daily Mail dataset. We conduct data preprocessing using the same method2 in See et al. (2017), including sentence splitting and word tokenization. Both Nallapati et al. (2016, 2017) use the anonymized version of the data, where the named entities are replaced by identifiers such as entity4. Following See et al. (2017), we use the non-anonymized version so we can directly operate on the original text. Si ∈D 4.3 (20) Experiments 5.1 whereWm and bm are learnable parameters, and s~1 is the last backward state of the document level encoder BiGRU. Since we do not have any sentences extracted yet, we use a zero vector to represent the previous extracted sentence, i.e., s0 = 0. With the score"
P18-1061,W04-3252,0,0.790016,"∗, Nan Yang‡ , Furu Wei‡ , Shaohan Huang‡ , Ming Zhou‡ , Tiejun Zhao† † Harbin Institute of Technology, Harbin, China ‡ Microsoft Research, Beijing, China {qyzhou,tjzhao}@hit.edu.cn {nanya,fuwei,shaohanh,mingzhou}@microsoft.com Abstract Sentence scoring aims to assign an importance score to each sentence, and has been broadly studied in many previous works. Feature-based methods are popular and have proven effective, such as word probability, TF*IDF weights, sentence position and sentence length features (Luhn, 1958; Hovy and Lin, 1998; Ren et al., 2017). Graph-based methods such as TextRank (Mihalcea and Tarau, 2004) and LexRank (Erkan and Radev, 2004) measure sentence importance using weighted-graphs. In recent years, neural network has also been applied to sentence modeling and scoring (Cao et al., 2015a; Ren et al., 2017). For the second step, sentence selection adopts a particular strategy to choose content sentence by sentence. Maximal Marginal Relevance (Carbonell and Goldstein, 1998) based methods select the sentence that has the maximal score and is minimally redundant with sentences already included in the summary. Integer Linear Programming based methods (McDonald, 2007) treat sentence selection"
P18-1061,N06-2046,0,0.175732,"for Computational Linguistics sentences to determine which sentence should be extracted, which is usually done heuristically. Many techniques have been proposed to model and score sentences. Unsupervised methods do not require model training or data annotation. In these methods, many surface features are useful, such as term frequency (Luhn, 1958), TF*IDF weights (Erkan and Radev, 2004), sentence length (Cao et al., 2015a) and sentence positions (Ren et al., 2017). These features can be used alone or combined with weights. Graph-based methods (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Wan and Yang, 2006) are also applied broadly to ranking sentences. In these methods, the input document is represented as a connected graph. The vertices represent the sentences, and the edges between vertices have attached weights that show the similarity of the two sentences. The score of a sentence is the importance of its corresponding vertex, which can be computed using graph algorithms. Machine learning techniques are also widely used for better sentence modeling and importance estimation. Kupiec et al. (1995) use a Naive Bayes classifier to learn feature combinations. Conroy and O’leary (2001) further use"
P18-1061,K16-1028,0,0.224849,"Missing"
P18-1116,P17-2021,0,0.394426,"forest-based NMT method that translates a linearized packed forest under a simple sequence-to-sequence framework (i.e., a forest-to-string NMT model). The BLEU score of the proposed method is higher than that of the string-to-string NMT, treebased NMT, and forest-based SMT systems. 1 Introduction NMT has witnessed promising improvements recently. Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017). Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features. They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017). ∗ Contribution during internship at National Institute of Information and Communications Technology. † Corresponding author Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays. Based on how to represent trees, there are two main categories of tree-ba"
P18-1116,P05-1022,0,0.250252,"Missing"
P18-1116,P17-1177,0,0.21255,"e used beam search, and fixed the beam size to 12. For the case of Forest (SoA), with 1 core of Tesla K80 GPU and LDC corpus as the training data, training spent about 10 days, and decoding speed is about 10 sentences per second. 5 https://nlp.stanford.edu/software/ stanford-segmenter-2017-06-09.zip 6 http://lotus.kuee.kyoto-u.ac.jp/WAT/ WAT2017/baseline/dataPreparationJE.html 7 LDC2002E18, LDC2003E07, LDC2003E14, Hansards portion of LDC2004T07, LDC2004T08, and LDC2005T06 8 https://github.com/EdinburghNLP/ nematus Types FS TN FN Systems & Configurations Mi et al. (2008) Eriguchi et al. (2016) Chen et al. (2017) Li et al. (2017) s2s 1-best (No score) 1-best (SoE) 1-best (SoA) Forest (No score) Forest (SoE) Forest (SoA) MT 03 FBIS LDC 27.10 28.21 29.00 29.71 28.34 29.64 28.40 29.60 27.44 29.18 28.61 29.38 28.78 30.65 29.39 30.80 28.06 29.63 29.58 31.07 29.63 31.35 MT 04 FBIS LDC 28.67 30.09 30.24 31.56 30.00 31.25 29.66 31.96 29.73 30.53 30.07 31.58 30.36 32.22 30.25 32.39 29.51 31.41 30.67 32.69 30.31 33.14 MT 05 FBIS LDC 26.57 28.36 28.38 30.33 28.14 29.59 27.74 29.84 27.32 28.80 28.59 30.01 29.31 30.16 29.30 30.61 28.48 29.75 29.26 30.41 29.87 31.23 p value < 0.01 < 0.05 < 0.005 < 0.01 < 0.001 < 0."
P18-1116,N16-1024,0,0.362868,"more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017). ∗ Contribution during internship at National Institute of Information and Communications Technology. † Corresponding author Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays. Based on how to represent trees, there are two main categories of tree-based NMT methods: representing trees by a tree-structured neural network (Eriguchi et al., 2016; Zaremoodi and Haffari, 2017), representing trees by linearization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017). Compared with the former, the latter method has a relatively simple model structure, so that a larger corpus can be used for training and the model can be trained within reasonable time, hence is preferred from the viewpoint of computation. Therefore we focus on this kind of methods in this paper. In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006). For SMT, forest"
P18-1116,P16-1078,0,0.358869,"f approach has not been attempted. This paper proposes a forest-based NMT method that translates a linearized packed forest under a simple sequence-to-sequence framework (i.e., a forest-to-string NMT model). The BLEU score of the proposed method is higher than that of the string-to-string NMT, treebased NMT, and forest-based SMT systems. 1 Introduction NMT has witnessed promising improvements recently. Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017). Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features. They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017). ∗ Contribution during internship at National Institute of Information and Communications Technology. † Corresponding author Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays. Based on ho"
P18-1116,P17-2012,0,0.0416471,"ked forest with a forest-structured neural network. However, their method was evaluated in small-scale MT settings (each training dataset consists of under 10k parallel sentences). In contrast, our proposed method is effective in a largescale MT setting, and we present qualitative analysis regarding the effectiveness of using forests in NMT. Although these methods obtained good results, the tree-structured network used by the encoder made the training and decoding relatively slow, therefore restricts the scope of application. Other attempts at encoding syntactic trees have also been proposed. Eriguchi et al. (2017) combined the Recurrent Neural Network Grammar (Dyer et al., 2016) with NMT systems, while Li et al. (2017) linearized the constituent tree and encoded it using RNNs. The training of these methods is fast, because of the linear structures of RNNs. However, all these syntax-based NMT systems used only the 1-best parsing tree, making the systems sensitive to parsing errors. Instead of using trees to represent syntactic information, some studies use other data structures to represent the latent syntax of the input sentence. For example, Hashimoto and Tsuruoka (2017) proposed translating using a l"
P18-1116,D17-1012,0,0.034678,"Missing"
P18-1116,P08-1067,0,0.492245,"relatively simple model structure, so that a larger corpus can be used for training and the model can be trained within reasonable time, hence is preferred from the viewpoint of computation. Therefore we focus on this kind of methods in this paper. In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006). For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008). But for NMT, (computationally efficient) forestbased methods are still being explored1 . Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest. This hinders the development of forest-based NMT to some extent. Inspired by the tree-based NMT methods based on linearization, we propose an efficient forestbased NMT a"
P18-1116,W04-3250,0,0.0752847,"29.63 31.35 MT 04 FBIS LDC 28.67 30.09 30.24 31.56 30.00 31.25 29.66 31.96 29.73 30.53 30.07 31.58 30.36 32.22 30.25 32.39 29.51 31.41 30.67 32.69 30.31 33.14 MT 05 FBIS LDC 26.57 28.36 28.38 30.33 28.14 29.59 27.74 29.84 27.32 28.80 28.59 30.01 29.31 30.16 29.30 30.61 28.48 29.75 29.26 30.41 29.87 31.23 p value < 0.01 < 0.05 < 0.005 < 0.01 < 0.001 < 0.001 Table 2: English-Chinese experimental results (character-level BLEU). “FS,” “TN,” and “FN” denote forest-based SMT, tree-based NMT, and forest-based NMT systems, respectively. We performed the paired bootstrap resampling significance test (Koehn, 2004) over the NIST MT 03 to 05 corpus, with respect to the s2s baseline, and list the p values in the table. Types FS TN FN Systems & Configurations Mi et al. (2008) Eriguchi et al. (2016) Chen et al. (2017) Li et al. (2017) s2s 1-best (No score) 1-best (SoE) 1-best (SoA) Forest (No score) Forest (SoE) Forest (SoA) BLEU (test) 34.13 37.52 36.94 36.21 37.10 38.01 38.53 39.42 37.92 41.35 42.17 p value < 0.05 < 0.01 < 0.001 < 0.1 < 0.01 < 0.005 Table 3: English-Japanese experimental results (character-level BLEU). 4.2 Experimental results Table 2 and 3 summarize the experimental results. To avoid the"
P18-1116,P17-1064,0,0.139505,"reebased NMT, and forest-based SMT systems. 1 Introduction NMT has witnessed promising improvements recently. Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017). Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features. They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017). ∗ Contribution during internship at National Institute of Information and Communications Technology. † Corresponding author Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays. Based on how to represent trees, there are two main categories of tree-based NMT methods: representing trees by a tree-structured neural network (Eriguchi et al., 2016; Zaremoodi and Haffari, 2017), representing trees by linearization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017). Compare"
P18-1116,J93-2004,0,0.0609437,"endency labels and the sequence of words simultaneously, partially utilizing the syntax information, while Li et al. (2017) traversed the constituent tree of the source sentence and combined this with the word sequence, utilizing the syntax information completely. Regarding the linearization used for string-totree NMT (i.e., linearization of the target side), Nadejde et al. (2017) used a CCG supertag sequence as the target sequence, while Aharoni and Goldberg (2017) applied a linearization method in a top-down manner, generating a sequence ensemble for the annotated tree in the Penn Treebank (Marcus et al., 1993). Wu et al. (2017) used transition actions to linearize a dependency tree, and employed the sequence-to-sequence framework for NMT. It can be seen all current tree-based NMT systems use only one tree for encoding or decoding. In contrast, we hope to utilize multiple trees (i.e., a forest). This is not trivial, on account of the lack of a fixed traversal order and the need for a compact representation. 2.3 Packed forest The packed forest gives a representation of exponentially many parsing trees, and can compactly encode many more candidates than the n-best list S [11] [9] S0,5 NP 5.8665 VP NNP"
P18-1116,D08-1022,0,0.0348446,"within reasonable time, hence is preferred from the viewpoint of computation. Therefore we focus on this kind of methods in this paper. In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006). For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008). But for NMT, (computationally efficient) forestbased methods are still being explored1 . Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest. This hinders the development of forest-based NMT to some extent. Inspired by the tree-based NMT methods based on linearization, we propose an efficient forestbased NMT approach (Section 3), which can en1 Zaremoodi and Haffari (2017) have proposed a forestbased NMT method based on a fores"
P18-1116,P08-1023,0,0.164271,"el can be trained within reasonable time, hence is preferred from the viewpoint of computation. Therefore we focus on this kind of methods in this paper. In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006). For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008). But for NMT, (computationally efficient) forestbased methods are still being explored1 . Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest. This hinders the development of forest-based NMT to some extent. Inspired by the tree-based NMT methods based on linearization, we propose an efficient forestbased NMT approach (Section 3), which can en1 Zaremoodi and Haffari (2017) have proposed a forestbased NMT me"
P18-1116,P02-1040,0,0.100987,"es in the table. Types FS TN FN Systems & Configurations Mi et al. (2008) Eriguchi et al. (2016) Chen et al. (2017) Li et al. (2017) s2s 1-best (No score) 1-best (SoE) 1-best (SoA) Forest (No score) Forest (SoE) Forest (SoA) BLEU (test) 34.13 37.52 36.94 36.21 37.10 38.01 38.53 39.42 37.92 41.35 42.17 p value < 0.05 < 0.01 < 0.001 < 0.1 < 0.01 < 0.005 Table 3: English-Japanese experimental results (character-level BLEU). 4.2 Experimental results Table 2 and 3 summarize the experimental results. To avoid the affect of segmentation errors, the performance were evaluated by character-level BLEU (Papineni et al., 2002). We compare our proposed models (i.e., Forest (SoE) and Forest (SoA)) with three types of baseline: a string-to-string model (s2s), forest-based models that do not use score sequences (Forest (No score)), and tree-based models that use the 1-best parsing tree (1-best (No score, SoE, SoA)). For the 1-best models, we preserve the nodes and hyperedges that are used in the 1-best constituent tree in the packed forest, and remove all other nodes and hyperedges, yielding a pruned forest that contains only the 1-best constituent tree. For the “No score” configurations, we force the input score seque"
P18-1116,W06-1608,0,0.0520192,"ization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017). Compared with the former, the latter method has a relatively simple model structure, so that a larger corpus can be used for training and the model can be trained within reasonable time, hence is preferred from the viewpoint of computation. Therefore we focus on this kind of methods in this paper. In spite of impressive performance of tree-based NMT systems, they suffer from a major drawback: they only use the 1-best parse tree to direct the translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006). For SMT, forest-based methods have employed a packed forest to address this problem (Huang, 2008), which represents exponentially many parse trees rather than just the 1-best one (Mi et al., 2008; Mi and Huang, 2008). But for NMT, (computationally efficient) forestbased methods are still being explored1 . Because of the structural complexity of forests, the inexistence of appropriate topological ordering, and the hyperedge-attachment nature of weights (see Section 3.1 for details), it is not trivial to linearize a forest. This hinders the development of forest-based NMT to some extent. Inspi"
P18-1116,E17-3017,0,0.054061,"Missing"
P18-1116,W16-2209,0,0.0382625,"n states of the source-side RNN and target-side RNN, respectively, c is the context vector, and et is the embedding of xt . Bahdanau et al. (2014) introduced an attention mechanism to deal with the issues related to long sequences (Cho et al., 2014). Instead of encoding the source sequence into a fixed vector c, the attention model uses different ci -s when calculating ci = T X αij hj , (6) j=0 exp(a(si−1 , hj )) αij = PT . k=0 exp(a(si−1 , hk )) 2.2 (7) Linear-structured tree-based NMT systems Regarding the linearization adopted for tree-tostring NMT (i.e., linearization of the source side), Sennrich and Haddow (2016) encoded the sequence of dependency labels and the sequence of words simultaneously, partially utilizing the syntax information, while Li et al. (2017) traversed the constituent tree of the source sentence and combined this with the word sequence, utilizing the syntax information completely. Regarding the linearization used for string-totree NMT (i.e., linearization of the target side), Nadejde et al. (2017) used a CCG supertag sequence as the target sequence, while Aharoni and Goldberg (2017) applied a linearization method in a top-down manner, generating a sequence ensemble for the annotated"
P18-1116,P15-1150,0,0.0449153,"Missing"
P18-1116,P17-1065,0,0.0199032,"sequence of words simultaneously, partially utilizing the syntax information, while Li et al. (2017) traversed the constituent tree of the source sentence and combined this with the word sequence, utilizing the syntax information completely. Regarding the linearization used for string-totree NMT (i.e., linearization of the target side), Nadejde et al. (2017) used a CCG supertag sequence as the target sequence, while Aharoni and Goldberg (2017) applied a linearization method in a top-down manner, generating a sequence ensemble for the annotated tree in the Penn Treebank (Marcus et al., 1993). Wu et al. (2017) used transition actions to linearize a dependency tree, and employed the sequence-to-sequence framework for NMT. It can be seen all current tree-based NMT systems use only one tree for encoding or decoding. In contrast, we hope to utilize multiple trees (i.e., a forest). This is not trivial, on account of the lack of a fixed traversal order and the need for a compact representation. 2.3 Packed forest The packed forest gives a representation of exponentially many parsing trees, and can compactly encode many more candidates than the n-best list S [11] [9] S0,5 NP 5.8665 VP NNP VBZ John has VP1,"
P18-1116,P17-1139,0,0.026196,"itnessed promising improvements recently. Depending on the types of input and output, these efforts can be divided into three categories: string-to-string systems (Sutskever et al., 2014; Bahdanau et al., 2014); tree-to-string systems (Eriguchi et al., 2016, 2017); and string-totree systems (Aharoni and Goldberg, 2017; Nadejde et al., 2017). Compared with string-to-string systems, tree-to-string and string-to-tree systems (henceforth, tree-based systems) offer some attractive features. They can use more syntactic information (Li et al., 2017), and can conveniently incorporate prior knowledge (Zhang et al., 2017). ∗ Contribution during internship at National Institute of Information and Communications Technology. † Corresponding author Because of these advantages, tree-based methods become the focus of many researches of NMT nowadays. Based on how to represent trees, there are two main categories of tree-based NMT methods: representing trees by a tree-structured neural network (Eriguchi et al., 2016; Zaremoodi and Haffari, 2017), representing trees by linearization (Vinyals et al., 2015; Dyer et al., 2016; Ma et al., 2017). Compared with the former, the latter method has a relatively simple model stru"
P19-1119,D16-1250,0,0.0277561,"ods that train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods significantly outperform conventional UNMT. 1 • 1) There is a positive correlation between the quality of the pre-trained UBWE and the performance of UNMT. • 2) The UBWE quality significantly decreases during UNMT training. Introduction Since 2013, neural network based bilingual word embedding (BWE) has been applied to several natural language processing tasks (Mikolov et al., 2013; Faruqui and Dyer, 2014; Xing et al., 2015; Dinu et al., 2015; Lu et al., 2015; Wang et al., 2016; Artetxe et al., 2016; Smith et al., 2017; Wang et al., 2018). Recently, researchers have found that supervision is not always necessary (Cao et al., 2016; Zhang et al., 2017). Several unsupervised BWE (UBWE) methods (Conneau et al., 2018; Artetxe et al., 2018a) have been proposed and these have achieved impressive performance in wordtranslation tasks. The success of UBWE makes unsupervised neural machine translation (UNMT) possible. The combination of UBWE with denoising autoencoder and back-translation has ∗ Haipeng Sun was an internship research fellow at NICT when conducting this work. Based on these two findi"
P19-1119,P17-1042,0,0.0444313,"The supervised BWE (Mikolov et al., 2013), which exploits similarities between the source language and the target language through a linear transformation matrix, serves as the basis for many NLP tasks, such as machine translation (Bahdanau et al., 2015; Vaswani et al., 2017; Chen et al., 2018b; Zhang and Zhao, 2019), dependency parsing (Zhang et al., 2016; Li et al., 2018), semantic role labeling (He et al., 2018; Li et al., 2019). However, the lack of a large wordpair dictionary poses a major practical problem for many language pairs. UBWE has attracted considerable attention. For example, Artetxe et al. (2017) proposed a self-learning framework to learn BWE with a 25-word dictionary, and Artetxe et al. (2018a) extended previous work without any word dictionary via fully unsupervised initialization. Zhang et al. (2017) and Conneau et al. (2018) proposed UBWE methods via generative adversarial network training. Recently, several UBWE methods (Conneau et al., 2018; Artetxe et al., 2018a) have been applied to UNMT (Artetxe et al., 2018c; Lample et al., 2018a). These rely solely on monolingual corpora in each language via UBWE initialization, denoising auto-encoder, and back-translation. A shared encode"
P19-1119,P18-1073,0,0.117216,"BWE and the performance of UNMT. • 2) The UBWE quality significantly decreases during UNMT training. Introduction Since 2013, neural network based bilingual word embedding (BWE) has been applied to several natural language processing tasks (Mikolov et al., 2013; Faruqui and Dyer, 2014; Xing et al., 2015; Dinu et al., 2015; Lu et al., 2015; Wang et al., 2016; Artetxe et al., 2016; Smith et al., 2017; Wang et al., 2018). Recently, researchers have found that supervision is not always necessary (Cao et al., 2016; Zhang et al., 2017). Several unsupervised BWE (UBWE) methods (Conneau et al., 2018; Artetxe et al., 2018a) have been proposed and these have achieved impressive performance in wordtranslation tasks. The success of UBWE makes unsupervised neural machine translation (UNMT) possible. The combination of UBWE with denoising autoencoder and back-translation has ∗ Haipeng Sun was an internship research fellow at NICT when conducting this work. Based on these two findings, we hypothesize that the learning of UNMT with UBWE agreement would enhance UNMT performance. In detail, we propose two approaches, UBWE agreement regularization and UBWE adversarial training, to maintain the quality of UBWE during NMT"
P19-1119,D18-1399,0,0.0466684,"Missing"
P19-1119,P19-1019,0,0.0982651,"Missing"
P19-1119,J82-2005,0,0.756838,"Missing"
P19-1119,Q17-1010,0,0.039396,"UNMT Baseline + UBWE agreement regularization + UBWE adversarial training De-En n/a 13.33 14.62 21.0 21.23 22.38++ 22.67++ En-De n/a 9.64 10.86 17.2 17.06 18.04++ 18.29++ Fr-En 15.56 14.31 15.58 24.2 24.50 25.21++ 25.87++ En-Fr 15.13 15.05 16.97 25.1 25.37 27.86++ 28.38++ Ja-En n/a n/a n/a n/a 14.09 16.36++ 17.22++ En-Ja n/a n/a n/a n/a 21.63 23.01++ 23.64++ Table 2: Performance (BLEU score) of UNMT. “++” after a score indicates that the proposed method was significantly better than the UNMT baseline at significance level p <0.01. the embeddings for each language independently with fastText3 (Bojanowski et al., 2017) (default settings). The word embeddings were normalized by length and mean centered before bilingual projection. We then used VecMap4 (Artetxe et al., 2018a) (default settings) to project two monolingual word embeddings into one space. To evaluate the quality of UBWE, we selected the accuracy of word translation using the top-1 predicted candidate in the MUSE test set as the criterion. 5.3 UNMT Settings In the training process for UNMT, we used the transformer-based UNMT toolkit5 and the settings of Lample et al. (2018b). That is, we used four 3 https://github.com/facebookresearch/ fastText 4"
P19-1119,C16-1171,1,0.803699,"orm conventional UNMT. 1 • 1) There is a positive correlation between the quality of the pre-trained UBWE and the performance of UNMT. • 2) The UBWE quality significantly decreases during UNMT training. Introduction Since 2013, neural network based bilingual word embedding (BWE) has been applied to several natural language processing tasks (Mikolov et al., 2013; Faruqui and Dyer, 2014; Xing et al., 2015; Dinu et al., 2015; Lu et al., 2015; Wang et al., 2016; Artetxe et al., 2016; Smith et al., 2017; Wang et al., 2018). Recently, researchers have found that supervision is not always necessary (Cao et al., 2016; Zhang et al., 2017). Several unsupervised BWE (UBWE) methods (Conneau et al., 2018; Artetxe et al., 2018a) have been proposed and these have achieved impressive performance in wordtranslation tasks. The success of UBWE makes unsupervised neural machine translation (UNMT) possible. The combination of UBWE with denoising autoencoder and back-translation has ∗ Haipeng Sun was an internship research fellow at NICT when conducting this work. Based on these two findings, we hypothesize that the learning of UNMT with UBWE agreement would enhance UNMT performance. In detail, we propose two approache"
P19-1119,D17-1304,1,0.782183,"Missing"
P19-1119,C18-1271,0,0.0472765,"seline UBWE agreement regularization UBWE adversarial training Parameters 120,141K 120,141K 120,764K Speed 3784 3741 3733 Table 4: Analysis on parameters and training speed (number of processed words per second on one P100). 7 Related Work The supervised BWE (Mikolov et al., 2013), which exploits similarities between the source language and the target language through a linear transformation matrix, serves as the basis for many NLP tasks, such as machine translation (Bahdanau et al., 2015; Vaswani et al., 2017; Chen et al., 2018b; Zhang and Zhao, 2019), dependency parsing (Zhang et al., 2016; Li et al., 2018), semantic role labeling (He et al., 2018; Li et al., 2019). However, the lack of a large wordpair dictionary poses a major practical problem for many language pairs. UBWE has attracted considerable attention. For example, Artetxe et al. (2017) proposed a self-learning framework to learn BWE with a 25-word dictionary, and Artetxe et al. (2018a) extended previous work without any word dictionary via fully unsupervised initialization. Zhang et al. (2017) and Conneau et al. (2018) proposed UBWE methods via generative adversarial network training. Recently, several UBWE methods (Conneau et al., 20"
P19-1119,E14-1049,0,0.0395704,"erformance of UNMT is significantly affected by the performance of UBWE. Thus, we propose two methods that train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods significantly outperform conventional UNMT. 1 • 1) There is a positive correlation between the quality of the pre-trained UBWE and the performance of UNMT. • 2) The UBWE quality significantly decreases during UNMT training. Introduction Since 2013, neural network based bilingual word embedding (BWE) has been applied to several natural language processing tasks (Mikolov et al., 2013; Faruqui and Dyer, 2014; Xing et al., 2015; Dinu et al., 2015; Lu et al., 2015; Wang et al., 2016; Artetxe et al., 2016; Smith et al., 2017; Wang et al., 2018). Recently, researchers have found that supervision is not always necessary (Cao et al., 2016; Zhang et al., 2017). Several unsupervised BWE (UBWE) methods (Conneau et al., 2018; Artetxe et al., 2018a) have been proposed and these have achieved impressive performance in wordtranslation tasks. The success of UBWE makes unsupervised neural machine translation (UNMT) possible. The combination of UBWE with denoising autoencoder and back-translation has ∗ Haipeng S"
P19-1119,P18-1192,0,0.062598,"adversarial training Parameters 120,141K 120,141K 120,764K Speed 3784 3741 3733 Table 4: Analysis on parameters and training speed (number of processed words per second on one P100). 7 Related Work The supervised BWE (Mikolov et al., 2013), which exploits similarities between the source language and the target language through a linear transformation matrix, serves as the basis for many NLP tasks, such as machine translation (Bahdanau et al., 2015; Vaswani et al., 2017; Chen et al., 2018b; Zhang and Zhao, 2019), dependency parsing (Zhang et al., 2016; Li et al., 2018), semantic role labeling (He et al., 2018; Li et al., 2019). However, the lack of a large wordpair dictionary poses a major practical problem for many language pairs. UBWE has attracted considerable attention. For example, Artetxe et al. (2017) proposed a self-learning framework to learn BWE with a 25-word dictionary, and Artetxe et al. (2018a) extended previous work without any word dictionary via fully unsupervised initialization. Zhang et al. (2017) and Conneau et al. (2018) proposed UBWE methods via generative adversarial network training. Recently, several UBWE methods (Conneau et al., 2018; Artetxe et al., 2018a) have been appl"
P19-1119,N16-1162,0,0.097674,"Missing"
P19-1119,N15-1028,0,0.0983804,"Missing"
P19-1119,W18-6419,1,0.821417,"ur method. In addition, an alternative unsupervised method based on statistical machine translation (SMT) was proposed (Lample et al., 2018b; Artetxe et al., 2018b). The unsupervised machine translation performance was improved through combining UNMT and unsupervised SMT (Marie and Fujita, 2018; Ren et al., 2019; Artetxe et al., 2019). More recently, Lample and Conneau (2019) achieved 1242 better UNMT performance through introducing the pretrained language model. Neural network based language model has been shown helpful in supervised machine translation (Wang et al., 2014; Wang et al., 2018; Marie et al., 2018). We think that the proposed agreement mechanism can work with the pretrained language model. 8 Conclusion UBWE is a fundamental component of UNMT. In previous methods, the pre-trained UBWE is only used to initialize the word embedding of UNMT. In this study, we found that the performance of UNMT is significantly affected by the quality of UBWE, not only in the initialization stage, but also during UNMT training. Based on this finding, we proposed two joint learning methods to train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods can mitigat"
P19-1119,P16-1009,0,0.124354,"et al., 2016). The denoising auto-encoder, which encodes a noisy version and reconstructs it with the decoder in the same language, is optimized by minimizing the Lauto = EX∼φL1 [−logPL1 →L1 (X|C(X)] + EY ∼φL2 [−logPL2 →L2 (Y |C(Y )], (2) where C(X) and C(Y ) are noisy versions of sentences X and Y , PL1 →L1 (PL2 →L2 ) denotes the reconstruction probability in the language L1 (L2 ). 2.3 Back-translation The denoising auto-encoder acts as a language model that has been trained in one language and does not consider the final goal of translating between two languages. Therefore, backtranslation (Sennrich et al., 2016) was adapted to train translation systems in a true translation setting based on monolingual corpora. Formally, given the sentences X and Y , the sentences YP (X) and XP (Y ) would be produced by the model at the previous iteration. The pseudo-parallel sentence pair (YP (X), X) and (XP (Y ), Y ) would be obtained to train the new translation model. Finally, the back-translation process is optimized by minimizing the following objective function: Lbt = EX∼φL1 [−logPL2 →L1 (X|YP (X)] + EY ∼φL2 [−logPL1 →L2 (Y |XP (Y )], (3) where PL1 →L2 (PL2 →L1 ) denotes the translation probability across two"
P19-1119,P18-1072,0,0.043009,"Missing"
P19-1119,P17-1179,0,0.327433,"NMT. 1 • 1) There is a positive correlation between the quality of the pre-trained UBWE and the performance of UNMT. • 2) The UBWE quality significantly decreases during UNMT training. Introduction Since 2013, neural network based bilingual word embedding (BWE) has been applied to several natural language processing tasks (Mikolov et al., 2013; Faruqui and Dyer, 2014; Xing et al., 2015; Dinu et al., 2015; Lu et al., 2015; Wang et al., 2016; Artetxe et al., 2016; Smith et al., 2017; Wang et al., 2018). Recently, researchers have found that supervision is not always necessary (Cao et al., 2016; Zhang et al., 2017). Several unsupervised BWE (UBWE) methods (Conneau et al., 2018; Artetxe et al., 2018a) have been proposed and these have achieved impressive performance in wordtranslation tasks. The success of UBWE makes unsupervised neural machine translation (UNMT) possible. The combination of UBWE with denoising autoencoder and back-translation has ∗ Haipeng Sun was an internship research fellow at NICT when conducting this work. Based on these two findings, we hypothesize that the learning of UNMT with UBWE agreement would enhance UNMT performance. In detail, we propose two approaches, UBWE agreement reg"
P19-1119,P16-1131,0,0.0253662,"eed of the model. Baseline UBWE agreement regularization UBWE adversarial training Parameters 120,141K 120,141K 120,764K Speed 3784 3741 3733 Table 4: Analysis on parameters and training speed (number of processed words per second on one P100). 7 Related Work The supervised BWE (Mikolov et al., 2013), which exploits similarities between the source language and the target language through a linear transformation matrix, serves as the basis for many NLP tasks, such as machine translation (Bahdanau et al., 2015; Vaswani et al., 2017; Chen et al., 2018b; Zhang and Zhao, 2019), dependency parsing (Zhang et al., 2016; Li et al., 2018), semantic role labeling (He et al., 2018; Li et al., 2019). However, the lack of a large wordpair dictionary poses a major practical problem for many language pairs. UBWE has attracted considerable attention. For example, Artetxe et al. (2017) proposed a self-learning framework to learn BWE with a 25-word dictionary, and Artetxe et al. (2018a) extended previous work without any word dictionary via fully unsupervised initialization. Zhang et al. (2017) and Conneau et al. (2018) proposed UBWE methods via generative adversarial network training. Recently, several UBWE methods ("
P19-1119,C18-1269,0,0.0524389,"Missing"
P19-1119,D14-1023,1,0.81634,"s initialization process for UBWE in our method. In addition, an alternative unsupervised method based on statistical machine translation (SMT) was proposed (Lample et al., 2018b; Artetxe et al., 2018b). The unsupervised machine translation performance was improved through combining UNMT and unsupervised SMT (Marie and Fujita, 2018; Ren et al., 2019; Artetxe et al., 2019). More recently, Lample and Conneau (2019) achieved 1242 better UNMT performance through introducing the pretrained language model. Neural network based language model has been shown helpful in supervised machine translation (Wang et al., 2014; Wang et al., 2018; Marie et al., 2018). We think that the proposed agreement mechanism can work with the pretrained language model. 8 Conclusion UBWE is a fundamental component of UNMT. In previous methods, the pre-trained UBWE is only used to initialize the word embedding of UNMT. In this study, we found that the performance of UNMT is significantly affected by the quality of UBWE, not only in the initialization stage, but also during UNMT training. Based on this finding, we proposed two joint learning methods to train UNMT with UBWE agreement. Empirical results on several language pairs sh"
P19-1119,N15-1104,0,0.0375279,"gnificantly affected by the performance of UBWE. Thus, we propose two methods that train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods significantly outperform conventional UNMT. 1 • 1) There is a positive correlation between the quality of the pre-trained UBWE and the performance of UNMT. • 2) The UBWE quality significantly decreases during UNMT training. Introduction Since 2013, neural network based bilingual word embedding (BWE) has been applied to several natural language processing tasks (Mikolov et al., 2013; Faruqui and Dyer, 2014; Xing et al., 2015; Dinu et al., 2015; Lu et al., 2015; Wang et al., 2016; Artetxe et al., 2016; Smith et al., 2017; Wang et al., 2018). Recently, researchers have found that supervision is not always necessary (Cao et al., 2016; Zhang et al., 2017). Several unsupervised BWE (UBWE) methods (Conneau et al., 2018; Artetxe et al., 2018a) have been proposed and these have achieved impressive performance in wordtranslation tasks. The success of UBWE makes unsupervised neural machine translation (UNMT) possible. The combination of UBWE with denoising autoencoder and back-translation has ∗ Haipeng Sun was an internshi"
P19-1119,P18-1005,0,0.321075,"racy Base-Fr enc-En dec AR-Fr-En AR-Fr enc-En dec AT-Fr-En UBWEAT-Fr accuracy enc-En dec AR-Fr-En BLEU 20 40 60 80 100 120 140 Epoch Base-Ja-En UBWE accuracy UBWE accuracy Base-Ja enc-En dec AR-Ja-En AR-Ja enc-En dec Base-Fr-En BLEU AT-Ja-En UBWE AT-Ja accuracy enc-En dec AT-Fr-En BLEU AR-Ja-En BLEU (a) Fr-En Base-Ja-En BLEU AT-Ja-En BLEU (b) Ja-En Figure 4: The trends of UBWE quality and BLEU score for baseline (Base), UBWE agreement regularization (AR), and UBWE adversarial training (AT) during UNMT training on the Fr-En and Ja-En dataset Methods Artetxe et al. (2018c) Lample et al. (2018a) Yang et al. (2018) Lample et al. (2018b) UNMT Baseline + UBWE agreement regularization + UBWE adversarial training De-En n/a 13.33 14.62 21.0 21.23 22.38++ 22.67++ En-De n/a 9.64 10.86 17.2 17.06 18.04++ 18.29++ Fr-En 15.56 14.31 15.58 24.2 24.50 25.21++ 25.87++ En-Fr 15.13 15.05 16.97 25.1 25.37 27.86++ 28.38++ Ja-En n/a n/a n/a n/a 14.09 16.36++ 17.22++ En-Ja n/a n/a n/a n/a 21.63 23.01++ 23.64++ Table 2: Performance (BLEU score) of UNMT. “++” after a score indicates that the proposed method was significantly better than the UNMT baseline at significance level p <0.01. the embeddings for each language indepen"
P19-1296,D17-1304,1,0.807793,"Missing"
P19-1296,I17-1002,1,0.860783,"Missing"
P19-1296,P18-1192,0,0.0281199,"mize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance. 1 Introduction Neural network based methods have been applied to several natural language processing tasks (Zhang et al., 2016; Li et al., 2018; Chen et al., 2018; Li et al., 2019; He et al., 2018). In neural machine translation (NMT), unlike conventional phrase-based statistical machine translation, an attention mechanism is adopted to help align output with input words (Bahdanau et al., 2015). It is based on the estimation of a probability distribution over all input words for each target word. However, source and target words are in different representation space, and they still have to go through a long information processing procedure that may lead to the source words are incorrectly translated into the target words. ∗ Mingming Yang was an internship research fellow at NICT when co"
P19-1296,P18-1164,0,0.250005,"conventional phrase-based statistical machine translation, an attention mechanism is adopted to help align output with input words (Bahdanau et al., 2015). It is based on the estimation of a probability distribution over all input words for each target word. However, source and target words are in different representation space, and they still have to go through a long information processing procedure that may lead to the source words are incorrectly translated into the target words. ∗ Mingming Yang was an internship research fellow at NICT when conducting this work. Based on this hypothesis, Kuang et al. (2018) proposed a direct bridging model, which directly connects source and target word embeddings seeking to minimize errors in the translation. Tu et al. (2017) incorporated a reconstructor module into NMT, which reconstructs the input source sentence from the hidden layer of the output target sentence to enhance source representation. However, in previous studies, the training objective function was usually based on word-level and lacked explicit sentencelevel relationships (Zhang and Zhao, 2019). Although Transformer model (Vaswani et al., 2017) has archived state-of-the-art performance of NMT,"
P19-1296,C18-1271,0,0.0150768,"ose a sentencelevel agreement module to directly minimize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance. 1 Introduction Neural network based methods have been applied to several natural language processing tasks (Zhang et al., 2016; Li et al., 2018; Chen et al., 2018; Li et al., 2019; He et al., 2018). In neural machine translation (NMT), unlike conventional phrase-based statistical machine translation, an attention mechanism is adopted to help align output with input words (Bahdanau et al., 2015). It is based on the estimation of a probability distribution over all input words for each target word. However, source and target words are in different representation space, and they still have to go through a long information processing procedure that may lead to the source words are incorrectly translated into the target words. ∗ Mingming"
P19-1296,D15-1166,0,0.122472,"Missing"
P19-1296,P02-1040,0,0.103188,"Missing"
P19-1296,W18-6319,0,0.0337367,"Missing"
P19-1296,W16-0533,0,0.0307462,"Although Transformer model (Vaswani et al., 2017) has archived state-of-the-art performance of NMT, more attention is paid to the words-level relationship via self-attention networks. Sentence-level agreement method has been applied to many natural language processing tasks. Aliguliyev (2009) used sentence similarity measure technique for automatic text summarization. Liang et al. (2010) have shown that the sentence similarity algorithm based on VSM is beneficial to address the FAQ problem. Su et al. (2016) presented a sentence similarity method for spoken dialogue system to improve accuracy. Rei and Cummins (2016) proposed sentence similarity measures to improve the estimation of topical relevance. Wang et al. (2017b; 2018) used sentence similarity to select sentences with the similar domains. The above methods only considered monolingual sentence-level agreement. In human translation, a translator’s primary concern is to translate a sentence through its entire meaning rather than word-by-word meaning. Therefore, in early machine translation studies, such as example-based machine translation (Nagao, 1984; Nio et al., 2013), use the sentence similarity matching between the sentences to be translated and"
P19-1296,W16-2323,0,0.0605544,"Missing"
P19-1296,P16-1162,0,0.158734,"Missing"
P19-1296,P16-1131,0,0.017386,"this paper, we propose a sentencelevel agreement module to directly minimize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance. 1 Introduction Neural network based methods have been applied to several natural language processing tasks (Zhang et al., 2016; Li et al., 2018; Chen et al., 2018; Li et al., 2019; He et al., 2018). In neural machine translation (NMT), unlike conventional phrase-based statistical machine translation, an attention mechanism is adopted to help align output with input words (Bahdanau et al., 2015). It is based on the estimation of a probability distribution over all input words for each target word. However, source and target words are in different representation space, and they still have to go through a long information processing procedure that may lead to the source words are incorrectly translated into the target w"
P19-1296,P16-1008,0,0.0212731,"nction in between: FFN(x) = max(0, xW1 + b1 )W2 + b2 , (2) where W1 and W2 are both linear transformation networks, b1 and b2 are both bias. We define Henc as the sentence representation of X via the self-attention layers in encoder, and Hdec as the sentence representation of words Y via embedding layers in decoder. The parameters of Transformer are trained to minimize the following objective function on a set of training examples {(X n , Y n )}N n=1 : Lmle = − 3 N Iy 1 XX n logP (yin |y<i , Henc , Hdec ). N n=1 i=1 (3) Agreement on Source and Target Sentence Some studies (Luong et al., 2015; Tu et al., 2016; Chen et al., 2017a,b; Kuang et al., 2018) showed that improving word alignment is beneficial to machine translation. Their idea is based on word-level agreement and make the embeddings of source words and corresponding target words similar. In this paper, we investigate the sentence-level relationship between the source and target sentences. We propose a sentence-level agreement method which can make the sentencelevel semantics of the source and target closer. The entire architecture of the proposed method is illustrated in Figure 1. 3.1 Sentence-Level Agreement First, we need to get the sen"
P19-1296,P17-2089,1,0.919928,"Missing"
P19-1296,C18-1269,0,0.0400623,"Missing"
P19-1296,D17-1155,1,0.822564,"ntion is paid to the words-level relationship via self-attention networks. Sentence-level agreement method has been applied to many natural language processing tasks. Aliguliyev (2009) used sentence similarity measure technique for automatic text summarization. Liang et al. (2010) have shown that the sentence similarity algorithm based on VSM is beneficial to address the FAQ problem. Su et al. (2016) presented a sentence similarity method for spoken dialogue system to improve accuracy. Rei and Cummins (2016) proposed sentence similarity measures to improve the estimation of topical relevance. Wang et al. (2017b; 2018) used sentence similarity to select sentences with the similar domains. The above methods only considered monolingual sentence-level agreement. In human translation, a translator’s primary concern is to translate a sentence through its entire meaning rather than word-by-word meaning. Therefore, in early machine translation studies, such as example-based machine translation (Nagao, 1984; Nio et al., 2013), use the sentence similarity matching between the sentences to be translated and the sentences in the 3076 Proceedings of the 57th Annual Meeting of the Association for Computational L"
P19-1435,D15-1075,0,\N,Missing
P19-1435,C04-1051,0,\N,Missing
P19-1435,P02-1040,0,\N,Missing
P19-1435,D14-1162,0,\N,Missing
P19-1435,marelli-etal-2014-sick,0,\N,Missing
P19-1435,P18-1041,0,\N,Missing
P19-1435,D18-1453,0,\N,Missing
P19-1435,N18-1101,0,\N,Missing
S07-1035,W00-1702,0,0.058418,"Missing"
S07-1035,P06-1057,0,0.0142722,"d on search engine, which does not require any sense tagged corpus. The majority of methods using the Web often try to automatically generate sense tagged corpora (Agirre and Martinez 2000;Agirre and Martinez 2004;Gonzalo et al. 2003; Mihalcea and Moldovan 1999;Santamaria et al. 2003). In this paper, we experiment with our initial attempt on another research trend that uses the Web not for extracting training samples but helping disambiguate directly during the translation selection process. The approach we present here is inspired by (Mihalcea and Moldovan 1999;Brill 2003; Rosso et al. 2005; Dagan et al. 2006; McCarthy 2002). Suppose that source ambiguous words are apt to appear with its target translation on bilingual web pages either parallel or non-parallel. Instead of searching the source language or target language respectively on web, we try to let the search engine think in a bilingual style. First, our system gets the co-occurrence information of Chinese context and its corresponding English context. Then it computes association measurements of Chinese context and English context in 4 kinds of way. Finally, it selects the correct English translation by computing the association measurement"
S07-1035,W02-0816,0,0.0296483,"which does not require any sense tagged corpus. The majority of methods using the Web often try to automatically generate sense tagged corpora (Agirre and Martinez 2000;Agirre and Martinez 2004;Gonzalo et al. 2003; Mihalcea and Moldovan 1999;Santamaria et al. 2003). In this paper, we experiment with our initial attempt on another research trend that uses the Web not for extracting training samples but helping disambiguate directly during the translation selection process. The approach we present here is inspired by (Mihalcea and Moldovan 1999;Brill 2003; Rosso et al. 2005; Dagan et al. 2006; McCarthy 2002). Suppose that source ambiguous words are apt to appear with its target translation on bilingual web pages either parallel or non-parallel. Instead of searching the source language or target language respectively on web, we try to let the search engine think in a bilingual style. First, our system gets the co-occurrence information of Chinese context and its corresponding English context. Then it computes association measurements of Chinese context and English context in 4 kinds of way. Finally, it selects the correct English translation by computing the association measurements. In view that"
S07-1035,J03-3006,0,\N,Missing
S10-1067,P03-1056,0,0.0468786,"Missing"
S10-1067,W05-0639,0,0.0565545,"Missing"
S10-1067,H93-1052,0,0.0736784,"Missing"
S10-1067,S10-1015,0,0.0418449,"Missing"
S10-1083,J98-1006,0,0.0397268,"Missing"
S10-1083,A00-2009,0,0.0995108,"Missing"
S10-1083,U06-1008,0,\N,Missing
S10-1083,H93-1052,0,\N,Missing
S10-1083,P03-1058,0,\N,Missing
S10-1083,W04-3204,0,\N,Missing
S19-2101,W17-3012,0,0.0587373,"019 Association for Computational Linguistics language research, such as TRAC1 which shared task on Aggression Identification summarized in Kumar et al. (2018), need to distinguish open, secret and non-aggressive texts. And ALW2 which is work for Abusive Language. Fiˇser et al. (2017) did some work on the legal framework, dataset and annotation schema of socially unacceptable discourse practices on social networking platforms in Slovenia. Gamb¨ack and Sikdar (2017) introduced a deep learning based Twitter Hate Speech text include racism, sexism, both and non-hate-speech classification system. Waseem et al. (2017) put forward a series of subtasks of hate speech, cyberbullying, and online abuse. Su et al. (2017) described a system for detecting and modifying Chinese dirty sentences. And GermEval is also shared related tasks (Wiegand et al., 2018) which initiate and foster research on the identification of offensive content in German language microposts. Additionally, the main work of Malmasi and Zampieri (2017) and Malmasi and Zampieri (2018) is to approach the problem of distinguishing general profanity from hate speech. Zhang et al. (2018) tried to use a Convolution-GRU for detecting hate speech on Tw"
S19-2101,S17-2126,0,0.0225314,"t”, ”you’re” and so on into ”do n’t” and ”you ’re”, because there is no ”don’t” or ”you’re” in the dictionary. We haven’t expanded the abbreviations like ”do not” or ”you are”, because the results may not be unique just like ”I’d” can represent ”I would” or ”I had”. Forth, we also need to separate the emojis refer to the dictionary of emojis. (We will introduce the word dictionary and emoji dictionary in detail in embedding section). In addition, we regard all numbers as one word. After completing the above preprocessing, if a word is still detected as an unknown word, we use ekphrasis3 tool (Baziotis et al., 2017) for further processing. The first step is word segmentation. We separate some words together may be a customary expression by spaces. For example, ”Googlearecorrupt” is turned into ”Google are corrupt”. Second, if the word still does not exist in the dictionary, we do an error correction operation. After all operations, words that do not exist in the dictionary are marked as unknown words. Step-by-step processing instead of direct batch processing without intermediate detection improves reliability and avoids modifying correct expressions to errors. Methodology and Data 3.1 Method Our method"
S19-2101,N19-1144,0,0.115423,"ng 30/75. In sub-task C, we got 0.549, ranking 22/65. We also tried some other methods of not submitting results. 1 Introduction Recognition of Offensive information has research and application value in many aspects. With the popularity of social media, people’s comments on social media has become an important part of public opinion. Although freedom of speech is advocated, there are still some unacceptable words. The study of offensive language has only recently arisen. With the deepening of the research, we need to consider the different sub-tasks of its decomposition. In OffensEval tasks (Zampieri et al., 2019b), offensive content was divided into three sub-tasks taking the type and target of offenses into account. Sub-task A is offensive language identification. We should identify a short text sentence as offensive or non-offensive. Sub-task B is automatic categorization of offense types. We need to classify a sentence as having an attack target or not, if this is 2 Related Work Due to the universality of offensive language in social media, in order to cope with offensive language and prevent abuse in social media, research on related aspects has gradually emerged in recent years. There have been"
S19-2101,W16-6208,0,0.0173054,"ivide sentences into words. But in many cases in data sets, punctuation We used a word embedding layer to represent words as vectors. The 200 dimension word vectors4 is pre-trained by GloVe based on a large corpus of Twitter provided by Jeffrey et al. (2014). It includes 1,193,514 words and their vector representations. A sentence sequence S(w1 , w2 , ..., wl ) is represented as C(c1 , c2 , ..., cl ), where wi (i ∈ [1, l]) represents a word, ci represents the vector corresponding to the word. C is the matrix representation of the sequence S. We also use emoji vectors provided by Eisner et al. (2016) to represent the emoji that appears in a sequence. It includes 1,661 emojis used in 1 https://sites.google.com/view/trac1/ home 2 https://sites.google.com/site/ abusivelanguageworkshop2017/ 3 https://www.github.com/cbaziotis/ ekphrasis 4 https://nlp.stanford.edu/projects/ glove/ 3.1.1 Preprocessing 565 Figure 1: The whole architecture of 2-layer BiLSTM with Double Attention Based Offensive Language Identification. Where w is word, and e is emoji Twitter and their 300 dimension vector representations. We have made a PCA dimension reduction on emoji vectors, making 300 dimensions into 200 dimen"
S19-2101,S19-2010,0,0.0945614,"ng 30/75. In sub-task C, we got 0.549, ranking 22/65. We also tried some other methods of not submitting results. 1 Introduction Recognition of Offensive information has research and application value in many aspects. With the popularity of social media, people’s comments on social media has become an important part of public opinion. Although freedom of speech is advocated, there are still some unacceptable words. The study of offensive language has only recently arisen. With the deepening of the research, we need to consider the different sub-tasks of its decomposition. In OffensEval tasks (Zampieri et al., 2019b), offensive content was divided into three sub-tasks taking the type and target of offenses into account. Sub-task A is offensive language identification. We should identify a short text sentence as offensive or non-offensive. Sub-task B is automatic categorization of offense types. We need to classify a sentence as having an attack target or not, if this is 2 Related Work Due to the universality of offensive language in social media, in order to cope with offensive language and prevent abuse in social media, research on related aspects has gradually emerged in recent years. There have been"
S19-2101,W17-3007,0,0.0224513,"Missing"
S19-2101,W17-3013,0,0.04242,"Missing"
S19-2101,D14-1162,0,0.0829462,"the data cleaner, reduce the number of unknown words in the dictionary, and do some processing of error words. The first step is to convert all words into lowercase. Our preliminary view is that uppercase or lowercase has no direct impact on offensive language recognition tasks. The second step is to deal with punctuation symbols. We use space as separator to divide sentences into words. But in many cases in data sets, punctuation We used a word embedding layer to represent words as vectors. The 200 dimension word vectors4 is pre-trained by GloVe based on a large corpus of Twitter provided by Jeffrey et al. (2014). It includes 1,193,514 words and their vector representations. A sentence sequence S(w1 , w2 , ..., wl ) is represented as C(c1 , c2 , ..., cl ), where wi (i ∈ [1, l]) represents a word, ci represents the vector corresponding to the word. C is the matrix representation of the sequence S. We also use emoji vectors provided by Eisner et al. (2016) to represent the emoji that appears in a sequence. It includes 1,661 emojis used in 1 https://sites.google.com/view/trac1/ home 2 https://sites.google.com/site/ abusivelanguageworkshop2017/ 3 https://www.github.com/cbaziotis/ ekphrasis 4 https://nlp.s"
S19-2101,W18-4401,0,0.0922497,"Missing"
S19-2101,malmasi-zampieri-2017-detecting,0,0.0645656,"s on social networking platforms in Slovenia. Gamb¨ack and Sikdar (2017) introduced a deep learning based Twitter Hate Speech text include racism, sexism, both and non-hate-speech classification system. Waseem et al. (2017) put forward a series of subtasks of hate speech, cyberbullying, and online abuse. Su et al. (2017) described a system for detecting and modifying Chinese dirty sentences. And GermEval is also shared related tasks (Wiegand et al., 2018) which initiate and foster research on the identification of offensive content in German language microposts. Additionally, the main work of Malmasi and Zampieri (2017) and Malmasi and Zampieri (2018) is to approach the problem of distinguishing general profanity from hate speech. Zhang et al. (2018) tried to use a Convolution-GRU for detecting hate speech on Twitter. 3 symbols and words, as well as punctuation symbols and punctuation symbols are closely linked without space. In this way, the system will not be able to recognize them. Just like ”sloth.” or ”!!!”, and we turned them into ”sloth .” and ”! ! !”. The third step is abbreviation processing. We converted ”don’t”, ”you’re” and so on into ”do n’t” and ”you ’re”, because there is no ”don’t” or ”you’re"
S19-2101,W17-3003,0,0.0230701,"ression Identification summarized in Kumar et al. (2018), need to distinguish open, secret and non-aggressive texts. And ALW2 which is work for Abusive Language. Fiˇser et al. (2017) did some work on the legal framework, dataset and annotation schema of socially unacceptable discourse practices on social networking platforms in Slovenia. Gamb¨ack and Sikdar (2017) introduced a deep learning based Twitter Hate Speech text include racism, sexism, both and non-hate-speech classification system. Waseem et al. (2017) put forward a series of subtasks of hate speech, cyberbullying, and online abuse. Su et al. (2017) described a system for detecting and modifying Chinese dirty sentences. And GermEval is also shared related tasks (Wiegand et al., 2018) which initiate and foster research on the identification of offensive content in German language microposts. Additionally, the main work of Malmasi and Zampieri (2017) and Malmasi and Zampieri (2018) is to approach the problem of distinguishing general profanity from hate speech. Zhang et al. (2018) tried to use a Convolution-GRU for detecting hate speech on Twitter. 3 symbols and words, as well as punctuation symbols and punctuation symbols are closely link"
W00-1211,A88-1019,0,\N,Missing
W01-1813,J95-4004,0,0.118714,"Missing"
W07-0709,W03-1001,0,0.0335556,"Missing"
W07-0709,J97-3002,0,0.168465,"Missing"
W07-0709,J04-2004,0,0.0325852,"Missing"
W07-0709,J00-1004,0,0.0234738,"Missing"
W07-0709,W95-0115,0,0.034968,"Missing"
W07-0709,N04-1014,0,0.0264525,"Missing"
W07-0709,P01-1067,0,0.0848808,"Missing"
W07-0709,N03-1017,0,0.0186915,"f decoding to achieve better reordering performance. 5 Experiments The experiment was conducted for the task of Chinese-to-English translation. A corpus, which consists of 602,701 sentence pairs, was used as the training set. We took CLDC 863 test set as our test set (http://www.chineseldc.org/resourse.asp), which consists of 467 sentences with an average length of 14.287 Chinese words and 4 references. To evaluate the result of the translation, the BLEU metric (Papineni et al. 2002) was used. 5.1 Figure4. Process of translation based on RM (r ,WRB VBD) System used for comparison was Pharaoh (Koehn et al., 2003; Koehn, 2004), which uses a beam search algorithm for decoding. In its model, it takes the following features: language model, phrase translation probability in the two directions, distortion model, word penalty and phrase penalty, all of which can be achieved with the training toolkits distributed by Koehn. The training set and development set mentioned above were used to perform the training task and to tune the feature weights by the minimum error training algorithm. All the other settings were the same as the default ones. SRI Language Modeling Toolkit was used to train a 3-gram language"
W07-0709,koen-2004-pharaoh,0,0.0156852,"e better reordering performance. 5 Experiments The experiment was conducted for the task of Chinese-to-English translation. A corpus, which consists of 602,701 sentence pairs, was used as the training set. We took CLDC 863 test set as our test set (http://www.chineseldc.org/resourse.asp), which consists of 467 sentences with an average length of 14.287 Chinese words and 4 references. To evaluate the result of the translation, the BLEU metric (Papineni et al. 2002) was used. 5.1 Figure4. Process of translation based on RM (r ,WRB VBD) System used for comparison was Pharaoh (Koehn et al., 2003; Koehn, 2004), which uses a beam search algorithm for decoding. In its model, it takes the following features: language model, phrase translation probability in the two directions, distortion model, word penalty and phrase penalty, all of which can be achieved with the training toolkits distributed by Koehn. The training set and development set mentioned above were used to perform the training task and to tune the feature weights by the minimum error training algorithm. All the other settings were the same as the default ones. SRI Language Modeling Toolkit was used to train a 3-gram language model. After t"
W07-0709,N03-1003,0,0.0626963,"Missing"
W07-0709,P05-1067,0,0.0323964,"Missing"
W07-0709,W99-0604,0,\N,Missing
W07-0709,J93-2003,0,\N,Missing
W07-0709,J03-4003,0,\N,Missing
W07-0709,P03-1011,0,\N,Missing
W07-0709,J04-2003,0,\N,Missing
W07-0709,P02-1038,0,\N,Missing
W07-2418,W90-0110,0,0.0231843,"Missing"
W09-2305,W05-0909,0,0.388154,"Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics fication (Lepage and Denoual, 2005; Lassner et al. 2005; Zhou et al. 2006; Kauchak and Barzilay, 2006; Owczarzak et al. 2006; Owczarzak et al. 2007). In this kind of method, the quality of system translations can be viewed as the extent to which the conveyed meaning matches the semantics of the reference translations, independent of substrings they may share. In short, all paraphrases of human-generated references should be considered “good” translations. The second strategy extends the references with the synonymy (Banerjee and Lavie, 2005; Lassner et al. 2005). This is an alternation to obtain lexical variations with synonymy dictionaries instead of the paraphrase. In this kind of method, the reference is matched against to the system translation with the pack of the synonymies of the reference words instead of the exact matching. Both two strategies can successfully capture the lexical variations and greatly extend the coverage of the references. But they still have two common deficiencies. The first is the demand of the external knowledge. Paraphrase based method need a mass of external corpus to extract paraphrases and syno"
W09-2305,N03-2021,0,0.0283808,"evaluation metrics. The evaluation is carried out on sentence level using the original reference set and the extended reference set respectively. Finally, the Pearson’s correlations between the human assessments and evaluation scores using two reference set are calculated and compared. The multiple translations and human assessments are obtained from the dataset of the MT evaluation workshop at ACL05 (LDC2006T04) and the dataset from NistMATR08 (LDC2008E43). Table 1 & 2 describes the detail of the two datasets. The popular automatic evaluation metrics include BLEU (Papieni et al., 2002), GTM (Melamed et al., 2003), Rouge (Lin and Och, 2004) and METEOR (Banerjee and Lavie, 2005). The syntactic trees of the reference sentences are obtained with the Stanford statistical parser (Klein 2003) for LDC2006T04 and Collins parser (Collins 1999) for LDC2008E43. Table 3 & 4 gives out the correlations using two reference set on both datasets. The first column is the name of the used metrics. The second column is the correlations based on the original reference set. The third column is the correlations based on the extended reference set. In the experiment, the maximum length of N-gram in BLEU is 4. The exponent of"
W09-2305,N06-1058,0,0.0202515,"ighly desirable to extend the coverage of the references for the similarity based evaluation methods. To match the system translation with various presentation of the same meaning, many work haven been proposed to extend the references by generating lexical variations. The first strategy focuses on the extension based on paraphrase identi37 Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation, pages 37–44, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics fication (Lepage and Denoual, 2005; Lassner et al. 2005; Zhou et al. 2006; Kauchak and Barzilay, 2006; Owczarzak et al. 2006; Owczarzak et al. 2007). In this kind of method, the quality of system translations can be viewed as the extent to which the conveyed meaning matches the semantics of the reference translations, independent of substrings they may share. In short, all paraphrases of human-generated references should be considered “good” translations. The second strategy extends the references with the synonymy (Banerjee and Lavie, 2005; Lassner et al. 2005). This is an alternation to obtain lexical variations with synonymy dictionaries instead of the paraphrase. In this kind of method, t"
W09-2305,P03-1054,0,0.00784953,"Missing"
W09-2305,I05-5008,0,0.0165819,"for any given foreign language sentence. Therefore, it would be highly desirable to extend the coverage of the references for the similarity based evaluation methods. To match the system translation with various presentation of the same meaning, many work haven been proposed to extend the references by generating lexical variations. The first strategy focuses on the extension based on paraphrase identi37 Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation, pages 37–44, c Boulder, Colorado, June 2009. 2009 Association for Computational Linguistics fication (Lepage and Denoual, 2005; Lassner et al. 2005; Zhou et al. 2006; Kauchak and Barzilay, 2006; Owczarzak et al. 2006; Owczarzak et al. 2007). In this kind of method, the quality of system translations can be viewed as the extent to which the conveyed meaning matches the semantics of the reference translations, independent of substrings they may share. In short, all paraphrases of human-generated references should be considered “good” translations. The second strategy extends the references with the synonymy (Banerjee and Lavie, 2005; Lassner et al. 2005). This is an alternation to obtain lexical variations with synonym"
W09-2305,W06-3112,0,0.0470017,"Missing"
W09-2305,W07-0411,0,0.03494,"Missing"
W09-2305,P02-1040,0,0.0829579,"h several popular automatic evaluation metrics. The evaluation is carried out on sentence level using the original reference set and the extended reference set respectively. Finally, the Pearson’s correlations between the human assessments and evaluation scores using two reference set are calculated and compared. The multiple translations and human assessments are obtained from the dataset of the MT evaluation workshop at ACL05 (LDC2006T04) and the dataset from NistMATR08 (LDC2008E43). Table 1 & 2 describes the detail of the two datasets. The popular automatic evaluation metrics include BLEU (Papieni et al., 2002), GTM (Melamed et al., 2003), Rouge (Lin and Och, 2004) and METEOR (Banerjee and Lavie, 2005). The syntactic trees of the reference sentences are obtained with the Stanford statistical parser (Klein 2003) for LDC2006T04 and Collins parser (Collins 1999) for LDC2008E43. Table 3 & 4 gives out the correlations using two reference set on both datasets. The first column is the name of the used metrics. The second column is the correlations based on the original reference set. The third column is the correlations based on the extended reference set. In the experiment, the maximum length of N-gram in"
W09-2305,W06-1610,0,0.0291947,"Missing"
W09-2305,P04-1077,0,0.030851,"tion is carried out on sentence level using the original reference set and the extended reference set respectively. Finally, the Pearson’s correlations between the human assessments and evaluation scores using two reference set are calculated and compared. The multiple translations and human assessments are obtained from the dataset of the MT evaluation workshop at ACL05 (LDC2006T04) and the dataset from NistMATR08 (LDC2008E43). Table 1 & 2 describes the detail of the two datasets. The popular automatic evaluation metrics include BLEU (Papieni et al., 2002), GTM (Melamed et al., 2003), Rouge (Lin and Och, 2004) and METEOR (Banerjee and Lavie, 2005). The syntactic trees of the reference sentences are obtained with the Stanford statistical parser (Klein 2003) for LDC2006T04 and Collins parser (Collins 1999) for LDC2008E43. Table 3 & 4 gives out the correlations using two reference set on both datasets. The first column is the name of the used metrics. The second column is the correlations based on the original reference set. The third column is the correlations based on the extended reference set. In the experiment, the maximum length of N-gram in BLEU is 4. The exponent of GTM is 2. ROUGE uses skip-b"
W09-2305,J03-4003,0,\N,Missing
W09-2306,2007.mtsummit-papers.8,0,0.09837,"2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents. To alleviate this constraint, a few works have attempted to make full use of the non-syntactic rules by extending their syntax-based model"
W09-2306,J07-2003,0,0.153302,"research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinde"
W09-2306,P05-1067,0,0.0230261,"Missing"
W09-2306,D07-1079,0,0.0591386,"rred and which kinds of rules could be discard without too much decline in translation quality. However, one of the precondition for the investigations of these issues is what are the “rule categories”? In other words, some comprehensive rule classifications are necessary to make the rule analyses feasible. The motivation of this paper is to present such a rule classification. 2 Related Works A few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories (Liu et al., 2007; Zhang et al., 2008a; DeNeefe et al., 2007). Liu et al. (2007) differentiated the rules in their tree-to-string model which integrated with forest1 -to-string into fully lexicalized rules, non-lexicalized rules and partial lexicalized rules according to the lexicalization levels. As an extension, Zhang et al. (2008a) proposed two more categories: Structure Reordering Rules (SRR) and Discontiguous Phrase Rules (DPR). The SRR stands for the rules which have at least two non-terminal leaf nodes with inverted order in the source and target side. And DPR refers to the rules having at least one non-terminal leaf node between two terminal lea"
W09-2306,N04-1035,0,0.195048,"nd Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents. To alleviate this constraint, a few works have attempted to make full use of the non-syntactic rules by ex"
W09-2306,P06-1121,0,0.01405,"rules and partial lexicalized rules according to the lexicalization levels. As an extension, Zhang et al. (2008a) proposed two more categories: Structure Reordering Rules (SRR) and Discontiguous Phrase Rules (DPR). The SRR stands for the rules which have at least two non-terminal leaf nodes with inverted order in the source and target side. And DPR refers to the rules having at least one non-terminal leaf node between two terminal leaf nodes. (DeNeefe et al., 2007) made an illuminating breakdown of the different kinds of rules. Firstly, they classify all the GHKM2 rules (Galley et al., 2004; Galley et al., 2006) into two categories: lexical rules and non-lexical rules. The former are the rules whose source side has no source words. In other words, a non-lexical rule is a purely ab1 A “forest” means a sub-tree sequence derived from a given parse tree 2 One reviewer asked about the acronym GHKM. We guess it is an acronym for the authors of (Galley et al., 2004): Michel Galley, Mark Hopkins, Kevin Knight and Daniel Marcu. 46 把 钢笔 给 我 Figure 1: A syntax tree pair example. Dotted lines stands for the word alignments. stract rule. The latter is the complementary set of the former. And then lexical rules ar"
W09-2306,P03-2041,0,0.0376687,"ful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syn"
W09-2306,N03-1017,0,0.00830537,"model and syntax model, the mixture of diversified rules still leaves much room for study. In this paper, we present a refined rule classification system. Based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization. Especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules. This novel classification system may supports the SMT research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea,"
W09-2306,koen-2004-pharaoh,0,0.0220538,"diversified rules still leaves much room for study. In this paper, we present a refined rule classification system. Based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization. Especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules. This novel classification system may supports the SMT research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marc"
W09-2306,P07-2045,0,0.00446763,"rules still leaves much room for study. In this paper, we present a refined rule classification system. Based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization. Especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules. This novel classification system may supports the SMT research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod,"
W09-2306,P06-1077,0,0.0235576,"rresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents. To alleviate this constraint, a few works have attempted to make full use of the non-syntactic rules by extending their syntax-based models to more general frameworks. For example, forest-to-string transformation rules have been integrated into the tree-to-string translation framework by (Liu et al., 2006; Liu et al., 2007). Zhang et al. (2008a) made it possible to utilize the non-syntactic rules and even the phrases which are used in phrase based model by advancing a general tree sequence to tree sequence framework based on the tree-to-tree model presented in (Zhang et al., 2007). In these models, various kinds of rules can be employed. For example, as shown in Figure 1 and Figure 2, Figure 1 shows a Chinese-to-English sentence pair with syntax parses on both sides and the word alignments (dotted lines). Figure 2 lists some of the rules which can be extracted from the sentence pair in Figure"
W09-2306,P07-1089,0,0.0180885,"d be discard without too much decline in translation quality. However, one of the precondition for the investigations of these issues is what are the “rule categories”? In other words, some comprehensive rule classifications are necessary to make the rule analyses feasible. The motivation of this paper is to present such a rule classification. 2 Related Works A few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories (Liu et al., 2007; Zhang et al., 2008a; DeNeefe et al., 2007). Liu et al. (2007) differentiated the rules in their tree-to-string model which integrated with forest1 -to-string into fully lexicalized rules, non-lexicalized rules and partial lexicalized rules according to the lexicalization levels. As an extension, Zhang et al. (2008a) proposed two more categories: Structure Reordering Rules (SRR) and Discontiguous Phrase Rules (DPR). The SRR stands for the rules which have at least two non-terminal leaf nodes with inverted order in the source and target side. And DPR refers to the rules having at least one non-terminal leaf node between two terminal leaf nodes. (DeNeefe e"
W09-2306,W02-1018,0,0.0368681,"he conventional phrase model and syntax model, the mixture of diversified rules still leaves much room for study. In this paper, we present a refined rule classification system. Based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization. Especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules. This novel classification system may supports the SMT research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et"
W09-2306,W06-1606,0,0.0153397,"2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents. To alleviate this constraint, a few works have attempted to make full use of the non-syntactic rules by extending their syntax"
W09-2306,P00-1056,0,0.0328612,"Missing"
W09-2306,J04-4002,0,0.0363686,"del, the mixture of diversified rules still leaves much room for study. In this paper, we present a refined rule classification system. Based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization. Especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules. This novel classification system may supports the SMT research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al"
W09-2306,P05-1034,0,0.0300514,"Missing"
W09-2306,N06-1002,0,0.0178123,"(such as R5 in Figure 2) also can model the useful structure reorderings. Moreover, it is not uncommon that a rule demonstrates the reorderings between two non-terminals as well as the reorderings between one non-terminal and one content word terminal. The reason for our emphasis of content word terminal is that the reorderings between the non-terminals and function word are less meaningful. One of the theoretical problems with phrase based SMT models is that they can not effectively model the discontiguous translations and numerous attempts have been made on this issue (Simard et al., 2005; Quirk and Menezes, 2006; Wellington et al., 2006; Bod, 2007; Zhang et al., 2007). What seems to be lacking, however, is a explicit definition to the discontiguous translation. The definition of DPR in (Zhang et al., 2008a) is explicit but somewhat rough and not very accurate. For example, in Figure 3(a), non-terminal node pair ([0,‘爱’], [0,‘love’] ) is surrounded by lexical terminals. According to Definition 2, it is a DPR. However, obviously it is not a discontiguous phrase actually. This rule can be simulated by conjunctions of three phrases (‘我’, ‘I’; ‘爱’, ‘love’; ‘你’,‘you’). In contrast, the translation rule in"
W09-2306,P06-1123,0,0.0154268,"also can model the useful structure reorderings. Moreover, it is not uncommon that a rule demonstrates the reorderings between two non-terminals as well as the reorderings between one non-terminal and one content word terminal. The reason for our emphasis of content word terminal is that the reorderings between the non-terminals and function word are less meaningful. One of the theoretical problems with phrase based SMT models is that they can not effectively model the discontiguous translations and numerous attempts have been made on this issue (Simard et al., 2005; Quirk and Menezes, 2006; Wellington et al., 2006; Bod, 2007; Zhang et al., 2007). What seems to be lacking, however, is a explicit definition to the discontiguous translation. The definition of DPR in (Zhang et al., 2008a) is explicit but somewhat rough and not very accurate. For example, in Figure 3(a), non-terminal node pair ([0,‘爱’], [0,‘love’] ) is surrounded by lexical terminals. According to Definition 2, it is a DPR. However, obviously it is not a discontiguous phrase actually. This rule can be simulated by conjunctions of three phrases (‘我’, ‘I’; ‘爱’, ‘love’; ‘你’,‘you’). In contrast, the translation rule in Figure 3(b) is an actual"
W09-2306,J97-3002,0,0.104504,"s the SMT research community with some helpful references. 1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse)"
W09-2306,2007.mtsummit-papers.71,1,0.907841,"machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents. To alleviate this constraint,"
W09-2306,P08-1064,1,0.119349,"models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model. However, there are still many limitations in phrase based models. The most frequently pointed limitation is its inefficacy to modeling the structure reordering and the discontiguous corresponding. To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk 45 et al., 2005; Liu et al., 2007; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Marcu et al., 2006; Bod, 2007). The basic motivation behind syntax-based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents. To alleviate this constraint, a few works have at"
W09-2306,C08-1138,1,\N,Missing
W09-2306,H05-1095,0,\N,Missing
W09-2306,P03-1011,0,\N,Missing
W09-3106,2005.eamt-1.19,0,0.0194511,"ed on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to decrease the amount of training data to make SMT systems adaptable to small devices. Some other works select training data according to domain information of the test set. Hildebrand et al. (2005) used an information retrieval method for translation model adaptation. They selected sentences similar to the test set from available in-of-domain and out-of-domain training data to form an adapted translation model. Lü et al. (2007) further used smaller adapted data to optimize the distribution of the whole training data. They took advantage both of larger data and adapted data. Unlike all the above-mentioned studies, our method selected the training corpus according to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme"
W09-3106,C04-1059,0,0.0540906,"Missing"
W09-3106,J05-4003,0,0.0291564,"oper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. OOV 23 18 26 39 47 Table 3: SMT performances with weighted corpora 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to"
W09-3106,W10-4217,0,0.0383922,"Missing"
W09-3106,J03-1002,0,0.00232923,"irs of free translation1. Our evaluation corpus was drawn from the IWSLT Chinese-to-English MT test set of 2004, which includes 506 Chinese sentences and 16 English reference sentences for each Chinese one. Since our focus is not on a specific SMT architecture, we use the off-the-shelf phrase-based decoder Pharaoh (Koehn 2004). Pharaoh implements a beam search decoder for phrase-based statistical models, and has the advantages of being freely available and widely used. The phrase bilingual lexicon is derived from the intersection of bi-directional IBM Model 4 alignments, obtained with GIZA++ (Och and Ney 2003). For better comparison between experimental results, we kept all the system parameters as default, while only tuning our own parameters. GEi is an English grammatical category, |GEi| is the number it occurs in the English sentence, and GCi is the Chinese counterpart (see Table 1). n is the number of common grammatical categories that make differences in the special task of recognizing literal translated sentence pairs. λi is the weight for the respective category, which is trained by a simple gradient descent algorithm on a sample of 10,000 manually analysed sentence pairs. i 1 2 3 4 SMT Expe"
W09-3106,eck-etal-2004-language,0,0.0755489,"Missing"
W09-3106,koen-2004-pharaoh,0,0.109829,"Missing"
W09-3106,J03-3002,0,0.0107839,"tial improvement to a certain degree although it did not have a devastating effects in these two cases. Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. OOV 23 18 26 39 47 Table 3: SMT performances with weighted corpora 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded."
W09-3106,D07-1036,0,0.142351,"ist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to decrease the amount of training data to make SMT systems adaptable to small devices. Some other works select training data according to domain information of the test set. Hildebrand et al. (2005) used an information retrieval method for translation model adaptation. They selected sentences similar to the test set from available in-of-domain and out-of-domain training data to form an adapted translation model. Lü et al. (2007) further used smaller adapted data to optimize the distribution of the whole training data. They took advantage both of larger data and adapted data. Unlike all the above-mentioned studies, our method selected the training corpus according to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme also tried to make use of Figure 3: Trajectory of BLEU score Figure 4: Trajectory of NIST score Among the five models, that of λ = 0.5 is the baseline since here all sentence pairs contributed in the same way. Those of λ = 0 and 1 ar"
W09-3106,W06-1626,0,\N,Missing
W09-3106,J03-4003,0,\N,Missing
W09-3106,P06-1011,0,\N,Missing
W09-3106,2006.iwslt-evaluation.15,0,\N,Missing
W10-2416,P02-1060,0,0.0506863,"and knowledge bases. Later, Collins (1999) adopted the AdaBoost algorithm to find a weighted combination of simple classifiers. They reported that the combination of simple classifiers can yield some powerful systems with much better performances. As a matter of fact, these methods all need manual studies on the construction of the rule set or the simple classifiers. Machine learning models attract more attentions recently. Usually, they train classification models based on context features. Various lexical and syntactic features are considered, such as N-grams, Part-Of-Speech (POS), and etc. Zhou and Su (2002) integrated four different kinds of features, which convey different semantic information, for a classification model based on the Hidden Markov Model (HMM). Koen (2006) built a classifier with the Conditional Random Field (CRF) model to classify noun phrases in a text with the WordNet SynSet. Isozaki and Kazawa (2002) studied the use of SVM instead. There were fewer studies in Chinese entity categorization. Guo and Jiang (2005) applied Robust Risk Minimization to classify the named entities. The features include seven traditional lexical features and two external-NE-hints based features. An i"
W10-2416,C02-1054,0,0.0364763,"construction of the rule set or the simple classifiers. Machine learning models attract more attentions recently. Usually, they train classification models based on context features. Various lexical and syntactic features are considered, such as N-grams, Part-Of-Speech (POS), and etc. Zhou and Su (2002) integrated four different kinds of features, which convey different semantic information, for a classification model based on the Hidden Markov Model (HMM). Koen (2006) built a classifier with the Conditional Random Field (CRF) model to classify noun phrases in a text with the WordNet SynSet. Isozaki and Kazawa (2002) studied the use of SVM instead. There were fewer studies in Chinese entity categorization. Guo and Jiang (2005) applied Robust Risk Minimization to classify the named entities. The features include seven traditional lexical features and two external-NE-hints based features. An important result they reported is that character-based features can be as good as wordbased features since they avoid the Chinese word segmentation errors. In (Jing et al., 2003), it was further reported that pure character-based models can even outperform word-based models with character combination features. Deep Beli"
W10-2416,W06-0505,0,0.0667592,"Missing"
W10-2416,W99-0613,0,0.195004,"Missing"
W10-2416,A97-1030,0,0.171859,"Missing"
W10-2416,W03-1026,0,\N,Missing
W10-4115,I05-2023,0,0.0688774,"Missing"
W10-4115,N07-1015,0,0.0695042,"Missing"
W10-4115,P06-1017,0,0.049374,"Missing"
W10-4115,P08-2023,1,0.826889,"Missing"
W10-4115,W02-1010,0,0.0822543,"Missing"
W10-4115,zhang-etal-2008-exploiting,1,0.52438,"ul. Kernel-based approaches utilize kernel functions on structures between two entities, such as sequences and trees, to measure the similarity between two relation instances. Zelenok (2003) applied parsing tree kernel function to distinguish whether there was an existing relationship between two entities. However, they limited their task on Personaffiliation and organization-location. The previous work mainly concentrated on relation extraction in English. Relatively, less attention was drawn on Chinese relation extraction. However, its importance is being gradually recognized. For instance, Zhang et al. (2008) combined position information, entity type and context features in a feature-based approach and Che (2005) introduced the edit distance kernel over the original Chinese string representation. DBN is a new feature-based approach for NLP tasks. According to the work by Hinton (2006), DBN consisted of several layers including multiple Restricted Boltzmann Machine (RBM) layers and a Back Propagation (BP) layer. It was reported to perform very well in many classification problems (Ackley, 1985), which is from the origin of its ability to scale gracefully and be computationally tractable when appli"
W10-4115,W03-1026,0,\N,Missing
W12-4407,P10-2051,0,0.0414342,"Missing"
W12-4407,J03-1002,0,0.00464128,"Missing"
W12-4407,P04-1021,0,0.43996,"Missing"
W12-4407,W11-3215,0,0.0273643,"Missing"
W12-4407,P07-2045,0,0.00490897,"se Character-based 368 Table 2 :Total number of unique units For the Chinese-English back transliteration track, the final training and test sets are formed in the same way; the original dev set is used directly. Here we use Character-based which treats single character as a ""syllable"", Simple and Fine-grained segmentation algorithms to deal with English names. Table 1 and table 2 show some syllabic statistics information. Table 1 shows the average syllables of the three segmentation approaches in training data. Table 2 shows the total number of unique units. 4.2 Experimental Setup The Moses (Koehn et al., 2007) is used to implement the model in this paper. The Srilm(Stolcke et al., 2002) toolkit is used to count n-gram on the target of the training set. Here we use a 3-gram language model. In the transliteration model training step, the Giza++(Och et al., 2003) generates the alignment with the grow-diag-andfinal heuristic, while other setup is default. In order to guarantee monotone decoding, the distortion distance is limited to 0. The MERT is used to tune model&apos;s weights. The method of (Jia et al., 2009) is the baseline setup. 4.3 Evaluation Metrics The following 4 metrics are used to measure the"
W12-4407,P11-2094,0,0.0541244,"Missing"
W12-4407,W09-3519,0,0.565705,"number of features  i is the weight of feature i In our phrase-based transliteration system, the following features are used by default:  the bidirectional probability between source phrase and the target phrase  The bidirectional lexical probability between source phrase and target phrase  the fluency of the output, namely language model  the length penalty 3 Syllable Segmentation Phrase Features and Extra This section describes two rule-based syllable segmentation algorithms and three extra phrase features added to machine transliteration model. 3.1 Syllable Segmentation Algorithm In (Jia et al., 2009), the basic alignment units are English character and Chinese character(called c2c). This setup is the simplest format to implement the model. However, transliteration from English to Chinese usually maps an English syllable to a single Chinese character. As one Chinese character usually corresponds to many English characters, the c2c method has only a modest discriminative ability. Obviously syllabifying English is more suitable for this 53 situation. Yang(2010) utilizes a CRF-based segmentor to syllabify English and Kwong(2011) syllabifies English with the Onset First Principle. Alternativel"
W12-4407,J98-4003,0,\N,Missing
W12-4407,C10-2165,0,\N,Missing
yang-etal-2008-chinese-term,W01-0513,0,\N,Missing
yang-etal-2008-chinese-term,C00-2116,0,\N,Missing
yang-etal-2008-chinese-term,P07-2018,0,\N,Missing
yang-etal-2008-chinese-term,J04-1004,0,\N,Missing
