2020.coling-main.201,Cycle-Consistent Adversarial Autoencoders for Unsupervised Text Style Transfer,2020,-1,-1,6,0,21297,yufang huang,Proceedings of the 28th International Conference on Computational Linguistics,0,"Unsupervised text style transfer is full of challenges due to the lack of parallel data and difficulties in content preservation. In this paper, we propose a novel neural approach to unsupervised text style transfer which we refer to as Cycle-consistent Adversarial autoEncoders (CAE) trained from non-parallel data. CAE consists of three essential components: (1) LSTM autoencoders that encode a text in one style into its latent representation and decode an encoded representation into its original text or a transferred representation into a style-transferred text, (2) adversarial style transfer networks that use an adversarially trained generator to transform a latent representation in one style into a representation in another style, and (3) a cycle-consistent constraint that enhances the capacity of the adversarial style transfer networks in content preservation. The entire CAE with these three components can be trained end-to-end. Extensive experiments and in-depth analyses on two widely-used public datasets consistently validate the effectiveness of proposed CAE in both style transfer and content preservation against several strong baselines in terms of four automatic evaluation metrics and human evaluation."
S17-1026,Generating Pattern-Based Entailment Graphs for Relation Extraction,2017,21,1,2,1,32412,kathrin eichler,Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*{SEM} 2017),0,"Relation extraction is the task of recognizing and extracting relations between entities or concepts in texts. A common approach is to exploit existing knowledge to learn linguistic patterns expressing the target relation and use these patterns for extracting new relation mentions. Deriving relation patterns automatically usually results in large numbers of candidates, which need to be filtered to derive a subset of patterns that reliably extract correct relation mentions. We address the pattern selection task by exploiting the knowledge represented by entailment graphs, which capture semantic relationships holding among the learned pattern candidates. This is motivated by the fact that a pattern may not express the target relation explicitly, but still be useful for extracting instances for which the relation holds, because its meaning entails the meaning of the target relation. We evaluate the usage of both automatically generated and gold-standard entailment graphs in a relation extraction scenario and present favorable experimental results, exhibiting the benefits of structuring and selecting patterns based on entailment graphs."
cotik-etal-2017-annotation,Annotation of Entities and Relations in {S}panish Radiology Reports,2017,13,4,5,1,20993,viviana cotik,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Radiology reports express the results of a radiology study and contain information about anatomical entities, findings, measures and impressions of the medical doctor. The use of information extraction techniques can help physicians to access this information in order to understand data and to infer further knowledge. Supervised machine learning methods are very popular to address information extraction, but are usually domain and language dependent. To train new classification models, annotated data is required. Moreover, annotated data is also required as an evaluation resource of information extraction algorithms. However, one major drawback of processing clinical data is the low availability of annotated datasets. For this reason we performed a manual annotation of radiology reports written in Spanish. This paper presents the corpus, the annotation schema, the annotation guidelines and further insight of the data."
thomas-etal-2017-streaming,Streaming Text Analytics for Real-Time Event Recognition,2017,17,0,7,1,13907,philippe thomas,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"A huge body of continuously growing written knowledge is available on the web in the form of social media posts, RSS feeds, and news articles. Real-time information extraction from such high velocity, high volume text streams requires scalable, distributed natural language processing pipelines. We introduce such a system for fine-grained event recognition within the big data framework Flink, and demonstrate its capabilities for extracting and geo-locating mobility- and industry-related events from heterogeneous text sources. Performance analyses conducted on several large datasets show that our system achieves high throughput and maintains low latency, which is crucial when events need to be detected and acted upon in real-time. We also present promising experimental results for the event extraction component of our system, which recognizes a novel set of event types. The demo system is available at \url{http://dfki.de/sd4m-sta-demo/}."
E17-3002,Common Round: Application of Language Technologies to Large-Scale Web Debates,2017,10,0,15,0,23887,hans uszkoreit,Proceedings of the Software Demonstrations of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Web debates play an important role in enabling broad participation of constituencies in social, political and economic decision-taking. However, it is challenging to organize, structure, and navigate a vast number of diverse argumentations and comments collected from many participants over a long time period. In this paper we demonstrate Common Round, a next generation platform for large-scale web debates, which provides functions for eliciting the semantic content and structures from the contributions of participants. In particular, Common Round applies language technologies for the extraction of semantic essence from textual input, aggregation of the formulated opinions and arguments. The platform also provides a cross-lingual access to debates using machine translation."
W16-5113,Negation Detection in Clinical Reports Written in {G}erman,2016,22,6,3,1,20993,viviana cotik,Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining ({B}io{T}xt{M}2016),0,"An important subtask in clinical text mining tries to identify whether a clinical finding is expressed as present, absent or unsure in a text. This work presents a system for detecting mentions of clinical findings that are negated or just speculated. The system has been applied to two different types of German clinical texts: clinical notes and discharge summaries. Our approach is built on top of NegEx, a well known algorithm for identifying non-factive mentions of medical findings. In this work, we adjust a previous adaptation of NegEx to German and evaluate the system on our data to detect negation and speculation. The results are compared to a baseline algorithm and are analyzed for both types of clinical documents. Our system achieves an F1-Score above 0.9 on both types of reports."
W16-4210,A fine-grained corpus annotation schema of {G}erman nephrology records,2016,0,5,3,1,13906,roland roller,Proceedings of the Clinical Natural Language Processing Workshop ({C}linical{NLP}),0,"In this work we present a fine-grained annotation schema to detect named entities in German clinical data of chronically ill patients with kidney diseases. The annotation schema is driven by the needs of our clinical partners and the linguistic aspects of German language. In order to generate annotations within a short period, the work also presents a semi-automatic annotation which uses additional sources of knowledge such as UMLS, to pre-annotate concepts in advance. The presented schema will be used to apply novel techniques from natural language processing and machine learning to support doctors treating their patients by improved information access from unstructured German texts."
P16-4007,"Real-Time Discovery and Geospatial Visualization of Mobility and Industry Events from Large-Scale, Heterogeneous Data Streams",2016,6,3,9,1,5578,leonhard hennig,Proceedings of {ACL}-2016 System Demonstrations,0,"Monitoring mobility- and industryrelevant events is important in areas such as personal travel planning and supply chain management, but extracting events pertaining to specific companies, transit routes and locations from heterogeneous, high-volume text streams remains a significant challenge. We present Spree, a scalable system for real-time, automatic event extraction from social media, news and domain-specific RSS feeds. Our system is tailored to a range of mobilityand industry-related events, and processes German texts within a distributed linguistic analysis pipeline implemented in Apache Flink. The pipeline detects and disambiguates highly ambiguous domain-relevant entities, such as street names, and extracts various events with their geo-locations. Event streams are visualized on a dynamic, interactive map for monitoring and analysis."
L16-1383,Relation- and Phrase-level Linking of {F}rame{N}et with Sar-graphs,2016,0,0,4,1,5580,aleksandra gabryszak,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Recent research shows the importance of linking linguistic knowledge resources for the creation of large-scale linguistic data. We describe our approach for combining two English resources, FrameNet and sar-graphs, and illustrate the benefits of the linked data in a relation extraction setting. While FrameNet consists of schematic representations of situations, linked to lexemes and their valency patterns, sar-graphs are knowledge resources that connect semantic relations from factual knowledge graphs to the linguistic phrases used to express instances of these relations. We analyze the conceptual similarities and differences of both resources and propose to link sar-graphs and FrameNet on the levels of relations/frames as well as phrases. The former alignment involves a manual ontology mapping step, which allows us to extend sar-graphs with new phrase patterns from FrameNet. The phrase-level linking, on the other hand, is fully automatic. We investigate the quality of the automatically constructed links and identify two main classes of errors."
L16-1537,{TEG}-{REP}: A corpus of Textual Entailment Graphs based on Relation Extraction Patterns,2016,19,0,2,1,32412,kathrin eichler,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The task of relation extraction is to recognize and extract relations between entities or concepts in texts. Dependency parse trees have become a popular source for discovering extraction patterns, which encode the grammatical relations among the phrases that jointly express relation instances. State-of-the-art weakly supervised approaches to relation extraction typically extract thousands of unique patterns only potentially expressing the target relation. Among these patterns, some are semantically equivalent, but differ in their morphological, lexical-semantic or syntactic form. Some express a relation that entails the target relation. We propose a new approach to structuring extraction patterns by utilizing entailment graphs, hierarchical structures representing entailment relations, and present a novel resource of gold-standard entailment graphs based on a set of patterns automatically acquired using distant supervision. We describe the methodology used for creating the dataset and present statistics of the resource as well as an analysis of inference types underlying the entailment decisions."
K16-1024,Event Linking with Sentential Features from Convolutional Neural Networks,2016,44,7,2,1,12589,sebastian krause,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,"Coreference resolution for event mentions enables extraction systems to process document-level information. Current systems in this area base their decisions on rich semantic features from various knowledge bases, thus restricting them to domains where such external sources are available. We propose a model for this task which does not rely on such features but instead utilizes sentential features coming from convolutional neural networks. Two such networks first process coreference candidates and their respective context, thereby generating latent-feature representations which are tuned towards event aspects relevant for a linking decision. These representations are augmented with lexicallevel and pairwise features, and serve as input to a trainable similarity function producing a coreference score. Our model achieves state-of-the-art performance on two datasets, one of which is publicly available. An error analysis points out directions for further research."
D16-1065,{AMR} Parsing with an Incremental Joint Model,2016,15,23,2,0,7847,junsheng zhou,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
W15-4405,Semi-automatic Generation of Multiple-Choice Tests from Mentions of Semantic Relations,2015,15,4,4,1,29662,renlong ai,Proceedings of the 2nd Workshop on Natural Language Processing Techniques for Educational Applications,0,"We propose a strategy for the semiautomatic generation of learning material for reading-comprehension tests, guided by semantic relations embedded in expository texts. Our approach combines methods from the areas of information extraction and paraphrasing in order to present a language teacher with a set of candidate multiple-choice questions and answers that can be used for verifying a language learners reading capabilities. We implemented a web-based prototype showing the feasibility of our approach and carried out a pilot user evaluation that resulted in encouraging feedback but also pointed out aspects of the strategy and prototype implementation which need improvements."
W15-4204,Sar-graphs: A Linked Linguistic Knowledge Resource Connecting Facts with Language,2015,21,4,4,1,12589,sebastian krause,Proceedings of the 4th Workshop on Linked Data in Linguistics: Resources and Applications,0,"We present sar-graphs, a knowledge resource that links semantic relations from factual knowledge graphs to the linguistic patterns with which a language can express instances of these relations. Sar-graphs expand upon existing lexicosemantic resources by modeling syntactic and semantic information at the level of relations, and are hence useful for tasks such as knowledge base population and relation extraction. We present a languageindependent method to automatically construct sar-graph instances that is based on distantly supervised relation extraction. We link sar-graphs at the lexical level to BabelNet, WordNet and UBY, and present our ongoing work on pattern- and relationlevel linking to FrameNet. An initial dataset of English sar-graphs for 25 relations is made publicly available, together with a Java-based API."
S15-2056,{DFKI}: Multi-objective Optimization for the Joint Disambiguation of Entities and Nouns {\\&} Deep Verb Sense Disambiguation,2015,15,2,2,0,28972,dirk weissenborn,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,We introduce an approach to word sense disambiguation and entity linking that combines a set of complementary objectives in an extensible multi-objective formalism. During disambiguation the system performs continuous optimization to find optimal probability distributions over candidate senses. Verb senses are disambiguated using a separate neural network model. Our results on noun and verb sense disambiguation as well as entity linking outperform all other submissions on the SemEval 2015 Task 13 for English.
P15-4001,A System Demonstration of a Framework for Computer Assisted Pronunciation Training,2015,9,1,2,1,29662,renlong ai,Proceedings of {ACL}-{IJCNLP} 2015 System Demonstrations,0,"In this paper, we demonstrate a system implementation of a framework for computer assisted pronunciation training for second language learner (L2). This framework supports an iterative improvement of the automatic pronunciation error recognition and classification by allowing integration of annotated error data. The annotated error data is acquired via an annotation tool for linguists. This paper will give a detailed description of the annotation tool and explains the error types. Furthermore, it will present the automatic error recognition method and the methods for automatic visual and audio feedback. This system demonstrates a novel approach to interactive and individualized learning for pronunciation training."
P15-4008,A Web-based Collaborative Evaluation Tool for Automatically Learned Relation Extraction Patterns,2015,10,0,4,1,5578,leonhard hennig,Proceedings of {ACL}-{IJCNLP} 2015 System Demonstrations,0,"Patterns extracted from dependency parses of sentences are a major source of knowledge for most state-of-the-art relation extraction systems, but can be of low quality in distantly supervised settings. We present a linguistic annotation tool that allows human experts to analyze and categorize automatically learned patterns, and to identify common error classes. The annotations can be used to create datasets that enable machine learning approaches to pattern quality estimation. We also present an experimental pattern error analysis for three semantic relations, where we find that between 24% and 61% of the learned dependency patterns are defective due to preprocessing or parsing errors, or due to violations of the distant supervision assumption."
P15-1058,Multi-Objective Optimization for the Joint Disambiguation of Nouns and Named Entities,2015,31,16,3,0,28972,dirk weissenborn,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"In this paper, we present a novel approach to joint word sense disambiguation (WSD) and entity linking (EL) that combines a set of complementary objectives in an extensible multi-objective formalism. During disambiguation the system performs continuous optimization to find optimal probability distributions over candidate senses. The performance of our system on nominal WSD as well as EL improves state-ofthe-art results on several corpora. These improvements demonstrate the importance of combining complementary objectives in a joint model for robust disambiguation."
krieger-etal-2014-information,Information Extraction from {G}erman Patient Records via Hybrid Parsing and Relation Extraction Strategies,2014,9,8,4,0,37133,hansulrich krieger,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we report on first attempts and findings to analyzing German patient records, using a hybrid parsing architecture and a combination of two relation extraction strategies. On a practical level, we are interested in the extraction of concepts and relations among those concepts, a necessary cornerstone for building medical information systems. The parsing pipeline consists of a morphological analyzer, a robust chunk parser adapted to Latin phrases used in medical diagnosis, a repair rule stage, and a probabilistic context-free parser that respects the output from the chunker. The relation extraction stage is a combination of two systems: SProUT, a shallow processor which uses hand-written rules to discover relation instances from local text units and DARE which extracts relation instances from complete sentences, using rules that are learned in a bootstrapping process, starting with semantic seeds. Two small experiments have been carried out for the parsing pipeline and the relation extraction stage."
li-etal-2014-annotating,Annotating Relation Mentions in Tabloid Press,2014,7,2,3,1,20464,hong li,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents a new resource for the training and evaluation needed by relation extraction experiments. The corpus consists of annotations of mentions for three semantic relations: marriage, parentâchild, siblings, selected from the domain of biographic facts about persons and their social relationships. The corpus contains more than one hundred news articles from Tabloid Press. In the current corpus, we only consider the relation mentions occurring in the individual sentences. We provide multi-level annotations which specify the marked facts from relation, argument, entity, down to the token level, thus allowing for detailed analysis of linguistic phenomena and their interactions. A generic markup tool Recon developed at the DFKI LT lab has been utilised for the annotation task. The corpus has been annotated by two human experts, supported by additional conflict resolution conducted by a third expert. As shown in the evaluation, the annotation is of high quality as proved by the stated inter-annotator agreements both on sentence level and on relationmention level. The current corpus is already in active use in our research for evaluation of the relation extraction performance of our automatically learned extraction patterns."
ai-etal-2014-sprinter,{S}printer: Language Technologies for Interactive and Multimedia Language Learning,2014,13,4,6,1,29662,renlong ai,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Modern language learning courses are no longer exclusively based on books or face-to-face lectures. More and more lessons make use of multimedia and personalized learning methods. Many of these are based on e-learning solutions. Learning via the Internet provides 7/24 services that require sizeable human resources. Therefore we witness a growing economic pressure to employ computer-assisted methods for improving language learning in quality, efficiency and scalability. In this paper, we will address three applications of language technologies for language learning: 1) Methods and strategies for pronunciation training in second language learning, e.g., multimodal feedback via visualization of sound features, speech verification and prosody transplantation; 2) Dialogue-based language learning games; 3) Application of parsing and generation technologies to the automatic generation of paraphrases for the semi-automatic production of learning material."
krause-etal-2014-language,Language Resources and Annotation Tools for Cross-Sentence Relation Extraction,2014,12,0,3,1,12589,sebastian krause,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present a novel combination of two types of language resources dedicated to the detection of relevant relations (RE) such as events or facts across sentence boundaries. One of the two resources is the sar-graph, which aggregates for each target relation ten thousands of linguistic patterns of semantically associated relations that signal instances of the target relation (Uszkoreit and Xu, 2013). These have been learned from the Web by intra-sentence pattern extraction (Krause et al., 2012) and after semantic filtering and enriching have been automatically combined into a single graph. The other resource is cockrACE, a specially annotated corpus for the training and evaluation of cross-sentence RE. By employing our powerful annotation tool Recon, annotators mark selected entities and relations (including events), coreference relations among these entities and events, and also terms that are semantically related to the relevant relations and events. This paper describes how the two resources are created and how they complement each other."
li-etal-2012-annotating,Annotating Opinions in {G}erman Political News,2012,20,20,5,1,20464,hong li,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents an approach to construction of an annotated corpus for German political news for the opinion mining task. The annotated corpus has been applied to learn relation extraction rules for extraction of opinion holders, opinion content and classification of polarities. An adapted annotated schema has been developed on top of the state-of-the-art research. Furthermore, a general tool for annotating relations has been utilized for the annotation task. An evaluation of the inter-annotator agreement has been conducted. The rule learning is realized with the help of a minimally supervised machine learning framework DARE."
kluewer-etal-2012-evaluation,Evaluation of the {K}om{P}arse Conversational Non-Player Characters in a Commercial Virtual World,2012,19,3,2,0,43160,tina kluewer,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The paper describes the evaluation of the KomParse system. KomParse is a dialogue system embedded in a 3-D massive multiplayer online game, allowing conversations between non player characters (NPCs) and game users. In a field test with game users, the system was evaluated with respect to acceptability and usability of the overall system as well as task completion, dialogue control and efficiency of three conversational tasks. Furthermore, subjective feedback has been collected for evaluating the single communication components of the system such as natural language understanding. The results are very satisfying and promising. In general, both the usability and acceptability tests show that the tested NPC is useful and well-accepted by the users. Even if the NPC does not always understand the users well and expresses things unexpected, he could still provide appropriate responses to help users to solve their problems or entertain them."
W11-2915,Minimally Supervised Domain-Adaptive Parse Reranking for Relation Extraction,2011,34,2,1,1,21300,feiyu xu,Proceedings of the 12th International Conference on Parsing Technologies,0,"The paper demonstrates how the generic parser of a minimally supervised information extraction framework can be adapted to a given task and domain for relation extraction (RE). For the experiments a generic deep-linguistic parser was employed that works with a largely hand-crafted head-driven phrase structure grammar (HPSG) for English. The output of this parser is a list of n best parses selected and ranked by a MaxEnt parse-ranking component, which had been trained on a more or less generic HPSG treebank. It will be shown how the estimated confidence of RE rules learned from the n best parses can be exploited for parse reranking. The acquired reranking model improves the performance of RE in both training and test phases with the new first parses. The obtained significant boost of recall does not come from an overall gain in parsing performance but from an application-driven selection of parses that are best suited for the RE task. Since the readings best suited for successful rule extraction and instance extraction are often not the readings favored by a regular parser evaluation, generic parsing accuracy actually decreases. The novel method for task-specific parse reranking does not require any annotated data beyond the semantic seed, which is needed anyway for the RE task."
R11-1003,Minimally Supervised Rule Learning for the Extraction of Biographic Information from Various Social Domains,2011,22,5,2,1,20464,hong li,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,This paper investigates the application of an existing seed-based minimally supervised learning algorithm to different social domains exhibiting different properties of the available data. A systematic analysis studies the respective data properties of the three domains including the distribution of the semantic arguments and their combinations. The experimental results confirm that data properties have a strong influence on the performance of the learning system. The main results are insights about: (i) the effects of data properties such as redundancy and frequency of argument mentions on coverage and precision (ii) the positive effects of negative examples if used effectively (iii) the different effects of negative examples depending on the domain data properties and (iv) the potential of reusing rules from one domain for improving the relation extraction performance in another domain.
R11-1052,{META}-{DARE}: Monitoring the Minimally Supervised {ML} of Relation Extraction Rules,2011,13,0,2,1,20464,hong li,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"This paper demonstrates a web-based online system, called META-DARE1. META-DARE is built to assist researchers to obtain insights into seed-based minimally supervised machine learning for relation extraction. META-DARE allows researchers and students to conduct experiments with an existing machine learning system called DARE (Xu et al., 2007). Users can run their own learning experiments by constructing initial seed examples and can monitor the learning process in a very detailed way, namely, via interacting with each node in the learning graph and viewing its content. Furthermore, users can study the learned relation extraction rules and their applications. META-DARE is also an analysis tool which gives an overview of the whole learning process: the number of iterations, the input and output behaviors of each iteration, and the general performance of the extracted instances and their distributions. Moreover, META-DARE provides a very convenient user interface for visualization of the learning graph, the learned rules and the system performance profile."
R11-1095,{T}ech{W}atch{T}ool: Innovation and Trend Monitoring,2011,9,6,2,1,20464,hong li,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"In this paper we present an information service system that allows users to search for the key players of requested technology areas and for their collaboration networks. This system utilizes information extraction and wrapper technologies for detecting persons, organizations, publications and patents as well as relationships among them. Furthermore, it applies relation extraction to detect statements on the web that indicate innovation trends. Various visualization methods are provided to let users monitor key players, their networks and technology trends in a comfortable way."
P10-4007,Talking {NPC}s in a Virtual Game World,2010,6,6,3,0,39621,tina kluwer,Proceedings of the {ACL} 2010 System Demonstrations,0,"This paper describes the KomParse system, a natural-language dialog system in the three-dimensional virtual world Twinity. In order to fulfill the various communication demands between nonplayer characters (NPCs) and users in such an online virtual world, the system realizes a flexible and hybrid approach combining knowledge-intensive domain-specific question answering, task-specific and domain-specific dialog with robust chatbot-like chitchat."
adolphs-etal-2010-question,Question Answering Biographic Information and Social Network Powered by the Semantic Web,2010,7,8,5,1,34902,peter adolphs,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"After several years of development, the vision of the Semantic Web is gradually becoming reality. Large data repositories have been created and offer semantic information in a machine-processable form for various domains. Semantic Web data can be published on the Web, gathered automatically, and reasoned about. All these developments open interesting perspectives for building a new class of domain-specific, broad-coverage information systems that overcome a long-standing bottleneck of AI systems, the notoriously incomplete knowledge base. We present a system that shows how the wealth of information in the Semantic Web can be interfaced with humans once again, using natural language for querying and answering rather than technical formalisms. Whereas current Question Answering systems typically select snippets from Web documents retrieved by a search engine, we utilize Semantic Web data, which allows us to provide natural-language answers that are tailored to the current dialog context. Furthermore, we show how to use natural language processing technologies to acquire new data and enrich existing data in a Semantic Web framework. Our system has acquired a rich biographic data resource by combining existing Semantic Web resources, which are discovered from semi-structured textual data in Web pages, with information extracted from free natural language texts."
fu-etal-2010-determining,Determining the Origin and Structure of Person Names,2010,12,5,2,0,46274,yu fu,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents a novel system HENNA (Hybrid Person Name Analyzer) for identifying language origin and analyzing linguistic structures of person names. We conduct ME-based classification methods for the language origin identification and achieve very promising performance. We will show that word-internal character sequences provide surprisingly strong evidence for predicting the language origin of person names. Our approach is context-, language- and domain-independent and can thus be easily adapted to person names in or from other languages. Furthermore, we provide a novel strategy to handle origin ambiguities or multiple origins in a name. HENNA also provides a person name parser for the analysis of linguistic and knowledge structures of person names. All the knowledge about a person name in HENNA is modelled in a person-name ontology, including relationships between language origins, linguistic features and grammars of person names of a specific language and interpretation of name elements. The approaches presented here are useful extensions of the named entity recognition task."
C10-2065,Using Syntactic and Semantic based Relations for Dialogue Act Recognition,2010,24,27,3,0,39621,tina kluwer,Coling 2010: Posters,0,"This paper presents a novel approach to dialogue act recognition employing multilevel information features. In addition to features such as context information and words in the utterances, the recognition task utilizes syntactic and semantic relations acquired by information extraction methods. These features are utilized by a Bayesian network classifier for our dialogue act recognition. The evaluation results show a clear improvement from the accuracy of the baseline (only with word features) with 61.9% to an accuracy of 67.4% achieved by the extended feature set."
C10-2155,Boosting Relation Extraction with Limited Closed-World Knowledge,2010,16,22,1,1,21300,feiyu xu,Coling 2010: Posters,0,"This paper presents a new approach to improving relation extraction based on minimally supervised learning. By adding some limited closed-world knowledge for confidence estimation of learned rules to the usual seed data, the precision of relation extraction can be considerably improved. Starting from an existing baseline system we demonstrate that utilizing limited closed world knowledge can effectively eliminate dangerous or plainly wrong rules during the bootstrapping process. The new method improves the reliability of the confidence estimation and the precision value of the extracted instances. Although recall suffers to a certain degree depending on the domain and the selected settings, the overall performance measured by F-score considerably improves. Finally we validate the adaptability of the best ranking method to a new domain and obtain promising results."
E09-2004,Gossip Galore {--} A Self-Learning Agent for Exchanging Pop Trivia,2009,5,3,3,1,43128,xiwen cheng,Proceedings of the Demonstrations Session at {EACL} 2009,0,"This paper describes a self-learning software agent who collects and learns knowledge from the web and also exchanges her knowledge via dialogues with the users. The agent is built on top of information extraction, web mining, question answering and dialogue system technologies, and users can freely formulate their questions within the gossip domain and obtain the answers in multiple ways: textual response, graph-based visualization of the related concepts and speech output."
xu-etal-2008-adaptation,Adaptation of Relation Extraction Rules to New Domains,2008,12,7,1,1,21300,feiyu xu,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents various strategies for improving the extraction performance of less prominent relations with the help of the rules learned for similar relations, for which large volumes of data are available that exhibit suitable data properties. The rules are learned via a minimally supervised machine learning system for relation extraction called DARE. Starting from semantic seeds, DARE extracts linguistic grammar rules associated with semantic roles from parsed news texts. The performance analysis with respect to different experiment domains shows that the data property plays an important role for DARE. Especially the redundancy of the data and the connectivity of instances and pattern rules have a strong influence on recall. However, most real-world data sets do not possess the desirable small-world property. Therefore, we propose three scenarios to overcome the data property problem of some domains by exploiting a similar domain with better data properties. The first two strategies stay with the same corpus but try to extract new similar relations with learned rules. The third strategy adapts the learned rules to a new corpus. All three strategies show that frequently mentioned relations can help in the detection of less frequent relations."
cheng-xu-2008-fine,Fine-grained Opinion Topic and Polarity Identification,2008,13,16,2,1,43128,xiwen cheng,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents OMINE, an opinion mining system which aims to identify concepts such as products and their attributes, and analyze their corresponding polarities. Our work pioneers at linking extracted topic terms with domain-specific concepts. Compared with previous work, taking advantage of ontological techniques, OMINE achieves 10{\%} higher recall with the same level precision on the topic extraction task. In addition, making use of opinion patterns for sentiment analysis, OMINE improves the performance of the backup system (NGram) around 6{\%} for positive reviews and 8{\%} for negative ones."
P07-1074,A Seed-driven Bottom-up Machine Learning Framework for Extracting Relations of Various Complexity,2007,11,73,1,1,21300,feiyu xu,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"A minimally supervised machine learning framework is described for extracting relations of various complexity. Bootstrapping starts from a small set of n-ary relation instances as xe2x80x9cseedsxe2x80x9d, in order to automatically learn pattern rules from parsed data, which then can extract new instances of the relation and its projections. We propose a novel rule representation enabling the composition of n-ary relation rules on top of the rules for projections of the relation. The compositional approach to rule construction is supported by a bottom-up pattern extraction method. In comparison to other automatic approaches, our rules cannot only localize relation arguments but also assign their exact target argument roles. The method is evaluated in two tasks: the extraction of Nobel Prize awards and management succession events. Performance for the new Nobel Prize task is strong. For the management succession task the results compare favorably with those of existing pattern acquisition approaches."
uszkoreit-etal-2006-pragmatic,The pragmatic combination of different crosslingual resources,2006,0,0,2,0,23887,hans uszkoreit,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"We will describe new cross-lingual strategies for the development multilingual information services on mobile devices. The novelty of our approach is the intelligent modeling of cross-lingual application domains and the combination of textual translation with speech generation. The final system helps users to speak foreign languages and communicate with the local people in relevant situations, such as restaurant, taxi and emergencies. The advantage of our information services is that they are robust enough for the use in real-world situations. They are developed for the Beijing Olympic Games 2008, where most foreigners will have to rely on translation assistance. Their deployment is foreseen as part of the planned ubiquitous mobile information system of the Olympic Games."
P03-2019,Integrating Information Extraction and Automatic Hyperlinking,2003,5,6,7,0,5120,stephan busemann,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"This paper presents a novel information system integrating advanced information extraction technology and automatic hyper-linking. Extracted entities are mapped into a domain ontology that relates concepts to a selection of hyperlinks. For information extraction, we use SProUT, a generic platform for the development and use of multilingual text processing components. By combining finite-state and unification-based formalisms, the grammar formalism used in SProUT offers both processing efficiency and a high degree of decalrativeness. The ExtraLink demo system show-cases the extraction of relevant concepts from German texts in the tourism domain, offering the direct connection to associated web documents on demand."
P02-1056,An Integrated Archictecture for Shallow and Deep Processing,2002,12,44,10,0,36792,berthold crysmann,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We present an architecture for the integration of shallow and deep NLP components which is aimed at flexible combination of different language technologies for a range of practical current and future applications. In particular, we describe the integration of a high-level HPSG parsing system with different high-performance shallow components, ranging from named entity recognition to chunk parsing and shallow clause recognition. The NLP components enrich a representation of natural language text with layers of new XML meta-information using a single shared data structure, called the text chart. We describe details of the integration methods, and show how information extraction and language checking applications for realworld German text benefit from a deep grammatical analysis."
piskorski-etal-2002-flexible,A Flexible {XML}-based Regular Compiler for Creation and Conversion of Linguistic Resources,2002,12,6,4,0,6080,jakub piskorski,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"Finite-state devices are widely used to compactly model linguistic phenomena, whereas regular expressions are regarded as the adequate level of abstraction for thinking about finite-state languages. In this paper we present a flexible XML-based and Unicodecompatible regular compiler for creating, and integrating existing linguistic resources. Our tool provides user-friendly graphical interface which enables the transparent control of the compilation process and allows for testing generated finite-state grammars with several diagnostic tools. Through the direct database connection, existing linguistic resources can be converted into user-definable finite-state representations."
xu-etal-2002-domain,A Domain Adaptive Approach to Automatic Acquisition of Domain Relevant Terms and their Relations with Bootstrapping,2002,11,68,1,1,21300,feiyu xu,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"In this paper, we present an unsupervised hybrid text-mining approach to automatic acquisition of domain relevant terms and their relations. We deploy the TFIDF-based term classification method to acquire domain relevant single -word terms. Further, we apply two strategies in order to learn lexico-syntatic patterns which indicate paradigmatic and domain relevant syntagmatic relations between the extracted terms. The first one uses an existing ontology as initial knowledge for learning lexico-syntactic patterns, while the second is based on different collocation acquisition methods to deal with the free-word order languages like German. This domain-adaptive method yields good results even when trained on relatively small training corpora. It can be applied to different real-world applications, which need domain-relevant ontology, for example , information extraction, information retrieval or text classification."
P98-1058,Constraints over Lambda-Structures in Semantic Underspecification,1998,19,43,4,0,25730,markus egg,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"We introduce a first-order language for semantic underspecification that we call Constraint Language for Lambda-Structures (CLLS). A xcexbb-structure can be considered as a xcexbb-term up to consistent renaming of bound variables (xcexbb-equality); a constraint of CLLS is an underspecified description of a xcexbb-structure. CLLS solves a capturing problem omnipresent in underspecified scope representations. CLLS features constraints for dominance, lambda binding, parallelism, and anaphoric links. Based on CLLS we present a simple, integrated, and underspecified treatment of scope, parallelism, and anaphora."
C98-1056,Constraints over Lambda-Structures in Semantic Underspecification,1998,19,43,4,0,25730,markus egg,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"We introduce a first-order language for semantic underspecification that we call Constraint Language for Lambda-Structures (CLLS). A xcexbb-structure can be considered as a xcexbb-term up to consistent renaming of bound variables (xcexbb-equality); a constraint of CLLS is an underspecified description of a xcexbb-structure. CLLS solves a capturing problem omnipresent in underspecified scope representations. CLLS features constraints for dominance, lambda binding, parallelism, and anaphoric links. Based on CLLS we present a simple, integrated, and underspecified treatment of scope, parallelism, and anaphora."
