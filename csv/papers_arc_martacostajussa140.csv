2021.ltedi-1.1,"Impact of {COVID}-19 in Natural Language Processing Publications: a Disaggregated Study in Gender, Contribution and Experience",2021,-1,-1,2,1,5325,christine basta,"Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion",0,"This study sheds light on the effects of COVID-19 in the particular field of Computational Linguistics and Natural Language Processing within Artificial Intelligence. We provide an inter-sectional study on gender, contribution, and experience that considers one school year (from August 2019 to August 2020) as a pandemic year. August is included twice for the purpose of an inter-annual comparison. While the trend in publications increased with the crisis, the results show that the ratio between female and male publications decreased. This only helps to reduce the importance of the female role in the scientific contributions of computational linguistics (it is now far below its peak of 0.24). The pandemic has a particularly negative effect on the production of female senior researchers in the first position of authors (maximum work), followed by the female junior researchers in the last position of authors (supervision or collaborative work)."
2021.iwslt-1.11,End-to-End Speech Translation with Pre-trained Models and Adapters: {UPC} at {IWSLT} 2021,2021,-1,-1,5,0,5755,gerard gallego,Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021),0,"This paper describes the submission to the IWSLT 2021 offline speech translation task by the UPC Machine Translation group. The task consists of building a system capable of translating English audio recordings extracted from TED talks into German text. Submitted systems can be either cascade or end-to-end and use a custom or given segmentation. Our submission is an end-to-end speech translation system, which combines pre-trained models (Wav2Vec 2.0 and mBART) with coupling modules between the encoder and decoder, and uses an efficient fine-tuning technique, which trains only 20{\%} of its total parameters. We show that adding an Adapter to the system and pre-training it, can increase the convergence speed and the final result, with which we achieve a BLEU score of 27.3 on the MuST-C test set. Our final model is an ensemble that obtains 28.22 BLEU score on the same set. Our submission also uses a custom segmentation algorithm that employs pre-trained Wav2Vec 2.0 for identifying periods of untranscribable text and can bring improvements of 2.5 to 3 BLEU score on the IWSLT 2019 test set, as compared to the result with the given segmentation."
2021.findings-emnlp.39,Attention Weights in Transformer {NMT} Fail Aligning Words Between Sequences but Largely Explain Model Predictions,2021,-1,-1,2,0,6486,javier ferrando,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"This work proposes an extensive analysis of the Transformer architecture in the Neural Machine Translation (NMT) setting. Focusing on the encoder-decoder attention mechanism, we prove that attention weights systematically make alignment errors by relying mainly on uninformative tokens from the source sequence. However, we observe that NMT models assign attention to these tokens to regulate the contribution in the prediction of the two contexts, the source and the prefix of the target sequence. We provide evidence about the influence of wrong alignments on the model behavior, demonstrating that the encoder-decoder attention mechanism is well suited as an interpretability method for NMT. Finally, based on our analysis, we propose methods that largely reduce the word alignment error rate compared to standard induced alignments from attention weights."
2021.eacl-main.80,Multilingual Machine Translation: Closing the Gap between Shared and Language-specific Encoder-Decoders,2021,-1,-1,2,1,5757,carlos escolano,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"State-of-the-art multilingual machine translation relies on a universal encoder-decoder, which requires retraining the entire system to add new languages. In this paper, we propose an alternative approach that is based on language-specific encoder-decoders, and can thus be more easily extended to new languages by learning their corresponding modules. So as to encourage a common interlingua representation, we simultaneously train the N initial languages. Our experiments show that the proposed approach outperforms the universal encoder-decoder by 3.28 BLEU points on average, while allowing to add new languages without the need to retrain the rest of the modules. All in all, our work closes the gap between shared and language-specific encoderdecoders, advancing toward modular multilingual machine translation systems that can be flexibly extended in lifelong learning settings."
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,4,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.wmt-1.2,Findings of the First Shared Task on Lifelong Learning Machine Translation,2020,-1,-1,3,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"A lifelong learning system can adapt to new data without forgetting previously acquired knowledge. In this paper, we introduce the first benchmark for lifelong learning machine translation. For this purpose, we provide training, lifelong and test data sets for two language pairs: English-German and English-French. Additionally, we report the results of our baseline systems, which we make available to the public. The goal of this shared task is to encourage research on the emerging topic of lifelong learning machine translation."
2020.wmt-1.10,The {TALP}-{UPC} System Description for {WMT}20 News Translation Task: Multilingual Adaptation for Low Resource {MT},2020,-1,-1,2,1,5757,carlos escolano,Proceedings of the Fifth Conference on Machine Translation,0,"In this article, we describe the TALP-UPC participation in the WMT20 news translation shared task for Tamil-English. Given the low amount of parallel training data, we resort to adapt the task to a multilingual system to benefit from the positive transfer from high resource languages. We use iterative backtranslation to fine-tune the system and benefit from the monolingual data available. In order to measure the effectivity of such methods, we compare our results to a bilingual baseline system."
2020.wmt-1.47,The {IPN}-{CIC} team system submission for the {WMT} 2020 similar language task,2020,-1,-1,3,0,13870,luis menendezsalazar,Proceedings of the Fifth Conference on Machine Translation,0,This paper describes the participation of the NLP research team of the IPN Computer Research center in the WMT 2020 Similar Language Translation Task. We have submitted systems for the Spanish-Portuguese language pair (in both directions). The three submitted systems are based on the Transformer architecture and used fine tuning for domain Adaptation.
2020.wmt-1.54,"Multilingual Neural Machine Translation: Case-study for {C}atalan, {S}panish and {P}ortuguese {R}omance Languages",2020,-1,-1,2,0,13881,pere boncompte,Proceedings of the Fifth Conference on Machine Translation,0,"In this paper, we describe the TALP-UPC participation in the WMT Similar Language Translation task between Catalan, Spanish, and Portuguese, all of them, Romance languages. We made use of different techniques to improve the translation between these languages. The multilingual shared encoder/decoder has been used for all of them. Additionally, we applied back-translation to take advantage of the monolingual data. Finally, we have applied fine-tuning to improve the in-domain data. Each of these techniques brings improvements over the previous one. In the official evaluation, our system was ranked 1st in the Portuguese-to-Spanish direction, 2nd in the opposite direction, and 3rd in the Catalan-Spanish pair."
2020.winlp-1.25,Towards Mitigating Gender Bias in a decoder-based Neural Machine Translation model by Adding Contextual Information,2020,-1,-1,2,1,5325,christine basta,Proceedings of the The Fourth Widening Natural Language Processing Workshop,0,"Gender bias negatively impacts many natural language processing applications, including machine translation (MT). The motivation behind this work is to study whether recent proposed MT techniques are significantly contributing to attenuate biases in document-level and gender-balanced data. For the study, we consider approaches of adding the previous sentence and the speaker information, implemented in a decoder-based neural MT system. We show improvements both in translation quality (+1 BLEU point) as well as in gender bias mitigation on WinoMT (+5{\%} accuracy)."
2020.spnlp-1.1,Syntax-driven Iterative Expansion Language Models for Controllable Text Generation,2020,34,0,3,1,14539,noe casas,Proceedings of the Fourth Workshop on Structured Prediction for NLP,0,"The dominant language modeling paradigm handles text as a sequence of discrete tokens. While that approach can capture the latent structure of the text, it is inherently constrained to sequential dynamics for text generation. We propose a new paradigm for introducing a syntactic inductive bias into neural text generation, where the dependency parse tree is used to drive the Transformer model to generate sentences iteratively. Our experiments show that this paradigm is effective at text generation, with quality between LSTMs and Transformers, and comparable diversity, requiring less than half their decoding steps, and its generation process allows direct control over the syntactic constructions of the generated text, enabling the induction of stylistic variations."
2020.lrec-1.191,Abusive language in {S}panish children and young teenager{'}s conversations: data preparation and short text classification with contextual word embeddings,2020,-1,-1,1,1,5326,marta costajussa,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Abusive texts are reaching the interests of the scientific and social community. How to automatically detect them is onequestion that is gaining interest in the natural language processing community. The main contribution of this paper is toevaluate the quality of the recently developed {''}Spanish Database for cyberbullying prevention{''} for the purpose of trainingclassifiers on detecting abusive short texts. We compare classical machine learning techniques to the use of a more ad-vanced model: the contextual word embeddings in the particular case of classification of abusive short-texts for the Spanishlanguage. As contextual word embeddings, we use Bidirectional Encoder Representation from Transformers (BERT), pro-posed at the end of 2018. We show that BERT mostly outperforms classical techniques. Far beyond the experimentalimpact of our research, this project aims at planting the seeds for an innovative technological tool with a high potentialsocial impact and aiming at being part of the initiatives in artificial intelligence for social good."
2020.lrec-1.502,{G}e{B}io{T}oolkit: Automatic Extraction of Gender-Balanced Multilingual Corpus of {W}ikipedia Biographies,2020,-1,-1,1,1,5326,marta costajussa,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We introduce GeBioToolkit, a tool for extracting multilingual parallel corpora at sentence level, with document and gender information from Wikipedia biographies. Despite the gender inequalities present in Wikipedia, the toolkit has been designed to extract corpus balanced in gender. While our toolkit is customizable to any number of languages (and different domains), in this work we present a corpus of 2,000 sentences in English, Spanish and Catalan, which has been post-edited by native speakers to become a high-quality dataset for machine translation evaluation. While GeBioCorpus aims at being one of the first non-synthetic gender-balanced test datasets, GeBioToolkit aims at paving the path to standardize procedures to produce gender-balanced datasets."
2020.lrec-1.677,Automatic {S}panish Translation of {SQ}u{AD} Dataset for Multi-lingual Question Answering,2020,-1,-1,2,1,8507,casimiro carrino,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Recently, multilingual question answering became a crucial research topic, and it is receiving increased interest in the NLP community. However, the unavailability of large-scale datasets makes it challenging to train multilingual QA systems with performance comparable to the English ones. In this work, we develop the Translate Align Retrieve (TAR) method to automatically translate the Stanford Question Answering Dataset (SQuAD) v1.1 to Spanish. We then used this dataset to train Spanish QA systems by fine-tuning a Multilingual-BERT model. Finally, we evaluated our QA models with the recently proposed MLQA and XQuAD benchmarks for cross-lingual Extractive QA. Experimental results show that our models outperform the previous Multilingual-BERT baselines achieving the new state-of-the-art values of 68.1 F1 on the Spanish MLQA corpus and 77.6 F1 on the Spanish XQuAD corpus. The resulting, synthetically generated SQuAD-es v1.1 corpora, with almost 100{\%} of data contained in the original English version, to the best of our knowledge, is the first large-scale QA training resource for Spanish."
2020.gebnlp-1.3,Fine-tuning Neural Machine Translation on Gender-Balanced Datasets,2020,-1,-1,1,1,5326,marta costajussa,Proceedings of the Second Workshop on Gender Bias in Natural Language Processing,0,"Misrepresentation of certain communities in datasets is causing big disruptions in artificial intelligence applications. In this paper, we propose using an automatically extracted gender-balanced dataset parallel corpus from Wikipedia. This balanced set is used to perform fine-tuning techniques from a bigger model trained on unbalanced datasets to mitigate gender biases in neural machine translation."
2020.ecomnlp-1.1,{E}-Commerce Content and Collaborative-based Recommendation using K-Nearest Neighbors and Enriched Weighted Vectors,2020,-1,-1,2,0,20778,bardia rafieian,Proceedings of Workshop on Natural Language Processing in E-Commerce,0,"In this paper, we present two productive and functional recommender methods to improve the ac- curacy of predicting the right product for the user. One proposal is a survey-based recommender system that uses k-nearest neighbors. It recommends products by asking questions from the user, efficiently applying a binary product vector to the product attributes, and processing the request with a minimum error. The second proposal uses an enriched collaborative-based recommender system using enriched weighted vectors. Thanks to the style rules, the enriched collaborative- based method recommends outfits with competitive recommendation quality. We evaluated both of the proposals on a Kaggle fashion-dataset along with iMaterialist and, results show equivalent performance on binary gender and product attributes."
2020.coling-main.574,Continual Lifelong Learning in Natural Language Processing: A Survey,2020,-1,-1,3,1,13773,magdalena biesialska,Proceedings of the 28th International Conference on Computational Linguistics,0,"Continual learning (CL) aims to enable information systems to learn from a continuous data stream across time. However, it is difficult for existing deep learning architectures to learn a new task without largely forgetting previously acquired knowledge. Furthermore, CL is particularly challenging for language learning, as natural language is ambiguous: it is discrete, compositional, and its meaning is context-dependent. In this work, we look at the problem of CL through the lens of various NLP tasks. Our survey discusses major challenges in CL and current methods applied in neural network models. We also provide a critical review of the existing CL evaluation methods and datasets in NLP. Finally, we present our outlook on future research directions."
2020.cl-2.1,Multilingual and Interlingual Semantic Representations for Natural Language Processing: A Brief Introduction,2020,2,0,1,1,5326,marta costajussa,Computational Linguistics,0,"We introduce the Computational Linguistics special issue on Multilingual and Interlingual Semantic Representations for Natural Language Processing. We situate the special issue{'}s five articles in the context of our fast-changing field, explaining our motivation for this project. We offer a brief summary of the work in the issue, which includes developments on lexical and sentential semantic representations, from symbolic and neural perspectives."
2020.acl-srw.10,Combining Subword Representations into Word-level Representations in the Transformer Architecture,2020,-1,-1,2,1,14539,noe casas,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"In Neural Machine Translation, using word-level tokens leads to degradation in translation quality. The dominant approaches use subword-level tokens, but this increases the length of the sequences and makes it difficult to profit from word-level information such as POS tags or semantic dependencies. We propose a modification to the Transformer model to combine subword-level representations into word-level ones in the first layers of the encoder, reducing the effective length of the sequences in the following layers and providing a natural point to incorporate extra word-level information. Our experiments show that this approach maintains the translation quality with respect to the normal Transformer model when no extra word-level information is injected and that it is superior to the currently dominant method for incorporating word-level source language information to models based on subword-level vocabularies."
2020.acl-srw.36,Enhancing Word Embeddings with Knowledge Extracted from Lexical Resources,2020,28,0,3,1,13773,magdalena biesialska,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"In this work, we present an effective method for semantic specialization of word vector representations. To this end, we use traditional word embeddings and apply specialization methods to better capture semantic relations between words. In our approach, we leverage external knowledge from rich lexical resources such as BabelNet. We also show that our proposed post-specialization method based on an adversarial neural network with the Wasserstein distance allows to gain improvements over state-of-the-art methods on two tasks: word similarity and dialog state tracking."
W19-5418,Terminology-Aware Segmentation and Domain Feature for the {WMT}19 Biomedical Translation Task,2019,0,0,3,1,8507,casimiro carrino,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"In this work, we give a description of the TALP-UPC systems submitted for the WMT19 Biomedical Translation Task. Our proposed strategy is NMT model-independent and relies only on one ingredient, a biomedical terminology list. We first extracted such a terminology list by labelling biomedical words in our training dataset using the BabelNet API. Then, we designed a data preparation strategy to insert the terms information at a token level. Finally, we trained the Transformer model with this terms-informed data. Our best-submitted system ranked 2nd and 3rd for Spanish-English and English-Spanish translation directions, respectively."
W19-5424,The {TALP}-{UPC} System for the {WMT} Similar Language Task: Statistical vs Neural Machine Translation,2019,15,0,3,1,13773,magdalena biesialska,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"Although the problem of similar language translation has been an area of research interest for many years, yet it is still far from being solved. In this paper, we study the performance of two popular approaches: statistical and neural. We conclude that both methods yield similar results; however, the performance varies depending on the language pair. While the statistical approach outperforms the neural one by a difference of 6 BLEU points for the Spanish-Portuguese language pair, the proposed neural model surpasses the statistical one by a difference of 2 BLEU points for Czech-Polish. In the former case, the language similarity (based on perplexity) is much higher than in the latter case. Additionally, we report negative results for the system combination with back-translation. Our TALP-UPC system submission won 1st place for Czech-{\textgreater}Polish and 2nd place for Spanish-{\textgreater}Portuguese in the official evaluation of the 1st WMT Similar Language Translation task."
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,3,0,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
W19-5311,The {TALP}-{UPC} Machine Translation Systems for {WMT}19 News Translation Task: Pivoting Techniques for Low Resource {MT},2019,0,0,5,1,14539,noe casas,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"In this article, we describe the TALP-UPC research group participation in the WMT19 news translation shared task for Kazakh-English. Given the low amount of parallel training data, we resort to using Russian as pivot language, training subword-based statistical translation systems for Russian-Kazakh and Russian-English that were then used to create two synthetic pseudo-parallel corpora for Kazakh-English and English-Kazakh respectively. Finally, a self-attention model based on the decoder part of the Transformer architecture was trained on the two pseudo-parallel corpora."
W19-3801,Gendered Ambiguous Pronoun ({GAP}) Shared Task at the Gender Bias in {NLP} Workshop 2019,2019,-1,-1,2,0,9606,kellie webster,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"The 1st ACL workshop on Gender Bias in Natural Language Processing included a shared task on gendered ambiguous pronoun (GAP) resolution. This task was based on the coreference challenge defined in Webster et al. (2018), designed to benchmark the ability of systems to resolve pronouns in real-world contexts in a gender-fair way. 263 teams competed via a Kaggle competition, with the winning system achieving logloss of 0.13667 and near gender parity. We review the approaches of eleven systems with accepted description papers, noting their effective use of BERT (Devlin et al., 2018), both via fine-tuning and for feature extraction, as well as ensembling."
W19-3805,Evaluating the Underlying Gender Bias in Contextualized Word Embeddings,2019,20,6,2,1,5325,christine basta,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"Gender bias is highly impacting natural language processing applications. Word embeddings have clearly been proven both to keep and amplify gender biases that are present in current data sources. Recently, contextualized word embeddings have enhanced previous word embedding techniques by computing word vector representations dependent on the sentence they appear in. In this paper, we study the impact of this conceptual change in the word embedding computation in relation with gender bias. Our analysis includes different measures previously applied in the literature to standard word embeddings. Our findings suggest that contextualized word embeddings are less biased than standard ones even when the latter are debiased."
W19-3811,{BERT} Masked Language Modeling for Co-reference Resolution,2019,0,1,2,0,24340,felipe alfaro,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"This paper explains the TALP-UPC participation for the Gendered Pronoun Resolution shared-task of the 1st ACL Workshop on Gender Bias for Natural Language Processing. We have implemented two models for mask language modeling using pre-trained BERT adjusted to work for a classification problem. The proposed solutions are based on the word probabilities of the original BERT model, but using common English names to replace the original test names."
W19-3821,Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques,2019,19,4,2,0,24353,joel font,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"Neural machine translation has significantly pushed forward the quality of the field. However, there are remaining big issues with the output translations and one of them is fairness. Neural models are trained on large text corpora which contain biases and stereotypes. As a consequence, models inherit these social biases. Recent methods have shown results in reducing gender bias in other natural language processing tools such as word embeddings. We take advantage of the fact that word embeddings are used in neural machine translation to propose a method to equalize gender biases in neural machine translation using these representations. Specifically, we propose, experiment and analyze the integration of two debiasing techniques over GloVe embeddings in the Transformer translation architecture. We evaluate our proposed system on the WMT English-Spanish benchmark task, showing gains up to one BLEU point. As for the gender bias evaluation, we generate a test set of occupations and we show that our proposed system learns to equalize existing biases from the baseline system."
P19-2033,From Bilingual to Multilingual Neural Machine Translation by Incremental Training,2019,22,0,2,1,5757,carlos escolano,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"Multilingual Neural Machine Translation approaches are based on the use of task specific models and the addition of one more language can only be done by retraining the whole system. In this work, we propose a new training schedule that allows the system to scale to more languages without modification of the previous components based on joint training and language-independent encoder/decoder modules allowing for zero-shot translation. This work in progress shows close results to state-of-the-art in the WMT task."
D19-3026,"Multilingual, Multi-scale and Multi-layer Visualization of Intermediate Representations",2019,15,1,2,1,5757,carlos escolano,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations,0,"The main alternatives nowadays to deal with sequences are Recurrent Neural Networks (RNN) architectures and the Transformer. In this context, Both RNN{'}s and Transformer have been used as an encoder-decoder architecture with multiple layers in each module. Far beyond this, these architectures are the basis for the contextual word embeddings which are revolutionizing most natural language downstream applications. However, intermediate representations in either the RNN or Transformer architectures can be difficult to interpret. To make these layer representations more accessible and meaningful, we introduce a web-based tool that visualizes them both at the sentence and token level. We present three use cases. The first analyses gender issues in contextual word embeddings. The second and third are showing multilingual intermediate representations for sentences and tokens and the evolution of these intermediate representations along with the multiple layers of the decoder and in the context of multilingual machine translation."
W18-6406,The {TALP}-{UPC} Machine Translation Systems for {WMT}18 News Shared Translation Task,2018,0,0,3,1,14539,noe casas,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"In this article we describe the TALP-UPC research group participation in the WMT18 news shared translation task for Finnish-English and Estonian-English within the multi-lingual subtrack. All of our primary submissions implement an attention-based Neural Machine Translation architecture. Given that Finnish and Estonian belong to the same language family and are similar, we use as training data the combination of the datasets of both language pairs to paliate the data scarceness of each individual pair. We also report the translation quality of systems trained on individual language pair data to serve as baseline and comparison reference."
W18-6449,Neural Machine Translation with the Transformer and Multi-Source {R}omance Languages for the Biomedical {WMT} 2018 task,2018,0,1,2,0,27726,brian tubay,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"The Transformer architecture has become the state-of-the-art in Machine Translation. This model, which relies on attention-based mechanisms, has outperformed previous neural machine translation architectures in several tasks. In this system description paper, we report details of training neural machine translation with multi-source Romance languages with the Transformer model and in the evaluation frame of the biomedical WMT 2018 task. Using multi-source languages from the same family allows improvements of over 6 BLEU points."
W18-3931,A Neural Approach to Language Variety Translation,2018,19,3,1,1,5326,marta costajussa,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,In this paper we present the first neural-based machine translation system trained to translate between standard national varieties of the same language. We take the pair Brazilian - European Portuguese as an example and compare the performance of this method to a phrase-based statistical machine translation system. We report a performance improvement of 0.9 BLEU points in translating from European to Brazilian Portuguese and 0.2 BLEU points when translating in the opposite direction. We also carried out a human evaluation experiment with native speakers of Brazilian Portuguese which indicates that humans prefer the output produced by the neural-based system in comparison to the statistical system.
W17-5309,Character-level Intra Attention Network for Natural Language Inference,2017,17,3,2,0,31537,han yang,Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for {NLP},0,"Natural language inference (NLI) is a central problem in language understanding. End-to-end artificial neural networks have reached state-of-the-art performance in NLI field recently. In this paper, we propose Character-level Intra Attention Network (CIAN) for the NLI task. In our model, we use the character-level convolutional network to replace the standard word embedding layer, and we use the intra attention to capture the intra-sentence semantics. The proposed CIAN model provides improved results based on a newly published MNLI corpus."
W17-4725,The {TALP}-{UPC} Neural Machine Translation System for {G}erman/{F}innish-{E}nglish Using the Inverse Direction Model in Rescoring,2017,4,4,2,1,5757,carlos escolano,Proceedings of the Second Conference on Machine Translation,0,"In this paper, we describe the TALP- UPC participation in the News Task for German-English and Finish-English. Our primary submission implements a fully character to character neural machine translation architecture with an additional rescoring of a n-best list of hypothesis us- ing a forced back-translation to the source sentence. This model gives consistent im- provements on different pairs of languages for the language direction with the low- est performance while keeping the qual- ity in the direction with the highest perfor- mance. Additional experiments are reported for multilingual character to character neural machine translation, phrase-based trans- lation and the additional Turkish-English language pair."
W17-4123,Byte-based Neural Machine Translation,2017,5,7,1,1,5326,marta costajussa,Proceedings of the First Workshop on Subword and Character Level Models in {NLP},0,This paper presents experiments comparing character-based and byte-based neural machine translation systems. The main motivation of the byte-based neural machine translation system is to build multi-lingual neural machine translation systems that can share the same vocabulary. We compare the performance of both systems in several language pairs and we see that the performance in test is similar for most language pairs while the training time is slightly reduced in the case of byte-based neural machine translation.
W17-1207,"Why {C}atalan-{S}panish Neural Machine Translation? Analysis, comparison and combination with standard Rule and Phrase-based technologies",2017,14,4,1,1,5326,marta costajussa,"Proceedings of the Fourth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial)",0,"Catalan and Spanish are two related languages given that both derive from Latin. They share similarities in several linguistic levels including morphology, syntax and semantics. This makes them particularly interesting for the MT task. Given the recent appearance and popularity of neural MT, this paper analyzes the performance of this new approach compared to the well-established rule-based and phrase-based MT systems. Experiments are reported on a large database of 180 million words. Results, in terms of standard automatic measures, show that neural MT clearly outperforms the rule-based and phrase-based MT system on in-domain test set, but it is worst in the out-of-domain test set. A naive system combination specially works for the latter. In-domain manual analysis shows that neural MT tends to improve both adequacy and fluency, for example, by being able to generate more natural translations instead of literal ones, choosing to the adequate target word when the source word has several translations and improving gender agreement. However, out-of-domain manual analysis shows how neural MT is more affected by unknown words or contexts."
W16-2713,{M}oses-based official baseline for {NEWS} 2016,2016,6,2,1,1,5326,marta costajussa,Proceedings of the Sixth Named Entity Workshop,0,Transliteration is the phonetic translation between two different languages. There are many works that approach transliteration using machine translation methods. This paper describes the official baseline system for the NEWS 2016 workshop shared task. This baseline is based on a standard phrase-based machine translation system using Moses. Results are between the range of best and worst from last yearxe2x80x99s workshops providing a nice starting point for participants this year.
W16-2336,The {TALP}{--}{UPC} {S}panish{--}{E}nglish {WMT} Biomedical Task: Bilingual Embeddings and Char-based Neural Language Model Rescoring in a Phrase-based System,2016,12,2,1,1,5326,marta costajussa,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the TALPxe2x80x93UPC system in the Spanishxe2x80x93English WMT 2016 biomedical shared task. Our system is a standard phrase-based system enhanced with vocabulary expansion using bilingual word embeddings and a characterbased neural language model with rescoring. The former focuses on resolving outof- vocabulary words, while the latter enhances the fluency of the system. The two modules progressively improve the final translation as measured by a combination of several lexical metrics."
W16-2362,{WMT} 2016 Multimodal Translation System Description based on Bidirectional Recurrent Neural Networks with Double-Embeddings,2016,17,2,2,0,33901,sergio guasch,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"Bidirectional Recurrent Neural Networks (BiRNNs) have shown outstanding results on sequence-to-sequence learning tasks. This architecture becomes specially interesting for multimodal machine translation task, since BiRNNs can deal with images and text. On most translation systems the same word embedding is fed to both BiRNN units. In this paper, we present several experiments to enhance a baseline sequence-to-sequence system (Elliott et al., 2015), for example, by using double embeddings. These embeddings are trained on the forward and backward direction of the input sequence. Our system is trained, validated and tested on the Multi30K dataset (Elliott et al., 2016) in the context of the WMT 2016 Multimodal Translation Task. The obtained results show that the double-embedding approach performs significantly better than the traditional single-embedding one."
P16-2058,Character-based Neural Machine Translation,2016,19,51,1,1,5326,marta costajussa,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Neural Machine Translation (MT) has reached state-of-the-art results. However, one of the main challenges that neural MT still faces is dealing with very large vocabularies and morphologically rich languages. In this paper, we propose a neural MT system using character-based embeddings in combination with convolutional and highway layers to replace the standard lookup-based word representations. The resulting unlimited-vocabulary and affix-aware source word embeddings are tested in a state-of-the-art neural MT based on an attention-based bidirectional recurrent neural network. The proposed MT scheme provides improved results even when the source language is not morphologically rich. Improvements up to 3 BLEU points are obtained in the German-English WMT task."
2016.eamt-2.9,Integration of machine translation paradigms,2016,-1,-1,1,1,5326,marta costajussa,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
W15-4109,Ongoing Study for Enhancing {C}hinese-{S}panish Translation with Morphology Strategies,2015,15,2,1,1,5326,marta costajussa,Proceedings of the Fourth Workshop on Hybrid Approaches to Translation ({H}y{T}ra),0,"Chinese and Spanish have different morphology structures, which poses a big challenge for translating between this pair of languages. In this paper, we analyze several strategies to better generalize from the Chinese non-morphology-based language to the Spanish rich morphologybased language. Strategies use a first-step of Spanish morphology-based simplifications and a second-step of fullform generation. The latter can be done using a translation system or classification methods. Finally, both steps are combined either by concatenation in cascade or integration using a factored-based style. Ongoing experiments (based on the United Nations corpus) and their results are described."
W14-3306,{E}nglish-to-{H}indi system description for {WMT} 2014: Deep Source-Context Features for {M}oses,2014,12,3,1,1,5326,marta costajussa,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes the IPN-UPV participation on the English-to-Hindi translation task from WMT 2014 International Evaluation Campaign. The system presented is based on Moses and enhanced with deep learning by means of a source-context feature function. This feature depends on the input sentence to translate, which makes it more challenging to adapt it into the Moses framework. This work reports the experimental details of the system putting special emphasis on: how the feature function is integrated in Moses and how the deep learning representations are trained and used."
W14-1015,{C}hinese-to-{S}panish rule-based machine translation system,2014,11,2,2,0,38798,jordi centelles,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,This paper describes the first freely available Chinese-to-Spanish rule-based machine translation system. The system has been built using the Apertium technology and combining manual and statistical techniques. Evaluation in different test sets shows a high coverage between 82-88%.
E14-2009,{CHISPA} on the {GO}: A mobile {C}hinese-{S}panish translation service for travellers in trouble,2014,7,4,2,0,38798,jordi centelles,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,This demo showcases a translation service that allows travelers to have an easy and convenient access to Chinese-Spanish translations via a mobile app. The system integrates a phrase-based translation system with other open source components such as Optical Character Recognition and Automatic Speech Recognition to provide a very friendly user experience.
W13-2801,Workshop on Hybrid Approaches to Translation: Overview and Developments,2013,17,6,1,1,5326,marta costajussa,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,"A current increasing trend in machine translation is to combine data-driven and rule-based techniques. Such combinations typically involve the hybridization of different paradigms such as, for instance, the introduction of linguistic knowledge into statistical paradigms, the incorporation of data-driven components into rulebased paradigms, or the pre- and postprocessing of either sort of translation system outputs. Aiming at bringing together researchers and practitioners from the different multidisciplinary areas working in these directions, as well as at creating a brainstorming and discussion venue for Hybrid Translation approaches, the HyTra initiative was born. This paper gives an overview of the Second Workshop on Hybrid Approaches to Translation (HyTra 2013) concerning its motivation, contents and outcomes."
W13-2215,"The {TALP}-{UPC} Phrase-Based Translation Systems for {WMT}13: System Combination with Morphology Generation, Domain Adaptation and Corpus Filtering",2013,18,5,2,0,40950,lluis formiga,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper describes the TALP participation in the WMT13 evaluation campaign. Our participation is based on the combination of several statistical machine translation systems: based on standard phrasebased Moses systems. Variations include techniques such as morphology generation, training sentence filtering, and domain adaptation through unit derivation. The results show a coherent improvement on TER, METEOR, NIST, and BLEU scores when compared to our baseline system."
N13-4006,"Morphological, Syntactical and Semantic Knowledge in Statistical Machine Translation",2013,0,1,1,1,5326,marta costajussa,NAACL HLT 2013 Tutorial Abstracts,0,"This tutorial focuses on how morphology, syntax and semantics may be introduced into a standard phrase-based statistical machine translation system with techniques such as machine learning, parsing and word sense disambiguation, among others. Regarding the phrase-based system, we will describe only the key theory behind it. The main challenges of this approach are that the output contains unknown words, wrong word orders and non-adequate translated words. To solve these challenges, recent research enhances the standard system using morphology, syntax and semantics. Morphologically-rich languages have many different surface forms, even though the stem of a word may be the same. This leads to rapid vocabulary growth, as various prefixes and suffixes can combine with stems in a large number of possible combinations. Language model probability estimation is less robust because many more word forms occur rarely in the data. This morphologically-induced sparsity can be reduced by incorporating morphological information into the SMT system. We will describe the three most common solutions to face morphology: preprocessing the data so that the input language more closely resembles the output language; using additional language models that introduce morphological information; and post-processing the output to add proper inflections. Syntax differences between the source and target language may lead to significant differences in the relative word order of translated words. Standard phrasebased SMT systems surmount reordering/syntactic challenges by learning from data. Most approaches model reordering inside translation units and using statistical methodologies, which limits the performance in language pairs with different grammatical structures. We will briefly introduce some recent advances in"
W12-5709,Results from the {ML}4{HMT}-12 Shared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine Translation,2012,11,0,4,0,6017,christian federmann,Proceedings of the Second Workshop on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid {MT},0,We describe the second edition of the ML4HMT shared task which challenges participants to create hybrid translations from the translation output of several individual MT systems. We provide an overview of the shared task and the data made available to participants before briefly describing the individual systems. We report on the results using automatic evaluation metrics and conclude with a summary of ML4HMT-12 and an outlook to future work.
avramidis-etal-2012-richly,"A Richly Annotated, Multilingual Parallel Corpus for Hybrid Machine Translation",2012,12,3,2,0,5140,eleftherios avramidis,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In recent years, machine translation (MT) research has focused on investigating how hybrid machine translation as well as system combination approaches can be designed so that the resulting hybrid translations show an improvement over the individual ÂcomponentÂ translations. As a first step towards achieving this objective we have developed a parallel corpus with source text and the corresponding translation output from a number of machine translation engines, annotated with metadata information, capturing aspects of the translation process performed by the different MT systems. This corpus aims to serve as a basic resource for further research on whether hybrid machine translation algorithms and system combination techniques can benefit from additional (linguistically motivated, decoding, and runtime) information provided by the different systems involved. In this paper, we describe the annotated corpus we have created. We provide an overview on the component MT systems and the XLIFF-based annotation format we have developed. We also report on first experiments with the ML4HMT corpus data."
melero-etal-2012-holaaa,Holaaa!! writin like u talk is kewl but kinda hard 4 {NLP},2012,14,5,2,0,4983,maite melero,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present work in progress aiming to build tools for the normalization of User-Generated Content (UGC). As we will see, the task requires the revisiting of the initial steps of NLP processing, since UGC (micro-blog, blog, and, generally, Web 2.0 user texts) presents a number of non-standard communicative and linguistic characteristics, and is in fact much closer to oral and colloquial language than to edited text. We present and characterize a corpus of UGC text in Spanish from three different sources: Twitter, consumer reviews and blogs. We motivate the need for UGC text normalization by analyzing the problems found when processing this type of text through a conventional language processing pipeline, particularly in the tasks of lemmatization and morphosyntactic tagging, and finally we propose a strategy for automatically normalizing UGC using a selector of correct forms on top of a pre-existing spell-checker."
adell-etal-2012-buceador,"{BUCEADOR}, a multi-language search engine for digital libraries",2012,17,3,4,0,43224,jordi adell,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents a web-based multimedia search engine built within the Buceador (www.buceador.org) research project. A proof-of-concept tool has been implemented which is able to retrieve information from a digital library made of multimedia documents in the 4 official languages in Spain (Spanish, Basque, Catalan and Galician). The retrieved documents are presented in the user language after translation and dubbing (the four previous languages + English). The paper presents the tool functionality, the architecture, the digital library and provide some information about the technology involved in the fields of automatic speech recognition, statistical machine translation, text-to-speech synthesis and information retrieval. Each technology has been adapted to the purposes of the presented tool as well as to interact with the rest of the technologies involved."
federmann-etal-2012-ml4hmt,The {ML}4{HMT} Workshop on Optimising the Division of Labour in Hybrid Machine Translation,2012,22,3,3,0,6017,christian federmann,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We describe the ÂShared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine TranslationÂ (ML4HMT) which aims to foster research on improved system combination approaches for machine translation (MT). Participants of the challenge are requested to build hybrid translations by combining the output of several MT systems of different types. We first describe the ML4HMT corpus used in the shared task, then explain the XLIFF-based annotation format we have designed for it, and briefly summarize the participating systems. Using both automated metrics scores and extensive manual evaluation, we discuss the individual performance of the various systems. An interesting result from the shared task is the fact that we were able to observe different systems winning according to the automated metrics scores when compared to the results from the manual evaluation. We conclude by summarising the first edition of the challenge and by giving an outlook to future work."
W11-2156,The {BM}-{I}2{R} {H}aitian-Cr{\\'e}ole-to-{E}nglish translation system description for the {WMT} 2011 evaluation campaign,2011,7,4,1,1,5326,marta costajussa,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,This work describes the Haitian-Creole to English statistical machine translation system built by Barcelona Media Innovation Center (BM) and Institute for Infocomm Research (I2R) for the 6th Workshop on Statistical Machine Translation (WMT 2011). Our system carefully processes the available data and uses it in a standard phrase-based system enhanced with a source context semantic feature that helps conducting a better lexical selection and a feature orthogonalization procedure that helps making MERT optimization more reliable and stable. Our system was ranked first (among a total of 9 participant systems) by the conducted human evaluation.
W11-1014,A Semantic Feature for Statistical Machine Translation,2011,19,28,2,0.231018,28438,rafael banchs,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"A semantic feature for statistical machine translation, based on Latent Semantic Indexing, is proposed and evaluated. The objective of the proposed feature is to account for the degree of similarity between a given input sentence and each individual sentence in the training dataset. This similarity is computed in a reduced vector-space constructed by means of the Latent Semantic Indexing decomposition. The computed similarity values are used as an additional feature in the log-linear model combination approach to statistical machine translation. In our implementation, the proposed feature is dynamically adjusted for each translation unit in the translation table according to the current input sentence to be translated. This model aims at favoring those translation units that were extracted from training sentences that are semantically related to the current input sentence being translated. Experimental results on a Spanish-to-English translation task on the Bible corpus demonstrate a significant improvement on translation quality with respect to a baseline system."
I11-1154,Enhancing scarce-resource language translation through pivot combinations,2011,17,10,1,1,5326,marta costajussa,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Chinese and Spanish are the most spoken languages in the world. However, there is not much research done in machine translation for this language pair. We experiment with the parallel Chinese-Spanish corpus (United Nations) to explore alternatives of SMT strategies which consist on using a pivot language. Particularly, two well-known alternatives are shown for pivoting: the cascade system and the pseudo-corpus. As Pivot language we use English, Arabic and French. Results show that English is the best pivot language between Chinese and Spanish. As a new strategy, we propose to perform a combination of the pivot strategies which is capable to highly outperform the direct translation strategy."
W10-1712,Using Collocation Segmentation to Augment the Phrase Table,2010,11,9,2,0,42253,carlos henriquez,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the 2010 phrase-based statistical machine translation system developed at the TALP Research Center of the UPC in cooperation with BMIC and VMU. In phrase-based SMT, the phrase table is the main tool in translation. It is created extracting phrases from an aligned parallel corpus and then computing translation model scores with them. Performing a collocation segmentation over the source and target corpus before the alignment causes that different and larger phrases are extracted from the same original documents. We performed this segmentation and used the union of this phrase set with the phrase set extracted from the non-segmented corpus to compute the phrase table. We present the configurations considered and also report results obtained with internal and official test sets."
W10-0718,Opinion Mining of {S}panish Customer Comments with Non-Expert Annotations on {M}echanical {T}urk,2010,7,30,5,0,45520,bart mellebeek,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"One of the major bottlenecks in the development of data-driven AI Systems is the cost of reliable human annotations. The recent advent of several crowdsourcing platforms such as Amazon's Mechanical Turk, allowing requesters the access to affordable and rapid results of a global workforce, greatly facilitates the creation of massive training data. Most of the available studies on the effectiveness of crowdsourcing report on English data. We use Mechanical Turk annotations to train an Opinion Mining System to classify Spanish consumer comments. We design three different Human Intelligence Task (HIT) strategies and report high inter-annotator agreement between non-experts and expert annotators. We evaluate the advantages/drawbacks of each HIT design and show that, in our case, the use of non-expert annotations is a viable and cost-effective alternative to expert annotations."
costa-jussa-fonollosa-2010-using,Using Linear Interpolation and Weighted Reordering Hypotheses in the {M}oses System,2010,-1,-1,1,1,5326,marta costajussa,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper proposes to introduce a novel reordering model in the open-source Moses toolkit. The main idea is to provide weighted reordering hypotheses to the SMT decoder. These hypotheses are built using a first-step Ngram-based SMT translation from a source language into a third representation that is called reordered source language. Each hypothesis has its own weight provided by the Ngram-based decoder. This proposed reordering technique offers a better and more efficient translation when compared to both the distance-based and the lexicalized reordering. In addition to this reordering approach, this paper describes a domain adaptation technique which is based on a linear combination of an specific in-domain and an extra out-domain translation models. Results for both approaches are reported in the Arabic-to-English 2008 IWSLT task. When implementing the weighted reordering hypotheses and the domain adaptation technique in the final translation system, translation results reach improvements up to 2.5 BLEU compared to a standard state-of-the-art Moses baseline system."
costa-jussa-etal-2010-automatic,Automatic and Human Evaluation Study of a Rule-based and a Statistical {C}atalan-{S}panish Machine Translation Systems,2010,12,2,1,1,5326,marta costajussa,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Machine translation systems can be classified into rule-based and corpus-based approaches, in terms of their core technology. Since both paradigms have largely been used during the last years, one of the aims in the research community is to know how these systems differ in terms of translation quality. To this end, this paper reports a study and comparison of a rule-based and a corpus-based (particularly, statistical) Catalan-Spanish machine translation systems, both of them freely available in the web. The translation quality analysis is performed under two different domains: journalistic and medical. The systems are evaluated by using standard automatic measures, as well as by native human evaluators. Automatic results show that the statistical system performs better than the rule-based system. Human judgements show that in the Spanish-to-Catalan direction the statistical system also performs better than the rule-based system, while in the Catalan-to-Spanish direction is the other way round. Although the statistical system obtains the best automatic scores, its errors tend to be more penalized by human judgements than the errors of the rule-based system. This can be explained because statistical errors are usually unexpected and they do not follow any pattern."
2010.iwslt-evaluation.26,{UPC}-{BMIC}-{VDU} system description for the {IWSLT} 2010: testing several collocation segmentations in a phrase-based {SMT} system,2010,0,1,2,0,42253,carlos henriquez,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the UPC-BMIC-VMU participation in the IWSLT 2010 evaluation campaign. The SMT system is a standard phrase-based enriched with novel segmentations. These novel segmentations are computed using statistical measures such as Log-likelihood, T-score, Chi-squared, Dice, Mutual Information or Gravity-Counts. The analysis of translation results allows to divide measures into three groups. First, Log-likelihood, Chi-squared and T-score tend to combine high frequency words and collocation segments are very short. They improve the SMT system by adding new translation units. Second, Mutual Information and Dice tend to combine low frequency words and collocation segments are short. They improve the SMT system by smoothing the translation units. And third, GravityCounts tends to combine high and low frequency words and collocation segments are long. However, in this case, the SMT system is not improved. Thus, the road-map for translation system improvement is to introduce new phrases with either low frequency or high frequency words. It is hard to introduce new phrases with low and high frequency words in order to improve translation quality. Experimental results are reported in the French-to-English IWSLT 2010 evaluation where our system was ranked 3rd out of nine systems."
2010.eamt-1.12,Linguistic-based Evaluation Criteria to identify Statistical Machine Translation Errors,2010,18,28,2,1,30210,mireia farrus,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"Machine translation evaluation methodsn are highly necessary in order to analyze then performance of translation systems. Up ton now, the most traditional methods are then use of automatic measures such as BLEUn or the quality perception performed by nativen human evaluations. In order to complementn these traditional procedures, then current paper presents a new human evaluationn based on the expert knowledge aboutn the errors encountered at several linguisticn levels: orthographic, morphological, lexical,n semantic and syntactic. The results obtainedn in these experiments show that somen linguistic errors could have more influencen than other at the time of performing a perceptual evaluation."
2010.eamt-1.17,Integration of statistical collocation segmentations in a phrase-based statistical machine translation system,2010,15,2,1,1,5326,marta costajussa,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,This study evaluates the impact of integrating two different collocation segmentations methods in a standard phrase-based statistical machine translation approach. The collocation segmentation techniques are implemented simultaneously in the source and target side. Each resulting collocation segmentation is used to extract translation units. Experiments are reported in the English-to-Spanish Bible task and promising results (an improvement over 0.7 BLEU absolute) are achieved in translation quality.
W09-0414,The {TALP}-{UPC} Phrase-Based Translation System for {EACL}-{WMT} 2009,2009,13,3,3,0,5758,jose fonollosa,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"This study presents the TALP-UPC submission to the EACL Fourth Worskhop on Statistical Machine Translation 2009 evaluation campaign. It outlines the architecture and configuration of the 2009 phrase-based statistical machine translation (SMT) system, putting emphasis on the major novelty of this year: combination of SMT systems implementing different word reordering algorithms.n n Traditionally, we have concentrated on the Spanish-to-English and English-to-Spanish News Commentary translation tasks."
2009.iwslt-evaluation.3,{B}arcelona Media {SMT} system description for the {IWSLT} 2009,2009,11,1,1,1,5326,marta costajussa,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the Barcelona Media SMT system in the IWSLT 2009 evaluation campaign. The Barcelona Media system is an statistical phrase-based system enriched with source context information. Adding source context in an SMT system is interesting to enhance the translation in order to solve lexical and structural choice errors. The novel technique uses a similarity metric among each test sentence and each training sentence. First experimental results of this technique are reported in the Arabic and Chinese Basic Traveling Expression Corpus (BTEC) task. Although working in a single domain, there are ambiguities in SMT translation units and slight improvements in BLEU are shown in both tasks (Zh2En and Ar2En)."
2009.eamt-1.8,Improving a {C}atalan-{S}panish Statistical Translation System using Morphosyntactic Knowledge,2009,7,5,2,1,30210,mireia farrus,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"In this paper, a human evaluation of a Catalan-Spanish Ngram-based statistical machine translation system is used to develop specific techniques based on the use of grammatical categories, lexical categorisation and text processing, for the enhancement of the final translation. The system is successfully improved when testing with ad hoc and general corpora, as it is shown in the final automatic evaluation."
W08-0315,The {TALP}-{UPC} {N}gram-Based Statistical Machine Translation System for {ACL}-{WMT} 2008,2008,11,6,3,0.454545,17603,maxim khalilov,Proceedings of the Third Workshop on Statistical Machine Translation,0,"This paper reports on the participation of the TALP Research Center of the UPC (Universitat Politecnica de Catalunya) to the ACL WMT 2008 evaluation campaign.n n This year's system is the evolution of the one we employed for the 2007 campaign. Main updates and extensions involve linguistically motivated word reordering based on the reordering patterns technique. In addition, this system introduces a target language model, based on linguistic classes (Part-of-Speech), morphology reduction for an inflectional language (Spanish) and an improved optimization procedure.n n Results obtained over the development and test sets on Spanish to English (and the other way round) translations for both the traditional Europarl and a challenging News stories tasks are analyzed and commented."
costa-jussa-etal-2008-using,Using Reordering in Statistical Machine Translation based on Alignment Block Classification,2008,25,4,1,1,5326,marta costajussa,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Statistical Machine Translation (SMT) is based on alignment models which learn from bilingual corpora the word correspondences between source and target language. These models are assumed to be capable of learning reorderings of sequences of words. However, the difference in word order between two languages is one of the most important sources of errors in SMT. This paper proposes a Recursive Alignment Block Classification algorithm (RABCA) that can take advantage of inductive learning in order to solve reordering problems. This algorithm should be able to cope with swapping examples seen during training; it should infer properties that might permit to reorder pairs of blocks (sequences of words) which did not appear during training; and finally it should be robust with respect to training errors and ambiguities. Experiments are reported on the EuroParl task and RABCA is tested using two state-of-the-art SMT systems: a phrased-based and an Ngram-based. In both cases, RABCA improves results."
2008.amta-papers.6,Computing multiple weighted reordering hypotheses for a phrase-based statistical machine translation system,2008,12,3,1,1,5326,marta costajussa,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"Reordering is one source of error in statistical machine translation (SMT). This paper extends the study of the statistical machine reordering (SMR) approach, which uses the powerful techniques of the SMT systems to solve reordering problems. Here, the novelties yield in: (1) using the SMR approach in a SMT phrase-based system, (2) adding a feature function in the SMR step, and (3) analyzing the reordering hypotheses at several stages. Coherent improvements are reported in the TC-STAR task (Es/En) at a relatively low computational cost."
W07-0720,Ngram-Based Statistical Machine Translation Enhanced with Multiple Weighted Reordering Hypotheses,2007,7,9,1,1,5326,marta costajussa,Proceedings of the Second Workshop on Statistical Machine Translation,0,"This paper describes the 2007 Ngram-based statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Politecnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the previous years system, being highlyghted and empirically compared. Mainly, these include a novel word ordering strategy based on: (1) statistically monotonizing the training source corpus and (2) a novel reordering approach based on weighted reordering graphs. In addition, this system introduces a target language model based on statistical classes, a feature for out-of-domain units and an improved optimization procedure.n n The paper provides details of this system participation in the ACL 2007 SECOND WORKSHOP ON STATISTICAL MACHINE TRANSLATION. Results on three pairs of languages are reported, namely from Spanish, French and German into English (and the other way round) for both the in-domain and out-of-domain tasks."
W07-0721,Analysis of Statistical and Morphological Classes to Generate Weigthed Reordering Hypotheses on a Statistical Machine Translation System,2007,15,10,1,1,5326,marta costajussa,Proceedings of the Second Workshop on Statistical Machine Translation,0,"One main challenge of statistical machine translation (SMT) is dealing with word order. The main idea of the statistical machine reordering (SMR) approach is to use the powerful techniques of SMT systems to generate a weighted reordering graph for SMT systems. This technique supplies reordering constraints to an SMT system, using statistical criteria.n n In this paper, we experiment with different graph pruning which guarantees the translation quality improvement due to reordering at a very low increase of computational cost.n n The SMR approach is capable of generalizing reorderings, which have been learned during training, by using word classes instead of words themselves. We experiment with statistical and morphological classes in order to choose those which capture the most probable reorderings.n n Satisfactory results are reported in the WMT07 Es/En task. Our system outperforms in terms of BLEU the WMT07 Official baseline system."
N07-2035,Analysis and System Combination of Phrase- and {N}-Gram-Based Statistical Machine Translation Systems,2007,10,9,1,1,5326,marta costajussa,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,"In the framework of the Tc-Star project, we analyze and propose a combination of two Statistical Machine Translation systems: a phrase-based and an N-gram-based one. The exhaustive analysis includes a comparison of the translation models in terms of efficiency (number of translation units used in the search and computational time) and an examination of the errors in each system's output. Additionally, we combine both systems, showing accuracy improvements."
D07-1045,Smooth Bilingual $N$-Gram Translation,2007,18,34,2,0.606061,5770,holger schwenk,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We address the problem of smoothing translation probabilities in a bilingual N-grambased statistical machine translation system. It is proposed to project the bilingual tuples onto a continuous space and to estimate the translation probabilities in this representation. A neural network is used to perform the projection and the probability estimation. Smoothing probabilities is most important for tasks with a limited amount of training material. We consider here the BTEC task of the 2006 IWSLT evaluation. Improvements in all official automatic measures are reported when translating from Italian to English. Using a continuous space model for the translation model and the target language model, an improvement of 1.5 BLEU on the test data is observed."
2007.iwslt-1.26,The {TALP} ngram-based {SMT} system for {IWSLT} 2007,2007,-1,-1,2,0.47619,23604,patrik lambert,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper describes TALPtuples, the 2007 N-gram-based statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Polite`cnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the system of previous years. Mainly, these include optimizing alignment parameters in function of translation metric scores and rescoring with a neural network language model. Results on two translation directions are reported, namely from Arabic and Chinese into English, thoroughly explaining all language-related preprocessing and translation schemes."
W06-3120,{TALP} Phrase-based statistical translation system for {E}uropean language pairs,2006,15,9,1,1,5326,marta costajussa,Proceedings on the Workshop on Statistical Machine Translation,0,This paper reports translation results for the Exploiting Parallel Texts for Statistical Machine Translation (HLT-NAACL Workshop on Parallel Texts 2006). We have studied different techniques to improve the standard Phrase-Based translation system. Mainly we introduce two reordering approaches and add morphological information.
W06-3125,N-gram-based {SMT} System Enhanced with Reordering Patterns,2006,13,20,4,0.680272,836,josep crego,Proceedings on the Workshop on Statistical Machine Translation,0,"This work presents translation results for the three data sets made available in the shared task Exploiting Parallel Texts for Statistical Machine Translation of the HLT-NAACL 2006 Workshop on Statistical Machine Translation. All results presented were generated by using the N-gram-based statistical machine translation system which has been enhanced from the last year's evaluation with a tagged target language model (using Part-Of-Speech tags). For both Spanish-English translation directions and the English-to-French translation task, the baseline system allows for linguistically motivated source-side reorderings."
W06-1609,Statistical Machine Reordering,2006,12,58,1,1,5326,marta costajussa,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"Reordering is currently one of the most important problems in statistical machine translation systems. This paper presents a novel strategy for dealing with it: statistical machine reordering (SMR). It consists in using the powerful techniques developed for statistical machine translation (SMT) to translate the source language (S) into a reordered source language (S'), which allows for an improved translation into the target language (T). The SMT task changes from S2T to S'2T which leads to a monotonized word alignment and shorter translation units. In addition, the use of classes in SMR helps to infer new word reorderings. Experiments are reported in the EsEn WMT06 tasks and the ZhEn IWSLT05 task and show significant improvement in translation quality."
J06-4004,N-gram-based Machine Translation,2006,36,210,7,0,40951,jose marino,Computational Linguistics,0,"This article describes in detail an n-gram approach to statistical machine translation. This approach consists of a log-linear combination of a translation model based on n-grams of bilingual units, which are referred to as tuples, along with four specific feature functions. Translation performance, which happens to be in the state of the art, is demonstrated with Spanish-to-English and English-to-Spanish translations of the European Parliament Plenary Sessions (EPPS)."
2006.iwslt-papers.2,Continuous space language models for the {IWSLT} 2006 task,2006,14,21,2,0.606061,5770,holger schwenk,Proceedings of the Third International Workshop on Spoken Language Translation: Papers,0,"The language model of the target language plays an important role in statistical machine translation systems. In this work, we propose to use a new statistical language model that is based on a continuous representation of the words in the vocabulary. A neural network is used to perform the projection and the probability estimation. This kind of approach is in particular promising for tasks where a very limited amount of resources are available, like the BTEC corpus of tourism related questions. This language model is used in two state-of-the-art statistical machine translation systems that were developed by UPC for the 2006 IWSLT evaluation campaign: a phraseand an n-gram-based approach. An experimental evaluation for four different language pairs is provided (translation of Mandarin, Japanese, Arabic and Italian to English). The proposed method achieved improvements in the BLEU score of up to 3 points on the development data and of almost 2 points on the official test data."
2006.iwslt-evaluation.17,The {TALP} Ngram-based {SMT} systems for {IWSLT} 2006,2006,37,25,5,0.680272,836,josep crego,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes TALPtuples, the 2006 Ngrambased statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Polit ecnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the system of previous years, being highlighted and empirically compared. Mainly, these include a novel and much more efcient word ordering strategy based on reordering patterns, a linguistically-guided tuple segmentation criterion and improved optimization procedures. The paper provides details of this system participation in the third International Workshop on Spoken Language Translation (IWSLT) held in Kyoto, Japan in November 2006. Results on four translation directions are reported, namely from Arabic, Chinese, Italian and Japanese into English for the open data track, thoroughly explaining all language-related preprocessing and optimization schemes."
2006.iwslt-evaluation.18,{TALP} phrase-based system and {TALP} system combination for {IWSLT} 2006,2006,14,7,1,1,5326,marta costajussa,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the TALP phrase-based statistical machine translation system, enriched with the statistical machine reordering technique. We also report the combination of this system and the TALP-tuple, the n-gram-based statistical machine translation system. We report the results for all the tasks (Chinese, Arabic, Italian and Japanese to English) in the framework of the third evaluation campaign of the International Workshop on Spoken Language Translation."
W05-0827,Improving Phrase-Based Statistical Translation by Modifying Phrase Extraction and Including Several Features,2005,15,5,1,1,5326,marta costajussa,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"Nowadays, most of the statistical translation systems are based on phrases (i.e. groups of words). In this paper we study different improvements to the standard phrase-based translation system. We describe a modified method for the phrase extraction which deals with larger phrases while keeping a reasonable number of phrases. We also propose additional features which lead to a clear improvement in the performance of the translation. We present results with the EuroParl task in the direction Spanish to English and results from the evaluation of the shared task Exploiting Parallel Texts for Statistical Machine Translation (ACL Workshop on Parallel Texts 2005)."
2005.iwslt-1.23,Ngram-based versus Phrase-based Statistical Machine Translation,2005,0,18,2,0,836,josep crego,Proceedings of the Second International Workshop on Spoken Language Translation,0,None
2005.iwslt-1.24,Tuning a phrase-based statistical translation system for the {IWSLT} 2005 {C}hinese to {E}nglish and {A}rabic to {E}nglish tasks,2005,13,3,1,1,5326,marta costajussa,Proceedings of the Second International Workshop on Spoken Language Translation,0,"Nowadays, most of the statistical translation systems are based on phrases (i.e. groups of words). We describe a phrase-based system using a modified method for the phrase extraction which deals with larger phrases while keeping a reasonable number of phrases. Also, different alignments to extract phrases are allowed and additional features are used which lead to a clear improvement in the performance of translation. Finally, the system manages to do reordering. We report results in terms of translation accuracy by using the BTEC corpus in the tasks of Chinese to English and Arabic to English, in the framework of IWSLTxe2x80x9905 evaluation."
