D14-1069,Non-linear Mapping for Improved Identification of 1300+ Languages,2014,11,6,1,1,40110,ralf brown,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Non-linear mappings of the form P (ngram)xcexb3 and log(1xcfx84P (ngram)) log(1xcfx84) are applied to the n-gram probabilities in five trainable open-source language identifiers. The first mapping reduces classification errors by 4.0% to 83.9% over a test set of more than one million 65-character strings in 1366 languages, and by 2.6% to 76.7% over a subset of 781 languages. The second mapping improves four of the five identifiers by 10.6% to 83.8% on the larger corpus and 14.4% to 76.7% on the smaller corpus. The subset corpus and the modified programs are made freely available for download at http://www.cs.cmu.edu/xe2x88xbcralf/langid.html."
2011.mtsummit-papers.2,Training Machine Translation with a Second-Order {T}aylor Approximation of Weighted Translation Instances,2011,-1,-1,2,0.833333,20495,aaron phillips,Proceedings of Machine Translation Summit XIII: Papers,0,None
W10-1758,Taming Structured Perceptrons on Wild Feature Vectors,2010,15,2,1,1,40110,ralf brown,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"Structured perceptrons are attractive due to their simplicity and speed, and have been used successfully for tuning the weights of binary features in a machine translation system. In attempting to apply them to tuning the weights of real-valued features with highly skewed distributions, we found that they did not work well. This paper describes a modification to the update step and compares the performance of the resulting algorithm to standard minimum error-rate training (MERT). In addition, preliminary results for combining MERT or structured-perceptron tuning of the log-linear feature weights with coordinate ascent of other translation system parameters are presented."
C10-2037,Monolingual Distributional Profiles for Word Substitution in Machine Translation,2010,19,5,2,1,22684,rashmi gangadharaiah,Coling 2010: Posters,0,"Out-of-vocabulary (OOV) words present a significant challenge for Machine Translation. For low-resource languages, limited training data increases the frequency of OOV words and this degrades the quality of the translations. Past approaches have suggested using stems or synonyms for OOV words. Unlike the previous methods, we show how to handle not just the OOV words but rare words as well in an Example-based Machine Translation (EBMT) paradigm. Presence of OOV words and rare words in the input sentence prevents the system from finding longer phrasal matches and produces low quality translations due to less reliable language model estimates. The proposed method requires only a monolingual corpus of the source language to find candidate replacements. A new framework is introduced to score and rank the replacements by efficiently combining features extracted for the candidate replacements. A lattice representation scheme allows the decoder to select from a beam of possible replacement candidates. The new framework gives statistically significant improvements in English-Chinese and English-Haitian translation systems."
2010.eamt-1.27,Chunk-Based {EBMT},2010,18,10,2,0.952381,46632,jae kim,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"Corpus driven machine translation approaches such as Phrase-Based Statistical Machine Translation and Example-Based Machine Translation have been successful by using word alignment to find translation fragments for matched source parts in a bilingual training corpus. However, they still cannot properly deal with systematic translation for insertion or deletion words between two distant languages. In this work, we used syntactic chunks as translation units to alleviate this problem, improve alignments and show improvement in BLEU for Korean to English and Chinese to English translation tasks."
2010.eamt-1.40,Automatic Determination of Number of clusters for creating Templates in Example-Based Machine Translation,2010,-1,-1,2,1,22684,rashmi gangadharaiah,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,None
W09-4633,Active Learning in Example-Based Machine Translation,2009,7,11,2,1,22684,rashmi gangadharaiah,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"In data-driven Machine Translation ap-proaches, like Example-Based MachineTranslation (EBMT) (Brown, 2000) andStatistical Machine Translation (Vogel etal., 2003), the quality of the translationsproduced depends on the amount of train-ing data available. While more data is al-ways useful, a large training corpus canslow down a machine translation system.We would like to selectively sample thehugecorpustoobtainasub-corpusofmostinformative sentence pairs that would leadto good quality translations. Reducing theamount of training data also enables oneto easily port an MT system onto smalldevices that have less memory and stor-age capacity. In this paper, we proposeusingActiveLearningstrategiestosamplethemostinformativesentencepairs. Therehas not been much progress in the ap-plication of active learning theory in ma-chine translation due to the complexity ofthe translation models. We use a pool-based strategy to selectively sample in-stances from a parallel corpora which notonly outperformed a random selector butalso a previously used sampling strategy(Eck et al., 2005) in an EBMT framework(Brown, 2000) by about one BLEU point(Papineni et al., 2002)."
2008.amta-papers.2,Exploiting Document-Level Context for Data-Driven Machine Translation,2008,20,5,1,1,40110,ralf brown,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"This paper presents a method for exploiting document-level similarity between the documents in the training corpus for a corpus-driven (statistical or example-based) machine translation system and the input documents it must translate. The method is simple to implement, efficient (increases the translation time of an example-based system by only a few percent), and robust (still works even when the actual document boundaries in the input text are not known). Experiments on French-English and Arabic-English showed relative gains over the same system without using document-level similarity of up to 7.4{\%} and 5.4{\%}, respectively, on the BLEU metric."
2007.mtsummit-papers.49,Improving example-based machine translation through morphological generalization and adaptation,2007,-1,-1,3,0.833333,20495,aaron phillips,Proceedings of Machine Translation Summit XI: Papers,0,None
N06-2011,Spectral Clustering for Example Based Machine Translation,2006,7,14,2,1,22684,rashmi gangadharaiah,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"Prior work has shown that generalization of data in an Example Based Machine Translation (EBMT) system, reduces the amount of pre-translated text required to achieve a certain level of accuracy (Brown, 2000). Several word clustering algorithms have been suggested to perform these generalizations, such as k-Means clustering or Group Average Clustering. The hypothesis is that better contextual clustering can lead to better translation accuracy with limited training data. In this paper, we use a form of spectral clustering to cluster words, and this is shown to result in as much as 29.08% improvement over the baseline EBMT system."
W05-0813,Symmetric Probabilistic Alignment,2005,8,4,1,1,40110,ralf brown,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"We recently decided to develop a new alignment algorithm for the purpose of improving our Example-Based Machine Translation (EBMT) system's performance, since subsentential alignment is critical in locating the correct translation for a matched fragment of the input. Unlike most algorithms in the literature, this new Symmetric Probabilistic Alignment (SPA) algorithm treats the source and target languages in a symmetric fashion.n n In this short paper, we outline our basic algorithm and some extensions for using context and positional information, and compare its alignment accuracy on the Romanian-English data for the shared task with IBM Model 4 and the reported results from the prior workshop."
2005.mtsummit-ebmt.2,Context-sensitive Retrieval for Example-based Translation,2005,-1,-1,1,1,40110,ralf brown,Workshop on example-based machine translation,0,"Example-Based Machine Translation (EBMT) systems have typically operated on individual sentences without taking into account prior context. By adding a simple reweighting of retrieved fragments of training examples on the basis of whether the previous translation retrieved any fragments from examples within a small window of the current instance, translation performance is improved. A further improvement is seen by performing a similar reweighting when another fragment of the current input sentence was retrieved from the same training example. Together, a simple, straightforward implementation of these two factors results in an improvement on the order of 1.0{--}1.6{\%} in the BLEU metric across multiple data sets in multiple languages."
2005.eamt-1.21,Symmetric probabilistic alignment for example-based translation,2005,4,8,2,0.952381,46632,jae kim,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"Since subsentential alignment is critically important to the translation quality of an Example-Based Machine Translation (EBMT) system which operates by finding and combining phrase-level matches against the training examples, we recently decided to de- velop a new alignment algorithm for the purpose of improving the EBMT system's per- formance. Unlike most algorithms in the literature, this new Symmetric Probabilistic Align- ment (SPA) algorithm treats the source and target languages in a symmetric fashion. In this paper, we describe our basic algorithm and some extensions for using context and posi- tional information, compare its alignment accuracy with IBM Model 4, and report on ex- periments in which either IBM Model 4 or SPA alignments are substituted for the aligner currently built into the EBMT system. Both Model 4 and SPA are significantly better than the internal aligner and SPA slightly outperforms Model 4 despite being handicapped by incomplete integration with EBMT."
monson-etal-2004-data,Data Collection and Analysis of {M}apudungun Morphology for Spelling Correction,2004,4,2,4,0,44751,christian monson,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper describes part of a three year collaboration between Carnegie Mellon University's Language Technologies Institute, the Programa de Educacion Intercultural Bilingue of the Chilean Ministry of Education, and Universidad de La Frontera (Temuco, Chile). We are currently constructing a spelling checker for Mapudungun, a polysynthetic language spoken by the Mapuche people in Chile and Argentina. The spelling checker will be built in MySpell, the spell checking system used by the open source office suite OpenOffice. This paper also describes the spoken language corpus that is used as a source of data for developing the spelling checker."
2004.eamt-1.5,Challenges in using an example-based {MT} system for a transnational digital government project,2004,7,2,2,0.625,28253,violetta cavallisforza,Proceedings of the 9th EAMT Workshop: Broadening horizons of machine translation and its applications,0,"We describe ongoing efforts towards and challenges in using an Example-Based Machine Translation (EBMT) system in the context of a multinational, multi-university and multi-agency transnational digital government project. The project is aimed at applying information technology to the problem of collecting and sharing information securely in a multilingual context. We report on a number of issues encountered in obtaining and using language data for the EBMT system, discuss our current solutions, and briefly describe ongoing enhancements to the system to meet some of the technical and practical challenges posed by using this machine translation approach in the project domain."
brown-2004-modified,A modified Burrows-Wheeler transform for highly scalable example-based translation,2004,8,16,1,1,40110,ralf brown,Proceedings of the 6th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"The Burrows-Wheeler Transform (BWT) was originally developed for data compression, but can also be applied to indexing text. In this paper, an adaptation of the BWT to word-based indexing of the training corpus for an example-based machine translation (EBMT) system is presented. The adapted BWT embeds the necessary information to retrieve matched training instances without requiring any additional space and can be instantiated in a compressed form which reduces disk space and memory requirements by about 40{\%} while still remaining searchable without decompression. Both the speed advantage from O(log N) lookups compared to the O(N) lookups in the inverted-file index which had previously been used and the structure of the index itself act as enablers for additional capabilities and run-time speed. Because the BWT groups all instances of any n-gram together, it can be used to quickly enumerate the most-frequent n-grams, for which translations can be precomputed and stored, resulting in an order-of-magnitude speedup at run time."
2003.mtsummit-papers.4,Reducing boundary friction using translation-fragment overlap,2003,10,26,1,1,40110,ralf brown,Proceedings of Machine Translation Summit IX: Papers,0,"Many corpus-based Machine Translation (MT) systems generate a number of partial translations which are then pieced together rather than immediately producing one overall translation. While this makes them more robust to ill-formed input, they are subject to disfluencies at phrasal translation boundaries even for well-formed input. We address this {``}boundary friction{''} problem by introducing a method that exploits overlapping phrasal translations and the increased confidence in translation accuracy they imply. We specify an efficient algorithm for producing translations using overlap. Finally, our empirical analysis indicates that this approach produces higher quality translations than the standard method of combining non-overlapping fragments generated by our Example-Based MT (EBMT) system in a peak-to-peak comparison."
W02-0711,Speech Translation on a Tight Budget without Enough Data,2002,11,3,3,0.48703,39652,robert frederking,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"The Tongues speech-to-speech translation system was developed for the US Army chaplains, with fairly stringent constraints on time, budget, and available data. The resulting prototype was required to undergo a quite realistic field test. We describe the development and architecture of the system, the field test, and our analysis of its results. The system performed quite well, especially given its development constraints."
P02-1052,Using Similarity Scoring to Improve the Bilingual Dictionary for Sub-sentential Alignment,2002,11,5,2,1,48480,katharina probst,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We describe an approach to improve the bilingual cooccurrence dictionary that is used for word alignment, and evaluate the improved dictionary using a version of the Competitive Linking algorithm. We demonstrate a problem faced by the Competitive Linking algorithm and present an approach to ameliorate it. In particular, we rebuild the bilingual dictionary by clustering similar words in a language and assigning them a higher cooccurrence score with a given word in the other language than each single word would have otherwise. Experimental results show a significant improvement in precision and recall for word alignment when the improved dicitonary is used."
frederking-etal-2002-field,Field Testing the Tongues Speech-to-Speech Machine Translation System,2002,5,12,3,0.48703,39652,robert frederking,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The Tongues portable, rapid-development, speech-to-speech machine translation system was developed specifically to allow a realistic field-test of a deployable prototype. In this paper we will describe the system, its field-testing using regular US Army officers and naive Croatians, and the evaluation of these tests. The evaluation includes analysis of answers to a questionnaire, analysis of system transcript logs, and the authorsxe2x80x99 qualitative observations. The overall result of the test was that while the system did successfully aid translation, it requires further development before it would be ready for regular field use. 1. The Tongues System The Tongues system was funded by the US Army to support the mission of the US Army chaplains, who are increasingly called upon to deal with local populations, usually without the benefit of human translators. It is thus intended to be used by a trained US Army chaplain with a completely naive and untrained non-English speaker. The architecture and user interface of the Tongues system were based in large measure on the Diplomat system (Frederking et al., 2000). The speech recognition system used was the open-source Sphinx II (Huang et al., 1992); the translation system was a EBMT/MEMT (ExampleBased MT/Multi-Engine MT) system (Brown, 1996; Frederking and Nirenburg, 1994; Brown and Frederking, 1995) very similar to that in Diplomat; and the synthesis system was the open-source Festival (Black et al., 1998). While the initial system was specifically to demonstrate translation in both directions between English and Croatian, the design was also required to allow rapid development for new languages. To ensure rapid development, the entire project was only allowed to take one calendar year, including contractual arrangements, hiring language experts, etc. The total development effort was similarly restricted: six senior research personnel (the authors of this paper) provided an estimated total of about two (2) fulltime person-years of effort. In addition to the senior staff, there were also part-time Croatian informants, chaplains, and some student programmers. We should note that some of the translation data used to train the system was collected for the Diplomat project (Frederking et al., 2000). In addition to rapid development, the system was not permitted to be restricted to a narrowly-limited domain, but had to be wide-coverage. (Both of these properties were important for the chaplainsxe2x80x99 envisioned activities.) Since we were to build a broad-coverage system in a short period of time on a small budget, data-driven approaches were the only reasonable choice. In order to provide in-domain conversational data, we arranged at the start of the project to record a number of chaplains in role-playing conversations of the type they expected the device to encounter. Fortunately, the chaplains were familiar with role-playing exercises, and all had relevant field experiences to re-enact. Both sides of the conversations were spoken in English. These were digitally recorded with head-mounted microphones at 16KHz in stereo (one speaker on each channel), as this was closest to the intended audio channel characteristics of the eventual system. In all, we recorded 46 conversations, ranging from a few minutes to 20 minutes length. This provided a total of 4.25 hours of actual speech. The recorded conversations were hand-transcribed at the word level, and translated into Croatian by native Croatian speakers. The English recordings were used for training the English speech recognition models. The transcripts and their translations were added to the EBMT systemxe2x80x99s example base of parallel sentences. A subset of the Croatian translations were read by native Croatian speakers to create data for the Croatian speech recognizer, as described elsewhere (Black et al., 2002). This simple approach appears to be surprisingly adequate. Simply stringing together a recognizer, translator, and synthesizer does not make a very useful speech-to-speech translation system. A good interface is necessary to make the parts work together in such a way that a user can actually derive benefit from it. Using our experience from the earlier Diplomat system, we designed the Tongues interface to be asymmetric, with the Croatian side being as simple as possible, and any necessary complexity handled on the English side, since the chaplain would be trained and practiced in using the system. Even the English side was not terribly complex (see Figure 1). We included a back-translation capability, to allow a user with no knowledge of the target language to better assess the quality of the translation. (We could not use the approach of generating paraphrases from meaning representations, since the system does not use any meaning representations.) We also included several user-requested features, such as built-in pre-recorded instructions and explanations for the Croatian (since the Croatian speaker is completely naive regarding the device and the chaplainxe2x80x99s intentions), emergency key phrases (such as xe2x80x9cDonxe2x80x99t move!xe2x80x9d), and enhancements such as being able to modify the translation lexicon in the field, so that the system could be tuned to more specific tasks. The final system ran on a Windows-based Toshiba Libretto, running at 200MHz with 192MB of memory. At the time of the project (2000) this was the best combination of speed and size that was readily available. The system was equipped with a custom touchscreen, so that the Croatian-speaker would not need to type or use a mouse at all. Aware that the system might be used in situations where the non-English participant would be unfamiliar with computer technology, we included a microphone/speaker handset that looks like a conventional telephone handset. This has the advantage of provided a close-talking microphone, thus making speech recognition easier, while coming in a form factor that will be familiar to most people. We have provided a more detailed description of the development of the Tongues system elsewhere (Black et al., 2002). Our design provides abundant opportunities for user error correction, in an effort to enable cooperative users to communicate well enough to accomplish significant tasks that they could not accomplish without the system (or a bilingual human interpreter), despite the error-prone nature of current speech recognition, broad-coverage rapiddevelopment machine translation, and speech synthesis. Determining whether we have met such a goal requires task-based evaluation; while error rates of components are useful information, the real system-level issue is whether communication is achieved, and at what level of effort. Figure 1: Tongues User Interface."
2002.tmi-papers.3,Corpus-driven splitting of compound words,2002,-1,-1,1,1,40110,ralf brown,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
2002.amta-tutorials.1,Example-based machine translation,2002,11,12,1,1,40110,ralf brown,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Tutorial Descriptions,0,"Translation is a repetitive activity. The attempt to automate such a difficult task has been a long-term scientific dream; in the past years research in this field has acquired a growing interest, making some forms of Machine Translation (MT) a reality. Among the several types of approaches in MT, one of the most promising paradigms is MAHT and, in particular, example-Based Machine Translation (EBMT). An EBMT system translates by analogy, using past translations to translate other, similar sourcelanguage sentences into the target language. The basic premise is that, if a previously translated sentence occurs again, the same translation is likely to be correct. In this paper, we propose a solution based on a purely syntactic approach for searching similar sentences and parts of them in an EBMT system; the underlying similarity measure is based on the similarity between sequence of terms such that the sentences most close to a given one are those who maintain most of the original form and contents. The system efficiently retrieves and ranks the most similar sentences available and, when no useful suggestion exists, it proceeds with the retrieval of similar parts. We opted for a design that would require minimal changes to existing databases and whose similarity measure and search algorithms are completely independent from the involved languages. This work has been developed as a joint work with LOGOS S.p.A., a worldwide leader in multilingual document translation."
carbonell-etal-2002-automatic,Automatic rule learning for resource-limited {MT},2002,8,21,6,0,10837,jaime carbonell,Proceedings of the 5th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"Machine Translation of minority languages presents unique challenges, including the paucity of bilingual training data and the unavailability of linguistically-trained speakers. This paper focuses on a machine learning approach to transfer-based MT, where data in the form of translations and lexical alignments are elicited from bilingual speakers, and a seeded version-space learning algorithm formulates and refines transfer rules. A rule-generalization lattice is defined based on LFG-style f-structures, permitting generalization operators in the search for the most general rules consistent with the elicited data. The paper presents these methods and illustrates examples."
H01-1002,Adapting an Example-Based Translation System to {C}hinese,2001,4,12,2,0,7842,ying zhang,Proceedings of the First International Conference on Human Language Technology Research,0,We describe an Example-Based Machine Translation (EBMT) system and the adaptations and enhancements made to create a Chinese-English translation system from the Hong Kong legal code and various other bilingual resources available from the Linguistic Data Consortium (LDC).
H01-1066,A Server for Real-Time Event Tracking in News,2001,6,1,1,1,40110,ralf brown,Proceedings of the First International Conference on Human Language Technology Research,0,"As the flood of information continues to grow, it becomes ever more necessary to extract just the portion of the flow which is of interest to each user. The Topic Detection and Tracking (TDT) project [1, 3, 6, 5] addressed and continues to address this need, but has been of necessity applied in a batch-processing context on a static collection. What is required for topic detection and tracking to be of utility to end-users is a real-time system which operates on a live stream of information. This paper describes the extension and modification of a batch-oriented tracking system into a real-time server for event detection, event tracking, document summarization, and translation."
2001.mtsummit-road.7,Design and implementation of controlled elicitation for machine translation of low-density languages,2001,10,17,2,1,48480,katharina probst,Workshop on MT2010: Towards a Road Map for MT,0,"NICE is a machine translation project for low-density languages. We are building a tool that will elicit a controlled corpus from a bilingual speaker who is not an expert in linguistics. The corpus is intended to cover major typological phenomena, as it is designed to work for any language. Using implicational universals, we strive to minimize the number of sentences that each informant has to translate. From the elicited sentences, we learn transfer rules with a version space algorithm. Our vision for MT in the future is one in which systems can be quickly trained for new languages by native speakers, so that speakers of minor languages can participate in education, health care, government, and internet without having to give up their languages."
2001.mtsummit-papers.69,Pre-processing of bilingual corpora for {M}andarin-{E}nglish {EBMT},2001,5,3,2,0,7842,ying zhang,Proceedings of Machine Translation Summit VIII,0,"Pre-processing of bilingual corpora plays an important role in Example-Based Machine Translation (EBMT) and Statistical-Based Machine Translation (SBMT). For our Mandarin-English EBMT system, pre-processing includes segmentation for Mandarin, bracketing for English and building a statistical dictionary from the corpora. We used the Mandarin segmenter from the Linguistic Data Consortium (LDC). It uses dynamic programming with a frequency dictionary to segment the text. Although the frequency dictionary is large, it does not completely cover the corpora. In this paper, we describe the work we have done to improve the segmentation for Mandarin and the bracketing process for English to increase the length of English phrases. A statistical dictionary is built from the aligned bilingual corpus. It is used as feedback to segmentation and bracketing to re-segment / re-bracket the corpus. The process iterates several times to achieve better results. The final results of the corpus pre-processing are a segmented/bracketed aligned bilingual corpus and a statistical dictionary. We achieved positive results by increasing the average length of Chinese terms about 60{\%} and 10{\%} for English. The statistical dictionary gained about a 30{\%} increase in coverage."
2001.mtsummit-ebmt.1,Transfer-rule induction for example-based translation,2001,4,22,1,1,40110,ralf brown,Workshop on Example-Based machine Translation,0,"Previous work has shown that grammars and similar structure can be induced from unlabeled text (both monolingually and bilingually), and that the performance of an example-based machine translation (EBMT) system can be substantially enhanced by using clustering techniques to determine equivalence classes of individual words which can be used interchangeably, thus converting translation examples into templates. This paper describes the combination of these two approaches to further increase the coverage (or conversely, decrease the required training text) of an EBMT system. Preliminary results show that a reduction in required training text by a factor of twelve is possible for translation from French into English."
C00-1019,Automated Generalization of Translation Examples,2000,4,66,1,1,40110,ralf brown,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Previous work has shown that adding generalization of the examples in the corpus of an example-based machine translation (EBMT) system can reduce the required amount of pretranslated example text by as much as an order of magnitude for Spanish-English and French-English EBMT. Using word clustering to automatically generalize the example corpus can provide the majority of this improvement for French-English with no manual intervention; the prior work required a large bilingual dictionary tagged with parts of speech and the manual creation of grammar rules. By seeding the clustering with a small amount of manually-created information, even better performance can be achieved. This paper describes a method whereby bilingual word clustering can be performed using standard monolingual document clustering techniques, and its effectiveness at reducing the size of the example corpus required."
1999.tmi-1.3,Adding linguistic knowledge to a lexical example-based translation system,1999,-1,-1,1,1,40110,ralf brown,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1997.tmi-1.13,Automated dictionary extraction for {``}knowledge-free{''} example-based translation,1997,-1,-1,1,1,40110,ralf brown,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1997.mtsummit-systems.9,The {DIPLOMAT} Rapid Development Speech {MT} System,1997,-1,-1,2,1,39652,robert frederking,Proceedings of Machine Translation Summit VI: Systems,0,None
C96-1030,Example-Based Machine Translation in the Pangloss System,1996,3,161,1,1,40110,ralf brown,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"The Pangloss Example-Based Machine Translation engine (PanEBMT) is a translation system requiring essentially no knowledge of the structure of a language, merely a large parallel corpus of example sentences and a bilingual dictionary. Input texts are segmented into sequences of words occurring in the corpus, for which translations are determined by subsentential alignment of the sentence pairs containing those sequences. These partial translations are then combined with the results of other translation engines to form the final translation produced by the Pangloss system. In an internal evaluation, PanEBMT achieved 70.2% coverage of unrestricted Spanish news-wire text, despite a simplistic subsentential alignment algorithm, a suboptimal dictionary, and a corpus from a different domain than the evaluation texts."
1996.amta-1.35,The {P}angloss-{L}ite machine translation system,1996,-1,-1,2,1,39652,robert frederking,Conference of the Association for Machine Translation in the Americas,0,None
1995.tmi-1.17,Applying Statistical {E}nglish Language Modelling to Symbolic Machine Translation,1995,-1,-1,1,1,40110,ralf brown,Proceedings of the Sixth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1994.amta-1.10,Integrating Translations from Multiple Sources within the {PANGLOSS} Mark {III} Machine Translation System,1994,-1,-1,11,0.731707,39652,robert frederking,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
C90-3008,Human-Computer Interaction for Semantic Disambiguation,1990,9,29,1,1,40110,ralf brown,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,We describe a semi-automatic semantic disambiguator integrated in a knowledge-based machine translation system. It is used to bridge the analysis and generation stages in machine translation. The user interface of the disambiguator is built on mouse-based multiple-selection menus.
C88-1021,Anaphora Resolution: A Multi-Strategy Approach,1988,14,106,2,0,10837,jaime carbonell,{C}oling {B}udapest 1988 Volume 1: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"Anaphora resolution has proven to be a very difficult problem; it requires the integrated application of syntactic, semantic, and pragmatic knowledge. This paper examines the hypothesis that instead of attempting to construct a monolithic method for resolving anaphora, the combination of multiple strategies, each exploiting a different knowledge source, proves more effective - theoretically and computationally. Cognitive plausibility is established in that human judgements of the optimal anaphoric referent accord with those of the strategy-based method, and human inability to determine a unique referent corresponds to the cases where different strategies offer conflicting candidates for the anaphoric referent."
