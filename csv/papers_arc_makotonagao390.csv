2005.mtsummit-invited.1,Reviewing Back the Past {MT} Summits,2005,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit X: Invited papers,0,None
W99-0205,Resolution of Indirect Anaphora in {J}apanese Sentences Using Examples: {``}{X} no {Y} ({Y} of {X}){''},1999,5,9,3,1,16788,masaki murata,Coreference and Its Applications,0,"A noun phrase can indirectly refer to an entity that has already been mentioned. For example, I went into an old house last night. The roof was leaking badly and .... indicates that the roof is associated with an old house, which was mentioned in the previous sentence. This kind of reference (indirect anaphora) has not been studied well in natural language processing, but is important for coherence resolution, language understanding, and machine translation. In order to analyze indirect anaphora, we need a case frame dictionary for nouns that contains knowledge of the relationships between two nouns but no such dictionary presently exists. Therefore, we are forced to use examples of X no Y (Y of X) and a verb case frame dictionary instead. We tried estimating indirect anaphora using this information and obtained a recall rate of 63% and a precision rate of 68% on test sentences. This indicates that the information of X no Y is useful to a certain extent when we cannot make use of a noun case frame dictionary. We estimated the results that would be given by a noun case frame dictionary, and obtained recall and precision rates of 71% and 82% respectively. Finally, we proposed a way to construct a noun case frame dictionary by using examples of X no Y."
W99-0206,Pronoun Resolution in {J}apanese Sentences Using Surface Expressions and Examples,1999,10,10,3,1,16788,masaki murata,Coreference and Its Applications,0,"In this paper, we present a method of estimating referents of demonstrative pronouns, personal pronouns, and zero pronouns in Japanese sentences using examples, surface expressions, topics and foci. Unlike conventional work which was semantic markers for semantic constraints, we used examples for semantic constraints and showed in our experiments that examples are as useful as semantic markers. We also propose many new methods for estimating referents of pronouns. For example, we use the form X of Y for estimating referents of demonstrative adjectives. In addition to our new methods, we used many conventional methods. As a result, experiments using these methods obtained a precision rate of 87% in estimating referents of demonstrative pronouns, personal pronouns, and zero pronouns for training sentences, and obtained a precision rate of 78% for test sentences."
W98-0701,General Word Sense Disambiguation Method Based on a Full Sentential Context,1998,32,47,3,0,55195,jiri stetina,Usage of {W}ord{N}et in Natural Language Processing Systems,0,"This paper presents a new general supervised word sense disambiguation method based on a relatively small syntactically parsed and semantically tagged training corpus.The method exploits a full sentential context and all the explicit semantic relations in a sentence to identify the senses of all of that sentence's content words. It solves the sparse data problem of a small training corpus by substituting the words by their semantic classes.In spite of a very small training corpus, we report an overall accuracy of 80.3% (85.7, 63.9, 83.6 and 86.5%, for nouns, verbs, adjectives and adverbs, respectively), which exceeds the accuracy of a statistical sense-frequency based semantic tagging, the only really applicable general disambiguating technique. Because the method uses the sentential syntactic structure it is particularly suitable for integration with a probabilistic syntactic analyser."
W98-0605,Construction of {J}apanese Nominal Semantic Dictionary using {``}A {NO} {B}{''} Phrases in Corpora,1998,1,1,5,1,297,sadao kurohashi,The Computational Treatment of Nominals,0,None
P98-2148,A Stochastic Language Model using Dependency and its Improvement by Word Clustering,1998,9,8,2,1,17147,shinsuke mori,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"In this paper, we present a stochastic language model for Japanese using dependency. The prediction unit in this model is an attribute of bunsetsu. This is represented by the product of the head of content words and that of function words. The relation between the attributes of bunsetsu is ruled by a context-free grammar. The word sequences are predicted from the attribute using word n-gram model. The spell of Unknow word is predicted using character n-gram model. This model is robust in that it can compute the probability of an arbitrary string and is complete in that it models from unknown word to dependency at the same time."
P98-2150,An Estimate of Referent of Noun Phrases in {J}apanese Sentences,1998,2,7,2,1,16788,masaki murata,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"In machine translation and man-machine dialogue, it is important to clarify referents of noun phrases. We present a method for determining the referents of noun phrases in Japanese sentences by using the referential properties, modifiers, and possessors of noun phrases. Since the Japanese language has no articles, it is difficult to decide whether a noun phrase has an antecedent or not. We had previously estimated the referential properties of noun phrases that correspond to articles by using clue words in the sentences (Murata and Nagao 1993). By using these referential properties, our system determined the referents of noun phrases in Japanese sentences. Furthermore we used the modifiers and possessors of noun phrases in determining the referents of noun phrases. As a result, on training sentences we obtained a precision rate of 82% and a recall rate of 85% in the determination of the referents of noun phrases that have antecedents. On test sentences, we obtained a precision rate of 79% and a recall rate of 77%."
P98-2224,Diagram Understanding Using Integration of Layout Information and Textual Information,1998,4,8,2,1,44119,yasuhiko watanabe,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"Pattern information and natural language information used together can complement and reinforce each other to enable more effective communication than can either medium alone (Feiner 91) (Nakamura 93). One of the good examples is a pictorial book of flora (PBF) . In the PBF, readable explanations which combine texts, pictures, and diagrams are achieved, as shown in Figure 1 and 2. Taking advantage of this, we propose here a new method for analyzing the PBF diagrams by using natural language information. In the PBF, many kinds of information about plants are generally stored in the following media:"
P98-2225,Aligning Articles in {TV} Newscasts and Newspapers,1998,4,12,4,1,44119,yasuhiko watanabe,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"It is important to use pattern information (e.g. TV newscasts) and textual information (e.g. newspapers) together. For this purpose, we describe a method for aligning articles in TV newscasts and newspapers. In order to align articles, the alignment system uses words extracted from telops in TV newscasts. The recall and the precision of the alignment process are 97% and 89%, respectively. In addition, using the results of the alignment process, we develop a browsing and retrieval system for articles in TV newscasts and newspapers."
C98-2143,A Stochastic Language Model using Dependency and Its Improvement by Word Clustering,1998,9,8,2,1,17147,shinsuke mori,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"In this paper, we present a stochastic language model for Japanese using dependency. The prediction unit in this model is an attribute of bunsetsu. This is represented by the product of the head of content words and that of function words. The relation between the attributes of bunsetsu is ruled by a context-free grammar. The word sequences are predicted from the attribute using word n-gram model. The spell of Unknow word is predicted using character n-gram model. This model is robust in that it can compute the probability of an arbitrary string and is complete in that it models from unknown word to dependency at the same time."
C98-2145,An Estimate of Referent of Noun Phrases in {J}apanese Sentences,1998,2,7,2,1,16788,masaki murata,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"In machine translation and man-machine dialogue, it is important to clarify referents of noun phrases. We present a method for determining the referents of noun phrases in Japanese sentences by using the referential properties, modifiers, and possessors of noun phrases. Since the Japanese language has no articles, it is difficult to decide whether a noun phrase has an antecedent or not. We had previously estimated the referential properties of noun phrases that correspond to articles by using clue words in the sentences (Murata and Nagao 1993). By using these referential properties, our system determined the referents of noun phrases in Japanese sentences. Furthermore we used the modifiers and possessors of noun phrases in determining the referents of noun phrases. As a result, on training sentences we obtained a precision rate of 82% and a recall rate of 85% in the determination of the referents of noun phrases that have antecedents. On test sentences, we obtained a precision rate of 79% and a recall rate of 77%."
C98-2219,Diagram Understanding Using Integration of Layout Information and Textual Information,1998,4,8,2,1,44119,yasuhiko watanabe,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"Pattern information and natural language information used together can complement and reinforce each other to enable more effective communication than can either medium alone (Feiner 91) (Nakamura 93). One of the good examples is a pictorial book of flora (PBF) . In the PBF, readable explanations which combine texts, pictures, and diagrams are achieved, as shown in Figure 1 and 2. Taking advantage of this, we propose here a new method for analyzing the PBF diagrams by using natural language information. In the PBF, many kinds of information about plants are generally stored in the following media:"
C98-2220,Aligning Articles in {TV} Newscasts and Newspapers,1998,4,12,4,1,44119,yasuhiko watanabe,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"It is important to use pattern information (e.g. TV newscasts) and textual information (e.g. newspapers) together. For this purpose, we describe a method for aligning articles in TV newscasts and newspapers. In order to align articles, the alignment system uses words extracted from telops in TV newscasts. The recall and the precision of the alignment process are 97% and 89%, respectively. In addition, using the results of the alignment process, we develop a browsing and retrieval system for articles in TV newscasts and newspapers."
W97-0109,Corpus Based {PP} Attachment Ambiguity Resolution with a Semantic Dictionary,1997,6,83,2,0,55195,jiri stetina,Fifth Workshop on Very Large Corpora,0,"This paper deals with two important ambiguities of natural language: prepositional phrase attachment and word sense ambiguity. We propose a new supervised learning method for PPattachment based on a semantically tagged corpus. Because any sufficiently big sense-tagged corpus does not exist, we also propose a new unsupervised context based word sense disambiguation algorithm which amends the training corpus for the PP attachment by word sense tags. We present the results of our approach and evaluate the achieved PP attachment accuracy in comparison with other methods."
1997.mtsummit-plenaries.11,Machine Translation Through Language Understanding,1997,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit VI: Plenaries,0,In this paper is described a general framework of a next generation machine translation system which translates a text not sentence by sentence but by considering inter-sentential discourse. The method is a step closer to human translation than the present-day machine translation systems. Particularly important are a detailed discourse analysis and a flexible text generation by using information obtained from the discourse analysis.
C96-2134,Document Classification Using Domain Specific Kanji Characters Extracted by X2 Method,1996,6,6,4,1,44119,yasuhiko watanabe,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"In this paper we describe a method of classifying Japanese text documents using domain specific kanji characters. Text documents are generally classified by significant words (keywords) of the documents. However, it is difficult to extract these significant words from Japanese text, because Japanese texts are written without using blank spaces, such as delimiters, and must be segmented into words. Therefore, instead of words, we used domain specific kanji characters which appear more frequently in one domain than the other. We extracted these domain specific kanji characters by X2 method. Then, using these domain specific kanji characters, we classified editorial columns TENSEI JINGO, editorial articles, and articles in Scientific American (in Japanese). The correct recognition scores for them were 47%, 74%, and 85%, respectively."
C96-2202,Word Extraction from Corpora and Its Part-of-Speech Estimation Using Distributional Analysis,1996,3,27,2,1,17147,shinsuke mori,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"Unknown words are inevitable at any step of analysis in natural language processing. We propose a method to extract words from a corpus and estimate the probability that each word belongs to given parts of speech (POSs), using a distributional analysis. Our experiments have shown that this method is effective for inferring the POS of unknown words."
1995.mtsummit-1.33,What have we to do for the future of {MT} systems?,1995,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit V,0,None
1995.iwpt-1.22,Parsing Without Grammar,1995,-1,-1,2,1,17147,shinsuke mori,Proceedings of the Fourth International Workshop on Parsing Technologies,0,"We describe and evaluate experimentally a method to parse a tagged corpus without grammar modeling a natural language on context-free language. This method is based on the following three hypotheses. 1) Part-of-speech sequences on the right-hand side of a rewriting rule are less constrained as to what part-of-speech precedes and follows them than non-constituent sequences. 2) Part-of-speech sequences directly derived from the same non-terminal symbol have similar environments. 3) The most suitable set of rewriting rules makes the greatest reduction of the corpus size. Based on these hypotheses, the system finds a set of constituent-like part-of-speech sequences and replaces them with a new symbol. The repetition of these processes brings us a set of rewriting rules, a grammar, and the bracketed corpus."
J94-4001,A Syntactic Analysis Method of Long {J}apanese Sentences Based on the Detection of Conjunctive Structures,1994,8,126,2,1,297,sadao kurohashi,Computational Linguistics,0,"This paper presents a syntactic analysis method that first detects conjunctive structures in a sentence by checking parallelism of two series of words and then analyzes the dependency structure of the sentence with the help of the information about the conjunctive structures. Analysis of long sentences is one of the most difficult problems in natural language processing. The main reason for this difficulty is the structural ambiguity that is common for conjunctive structures that appear in long sentences. Human beings can recognize conjunctive structures because of a certain, but sometimes subtle, similarity that exists between conjuncts. Therefore, we have developed an algorithm for calculating a similarity measure between two arbitrary series of words from the left and the right of a conjunction and selecting the two most similar series of words that can reasonably be considered as composing a conjunctive structure. This is realized using a dynamic programming technique. A long sentence can be reduced into a shorter form by recognizing conjunctive structures. Consequently, the total dependency structure of a sentence can be obtained by relatively simple head-dependent rules. A serious problem concerning conjunctive structures, besides the ambiguity of their scopes, is the ellipsis of some of their components. Through our dependency analysis process, we can find the ellipses and recover the omitted components. We report the results of analyzing 150 Japanese sentences to illustrate the effectiveness of this method."
C94-2169,Thesaurus-based Efficient Example Retrieval by Generating Retrieval Queries from Similarities,1994,3,20,4,1,15895,takehito utsuro,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In example-based NLP, the problem of computational cost of example retrieval is severe, since the retrieval time increases in proportion to the number of examples in the database. This paper proposes a novel example retrieval method for avoiding full retrieval of examples. The proposed method has the following three features, 1) it generates retrieval queries from similarities, 2) efficient example retrieval through the tree structure of a thesaurus, 3) binary search along subsumption ordering of retrieval queries. Example retrieval time drastically decreases with the method."
C94-2175,"Bilingual Text, Matching using Bilingual Dictionary and Statistics",1994,16,33,5,1,15895,takehito utsuro,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,This paper describes a unified framework for bilingual text matching by combining existing hand-written bilingual dictionaries and statistical techniques. The process of bilingual text matching consists of two major steps: sentence alignment and structural matching of bilingual sentences. Statistical techniques are applied to estimate word correspondences not included in bilingual dictionaries. Estimated word correspondences are useful for improving both sentence alignment and structural matching.
C94-2183,Automatic Detection of Discourse Structure by Checking Surface Information in Sentences,1994,10,81,2,1,297,sadao kurohashi,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In this paper, we propose an automatic method for detecting discourse structure using a variety of clues existing in the surface information of sentences. We have considered three types of clue information: clue expressions, occurrence of identical/synonymous words/phrases, and similarity between two sentences. Experimental results have shown that, in the case of scientific and technical texts, considerable part of the discourse structure can be estimated by incorporating the three types of clue information, without performing sentence understanding processes which requires giving knowledge to computers."
C94-1101,A New Method of N-gram Statistics for Large Number of n and Automatic Extraction of Words and Phrases from Large Text Data of {J}apanese,1994,2,109,1,1,51221,makoto nagao,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"In the process of establishing the information theory, C. E. Shannon proposed the Markov process as a good model to characterize a natural language. The core of this idea is to calculate the frequencies of strings composed of n characters (n-grams), but this statistical analysis of large text data and for a large n has never been carried out because of the memory limitation of computer and the shortage of text data. Taking advantage of the recent powerful computers we developed a new algorithm of n-grams of large text data for arbitrary large n and calculated successfully, within relatively short time, n-grams of some Japanese text data containing between two and thirty million characters. From this experiment it became clear that the automatic extraction or determination of words, compound words and collocations is possible by mutually comparing n-gram statistics for different values of n."
1993.tmi-1.18,Determination of Referential Property and Number of Nouns in {J}apanese Sentences for Machine Translation into {E}nglish,1993,-1,-1,2,1,16788,masaki murata,Proceedings of the Fifth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1993.tmi-1.19,Translation into {E}nglish,1993,-1,-1,2,1,16788,masaki murata,Proceedings of the Fifth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1993.mtsummit-1.1,Machine Translation: What have we to do?,1993,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit IV,0,None
1993.iwpt-1.11,Structural Disambiguation in {J}apanese by Evaluating Case Structures based on Examples in a Case Frame Dictionary,1993,-1,-1,2,1,297,sadao kurohashi,Proceedings of the Third International Workshop on Parsing Technologies,0,"A case structure expression is one of the most important forms to represent the \textit{meaning} of a sentence. Case structure analysis is usually performed by consulting \textit{case frame information} in verb dictionaries and by selecting a \textit{proper case frame} for an input sentence. However, this analysis is very difficult because of \textit{word sense ambiguity} and \textit{structural ambiguity}. A conventional method for solving these problems is to use the method of \textit{selectional restriction}, but this method has a drawback in the semantic marker (SM) system {--} the trade-off between descriptive power and construction cost. This paper describes a method of case structure analysis of Japanese sentences which overcomes the drawback in the SM system, concentrating on the structural disambiguation. This method selects a proper case frame for an input by the similarity measure between the input and typical example sentences of each case frame. When there are two or more possible readings for an input because of structural ambiguity, the best reading will be selected by evaluating case structures in each possible reading by the similarity measure with typical example sentences of case frames."
C92-2088,Lexical Knowledge Acquisition from Bilingual Corpora,1992,8,20,3,1,15895,takehito utsuro,{COLING} 1992 Volume 2: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"For practical research in natural language processing, it is indispensable to develop a large scale semantic dictionary for computers. It is especially important to improve the techniques for compiling semantic dictionaries from natural language texts such as those in existing human dictionaries or in large corpora. However, there are at least two difficulties in analyzing existing texts: the problem of syntactic ambiguities and the problem of polysemy. Our approach to solve these difficulties is to make use of translation examples in two distinct languages that have quite different syntactic structures and word meanings. The reason we took this approach is that in many cases both syntactic and semantic ambiguities are resolved by comparing analyzed results from both languages. In this paper, we propose a method for resolving the syntactic ambiguities of translation examples of bilingual corpora and a method for acquiring lexical knowledge, such as case frames of verbs and attribute sets of nouns."
C92-1029,Dynamic Programming Method for Analyzing Conjunctive Structures in {J}apanese,1992,0,26,2,1,297,sadao kurohashi,{COLING} 1992 Volume 1: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"Parsing a long sentence is very difficult, since long sentences often have conjunctions which result in ambiguities. If the conjunctive structures existing in a long sentence can be analyzed correctly, ambiguities can be reduced greatly and a sentence can be parsed in a high successful rate. Since the prior part and the posterior part of a conjunctive structure have a similar structure very often, finding two similar series of words is an essential point in solving this problem. Similarities of all pairs of words are calculated and then the two series of words which have the greatest sum of similarities are found by a technique of dynamic programming. We deal with not only conjunctive noun phrases, but also conjunctive predicative clauses created by Renyoh chuushi-ho. We will illustrate the effectiveness of this method by the analysis of 180 long Japanese sentences."
A92-1037,A Method of Automatic Hypertext Construction from an Encyclopedic Dictionary of a Specific Field,1992,0,8,2,1,297,sadao kurohashi,Third Conference on Applied Natural Language Processing,0,None
1992.tmi-1.11,Are the grammars so far developed appropriate to recognize the real structure of a sentence?,1992,-1,-1,1,1,51221,makoto nagao,Proceedings of the Fourth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1991.tc-1.12,Current Practical Machine Translation Systems in {J}apan and Future Directions {EUROTRA}: an assessment of the current state of the {EC}{'}s {MT} programme,1991,-1,-1,1,1,51221,makoto nagao,Proceedings of Translating and the Computer 13: The theory and practice of machine translation {--} a marriage of convenience?,0,None
1991.iwpt-1.1,Proceedings of the Second International Workshop on Parsing Technologies ({IWPT} {'}91),1991,-1,-1,7,0,56874,masaru tomita,Proceedings of the Second International Workshop on Parsing Technologies,0,"February 13-25, 1991"
C90-3044,Toward Memory-based Translation,1990,1,195,2,0,19022,satoshi sato,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,"An essential problem of example-based translation is how to utilize more than one translation example for translating one source sentence.This paper proposes a method to solve this problem. We introduce the representation, called matching expression, which represents the combination of fragments of translation examples. The translation process consists of three steps: (1) Make the source matching expression from the source sentence. (2) Transfer the source matching expression into the target matching expression. (3) Construct the target sentence from the target matching expression.This mechanism generates some candidates of translation. To select the best translation out of them, we define the score of a translation."
1989.mtsummit-1.1,Two years after the {MT} Summit,1989,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit II,0,None
1989.mtsummit-1.18,{J}apanese view of the future of machine translation,1989,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit II,0,None
C88-2091,{PANEL}: Language Engineering: The Real Bottle Neck of Natural Language Processing,1988,0,9,1,1,51221,makoto nagao,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
C88-2098,Extraction of Semantic Information from an Ordinary {E}nglish Dictionary and its Evaluation,1988,4,62,2,1,51028,junichi nakamura,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"The automatic extraction of semantic information especially semantic relationships between words, from an odinary English dictionary is described. For the extraction, the magnetic tape version of LDOCE (Longman Dictionary of Contemporary English, 1978 edition) is loaded into a relational database system. Developed extraction programs analyze a definition sentence in LDOCE with a pattern matching based algorithm. Since this algorithm is not perfect, the result of the extraction has been compared with semantic information (semantic markers) which the magnetic tape version of LDOCE contains. The result of comparison is also discussed for evaluating the reliability of such an automatic extraction."
C88-2141,How to Get Preferred Readings in Natural Language Analysis,1988,4,3,4,0.640607,20171,junichi tsujii,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper describes a parsing program called KGWp which is designed for integrating various sorts of knowledge to get most preferred structural descriptions of sentences. The system accepts not only a set of rules specifying constraints which any descriptions of sentences should satisfy, but also preferential rules which are utilized in selecting most preferred descriptions among possible ones. During the parsing process, the preferetial rules are utilized to select feasible parsing paths. Furthermore, KGWp is complete in the sense that it can generate all possible structural descriptions of sentences it required. The descriptions are generated in a preferential order."
C88-2142,Dialogue Translation vs. Text Translation,1988,3,3,2,0.640607,20171,junichi tsujii,{C}oling {B}udapest 1988 Volume 2: {I}nternational {C}onference on {C}omputational {L}inguistics,0,"The authors discuss the differences of envi~onmeats whexe dialogue translation and textual translation systems might be used. The differences are summarized as clear definition of information and active participations of speakers and hearers in dialogue t~anslation. A new approach to MT, interpretation based approach, is proposed to take the advantages of dialogue translation environments. The approach introduces a layer o/ understanding to MT and can produce less structure bound translations than conventional approaches."
1987.mtsummit-1.1,Present and future of machine translation systems {---} an introduction to the {MT} Summit {---},1987,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit I,0,None
1987.mtsummit-1.45,Concluding Remarks,1987,-1,-1,1,1,51221,makoto nagao,Proceedings of Machine Translation Summit I,0,None
C86-1029,Solutions for Problems of {MT} Parser - Methods Used in {M}u-Machine Translation Project -,1986,6,2,3,1,51028,junichi nakamura,Coling 1986 Volume 1: The 11th International Conference on Computational Linguistics,0,None
J85-2001,The {J}apanese Government Project for Machine Translation,1985,4,62,1,1,51221,makoto nagao,Computational Linguistics,0,"The project is funded by a grant from the Agency of Science and Technology through the Special Coordination Funds for the Promotion of Science and Technology, and was started in fiscal 1982. The formal title of the project is Research on Fast Information Services between Japanese and English for Scientific and Engineering Literature. The purpose is to demonstrate the feasibility of machine translation of abstracts of scientific and engineering papers between the two languages, and as a result, to establish a fast information exchange system for these papers. The project term was initially scheduled as three years from the fiscal year of 1982 with a budget of about seven hundred million yen, but, due to the present financial pressures on the government, the term has been extended to four years, up to 1986. The project is conducted by the close cooperation between four organizations. At Kyoto University, we have the responsibility of developing the software system for the core part of the machine translation process (grammar writing system and execution system); grammar systems for analysis, transfer and synthesis; detailed specification of what information is written in the word dictionaries (all the parts of speech in the analysis, transfer, and generation dictionaries), and the working manuals for constructing these dictionaries. The Electrotechnical Laboratories (ETL) are responsible for the machine translation text input and output, morphological analysis and synthesis, and the construction of the verb and adjective dictionaries based on the working manuals prepared at Kyoto. The Japan Information Center for Science and Technology (JICST) is in charge of the noun dictionary and the compiling of special technical terms in scientific and technical fields. The Research Information Processing System (RIPS) under the Agency of Engineer. # . mg Technology is responsible for completing the machine translation system, including the man-machine interfaces to the system developed at Kyoto, which allow preand post-editing, access to grammar rules, and dictionary maintenance. The project is not primarily concerned with the development of a final practical system; that will be developed by private industry using the results of this project. Technical know-how is already being transferred gradually to private enterprise through the participation in the project of people from industry. Software and linguistic data are also being transferred in part. Finally, complete technical transfer will be done under the proper conditions. The Japanese source texts being used are abstracts of scientific and technical papers published in the monthly JICST journal d Current Bibliography of Science and Technology. At present, the project is only processing texts in the electronics, electrical engineering, and computer science fields. English source texts will be abstracts from INSPEC in these f ields. . The sentence structures used in abstracts tend .to be complex compared to ordinary sentences, with long nominal compounds, noun-phrase conjunctions, mathematical and physical formulas, long embedded sentences, and so on. The analysis and translation of this type of sentence structure is far more difficult than ordinary sentence patterns. However, we have not included a pre-editing stage because we wanted to find the ultimate limitations on handling this type of complex sentence structure. Our system is based on the following concepts: 1. The use of all available linguistic information, both surface and syntactic. The writing of as detailed as possible syntactic rules. The development of a grammar writing system that can accept any future level of sophisticated linguistic theory. 2. The introduction of semantic information wherever necessary to enable the syntactic analysis to be as accurate as possible. The importance of semantic information not over-estimated; a well-balanced usage of both syntax and semantics. Heavily seman-"
1985.tmi-1.14,Structural Transformation in the Generation Stage of the {MU} {J}apanese to {E}nglish Machine Translation System,1985,-1,-1,1,1,51221,makoto nagao,Proceedings of the first Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
P84-1057,Analysis Grammar of {J}apanese in the {M}u-project - A Procedural Approach to Analysis Grammar,1984,9,9,3,0.769231,20171,junichi tsujii,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"Analysis grammar of Japanese in the Mu-project is presented. It is emphasized that rules expressing constraints on single linguistic structures and rules for selecting the most preferable readings are completely different in nature, and that rules for selecting preferale readings should be utilized in analysis grammars of practical MT systems. It is also claimed that procedural control is essential in integrating such rules into a unified grammar. Some sample rules are given to make the points of discussion clear and concrete."
P84-1069,Grammar Writing System ({GRADE}) of {M}u-Machine Translation Project and its Characteristics,1984,4,19,3,1,51028,junichi nakamura,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"A powerful grammar writing system has been developed. This grammar writing system is called GRADE (GRAmmar DEscriber). GRADE allows a grammar writer to write grammars including analysis, transfer, and generation using the same expression. GRADE has powerful grammar writing facility. GRADE allows a grammar writer to control the process of a machine translation. GRADE also has a function to use grammatical rules written in a word dictionary. GRADE has been used for more than a year as the software of the machine translation project from Japanese into English, which is supported by the Japanese Government and called Mu-project."
P84-1086,Dealing With Incompleteness of Linguistic Knowledge in Language Translation {--} Transfer and Generation Stage of {M}u Machine Translation Project,1984,4,11,1,1,51221,makoto nagao,10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,1,"Therefore the linguistic contents of machine translation system always fluctuate, and make gradual progress. The system should be designed to allow such constant change and improvements. This paper explains the details of the transfer and generation stages of Japanese-to-English system of the machine translation project by the Japanese Government, with the emphasis on the ideas to deal with the incompleteness of linguistic knowledge for machine translation."
1984.bcs-1.13,A software system for describing a grammar of machine translation: {GRADE},1984,-1,-1,2,1,51028,junichi nakamura,Proceedings of the International Conference on Methodology and Techniques of Machine Translation: Processing from words to language,0,"A new software system for describing a grammar of a machine translation system has been developed. This software system is called GRADE (GRAmmar DEscriber). GRADE has the following features: 1. GRADE allows a grammar writer to divide a whole grammar into several parts. Each part of the grammar is called a subgrammar. A subgrammar describes a step of the translation process. A whole grammar is then described by a network of sub-grammars. This network is called a subgrammar network. A subgrammar network allows a grammar writer to control the process of the translation precisely. When a subgrammar network in the analysis phase consists of a subgrammar for a noun-phrase (SG1) and a subgrammar for a verb-phase (SG2) in this sequence, the subgrammar network first applies SG1 to an input sentence, then applies SG2 to the result of an application of SG1, thus getting a syntactic structure for the input sentence. 2. A subgrammar consists of a set of rewriting rules. Rewriting rules in a subgrammar are applied for an input sentence in an appropriate order, which is specified in the description of the subgrammar. A rewriting rule transforms a tree structure into another tree structure. Rewriting rules use a powerful pattern matching algorithm to test their applicability to a tree structure. For example, a grammar writer can write a pattern that recognizes and parses an arbitrary numbers of sub-trees. Each node of a tree-structure has a list of pairs of a property name and a property value. A node can express a category name, a semantic marker, flags to control the translation process, and various other information. This tree-to-tree transformation operation by GRADE allows a grammar writer to describe all the processes of analysis, transfer and generation of a machine translation system with this uniform description capability of GRADE. 3. A subgrammar network or a subgrammar can be written in an entry of the dictionaries for a machine translation system. A subgrammar network or a subgrammar written in a dictionary entry is called a dictionary rule, which is specific for a word. When an input sentence contains a word which has a dictionary rule, it is applied to an input sentence at an appropriate point of a translation process. It can express more precise processing appropriate for that specific word that a general Subgrammar Network or Subgrammar. it also allows grammar writers to adjust a machine translation system to a specific domain easily. 4. GRADE is written in LISP. GRADE is implemented on FACOM M-382 and Symbolics 3600. GRADE is used in the machine translation system between Japanese and English. The project was started by the Japanese government in 1982. The effectiveness of GRADE has been demonstrated in the project."
C82-1039,An {E}nglish {J}apanese Machine Translation System of the Titles of Scientific and Engineering Papers,1982,0,14,1,1,51221,makoto nagao,{C}oling 1982: Proceedings of the {N}inth {I}nternational {C}onference on {C}omputational {L}inguistics,0,"The title sentences of scientific and engineering papers are analyzed by simple parsing strategies, and only eighteen fundamental sentential structures are obtained from ten thousand titles. Title sentences of physics and mathematics of some databases in English are translated into Japanese with their keywords, author names, journal names and so on by using these fundamental structures. The translation accuracy for the specific areas of physics and mathematics from INSPEC database was about 93%."
C82-1040,Parser Which Learns the Application Order of Rewriting Rules,1982,0,6,1,1,51221,makoto nagao,{C}oling 1982: Proceedings of the {N}inth {I}nternational {C}onference on {C}omputational {L}inguistics,0,None
J76-1003,{PLATON}--A New Programming Language for Natural Language Analysis,1976,-1,-1,1,1,51221,makoto nagao,American Journal of Computational Linguistics,0,None
J76-1008,Analysis of {J}apanese Sentences,1976,-1,-1,1,1,51221,makoto nagao,American Journal of Computational Linguistics,0,None
C65-1022,Sentence Generation by Semantic Concordance,1965,1,3,2,0,59236,toshiyuki sakai,COLING 1965,0,"Generation of English sentence is realized in the following three steps. First, the generation of kernel sentence by phrase structure rules; second, the application of transformational rules to the kernel sentence; and finally the completion of a sentence by the morphophonemic modifications.At the first stage of generating kernel sentence, the semantics of words are fully utilized. The method is such that a pair of words in the generation process (subject noun and predicate verb, verb and object or complement, sdjective and modified noun etc.) is selected in accordance with the semantic categories which are attached to each word in the word dictionary. The semantic categories are determined by considering both the meaning of words themselves and also the functioning of words in sentences.At the stage of transformational rules, sentence is considered not as a simple string but as the one having the internal tree structure, and the transformational rules are applied to this tree structure. For these two stages the generation process is formalized strictly and is realized in a computer programming. We have presented in relation to the transformational rules a method of sentence generation not from the axiom (from the top of the tree) but from any point, from which the whole tree is constructed.We have also proposed that the morphophonemic rules can be presented as a kind of operators operating on words in the neighbourhood of a generated string."
