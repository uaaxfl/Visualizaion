2021.jeptalnrecital-taln.4,La g{\\'e}n{\\'e}ration de textes artificiels en substitution ou en compl{\\'e}ment de donn{\\'e}es d{'}apprentissage (Generating artificial texts as substitution or complement of training data ),2021,-1,-1,1,1,5590,vincent claveau,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\\'e}rence principale,0,"La qualit{\'e} des textes g{\'e}n{\'e}r{\'e}s artificiellement s{'}est consid{\'e}rablement am{\'e}lior{\'e}e avec l{'}apparition des transformers. La question d{'}utiliser ces mod{\`e}les pour augmenter les donn{\'e}es d{'}apprentissage pour des t{\^a}ches d{'}apprentissage supervis{\'e} se pose naturellement. Dans cet article, cette question est explor{\'e}e sous 3 aspects : (i) les donn{\'e}es artificielles sont-elles un compl{\'e}ment efficace ? (ii) peuvent-elles remplacer les donn{\'e}es d{'}origines quand ces derni{\`e}res ne peuvent pas {\^e}tre distribu{\'e}es, par exemple pour des raisons de confidentialit{\'e} ? (iii) peuvent-elles am{\'e}liorer l{'}explicabilit{\'e} des classifieurs ? Diff{\'e}rentes exp{\'e}riences sont men{\'e}es sur une t{\^a}che de classification en utilisant des donn{\'e}es g{\'e}n{\'e}r{\'e}es artificiellement en adaptant des mod{\`e}les GPT-2. Les r{\'e}sultats montrent que les donn{\'e}es artificielles ne sont pas encore suffisamment bonnes et n{\'e}cessitent un pr{\'e}-traitement pour am{\'e}liorer significativement les performances. Nous montrons que les approches sac-de-mots b{\'e}n{\'e}ficient le plus de telles augmentations de donn{\'e}es."
2020.lrec-1.589,On the Correlation of Word Embedding Evaluation Metrics,2020,-1,-1,2,0,17837,franccois torregrossa,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Word embeddings intervene in a wide range of natural language processing tasks. These geometrical representations are easy to manipulate for automatic systems. Therefore, they quickly invaded all areas of language processing. While they surpass all predecessors, it is still not straightforward why and how they do so. In this article, we propose to investigate all kind of evaluation metrics on various datasets in order to discover how they correlate with each other. Those correlations lead to 1) a fast solution to select the best word embeddings among many others, 2) a new criterion that may improve the current state of static Euclidean word embeddings, and 3) a way to create a set of complementary datasets, i.e. each dataset quantifies a different aspect of word embeddings."
2020.jeptalnrecital-taln.16,Construction de plongements de concepts m{\\'e}dicaux sans textes (Embedding medical concepts without texts),2020,-1,-1,1,1,5590,vincent claveau,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Dans le domaine m{\'e}dical, beaucoup d{'}outils du TAL reposent d{\'e}sormais sur des plongements de concepts issus de l{'}UMLS. Les approches existantes pour g{\'e}n{\'e}rer ces plongements n{\'e}cessitent de grandes quantit{\'e}s de documents m{\'e}dicaux. Au contraire des ces approches, nous proposons dans cet article de nous appuyer sur les traductions en japonais, plus pr{\'e}cis{\'e}ment en kanjis, disponibles dans l{'}UMLS pour g{\'e}n{\'e}rer ces plongements. Test{\'e}e sur diff{\'e}rents jeux d{'}{\'e}valuation propos{\'e}s dans la litt{\'e}rature, notre approche, qui ne requiert donc aucun texte, donne de bons r{\'e}sultats comparativement {\`a} l{'}{\'e}tat-de-l{'}art. De plus, nous montrons qu{'}il est int{\'e}ressant de les combiner avec les plongements {--} contextuels {--} existants."
W19-5029,Clinical Case Reports for {NLP},2019,0,1,3,0.153235,5675,cyril grouin,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"Textual data are useful for accessing expert information. Yet, since the texts are representative of distinct language uses, it is necessary to build specific corpora in order to be able to design suitable NLP tools. In some domains, such as medical domain, it may be complicated to access the representative textual data and their semantic annotations, while there exists a real need for providing efficient tools and methods. Our paper presents a corpus of clinical cases written in French, and their semantic annotations. Thus, we manually annotated a set of 717 files into four general categories (age, gender, outcome, and origin) for a total number of 2,835 annotations. The values of age, gender, and outcome are normalized. A subset with 70 files has been additionally manually annotated into 27 categories for a total number of 5,198 annotations."
R19-1026,Speculation and Negation detection in {F}rench biomedical corpora,2019,0,0,2,1,25287,clement dalloux,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"In this work, we propose to address the detection of negation and speculation, and of their scope, in French biomedical documents. It has been indeed observed that they play an important role and provide crucial clues for other NLP applications. Our methods are based on CRFs and BiLSTM. We reach up to 97.21 {\%} and 91.30 {\%} F-measure for the detection of negation and speculation cues, respectively, using CRFs. For the computing of scope, we reach up to 90.81 {\%} and 86.73 {\%} F-measure on negation and speculation, respectively, using BiLSTM-CRF fed with word embeddings."
2019.jeptalnrecital-long.5,Corpus annot{\\'e} de cas cliniques en fran{\\c{c}}ais (Annotated corpus with clinical cases in {F}rench),2019,-1,-1,4,0,5649,natalia grabar,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume I : Articles longs,0,"Les corpus textuels sont utiles pour diverses applications de traitement automatique des langues (TAL) en fournissant les donn{\'e}es n{\'e}cessaires pour leur cr{\'e}ation, adaptation ou {\'e}valuation. Cependant, dans certains domaines comme le domaine m{\'e}dical, l{'}acc{\`e}s aux donn{\'e}es est rendu compliqu{\'e}, voire impossible, pour des raisons de confidentialit{\'e} et d{'}{\'e}thique. Il existe n{\'e}anmoins de r{\'e}els besoins en corpus cliniques pour l{'}enseignement et la recherche. Pour r{\'e}pondre {\`a} ce d{\'e}fi, nous pr{\'e}sentons dans cet article le corpus CAS contenant des cas cliniques de patients, r{\'e}els ou fictifs, que nous avons compil{\'e}s. Ces cas cliniques en fran{\c{c}}ais couvrent plusieurs sp{\'e}cialit{\'e}s m{\'e}dicales et focalisent donc sur diff{\'e}rentes situations cliniques. Actuellement, le corpus contient 4 300 cas (environ 1,5M d{'}occurrences de mots). Il est accompagn{\'e} d{'}informations (discussions des cas cliniques, mots-cl{\'e}s, etc.) et d{'}annotations que nous avons effectu{\'e}es au regard des besoins de la recherche en TAL dans ce domaine. Nous pr{\'e}sentons {\'e}galement les r{\'e}sultats de premi{\`e}res exp{\'e}riences de recherche et d{'}extraction d{'}information qui ont {\'e}t{\'e} effectu{\'e}es avec ce corpus annot{\'e}. Ces exp{\'e}riences peuvent fournir une baseline {\`a} d{'}autres chercheurs souhaitant travailler avec les donn{\'e}es."
2019.jeptalnrecital-deft.1,Recherche et extraction d{'}information dans des cas cliniques. Pr{\\'e}sentation de la campagne d{'}{\\'e}valuation {DEFT} 2019 (Information Retrieval and Information Extraction from Clinical Cases),2019,-1,-1,4,0,5649,natalia grabar,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. D{\\'e}fi Fouille de Textes (atelier TALN-RECITAL),0,"Cet article pr{\'e}sente la campagne d{'}{\'e}valuation DEFT 2019 sur l{'}analyse de textes cliniques r{\'e}dig{\'e}s en fran{\c{c}}ais. Le corpus se compose de cas cliniques publi{\'e}s et discut{\'e}s dans des articles scientifiques, et index{\'e}s par des mots-cl{\'e}s. Nous proposons trois t{\^a}ches ind{\'e}pendantes : l{'}indexation des cas cliniques et discussions, {\'e}valu{\'e}e prioritairement par la MAP (mean average precision), l{'}appariement entre cas cliniques et discussions, {\'e}valu{\'e} au moyen d{'}une pr{\'e}cision, et l{'}extraction d{'}information parmi quatre cat{\'e}gories ({\^a}ge, genre, origine de la consultation, issue), {\'e}valu{\'e}e en termes de rappel, pr{\'e}cision et F-mesure. Nous pr{\'e}sentons les r{\'e}sultats obtenus par les participants sur chaque t{\^a}che."
W18-5913,{IRISA} at {SMM}4{H} 2018: Neural Network and Bagging for Tweet Classification,2018,0,0,3,0,5690,annelyse minard,Proceedings of the 2018 {EMNLP} Workshop {SMM}4{H}: The 3rd Social Media Mining for Health Applications Workshop {\\&} Shared Task,0,"This paper describes the systems developed by IRISA to participate to the four tasks of the SMM4H 2018 challenge. For these tweet classification tasks, we adopt a common approach based on recurrent neural networks (BiLSTM). Our main contributions are the use of certain features, the use of Bagging in order to deal with unbalanced datasets, and on the automatic selection of difficult examples. These techniques allow us to reach 91.4, 46.5, 47.8, 85.0 as F1-scores for Tasks 1 to 4."
W18-5614,{CAS}: {F}rench Corpus with Clinical Cases,2018,0,0,2,0,5649,natalia grabar,Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,0,"Textual corpora are extremely important for various NLP applications as they provide information necessary for creating, setting and testing these applications and the corresponding tools. They are also crucial for designing reliable methods and reproducible results. Yet, in some areas, such as the medical area, due to confidentiality or to ethical reasons, it is complicated and even impossible to access textual data representative of those produced in these areas. We propose the CAS corpus built with clinical cases, such as they are reported in the published scientific literature in French. We describe this corpus, currently containing over 397,000 word occurrences, and the existing linguistic and semantic annotations."
2018.jeptalnrecital-deft.1,{DEFT}2018 : recherche d{'}information et analyse de sentiments dans des tweets concernant les transports en {{\\^I}}le de {F}rance ({DEFT}2018 : Information Retrieval and Sentiment Analysis in Tweets about Public Transportation in {{\\^I}}le de {F}rance Region ),2018,-1,-1,4,0,5615,patrick paroubek,"Actes de la Conf{\\'e}rence TALN. Volume 2 - D{\\'e}monstrations, articles des Rencontres Jeunes Chercheurs, ateliers DeFT",0,"Cet article pr{\'e}sente l{'}{\'e}dition 2018 de la campagne d{'}{\'e}valuation DEFT (D{\'e}fi Fouille de Textes). A partir d{'}un corpus de tweets, quatre t{\^a}ches ont {\'e}t{\'e} propos{\'e}es : identifier les tweets sur la th{\'e}matique des transports, puis parmi ces derniers, identifier la polarit{\'e} (n{\'e}gatif, neutre, positif, mixte), identifier les marqueurs de sentiment et la cible, et enfin, annoter compl{\`e}tement chaque tweet en source et cible des sentiments exprim{\'e}s. Douze {\'e}quipes ont particip{\'e}, majoritairement sur les deux premi{\`e}res t{\^a}ches. Sur l{'}identification de la th{\'e}matique des transports, la micro F-mesure varie de 0,827 {\`a} 0,908. Sur l{'}identification de la polarit{\'e} globale, la micro F-mesure varie de 0,381 {\`a} 0,823."
2018.jeptalnrecital-deft.6,Participation de l{'}{IRISA} {\\`a} {D}e{FT} 2018 : classification et annotation d{'}opinion dans des tweets ({IRISA} at {D}e{FT} 2018: classifying and tagging opinion in tweets ),2018,-1,-1,3,0,5690,annelyse minard,"Actes de la Conf{\\'e}rence TALN. Volume 2 - D{\\'e}monstrations, articles des Rencontres Jeunes Chercheurs, ateliers DeFT",0,"Cet article d{\'e}crit les syst{\`e}mes d{\'e}velopp{\'e}s par l{'}{\'e}quipe LinkMedia de l{'}IRISA pour la campagne d{'}{\'e}valuation DeFT 2018 portant sur l{'}analyse d{'}opinion dans des tweets en fran{\c{c}}ais. L{'}{\'e}quipe a particip{\'e} {\`a} 3 des 4 t{\^a}ches de la campagne : (i) classification des tweets selon s{'}ils concernent les transports ou non, (ii) classification des tweets selon leur polarit{\'e} et (iii) annotation des marqueurs d{'}opinion et de l{'}objet {\`a} propos duquel est exprim{\'e}e l{'}opinion. Nous avons utilis{\'e} un algorithme de boosting d{'}arbres de d{\'e}cision et des r{\'e}seaux de neurones r{\'e}currents (RNN) pour traiter les t{\^a}ches 1 et 2. Pour la t{\^a}che 3 nous avons exp{\'e}riment{\'e} l{'}utilisation de r{\'e}seaux de neurones r{\'e}currents associ{\'e}s {\`a} des CRF. Ces approches donnent des r{\'e}sultats proches, avec un l{\'e}ger avantage aux RNN, et ont permis d{'}{\^e}tre parmi les premiers class{\'e}s pour chacune des t{\^a}ches."
2018.jeptalnrecital-court.24,Port{\\'e}e de la n{\\'e}gation : d{\\'e}tection par apprentissage supervis{\\'e} en fran{\\c{c}}ais et portugais br{\\'e}silien (Negation scope : sequence labeling by supervised learning in {F}rench and {B}razilian-{P}ortuguese),2018,-1,-1,2,1,25287,clement dalloux,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"La d{\'e}tection automatique de la n{\'e}gation fait souvent partie des pr{\'e}-requis dans les syst{\`e}mes d{'}extraction d{'}information, notamment dans le domaine biom{\'e}dical. Cet article pr{\'e}sente nos contributions concernant la d{\'e}tection de la port{\'e}e de la n{\'e}gation en fran{\c{c}}ais et portugais br{\'e}silien. Nous pr{\'e}sentons d{'}une part deux corpus principalement constitu{\'e}s d{'}extraits de protocoles d{'}essais cliniques en fran{\c{c}}ais et portugais br{\'e}silien, d{\'e}di{\'e}s aux crit{\`e}res d{'}inclusion de patients. Les marqueurs de n{\'e}gation et leurs port{\'e}es y ont {\'e}t{\'e} annot{\'e}s manuellement. Nous pr{\'e}sentons d{'}autre part une approche par r{\'e}seau de neurones r{\'e}currents pour extraire les port{\'e}es."
2017.jeptalnrecital-court.5,"Crit{\\`e}res num{\\'e}riques dans les essais cliniques : annotation, d{\\'e}tection et normalisation (Numerical criteria in clinical trials : annotation, detection and normalization)",2017,-1,-1,2,0,5649,natalia grabar,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"Les essais cliniques sont un {\'e}l{\'e}ment fondamental pour l{'}{\'e}valuation de nouvelles th{\'e}rapies ou techniques de diagnostic, de leur s{\'e}curit{\'e} et efficacit{\'e}. Ils exigent d{'}avoir un {\'e}chantillon convenable de la population. Le d{\'e}fi consiste alors {\`a} recruter le nombre suffisant de participants avec des caract{\'e}ristiques similaires pour garantir que les r{\'e}sultats des essais sont bien contr{\^o}l{\'e}s et dus aux facteurs {\'e}tudi{\'e}s. C{'}est une t{\^a}che difficile, effectu{\'e}e essentiellement manuellement. Comme les valeurs num{\'e}riques sont une information tr{\`e}s fr{\'e}quente et importante, nous proposons un syst{\`e}me automatique qui vise leur extraction et normalisation."
L16-1190,Evaluating Lexical Similarity to build Sentiment Similarity,2016,4,0,2,0,34912,gregoire jadi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this article, we propose to evaluate the lexical similarity information provided by word representations against several opinion resources using traditional Information Retrieval tools. Word representation have been used to build and to extend opinion resources such as lexicon, and ontology and their performance have been evaluated on sentiment analysis tasks. We question this method by measuring the correlation between the sentiment proximity provided by opinion resources and the semantic similarity provided by word representations using different correlation coefficients. We also compare the neighbors found in word representations and list of similar opinion words. Our results show that the proximity of words in state-of-the-art word representations is not very effective to build sentiment similarity."
L16-1588,Distributional Thesauri for Information Retrieval and vice versa,2016,30,1,1,1,5590,vincent claveau,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Distributional thesauri are useful in many tasks of Natural Language Processing. In this paper, we address the problem of building and evaluating such thesauri with the help of Information Retrieval (IR) concepts. Two main contributions are proposed. First, following the work of [8], we show how IR tools and concepts can be used with success to build a thesaurus. Through several experiments and by evaluating directly the results with reference lexicons, we show that some IR models outperform state-of-the-art systems. Secondly, we use IR as an applicative framework to indirectly evaluate the generated thesaurus. Here again, this task-based evaluation validates the IR approach used to build the thesaurus. Moreover, it allows us to compare these results with those from the direct evaluation framework used in the literature. The observed differences bring these evaluation habits into question."
C16-1173,Direct vs. indirect evaluation of distributional thesauri,2016,30,2,1,1,5590,vincent claveau,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"With the success of word embedding methods in various Natural Language Processing tasks, all the field of distributional semantics has experienced a renewed interest. Beside the famous word2vec, recent studies have presented efficient techniques to build distributional thesaurus; in particular, Claveau et al. (2014) have already shown that Information Retrieval (IR) tools and concepts can be successfully used to build a thesaurus. In this paper, we address the problem of the evaluation of such thesauri or embedding models and compare their results. Through several experiments and by evaluating directly the results with reference lexicons, we show that the recent IR-based distributional models outperform state-of-the-art systems such as word2vec. Following the work of Claveau and Kijak (2016), we use IR as an applicative framework to indirectly evaluate the generated thesaurus. Here again, this task-based evaluation validates the IR approach used to build the thesaurus. Moreover, it allows us to compare these results with those from the direct evaluation framework used in the literature. The observed differences bring these evaluation habits into question."
2016.jeptalnrecital-poster.17,Extraction d{'}expressions-cibles de l{'}opinion : de l{'}anglais au fran{\\c{c}}ais (Opinion Target Expression extraction : from {E}nglish to {F}rench),2016,-1,-1,3,0,34912,gregoire jadi,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,"Dans cet article, nous pr{\'e}sentons le d{\'e}veloppement d{'}un syst{\`e}me d{'}extraction d{'}expressions-cibles pour l{'}anglais et sa transposition au fran{\c{c}}ais. En compl{\'e}ment, nous avons r{\'e}alis{\'e} une {\'e}tude de l{'}efficacit{\'e} des traits en anglais et en fran{\c{c}}ais qui tend {\`a} montrer qu{'}il est possible de r{\'e}aliser un syst{\`e}me d{'}extraction d{'}expressions-cibles ind{\'e}pendant du domaine. Pour finir, nous proposons une analyse comparative des erreurs commises par nos syst{\`e}mes en anglais et fran{\c{c}}ais et envisageons diff{\'e}rentes solutions {\`a} ces probl{\`e}mes."
2016.jeptalnrecital-poster.24,"M{\\'e}dias traditionnels, m{\\'e}dias sociaux : caract{\\'e}riser la r{\\'e}information (Traditional medias, social medias : characterizing reinformation)",2016,-1,-1,3,0,35932,cedric maigrot,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters),0,"Les m{\'e}dias traditionnels sont de plus en plus pr{\'e}sents sur les r{\'e}seaux sociaux, mais ces sources d{'}informations sont confront{\'e}es {\`a} d{'}autres sources dites de r{\'e}information. Ces derni{\`e}res ont parfois tendance {\`a} d{\'e}former les informations relay{\'e}es pour correspondre aux id{\'e}ologies qu{'}elles souhaitent d{\'e}fendre, les rendant partiellement ou totalement fausses. Le but de cet article est, d{'}une part, de pr{\'e}senter un corpus que nous avons constitu{\'e} {\`a} partir de groupes Facebook de ces deux types de m{\'e}dias. Nous pr{\'e}sentons d{'}autre part quelques exp{\'e}riences de d{\'e}tection automatique des messages issus des m{\'e}dias de r{\'e}information, en {\'e}tudiant notamment l{'}influence d{'}attributs de surface et d{'}attributs portant plus sp{\'e}cifiquement sur le contenu de ces messages."
2015.jeptalnrecital-long.2,Strat{\\'e}gies de s{\\'e}lection des exemples pour l{'}apprentissage actif avec des champs al{\\'e}atoires conditionnels,2015,-1,-1,1,1,5590,vincent claveau,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Beaucoup de probl{\`e}mes de TAL sont d{\'e}sormais mod{\'e}lis{\'e}s comme des t{\^a}ches d{'}apprentissage supervis{\'e}. De ce fait, le co{\^u}t des annotations des exemples par l{'}expert repr{\'e}sente un probl{\`e}me important. L{'}apprentissage actif (active learning) apporte un cadre {\`a} ce probl{\`e}me, permettant de contr{\^o}ler le co{\^u}t d{'}annotation tout en maximisant, on l{'}esp{\`e}re, la performance de la t{\^a}che vis{\'e}e, mais repose sur le choix difficile des exemples {\`a} soumettre {\`a} l{'}expert. Dans cet article, nous examinons et proposons des strat{\'e}gies de s{\'e}lection des exemples pour le cas sp{\'e}cifique des champs al{\'e}atoires conditionnels (Conditional Random Fields, CRF), outil largement utilis{\'e} en TAL. Nous proposons d{'}une part une m{\'e}thode simple corrigeant un biais de certaines m{\'e}thodes de l{'}{\'e}tat de l{'}art. D{'}autre part, nous d{\'e}taillons une m{\'e}thode originale de s{\'e}lection s{'}appuyant sur un crit{\`e}re de respect des proportions dans les jeux de donn{\'e}es manipul{\'e}s. Le bien- fond{\'e} de ces propositions est v{\'e}rifi{\'e} au travers de plusieurs t{\^a}ches et jeux de donn{\'e}es, incluant reconnaissance d{'}entit{\'e}s nomm{\'e}es, chunking, phon{\'e}tisation, d{\'e}sambigu{\""\i}sation de sens."
claveau-kijak-2014-generating,Generating and using probabilistic morphological resources for the biomedical domain,2014,18,1,1,1,5590,vincent claveau,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In most Indo-European languages, many biomedical terms are rich morphological structures composed of several constituents mainly originating from Greek or Latin. The interpretation of these compounds are keystones to access information. In this paper, we present morphological resources aiming at coping with these biomedical morphological compounds. Following previous work (Claveau et al. 2011,Claveau et al. 12), these resources are automatically built using Japanese terms in Kanjis as a pivot language and alignment techniques. We show how these alignment information can be used for segmenting compounds, attaching semantic interpretation to each part, proposing definitions (gloses) of the compounds... When possible, these tasks are compared with state-of-the-art tools, and the results show the interest of our automatically built probabilistic resources."
F14-1020,Exploring the neighbor graph to improve distributional thesauri (Explorer le graphe de voisinage pour am{\\'e}liorer les th{\\'e}saurus distributionnels) [in {F}rench],2014,-1,-1,1,1,5590,vincent claveau,Proceedings of TALN 2014 (Volume 1: Long Papers),0,None
C14-1067,Improving distributional thesauri by exploring the graph of neighbors,2014,35,6,1,1,5590,vincent claveau,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In this paper, we address the issue of building and improving a distributional thesaurus. We first show that existing tools from the information retrieval domain can be directly used in order to build a thesaurus with state-of-the-art performance. Secondly, we focus more specifically on improving the obtained thesaurus, seen as a graph of k-nearest neighbors. By exploiting information about the neighborhood contained in this graph, we propose several contributions. 1) We show how the lists of neighbors can be globally improved by examining the reciprocity of the neighboring relation, that is, the fact that a word can be close of another and vice-versa. 2) We also propose a method to associate a confidence score to any lists of nearest neighbors (i.e. any entry of the thesaurus). 3) Last, we demonstrate how these confidence scores can be used to reorder the closest neighbors of a word. These different contributions are validated through experiments and offer significant improvement over the state-of-the-art."
W13-2027,{IRISA} participation to {B}io{NLP}-{ST}13: lazy-learning and information retrieval for information extraction tasks,2013,31,14,1,1,5590,vincent claveau,Proceedings of the {B}io{NLP} Shared Task 2013 Workshop,0,"This paper describes the information extraction techniques developed in the framework of the participation of IRISA-TexMex to the following BioNLP-ST13 tasks: Bacterial Biotope subtasks 1 and 2, and Graph Regulation Network. The approaches developed are general-purpose ones and do not rely on specialized preprocessing, nor specialized external data, and they are expected to work independently of the domain of the texts processed. They are classically based on machine learning techniques, but we put the emphasis on the use of similarity measures inherited from the information retrieval domain (Okapi-BM25 (Robertson et al., 1998), language modeling (Hiemstra, 1998)). Through the good results obtained for these tasks, we show that these simple settings are competitive provided that the representation and similarity chosen are well suited for the task."
F13-1019,Unsupervised {CRF} for knowledge discovery (D{\\'e}couverte de connaissances dans les s{\\'e}quences par {CRF} non-supervis{\\'e}s) [in {F}rench],2013,-1,-1,1,1,5590,vincent claveau,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
W12-1106,Participation de l{'}{IRISA} {\\`a} {D}e{FT}2012 : recherche d{'}information et apprentissage pour la g{\\'e}n{\\'e}ration de mots-cl{\\'e}s ({IRISA} participation to {D}e{FT}2012: information retrieval and machine-learning for keyword generation) [in {F}rench],2012,-1,-1,1,1,5590,vincent claveau,"JEP-TALN-RECITAL 2012, Workshop DEFT 2012: D{\\'E}fi Fouille de Textes (DEFT 2012 Workshop: Text Mining Challenge)",0,None
fort-claveau-2012-annotating,Annotating Football Matches: Influence of the Source Medium on Manual Annotation,2012,8,7,2,0,10472,karen fort,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we present an annotation campaign of football (soccer) matches, from a heterogeneous text corpus of both match minutes and video commentary transcripts, in French. The data, annotations and evaluation process are detailed, and the quality of the annotated corpus is discussed. In particular, we propose a new technique to better estimate the annotator agreement when few elements of a text are to be annotated. Based on that, we show how the source medium influenced the process and the quality."
F12-2007,"Vectorisation, Okapi et calcul de similarit{\\'e} pour le {TAL} : pour oublier enfin le {TF}-{IDF} (Vectorization, Okapi and Computing Similarity for {NLP} : Say Goodbye to {TF}-{IDF}) [in {F}rench]",2012,0,1,1,1,5590,vincent claveau,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
F12-2031,Annotation manuelle de matchs de foot : Oh la la la ! l{'}accord inter-annotateurs ! et c{'}est le but ! (Manual Annotation of Football Matches : Inter-annotator Agreement ! Gooooal !) [in {F}rench],2012,0,0,2,0,10472,karen fort,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
C12-1039,Unsupervised and Semi-Supervised Morphological Analysis for Information Retrieval in the Biomedical Domain,2012,29,7,1,1,5590,vincent claveau,Proceedings of {COLING} 2012,0,"In the biomedical field, the key to access information is the use of specialized terms. However, in most of Indo-European languages, these terms are complex morphological structures. The aim of the presented work is to identify the various meaningful components of these terms and use this analysis to improve biomedical Information Retrieval. We present an approach combining an automatic alignment using a pivot language, and an analogical learning that allows an accurate morphological analysis of terms. These morphological analysis are used to improve the indexing of medical documents. The experiments reported in this paper show the validity of this approach with a 10% improvement in MAP over a standard IR system."
R11-1048,Morphological Analysis of Biomedical Terminology with Analogy-Based Alignment,2011,19,5,1,1,5590,vincent claveau,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"In the biomedical domain, many terms are neoclassical compounds (composed of several Greek or Latin roots). The study of their morphology is important for numerous applications since it makes it possible to structure, translate, retrieve them efficiently... In this paper, we propose an original yet fruitful approach to carry out this morphological analysis by relying on Japanese, more precisely on terms written in kanjis, as a pivot language. In order to do so, we have developed a specially crafted alignment algorithm relying on analogy learning. Aligning terms with their kanji-based counterparts provides at the same time a decomposition of the term into morphs, and a kanji label for each morph. Evaluated on a dataset of French terms, our approach yields a precision greater than 70% and shows its relevance compared with existing techniques. We also illustrate the interest of this approach through two direct applications of the produced alignments: translating unknown terms and discovering relationships between morphs for terminological structuring."
2011.jeptalnrecital-court.21,Utilisation de crit{\\`e}res linguistiques de surface pour l{'}extraction de relation dans les textes bio-m{\\'e}dicaux (Using shallow linguistic features for relation extraction in bio-medical texts),2011,-1,-1,2,0,44492,ali ebadat,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous proposons de mod{\'e}liser la t{\^a}che d{'}extraction de relations {\`a} partir de corpus textuels comme un probl{\`e}me de classification. Nous montrons que, dans ce cadre, des repr{\'e}sentations fond{\'e}es sur des informations linguistiques de surface sont suffisantes pour que des algorithmes d{'}apprentissage artificiel standards les exploitant rivalisent avec les meilleurs syst{\`e}mes d{'}extraction de relations reposant sur des connaissances issues d{'}analyses profondes (analyses syntaxiques ou s{\'e}mantiques). Nous montrons {\'e}galement qu{'}en prenant davantage en compte les sp{\'e}cificit{\'e}s de la t{\^a}che d{'}extraction {\`a} r{\'e}aliser et des donn{\'e}es disponibles, il est possible d{'}obtenir des m{\'e}thodes encore plus efficaces tout en exploitant ces informations simples. La technique originale {\`a} base d{'}apprentissage Â« paresseux Â» et de mod{\`e}les de langue que nous {\'e}valuons en extraction d{'}interactions g{\'e}niques sur les donn{\'e}es du challenge LLL2005 d{\'e}passe les r{\'e}sultats de l{'}{\'e}tat de l{'}art."
tirilly-etal-2010-news,News Image Annotation on a Large Parallel Text-image Corpus,2010,12,8,2,0,46280,pierre tirilly,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we present a multimodal parallel text-image corpus, and propose an image annotation method that exploits the textual information associated with images. Our corpus contains news articles composed of a text, images and image captions, and is significantly larger than the other news corpora proposed in image annotation papers (27,041 articles and 42,568 captionned images). In our experiments, we use the text of the articles as a textual information source to annotate images, and image captions as a groundtruth to evaluate our annotation algorithm. Our annotation method identifies relevant named entities in the texts, and associates them with high-level visual concepts detected in the images (in this paper, faces and logos). The named entities most suited to image annotation are selected using an unsupervised score based on their statistics, inspired from the weights used in information retrieval. Our experiments show that, although it is very simple, our annotation method achieves an acceptable accuracy on our real-world news corpus."
ozdowska-claveau-2010-inferring,Inferring Syntactic Rules for Word Alignment through Inductive Logic Programming,2010,19,0,2,0.384615,46337,sylwia ozdowska,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents and evaluates an original approach to automatically align bitexts at the word level. It relies on a syntactic dependency analysis of the source and target texts and is based on a machine-learning technique, namely inductive logic programming (ILP). We show that ILP is particularly well suited for this task in which the data can only be expressed by (translational and syntactic) relations. It allows us to infer easily rules called syntactic alignment rules. These rules make the most of the syntactic information to align words. A simple bootstrapping technique provides the examples needed by ILP, making this machine learning approach entirely automatic. Moreover, through different experiments, we show that this approach requires a very small amount of training data, and its performance rivals some of the best existing alignment systems. Furthermore, cases of syntactic isomorphisms or non-isomorphisms between the source language and the target language are easily identified through the inferred rules."
2010.jeptalnrecital-long.39,Analyse morphologique en terminologie biom{\\'e}dicale par alignement et apprentissage non-supervis{\\'e},2010,-1,-1,1,1,5590,vincent claveau,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le domaine biom{\'e}dical, beaucoup de termes sont des compos{\'e}s savants (compos{\'e}s de plusieurs racines gr{\'e}co-latines). L{'}{\'e}tude de leur morphologie est importante pour de nombreuses applications puisqu{'}elle permet de structurer ces termes, de les rechercher efficacement, de les traduire... Dans cet article, nous proposons de suivre une d{\'e}marche originale mais fructueuse pour mener cette analyse morphologique sur des termes simples en fran{\c{c}}ais, en nous appuyant sur une langue pivot, le japonais, et plus pr{\'e}cis{\'e}ment sur les termes {\'e}crits en kanjis. Pour cela nous avons d{\'e}velopp{\'e} un algorithme d{'}alignement de termes sp{\'e}cialement adapt{\'e} {\`a} cette t{\^a}che. C{'}est cet alignement d{'}un terme fran{\c{c}}ais avec sa traduction en kanjis qui fournit en m{\^e}me temps une d{\'e}composition en morphe et leur {\'e}tiquetage par les kanjis correspondants. {\'E}valu{\'e} sur un jeu de donn{\'e}es cons{\'e}quent, notre approche obtient une pr{\'e}cision sup{\'e}rieure {\`a} 70{\%} et montrent son bien fond{\'e} en comparaison avec les techniques existantes. Nous illustrons {\'e}galement l{'}int{\'e}r{\^e}t de notre d{\'e}marche au travers de deux applications directes de ces alignements : la traduction de termes inconnus et la d{\'e}couverte de relations entre morphes pour la tructuration terminologique."
2009.jeptalnrecital-court.27,La /f{O}netizasjc/ comme un probl{\\`e}me de translitt{\\'e}ration,2009,-1,-1,1,1,5590,vincent claveau,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"La phon{\'e}tisation est une {\'e}tape essentielle pour le traitement de l{'}oral. Dans cet article, nous d{\'e}crivons un syst{\`e}me automatique de phon{\'e}tisation de mots isol{\'e}s qui est simple, portable et performant. Il repose sur une approche par apprentissage ; le syst{\`e}me est donc construit {\`a} partir d{'}exemples de mots et de leur repr{\'e}sentation phon{\'e}tique. Nous utilisons pour cela une technique d{'}inf{\'e}rence de r{\`e}gles de r{\'e}{\'e}criture initialement d{\'e}velopp{\'e}e pour la translitt{\'e}ration et la traduction. Pour {\'e}valuer les performances de notre approche, nous avons utilis{\'e} plusieurs jeux de donn{\'e}es couvrant diff{\'e}rentes langues et divers alphabets phon{\'e}tiques, tir{\'e}s du challenge Pascal Pronalsyl. Les tr{\`e}s bons r{\'e}sultats obtenus {\'e}galent ou d{\'e}passent ceux des meilleurs syst{\`e}mes de l{'}{\'e}tat de l{'}art."
W08-0612,Automatic inference of indexing rules for {MEDLINE},2008,21,11,3,0,863,aurelie neveol,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,0,"This paper describes the use and customization of Inductive Logic Programming (ILP) to infer indexing rules from MEDLINE citations. Preliminary results suggest this method may enhance the subheading attachment module of the Medical Text Indexer, a system for assisting MEDLINE indexers."
claveau-2008-automatic,Automatic Translation of Biomedical Terms by Supervised Machine Learning,2008,25,5,1,1,5590,vincent claveau,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, we present a simple yet efficient automatic system to translate biomedical terms. It mainly relies on a machine learning approach able to infer rewriting rules from pair of terms in two languages. Given a new term, these rules are then used to transform the initial term into its translation. Since conflicting rules may produce different translations, we also use language modeling to single out the best candidate. We report experiments on different language pairs (including Czech, English, French, Italian, German, Portuguese, Spanish and even Russian); our approach yields good results (varying according to the considered languages) and outperforms existing ones for the French-English pair."
2008.jeptalnrecital-long.30,Apprentissage artificiel de r{\\`e}gles d{'}indexation pour {MEDLINE},2008,12,0,2,0,863,aurelie neveol,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"L{'}indexation est une composante importante de tout syst{\`e}me de recherche d{'}information. Dans MEDLINE, la base documentaire de r{\'e}f{\'e}rence pour la litt{\'e}rature du domaine biom{\'e}dical, le contenu des articles r{\'e}f{\'e}renc{\'e}s est index{\'e} {\`a} l{'}aide de descripteurs issus du th{\'e}saurus MeSH. Avec l{'}augmentation constante de publications {\`a} indexer pour maintenir la base {\`a} jour, le besoin d{'}outils automatiques se fait pressant pour les indexeurs. Dans cet article, nous d{\'e}crivons l{'}utilisation et l{'}adaptation de la Programmation Logique Inductive (PLI) pour d{\'e}couvrir des r{\`e}gles d{'}indexation permettant de g{\'e}n{\'e}rer automatiquement des recommandations d{'}indexation pour MEDLINE. Les r{\'e}sultats obtenus par cette approche originale sont tr{\`e}s satisfaisants compar{\'e}s {\`a} ceux obtenus {\`a} l{'}aide de r{\`e}gles manuelles lorsque celles-ci existent. Ainsi, les jeux de r{\`e}gles obtenus par PLI devraient {\^e}tre prochainement int{\'e}gr{\'e}s au syst{\`e}me produisant les recommandations d{'}indexation automatique pour MEDLINE."
2007.jeptalnrecital-long.10,Inf{\\'e}rence de r{\\`e}gles de r{\\'e}{\\'e}criture pour la traduction de termes biom{\\'e}dicaux,2007,-1,-1,1,1,5590,vincent claveau,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le domaine biom{\'e}dical, le caract{\`e}re multilingue de l{'}acc{\`e}s {\`a} l{'}information est un probl{\`e}me d{'}importance. Dans cet article nous pr{\'e}sentons une technique originale permettant de traduire des termes simples du domaine biom{\'e}dical de et vers de nombreuses langues. Cette technique enti{\`e}rement automatique repose sur l{'}apprentissage de r{\`e}gles de r{\'e}{\'e}criture {\`a} partir d{'}exemples et l{'}utilisation de mod{\`e}les de langues. Les {\'e}valuations pr{\'e}sent{\'e}es sont men{\'e}es sur diff{\'e}rentes paires de langues (fran{\c{c}}ais-anglais, espagnol-portugais, tch{\`e}que-anglais, russe-anglais...). Elles montrent que cette approche est tr{\`e}s efficace et offre des performances variables selon les langues mais tr{\`e}s bonnes dans l{'}ensemble et nettement sup{\'e}rieures {\`a} celles disponibles dans l{'}{\'e}tat de l{'}art. Les taux de pr{\'e}cision de traductions s{'}{\'e}tagent ainsi de 57.5{\%} pour la paire russe-anglais jusqu{'}{\`a} 85{\%} pour la paire espagnol-portugais et la paire fran{\c{c}}aisanglais."
2005.jeptalnrecital-long.25,Alignement de mots par apprentissage de r{\\`e}gles de propagation syntaxique en corpus de taille restreinte,2005,-1,-1,2,0.384615,46337,sylwia ozdowska,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente et {\'e}value une approche originale et efficace permettant d{'}aligner automatiquement un bitexte au niveau des mots. Pour cela, cette approche tire parti d{'}une analyse syntaxique en d{\'e}pendances des bitextes effectu{\'e}e par les outils SYNTEX et utilise une technique d{'}apprentissage artificiel, la programmation logique inductive, pour apprendre automatiquement des r{\`e}gles dites de propagation. Celles-ci se basent sur les informations syntaxiques connues pour ensuite aligner les mots avec une grande pr{\'e}cision. La m{\'e}thode est enti{\`e}rement automatique, et les r{\'e}sultats {\'e}valu{\'e}s sur les donn{\'e}es de la campagne d{'}alignement HLT montrent qu{'}elle se compare aux meilleures techniques existantes. De plus, alors que ces derni{\`e}res n{\'e}cessitent plusieurs millions de phrases pour s{'}entra{\^\i}ner, notre approche n{'}en requiert que quelques centaines. Enfin, l{'}examen des r{\`e}gles de propagation inf{\'e}r{\'e}es permet d{'}identifier facilement les cas d{'}isomorphismes et de non-isomorphismes syntaxiques entre les deux langues trait{\'e}es."
2005.jeptalnrecital-long.26,Traduction de termes biom{\\'e}dicaux par inf{\\'e}rence de transducteurs,2005,-1,-1,1,1,5590,vincent claveau,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article propose et {\'e}value une m{\'e}thode de traduction automatique de termes biom{\'e}dicaux simples du fran{\c{c}}ais vers l{'}anglais et de l{'}anglais vers le fran{\c{c}}ais. Elle repose sur une technique d{'}apprentissage artificiel supervis{\'e}e permettant d{'}inf{\'e}rer des transducteurs {\`a} partir d{'}exemples de couples de termes bilingues ; aucune autre ressource ou connaissance n{'}est requise. Ces transducteurs, capturant les grandes r{\'e}gularit{\'e}s de traduction existant dans le domaine biom{\'e}dical, sont ensuite utilis{\'e}s pour traduire de nouveaux termes fran{\c{c}}ais en anglais et vice versa. Les {\'e}valuations men{\'e}es montrent que le taux de bonnes traductions de notre technique se situe entre 52 et 67{\%}. {\`A} travers un examen des erreurs les plus courantes, nous identifions quelques limites inh{\'e}rentes {\`a} notre approche et proposons quelques pistes pour les d{\'e}passer. Nous envisageons enfin plusieurs extensions {\`a} ce travail."
W04-1805,Discovering Specific Semantic Relationships between Nouns and Verbs in a Specialized {F}rench Corpus,2004,0,6,1,1,5590,vincent claveau,Proceedings of {C}ompu{T}erm 2004: 3rd International Workshop on Computational Terminology,0,None
C04-1038,From efficiency to portability: acquisition of semantic relations by semi-supervised machine learning,2004,14,5,1,1,5590,vincent claveau,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Numeric approaches to the corpus-based acquisition of lexical semantic relations offer robust and portable techniques, but poor explanations of their results. On the other hand, symbolic machine learning approaches can infer patterns of a target relation from examples of elements that verify this relation; the produced patterns are efficient and expressive, but such techniques are often supervised, i.e. require to be (manually) fed by examples. This paper presents two original algorithms to combine one technique from each of these approaches, and keep advantages of both (meaningful patterns, efficient extraction, portability). Moreover the extraction results of these two semi-supervised hybrid systems, when applied in an illustrative purpose to the acquisition of semantic noun-verb relations defined in the Generative Lexicon framework (Pustejovsky, 1995), rival those of supervised methods."
2004.jeptalnrecital-long.4,Extension de requ{\\^e}tes par lien s{\\'e}mantique nom-verbe acquis sur corpus,2004,-1,-1,1,1,5590,vincent claveau,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"En recherche d{'}information, savoir reformuler une id{\'e}e par des termes diff{\'e}rents est une des clefs pour l{'}am{\'e}lioration des performances des syst{\`e}mes de recherche d{'}information (SRI) existants. L{'}un des moyens pour r{\'e}soudre ce probl{\`e}me est d{'}utiliser des ressources s{\'e}mantiques sp{\'e}cialis{\'e}es et adapt{\'e}es {\`a} la base documentaire sur laquelle les recherches sont faites. Nous proposons dans cet article de montrer que les liens s{\'e}mantiques entre noms et verbes appel{\'e}s liens qualia, d{\'e}finis dans le mod{\`e}le du Lexique g{\'e}n{\'e}ratif (Pustejovsky, 1995), peuvent effectivement am{\'e}liorer les r{\'e}sultats des SRI. Pour cela, nous extrayons automatiquement des couples nom-verbe en relation qualia de la base documentaire {\`a} l{'}aide du syst{\`e}me d{'}acquisition ASARES (Claveau, 2003a). Ces couples sont ensuite utilis{\'e}s pour {\'e}tendre les requ{\^e}tes d{'}un syst{\`e}me de recherche. Nous montrons, {\`a} l{'}aide des donn{\'e}es de la campagne d{'}{\'e}valuation Amaryllis, que cette extension permet effectivement d{'}obtenir des r{\'e}ponses plus pertinentes, et plus particuli{\`e}rement pour les premiers documents retourn{\'e}s {\`a} l{'}utilisateur."
2003.jeptalnrecital-long.5,Extraction de couples nom-verbe s{\\'e}mantiquement li{\\'e}s : une technique symbolique automatique,2003,21,0,1,1,5590,vincent claveau,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans le mod{\`e}le du Lexique g{\'e}n{\'e}ratif (Pustejovsky, 1995), certaines propri{\'e}t{\'e}s s{\'e}mantiques des noms sont exprim{\'e}es {\`a} l{'}aide de verbes. Les couples nom-verbe ainsi form{\'e}s pr{\'e}sentent un int{\'e}r{\^e}t applicatif notamment en recherche d{'}information. Leur acquisition sur corpus constitue donc un enjeu, mais la d{\'e}couverte des patrons qui les d{\'e}finissent en contexte est {\'e}galement importante pour la compr{\'e}hension m{\^e}me du mod{\`e}le du Lexique g{\'e}n{\'e}ratif. Cet article pr{\'e}sente une technique enti{\`e}rement automatique permettant de r{\'e}pondre {\`a} ce double besoin d{'}extraction sur corpus de couples et de patrons morpho-syntaxiques et s{\'e}mantiques. Elle combine pour ce faire deux approches d{'}acquisition{---} l{'}approche statistique et l{'}approche symbolique{---} en conservant les avantages propres {\`a} chacune d{'}entre elles : robustesse et automatisation des m{\'e}thodes statistiques, qualit{\'e} et expressivit{\'e} des r{\'e}sultats des techniques symboliques."
bouillon-etal-2002-acquisition,Acquisition of Qualia Elements from Corpora - Evaluation of a Symbolic Learning Method,2002,14,13,2,0,2866,pierrette bouillon,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper presents and evaluates a system extracting from a corpus noun-verb pairs whose components are related by a special kind of link: the qualia roles as defined in the Generative Lexicon. This system is based on a symbolic learning method that automatically learns, from noun-verb pairs that are or are not related by a qualia link, rules characterizing positive examples from negative ones in terms of their surrounding part-of-speech or semantic contexts. The qualia noun-verb pair extraction is thus performed by applying the learnt rules on a part-of-speech or semantically tagged text. Stress is put on the quality of the learning when compared with traditional statistical or syntactical-based approaches. The linguistic relevance of the rules is also evaluated through a comparison with manually acquired qualia patterns."
