W16-5205,Recurrent Neural Network with Word Embedding for Complaint Classification,2016,0,4,3,0,33511,panuwat assawinjaipetch,Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies ({WLSI}/{OIAF}4{HLT}2016),0,"Complaint classification aims at using information to deliver greater insights to enhance user experience after purchasing the products or services. Categorized information can help us quickly collect emerging problems in order to provide a support needed. Indeed, the response to the complaint without the delay will grant users highest satisfaction. In this paper, we aim to deliver a novel approach which can clarify the complaints precisely with the aim to classify each complaint into nine predefined classes i.e. acces-sibility, company brand, competitors, facilities, process, product feature, staff quality, timing respec-tively and others. Given the idea that one word usually conveys ambiguity and it has to be interpreted by its context, the word embedding technique is used to provide word features while applying deep learning techniques for classifying a type of complaints. The dataset we use contains 8,439 complaints of one company."
Y14-1002,Social Media Understanding by Word Cloud Timeline,2014,3,0,1,1,33512,virach sornlertlamvanich,"Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing",0,"Text from social media is significant key information to understand social movement. However, the length of the social media text is typically short and concise with a lot of absent words. Our task is to identify the proper keyword representing the message content that we are accounting for. Instead of training the model for keyword extraction directly from the Twitter messages, we propose a new method to fine-tune the model trained from some known documents containing richer context information. We conducted the experiment on Twitter messages and expressed in word cloud timeline. It shows a promising result."
W12-5002,Semantic Relation Extraction from a Cultural Database,2012,14,2,2,1,8038,canasai kruengkrai,Proceedings of the 3rd Workshop on South and Southeast {A}sian Natural Language Processing,0,"Semantic relation extraction aims to extract relation instances from natural language texts. In this paper, we propose a semantic relation extraction approach based on simple relation templates that determine relation types and their arguments. We attempt to reduce semantic drift of the arguments by using named entity models as semantic constraints. Experimental results indicate that our approach is very promising. We successfully apply our approach to a cultural database and discover more than 18,000 relation instances with expected high accuracy."
W11-3401,Participation in Language Resource Development and Sharing,2011,0,0,1,1,33512,virach sornlertlamvanich,Proceedings of the 9th Workshop on {A}sian Language Resources,0,"Language resources are really much required for understanding and modeling the language in the present approaches. The language that has a rich language resource gains a big benefit in making a big advance in language processing. On the other hand, the less resource language is struggling with preparing a large enough language resource such as raw text or annotated corpora. It is a labor intensive and time consuming task. Moreover, computerization of the text is another non-trivial effort. There needs a supportive computing environment in inputting, encoding, retrieving, analysis, etc.. Learning from the rich resource languages, we gradually collecting the resource and preparing the necessary tools. Through many efforts in the recent years, we can see some significant outcomes from PAN localization project (2004-2007, 2007-2101, http://www.panl10n.net/), ADD (2006-2010, http://www.tcllab.org/), Asian WordNet (http://asianwordnet.org/), Hindi WordNet (http://www.cfilt.iitb.ac.in/wordnet/webhwn/), BEST (since 2009, Thai Word Segmentation Software Contest, http://thailang.nectec.or.th/ best/) and many NLP summer schools. The activities gain a big potential in leveraging the NLP tools development and research personnel development. It results in a big growth of Asian language resource development and research. With the spirit of sharing on social networking, the resources can efficiently be developed to a satisfied amount in a reasonable time scale. Asian WordNet is an example of developing a set of 13 languages of Wordnet connected via Princeton WordNet. Thai WordNet is open for online collaborative development. About 70K synsets and 80K words of Thai WordNet are available online. ThaiLao conversion is an approach to exhibit the advantage in utilization of language similarity to increase the other language resource. Lao WordNet is created by converting from Thai WordNet by using the phoneme transfer approach. Taking the advantage of language similarity, the language corpus can be obtained by a quick conversion rule. In this case, the study of direct transfer is much more efficient than creating from the scratch. Currently, most of the above mentioned results are open to public for at least research purpose. However, more and more language resources are still needed to improve the language processing. The possible of online collaborative development and sharing is a key factor in the language resource development."
W11-3303,Service Quality Improvement in Web Service Based Machine Translation,2011,10,0,2,0,44103,sapa chanyachatchawan,"Proceedings of the Workshop on Language Resources, Technology and Services in the Sharing Paradigm",0,"There are many approaches to increase web service based machine translation result. However, perfect result alone does not guarantee the quality of translation service or user satisfaction. This paper proposes framework to improve translation service by using non functional attributes information. In this paper, we present methodology to measure quality of composite translation service using existing services information and also the guideline for selecting the composition web service which has highest quality of service."
W11-3204,Simple Discriminative Training for Machine Transliteration,2011,13,3,3,1,8038,canasai kruengkrai,Proceedings of the 3rd Named Entities Workshop ({NEWS} 2011),0,"In this paper, we describe our system used in the NEWS 2011 machine transliteration shared task. Our system consists of two main components: simple strategies for generating training examples based on character alignment, and discriminative training based on the Margin Infused Relaxed Algorithm. We submitted results for 10 language pairs on standard runs. Our system achieves the best performance for English-to-Thai and English-to-Hebrew."
sornlertlamvanich-etal-2010-language,Language Resource Management System for {A}sian {W}ord{N}et Collaboration and Its Web Service Application,2010,5,1,1,1,33512,virach sornlertlamvanich,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents the language resource management system for the development and dissemination of Asian WordNet (AWN) and its web service application. We develop the platform to establish a network for the cross language WordNet development. Each node of the network is designed for maintaining the WordNet for a language. Via the table that maps between each language WordNet and the Princeton WordNet (PWN), the Asian WordNet is realized to visualize the cross language WordNet between the Asian languages. We propose a language resource management system, called WordNet Management System (WNMS), as a distributed management system that allows the server to perform the cross language WordNet retrieval, including the fundamental web service applications for editing, visualizing and language processing. The WNMS is implemented on a web service protocol therefore each node can be independently maintained, and the service of each language WordNet can be called directly through the web service API. In case of cross language implementation, the synset ID (or synset offset) defined by PWN is used to determined the linkage between the languages."
W09-3420,{T}hai {W}ord{N}et Construction,2009,6,18,6,0,46895,sareewan thoongsup,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper describes semi-automatic construction of Thai WordNet and the applied method for Asian wordNet. Based on the Princeton WordNet, we develop a method in generating a WordNet by using an existing bi-lingual dictionary. We align the PWN synset to a bilingual dictionary through the English equivalent and its part-of-speech (POS), automatically. Manual translation is also employed after the alignment. We also develop a web-based collaborative workbench, called KUI (Knowledge Unifying Initiator), for revising the result of synset assignment and provide a framework to create Asian WordNet via the linkage through PWN synset."
W09-3421,Query Expansion using {LMF}-Compliant Lexical Resources,2009,8,4,6,0,301,takenobu tokunaga,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"This paper reports prototype multilingual query expansion system relying on LMF compliant lexical resources. The system is one of the deliverables of a three-year project aiming at establishing an international standard for language resources which is applicable to Asian languages. Our important contributions to ISO 24613, standard Lexical Markup Framework (LMF) include its robustness to deal with Asian languages, and its applicability to cross-lingual query tasks, as illustrated by the prototype introduced in this paper."
tokunaga-etal-2008-adapting,Adapting International Standard for {A}sian Language Technologies,2008,8,6,9,0,301,takenobu tokunaga,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Corpus-based approaches and statistical approaches have been the main stream of natural language processing research for the past two decades. Language resources play a key role in such approaches, but there is an insufficient amount of language resources in many Asian languages. In this situation, standardisation of language resources would be of great help in developing resources in new languages. This paper presents the latest development efforts of our project which aims at creating a common standard for Asian language resources that is compatible with an international standard. In particular, the paper focuses on i) lexical specification and data categories relevant for building multilingual lexical resources for Asian languages; ii) a core upper-layer ontology needed for ensuring multilingual interoperability and iii) the evaluation platform used to test the entire architectural framework."
tongchim-etal-2008-dependency,A Dependency Parser for {T}hai,2008,16,5,3,1,48449,shisanu tongchim,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper presents some preliminary results of our dependency parser for Thai. It is part of an ongoing project in developing a syntactically annotated Thai corpus. The parser has been trained and tested by using the complete part of the corpus. The parser achieves 83.64{\%} as the root accuracy, 78.54{\%} as the dependency accuracy and 53.90{\%} as the complete sentence accuracy. The trained parser will be used as a preprocessing step in our corpus annotation workflow in order to accelerate the corpus development."
I08-7020,Enhanced Tools for Online Collaborative Language Resource Development,2008,0,0,1,1,33512,virach sornlertlamvanich,Proceedings of the 6th Workshop on {A}sian Language Resources,0,"This paper reports our recent work of tool development for language resource construction. To make a revision of Asian WordNet which is automatically generated by using the existing English translation dictionary, we propose an online collaborative tool which can organize multiple translations. To support the work of syntactic dependency tree annotation, we develop an editing suite which integrates the utilities for word segmentation, POS tagging and dependency tree into a sequence of editing."
I08-3002,Invited Talk: Cross Language Resource Sharing,2008,0,0,1,1,33512,virach sornlertlamvanich,Proceedings of the {IJCNLP}-08 Workshop on {NLP} for Less Privileged Languages,0,None
I08-3005,{KUI}: an ubiquitous tool for collective intelligence development,2008,2,2,2,1,42113,thatsanee charoenporn,Proceedings of the {IJCNLP}-08 Workshop on {NLP} for Less Privileged Languages,0,"Collective intelligence is the capability for a group of people to collaborate in order to achieve goals in a complex context than its individual member. This common concept increases topic of interest in many sciences including computer science where computers are bring about as group support elements. This paper presents a new platform, called Knowledge Unifying Initiator (KUI) for knowledge development which enables connection and collaboration among individual intelligence in order to accomplish a complex mission. KUI is a platform to unify the various thoughts following the process of thinking, i.e., initiating the topic of interest, collecting the opinions to the selected topics, localizing the opinions through the translation or customization and posting for public hearing to conceptualize the knowledge. The process of thinking is done under the selectional preference simulated by voting mechanism in case that many alternatives occur. By measuring the history of participation of each member, KUI adaptively manages the reliability of each memberxe2x80x99s opinion and vote according to the estimated ExpertScore."
I08-2091,Synset Assignment for Bi-lingual Dictionary with Limited Resource,2008,5,6,1,1,33512,virach sornlertlamvanich,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper explores an automatic WordNet synset assignment to the bi-lingual dictionaries of languages having limited lexicon information. Generally, a term in a bilingual dictionary is provided with very limited information such as part-of-speech, a set of synonyms, and a set of English equivalents. This type of dictionary is comparatively reliable and can be found in an electronic form from various publishers. In this paper, we propose an algorithm for applying a set of criteria to assign a synset with an appropriate degree of confidence to the existing bi-lingual dictionary. We show the efficiency in nominating the synset candidate by using the most common lexical information. The algorithm is evaluated against the implementation of ThaiEnglish, Indonesian-English, and Mongolian-English bi-lingual dictionaries. The experiment also shows the effectiveness of using the same type of dictionary from different sources."
I08-1052,Constructing Taxonomy of Numerative Classifiers for {A}sian Languages,2008,5,9,6,0,29633,kiyoaki shirai,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"Numerative classifiers are ubiquitous in many Asian languages. This paper proposes a method to construct a taxonomy of numerative classifiers based on a nounclassifier agreement database. The taxonomy defines superordinate-subordinate relation among numerative classifiers and represents the relations in tree structures. The experiments to construct taxonomies were conducted for evaluation by using data from three different languages: Chinese, Japanese and Thai. We found that our method was promising for Chinese and Japanese, but inappropriate for Thai. It confirms that there really is no hierarchy among Thai classifiers."
C08-2031,Experiments in Base-{NP} Chunking and Its Role in Dependency Parsing for {T}hai,2008,9,0,2,1,48449,shisanu tongchim,Coling 2008: Companion volume: Posters,0,"This paper studies the role of base-NP information in dependency parsing for Thai. The baseline performance reveals that the base-NP chunking task for Thai is much more difficult than those of some languages (like English). The results show that the parsing performance can be improved (from 60.30% to 63.74%) with the use of base-NP chunk information, although the best chunker is still far from perfect (Fxefxbfxbd=1 = 83.06%)."
P06-2106,Infrastructure for Standardization of {A}sian Language Resources,2006,10,18,2,0,301,takenobu tokunaga,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"As an area of great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least three strong advantages: to increase the competitive edge of Asian countries, to bring Asian countries to closer to their western counterparts, and to bring more cohesion among Asian countries. To achieve this goal, we have launched a two year project to create a common standard for Asian language resources. The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upper-layer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach."
tongchim-etal-2006-blind,Blind Evaluation for {T}hai Search Engines,2006,8,0,3,1,48449,shisanu tongchim,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper compares the effectiveness of two different Thai search engines by using a blind evaluation. The probabilistic-based dictionary-less search engine is evaluated against the traditional word-based indexing method. The web documents from 12 Thai newspaper web sites consisting of 83,453 documents are used as the test collection. The relevance judgment is conducted on the first five returned results from each system. The evaluation process is completely blind. That is, the retrieved documents from both systems are shown to the judges without any information about thesearch techniques. Statistical testing shows that the dictionary-less approach is better than the word-based indexingapproach in terms of the number of found documents and the number of relevance documents."
kruengkrai-etal-2006-conditional,A Conditional Random Field Framework for {T}hai Morphological Analysis,2006,14,27,2,1,8038,canasai kruengkrai,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents a framework for Thai morphological analysis based on the theoretical background of conditional random fields. We formulate morphological analysis of an unsegmented language as the sequential supervised learning problem. Given a sequence of characters, all possibilities of word/tag segmentation are generated, and then the optimal path is selected with some criterion. We examine two different techniques, including the Viterbi score and the confidence estimation. Preliminary results are given to show the feasibility of our proposed framework."
charoenporn-etal-2006-word,Word Knowledge Acquisition for Computational Lexicon Construction,2006,8,0,4,1,42113,thatsanee charoenporn,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The growing of multilingual information processing technology has created the need of linguistic resources, especially lexical database. Many attempts were put to alter the traditional dictionary to computational dictionary, or widely named as computational lexicon. TCLÂs Computational Lexicon (TCLLEX) is a recent development of a large-scale Thai Lexicon, which aims to serve as a fundamental linguistic resource for natural language processing research. We design either terminology or ontology for structuring the lexicon based on the idea of computability and reusability."
U05-1003,From Non-segmenting Language Processing to Web Language Engineering,2005,-1,-1,1,1,33512,virach sornlertlamvanich,Proceedings of the Australasian Language Technology Workshop 2005,0,None
I05-1031,Analysis of an Iterative Algorithm for Term-Based Ontology Alignment,2005,11,1,3,1,48449,shisanu tongchim,Second International Joint Conference on Natural Language Processing: Full Papers,0,"This paper analyzes the results of automatic concept alignment between two ontologies. We use an iterative algorithm to perform concept alignment. The algorithm uses the similarity of shared terms in order to find the most appropriate target concept for a particular source concept. The results show that the proposed algorithm not only finds the relation between the target concepts and the source concepts, but the algorithm also shows some flaws in the ontologies. These results can be used to improve the correctness of the ontologies."
charoenporn-etal-2004-open,Open Collaborative Development of the {T}hai Language Resources for Natural Language Processing,2004,5,0,2,1,42113,thatsanee charoenporn,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Language Resources are recognized as an essential component in linguistic infrastructure and a starting point of Natural Language Processing systems and applications. In this paper, we describe the achievement of the development and the use of Thai Language Resources germinated with an open collaboration platform, under the collaboration between research institutes. The resources include either text or speech. Text resources are divided into lexicon database and annotated corpus. We started developing a corpus-based Thai-English lexicon database (LEXiTRON) since 1994. It was originated from a dictionary designed for using in developing a machine translation system. Since then the Thai POS was designed and evaluated in several applications (word segmentation, machine translation, grapheme-to-phoneme, etc.) Extending the lexicon database, POS tagged corpus (ORCHID), and speech corpora for both synthesis and recognition are developed and functioned as an important part of research and development on NLP or HLT. These language resources are available for academic experiment."
kruengkrai-etal-2004-enriching,Enriching a {T}hai Lexical Database with Selectional Preferences,2004,10,0,3,1,8038,canasai kruengkrai,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"A statistical corpus-based approach for acquiring selectional preferences of verbs is proposed. By parsing through text corpora, we obtain examples of context nouns that are considered to be the selectional preferences of a given verb. The approach is to generalize initial noun classes to the most appropriate levels on a semantic hierarchy. We present an iterative algorithm for generalization by combining an agglomerative merging and a model selection technique called the Bayesian Information Criterion (BIC). In our experiments, we consider the Web as the large corpora. We also propose approaches for extracting examples from the Web. Preliminarily experimental results are given to show the feasibility and effectiveness of our approach."
N03-2035,A Context-Sensitive Homograph Disambiguation in {T}hai Text-to-Speech Synthesis,2003,10,15,3,0,52895,virongrong tesprasit,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Short Papers,0,"Homograph ambiguity is an original issue in Text-to-Speech (TTS). To disambiguate homograph, several efficient approaches have been proposed such as part-of-speech (POS) n-gram, Bayesian classifier, decision tree, and Bayesian-hybrid approaches. These methods need words or/and POS tags surrounding the question homographs in disambiguation. Some languages such as Thai, Chinese, and Japanese have no word-boundary delimiter. Therefore before solving homograph ambiguity, we need to identify word boundaries. In this paper, we propose a unique framework that solves both word segmentation and homograph ambiguity problems altogether. Our model employs both local and long-distance contexts, which are automatically extracted by a machine learning technique called Winnow."
W02-1605,Improving Translation Quality of Rule-based Machine Translation,2002,10,19,2,1,47315,paisarn charoenpornsawat,{COLING}-02: Machine Translation in Asia,0,"This paper proposes machine learning techniques, which help disambiguate word meaning. These methods focus on considering the relationship between a word and its surroundings, described as context information in the paper. Context information is produced from rule-based translation such as part-of-speech tags, semantic concept, case relations and so on. To automatically extract the context information, we apply machine learning algorithms which are C4.5, C4.5rule and RIPPER. In this paper, we test on ParSit, which is an interlingual-based machine translation for English to Thai. To evaluate our approach, an verb-to-be is selected because it has increased in frequency and it is quite difficult to be translated into Thai by using only linguistic rules. The result shows that the accuracy of C4.5, C4.5rule and RIPPER are 77.7%, 73.1% and 76.1% respectively whereas ParSit give accuracy only 48%."
W02-1612,A Cross System Machine Translation,2002,2,3,2,0,317,thepchai supnithi,{COLING}-02: Machine Translation in Asia,0,"The rapid growth of Internet Technology, especially user friendliness approach, helps increase the number of Internet users and the amount of information in the cyberspace. There is a countless amount of information in languages. This has spread developments of MT systems. The focus of our approach is to increase the reusability of those MT systems by using Cross System machine translation. Using natural language as an intermediate language, such as English, will help us use the information in Internet qualitatively. In this paper, we point out some problems that may cause the efficiency to decrease when a sentence is translated from a second language to a third language. A novel method is proposed to solve this problem."
H01-1070,Towards an Intelligent Multilingual Keyboard System,2001,8,14,2,0,53996,tanapong potipiti,Proceedings of the First International Conference on Human Language Technology Research,0,This paper proposes a practical approach employing n-gram models and error-correction rules for Thai key prediction and Thai-English language identification. The paper also proposes rule-reduction algorithm applying mutual information to reduce the error-correction rules. Our algorithm reported more than 99% accuracy in both language identification and key prediction.
P00-1078,Panel: The State of the Art in {T}hai Language Processing,2000,0,1,1,1,33512,virach sornlertlamvanich,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,None
C00-2116,Automatic Corpus-Based {T}hai Word Extraction with the {C}4.5 Learning Algorithm,2000,6,51,1,1,33512,virach sornlertlamvanich,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"Word is difficult to define in the languages that do not exhibit explicit word boundary, such as Thai. Traditional methods on defining words for this kind of languages have to depend on human judgement which bases on unclear criteria or procedures, and have several limitations. This paper proposes an algorithm for word extraction from Thai texts without borrowing a hand from word segmentation. We employ the c4.5 learning algorithm for this task. Several attributes such as string length, frequency, mutual information and entropy are chosen for word/non-word determination. Our experiment yields high precision results about 85% in both training and test corpus."
1997.iwpt-1.16,A New Formalization of Probabilistic {GLR} Parsing,1997,-1,-1,2,0,55795,kentaro unui,Proceedings of the Fifth International Workshop on Parsing Technologies,0,"This paper presents a new formalization of probabilistic GLR language modeling for statistical parsing. Our model inherits its essential features from Briscoe and Carroll{'}s generalized probabilistic LR model, which obtains context-sensitivity by assigning a probability to each LR parsing action according to its left and right context. Briscoe and Carroll{'}s model, however, has a drawback in that it is not formalized in any probabilistically well-founded way, which may degrade its parsing performance. Our formulation overcomes this drawback with a few significant refinements, while maintaining all the advantages of Briscoe and Carroll{'}s modeling."
C96-2208,The Automatic Extraction of Open Compounds from Text Corpora,1996,4,11,1,1,33512,virach sornlertlamvanich,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"This paper describes a new method for extracting open compounds (uninterrupted sequences of words) from text corpora of languages, such as Thai, Japanese and Korea that exhibit unexplicit word segmentation. Without applying word segmentation techniques to the inputted plain text, we generate n-gram data from it. We then count the occurence of each string and sort them in alphabetical order. It is significant that the frequency of occurrence of strings decreases when the window size of observation is extended. From the statistical point of view, a word is a string with a fixed pattern that is used repeatedly, meaning that it should occur with a higher frequency than a string that is not a word. We observe the variation of frequency of the sorted n-gram data and extract the strings that experience a significant change in frequency of occurrence when their length is extended. We apply this occurrence test to both the right and left hand sides of all strings to ensure the accurate detection of both boundaries of the string. The method returned satisfying results regardless of the size of the input file."
C94-1091,Classifier Assignment by Corpus-Based Approach,1994,3,15,1,1,33512,virach sornlertlamvanich,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper presents an algorithm for selecting an appropriate classifier word for a noun. In Thai language, it frequently happens that there is fluctuation in the choice of classifier for a given concrete noun, both from the point of view of the whole speech community and individual speakers. Basically, there is no exact rule for classifier selection. As far as we can do in the rule-based approach is to give a default rule to pick up a corresponding classifier of each noun. Registration of classifier for each noun is limited to the type of unit classifier because other types are open due to the meaning of representation. We propose a corpus-based method (Biber, 1993; Nagao, 1993; Smadja, 1993) which generates Noun Classifier Associations (NCA) to overcome the problems in classifier assignment and semantic construction of noun phrase. The NCA is created statistically from a large corpus and recomposed under concept hierarchy constraints and frequency of occurrences."
