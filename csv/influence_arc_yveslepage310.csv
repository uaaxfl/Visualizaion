2005.iwslt-1.4,W02-2125,0,0.0291852,"rtional analogy, to process any sentence of any language. The third section explains in detail the algorithm used to solve proportional analogies, while the fourth section shows its use as a blackbox function to perform translation. The fifth section recalls the experimental conditions of the Unrestricted Data track of IWSLT 2004, gives the configuration details for the ALEPH system and ranks it among the participants of IWSLT 2004. The sixth section gives the results of this year’s campaign. The final section discusses the results obtained and future research. 2. Divergences across languages [1] quotes a study on a sample of 19, 000 sentences between English and Spanish showing that one translation pair in three presents divergences. A typical example is the translation of a Spanish verb into an English preposition. 1: Atraves´o V 2: el r´ıo N 3: flotando particip. ↔ 0: 3: 1: 2: It floated V across prep. the river N Approaches that rely on the word as the unit of processing forget the fact that corresponding pieces of information in different languages are indeed distributed over the entire strings and do not necessarily correspond to complete words. For this reason, the corresponden"
2005.iwslt-1.4,lepage-peralta-2004-using,1,0.767045,"in the Saussurian sense of the term. This systematicity appears at best in commutations exhibited by proportional analogies like in the following examples. Obviously, any sentence of any language can be cast into a wide number of such proportional analogies, like the following ones: They It floated They swam :: It floated : across the swam in : across the in the sea. river. the sea. river. It floated It floats It walks It walked across the : across the :: across the : across the river. river. street. street. It swam It floated He swam. : He floated. :: across the : across the river. river. In [2] we have shown how to automatically build tables (or matrices) to visualize the many proportional analogies that can be found in the same resource around a given sentence: in such tables, each cell contains a sentence, and rectangles of four cells constitute proportional analogies. Such proportional analogies reveal the paradigmatic and syntagmatic variations around a given sentence. From a bilingual point of view, proportional analogies neutralize translation divergences across languages. They leave the choice for a correct translation to an implicit use of the structure of the target languag"
2005.iwslt-1.4,2004.iwslt-evaluation.1,0,0.0517085,"Missing"
2005.iwslt-1.4,P98-1120,1,\N,Missing
2005.iwslt-1.4,C98-1116,1,\N,Missing
2005.mtsummit-ebmt.11,J93-2003,0,0.00655733,"Missing"
2005.mtsummit-ebmt.11,W98-1230,0,0.0378819,"Missing"
2005.mtsummit-ebmt.11,W02-2125,0,0.0261153,"linguistic resource so as to visualize these meshworks: each cell in a table contains a sentence, and rectangles formed with four cells in the tables are proportional analogies. 1.2 Dealing with divergences across languages Machine translation has specific problems to address: one of them, at the core of translation, is to tackle divergences across languages. A classical and simple example of divergence is the exchange of the arguments of a predicate in Vauquois’s famous example between English and French: Elle 1 lui 2 plaˆıt. ↔ He 2 likes her 1 . To confirm the importance of the phenomenon, (Habash, 2002) quotes a study on a sample of 19, 000 sentences between English and Spanish that shows that one sentence in three presents divergences that can be classified into five different types. An example of type 4 is the classical translation of a Spanish verb into an English preposition. 1: Atraves´ oV 2: el r´ıo N 3: flotando particip. ↔ 0: 3: 1: 2: It floated V across prep. the river N I’d like Could I’d like to cash Could you cash to open you open :: these : a travthese : trava eler’s wineler’s window? check? dows. checks. l l l l Ces Vous Est-ce Est-ce ch`eques pouvez que ces que vous de m’´echa"
2005.mtsummit-ebmt.11,lepage-peralta-2004-using,1,0.884057,"Missing"
2005.mtsummit-ebmt.11,P98-1120,1,0.673844,"tional analogy. There exist four translation relations between the sentences. 2.3 A geometric view of the principle The processing of the previous example, which is reminiscent of distributionalism (Harris, 1954), can be viewed in the shape of a parallelopiped as shown in Figure 2. The left plane of this parallelopiped is the plane of the English analogy. The right plane is the Japanese one. Because each of these planes resides in one and only one language, the terms of the proportional analogy involve monolingual data only so that they can be processed by algorithms like the one proposed in (Lepage, 1998). 3 3.1 Features of the method No transfer To stress that the choice of a correct translation is really left to an implicit use of the structure of the target language, and does not imply any explicit transfer processing, consider the Spanish example of Section 1.2 again. The correspondences between the source and the target language in a proportional analogy will be entirely responsible not only for the selection of the correct lemmas wit their lexical POS, but also for the correct word order7 . This could be compared to some extent to the translation of the adnominal particle N 1 no N2 from"
2005.mtsummit-ebmt.11,C04-1106,1,0.638883,"Missing"
2005.mtsummit-ebmt.11,P91-1024,0,0.127754,"Missing"
2006.iwslt-evaluation.12,C02-1076,1,0.827325,"ntactic transfer; and EM by exact match. For the OPEN track, only TATR was used; for the CSTAR track, a hybrid system using three engines and Selector was used. See Figure 1. 5.4. Selector 5.1. TATR In order to select the best translation among outputs generated by multiple MT systems, we employ an SMT-based method that scores MT outputs by using multiple language (LM) and translation model (TM) pairs trained on different subsets of the training data. It uses a statistical test to check whether the obtained TM·LM scores of one MT output are significantly higher than those of another MT output [9]. Given an input sentence, m translation hypotheses are produced by the component MT engines (m = 1 for this evaluation), whereby n different TM·LM scores are assigned to each hypothesis. In order to check whether the highest scoring hypothesis is significantly better then the other MT outputs, a multiple comparison test based on the Kruskal-Wallis test is used [10]. If one of the MT outputs is significantly better, this output is selected. Otherwise, the output of the MT engine that performs best on a development set is selected. TATR is a phrase-based SMT system built within the framework of"
2006.iwslt-evaluation.12,J03-1002,0,0.0511227,"Missing"
2006.iwslt-evaluation.12,2006.iwslt-evaluation.15,0,0.0505268,"Missing"
2006.iwslt-evaluation.12,2005.mtsummit-papers.35,1,0.807212,"Missing"
2006.iwslt-evaluation.12,2005.iwslt-1.5,1,0.8833,"Missing"
2006.iwslt-evaluation.12,N06-2049,1,0.870022,"ation. Our main translation engine for this year’s IWSLT evaluation, TATR, is also a phrase-based SMT. The hybrid multiple engine approach, that was used last year [1], was used again this year. But we replaced the 2005 SMTs (PBHMTM and SAT) with TATR, partly for simplification reasons. In addition to TATR, two other engines are included in this year’s hybrid system: HPATR3, a SMT based on syntactic transfer; and EM, the translation memory based on exact match. We employed new approaches for pre-processing, postprocessing, and language modeling. We used subword-based Chinese word segmentation [2]. This word segmentation achieved the highest F-score rate for the second Sighan test data, and can recognize numerical expressions and foreign names. We built a conversion model to implement capitalization and punctuation by using the maximum entropy principle and the conditional random field (CRF) approach, which can integrate long-range features to enhance performance. We applied sentence-splitting techniques to all languages. This approach significantly improved CE and JE translation. 2. Preprocessing 2.1. Arabic segmentation Of the released data, we threw away all end-of-utterance markers"
2006.iwslt-evaluation.12,N06-2013,0,\N,Missing
2006.jeptalnrecital-tutoriel.1,C96-1046,0,0.0406433,"Missing"
2006.jeptalnrecital-tutoriel.1,2001.jeptalnrecital-long.20,0,0.0968795,"Missing"
2006.jeptalnrecital-tutoriel.1,C00-1071,1,0.868291,"Missing"
2006.jeptalnrecital-tutoriel.1,C04-1106,1,0.866167,"Missing"
2006.jeptalnrecital-tutoriel.1,I05-5008,1,0.838813,"Missing"
2006.jeptalnrecital-tutoriel.1,lepage-peralta-2004-using,1,0.787496,"Missing"
2006.jeptalnrecital-tutoriel.1,takezawa-etal-2002-toward,0,0.0315033,"Missing"
2007.iwslt-1.7,2007.mtsummit-papers.19,0,0.227782,"e type of the data provided led to different preprocessing methods. For Japanese, the data provided a segmentation into words for each utterance. Such a segmentation seems to have been performed by ChaSen.2 Standard Japanese usually does not insert any space between words. We could thus compute a dictionary of words for both the training set and the test set. The counts are to be found in Table 1. We also performed an experiment in specifically translating unknown words from Japanese into English with the set of words from the training set. This kind of experiment has been reported in [5] and [6]. As a result, we could correctly generate half 2 http://chasen.naist.jp/hiki/ChaSen/. of them (18 words out of 35). As for the chunking method, it is based on markers. Indeed, Japanese is a language with case markers, a closed set of words (or morphemes) appearing at the end of chunks. Our list of markers consisted of eight nominal case markers, one verbal ending and one punctuation mark.3 Some data concerning the number of chunks obtained as well as sequences of chunks for the Japanese training data are given in Table 2. The case of Arabic is still different from English and Japanese. The Ar"
2007.iwslt-1.7,2005.iwslt-1.1,0,\N,Missing
2007.iwslt-1.7,2005.iwslt-1.4,1,\N,Missing
2008.amta-papers.11,P06-2035,0,0.126478,"Missing"
2008.amta-papers.11,N03-1017,0,0.111509,"ty multi-word alignments from sentence-aligned multilingual parallel corpora. The method can handle several languages at once. The phrase tables obtained by the method have a comparable accuracy and a higher coverage than those obtained by current methods. They are also obtained much faster. 1 Introduction Alignment is an important task in natural language processing for a variety of purposes like the constitution of lexical resources, machine translation or cross-lingual information retrieval. In the case of machine translation, alignment serves as a starting point to generate phrase tables (Koehn et al., 2003), which are the primary source of knowledge for most data-driven machine translation systems. Several alignment tools are freely available today. Among them, the bilingual phrase aligner Giza++ (Och and Ney, 2003) can perform high quality alignments based on words statistics. It is considered the most efficient tool. Some criticisms may however be addressed to this kind of tool. Firstly, numerous parameters have to be tuned in order to optimize the results for a particular alignment task, which can be very time consuming. This is all the more important when multilingual alignment is concerned,"
2008.amta-papers.11,W02-1018,0,0.0311262,"n a complexity explosion when multilingual alignments are needed. Giguet and Luquet (2006) report alignments in 20 languages, but only pairs between English and 19 other European languages are considered. Simard (1999) showed how to adapt a bilingual method to align more than two versions of a text at the sentence level, but this requires to identify first which of the language pairs are the most “similar”: languages still require to be processed by pairs. We propose an approach that differs from all previous techniques. It is intended to be multilingual, fast, simple, yet accurate. Following Marcu and Wong (2002), phrase alignments can directly be obtained without any intermediate word alignment step. And more generally, any sequence of words can be obtained. The method relies on simple heuristics based on similarities and differences between sentences, such as used by Cicekli (2000). The paper is organized as follows. Section 2 gives an overview of the basic concepts used in the proposed multilingual alignment technique. Section 3 describes the technique in more details. Section 4 shows some alignment results on actual data. Section 5 elaborates on some possible optimization. Section 6 compares the m"
2008.amta-papers.11,H05-1011,0,0.0252434,"ms. Several alignment tools are freely available today. Among them, the bilingual phrase aligner Giza++ (Och and Ney, 2003) can perform high quality alignments based on words statistics. It is considered the most efficient tool. Some criticisms may however be addressed to this kind of tool. Firstly, numerous parameters have to be tuned in order to optimize the results for a particular alignment task, which can be very time consuming. This is all the more important when multilingual alignment is concerned, since every language pair will require its own set of parameter values. For this reason, Moore (2005) proposes an alternative to 125 Secondly, freely available tools cannot align a large number of languages simultaneously. They can only handle pairs of languages. This results in a complexity explosion when multilingual alignments are needed. Giguet and Luquet (2006) report alignments in 20 languages, but only pairs between English and 19 other European languages are considered. Simard (1999) showed how to adapt a bilingual method to align more than two versions of a text at the sentence level, but this requires to identify first which of the language pairs are the most “similar”: languages st"
2008.amta-papers.11,J03-1002,0,0.00377049,"ge than those obtained by current methods. They are also obtained much faster. 1 Introduction Alignment is an important task in natural language processing for a variety of purposes like the constitution of lexical resources, machine translation or cross-lingual information retrieval. In the case of machine translation, alignment serves as a starting point to generate phrase tables (Koehn et al., 2003), which are the primary source of knowledge for most data-driven machine translation systems. Several alignment tools are freely available today. Among them, the bilingual phrase aligner Giza++ (Och and Ney, 2003) can perform high quality alignments based on words statistics. It is considered the most efficient tool. Some criticisms may however be addressed to this kind of tool. Firstly, numerous parameters have to be tuned in order to optimize the results for a particular alignment task, which can be very time consuming. This is all the more important when multilingual alignment is concerned, since every language pair will require its own set of parameter values. For this reason, Moore (2005) proposes an alternative to 125 Secondly, freely available tools cannot align a large number of languages simul"
2008.amta-papers.11,P02-1040,0,0.0811597,"d). The test set consists in roughly 500 Japanese utterences. We use the Moses decoder (Koehn et al., 2007) to perform this experiment. Several runs are performed using phrase tables generated from alignments obtained with different numbers of iterations. Each entry in the phrase tables contains a source and a target sequences of words, as well as two translation probabilities (target to source and source to target). Note that no tuning is performed before translation; more precisely, the same parameter values from a previous tuning is reused for all runs. The evaluation uses the BLEU metric (Papineni et al., 2002). The results are plotted on Figure 6. The more iterations, the higher the score in both cases. The score increases much faster with the hyperbolic distribution. The uniform distribution never reaches the results of the hyperbolic distribution, whatever the number of iterations (even greater than 10,000 — not plotted), although they both tend to the same 131 Figure 6: More iterations lead to better translation quality. Better translations are obtained faster using small sizes of subcorpora. Consequently, a hyperbolic distribution is much more efficient than a uniform one for the choice of the"
2008.amta-papers.11,W99-0602,0,0.120599,"ent task, which can be very time consuming. This is all the more important when multilingual alignment is concerned, since every language pair will require its own set of parameter values. For this reason, Moore (2005) proposes an alternative to 125 Secondly, freely available tools cannot align a large number of languages simultaneously. They can only handle pairs of languages. This results in a complexity explosion when multilingual alignments are needed. Giguet and Luquet (2006) report alignments in 20 languages, but only pairs between English and 19 other European languages are considered. Simard (1999) showed how to adapt a bilingual method to align more than two versions of a text at the sentence level, but this requires to identify first which of the language pairs are the most “similar”: languages still require to be processed by pairs. We propose an approach that differs from all previous techniques. It is intended to be multilingual, fast, simple, yet accurate. Following Marcu and Wong (2002), phrase alignments can directly be obtained without any intermediate word alignment step. And more generally, any sequence of words can be obtained. The method relies on simple heuristics based on"
2008.amta-papers.11,takezawa-etal-2002-toward,0,0.0376711,"od. It is open source and available at http://users.info.unicaen.fr/ ∼alardill/malign/. In the following, iterations are processed sequentially. Execution times are measured on a machine equipped with a 2.2 GHz processor, using the Psyco2 JIT compiler to speed up code execution. 4 Testing the method 4.1 Data used in the subsequent experiments We used the English, Japanese and Arabic training parts of the IWSLT 2007 machine translation campaign corpus (Fordyce, 2007) to conduct our experiments. This is nearly 20,000 triples of aligned sentences from the BTEC (Basic Traveler Expression Corpus) (Takezawa et al., 2002). The corpus has been tokenized and lowercased for the English part. Figure 1 shows an excerpt of the data. 4.2 First experiment: aligning three languages at a time In a first experiment, we set the number of iterations to 100 and use new random sizes of subcorpora at 2 http://psyco.sourceforge.net/ [8th AMTA conference, Hawaii, 21-25 October 2008] ? Aë ©J .K øQk @ éJ . JºÓ AJë Éë ↔ does another bookstore sell it ? ↔ 別 の 書店 で 売っ て ます か 。 ↔ i ’d like a towel . ↔ タオル が 欲しい の です が 。 ↔ to each his own . i ’m having a beer . ↔ 人 それぞれ ね 。 私 は ビール に する 。 /hl hn¯ak mktbh -ahr¯a tby, h¯a ?/ ˘  ¯"
2008.amta-papers.11,2007.iwslt-1.1,0,\N,Missing
2008.amta-papers.11,P07-2045,0,\N,Missing
2008.iwslt-evaluation.5,2005.iwslt-1.4,1,0.935292,"unit on the contrary to previous years where the processing unit used to be the character. The tracks the system participated in are all classic BTEC tracks (Arabic-English, Chinese-English and Chinese-Spanish) plus the so-called PIVOT task, where the test set had to be translated from Chinese into Spanish by way of English. 1. Introduction This paper gives a sketch of the GREYC machine translation system that participated in the IWSLT 2008 evaluation campaign. This system is an on-going effort to re-engineer the ALEPH machine translation system presented at the IWSLT 2005 evaluation campaign [1] in the Python programming language. It incorporates three major changes over the system presented at the IWSLT 2007 evaluation campaign [2]. The system participated in all read speech tasks, i.e., the three BTEC tasks with the following source-target languages: Arabic-English, Chinese-English, Chinese-Spanish, and the PIVOT task where the test set had to be translated from Chinese into Spanish by way of English. In each of these tasks, the translation of two test sets was performed, correct recognition result (CRR in the tables in Section 5) and 1-best output of read speech (ASR.1). The resul"
2008.iwslt-evaluation.5,J03-1002,0,0.00368404,"nglish. In each of these tasks, the translation of two test sets was performed, correct recognition result (CRR in the tables in Section 5) and 1-best output of read speech (ASR.1). The results obtained constitute our primary results and reflect our improvement (or regression for this year) in the development of our example-based MT engine. As for comparison, and so to have an idea of the performance of our system against off-the-shelf tools, we performed translation of all the test sets for the above-mentioned tracks using the two tools listed on the IWSLT 2008 resources - 39 - page,1 Giza++ [3]2 and Moses [4]3 . These results were submitted as our contrast2 result sets. In the same spirit as for our participations in previous evaluation campaigns, we intentionally did not use any data outside of the training data provided by the organizers. This year, this constraint was imposed by the organizers to all participants. In the same vein, and in addition, we stress the fact that we did not either use any data from the development sets for the final runs. In previous experiments and during a previous participation to IWSLT in 2005, the system was shown to be unable to translate in the ab"
2008.iwslt-evaluation.5,P07-2045,0,0.00742794,"of these tasks, the translation of two test sets was performed, correct recognition result (CRR in the tables in Section 5) and 1-best output of read speech (ASR.1). The results obtained constitute our primary results and reflect our improvement (or regression for this year) in the development of our example-based MT engine. As for comparison, and so to have an idea of the performance of our system against off-the-shelf tools, we performed translation of all the test sets for the above-mentioned tracks using the two tools listed on the IWSLT 2008 resources - 39 - page,1 Giza++ [3]2 and Moses [4]3 . These results were submitted as our contrast2 result sets. In the same spirit as for our participations in previous evaluation campaigns, we intentionally did not use any data outside of the training data provided by the organizers. This year, this constraint was imposed by the organizers to all participants. In the same vein, and in addition, we stress the fact that we did not either use any data from the development sets for the final runs. In previous experiments and during a previous participation to IWSLT in 2005, the system was shown to be unable to translate in the absence of suffic"
2008.iwslt-evaluation.5,P98-1120,1,0.742449,"ation of A. There may exist a plurality of solutions for equation (1) as well as for equation (2). This year&apos;s analogy solver is non-deterministic and renders all the solutions in such cases. When no solution at all can be found by analogy, the engine backs off to the basic behavior of a translation memory, i.e., it outputs the translation of the source sentence closest to the input sentence. 4. Three major changes to the MT system 4.1. A non-deterministic analogy-solver Previous versions of the MT system used an analogy solver programmed in C that was extremely fast. It has been described in [8] and [5]. Theoretically, an analogical equation may have no solution, one solution or several solutions. The version implemented in C was programmed in a way such that the first solution encountered by the program, if any, would be the only one outputted. This decision was in a good part responsible for the speed of the program. The analogy solver that we used this year is truly nondeterministic and is a much slower implementation in Python. Proceedings of IWSLT 2008, Hawaii - U.S.A. Table 1: Distribution of the number of solutions according to whether they have no solution, one solution, or m"
2008.iwslt-evaluation.5,N03-1017,0,0.00260305,"LEU scores obtained with Moses using alignment tables obtained with Giza++ and with our method. The first half of development set 3 was used for tuning (253 lines). The second half was used as a test set (253 lines also). 16 references were used for evaluation. BTEC Task Arabic to English Chinese to English Chinese to Spanish Translation tables obtained from Giza++ (IBM model 4) 0.47 0.39 0.28 Our method 0.45 0.37 0.30 over the total number of alignments where Si appears, C(Si ): P (Sj |Si ) = C(Sj , Si ) C(Si ) This is similar to the way Koehn et al. estimate phrase translation probabilities [11]. Consequently, the proposed technique outputs translation tables directly usable by a statistical machine translation software, like Moses. However, our tables contain no lexical weightings. We tested the above-described alignment method against Giza++ on the task of translating half of the development set number 3 that has been released with the training data. Our alignment tables just replaced those alignment tables obtained from Giza++, the next steps for machine translation (training and tuning) being performed using Moses in exactly the same way. The results are given in Table 3 and they"
2008.iwslt-evaluation.5,2005.iwslt-1.1,0,\N,Missing
2008.iwslt-evaluation.5,C98-1116,1,\N,Missing
2008.iwslt-evaluation.5,2007.iwslt-1.7,1,\N,Missing
2009.iwslt-evaluation.6,1983.tc-1.13,0,0.196479,"ranslation tables according to the languages: GIZA++ [4] and anymalign [5]. Preliminary experiments performed with both tools for the three language pairs showed better results with GIZA++ for Arabic and Turkish and with anymalign for Chinese. All these experiments were performed on devset1 and devset2 as they were common to the three tasks. We found 189 unknown hyperwords in Arabic and 134 unknown words in Turkish. These unknown (hyper)words correspond to words that were not found in the translation tables. Following the proposal in [1] and [2] in the general case of machine translation, and [3] for terminology, we conducted experiments to translate unknown (hyper)words in these two languages by analogy. On the contrary to the approach taken in the papers cited above, the technique we used consisted in producing all possible new word pairs (a, a ˆ) in the source and in the target languages from all possible triples of word pairs ((b ↔ ˆb), ˆ using an analogy solver written in Python: (c ↔ cˆ), (d ↔ d)) x : b :: c : d l l l x ˆ : ˆb :: cˆ : dˆ Total 4,852,505 73,997 9,609,402 ⇒x=a l ⇒x ˆ=a ˆ 3.3. Translation tool 3.3.1. “Pure” translation by analogy These analogical equations were sol"
2009.iwslt-evaluation.6,2005.iwslt-1.4,1,0.895064,"at.’ Suppose that the translation process did not succeed in translating the input sentence, but produced, possibly using other text pieces, a translation by analogy for the text ‘the cat.’ On backing-off to a memory translation behavior, the text ‘the cat’ will be found to be the closest one to the input sentence ‘the ruddy cat’ and consequently, the translation corresponding to ‘the cat’ will be output as a hypothesis for the translation of ‘the ruddy cat.’ 3.3.3. One step beyond translation memory The translation tool used in this year departs from the ones used in previous years’ campaign [8, 9, 7] by modifying the approach taken in last years’ campaigns. In last years’ engines, the translation memory behavior was a back-off strategy. This year, the translation memory strategy was made the very starting point of the overall translation process. Starting from an input sentence A the tool first adopts a translation memory behavior: it looks for pairs of sentences B0 ↔ Bˆ0 in the source and the target languages such that B0 is close to A. The proximity criterion is a normalized edit distance with a unit processing of (hyper)words (except for Chinese, where the processing unit is character)"
2009.iwslt-evaluation.6,R09-1040,1,0.854281,"ee languages were not significant. 3. The tools used 3.2. Translation tables 3.1. Morphological synthesizer In the same way as standard phrase-based SMT systems (Pharaoh, Moses or Joshua) need translation tables, the tool we designed specifically for this year campaign also requires translation tables obtained by alignment. In this tool, alignments are used to feed the first part of the fundamental operation at work in the translation tool, in collaboration with a translation memory. We used two different tools to produce translation tables according to the languages: GIZA++ [4] and anymalign [5]. Preliminary experiments performed with both tools for the three language pairs showed better results with GIZA++ for Arabic and Turkish and with anymalign for Chinese. All these experiments were performed on devset1 and devset2 as they were common to the three tasks. We found 189 unknown hyperwords in Arabic and 134 unknown words in Turkish. These unknown (hyper)words correspond to words that were not found in the translation tables. Following the proposal in [1] and [2] in the general case of machine translation, and [3] for terminology, we conducted experiments to translate unknown (hyper)"
2009.iwslt-evaluation.6,D07-1092,0,\N,Missing
2009.iwslt-evaluation.6,J03-1002,0,\N,Missing
2009.iwslt-evaluation.6,2007.iwslt-1.7,1,\N,Missing
2009.iwslt-evaluation.6,2008.iwslt-evaluation.5,1,\N,Missing
2009.jeptalnrecital-demonstration.3,2008.amta-papers.11,1,0.894883,"Missing"
2009.jeptalnrecital-demonstration.3,J03-1002,0,0.0168102,"Missing"
2010.iwslt-evaluation.6,J04-2003,0,0.0212156,"ocus on the case of the Arabic to English translation task, i.e., the BTEC AE track of IWSLT 2010 campaign. Arabic is a language with very rich morphology, the complexity of which challenges machine translation (see [1] for a description of some morphological problems relatively to this task). On the opposite, English morphology is quite poor. It thus makes sense to use the output of an Arabic morphological analyzer to possibly improve a statistical machine translation system. Experiments in using morphological analysis to get improved translation quality have already been reported for German [2] or Turkish [3]. These works used various kinds of segmentation, lemmatization and POS tagging. In the case of Arabic, previous works led to opposite conclusions: on one hand, Lee [4] (affix-stem segmented Arabic) and Habash and Sadat [5] (linguistically informed tokenization) showed that morphological preprocessing may be helpful for statistical machine translation; on the other hand, Diab, Ghoneim and Habash [6] concluded that the use of morphological analysis led to no improvement (for partial vocalization) or even to worse results (with full vocalization). In this paper, we similarly inspe"
2010.iwslt-evaluation.6,2009.iwslt-papers.1,0,0.0144633,"e of the Arabic to English translation task, i.e., the BTEC AE track of IWSLT 2010 campaign. Arabic is a language with very rich morphology, the complexity of which challenges machine translation (see [1] for a description of some morphological problems relatively to this task). On the opposite, English morphology is quite poor. It thus makes sense to use the output of an Arabic morphological analyzer to possibly improve a statistical machine translation system. Experiments in using morphological analysis to get improved translation quality have already been reported for German [2] or Turkish [3]. These works used various kinds of segmentation, lemmatization and POS tagging. In the case of Arabic, previous works led to opposite conclusions: on one hand, Lee [4] (affix-stem segmented Arabic) and Habash and Sadat [5] (linguistically informed tokenization) showed that morphological preprocessing may be helpful for statistical machine translation; on the other hand, Diab, Ghoneim and Habash [6] concluded that the use of morphological analysis led to no improvement (for partial vocalization) or even to worse results (with full vocalization). In this paper, we similarly inspect the use of m"
2010.iwslt-evaluation.6,N04-4015,0,0.0355538,"llenges machine translation (see [1] for a description of some morphological problems relatively to this task). On the opposite, English morphology is quite poor. It thus makes sense to use the output of an Arabic morphological analyzer to possibly improve a statistical machine translation system. Experiments in using morphological analysis to get improved translation quality have already been reported for German [2] or Turkish [3]. These works used various kinds of segmentation, lemmatization and POS tagging. In the case of Arabic, previous works led to opposite conclusions: on one hand, Lee [4] (affix-stem segmented Arabic) and Habash and Sadat [5] (linguistically informed tokenization) showed that morphological preprocessing may be helpful for statistical machine translation; on the other hand, Diab, Ghoneim and Habash [6] concluded that the use of morphological analysis led to no improvement (for partial vocalization) or even to worse results (with full vocalization). In this paper, we similarly inspect the use of morphological analysis as a preprocessing step in Arabic-English statistical machine translation, but we use an in-house morphological analyzer, G-LexAr, and compare its"
2010.iwslt-evaluation.6,N06-2013,0,0.0177807,"of some morphological problems relatively to this task). On the opposite, English morphology is quite poor. It thus makes sense to use the output of an Arabic morphological analyzer to possibly improve a statistical machine translation system. Experiments in using morphological analysis to get improved translation quality have already been reported for German [2] or Turkish [3]. These works used various kinds of segmentation, lemmatization and POS tagging. In the case of Arabic, previous works led to opposite conclusions: on one hand, Lee [4] (affix-stem segmented Arabic) and Habash and Sadat [5] (linguistically informed tokenization) showed that morphological preprocessing may be helpful for statistical machine translation; on the other hand, Diab, Ghoneim and Habash [6] concluded that the use of morphological analysis led to no improvement (for partial vocalization) or even to worse results (with full vocalization). In this paper, we similarly inspect the use of morphological analysis as a preprocessing step in Arabic-English statistical machine translation, but we use an in-house morphological analyzer, G-LexAr, and compare its performance with the well known Buckwalter’s morpholog"
2010.iwslt-evaluation.6,2007.mtsummit-papers.20,0,0.0161813,"er to possibly improve a statistical machine translation system. Experiments in using morphological analysis to get improved translation quality have already been reported for German [2] or Turkish [3]. These works used various kinds of segmentation, lemmatization and POS tagging. In the case of Arabic, previous works led to opposite conclusions: on one hand, Lee [4] (affix-stem segmented Arabic) and Habash and Sadat [5] (linguistically informed tokenization) showed that morphological preprocessing may be helpful for statistical machine translation; on the other hand, Diab, Ghoneim and Habash [6] concluded that the use of morphological analysis led to no improvement (for partial vocalization) or even to worse results (with full vocalization). In this paper, we similarly inspect the use of morphological analysis as a preprocessing step in Arabic-English statistical machine translation, but we use an in-house morphological analyzer, G-LexAr, and compare its performance with the well known Buckwalter’s morphological analyzer (BAMA). As for translation results, our conclusion are similar to those in [6], as the contribution of morphological analysis is negative on the translation task: th"
2010.iwslt-evaluation.6,W04-3250,0,0.0710392,"Missing"
2010.iwslt-evaluation.6,P07-2045,0,\N,Missing
2010.iwslt-evaluation.6,J03-1002,0,\N,Missing
2010.jeptalnrecital-court.3,P05-1074,0,0.0619311,"Missing"
2010.jeptalnrecital-court.3,P01-1008,0,0.0408852,"Missing"
2010.jeptalnrecital-court.3,C08-1013,0,0.0345868,"Missing"
2010.jeptalnrecital-court.3,N06-1003,0,0.0501278,"Missing"
2010.jeptalnrecital-court.3,P09-2063,1,0.794665,"Missing"
2010.jeptalnrecital-court.3,2005.mtsummit-papers.11,0,0.0199463,"Missing"
2010.jeptalnrecital-court.3,2008.jeptalnrecital-long.23,0,0.060257,"Missing"
2010.jeptalnrecital-court.3,I05-5011,0,0.0539082,"Missing"
2010.jeptalnrecital-court.3,P09-1094,0,0.0663892,"Missing"
2011.jeptalnrecital-court.40,2009.iwslt-papers.1,0,0.0246236,"Missing"
2011.jeptalnrecital-court.40,2007.mtsummit-papers.20,0,0.0414174,"Missing"
2011.jeptalnrecital-court.40,N06-2013,0,0.0387327,"Missing"
2011.jeptalnrecital-court.40,W04-3250,0,0.138094,"Missing"
2011.jeptalnrecital-court.40,P07-2045,0,0.00880636,"Missing"
2011.jeptalnrecital-court.40,N04-4015,0,0.0697092,"Missing"
2011.jeptalnrecital-court.40,J04-2003,0,0.0396779,"Missing"
2011.jeptalnrecital-long.25,2007.mtsummit-papers.19,0,0.0775027,"Missing"
2011.jeptalnrecital-long.25,2009.jeptalnrecital-long.1,0,0.0755161,"Missing"
2011.jeptalnrecital-long.25,2005.mtsummit-papers.11,0,0.01414,"Missing"
2011.jeptalnrecital-long.25,D07-1092,0,0.060824,"Missing"
2011.jeptalnrecital-long.25,W03-0416,0,0.0803914,"Missing"
2011.jeptalnrecital-long.25,P09-2088,0,0.0600769,"Missing"
2011.jeptalnrecital-long.25,C08-1114,0,0.0438376,"Missing"
2011.jeptalnrecital-long.36,C94-2178,0,0.340414,"Missing"
2011.jeptalnrecital-long.36,H91-1026,0,0.402571,"Missing"
2011.jeptalnrecital-long.36,W08-0509,0,0.0278544,"Missing"
2011.jeptalnrecital-long.36,2005.mtsummit-papers.11,0,0.0678284,"Missing"
2011.jeptalnrecital-long.36,P07-2045,0,0.00856459,"Missing"
2011.jeptalnrecital-long.36,N03-1017,0,0.0393429,"Missing"
2011.jeptalnrecital-long.36,2008.amta-papers.11,1,0.873477,"Missing"
2011.jeptalnrecital-long.36,R09-1040,1,0.810694,"Missing"
2011.jeptalnrecital-long.36,J00-2004,0,0.0878283,"Missing"
2011.jeptalnrecital-long.36,W05-0801,0,0.0463745,"Missing"
2011.jeptalnrecital-long.36,P02-1040,0,0.0798969,"Missing"
2011.jeptalnrecital-long.36,2006.amta-papers.25,0,0.0980577,"Missing"
2011.jeptalnrecital-long.36,takezawa-etal-2002-toward,0,0.0599455,"Missing"
2011.jeptalnrecital-long.36,W09-3830,0,0.0320763,"Missing"
2011.mtsummit-papers.39,J93-2003,0,0.0205027,"[ it is ] [ impossible to ] [ see why ] [ the resale right should ] [ be imposed on ] [ artists against their will ] [ as a form of ] [ copyright . ] • [ on ne voit pas pourquoi ] [ le droit de ] [ suite doit eˆ tre impos´e comme une forme du ] [ droit d’ ] [ auteur aux artistes , et ] [ ce contre leur volont´e . ] • [ es ist ] [ nicht einzusehen , ] [ warum ] [ das folgerecht als ausformung des urheberrechts ] [ den k¨unstlern gegen ihren willen aufgezwungen werden soll . ] 2.2 Determining Markers by Informativity Gough and Way (2004) use marker-based chunking as a preprocessing step in SMT (Brown et al., 1993) to improve the quality of translation tables and get improved results when combining their chunks with GIZA++/Moses translation table. They deﬁne a list of markers by hand and always cut left for European languages. In contrast with that, we choose to automatically compute the list of markers. Frequency 339 cannot do it: in the Europarl corpus “European” is a frequent word, but cannot be considered as a marker. We rely on some results from information theory and from our experimental results. If a language would be a perfect code, the length of each word would be a function of its number of o"
2011.mtsummit-papers.39,2004.tmi-1.11,0,0.430508,"ed framework. The second part of the paper describes the experiments. Section 5 describes the data that we have used in the experiments and experimental protocol. The conclusion is given in Section 6. 2 Marker-based Chunking Our goal is to segment different languages into subsentential units in a fully automatic way. 2.1 The Marker Hypothesis Chunking is the process by which a sentence is divided into chunks. We use the Marker Hypothesis for chunking. This hypothesis was ﬁrst laid by Green (1979). We do chunking based on this notion and use the method of chunking called marker-based chunking (Gough and Way, 2004; Stroppa and Way, 2006; Van Den Bosch et al., 2007). The Marker Hypothesis states that all natural languages contain a small number of elements that signal the presence of particular syntactic constructions. In this framework, a chunk is a sequence of words delimited by markers, such as determiners (the), conjunctions (and, but, or), prepositions (in, from, to), possessive and personal pronouns (mine, you). A chunk is created at each occurrence of a marker word. In addition, a further constraint requires that each chunk must contain at least one non-marker word. This restriction is very impor"
2011.mtsummit-papers.39,P06-2056,0,0.226546,"is the list of words with the smallest values for the following function: − log C(w) / l(w) Table 1 shows markers obtained in accordance with the above considerations. For example, the tokens with the smallest values of information are “,” and “.” in English, French and German. This is because these two tokens occur very frequently and are very short compared with other words. 2.3 Left or Right Cutting We use the branching entropy to ﬁnd out whether to cut on the left or on the right of a marker. Following the famous intuition by Harris (1955) about branching entropy, Tanaka-Ishii (2005) and Jin and Tanaka-Ishii (2006) have shown how Japanese and Chinese can be segmented into words by formalizing the uncertainty using branching entropy. The entropy of a random variable X with m outcomes xi is deﬁned as its mathematical expectation and is a measure of its overall uncertainty: H(X) = − m  Table 1: The ﬁrst 20 marker words, selected as the ﬁrst 20 least informative words. Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 .. . p(xi ) log p(xi ) i=1 with p(xi ) the probability of the outcome xi . The branching entropy at some position in a text is the entropy of the right context knowing the left context."
2011.mtsummit-papers.39,N03-1017,0,0.0356478,"nguages. A translation probability is computed for each language i (1 ≤ i ≤ L). si is the probability of the sequence of words that it can be computed by the rest of the alignment. C(si ) is the total count of all alignments that si appears and C(s1 , . . . , sL ) is the count of rest of the alignment that C(s1 , . . . , sL ) appear. w(s1 , . . . , si−1 , si+1 , . . . , sL |si ) = 1 C(s1 , . . . , sL ) C(si ) Anymalign is available at http://users.info. unicaen.fr/˜alardill/anymalign/ 3.2 Lexical Weights To validate the quality of a chunk translation pair, we use a lexical weight proposed in (Koehn et al., 2003; Koehn, 2010). Based on the word-to-word translation probability, we can check how much reliable chunk translation pairs are. Following equation is the deﬁnition stated by Koehn et al. (2003). Given a chunk pair f¯, e¯ and a word alignment a between the foreign word positions i = 1, . . . , I and the English word positions j = 0, 1, . . . , J, the lexical weight lex can be computed according to the following formula: lex(f¯|¯ e) = n  i=1  1 w(fi |ej ) |{j|(i, j) ∈ a}| ∀(i,j)∈a As we do not have an alignment at our disposal in our method, we have changed the equation above a little bit. We c"
2011.mtsummit-papers.39,2005.mtsummit-papers.11,0,0.0278065,"tter the translation outputs are expected to be. A similar experiment has been done in (Takeya et al., 2011). Figure 1(a) plots the number of analogies between sentences for different numbers of sentences. The maximum number of analogies is 474 for Danish for 100,000 sentences. In comparison with Figure 1(a), Figure 1(b) plots the number of analogies between chunks extracted from 10 to 1,000 sentences using 50 markers. After some 1,000 sentences, the number of analogies increases to more than 1,000 to 45,000 analogies ,however , with much variation. 5.1 Experiments We use the Europarl corpus (Koehn, 2005). It is a collection of proceedings of the European Parliament. The corpus comprises of about 10 million words for each of 11 ofﬁcial languages of the European Union: Danish (da), German (de), Greek (el), English (en), Spanish (es), Finnish (ﬁ), French (fr), Italian (it), Dutch (nl), Portuguese (pt) and Swedish (sv). Since the corpus is not exactly aligned, we aligned 11 languages properly. This gives about 13,000 words in each of the 11 languages for more than 380,000 utterances. Precise statistics are given in Table 2. 342 8 7 6 5 4 3 1 0 50 100 150 200 250 300 Number of markers Figure 2: Av"
2011.mtsummit-papers.39,J10-4005,0,0.0452361,"on probability is computed for each language i (1 ≤ i ≤ L). si is the probability of the sequence of words that it can be computed by the rest of the alignment. C(si ) is the total count of all alignments that si appears and C(s1 , . . . , sL ) is the count of rest of the alignment that C(s1 , . . . , sL ) appear. w(s1 , . . . , si−1 , si+1 , . . . , sL |si ) = 1 C(s1 , . . . , sL ) C(si ) Anymalign is available at http://users.info. unicaen.fr/˜alardill/anymalign/ 3.2 Lexical Weights To validate the quality of a chunk translation pair, we use a lexical weight proposed in (Koehn et al., 2003; Koehn, 2010). Based on the word-to-word translation probability, we can check how much reliable chunk translation pairs are. Following equation is the deﬁnition stated by Koehn et al. (2003). Given a chunk pair f¯, e¯ and a word alignment a between the foreign word positions i = 1, . . . , I and the English word positions j = 0, 1, . . . , J, the lexical weight lex can be computed according to the following formula: lex(f¯|¯ e) = n  i=1  1 w(fi |ej ) |{j|(i, j) ∈ a}| ∀(i,j)∈a As we do not have an alignment at our disposal in our method, we have changed the equation above a little bit. We compute the ari"
2011.mtsummit-papers.39,R09-1040,1,0.901809,"Missing"
2011.mtsummit-papers.39,lardilleux-etal-2010-bilingual,1,0.897813,"Missing"
2011.mtsummit-papers.39,P98-1120,1,0.670312,"gn language over all the English words: lex(f1I |eJ1 ) = I  i=1 4 ⎞ J  ⎝1 w(fi |ej )⎠ J ⎛ j=1 The Analogy-based Framework of Translation 4.1 Analogy In this work, we use the notion of analogy formed in (Lepage, 2004). Between strings of characters, an analogy A : B :: C : D means that “A is to B as C is to D”. Saussure (1955) (Part III, Chap. 5) applied on words, solving analogical equations as a typically synchronic operation by which, given two forms of a given word, and only one form of a second word, the fourth missing form is coined. relate : unrelated :: modulate : x ⇒ x = ummodulated Lepage (1998) gives an efﬁcient algorithm for the resolution of analogical equations. The algorithm is based on the following formalisation of analogies in terms of edit distances, or equivalently, in terms of similarity. From the programming point of view, the formalization reduces to the counting of number of symbol occurrences and the computation of edit distances. 341 We denote d(A, B) as the distance between strings A and B. We also denote |A|a as the number of occurrences of character a in string A and |A |as the length of A. ⎧ d(B, D) = d(A, C) ⎪ ⎪ ⎨ d(C, D) = d(A, B) A : B :: C : D ⇒ ⎪ ⎪ ⎩ |A|a + |"
2011.mtsummit-papers.39,2006.iwslt-evaluation.4,0,0.350938,"ond part of the paper describes the experiments. Section 5 describes the data that we have used in the experiments and experimental protocol. The conclusion is given in Section 6. 2 Marker-based Chunking Our goal is to segment different languages into subsentential units in a fully automatic way. 2.1 The Marker Hypothesis Chunking is the process by which a sentence is divided into chunks. We use the Marker Hypothesis for chunking. This hypothesis was ﬁrst laid by Green (1979). We do chunking based on this notion and use the method of chunking called marker-based chunking (Gough and Way, 2004; Stroppa and Way, 2006; Van Den Bosch et al., 2007). The Marker Hypothesis states that all natural languages contain a small number of elements that signal the presence of particular syntactic constructions. In this framework, a chunk is a sequence of words delimited by markers, such as determiners (the), conjunctions (and, but, or), prepositions (in, from, to), possessive and personal pronouns (mine, you). A chunk is created at each occurrence of a marker word. In addition, a further constraint requires that each chunk must contain at least one non-marker word. This restriction is very important to create chunks."
2011.mtsummit-papers.39,Y11-1061,1,0.390347,"sh Finnish French Italian Dutch Portuguese Swedish 200 100 30000 20000 10000 0 0 0 20000 40000 60000 80000 100000 0 200 Number of sentences 400 600 800 1000 Number of sentences (a) Analogies between sentences. (b) Analogies between chunks. Figure 1: Number of analogies between sentences and chunks. 11 Average number of chunks in each sentence Its solution is a candidate translation of the source  = “un gros programme et” chunk: D For such an EBMT system to work well, the more numerous the analogies, the better the translation outputs are expected to be. A similar experiment has been done in (Takeya et al., 2011). Figure 1(a) plots the number of analogies between sentences for different numbers of sentences. The maximum number of analogies is 474 for Danish for 100,000 sentences. In comparison with Figure 1(a), Figure 1(b) plots the number of analogies between chunks extracted from 10 to 1,000 sentences using 50 markers. After some 1,000 sentences, the number of analogies increases to more than 1,000 to 45,000 analogies ,however , with much variation. 5.1 Experiments We use the Europarl corpus (Koehn, 2005). It is a collection of proceedings of the European Parliament. The corpus comprises of about 10"
2011.mtsummit-papers.39,I05-1009,0,0.380748,"e list of markers we use is the list of words with the smallest values for the following function: − log C(w) / l(w) Table 1 shows markers obtained in accordance with the above considerations. For example, the tokens with the smallest values of information are “,” and “.” in English, French and German. This is because these two tokens occur very frequently and are very short compared with other words. 2.3 Left or Right Cutting We use the branching entropy to ﬁnd out whether to cut on the left or on the right of a marker. Following the famous intuition by Harris (1955) about branching entropy, Tanaka-Ishii (2005) and Jin and Tanaka-Ishii (2006) have shown how Japanese and Chinese can be segmented into words by formalizing the uncertainty using branching entropy. The entropy of a random variable X with m outcomes xi is deﬁned as its mathematical expectation and is a measure of its overall uncertainty: H(X) = − m  Table 1: The ﬁrst 20 marker words, selected as the ﬁrst 20 least informative words. Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 .. . p(xi ) log p(xi ) i=1 with p(xi ) the probability of the outcome xi . The branching entropy at some position in a text is the entropy of the right c"
2012.eamt-1.62,P06-1002,0,0.0892244,"Missing"
2012.eamt-1.62,C88-1016,0,0.340863,"a certain number of scores loosely reflecting the likelihood that source translates to target. The problem of identifying sub-sentential mappings from parallel texts, e.g. between isolated words or n-grams of words, is well-known, and numerous proposals have been put forward to perform this task. Those methods roughly fall into two main c 2012 European Association for Machine Translation. this context, a phrase is a sequence of words and does not necessarily correspond to a syntactic phrase. 1 In 279 yves.lepage@waseda.jp categories. On the one hand, the probabilistic approach, introduced by Brown et al. (1988), considers the problem of identifying links between words or groups of words in parallel sentences. This approach consists in defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an imp"
2012.eamt-1.62,J93-2003,0,0.245932,". On the one hand, the probabilistic approach, introduced by Brown et al. (1988), considers the problem of identifying links between words or groups of words in parallel sentences. This approach consists in defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the s"
2012.eamt-1.62,A94-1006,0,0.331398,"Missing"
2012.eamt-1.62,P07-1003,0,0.0204054,"the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are gene"
2012.eamt-1.62,H05-1022,0,0.0233815,"rallel sentences. This approach consists in defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heu"
2012.eamt-1.62,J93-1003,0,0.078444,"tric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are generally limited to a list of association candidates precomputed using patterns and filters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation process is used, where each sentence is processed independently. Alignment links can then be computed, using for instance the greedy algorithm proposed by Melamed (2000) (competitive linking). The probabilistic approach is the most widely used, mainly due to its tight integration with SMT, of which it constitu"
2012.eamt-1.62,D07-1006,0,0.016161,"n defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduc"
2012.eamt-1.62,C94-2178,0,0.381878,"ly produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are generally limited to a list of association candidates precomputed using patterns and filters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation process is used, where each sentence is processed independently. Alignment links can then be computed, using for instance the greedy algorithm proposed by Melamed (2000) (competitive linking). The probabilistic approach is the most widely used, mainly due to its tight integ"
2012.eamt-1.62,P98-1069,0,0.166484,"Missing"
2012.eamt-1.62,H91-1026,0,0.581153,"hev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are generally limited to a list of association candidates precomputed using patterns and filters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation process is used, where each sentence is proces"
2012.eamt-1.62,P08-1112,0,0.040818,"Missing"
2012.eamt-1.62,W08-0509,0,0.0890915,"roparl corpus (Koehn, 2005), in three languages: Finnish–English (agglutinating language–isolating language), French–Spanish, and Portuguese-Spanish (very close languages). For each pair, we use a training set made up of 350,000 sentence pairs (avg.: 30 words/sentence in English), and development and test sets made up of 2,000 sentence pairs each. The systems are optimized with MERT (Och, 2003). Unless otherwise specified, a lexicalized reordering model is used. Translations are evaluated using BLEU (Papineni et al., 2002) and TER2 (Snover et al., 2006). Five approaches are compared: MGIZA++ (Gao and Vogel, 2008), implements the IBM models (Brown et al., 1993) and the HMM of Vogel et al. (1996). Integrated to Moses, it remains the reference in the domain. It is run with default settings: 5 iterations of IBM1, HMM, IBM3, and IBM4, in both directions (source to target and target to source). The alignments are then made symmetric and a translation table is produced from the alignments using Moses tools (grow-diag-finaland heuristic for phrase pair extraction). Anymalign (Lardilleux et al., 2011a), used to directly build the translation tables. As this tool can be stopped at any time, its running time is"
2012.eamt-1.62,D07-1103,0,0.0190696,"ters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation process is used, where each sentence is processed independently. Alignment links can then be computed, using for instance the greedy algorithm proposed by Melamed (2000) (competitive linking). The probabilistic approach is the most widely used, mainly due to its tight integration with SMT, of which it constitutes a cornerstone since the introduction of IBM models (Brown et al., 1993). The two approaches have shown complementary strengths and weaknesses, as acknowledged by e.g. Johnson et al. (2007), where phrase associations extracted from word alignments are filtered out according to statistical association measures. Anymalign, introduced in (Lardilleux and Lepage, 2009; Lardilleux et al., 2011a), aims at extracting sub-sentential associations, addressing a number of issues that are often overlooked. It can process any number of languages simultaneously, it does not make any distinction between source and target, is amenable to massive parallelism, scales easily, and is very simple to implement. Anymalign’s association scores have proven to produce better results than state-of-the-art"
2012.eamt-1.62,N03-1017,0,0.0492979,"n this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (200"
2012.eamt-1.62,P07-2045,0,0.0101203,"arallel corpus to align, because each sentence pair is processed independently. Aligning a corpus can thus easily be made parallel: the total running time is divided by the number of available processors. Another advantage is that the alignments produced are symmetric during the whole process, contrary to more widely spread models such as IBM models that produce better result when run in both translation directions and their outputs combined using heuristics. 282 Evaluation Description of Experiments Our alignment method is evaluated within a phrase-based SMT system. We use the Moses toolkit (Koehn et al., 2007), and data extracted from the Europarl corpus (Koehn, 2005), in three languages: Finnish–English (agglutinating language–isolating language), French–Spanish, and Portuguese-Spanish (very close languages). For each pair, we use a training set made up of 350,000 sentence pairs (avg.: 30 words/sentence in English), and development and test sets made up of 2,000 sentence pairs each. The systems are optimized with MERT (Och, 2003). Unless otherwise specified, a lexicalized reordering model is used. Translations are evaluated using BLEU (Papineni et al., 2002) and TER2 (Snover et al., 2006). Five ap"
2012.eamt-1.62,2005.mtsummit-papers.11,0,0.359582,"7 122 t1 A A¯ s1 ... sx−1 sx .. . sI B ... ty−1 B¯ ... ty W (A, B) ¯ W (A, B) ¯ B) W (A, ¯ B) ¯ W (A, tJ Figure 2: Schematic representation of the segmen¯ tation of a pair of sentences S = A. A¯ and T = B. B. w(pays, country) = p(pays|country) × p(country|pays) + 4,057 + 2,007 = 151,190 + 17,717 +17,717 10,865 + 6,284 + 4,057 + 3,742 + 2,007 17,717 + 4,057 + 2,007 × 17,717 + 4,057 + 2,007 + 122 ' 0.121 Figure 1: Computing a score between source word pays and target word country from a subset of a translation table produced by Anymalign with the French and English parts of the Europarl corpus (Koehn, 2005). an indicator of the quality of the entry; it is just the number of times the translation pair has been produced by Anymalign (see (Lardilleux et al., 2011a) for details). This computation is illustrated on Figure 1. What we do here is tantamount to a very simplified version of the algorithm that is used to train standard translation models: starting with lexical associations, we derive by heuristic means an optimal (Viterbi) alignment, from which the translation tables are finally computed. Our procedure is much simpler, though, as we do not iterate the procedure (like in EM training) and di"
2012.eamt-1.62,R09-1040,1,0.878331,"dependently. Alignment links can then be computed, using for instance the greedy algorithm proposed by Melamed (2000) (competitive linking). The probabilistic approach is the most widely used, mainly due to its tight integration with SMT, of which it constitutes a cornerstone since the introduction of IBM models (Brown et al., 1993). The two approaches have shown complementary strengths and weaknesses, as acknowledged by e.g. Johnson et al. (2007), where phrase associations extracted from word alignments are filtered out according to statistical association measures. Anymalign, introduced in (Lardilleux and Lepage, 2009; Lardilleux et al., 2011a), aims at extracting sub-sentential associations, addressing a number of issues that are often overlooked. It can process any number of languages simultaneously, it does not make any distinction between source and target, is amenable to massive parallelism, scales easily, and is very simple to implement. Anymalign’s association scores have proven to produce better results than state-of-the-art methods on bilingual lexicon constitution tasks (evaluation performed by comparing word associations with reference dictionaries). However, Anymalign’s phrase tables are not as"
2012.eamt-1.62,N06-1014,0,0.0326161,"approach consists in defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ne"
2012.eamt-1.62,Y11-1016,1,0.702092,"performed by comparing word associations with reference dictionaries). However, Anymalign’s phrase tables are not as good as those obtained with standard methods (evaluation performed with standard MT metrics) (Lardilleux et al., 2011b). One possible explanation for these contrasted results is that, Anymalign does not compute any alignment at the word or at the phrase level; instead, it directly computes translation tables along with their associated scores. Those tables have very different profiles than those obtained with probabilistic methods, mainly in terms of their n-gram distribution (Luo et al., 2011). In particular, despite recent improvements (Lardilleux et al., 2011b), the quantity of long n-grams produced remains relatively small compared with Moses’s translation tables. In this paper, we complement Anymalign with a simple alignment algorithm, so as to better understand its current limitations. The resulting alignments improve Anymalign’s phrase tables to a point where they can be used to obtain state-of-the art results. In passing, we also propose a computationally cheap way to compute ITG alignments based on arbitrary word level association scores. The rest of this paper is organized"
2012.eamt-1.62,W02-1018,0,0.0453506,"he corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficien"
2012.eamt-1.62,J00-2004,0,0.0244408,"h directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are generally limited to a list of association candidates precomputed using patterns and filters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation process is used, where each sentence is processed independently. Alignment links can then be computed, using for instance the greedy algorithm proposed by Melamed (2000) (competitive linking). The probabilistic approach is the most widely used, mainly due to its tight integration with SMT, of which it constitutes a cornerstone since the introduction of"
2012.eamt-1.62,W04-3243,0,0.0817405,"Missing"
2012.eamt-1.62,W05-0801,0,0.0788276,"al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are generally limited to a list of association candidates precomputed using patterns and filters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation process is used, where each sentence is processed independently. Alignment links can then be computed, using for instance the greedy algorithm proposed by Melamed (2000) (competitive linking). The probabilistic approach is the most widely used, mainly due to its tight integration with SMT, of which it constitutes a cornerstone since the introduction of IBM models (Brown et"
2012.eamt-1.62,J03-1002,0,0.0566834,"al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual information (Gale and Church, 1991; Fung and Church, 1994), or likelihood ratio (Dunning, 1993)—see also more recent work by Melamed (2000) and by Moore (2005). Computations are generally limited to a list of association candidates precomputed using patterns and filters, for instance, by focusing exclusively on the most frequent word n-grams. In this approach, a local maximisation pr"
2012.eamt-1.62,P03-1021,0,0.0164216,"ombined using heuristics. 282 Evaluation Description of Experiments Our alignment method is evaluated within a phrase-based SMT system. We use the Moses toolkit (Koehn et al., 2007), and data extracted from the Europarl corpus (Koehn, 2005), in three languages: Finnish–English (agglutinating language–isolating language), French–Spanish, and Portuguese-Spanish (very close languages). For each pair, we use a training set made up of 350,000 sentence pairs (avg.: 30 words/sentence in English), and development and test sets made up of 2,000 sentence pairs each. The systems are optimized with MERT (Och, 2003). Unless otherwise specified, a lexicalized reordering model is used. Translations are evaluated using BLEU (Papineni et al., 2002) and TER2 (Snover et al., 2006). Five approaches are compared: MGIZA++ (Gao and Vogel, 2008), implements the IBM models (Brown et al., 1993) and the HMM of Vogel et al. (1996). Integrated to Moses, it remains the reference in the domain. It is run with default settings: 5 iterations of IBM1, HMM, IBM3, and IBM4, in both directions (source to target and target to source). The alignments are then made symmetric and a translation table is produced from the alignments"
2012.eamt-1.62,P02-1040,0,0.0913641,"ased SMT system. We use the Moses toolkit (Koehn et al., 2007), and data extracted from the Europarl corpus (Koehn, 2005), in three languages: Finnish–English (agglutinating language–isolating language), French–Spanish, and Portuguese-Spanish (very close languages). For each pair, we use a training set made up of 350,000 sentence pairs (avg.: 30 words/sentence in English), and development and test sets made up of 2,000 sentence pairs each. The systems are optimized with MERT (Och, 2003). Unless otherwise specified, a lexicalized reordering model is used. Translations are evaluated using BLEU (Papineni et al., 2002) and TER2 (Snover et al., 2006). Five approaches are compared: MGIZA++ (Gao and Vogel, 2008), implements the IBM models (Brown et al., 1993) and the HMM of Vogel et al. (1996). Integrated to Moses, it remains the reference in the domain. It is run with default settings: 5 iterations of IBM1, HMM, IBM3, and IBM4, in both directions (source to target and target to source). The alignments are then made symmetric and a translation table is produced from the alignments using Moses tools (grow-diag-finaland heuristic for phrase pair extraction). Anymalign (Lardilleux et al., 2011a), used to directly"
2012.eamt-1.62,J96-1001,0,0.2525,"Missing"
2012.eamt-1.62,2006.amta-papers.25,0,0.0463637,"toolkit (Koehn et al., 2007), and data extracted from the Europarl corpus (Koehn, 2005), in three languages: Finnish–English (agglutinating language–isolating language), French–Spanish, and Portuguese-Spanish (very close languages). For each pair, we use a training set made up of 350,000 sentence pairs (avg.: 30 words/sentence in English), and development and test sets made up of 2,000 sentence pairs each. The systems are optimized with MERT (Och, 2003). Unless otherwise specified, a lexicalized reordering model is used. Translations are evaluated using BLEU (Papineni et al., 2002) and TER2 (Snover et al., 2006). Five approaches are compared: MGIZA++ (Gao and Vogel, 2008), implements the IBM models (Brown et al., 1993) and the HMM of Vogel et al. (1996). Integrated to Moses, it remains the reference in the domain. It is run with default settings: 5 iterations of IBM1, HMM, IBM3, and IBM4, in both directions (source to target and target to source). The alignments are then made symmetric and a translation table is produced from the alignments using Moses tools (grow-diag-finaland heuristic for phrase pair extraction). Anymalign (Lardilleux et al., 2011a), used to directly build the translation tables."
2012.eamt-1.62,C96-2141,0,0.89756,"words or groups of words in parallel sentences. This approach consists in defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associa"
2012.eamt-1.62,2005.mtsummit-papers.33,0,0.0267901,"determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative approaches (also called heuristic by Och and Ney (2003)), were introduced by Gale and Church (1991). They do not rely on an alignment model: in order to detect translations, they rely on independence statistical measures such as, for instance, Dice coefficient, mutual informa"
2012.eamt-1.62,J97-3002,0,0.921712,"ords in parallel sentences. This approach consists in defining a probabilistic model of the parallel corpus, the parameters of which are estimated by a global maximization process which simultaneously considers all possible associations in the corpus. The goal is to determine the best set of alignment links between all source and target words of every parallel sentence pair. The most famous representatives in this category are the IBM models (Brown et al., 1993) for aligning isolated words, which have given rise to an impressive series of variants and amendments (see e.g. (Vogel et al., 1996; Wu, 1997; Deng and Byrne, 2005; Liang et al., 2006; Fraser and Marcu, 2007; Ganchev et al., 2008), to cite a few). Generalizing word alignment models to phrase alignment proves to be a much more difficult problem, and in the view of work of Marcu and Wong (2002) and Vogel (2005), such alignments are generally produced by heuristically combining asymmetric 1–n word alignments (“oriented”) in both directions (Koehn et al., 2003; DeNero and Klein, 2007). Once the set of alignment links is constituted, it is possible to assign scores to each pair of segments extracted. On the other hand, associative appro"
2012.eamt-1.62,C98-1066,0,\N,Missing
2020.jeptalnrecital-taln.9,P18-1073,0,0.022758,"Missing"
2020.jeptalnrecital-taln.9,Q17-1010,0,0.0154257,"Missing"
2020.jeptalnrecital-taln.9,Y10-1041,0,0.0497566,"Missing"
2020.jeptalnrecital-taln.9,K19-1085,0,0.03052,"Missing"
2020.jeptalnrecital-taln.9,L18-1171,1,0.835202,"Missing"
2020.jeptalnrecital-taln.9,E09-1056,0,0.0693521,"Missing"
2020.jeptalnrecital-taln.9,P98-1120,1,0.523513,"Missing"
2020.loresmt-1.7,P15-1166,0,0.203481,"es with the risk that small amounts of training data result in low translation accuracy (Koehn and Knowles, 2017). Improvement in translation of low resource languages has been reported with the use of multilingual models (Ha et al., 2016; Johnson et al., 2017), back-translation (Sennrich et al., 2016a) and unsupervised learning (Lample et al., 2018). Initially, MT systems were designed for one single language pair (Johnson et al., 2017). However, NMT systems can be trained simultaneously on many language pairs. This enables translation from and into any of the languages used during training. Dong et al. (2015) first modified an attention-based 1 http://data.statmt.org/pmindia/ 47 Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages, pages 47–54 c Decmber 04, 2020. 2020 Association for Computational Linguistics Bengali–English, Hindi–English and Manipuri– English2 . Our main objective is to measure how much accuracy can be achieved in translation from Manipuri into the three other Indian languages (Assamese, Bengali and Hindi), without using any data from these language pairs, thanks to zeroshot translation. Additionally, we use the JW300 dataset3 (Agi´c and Vuli´c, 2019;"
2020.loresmt-1.7,D16-1026,0,0.0338251,"Missing"
2020.loresmt-1.7,N18-1032,0,0.0464779,"Missing"
2020.loresmt-1.7,P19-1310,0,0.0541963,"Missing"
2020.loresmt-1.7,P82-1020,0,0.80752,"Missing"
2020.loresmt-1.7,D13-1176,0,0.0394457,"le to improve the translation for low resource language pairs by leveraging high resource language pairs, thanks to transfer learning. Our work is closely related to (Johnson et al., 2017): we analyse the performance of multilingual models on our data and perform zero-shot translation as well. The originality in our work is that we aim to improve the translation quality of our model and since we deal with low resource languages, we propose to control the translation quality such that we train, validate and test our model on balanced data sets across all the language pairs. Related work 3 NMT (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) for a single language pair has been explored extensively over the years. It has been extended to multilingual models (Dong et al., 2015; Luong et al., 2015; Ha et al., 2016; Firat et al., 2016; Johnson et al., 2017) on available multilingual data. One of the approach is that of zero-shot translation (Johnson et al., 2017; Arivazhagan et al., 2019) between language pairs Dataset We use the pmindia dataset (Haddow and Kirefu, 2020).4 This data set contains the official documents from the Prime Minister Office of the Government of"
2020.loresmt-1.7,2020.wildre-1.6,0,0.0365638,"on. Their model consists in multiple encoders with a different attention mechanism for each source language. However, this model requires a multi-way parallel corpus for every language pairs, which is hard to obtain, especially for languages with low resource. NMT is capable of cross-lingual learning (Kim et al., 2019; Zoph and Knight, 2016). This is the motivation for zero-shot translation. Firat et al. (2017) introduced the notion of zero-resource translation. They used a pre-trained multi-way multilingual model and performed fine-tuning with the pseudo parallel data generated by the model. Madaan and Sadat (2020) introduced an approach for improving multilingual NMT for Indian languages. They showed that their model is able to improve the translation for low resource language pairs by leveraging high resource language pairs, thanks to transfer learning. Our work is closely related to (Johnson et al., 2017): we analyse the performance of multilingual models on our data and perform zero-shot translation as well. The originality in our work is that we aim to improve the translation quality of our model and since we deal with low resource languages, we propose to control the translation quality such that"
2020.loresmt-1.7,P19-1120,0,0.0305345,"Missing"
2020.loresmt-1.7,P16-1009,0,0.144602,"n an increase in translation accuracy with its balanced data settings score multiplied by 7 for Manipuri to Hindi during Round-III of zeroshot translation. 1 Introduction End-to-end neural Machine Translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) can be applied to low resource languages with the risk that small amounts of training data result in low translation accuracy (Koehn and Knowles, 2017). Improvement in translation of low resource languages has been reported with the use of multilingual models (Ha et al., 2016; Johnson et al., 2017), back-translation (Sennrich et al., 2016a) and unsupervised learning (Lample et al., 2018). Initially, MT systems were designed for one single language pair (Johnson et al., 2017). However, NMT systems can be trained simultaneously on many language pairs. This enables translation from and into any of the languages used during training. Dong et al. (2015) first modified an attention-based 1 http://data.statmt.org/pmindia/ 47 Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages, pages 47–54 c Decmber 04, 2020. 2020 Association for Computational Linguistics Bengali–English, Hindi–English and Manipuri– Englis"
2020.loresmt-1.7,P16-1162,0,0.212612,"n an increase in translation accuracy with its balanced data settings score multiplied by 7 for Manipuri to Hindi during Round-III of zeroshot translation. 1 Introduction End-to-end neural Machine Translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) can be applied to low resource languages with the risk that small amounts of training data result in low translation accuracy (Koehn and Knowles, 2017). Improvement in translation of low resource languages has been reported with the use of multilingual models (Ha et al., 2016; Johnson et al., 2017), back-translation (Sennrich et al., 2016a) and unsupervised learning (Lample et al., 2018). Initially, MT systems were designed for one single language pair (Johnson et al., 2017). However, NMT systems can be trained simultaneously on many language pairs. This enables translation from and into any of the languages used during training. Dong et al. (2015) first modified an attention-based 1 http://data.statmt.org/pmindia/ 47 Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages, pages 47–54 c Decmber 04, 2020. 2020 Association for Computational Linguistics Bengali–English, Hindi–English and Manipuri– Englis"
2020.loresmt-1.7,P17-4012,0,0.0187828,"tion 4 on language pairs without parallel data. Our model translates between Manipuri into the other Indian languages, i.e., Assamese, Bengali and Hindi. 5.1.4 Pre-processing and tools Before preprocessing the data, we use Joint BytePair Encoding (Sennrich et al., 2016b) to address the problem of rare words by using sub-word segmentation. We apply Byte-Pair Encoding (BPE) and perform sub-word segmentation on all of our selected data set with 10,000 merge operations so as to obtain a vocabulary representation of all our language pairs. For all of our experiments, we use the OpenNMT-py toolkit (Klein et al., 2017). We preprocess the training and validation data set for all 5.1.1 Single models We train the single models on a single language pair, one for each language pair. There are a total of eight language pairs in our experiments: from each of Assamese (asm), Bengali (ben), Hindi (hin) and Manipuri (mni), into English and vice-versa. We then measure the effects of balanced data set on our single models. Each language pair has 5,000 50 RNN model Embed Dim 500 RNN Type LSTM Num Layers 2 Hidden Dim 500 Input Feeding True Attention Global Attention type General Dropout 0.3 Encoder Type brnn Decoder Type"
2020.loresmt-1.7,W04-3250,0,0.448405,"Missing"
2020.loresmt-1.7,W17-3204,0,0.128709,"ered language pairs. We then expand our experiments for additional three rounds by increasing the training data with 2,000 sentence pairs in each round for some of the language pairs. We obtain an increase in translation accuracy with its balanced data settings score multiplied by 7 for Manipuri to Hindi during Round-III of zeroshot translation. 1 Introduction End-to-end neural Machine Translation (NMT) (Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) can be applied to low resource languages with the risk that small amounts of training data result in low translation accuracy (Koehn and Knowles, 2017). Improvement in translation of low resource languages has been reported with the use of multilingual models (Ha et al., 2016; Johnson et al., 2017), back-translation (Sennrich et al., 2016a) and unsupervised learning (Lample et al., 2018). Initially, MT systems were designed for one single language pair (Johnson et al., 2017). However, NMT systems can be trained simultaneously on many language pairs. This enables translation from and into any of the languages used during training. Dong et al. (2015) first modified an attention-based 1 http://data.statmt.org/pmindia/ 47 Proceedings of the 3rd"
2020.loresmt-1.7,tiedemann-2012-parallel,0,0.293426,"first modified an attention-based 1 http://data.statmt.org/pmindia/ 47 Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages, pages 47–54 c Decmber 04, 2020. 2020 Association for Computational Linguistics Bengali–English, Hindi–English and Manipuri– English2 . Our main objective is to measure how much accuracy can be achieved in translation from Manipuri into the three other Indian languages (Assamese, Bengali and Hindi), without using any data from these language pairs, thanks to zeroshot translation. Additionally, we use the JW300 dataset3 (Agi´c and Vuli´c, 2019; Tiedemann, 2012) for Assamese–English language pairs for two rounds of the experiment due to the limited number of data present in the pmindia data set for this language pair. In our experiments, we use only the above-mentioned resources. Our goal is to improve the translation quality of our zero-shot translation system among the low resourced languages. We propose to control the translation quality by introducing the notion of balanced data in the respective language pairs as a parameter. The reason why we concentrate on Manipuri is because it is an extremely low resource language: only 7,000 sentence pairs"
2020.loresmt-1.7,C18-1054,0,0.0254772,"Missing"
2020.loresmt-1.7,N16-1004,0,0.0199814,"e of the paper is as follows. Section 2 describes previous work. Section 3 gives details about the data set used. Section 4 presents the methodology. Section 5 describes the experiments, their results and provides an analysis. Section 6 concludes and proposes future directions. 2 for which no parallel data has been seen during training. Another interesting work addressed by (Johnson et al., 2017; Ha et al., 2016) is the introduction of artificial tokens. It helps in minimizing the architectural changes in the decoder. Zero-shot machine translation has been explored for low resource languages. Zoph and Knight (2016) proposed an approach for multi-source translation. Their model consists in multiple encoders with a different attention mechanism for each source language. However, this model requires a multi-way parallel corpus for every language pairs, which is hard to obtain, especially for languages with low resource. NMT is capable of cross-lingual learning (Kim et al., 2019; Zoph and Knight, 2016). This is the motivation for zero-shot translation. Firat et al. (2017) introduced the notion of zero-resource translation. They used a pre-trained multi-way multilingual model and performed fine-tuning with t"
2020.loresmt-1.7,D15-1166,0,0.0403576,"odels on our data and perform zero-shot translation as well. The originality in our work is that we aim to improve the translation quality of our model and since we deal with low resource languages, we propose to control the translation quality such that we train, validate and test our model on balanced data sets across all the language pairs. Related work 3 NMT (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015; Cho et al., 2014) for a single language pair has been explored extensively over the years. It has been extended to multilingual models (Dong et al., 2015; Luong et al., 2015; Ha et al., 2016; Firat et al., 2016; Johnson et al., 2017) on available multilingual data. One of the approach is that of zero-shot translation (Johnson et al., 2017; Arivazhagan et al., 2019) between language pairs Dataset We use the pmindia dataset (Haddow and Kirefu, 2020).4 This data set contains the official documents from the Prime Minister Office of the Government of India. It contains monolingual and parallel corpora. There are 13 Indian languages and English in it. We use data for four language pairs from the parallel corpus found in the data set: from Assamese, Bengali, Hindi and M"
2020.signlang-1.34,P13-2059,0,0.0550851,"Missing"
2020.signlang-1.34,dreuw-etal-2010-signspeak,0,0.0405814,"vocabulary automatically, which improved annotation speed. However, video and image data require heavy processing. For exam¨ ple, Ostling et al. (2018) presented comprehensive research on 31 sign languages and 120,000 sign videos. The location and movement information was collected using video processing. The collection alone took two months of computing time on a single GPU. Another problem with videobased corpora is an issue with signers’ privacy. Most of the SL corpora that available today for researchers include a signing person. Which often leads to limited accessibility of the corpora. Dreuw et al. (2010) presented a sign language translation system as a part of The SignSpeak Project, which includes an automatic sign language recognition system that is based on sign feature extraction from tracking the body parts on video frames. Curiel Diaz and Collet (2013) proposed another semi-automatic sign language recognition system, which also relies on head and hands tracking on video frames and uses a Propositional Dynamic Logic. Still, many SL corpora do not include HamNoSys annotations. Hr´uz et al. (2011) used an existing dictionary with annotated video data and custom classes for the categorizati"
C08-2014,J03-1002,0,0.00533114,"n subsentential alignments from several languages simultaneously. The method handles several languages at once, and avoids the complexity explosion due to the usual pair-bypair processing. It can be used for different units (characters, morphemes, words, chunks). An evaluation of word alignments with a trilingual machine translation corpus has been conducted. A comparison of the results with those obtained by state of the art alignment software is reported. 1 Introduction 2 Several tools are available nowadays for alignment of pairs of languages. Among them, the bilingual word aligner GIZA++ (Och and Ney, 2003) can perform high quality alignments based on words statistics and is considered the most efficient tool. Three main criticisms may be addressed to this kind of tool. Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. This is all the more important when multilingual alignment is concerned, since every language pair will require its own set of parameter values. Secondly, the best methods available nowadays can only work on language pairs, which results in a complexity expl"
C08-2014,W99-0602,0,0.0393939,"ords statistics and is considered the most efficient tool. Three main criticisms may be addressed to this kind of tool. Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming. This is all the more important when multilingual alignment is concerned, since every language pair will require its own set of parameter values. Secondly, the best methods available nowadays can only work on language pairs, which results in a complexity explosion when multilingual alignments are needed. Simard (1999) showed how to adapt a bilingual method to align more than two Alignment by string differences 2.1 String differences In order to introduce the operation we use, let us start with a well-known similar technique, the Longest Common Subsequence (LCS) (Hirschberg, 1975). Given two strings A and B, it is always possible to find their longest subsequence. Such a subsequence is a sequence of non necessarily contiguous characters. For instance, assume we have the following short English sentences (space characters are marked by an underscore and have the same status as any other character): A = I wou"
C08-2014,W98-1006,0,0.0101186,"he strings requested to be aligned can be anything, from one character (see the first lines of the table) to entire sentences (see last line). Most alignments, if not perfect, differ from the expected meaning by slight differences only, even in Arabic. 3.3 3 We used an English-Arabic dictionary from sdict (87,000 entries): http://sdict.com and the EDICT English-Japanese dictionary (115,000 entries): http://www.csse.monash.edu.au/∼jwb/j edict.html. The Arabic part of the English-Arabic dictionary being lemmatized, we had to preprocess the Arabic part of our corpus so that it be lemmatized too (Debili and Achour, 1998). Comparison against GIZA++ We compared our system to the state of the art device, GIZA++, in the particular case of bilingual word alignments on two pairs of languages: English to Arabic and English to Japanese. Our 57 English . Arabic . ? áK @ AJë YK P @ @Qº  Õç' Q»  @ ? Wh here I ’d like Thank you Ice I have to get Japanese /./ ‘.’ 。 /?/ ‘?’ か。 ‘where’ /-ayn/ ‘here’ /hn¯a/ ‘I’d like’ /-aryd/ ‘thank you’ /ˇskr¯a/ /-¯ays krym/ ‘ice cream’  È@ ÉJ®ÊJ  é«A . Ê« ‘?’ /ka ./ /nani/, /nan/ ‘what’, ‘wh. . . ’ ここ /koko/ 下さい /kudasai/ ‘here’ ‘please’ ありがとう /arigatou/ ‘thank you’ 氷を /koori wo/"
C08-2014,takezawa-etal-2002-toward,0,0.0379944,"their n-sequences of characters in the initial data. This is performed in the target languages. Eventually, each alignment is scored by its frequency divided by the number of sentences that were required to obtain it. The reason for doing so is that, in practice, the less sentences required, the longer and the safer the LCSubstr’s used. 3 3.1 Evaluation Data used We used the English, Japanese and Arabic training parts of the IWSLT 2007 machine translation campaign corpus (Fordyce, 2007) to conduct our experiments. It is made of nearly 20,000 triples of aligned sentences from the BTEC corpus (Takezawa et al., 2002). 3.2 Result samples As mentioned earlier, one advantage of our method is that it can align any string of text, providing the data is sufficient. Table 2 shows a sample of alignments obtained using English as the source language. The strings requested to be aligned can be anything, from one character (see the first lines of the table) to entire sentences (see last line). Most alignments, if not perfect, differ from the expected meaning by slight differences only, even in Arabic. 3.3 3 We used an English-Arabic dictionary from sdict (87,000 entries): http://sdict.com and the EDICT English-Japan"
C08-2014,2007.iwslt-1.1,0,\N,Missing
C08-2014,H05-1011,0,\N,Missing
C10-2017,P05-1074,0,0.503926,"coverage of patterns that can be translated. In the same way, most NLP systems like information retrieval (Sekine, 2005) or questionanswering (Duclaye et al., 2003), based on pattern recognition, can be improved by a paraphrase generator. Most of these applications need a n-best set of solutions in order to rerank them according to a task-specific criterion. In order to produce the paraphrases, a promising approach is to see the paraphrase generation problem as a statistical translation problem. In that approach, the target language becomes the same as the source language (Quirk et al., 2004; Bannard and Callison-Burch, 2005; Max and Zock, 2008). The first difficulty of this approach is the need of a paraphrase table. A paraphrase table is a monolingual version of a translation table in the statistical machine translation (SMT) field. In this field, the difficulty is basically overcome by using huge aligned bilingual corpora like the Europarl (Koehn, 2005) corpus. In the paraphrase generation field, one needs a huge aligned monolingual corpus to build a paraphrase table. The low availability of such monolingual corpora nurtures researches in order to find heuristics to produce them (Barzilay and Lee, 2003; Quirk"
C10-2017,N03-1003,0,0.646853,"xperiment shows that a major boost of performance can be obtained by embedding a true score computation inside a Monte-Carlo sampling based paraphrase generator. 1 Introduction A paraphrase generator is a program which, given a source sentence, produces a new sentence with almost the same meaning. The modification place is not imposed but the paraphrase has to differ from the original sentence. Paraphrase generation is useful in applications where it is needed to choose between different forms to keep the most fit. For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) by selecting the shortest paraphrase. They can help human writers by proposing alternatives and having them choose the most appropriate (Max and Zock, 2008). Paraphrases can also be used to improve natural language processing (NLP) systems. In this direction, (Callison-Burch et al., 2006) tried to improve machine translations by enlarging the coverage of patterns that can be translated. In the same way, most NLP systems like information retrieval (Sekine, 2005) or questionanswering (Duclaye et al., 2003), based on pattern recognition, can be improved by a paraphrase generator. Most of these a"
C10-2017,N06-1003,0,0.0255044,"same meaning. The modification place is not imposed but the paraphrase has to differ from the original sentence. Paraphrase generation is useful in applications where it is needed to choose between different forms to keep the most fit. For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) by selecting the shortest paraphrase. They can help human writers by proposing alternatives and having them choose the most appropriate (Max and Zock, 2008). Paraphrases can also be used to improve natural language processing (NLP) systems. In this direction, (Callison-Burch et al., 2006) tried to improve machine translations by enlarging the coverage of patterns that can be translated. In the same way, most NLP systems like information retrieval (Sekine, 2005) or questionanswering (Duclaye et al., 2003), based on pattern recognition, can be improved by a paraphrase generator. Most of these applications need a n-best set of solutions in order to rerank them according to a task-specific criterion. In order to produce the paraphrases, a promising approach is to see the paraphrase generation problem as a statistical translation problem. In that approach, the target language becom"
C10-2017,P09-2063,1,0.781494,"ven paraphrase t, they consider only some ZtI where they should estimate ZI∗ . SMT decoders are overlooking the partitioning step in their computations. There is no reason for the decoder solution to reach the true score. Troubles arise when one needs the scores of generated paraphrases, for instance when the system must produce an ordered n-best solution. What is the relevance of the estimated scores – and orders – with respect to the true scores – and orders – of the model? Is the true score able to help the generation process? 2.2 Algorithm Let us first adopt the point of view proposed in (Chevelu et al., 2009). The paraphrase generation problem can be seen as an exploration problem. We seek the best paraphrase according to a scoring function in a space to search by applying successive transformations. This space is composed of states connected by actions. An action is a transformation rule with a place where it applies in the sentence. States are a sentence with a set of possible actions. Applying an action in a given state consists in transforming the sentence of the state and removing all rules that are no more applicable. In this framework, each state, except the root, can be a final state. The"
C10-2017,P07-2045,0,0.0132002,"ollowed to generate a paraphrase. Because of the step-by-step computation, different ways can produce the same paraphrase, but with different scores. Amongst these scores, the best one is the true score of a paraphrase according to the SMT model. Most paraphrase generators use some standard SMT decoding algorithms (Quirk et al., 2004) or some off-the-shelf decoding tools like MOSES. The goal of these decoders is to find the best path in the lattice produced by the paraphrase table. This is basically achieved by using dynamic programming – especially the Viterbi algorithm – and beam searching (Koehn et al., 2007). The best paraphrase proposed by these programs is known not to be the optimal paraphrase. One can even question if the score returned is the true score. We first show in Section 2 that in the particular domain of statistical paraphrase generation, one can compute true a posteriori scores of generated paraphrases. We then explore some applications of the true score algorithm in the paraphrase generation field. In Section 3, we show that scores returned by SMT decoders are not always true scores and they plague the ranking of output n-best solutions. In Section 4, we show that the true score c"
C10-2017,2005.mtsummit-papers.11,0,0.169731,"n. In order to produce the paraphrases, a promising approach is to see the paraphrase generation problem as a statistical translation problem. In that approach, the target language becomes the same as the source language (Quirk et al., 2004; Bannard and Callison-Burch, 2005; Max and Zock, 2008). The first difficulty of this approach is the need of a paraphrase table. A paraphrase table is a monolingual version of a translation table in the statistical machine translation (SMT) field. In this field, the difficulty is basically overcome by using huge aligned bilingual corpora like the Europarl (Koehn, 2005) corpus. In the paraphrase generation field, one needs a huge aligned monolingual corpus to build a paraphrase table. The low availability of such monolingual corpora nurtures researches in order to find heuristics to produce them (Barzilay and Lee, 2003; Quirk et al., 2004). On the other hand, an interesting method proposed by (Bannard and CallisonBurch, 2005) tries to make a paraphrase table using a translation table learned on bilingual corpora. The method uses a well-known heuristic (Lepage and Denoual, 2005) which says that if two sentences have the same translation, then they should be p"
C10-2017,I05-5008,1,0.850946,"he difficulty is basically overcome by using huge aligned bilingual corpora like the Europarl (Koehn, 2005) corpus. In the paraphrase generation field, one needs a huge aligned monolingual corpus to build a paraphrase table. The low availability of such monolingual corpora nurtures researches in order to find heuristics to produce them (Barzilay and Lee, 2003; Quirk et al., 2004). On the other hand, an interesting method proposed by (Bannard and CallisonBurch, 2005) tries to make a paraphrase table using a translation table learned on bilingual corpora. The method uses a well-known heuristic (Lepage and Denoual, 2005) which says that if two sentences have the same translation, then they should be paraphrases of each others. Another aspect, less studied, is the generation process of paraphrases, i.e. the decoding process in SMT. This process is subject to combinatorial 144 Coling 2010: Poster Volume, pages 144–152, Beijing, August 2010 explosions. Heuristics are then frequently used to drive the exploration process in the a priori intractable high dimensional spaces. On the one hand, these heuristics are used to build a paraphrase step by step according to the paraphrase table. On the other hand, they try t"
C10-2017,W08-1911,0,0.0161227,"1 Introduction A paraphrase generator is a program which, given a source sentence, produces a new sentence with almost the same meaning. The modification place is not imposed but the paraphrase has to differ from the original sentence. Paraphrase generation is useful in applications where it is needed to choose between different forms to keep the most fit. For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) by selecting the shortest paraphrase. They can help human writers by proposing alternatives and having them choose the most appropriate (Max and Zock, 2008). Paraphrases can also be used to improve natural language processing (NLP) systems. In this direction, (Callison-Burch et al., 2006) tried to improve machine translations by enlarging the coverage of patterns that can be translated. In the same way, most NLP systems like information retrieval (Sekine, 2005) or questionanswering (Duclaye et al., 2003), based on pattern recognition, can be improved by a paraphrase generator. Most of these applications need a n-best set of solutions in order to rerank them according to a task-specific criterion. In order to produce the paraphrases, a promising a"
C10-2017,J03-1002,0,0.00472715,"ing corpus. The language models we use are n-gram language models with back-off. We use SRILM (Stolcke, 2002) with its default parameters for this purpose. The length of the n-grams is five. To build a paraphrase table, we use a variant of the construction method via a pivot language proposed in (Bannard and Callison-Burch, 2005). The first step consists in building a bilingual translation table from the aligned corpus. Given a source phrase si and another phrase ti in a different language, a bilingual translation table provides the two probabilities p(si |ti ) and p(ti |si ). We use GIZA ++ (Och and Ney, 2003) with its default parameters to produce phrase alignments. The paraphrase table is then built from the phrase translation table. The probability for a phrase si to be paraphrased by a phrase s0i in the same language is estimated by the sum of each round-trip from si to s0i through any phrase ti of a pivot language. The construction of this table is very simple. Given a bilingual translation table sorted by pivot phrases, the algorithm retrieves all the phrases linked with the same pivot (named a pivot cluster). For each ordered pair of phrases, the program assigns a probability that is the pro"
C10-2017,W04-3219,0,0.17067,"Missing"
C10-2017,I05-5011,0,0.0285692,"etween different forms to keep the most fit. For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) by selecting the shortest paraphrase. They can help human writers by proposing alternatives and having them choose the most appropriate (Max and Zock, 2008). Paraphrases can also be used to improve natural language processing (NLP) systems. In this direction, (Callison-Burch et al., 2006) tried to improve machine translations by enlarging the coverage of patterns that can be translated. In the same way, most NLP systems like information retrieval (Sekine, 2005) or questionanswering (Duclaye et al., 2003), based on pattern recognition, can be improved by a paraphrase generator. Most of these applications need a n-best set of solutions in order to rerank them according to a task-specific criterion. In order to produce the paraphrases, a promising approach is to see the paraphrase generation problem as a statistical translation problem. In that approach, the target language becomes the same as the source language (Quirk et al., 2004; Bannard and Callison-Burch, 2005; Max and Zock, 2008). The first difficulty of this approach is the need of a paraphrase"
C10-2017,N03-1017,0,0.00503365,"e generated by applying to the source sentence the sequences of transformations {T 1, T 2} , {T 1, T 4, T 5} or even {T 5, T 1, T 4} ... Example 1 Decoding Source sentence: The dog runs after the young cat. Paraphrase table excerpt: T1: P(the beast |the dog) = 0.8 T2: P(the kitten |the young cat) = 0.7 T3: P(after it |after the) = 0.4 T4: P(the |the young) = 0.05 T5: P(cat |kitten) = 0.1 Some possible generated paraphrases: P1: the beast runs after the young cat. P2: *the dog runs after it young cat. True Score Computing P3: the beast runs after the kitten. Context The phrase based SMT model (Koehn et al., 2003) can be transposed to paraphrase generation as follows: ∗ We define the score of a potential paraphrase t following a segmentation I as: ZtI = P (t) t = arg max P (t) × P (s|t, B) Y i∈I t where s is the source sentence, t the target sentence i.e. the paraphrase, t∗ the best paraphrase and B a model of the noisy channel between the P (sIi |tIi , B) The true score of a potential paraphrase t is defined as: Zt∗ = max ZtI 145 I Because of high-dimension problems, decoders apply sub-optimal algorithms to search for t∗ . They produce estimated solutions over all possible paraphrases t and over all p"
C94-1102,1992.tmi-1.12,0,0.0383021,"Missing"
C94-1102,C90-3101,0,0.0669585,"Missing"
C94-1102,C90-3044,0,0.061769,"Missing"
C94-1102,C88-1013,0,\N,Missing
C96-2121,C90-3101,0,0.473363,"Missing"
C96-2121,1993.tmi-1.5,0,0.295121,"Missing"
C98-1116,C96-1046,0,0.0284826,"Missing"
C98-1116,C96-2121,1,0.879004,"Missing"
C98-1116,C94-1037,0,0.0585651,"Missing"
C98-1116,C90-3101,0,0.0189153,"Missing"
C98-1116,P97-1055,0,\N,Missing
F12-2009,C88-1016,0,0.755749,"Missing"
F12-2009,J93-2003,0,0.0485365,"Missing"
F12-2009,A94-1006,0,0.396761,"Missing"
F12-2009,P07-1003,0,0.0485499,"Missing"
F12-2009,H05-1022,0,0.0483634,"Missing"
F12-2009,J93-1003,0,0.367015,"Missing"
F12-2009,D07-1006,0,0.0354864,"Missing"
F12-2009,C94-2178,0,0.315955,"Missing"
F12-2009,P98-1069,0,0.213132,"Missing"
F12-2009,H91-1026,0,0.660246,"Missing"
F12-2009,P08-1112,0,0.0401714,"Missing"
F12-2009,W08-0509,0,0.0397229,"Missing"
F12-2009,D07-1103,0,0.0539592,"Missing"
F12-2009,2005.mtsummit-papers.11,0,0.0929043,"Missing"
F12-2009,P07-2045,0,0.0105362,"Missing"
F12-2009,N03-1017,0,0.0377534,"Missing"
F12-2009,N06-1014,0,0.0864734,"Missing"
F12-2009,Y11-1016,1,0.752487,"Missing"
F12-2009,W02-1018,0,0.0583631,"Missing"
F12-2009,J00-2004,0,0.057226,"Missing"
F12-2009,W04-3243,0,0.0800367,"Missing"
F12-2009,W05-0801,0,0.0483887,"Missing"
F12-2009,P03-1021,0,0.0178865,"Missing"
F12-2009,J03-1002,0,0.0268946,"Missing"
F12-2009,P02-1040,0,0.0929894,"Missing"
F12-2009,J96-1001,0,0.158519,"Missing"
F12-2009,2006.amta-papers.25,0,0.038671,"Missing"
F12-2009,2005.mtsummit-papers.33,0,0.103911,"Missing"
F12-2009,C96-2141,0,0.473813,"Missing"
F12-2009,J97-3002,0,0.135811,"Missing"
I05-5008,2004.iwslt-evaluation.1,0,0.0818063,"Missing"
I05-5008,P04-1079,0,0.0400102,"Missing"
I05-5008,N03-1003,0,0.163702,"Missing"
I05-5008,P98-1120,1,0.811245,"irst analogy of Table 3, one gets the following analogical equation, that is solved as indicated. A beer, please. by the following paraphrase detected during the first phase: I’d like a beer, please. : Can I have a beer? :: I’d like a slice of pizza, please. : x ⇒ x = Can I have a slice of pizza? A bottle of beer, please. It is then legitimate to say that the produced sentence: produces the unfortunate sentence: ∗A Can I have a slice of pizza? bottle of slice of pizza, please. Moreover, as no complete and valid formalisation of linguistic analogies has yet been proposed, the algorithm used (L EPAGE, 1998) may deliver such unacceptable strings as: is a paraphrase of the seed sentence (see Table 4). Such a method alleviates the problem of creating templates from examples which would be 59 43 43 43 28 5 5 4 2 2 2 1 1 Could we have a table in the corner? I’d like a table in the corner. We would like a table in the corner. Can we have a table in the corner? Can I get a table in the corner? In the corner, please. We’d like to sit in the corner. I’d like to sit in the corner. I would like a table in the corner. We’d like a table in the corner. I’d prefer a table in the corner. I prefer a table in the"
I05-5008,N03-1020,0,0.0964648,"Missing"
I05-5008,Y03-1042,0,0.0181923,"se generation. Any given sentence may share commutations with other sentences of the corpus. Such commutations are best seen in analogical relations that explicit syntagmatic and paradigmatic variations (de S AUSSURE, 1995, part 3, chap 4). For instance, the seed sentence In a first phase we initialise our data by paraphrase detection. By definition, paraphrase is an equivalence in meaning, thus, different sentences having the same translation ought to be considered equivalent in meaning, i.e., they are paraphrases2 . As the linguistic resource used 2 This is basically the same approach as (O HTAKE and YAMAMOTO, 2003, p. 3 and 4). A slice of pizza, please. 58 I’d like a beer, : A beer, please. please. :: A slice of pizza, I’d like a slice of : please. pizza, please. I’d like a twin, : A twin, please. please. :: I’d like a slice of A slice of pizza, : pizza, please. please. A slice of pizza, I’d like a slice of A bottle of red I’d like a bottle of : :: : please. pizza, please. wine, please. red wine, please. Table 3: Some analogies formed with sentences of the linguistic resource that show commutations with the sentence A slice of pizza, please. (i) I’d like a beer, : A beer, please. please. :: I’d like a"
I05-5008,P02-1040,0,\N,Missing
I05-5008,C98-1116,1,\N,Missing
K18-3003,L18-1171,1,0.835537,"Missing"
K18-3003,N15-1107,0,0.024114,"l in lower resources settings, although it still cannot beat the other systems. In the end, for the low resources setting, our holistic approach performs best in comparison to the baseline and the neural approach (even with data augmentation). 1 • The hand-engineered rule-based approach offers a high accuracy but costs time during construction. It usually faces the world coverage problem and is language-dependent. • The supervised approach automatically induces the rules from a given training data and applies the best rules to generate the target forms by using some classification techniques (Ahlberg et al., 2015). It is practically language independent and relatively easier to build. However, the data sparsity is an issue. • The neural approach is the model which triumphed in the task recently, especially the RNN encoder-decoder model (Kann and Schütze, 2016; Makarov et al., 2017). Some drawbacks of this approach are very long training times and the need for a large amount of training data. Introduction Lemma: Target MSDs: Target form: illustrate V;V.PTCP;PRS illustrating This paper describes the systems we developed for the CoNLL–SIGMORPHON 2018 Shared Task 1 (Cotterell et al., 2018). The recent succ"
K18-3003,W08-2001,0,0.0350024,"fixes remembered by the baseline system from the training data. It memorizes all changes from lemma into target form in various character length. ⇒ x = formq Proportional analogy Analogy is a relationship between four objects: A, B, C, and D usually noted as A : B :: C : D . It states that A is to B as C is to D where the ratio between A and B is the same as the ratio between C and D. Here, we consider analogy as a possible way to explain derivation between words as it is already used from the ancient Greek and Latin grammatical tradition up to recent works on computational linguistics, like (Hathout, 2008, 2009). Various formalisations of analogy have been proposed in (Yvon, 2003; Lepage, 2004; Stroppa and Yvon, 2005). In this work, we select the following definition2 .  d(A, B) = d(C, D)    d(A, C) = d(B, D) A : B :: C : D ⇒ |A|a + |D|a = |B|a + |C|a ,    ∀a (1) We can construct analogical grids (Fam and Lepage, 2017b, 2018) to give a compact view of different analogies that emerge from a set of words contained in a corpus. An analogical grid is a MxN matrix of words. The special property of this matrix is that any four words from two rows and two columns is an analogy (see Formula 2)."
K18-3003,K17-2002,0,0.0462657,";SG amoindrît prefix lemma target form root amoindr amoindr suffix ir ît • Insertion and substitution at the same time Language: Lemma: Target MSDs: Target form: Simple data augmentation lemma target form Preliminary results show that the neural approach suffers from the lack of data. To tackle this problem, we perform a simple data augmentation which artificially creates additional training data from evidences seen in the original training data. Additional training data is expected to bring improvement to the performance of our model, especially on low data situation (Kann and Schütze, 2017; Bergmanis et al., 2017; Silfverberg et al., 2017; Zhou and Neubig, 2017; Nicolai et al., 2017). German einschließen V;SBJV;PST;2;SG schlössest ein prefix ein root schl schl suffix ießen össest ein Figure 4: Illustrations of rules extraction for data augmentation: simple insertion (Irish); substitution (French); insertion and substitution at the same time (German). example, happens for regular past form in English where you add only -d as suffix for lemmata ended with e, instead of adding -ed At a glance, it looks similar to how the baseline system extracts the affix rules. However, we only memorize the left (prefix"
K18-3003,D14-1179,0,0.0441581,"Missing"
K18-3003,K18-3001,0,0.135112,"Missing"
K18-3003,W16-2010,0,0.0600505,"he hand-engineered rule-based approach offers a high accuracy but costs time during construction. It usually faces the world coverage problem and is language-dependent. • The supervised approach automatically induces the rules from a given training data and applies the best rules to generate the target forms by using some classification techniques (Ahlberg et al., 2015). It is practically language independent and relatively easier to build. However, the data sparsity is an issue. • The neural approach is the model which triumphed in the task recently, especially the RNN encoder-decoder model (Kann and Schütze, 2016; Makarov et al., 2017). Some drawbacks of this approach are very long training times and the need for a large amount of training data. Introduction Lemma: Target MSDs: Target form: illustrate V;V.PTCP;PRS illustrating This paper describes the systems we developed for the CoNLL–SIGMORPHON 2018 Shared Task 1 (Cotterell et al., 2018). The recent success of neural approach encouraged us to implement a sequence-to-sequence (seq2seq) model to solve the task. Knowing that the neural approach tends to need a large amount of training data, we also consider another approach as a back-off, which is a ho"
K18-3003,D11-1057,0,0.0786242,"Missing"
K18-3003,L18-1293,0,0.107472,"Missing"
K18-3003,D15-1166,0,0.0209419,"s according to the given MSD pattern. We construct the analogical equation as follows: 5 Neural approach Following the recent success of neural approach in previous evaluation campaign, we implement a common architecture of seq2seq model. We treat the inflection task as the problem of translating the given target MSDs and lemma into target form. Thus, the input string for the example given in Figure 1 will be as follows. V V.PTCP PRS i l l u s t r a t e 5.1 Seq2seq model Our model is a standard seq2seq model with attention mechanism inspired from the one which is used for machine translation (Luong et al., 2015). The difference is that we consider a character or MSD as one token, instead of a word. Each token (character) is represented by a continuous vector representation learned in the embedding layer. We use a bi-directional Gated Recurrent Unit (GRU) cell (Cho et al., 2014) which is a variation of Long Short-Term Memory (LSTM) cell (Hochreiter and Schmidhuber, 1997) that tries to solve the vanishing gradient problem. Our decoder is two layers of uni-directional GRU cell with attention mechanism. There are various imlemmat : formt :: illustrate : formq taken from the first and second column of the"
K18-3003,K17-2008,0,0.0344622,"• Insertion and substitution at the same time Language: Lemma: Target MSDs: Target form: Simple data augmentation lemma target form Preliminary results show that the neural approach suffers from the lack of data. To tackle this problem, we perform a simple data augmentation which artificially creates additional training data from evidences seen in the original training data. Additional training data is expected to bring improvement to the performance of our model, especially on low data situation (Kann and Schütze, 2017; Bergmanis et al., 2017; Silfverberg et al., 2017; Zhou and Neubig, 2017; Nicolai et al., 2017). German einschließen V;SBJV;PST;2;SG schlössest ein prefix ein root schl schl suffix ießen össest ein Figure 4: Illustrations of rules extraction for data augmentation: simple insertion (Irish); substitution (French); insertion and substitution at the same time (German). example, happens for regular past form in English where you add only -d as suffix for lemmata ended with e, instead of adding -ed At a glance, it looks similar to how the baseline system extracts the affix rules. However, we only memorize the left (prefix candidate) and right part (suffix candidate), not all of the possible a"
K18-3003,K17-2010,0,0.104447,"ma target form root amoindr amoindr suffix ir ît • Insertion and substitution at the same time Language: Lemma: Target MSDs: Target form: Simple data augmentation lemma target form Preliminary results show that the neural approach suffers from the lack of data. To tackle this problem, we perform a simple data augmentation which artificially creates additional training data from evidences seen in the original training data. Additional training data is expected to bring improvement to the performance of our model, especially on low data situation (Kann and Schütze, 2017; Bergmanis et al., 2017; Silfverberg et al., 2017; Zhou and Neubig, 2017; Nicolai et al., 2017). German einschließen V;SBJV;PST;2;SG schlössest ein prefix ein root schl schl suffix ießen össest ein Figure 4: Illustrations of rules extraction for data augmentation: simple insertion (Irish); substitution (French); insertion and substitution at the same time (German). example, happens for regular past form in English where you add only -d as suffix for lemmata ended with e, instead of adding -ed At a glance, it looks similar to how the baseline system extracts the affix rules. However, we only memorize the left (prefix candidate) and right part"
K18-3003,W05-0616,0,0.0645715,"target form in various character length. ⇒ x = formq Proportional analogy Analogy is a relationship between four objects: A, B, C, and D usually noted as A : B :: C : D . It states that A is to B as C is to D where the ratio between A and B is the same as the ratio between C and D. Here, we consider analogy as a possible way to explain derivation between words as it is already used from the ancient Greek and Latin grammatical tradition up to recent works on computational linguistics, like (Hathout, 2008, 2009). Various formalisations of analogy have been proposed in (Yvon, 2003; Lepage, 2004; Stroppa and Yvon, 2005). In this work, we select the following definition2 .  d(A, B) = d(C, D)    d(A, C) = d(B, D) A : B :: C : D ⇒ |A|a + |D|a = |B|a + |C|a ,    ∀a (1) We can construct analogical grids (Fam and Lepage, 2017b, 2018) to give a compact view of different analogies that emerge from a set of words contained in a corpus. An analogical grid is a MxN matrix of words. The special property of this matrix is that any four words from two rows and two columns is an analogy (see Formula 2). We also count the number of rules found in the dataset (see the last two rows in Table 1). These rules are not the"
K18-3003,K17-2005,0,0.106793,"r amoindr suffix ir ît • Insertion and substitution at the same time Language: Lemma: Target MSDs: Target form: Simple data augmentation lemma target form Preliminary results show that the neural approach suffers from the lack of data. To tackle this problem, we perform a simple data augmentation which artificially creates additional training data from evidences seen in the original training data. Additional training data is expected to bring improvement to the performance of our model, especially on low data situation (Kann and Schütze, 2017; Bergmanis et al., 2017; Silfverberg et al., 2017; Zhou and Neubig, 2017; Nicolai et al., 2017). German einschließen V;SBJV;PST;2;SG schlössest ein prefix ein root schl schl suffix ießen össest ein Figure 4: Illustrations of rules extraction for data augmentation: simple insertion (Irish); substitution (French); insertion and substitution at the same time (German). example, happens for regular past form in English where you add only -d as suffix for lemmata ended with e, instead of adding -ed At a glance, it looks similar to how the baseline system extracts the affix rules. However, we only memorize the left (prefix candidate) and right part (suffix candidate), no"
L18-1068,C12-1023,0,0.0206631,"ts training the best model on subsets of the training data to investigate how much annotation data is needed to achieve good results. 4.3.1. Baseline Models The General SVM Models described in the previous section incorporate a comprehensive set of word features, which is practical only because we have a sufficiently large labeled dataset for training. Since such a resource is often lacking, many previous approaches have often used only one or two features as proxies for word complexity. Most commonly, word frequency, word length, or some combination thereof has been used, such as was done in Bott et al. (2012). For L2 learners, however, defining word complexity by the word’s level of first occurance within a graded corpus may produce more accurate results, as was investigated by Tack et al. (2016). To determine if similar results could be achieved with these approaches, we build three baseline models in the same manner described in the previous section, but using only the word features proposed by these approaches: one using only log inverse word frequency, one using both log inverse word frequency and word length, and one using word level within a graded corpus. For the last of these, we use the T"
L18-1068,P13-3015,0,0.0255796,"Missing"
L18-1068,L16-1035,0,0.459244,"n the previous section incorporate a comprehensive set of word features, which is practical only because we have a sufficiently large labeled dataset for training. Since such a resource is often lacking, many previous approaches have often used only one or two features as proxies for word complexity. Most commonly, word frequency, word length, or some combination thereof has been used, such as was done in Bott et al. (2012). For L2 learners, however, defining word complexity by the word’s level of first occurance within a graded corpus may produce more accurate results, as was investigated by Tack et al. (2016). To determine if similar results could be achieved with these approaches, we build three baseline models in the same manner described in the previous section, but using only the word features proposed by these approaches: one using only log inverse word frequency, one using both log inverse word frequency and word length, and one using word level within a graded corpus. For the last of these, we use the TOPIK exams as our graded corpus. 4.3.2. Model Evaluation Metrics Each of these models predict the probability that a given word is unknown by a given reader. Since the cost of misclassifying"
L18-1171,W08-2001,0,0.783894,"s, like the one shown in Figure 2 (left) which is taken from a French & English dictionary (Mansion, 1981, grey section, p. 1). Analogical grids are not paradigm tables, but they also give a compact view on the organization of a lexicon up to a certain extent (see below, Section 2.1.). Analogical grids are the result of an empirical procedure. They may be seen as a preliminary step towards the production of paradigm tables. Figure 2 (right) shows an example of an analogical grid in English. They can be used to study the productivity of a language (Singh and Ford, 2000; Neuvel and Fulop, 2002; Hathout, 2008). Fam and Lepage (2016) performed such an analysis across 12 languages using analogical grids built from the Bible corpus (Christodouloupoulos, 2015). As another example of use, Hathout (2009) showed how to produce the French word form rectification by analogy from the neighboring word forms fructifier, fructification, and rectifier in the same series (see Figure 1). rectifier fructification family —————— 2. Main Usages of the Tools Released We release an implementation of previously presented algorithms to produce analogical grids as a Python 2 module1 called Nlg. The various algorithms have"
L18-1171,P98-1120,1,0.787166,"rformed such an analysis across 12 languages using analogical grids built from the Bible corpus (Christodouloupoulos, 2015). As another example of use, Hathout (2009) showed how to produce the French word form rectification by analogy from the neighboring word forms fructifier, fructification, and rectifier in the same series (see Figure 1). rectifier fructification family —————— 2. Main Usages of the Tools Released We release an implementation of previously presented algorithms to produce analogical grids as a Python 2 module1 called Nlg. The various algorithms have been presented elsewhere (Lepage, 1998; Lepage, 2014; Fam and Lepage, 2016). One particular program called Words2Grids in this module simply takes a list of word forms as input and delivers a list of analogical grids. Each word form in the list is converted into a feature vector before analogical grids are constructed from such feature vectors. The module also provides another program, Words2Vectors, to produce feature vector representations either directly from word forms or from descriptions of word forms. The following sections introduce several ways to use the Python module. 2.1. From Word Forms to Analogical Grids The default"
L18-1171,W02-0604,0,0.015446,"rom lexemes and exponents, like the one shown in Figure 2 (left) which is taken from a French & English dictionary (Mansion, 1981, grey section, p. 1). Analogical grids are not paradigm tables, but they also give a compact view on the organization of a lexicon up to a certain extent (see below, Section 2.1.). Analogical grids are the result of an empirical procedure. They may be seen as a preliminary step towards the production of paradigm tables. Figure 2 (right) shows an example of an analogical grid in English. They can be used to study the productivity of a language (Singh and Ford, 2000; Neuvel and Fulop, 2002; Hathout, 2008). Fam and Lepage (2016) performed such an analysis across 12 languages using analogical grids built from the Bible corpus (Christodouloupoulos, 2015). As another example of use, Hathout (2009) showed how to produce the French word form rectification by analogy from the neighboring word forms fructifier, fructification, and rectifier in the same series (see Figure 1). rectifier fructification family —————— 2. Main Usages of the Tools Released We release an implementation of previously presented algorithms to produce analogical grids as a Python 2 module1 called Nlg. The various"
L18-1171,P15-2111,0,0.0167463,"is N N (A)     is P RST (A)     ..   . is P T CP (A) From Morphological Features to Paradigm tables The previous use of the released tools automatically converts word forms into specific feature vectors. In opposition to that, it is possible for the user to produce real paradigm tables from feature vectors standing for actual morphological features, like lemma, part-of-speech, case, tense. Such feature vectors can be built, for instance, from the Unimorph Project (Kirov et al., 2016) data which have been built from parsing Wiktionary data into a languageindependent feature schema (Sylak-Glassman et al., 2015b; Sylak-Glassman et al., 2015a). Formula (3) illustrates the representation of the word form walking: its lemma is to walk and it has the verb (VB), present (PRST), participle (PTCP) tags as morphological features. For the purpose of inner processing, the labels are converted into Boolean values.     lemma = ”to walk”(A) 1  1  is V B(A)       0 is N N (A)     A=  walking =  1  is P RST (A)        .. ..   .  . is P T CP (A) 1 (3) Figure 3 shows an example of a paradigm table built from a list of word forms described by morphological features. For some lemmas"
lardilleux-etal-2010-bilingual,nerima-wehrli-2008-generating,0,\N,Missing
lardilleux-etal-2010-bilingual,1994.amta-1.26,0,\N,Missing
lardilleux-etal-2010-bilingual,W95-0115,0,\N,Missing
lardilleux-etal-2010-bilingual,W95-0114,0,\N,Missing
lardilleux-etal-2010-bilingual,J93-2003,0,\N,Missing
lardilleux-etal-2010-bilingual,C02-2020,0,\N,Missing
lardilleux-etal-2010-bilingual,C96-2141,0,\N,Missing
lardilleux-etal-2010-bilingual,C94-2178,0,\N,Missing
lardilleux-etal-2010-bilingual,C94-1048,0,\N,Missing
lardilleux-etal-2010-bilingual,2001.mtsummit-papers.10,0,\N,Missing
lardilleux-etal-2010-bilingual,P07-2045,0,\N,Missing
lardilleux-etal-2010-bilingual,J03-1002,0,\N,Missing
lardilleux-etal-2010-bilingual,R09-1040,1,\N,Missing
lardilleux-etal-2010-bilingual,W08-0509,0,\N,Missing
lardilleux-etal-2010-bilingual,N06-1014,0,\N,Missing
lepage-peralta-2004-using,P98-1120,1,\N,Missing
lepage-peralta-2004-using,C98-1116,1,\N,Missing
luo-lepage-2014-production,2007.mtsummit-papers.36,0,\N,Missing
luo-lepage-2014-production,D07-1103,0,\N,Missing
luo-lepage-2014-production,J93-2003,0,\N,Missing
luo-lepage-2014-production,C96-2141,0,\N,Missing
luo-lepage-2014-production,P07-2045,0,\N,Missing
luo-lepage-2014-production,P07-1039,0,\N,Missing
luo-lepage-2014-production,W05-0801,0,\N,Missing
luo-lepage-2014-production,P11-1064,0,\N,Missing
luo-lepage-2014-production,2008.amta-papers.14,0,\N,Missing
luo-lepage-2014-production,N03-1017,0,\N,Missing
luo-lepage-2014-production,H91-1026,0,\N,Missing
luo-lepage-2014-production,R09-1040,1,\N,Missing
luo-lepage-2014-production,2012.eamt-1.59,0,\N,Missing
luo-lepage-2014-production,P98-1004,0,\N,Missing
luo-lepage-2014-production,C98-1004,0,\N,Missing
luo-lepage-2014-production,2005.mtsummit-papers.11,0,\N,Missing
luo-lepage-2014-production,lardilleux-etal-2010-bilingual,1,\N,Missing
luo-lepage-2014-production,W10-1712,0,\N,Missing
luo-lepage-2014-production,P00-1056,0,\N,Missing
luo-lepage-2014-production,W08-0509,0,\N,Missing
luo-lepage-2014-production,P03-1021,0,\N,Missing
luo-lepage-2014-production,N13-1073,0,\N,Missing
luo-lepage-2014-production,N06-1014,0,\N,Missing
N16-2012,W11-2123,0,0.0421781,"Missing"
N16-2012,P07-2045,0,0.00458598,"Missing"
N16-2012,Y12-1012,0,\N,Missing
N16-2012,W15-5005,0,\N,Missing
O14-1019,Y10-1047,0,0.0258368,"technical words contained in United States Patent and Trademark Office (USPTO) and Japan Patent Office (JPO) in terms of lexical variation, lexical density and lexical sophistication, in brief, highlights distributional similarity of technical genre, and in particular, distibutional difference of academic and general genres. Keywords: Patent Translation, Native Characterization, Corpus, Co-Occurrence. 1. Introduction As globalization has resulted in rapid greater economic growth, the challenges of interdisciplinary interaction in pursuit of precise patent writing have incredibly increased. In Lin and Hsieh (2010a), English patent documents were statistically extracted and computationally examined from LexisNexis Academic, a database for legal professionals. They compiled a reference corpus of independent claim texts and lay the focus on their collocation features. Mutual information is attainable with the help of selectional collocation features underlining specific clausal types represented in natural language processing of patent specification. While their work appears to fill a niche in the ESP (English for Specific Purposes) field (and particularly in the English for Occupational Legal Purposes),"
O14-1019,O11-4005,0,0.0336145,"rs to fill a niche in the ESP (English for Specific Purposes) field (and particularly in the English for Occupational Legal Purposes), Lin and Hsieh (2010b) further compiled a modern patent language technical term list with statistical-retrieval methodologies as a mandatory  Graduate School of Information, Production, and Systems, Waseda University, Japan. E-mail: nobuhiro602@toki.waseda.jp; yves.lepage@waseda.jp 185 approach. The research content and statistical investigations assist patent attorneys expand the vocabulary size for the advancement of patent writing at an international level. Lin and Hsieh (2011) proposed a mixed-method approach to detecting scholarly discourse in patent technical documents. The Patent Technical Word Corpus (hereafter PTWC), containing 16 million word tokens, was compiled to elucidate the underpinning principles in identifying discourse elements, text-structure components, and the location of references. Whereas most existing IPR (intellectual property rights) databases accessible for information retrieval, the creation of PTWC, based on corpus-statistics and text-processing technology, refines more decisive characteristics of terminological knowledge as potential con"
O14-1019,P05-1016,0,0.0370757,"77 representative 72519 18 specification 18102 Request (PCT) 70606 19 classification 16977 application 20 62027 independent claim 15513 (patent) 187 3. Methodology 3.1 The Distributional Hypothesis Sahlgren (2008:33) maintains that distributional approaches to meaning acquisition utilize distributional properties of linguistic entities as the building blocks of semantics. This hypothesis is often stated in terms like words which are similar in meaning occur in similar contexts (Rubenstein & Goodenough, 1965). In other words, words that occur in the same contexts tend to have similar meanings (Pantel, 2005). 3.2 Corpus Preparation Transitional phrases in patent application were used to specify whether the claim is limited to only the elements listed, or whether the claim may cover items or processes that have additional elements. The most common transitional phrase used is the open-ended phrase &quot;comprising&quot;. However, many claims use closed-ended language such as &quot;consisting of&quot;. In this regards, we retrieve co-occurring information containing &quot;comprising&quot; and &quot;consisting of” from LexisNexis Academic for corpus preparation. Table 3 shows the structure for the corpus creation. Table 3. Genre-based"
P09-2063,P05-1074,0,0.72792,"nd Lee, 2003) with the aim of selecting the shortest paraphrase. Paraphrases can also be used to improve natural language processing (NLP) systems. (CallisonBurch et al., 2006) improved machine translations by augmenting the coverage of patterns that can be translated. Similarly, (Sekine, 2005) improved information retrieval based on pattern recognition by introducing paraphrase generation. In order to produce paraphrases, a promising approach is to see the paraphrase generation problem as a translation problem, where the target language is the same as the source language (Quirk et al., 2004; Bannard and Callison-Burch, 2005). A problem that has drawn less attention is the generation step which corresponds to the decoding 2 Statistical paraphrase generation using transformation rules The paraphrase generation problem can be seen as an exploration problem. We seek the best paraphrase according to a scoring function in a space 249 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 249–252, c Suntec, Singapore, 4 August 2009. 2009 ACL and AFNLP We propose a variation of the UCT algorithm for paraphrase generation named MCPG for MonteCarlo based Paraphrase Generation. The main part of the algorithm is t"
P09-2063,N03-1003,0,0.107239,"Viterbi based decoders. It is now possible to use some global features in paraphrase scoring functions. This algorithm opens new outlooks for paraphrase generation and other natural language processing applications like statistical machine translation. 1 Introduction A paraphrase generation system is a program which, given a source sentence, produces a different sentence with almost the same meaning. Paraphrase generation is useful in applications to choose between different forms to keep the most appropriate one. For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) with the aim of selecting the shortest paraphrase. Paraphrases can also be used to improve natural language processing (NLP) systems. (CallisonBurch et al., 2006) improved machine translations by augmenting the coverage of patterns that can be translated. Similarly, (Sekine, 2005) improved information retrieval based on pattern recognition by introducing paraphrase generation. In order to produce paraphrases, a promising approach is to see the paraphrase generation problem as a translation problem, where the target language is the same as the source language (Quirk et al., 2004; Bannard and C"
P09-2063,N06-1003,0,0.399695,"Missing"
P09-2063,P07-2045,0,0.00410627,"for which there is no strong evaluation function. For the same reasons, this algorithm sounds interesting for paraphrase generation. In particular, it does not put constraint on the scoring function. 4 Experimental context This section describes the experimental context and the methodology followed to evaluate our statistical paraphrase generation tool. 4.1 Data For the experiment reported in section 5, we use one of the largest, multi-lingual, freely available aligned corpus, Europarl (Koehn, 2005). It consists of European parliament debates. We choose 250 decoder. We use the MOSES decoder (Koehn et al., 2007) as a baseline. The MOSES scoring function is set by four weighting factors αΦ , αLM , αD , αW . Conventionally, these four weights are adjusted during a tuning step on a training corpus. The tuning step is inappropriate for paraphrase because there is no such tuning corpus available. We empirically set αΦ = 1, αLM = 1, αD = 10 and αW = 0. Hence, the scoring function (or reward function for MCPG) is equivalent to: French as the language for paraphrases and English as the pivot language. For this pair of languages, the corpus consists of 1, 487, 459 French sentences aligned with 1, 461, 429 Eng"
P09-2063,2005.mtsummit-papers.11,0,0.0109286,"wledge to evaluate states. These properties make it ideally suited for games with high branching factor and for which there is no strong evaluation function. For the same reasons, this algorithm sounds interesting for paraphrase generation. In particular, it does not put constraint on the scoring function. 4 Experimental context This section describes the experimental context and the methodology followed to evaluate our statistical paraphrase generation tool. 4.1 Data For the experiment reported in section 5, we use one of the largest, multi-lingual, freely available aligned corpus, Europarl (Koehn, 2005). It consists of European parliament debates. We choose 250 decoder. We use the MOSES decoder (Koehn et al., 2007) as a baseline. The MOSES scoring function is set by four weighting factors αΦ , αLM , αD , αW . Conventionally, these four weights are adjusted during a tuning step on a training corpus. The tuning step is inappropriate for paraphrase because there is no such tuning corpus available. We empirically set αΦ = 1, αLM = 1, αD = 10 and αW = 0. Hence, the scoring function (or reward function for MCPG) is equivalent to: French as the language for paraphrases and English as the pivot lang"
P09-2063,W04-3219,0,0.207055,"Missing"
P09-2063,I05-5011,0,0.110962,"system is a program which, given a source sentence, produces a different sentence with almost the same meaning. Paraphrase generation is useful in applications to choose between different forms to keep the most appropriate one. For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) with the aim of selecting the shortest paraphrase. Paraphrases can also be used to improve natural language processing (NLP) systems. (CallisonBurch et al., 2006) improved machine translations by augmenting the coverage of patterns that can be translated. Similarly, (Sekine, 2005) improved information retrieval based on pattern recognition by introducing paraphrase generation. In order to produce paraphrases, a promising approach is to see the paraphrase generation problem as a translation problem, where the target language is the same as the source language (Quirk et al., 2004; Bannard and Callison-Burch, 2005). A problem that has drawn less attention is the generation step which corresponds to the decoding 2 Statistical paraphrase generation using transformation rules The paraphrase generation problem can be seen as an exploration problem. We seek the best paraphrase"
P98-1120,C96-1046,0,0.0311443,"Missing"
P98-1120,C96-2121,1,0.904284,"Missing"
P98-1120,C94-1037,0,0.0573522,"Missing"
P98-1120,C90-3101,0,0.0194384,"Missing"
P98-1120,P97-1055,0,\N,Missing
R09-1040,Y99-1030,0,0.0176514,"shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages) always required pair-by-pair processing of languages"
R09-1040,J93-2003,0,0.0149442,"s high quality multi-word alignments from sentence-aligned multilingual parallel corpora. Unlike other methods, it exploits low frequency terms, which makes it highly scalable. As it relies on alingual concepts, it can process any number of languages at once. Experiments have shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two l"
R09-1040,P06-2035,0,0.0275594,"shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages) always required pair-by-pair processing of languages"
R09-1040,P03-1011,0,0.00897994,"can process any number of languages at once. Experiments have shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages)"
R09-1040,2005.mtsummit-papers.11,0,0.0221284,"|e) W (e, g|f ) W (e, f |g) loud vifs ↔ ↔ applause applaudissements lebhafter beifall 122 0.730 0.760 0.826 0.936 0.995 0.990 loud vifs ↔ ↔ applaudissements applause starker beifall 24 0.144 0.143 0.820 0.936 0.995 0.895 loud vifs ↔ ↔ applause applaudissements ( lebhafter beifall ) 12 0.072 0.092 0.667 0.936 0.995 0.060 loud applaudissements ↔ ↔ applause prolong´ es lebhafter beifall 8 0.048 0.167 0.048 0.916 0.995 0.990 beifall 1 0.006 0.000 0.006 0.836 1.000 0.991 loud ↔ applause ↔ Table 1: Alignments of the English word sequence “loud applause” obtained from a sample of the Europarl corpus [7], along with their associated scores. Second, as we start without any word-to-word alignment, we estimate a simple lexical translation probability distribution D based on relative word frequencies from the input corpus: D(wj |wi ) = C(wi , wj ) C(wi ) where wi is a word in language i and wj is a word in language j (i 6= j). Lastly, the sampling-based approach does not link words, as would statistical models do. For example, in the first alignment of Table 1, one would expect English “loud” to link to French “vifs,” and “applause” to “applaudissements.” Our method does not permit this; instead,"
R09-1040,P07-2045,0,0.00985011,"Missing"
R09-1040,N03-1017,0,0.103076,"equences of words. They can subsequently be filtered according to specific criteria, like word contiguity, number of languages covered, or the number of words in a given language. 4 Scoring alignments We propose two ways to score multilingual alignments by generalizing two well-known bilingual scoring techniques to the case of multilingual contexts. 4.1 Translation probabilities Translation probabilities reflect the probability that some monolingual sequence of words of a multilingual alignment translates into the sequences of words in the remaining languages. We use the principle proposed in [9] to compute phrase translation probabilities, except 216 that we generalize it to multilingual contexts: since there is no “source” and “target” languages in our multilingual alignments, each language becomes the “source” in turn, and all remaining languages together become a single “target” one. In other words, assuming an input corpus in L languages, a score is computed for each language i (1 ≤ i ≤ L). It is the probability that the sequence of words si generates the rest of the alignment. It is computed by dividing the count of the current multilingual alignment, C(s1 , . . . , sL ), by the"
R09-1040,2008.amta-papers.11,1,0.774489,"the input corpus. However, rather than setting in advance some particular degree of coverage (hence imposing a fixed number of subcorpora to process), we deduce from the above result a probability distribution to randomly draw the sizes of the subcorpora to process: p(k) = −1 k log (1 − k/n) (to be normalized) The numerator (log t) was substituted for −1 because t is a constant: t ≤ 1 ⇒ log t ≤ 0. This distribution highly favors small subcorpora. Experiments have shown that they provide more accurate and more numerous alignments than large subcorpora, in addition to be much faster to process [11]. Input corpus: 1 2 3 English French German One coffee , please . ↔ Un caf´ e , s’il vous plaˆıt . ↔ Einen Kaffee , bitte . This coffee is not bad . ↔ Ce caf´ e est correct . ↔ Dieser Kaffee ist nicht schlecht . One strong tea . ↔ Un th´ e fort . ↔ Einen starken Tee . ⇓ “Perfect alignments:” One coffee , please . This is not bad strong tea The words: ↔ Un ↔ Einen ↔ caf´ e ↔ Kaffee ↔ , s’il vous plaˆıt ↔ , bitte ↔ . ↔ . ↔ Ce est correct ↔ Dieser ist nicht schlecht ↔ th´ e fort ↔ starken Tee appear on lines: 13 12 1 123 2 3 Fig. 1: Extracting “perfect alignments” from a toy parallel corpus in En"
R09-1040,J00-2004,0,0.0386569,"can process any number of languages at once. Experiments have shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages)"
R09-1040,W05-0801,0,0.0774986,"can process any number of languages at once. Experiments have shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages)"
R09-1040,J03-1002,0,0.0165342,"al parallel corpora. Unlike other methods, it exploits low frequency terms, which makes it highly scalable. As it relies on alingual concepts, it can process any number of languages at once. Experiments have shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As"
R09-1040,P02-1040,0,0.101002,"Missing"
R09-1040,W99-0602,0,0.0548057,". All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages) always required pair-by-pair processing of languages [16]. But the quality of alignments is hindered when relying on “pivot” languages. • Traditional statistical methods may not scale up, nor even scale down [1]. Despite the growing availability of resources for numerous languages, some will probably never reach a coverage that could make them usable in real applications. On the other hand, huge amounts of input, while known to produce better results, quickly turn out to be a plague in processing time. • These models are generally complex. This makes them difficult to integrate in actual applications, unless some free tool is available. 2 2.1 Ration"
R09-1040,2005.eamt-1.39,0,0.0164952,"can process any number of languages at once. Experiments have shown that it is competitive with state-of-the-art methods. Keywords Sub-sentential alignment, low frequency term, hapax, sampling. 1 Motivation Sub-sentential alignment from parallel corpora covers a variety of applications, such as the constitution of lexical resources or machine translation. The widely used IBM models [2] and their extensions, implemented in the open source tool Giza++ [14], constitute the standard. Many alternatives or improvements have been proposed in the past years. Most of them are based on statistics, e.g. [6, 12, 13, 17], other ones are non-statistical methods, e.g. [1, 5]. All of them mainly address the issue of quality of alignments, i.e., getting as close to human judgment as possible, or making machine translation as efficient as possible. Yet quality is only one aspect of alignment. Other issues still deserve to be explored: • Some applications require alignments in more than two languages. This is particularly true for multilingual lexicography. As sub-sentential alignment was introduced as a bilingual problem since its early stages, obtaining truly multilingual alignments (in at least three languages)"
R09-1040,2007.iwslt-1.1,0,\N,Missing
W09-4618,C08-2013,0,0.0442003,"Missing"
W09-4618,J06-3003,0,0.0406428,"t), +1 (right) or 0 (not relevant) along this dimension. Such a vectorial space captures those oppositions that are relevant to the sentences of a corpus, thus revealing the linguistic features concealed in that corpus. Such a representation enables the use of any standard vectorial technique for any further desirable computation. The goal of this paper, and the object of the next sections, is not to present such further computations, but to show how it is possible to extract the dimensions defining the space from a corpus of short sentences. 2 2.1 Basic Notions Analogous Sentences We follow (Turney, 2006) for the basic notions used in this work: Verbal analogies are often written A : B :: C : D, meaning A is to B as C is to D, for example traffic : street :: water : riverbed. Following this author, when the relational similarity between two pairs of words is high, we say that the two pairs of words are analogous.2 In this paper, we concentrate on sentences and extend the notion of analogous pairs of words to analogous pairs of sentences. For instance, the two following pairs of sentences are said to be analogous: Do you have Do you have Smaller, Small, this in darker : this in dark :: : please"
W09-4618,C08-1114,0,0.32452,"Missing"
W09-4618,2007.iwslt-1.1,0,\N,Missing
W14-4712,C92-2082,0,0.224215,"compares the semantic relations between pairs of words. For example, fish : fins :: bird : wings asserts that fish is to fins as bird is to wings: i.e., the semantic relations between fish and fins are highly similar to the semantic relations between bird and wings. To find the relational similarity between two words, knowledge resources such as WordNet (Miller, 1995) or Ontology (Suchanek et al., 2007) are generally used. Lexical syntactic patterns between two words also help in identifying relational similarity. For instance, the lexical syntactic patten ‘is a’ helps to identify hypernyms (Hearst, 1992; Snow et al., 2004). To measure the attributional similarity between words or the relational similarity between word pairs, Vector Space Models (VSM) are mainly used (Turney, 2005; Turney and Littman, 2005; Turney, 2006). The expressiveness of a vector space model differs in the way it is built the matrices. The different way to build the matrices is based on two types of associations. In this paper, we use two types of associations which are well-known in linguistics: syntagmatic associations and paradigmatic associations. Syntagmatic associations originate from word co-occurrences in texts."
W14-4712,S12-1047,0,0.0237424,"matrices. The context window size is 2 for the paradigmatic features (prefixes and suffixes). The range of the syntagmatic feature (infixes) is from 1 to 5. The first experiment shown in Section 4.1 directly outputs a measure of the relational similarity. The second experiment, on SAT analogy quizzes in Section 4.2 uses relational similarity to rank candidates. In both experiments, we do not preprocess with stemming and do not delete stop words. 4.1 Direct measure of relational similarity To test our measure of relational similarity between word pairs, we make use of the SemEval-2012 task 2 (Jurgens et al., 2012). Jurgens et al. (2012) constructed a data set of prototypical ratings for 3,218 word pairs in 79 different relation categories with the help of Amazon Mechanical Turk2 . There are two phases for measuring the degree of relational similarity in this task. The first phase is to generate pairs of a given relation. We do not perform this phase here. Another phase is used to rate word pairs from given word pairs. This task selects least and most illustrative word pairs in four word pairs (“oak:tree”; “vegetable:carrot”; “tree:oak”; “currency:dollar”) based on several given word pairs (“flower:tuli"
W14-4712,N13-1090,0,0.0970879,"Missing"
W14-4712,E99-1010,0,0.0343658,"to reduce the problem of data sparseness. The practical goal of our proposal is to achieve reasonable performance in measuring relational similarity and semantic proportional analogy from a small corpus. We will show that even small corpora have a great potential to measure similarity in actual tasks. Building a pair-feature matrices in such a setting obviously leads to sparseness since word pairs do not easily co-occur in the sentences of small corpora. We use clustering methods to cluster words into equivalence classes to reduce the problem. Here, we make use of monolingual word clustering (Och, 1999)1 . This method is based on maximum-likelihood estimation with Markov model. We build our proposed pair-feature model described in Section 3.2 based on the results of word clustering. 3.2 Vector Space Model (VSM) VSM (Salton et al., 1975) is an algebraic model for representing any object as a vector of identifiers. There are many ways to build a semantic space, like term-document, term-context, and pair-pattern matrices (Turney and Pantel, 2010). Turney (2006) showed that pair-pattern matrices are suited to measuring the similarity of semantic relations between pairs of words; that is, relatio"
W14-4712,S12-1055,0,0.0391615,"Missing"
W14-4712,J06-3003,0,0.161406,"the semantic relations between bird and wings. To find the relational similarity between two words, knowledge resources such as WordNet (Miller, 1995) or Ontology (Suchanek et al., 2007) are generally used. Lexical syntactic patterns between two words also help in identifying relational similarity. For instance, the lexical syntactic patten ‘is a’ helps to identify hypernyms (Hearst, 1992; Snow et al., 2004). To measure the attributional similarity between words or the relational similarity between word pairs, Vector Space Models (VSM) are mainly used (Turney, 2005; Turney and Littman, 2005; Turney, 2006). The expressiveness of a vector space model differs in the way it is built the matrices. The different way to build the matrices is based on two types of associations. In this paper, we use two types of associations which are well-known in linguistics: syntagmatic associations and paradigmatic associations. Syntagmatic associations originate from word co-occurrences in texts. Latent Semantic Analysis (LSA) relies on such syntagmatic associations. It has been successful at simulating a wide range of psychological and psycholinguistic phenomena, from judgments of semantic similarity (Landauer a"
W14-4712,Q13-1029,0,0.0325821,"Missing"
W14-4712,N13-1120,0,0.0293058,"Missing"
W14-7010,2006.amta-papers.25,0,0.0652176,"Missing"
W14-7010,C04-1151,0,0.0244331,"olingual data. Furthermore, in SMT experiments performed on Chinese-Japanese, by adding this kind of data into the baseline training corpus, on the same test set, the evaluation scores of the translation results we obtained were significantly or slightly improved over the baseline systems. 1 Introduction Bilingual corpora are an essential resource for current SMT. So as to enlarge such corpora, technology research has been done in extracting parallel sentences from existing non-parallel corpora. The approaches and difficulties depend on the parallelness of the given bilingual parallel corpus. Fung and Cheung (2004) give a detailed description of the types of non-parallel corpora. They proposed a completely unsupervised method for mining parallel sentences from quasi-comparable bilingual texts which include both in-topic and off-topic documents. Chu et al. (2013) proposed a novel method of classifier training and testing that simulates the real parallel sentence extraction process. They used linguistic knowledge of Chinese character features. Their approach improved in several aspects and worked well for extracting parallel sentences from quasi–comparable corpora. Their 69 Proceedings of the 1st Workshop"
W14-7010,D10-1092,0,0.290935,"Missing"
W14-7010,I05-5008,1,0.826668,"Missing"
W14-7010,P98-1120,1,0.286975,"ts and worked well for extracting parallel sentences from quasi–comparable corpora. Their 69 Proceedings of the 1st Workshop on Asian Translation (WAT2014), pages 69‒76, Tokyo, Japan, 4th October 2014. 2014 Copyright is held by the author(s). 2 Chinese and Japanese Linguistic Resources 2.1 3 3.1 Chinese and Japanese Parallel Sentences Proportional Analogies Proportional analogies establish a structural relationship between four objects, A, B, C and D: ‘A is to B as C is to D’. An efficient algorithm for the resolution of analogical equations between strings of characters has been proposed in (Lepage, 1998). The algorithm relies on counting numbers of occurrences of characters and computing edit distances (with only insertion and deletion as edit operations) between strings of characters (d (A, B) = d (C, D) and d (A,C) = d (B, D)). The algorithm uses fast bit string operations and distance computation (Allison and Dix, 1986). The Chinese and Japanese linguistic resources we use in this paper are the ASPEC-JC1 corpus. It is a parallel corpus consisting of Japanese scientific papers from the reference database and electronic journal site J-STAGE of the Japan Science and Technology Agency (JST) th"
W14-7010,niessen-etal-2000-evaluation,0,\N,Missing
W14-7010,P02-1040,0,\N,Missing
W14-7010,N10-1063,0,\N,Missing
W14-7010,W13-2505,0,\N,Missing
W14-7010,J03-1002,0,\N,Missing
W14-7010,C98-1116,1,\N,Missing
W14-7010,W14-7001,0,\N,Missing
W15-5011,2012.eamt-1.62,1,0.882259,"sults, thus preventing reproduction of results to a certain extent. The associative approaches, introduced in (Gale and Church, 1991), do not rely on an alignment model, but on independence statistical measures. The Dice coefficient, mutual information (Gale and Church, 1991), and likelihood ratio (Dunning, 1993) are representative cases of this approach. The associative approaches use a local maximization process in which each sentence is processed independently. Sampling-based multilingual alignment (Anymalign) (Lardilleux et al., 2013) and hierarchical sub-sentential alignment (Cutnalign) (Lardilleux et al., 2012) are two associative approaches. Anymalign1 is an open source multilingual associative aligner (Lardilleux and Lepage, 2009; Lardilleux et al., 2013). This method samples large numbers of sub-corpora randomly to obtain source and target word or phrase occurrence distributions. The more often two words or phrases have the same occurrence distribution over particular sub-corpora, the higher the association between them. We can run Anymalign by setting with -t (running time) option and stop it at any time, and the option -i allows to to extract longer phrases This paper describes Chinese–Japanese"
W15-5011,P06-1002,0,0.0217214,"with Moses version 2.1.1, a timeout of 1200 sec. for Anymalign and the C version of Cutnalign: 57 minutes, i.e., about one fifth of the time used by GIZA++ or MGIZA (Table 5 and 6). We also checked the confidence intervals between using GIZA++ and our method (the fastest one): 37.24 ± 0.86 and 35.72 ± 0.90. The probability of actually getting them (p-value) is 0. Experiments based on different alignment methods Experiment settings 5 Here, we basically perform experiments with GIZA++ or MGIZA. The phrase tables are extracted from the alignments obtained using the grow-diag-final-and heuristic (Ayan and Dorr, 2006) integrated in the Moses toolkit. Our sampling-based alignment method and hierarchical sub-sentential alignment method are also evaluated within a PB-SMT system built by using the Moses toolkit, the Ken Language Modeling toolkit (Heafield, 2011) and a lexicalized reordering model (Koehn et al., 2005). We built systems from Chinese to Japanese. Each experiment was run using the same data sets (see Section 2). Translations were evaluated using BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., Conclusion In this paper, we have shown that it is possible to accelerate development of SMT syste"
W15-5011,W15-5001,0,0.0271,"00 55,582 27.83 ±16.73 Japanese 820,184 20,279,246 25.08 ± 7.75 4,000 143,853 36.12 ± 21.73 2,000 70,117 35.09 ± 20.16 Table 1: Statistics of our baseline training data of JPC. • compute the optimal joint clustering of a bipartite graph to search the best alignment; • segment and align a pair of sentences. 2 Chinese and Japanese data used When building alignment matrices, the strength between two words is evaluated using the following formula (Lardilleux et al., 2012). The data used in our systems are the Chinese– Japanese JPO Patent Corpus (JPC)2 provided by WAT 2015 for the patents subtask (Nakazawa et al., 2015). It contains 1 million Chinese–Japanese parallel sentences in four domains in the training data. These are Chemistry, Electricity, Mechanical engineering, and Physics. We used sentences of 40 words or less than 40 words as our training data for the translation models, but use all of the Japanese sentences in the parallel corpus for training the language models. We used all of the development data for tuning. For Chinese and Japanese segmentation we used the Stanford Segmenter (version: 2014-01-04 with Chinese Penn Treebank (CTB) model)3 and Juman (version 7.0)4 . Table 1 shows some statistics"
W15-5011,J93-2003,0,0.0748269,"Missing"
W15-5011,J03-1002,0,0.0463885,"Missing"
W15-5011,W08-0509,0,0.0444172,"Waseda University {kevinyoogi@akane., zzw890827@fuji., yangbaosong@fuji.}waseda.jp yves.lepage@waseda.jp Abstract 1993) and HMM alignment models (Vogel et al., 1996), which are typical implementation of the EM algorithm (Dempster et al., 1977), are the most widely used representatives in this category. GIZA++ (Och and Ney, 2003) implemented IBM Models, it aligns words based on statistical models. It is a global optimization process simultaneously considers all possible associations in the entire corpus and estimates the parameters of the parallel corpus. Several improvements were made: MGIZA (Gao and Vogel, 2008) is a parallel implementation of IBM models. However, the parallelization may lead to slightly different final alignment results, thus preventing reproduction of results to a certain extent. The associative approaches, introduced in (Gale and Church, 1991), do not rely on an alignment model, but on independence statistical measures. The Dice coefficient, mutual information (Gale and Church, 1991), and likelihood ratio (Dunning, 1993) are representative cases of this approach. The associative approaches use a local maximization process in which each sentence is processed independently. Sampling"
W15-5011,W11-2123,0,0.0173649,"r method (the fastest one): 37.24 ± 0.86 and 35.72 ± 0.90. The probability of actually getting them (p-value) is 0. Experiments based on different alignment methods Experiment settings 5 Here, we basically perform experiments with GIZA++ or MGIZA. The phrase tables are extracted from the alignments obtained using the grow-diag-final-and heuristic (Ayan and Dorr, 2006) integrated in the Moses toolkit. Our sampling-based alignment method and hierarchical sub-sentential alignment method are also evaluated within a PB-SMT system built by using the Moses toolkit, the Ken Language Modeling toolkit (Heafield, 2011) and a lexicalized reordering model (Koehn et al., 2005). We built systems from Chinese to Japanese. Each experiment was run using the same data sets (see Section 2). Translations were evaluated using BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., Conclusion In this paper, we have shown that it is possible to accelerate development of SMT systems following the work by Lardilleux et al. (2012) and Yang and Lepage (2015) on bilingual hierarchical sub-sentential alignment. We performed several machine translation experiments using different alignment methods and obtained a significant re"
W15-5011,D10-1092,0,0.180098,"Missing"
W15-5011,2005.iwslt-1.8,0,0.0330803,"0.90. The probability of actually getting them (p-value) is 0. Experiments based on different alignment methods Experiment settings 5 Here, we basically perform experiments with GIZA++ or MGIZA. The phrase tables are extracted from the alignments obtained using the grow-diag-final-and heuristic (Ayan and Dorr, 2006) integrated in the Moses toolkit. Our sampling-based alignment method and hierarchical sub-sentential alignment method are also evaluated within a PB-SMT system built by using the Moses toolkit, the Ken Language Modeling toolkit (Heafield, 2011) and a lexicalized reordering model (Koehn et al., 2005). We built systems from Chinese to Japanese. Each experiment was run using the same data sets (see Section 2). Translations were evaluated using BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., Conclusion In this paper, we have shown that it is possible to accelerate development of SMT systems following the work by Lardilleux et al. (2012) and Yang and Lepage (2015) on bilingual hierarchical sub-sentential alignment. We performed several machine translation experiments using different alignment methods and obtained a significant reduction of processing training time. Setting different t"
W15-5011,C96-2141,0,\N,Missing
W15-5011,P02-1040,0,\N,Missing
W15-5011,P07-2045,0,\N,Missing
W15-5011,H91-1026,0,\N,Missing
W15-5011,W14-7001,0,\N,Missing
W16-4501,J90-2002,0,0.658666,"counting alignment matches in comparison with fast align. We also report the result of final machine translation in both English-Japanese and Japanese-English. We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES. 1 Introduction Since state-of-the-art machine translation systems start with word aligned data, the processing of word alignment plays a fundamental role in machine translation. A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows"
W16-4501,J93-2003,0,0.0624452,"on. A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was implemented as fast align1 (Dyer et al., 2013), which allows an effective alignment of words. There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++2 (Och and Ney, 2003), or MGIZA++3 (Gao and Vogel, 2008). Ho"
W16-4501,P05-1033,0,0.126227,"chine translation in both English-Japanese and Japanese-English. We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES. 1 Introduction Since state-of-the-art machine translation systems start with word aligned data, the processing of word alignment plays a fundamental role in machine translation. A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annot"
W16-4501,D15-1119,0,0.0440321,"M-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was implemented as fast align1 (Dyer et al., 2013), which allows an effective alignment of words. There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++2 (Och and Ney, 2003), or MGIZA++3 (Gao and Vogel, 2008). However, Ding et al. (2015) demonstrated that fast align does not outperform the baseline GIZA++, especially for the distantly related language pairs, like English-Japanese or Chinese-English. The reason may be explained by the fact that, given a source word, fast align tends to limit the probable target translation and its alignment nearest as possible to the diagonal in the alignment matrix according to the overall word orders, which is the drawback of IBM-model 2 (Brown et al., 1993) and its variations, in terms of being insensitive to word orders. The word alignments output by fast align This work is licensed under"
W16-4501,N13-1073,0,0.160946,"ignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was implemented as fast align1 (Dyer et al., 2013), which allows an effective alignment of words. There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++2 (Och and Ney, 2003), or MGIZA++3 (Gao and Vogel, 2008). However, Ding et al. (2015) demonstrated that fast align does not outperform the baseline GIZA++, especially for the distantly related language pairs, like English-Japanese or Chinese-English. The reason may be explained by the fact that, given a source word, fast align tends to limit the probable target translation and its alignment nearest as"
W16-4501,J07-3002,0,0.0343868,"ER) (Och and Ney, 2003) on the basis of human annotated alignment data provided with the KFTT corpus in Table 1. The first and second lines show the alignment difference using GIZA++ and fast align. The original HSSA, which allows 1-to-many or many-to-1 alignments, outperforms the fast align baseline from the point view of matching alignments and recall against the reference. The total number of alignments is much higher than with fast align which victim of the “noisy alignments” problem mentioned in Section 4. AER and precision are behind fast align, even more than GIZA++ baseline. However, (Fraser and Marcu, 2007; Ganchev et al., 2008) question the link between this word alignment quality metrics and translation results, like whether improvements in alignment quality metrics lead to improvements in phrase-based machine translation performance. A lower AER does not imply a better translation accuracy. We show it in the following discussion. When sampling the alignment results, we found that the output of the proposed hybrid approach usually generates better alignments than the baseline. Experimental results in both direction for English-Japanese and Japanese-English are shown in the right part of Table"
W16-4501,W08-0509,0,0.0302496,"els (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was implemented as fast align1 (Dyer et al., 2013), which allows an effective alignment of words. There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++2 (Och and Ney, 2003), or MGIZA++3 (Gao and Vogel, 2008). However, Ding et al. (2015) demonstrated that fast align does not outperform the baseline GIZA++, especially for the distantly related language pairs, like English-Japanese or Chinese-English. The reason may be explained by the fact that, given a source word, fast align tends to limit the probable target translation and its alignment nearest as possible to the diagonal in the alignment matrix according to the overall word orders, which is the drawback of IBM-model 2 (Brown et al., 1993) and its variations, in terms of being insensitive to word orders. The word alignments output by fast align"
W16-4501,P03-1011,0,0.0692551,"nese and Japanese-English. We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES. 1 Introduction Since state-of-the-art machine translation systems start with word aligned data, the processing of word alignment plays a fundamental role in machine translation. A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IB"
W16-4501,P09-1104,0,0.0262435,"ffective pipeline with an acceptable time cost. Given the output alignments of fast align, it is quite straightforward to estimate a maximum likelihood lexical translation table. We record both the direct p(f |e) as well as the inverse p(e|f ) word translation probabilities in the translation table. This step is easy and fast finished with the Moses6 training pipeline. The purpose that drives us to do this work is the idea of combining two different models into one. One (ITG) models distinct language pair well, while the other one (IBM models) models similar language pair well. Previous work (Haghighi et al., 2009) proved that importing ITG limitations improves word alignments for Chinese-English alignment. An example illustrating our proposed hybridization is shown in Figure 2. In the context of system combination, we extend the pipeline of standard phrase-based statistical machine translation. In the middle, a soft alignment matrix (as the one in Figure 1) is generated for each sentence pair by feeding it with scores from the lexical translation table. On such soft alignment matrices, we apply the HSSA approach to obtain a final word-to-word alignment. Thanks to the simplicity of the HSSA approach, th"
W16-4501,W11-2123,0,0.0335869,"0.001. Boldface indicates no significantly different with GIZA++ baseline ( † : p < 0.05, ‡ : p < 0.01 ) . replacement of the intersection alignments of fast align. Following this idea, we produce alignments with different strategy profiles. 5 Experiments English-Japanese alignment and translation is a much harder task for fast align than French-English alignment (Dyer et al., 2013). In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (Koehn et al., 2007), Minimum Error Rate Training (Och, 2003), and the KenLM language model (Heafield, 2011). The default training pipeline for phrasebased SMT is adopted with default distortion-limit 6. Two baseline systems, one built with GIZA++ and another built with fast align, are prepared for result comparison. For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) in all experiments. Since BLEU is insensitive to long-distance displacements of large sequences of words, we also use RIBES which was designed to take distinct word orders into consideration. In order to ensure a"
W16-4501,D10-1092,0,0.0266183,"013). In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (Koehn et al., 2007), Minimum Error Rate Training (Och, 2003), and the KenLM language model (Heafield, 2011). The default training pipeline for phrasebased SMT is adopted with default distortion-limit 6. Two baseline systems, one built with GIZA++ and another built with fast align, are prepared for result comparison. For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) in all experiments. Since BLEU is insensitive to long-distance displacements of large sequences of words, we also use RIBES which was designed to take distinct word orders into consideration. In order to ensure a consistent, repeatable and reproducible experiment, we use the original training, tuning and test sets provided in KFTT corpus8 . We first report the performance of various alignment profiles in terms of precision, recall and alignment error rate (AER) (Och and Ney, 2003) on the basis of human annotated alignment data provided with the KFTT corpus in Table 1. The first and second lin"
W16-4501,N03-1017,0,0.241444,"with fast align. We also report the result of final machine translation in both English-Japanese and Japanese-English. We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES. 1 Introduction Since state-of-the-art machine translation systems start with word aligned data, the processing of word alignment plays a fundamental role in machine translation. A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingua"
W16-4501,2005.iwslt-1.8,0,0.0217292,"an 1 minute in a real experiment on 320K sentence pairs). We employ the implementation cutnalign7 for HSSA step. Nevertheless, because HSSA outputs both 1-to-many and many-to-1 alignments, a drawback is, sometimes it returns some “noisy” alignments (referring to the alignment that appears weak in the soft alignment matrix). To solve this problem, instead of outputting all 1-to-1 matches contained in 1-to-many or many-to-1 blocks, it is better to prune low confidence matches while tweaking the alignments with heuristic search techniques, like the grow step in the grow-diag-final-and heuristic (Koehn et al., 2005). We consider that HSSA provides an alternative to grow-diag-final-and for alignments symmetrization in 6 7 http://www.statmt.org/moses/ https://github.com/wang-h/min-cutnalign 4 Ref GIZA++ fast align + HSSA 1-n/n-1 + prune + grow # 33,377 31,342 25,368 43,061 27,982 30,714 MatchRef Prec Rec AER en-ja BLEU RIBES 18,641 14,076 14,990 13,542 13,968 59.48 55.49 34.81 48.40 45.48 55.85 42.17 44.91 40.57 41.85 42.39 52.08 60.78 55.86 56.41 21.59 20.79‡ 21.23 21.83 21.53 68.10 68.13 68.01 68.42 68.14 ja-en BLEU RIBES 18.78 18.23† 18.14† 18.38 18.53 65.87 65.25 64.91 65.53 65.57 Table 1: Word alignme"
W16-4501,P07-2045,0,0.0109016,"h). prune is the case when filtering all alignments in 1-n/n-1 blocks using a threshold γ &gt; 0.001. Boldface indicates no significantly different with GIZA++ baseline ( † : p < 0.05, ‡ : p < 0.01 ) . replacement of the intersection alignments of fast align. Following this idea, we produce alignments with different strategy profiles. 5 Experiments English-Japanese alignment and translation is a much harder task for fast align than French-English alignment (Dyer et al., 2013). In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (Koehn et al., 2007), Minimum Error Rate Training (Och, 2003), and the KenLM language model (Heafield, 2011). The default training pipeline for phrasebased SMT is adopted with default distortion-limit 6. Two baseline systems, one built with GIZA++ and another built with fast align, are prepared for result comparison. For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) in all experiments. Since BLEU is insensitive to long-distance displacements of large sequences of words, we also use RIBES"
W16-4501,2012.eamt-1.62,1,0.908612,"phrase-based (or other kinds of statistical machine translation systems) relies on the continuous translation fragments. It has been proved that by applying structural models such as Inversion Transduction Grammars (ITG) (Wu, 1997) will achieve some gain. ITG has been widely applied to word alignment, bilingual parsing, etc., due to its simplicity and effectiveness of modeling bilingual correspondence. However, inducing ITGs from parallel data would be time-consuming. In this paper, in order to integrate ITG with IBM model, we propose to apply the hierarchical subsentential alignment (HSSA) (Lardilleux et al., 2012) approach to realign word alignments. HSSA is an online word alignment approach, which was first introduced as complementary to Anymalign4 . When fed with the lexical weights output by Anymalign, it yields comparable results with baseline MGIZA++. In fact, an important advantage of this approach is that it can be combined with any other existing approach by reusing the lexical weights output by this other approach. We make use of the structure named soft alignment matrix (Liu et al., 2009) to represent the alignment distribution for a given sentence pair, which cells are weighted by the lexica"
W16-4501,D09-1106,0,0.100432,"integrate ITG with IBM model, we propose to apply the hierarchical subsentential alignment (HSSA) (Lardilleux et al., 2012) approach to realign word alignments. HSSA is an online word alignment approach, which was first introduced as complementary to Anymalign4 . When fed with the lexical weights output by Anymalign, it yields comparable results with baseline MGIZA++. In fact, an important advantage of this approach is that it can be combined with any other existing approach by reusing the lexical weights output by this other approach. We make use of the structure named soft alignment matrix (Liu et al., 2009) to represent the alignment distribution for a given sentence pair, which cells are weighted by the lexical weights output by fast align. With the recursive binary segmentation processing in HSSA, we realign the sentence pairs top-down. We also present a simple but effective method to deal with error alignment points produced by this hybrid method, i.e., conflicting cells in soft alignment matrices. In Section 2 and Section 3, the notion of soft alignment matrix and HSSA will be introduced. The hybrid combination architecture of our proposed method will be illustrated in Section 4. Experimenta"
W16-4501,C04-1032,0,0.095445,"Missing"
W16-4501,W05-0801,0,0.0953966,"Missing"
W16-4501,J03-1002,0,0.1721,"n generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was implemented as fast align1 (Dyer et al., 2013), which allows an effective alignment of words. There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++2 (Och and Ney, 2003), or MGIZA++3 (Gao and Vogel, 2008). However, Ding et al. (2015) demonstrated that fast align does not outperform the baseline GIZA++, especially for the distantly related language pairs, like English-Japanese or Chinese-English. The reason may be explained by the fact that, given a source word, fast align tends to limit the probable target translation and its alignment nearest as possible to the diagonal in the alignment matrix according to the overall word orders, which is the drawback of IBM-model 2 (Brown et al., 1993) and its variations, in terms of being insensitive to word orders. The w"
W16-4501,P03-1021,0,0.0230692,"s in 1-n/n-1 blocks using a threshold γ &gt; 0.001. Boldface indicates no significantly different with GIZA++ baseline ( † : p < 0.05, ‡ : p < 0.01 ) . replacement of the intersection alignments of fast align. Following this idea, we produce alignments with different strategy profiles. 5 Experiments English-Japanese alignment and translation is a much harder task for fast align than French-English alignment (Dyer et al., 2013). In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (Koehn et al., 2007), Minimum Error Rate Training (Och, 2003), and the KenLM language model (Heafield, 2011). The default training pipeline for phrasebased SMT is adopted with default distortion-limit 6. Two baseline systems, one built with GIZA++ and another built with fast align, are prepared for result comparison. For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) in all experiments. Since BLEU is insensitive to long-distance displacements of large sequences of words, we also use RIBES which was designed to take distinct word"
W16-4501,P02-1040,0,0.107205,"-English alignment (Dyer et al., 2013). In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (Koehn et al., 2007), Minimum Error Rate Training (Och, 2003), and the KenLM language model (Heafield, 2011). The default training pipeline for phrasebased SMT is adopted with default distortion-limit 6. Two baseline systems, one built with GIZA++ and another built with fast align, are prepared for result comparison. For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) in all experiments. Since BLEU is insensitive to long-distance displacements of large sequences of words, we also use RIBES which was designed to take distinct word orders into consideration. In order to ensure a consistent, repeatable and reproducible experiment, we use the original training, tuning and test sets provided in KFTT corpus8 . We first report the performance of various alignment profiles in terms of precision, recall and alignment error rate (AER) (Och and Ney, 2003) on the basis of human annotated alignment data provided with the KFTT corpus in"
W16-4501,C96-2141,0,0.183255,"is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was implemented as fast align1 (Dyer et al., 2013), which allows an effective alignment of words. There is no doubt that fast align is almost the fastest word aligner, while keeping the quality of alignment, compared to the baseline using GIZA++2 (Och and Ney, 2003), or MGIZA++3 (Gao and Vogel, 2008). However, Ding et al. (2015) demonstrated th"
W16-4501,J97-3002,0,0.0574989,"Ney, 2003). Though this method can overcome the mentioned deficiency to some degree, the strong assumption of 1-m alignment forces the aligner to generate 1-best alignments, which is prone to learn noisy rules due to alignment or segmentation mistakes. Another problem exists is that the production of 1-m alignment losses the structural information of the whole sentence while phrase-based (or other kinds of statistical machine translation systems) relies on the continuous translation fragments. It has been proved that by applying structural models such as Inversion Transduction Grammars (ITG) (Wu, 1997) will achieve some gain. ITG has been widely applied to word alignment, bilingual parsing, etc., due to its simplicity and effectiveness of modeling bilingual correspondence. However, inducing ITGs from parallel data would be time-consuming. In this paper, in order to integrate ITG with IBM model, we propose to apply the hierarchical subsentential alignment (HSSA) (Lardilleux et al., 2012) approach to realign word alignments. HSSA is an online word alignment approach, which was first introduced as complementary to Anymalign4 . When fed with the lexical weights output by Anymalign, it yields co"
W16-4501,2007.mtsummit-papers.71,0,0.0540516,"ese-English. We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES. 1 Introduction Since state-of-the-art machine translation systems start with word aligned data, the processing of word alignment plays a fundamental role in machine translation. A reliable and accurate word aligner is considered as an essential component in the various implementations of machine translation, e.g., wordbased model (Brown et al., 1990), phrase-based model (Koehn et al., 2003), hierarchical phrase-based model (Chiang, 2005) and tree-to-tree model (Gildea, 2003; Zhang et al., 2007). In general, word alignment is prerequisite for extracting rules or sub-translations (word pairs, phrase pairs or partial tree templates) for translation. The most widely used word aligner is GIZA++ (Och and Ney, 2000), which is based on generative models, like IBM models (Brown et al., 1993) and HMM-based model (Vogel et al., 1996), in which parameters are estimated using the Expectation-Maximization (EM) algorithm. This generative approach allows GIZA++ to automatically extract bilingual lexicon from parallel corpus without any annotated data. Besides, a variation of IBM model 2 was impleme"
W16-4501,P08-1012,0,0.0218065,"A decides for the next search scope (the upper left and lower right blocks in Figure 1) by finding the position where N cut(m, n,XY ,XY ) or N cut(m, n,XY ,XY ) is the minimum value among all possible bipartite segmentation positions. In this example, N cut(m, n,XY ,XY ) is less than N cut(m, n,XY ,XY ), equals to straight rule. Since the time complexity of top-down HSSA algorithm is cubic (O(I × J × min(I, J)), the worst case) in the length of the input sentence pair, it is faster than the original ITG approach O(n6 ) employing the CYK algorithm and achieves the same performance compared to (Zhang et al., 2008) which has a best time complexity of O(n3 ) with synchronous parsing. 4 Hybrid Combination Architecture It is thus possible to use various word alignment tools, while fast align provides the most effective pipeline with an acceptable time cost. Given the output alignments of fast align, it is quite straightforward to estimate a maximum likelihood lexical translation table. We record both the direct p(f |e) as well as the inverse p(e|f ) word translation probabilities in the translation table. This step is easy and fast finished with the Moses6 training pipeline. The purpose that drives us to d"
W16-4619,W08-0336,0,0.0282656,"large amounts of domain-specific terms in words or multi-word expressions. This brings up the question of word segmentation: we may not want to tokenize terms in specific domains in patents. But we cannot control the tokenization of the multi-word terms: a large number of multi-word terms are always segmented into several single-word terms in one language but may not be segmented in another language, or some of the multi-word terms in two languages have different levels of granularity in segmentation because of different conventions of segmentation in different languages. The related work by Chang et al. (2008) shows that segmentation granularity of Chinese word segmentation affects the translation accuracy and that it is very important for MT. In (Chu et al., 2013), for improving the translation accuracy of scientific papers, they make use of a constructed mapping table for adjusting Chinese segmentation results according to Japanese segmentation based on characters shared between Chinese and Japanese. In our work, we focus on terms and patent segmentation and translation. To improve SMT translation accuracy, we change and adjust the segmentation for terms using extracted bilingual multi-word terms"
W16-4619,W11-2123,0,0.0610974,"Missing"
W16-4619,P07-2045,0,0.013024,"Missing"
W16-4619,R09-1040,1,0.92143,"ilingual multi-word terms for both languages (not only for Chinese or Japanese). Frantzi et al. (2000) describes a combination of linguistic and statistical methods (C-value/NC-value) for the automatic extraction of multi-word terms from English corpora. In (Mima and Ananiadou, 2001), it is showed that the C-/NC-value method is an efficient domain-independent multi-word term recognition not only in English but in Japanese as well. In this paper, we adopt the C-value method to extract monolingual multi-word terms in Chinese and Japanese, and combine it with the sampling-based alignment method (Lardilleux and Lepage, 2009) and kanji-hanzi conversion method for bilingual multi-word term extraction. We build SMT systems based on re-tokenized Chinese–Japanese patent training corpus using the extracted bilingual multi-word terms. Place licence statement here for the camera-ready version, see Section ?? of the instructions for preparing a manuscript. 194 Proceedings of the 3rd Workshop on Asian Translation, pages 194–202, Osaka, Japan, December 11-17 2016. Language Sentence Chinese 该/ 钽阳/极体 /通常/是/烧结/的/。 Japanese Meaning タンタル/陽極/ボディ /は/、/ 通常/、/ 焼結/さ/れて/いる/。 ‘Tantalum anode body are usually sintered.’ Chinese 贴片/52/-/"
W16-4619,P02-1040,0,0.09909,"21 33.29 33.38 33.93 33.43 33.41 33.52 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 &lt; 0.01 Table 6: Evaluation results in BLEU for Chinese to Japanese translation based on re-tokenized training corpus using different thresholds (a); based on combination of the ratio of lengths + the components (b) with kanji-hanzi conversion (c). In all experiments, the same data sets are used, the only difference being whether the training data is retokenized or not with bilingual multi-word terms. Table 6 shows the evaluation of the results of Chineseto-Japanese translation in BLEU scores (Papineni et al., 2002). Compared with the baseline system, for the training corpus re-tokenized with further filtering combined with kanji-hanzi conversion results (a +b + c), we obtain significant improvements in all thresholds. We obtain 1.55 BLEU point (threshold of 0.6) improvements compare with the baseline system. In this case, 20,679 re-tokenized terms are used. It is also improve 0.3 BLEU point comparing with the case of the bilingual terms are filtered only by thresholds (a). We then test 2,000 sentences based on this best SMT system and the baseline system. We obtain a significant BLEU score with 33.61 co"
Y11-1016,J93-2003,0,0.0402236,"techniques. Keywords: alignment, phrase translation table, statistical machine translation. 1 Introduction Phrase translation tables play an important role in the process of building machine translation systems. The quality of translation table, which identifies the relations between words or phrases in the source language and those in the target language, is crucial for the quality of the output of most machine translation systems. Currently, the most widely used state-of-the-art tool to generate phrase translation tables is GIZA++ (Och and Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implement"
Y11-1016,P91-1022,0,0.333767,"ses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultaneously; but we will not use this feature here as we will restrain ourselves to bilingual experiments in this paper. In sampling-based alignment, only those sequences of words sharing the exact same distribution (i.e., they appear exactly in the same sentences of the corpus) are considered for alignment. ? 1 Part of the research presented in this paper has been done under a Japanese grant-in-aid (Kakenhi C, A11515600: Improvement of alignments and release of multilingual syntactic pattern"
Y11-1016,H91-1026,0,0.67877,"ables is GIZA++ (Och and Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultaneously; but we will not use this feature here as we will restrain ourselves to bilingual experiments in this paper. In sampling-based alignment, only those sequences of words sharing the exact same distribution (i.e., they appear exactly in the same sentences of the corpus) are considered for alignment. ? 1 Part of the res"
Y11-1016,W08-0509,0,0.12955,"on systems. The quality of translation table, which identifies the relations between words or phrases in the source language and those in the target language, is crucial for the quality of the output of most machine translation systems. Currently, the most widely used state-of-the-art tool to generate phrase translation tables is GIZA++ (Och and Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultan"
Y11-1016,W10-1712,0,0.0437477,"Missing"
Y11-1016,D07-1103,0,0.435372,"e can see a significant increase in the number of phrase pairs of similar lengths, while the number of phrase pairs with different lengths tends to decrease slightly. This means that the standard normal time distribution allowed us to produce much more numerous useful alignments (a priori, phrase pairs with similar lengths), while maintaining the noise (phrase pairs with different lengths) to a low level, which is a neat advantage over the original method. 5 Translation Table Pruning Until now, we were concerned with the shape of phrase translation tables in standard configurations. However, (Johnson et al., 2007) have shown that substantially pruning the phrase translation tables can lead to slight but consistent improvements in translation quality. They use Fisher’s exact significance test to eliminate a substantial number of phrase pairs. The significance of the association between a (source, target) phrase pair is evaluated and their probability of co-occurrence in the corpus is calculated. The hypergeometric distribution is used to compute the observed probability of joint occurrence C(s, ˜ t˜), with s˜ a source phrase and t˜ a target phrase:    ph (C(s, ˜ t˜)) = C(s) ˜ C(s, ˜ t˜)  N−C(s) ˜ C"
Y11-1016,R09-1040,1,0.940416,"anguage, is crucial for the quality of the output of most machine translation systems. Currently, the most widely used state-of-the-art tool to generate phrase translation tables is GIZA++ (Och and Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultaneously; but we will not use this feature here as we will restrain ourselves to bilingual experiments in this paper. In sampling-based alignment, only those s"
Y11-1016,N06-1014,0,0.157519,"++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultaneously; but we will not use this feature here as we will restrain ourselves to bilingual experiments in this paper. In sampling-based alignment, only those sequences of words sharing the exact same distribution (i.e., they appear exactly in the same sentences of the corpus) are considered for alignment. ? 1 Part of the research presented in this paper has been done under a Japanese grant-in-aid (Kakenhi C, A11515600: Improvement of alignments and release of multilingual syntactic patterns for statistical and example-based mach"
Y11-1016,P07-1039,0,0.0146456,"and sequences of two and three words are called bigrams and trigrams, respectively. Theoretically, since the sampling-based alignment method excels at aligning unigrams, we could improve it by making it align bigrams, trigrams, or even longer n-grams as if they were unigrams. We do this by replacing spaces between words by underscore symbols and reduplicating words as many times as needed, which allows to make bigrams, trigrams, and longer n-grams appear as unigrams. Table 3 depicts the way of forcing n-grams into unigrams. Similar works on the idea of enlarging n-grams have been reported in (Ma et al., 2007), in which ”word packing” is used to obtain 1-to-n alignments based on co-occurrence frequencies, and (Henr´ıquez Q. et al., 2010), in which collocation segmentation is performed on bilingual corpus to extract n-to-m alignments. Table 3: Transforming n-grams into unigrams by inserting underscores and reduplicating words for both the French part and English part of the input parallel corpus. n 1 2 3 4 5 3.2 le le le le le French debat est clos . debat debat est est clos clos . debat est debat est clos est clos . debat est clos debat est clos . debat est clos . the the the the the English debate"
Y11-1016,J00-2004,0,0.291907,"d Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultaneously; but we will not use this feature here as we will restrain ourselves to bilingual experiments in this paper. In sampling-based alignment, only those sequences of words sharing the exact same distribution (i.e., they appear exactly in the same sentences of the corpus) are considered for alignment. ? 1 Part of the research presented"
Y11-1016,W05-0801,0,0.693461,"hich trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estimating trend illustrated by (Brown et al., 1991; Och and Ney, 2003; Liang et al., 2006). In addition, it is capable of aligning multiple languages simultaneously; but we will not use this feature here as we will restrain ourselves to bilingual experiments in this paper. In sampling-based alignment, only those sequences of words sharing the exact same distribution (i.e., they appear exactly in the same sentences of the corpus) are considered for alignment. ? 1 Part of the research presented in this paper"
Y11-1016,niessen-etal-2000-evaluation,0,0.0515045,"Missing"
Y11-1016,P03-1021,0,0.0272032,"1 Experimental Setup A sample of the French-English parts of the Europarl parallel corpus was used for training, tuning and testing. A detailed description of the data used in the experiments is given in Table 1. The training corpus is made of 100k sentences. The development set contains 500 sentences, and 1,000 sentences were used for testing. To perform the experiments, a standard statistical machine translation system was built for each different alignment setting, using the Moses decoder (Koehn et al., 2007), MERT (Minimum Error Rate Training) to tune the parameters of translation tables (Och, 2003), and the SRI Language Modeling toolkit (Stolcke, 2002) to build the target language model. As for the evaluation of translations, four standard automatic evaluation metrics were used: mWER (Nießen et al., 2000), BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and TER (Snover et al., 2006). Table 1: Statistics on the French-English parallel corpus used for the training, development, and test sets. Train Dev Test 2.2 sentences words words/sentence sentences words words/sentence sentences words words/sentence French 100,000 3,986,438 38 500 18,120 36 1,000 38,936 37 English 100,000 2,824,"
Y11-1016,J03-1002,0,0.0307546,"translation tables is shown to outperform state-of-the-art techniques. Keywords: alignment, phrase translation table, statistical machine translation. 1 Introduction Phrase translation tables play an important role in the process of building machine translation systems. The quality of translation table, which identifies the relations between words or phrases in the source language and those in the target language, is crucial for the quality of the output of most machine translation systems. Currently, the most widely used state-of-the-art tool to generate phrase translation tables is GIZA++ (Och and Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 200"
Y11-1016,P02-1040,0,0.0800868,"Missing"
Y11-1016,2006.amta-papers.25,0,0.115113,"Missing"
Y11-1016,C96-2141,0,0.679643,"tion table, statistical machine translation. 1 Introduction Phrase translation tables play an important role in the process of building machine translation systems. The quality of translation table, which identifies the relations between words or phrases in the source language and those in the target language, is crucial for the quality of the output of most machine translation systems. Currently, the most widely used state-of-the-art tool to generate phrase translation tables is GIZA++ (Och and Ney, 2003), which trains the ubiquitous IBM models (Brown et al., 1993) and the HMM introduced by (Vogel et al., 1996), in combination with the Moses toolkit (Koehn et al., 2007). MGIZA++, a multi-threaded word aligner based on GIZA++, is proposed by (Gao and Vogel, 2008). In this paper, we investigate a different approach to the production of phrase translation tables: the sampling-based approach (Lardilleux and Lepage, 2009b). This approach is implemented in a free open-source tool called Anymalign.1 Being in line with the associative alignment trend illustrated by (Gale and Church, 1991; Melamed, 2000; Moore, 2005), it is much simpler than the models implemented in MGIZA++, which are in line with the estim"
Y11-1016,P07-2045,0,\N,Missing
Y11-1016,N03-1017,0,\N,Missing
Y11-1061,J90-2002,0,0.69313,"solution if the number of analogies between chunks is confirmed to be large. This paper thus reports counts of number of analogies using different numbers of chunk markers in 11 European languages. These experiments confirm that the number of analogies between chunks is very large: several tens of thousands of analogies between chunks extracted from sentences among which only very few analogies, if not none, were found. Keywords: Analogy, Marker Hypothesis, Marker-based Chunking, Branching Entropy 1 Introduction The example-based approach (Nagao, 1984) contrasts with the statistical approach (Brown et al., 1990; Brown et al., 1993) to machine translation in that it uses a bilingual corpus of aligned sentences as its main knowledge at run time. We aim at building an EBMT system based on proportional analogies. A translation method based on proportional analogies has been proposed by Lepage and Denoual (2005b). The following procedure gives the basic outline of the method to perform the translation of an input chunk. Let us suppose that we have a corpus of aligned chunks in two languages, German and French. Let x = “ein großes programm und” be a source chunk to be translated into one or more target ch"
Y11-1061,J93-2003,0,0.0341498,"er of analogies between chunks is confirmed to be large. This paper thus reports counts of number of analogies using different numbers of chunk markers in 11 European languages. These experiments confirm that the number of analogies between chunks is very large: several tens of thousands of analogies between chunks extracted from sentences among which only very few analogies, if not none, were found. Keywords: Analogy, Marker Hypothesis, Marker-based Chunking, Branching Entropy 1 Introduction The example-based approach (Nagao, 1984) contrasts with the statistical approach (Brown et al., 1990; Brown et al., 1993) to machine translation in that it uses a bilingual corpus of aligned sentences as its main knowledge at run time. We aim at building an EBMT system based on proportional analogies. A translation method based on proportional analogies has been proposed by Lepage and Denoual (2005b). The following procedure gives the basic outline of the method to perform the translation of an input chunk. Let us suppose that we have a corpus of aligned chunks in two languages, German and French. Let x = “ein großes programm und” be a source chunk to be translated into one or more target chunks x b. Let the bil"
Y11-1061,2004.tmi-1.11,0,0.68109,"ection 6. 2 Marker-based Chunking In order to be able to apply the previous proposed method to various languages, we want to segment in a fully automatic and universal way sentences in different languages into sub-sentential units like chunks. 2.1 The Marker Hypothesis We use the marker hypothesis for this. This hypothesis was first laid by Green (1979). The marker hypothesis states that all natural languages contain a small number of elements that signal the presence of particular syntactic constructions. We perform chunking based on this notion and use a method called marker-based chunking (Gough and Way, 2004; Stroppa and Way, 2006; Van Den Bosch et al., 2007). We define a chunk as a sequence of words delimited by markers. Markers should be words such as determiners (the), conjunctions (and, but, or), prepositions (in, from, to), possessive and personal pronouns (mine, you). A chunk can be created at each occurrence of a marker word. In addition, a further constraint requires that each chunk contains at least one non-marker word. Without non-marker words, a chunk would become meaningless as it would not contain any meaningful word. As result examples, the following English, French and German sente"
Y11-1061,P06-2056,0,0.383157,"f markers we use is the list of words with the smallest values for the following function: − log C(w) / l(w) (2) Table 1 shows markers obtained in accordance with the two proposed formulae. Those obtained with the latter formula (2) are true markers, on the contrary to those obtained with the former formula (1). Figure 1(a) and 1(b) visualize the better efficiency of formula (2) over formula formula (1) to isolate words that correspond to the intuitive notion of a marker. 2.3 Left or Right Cutting Following the famous intuition by Harris (1955) about branching entropy, Tanaka-Ishii (2005) and Jin and Tanaka-Ishii (2006) have shown how Japanese and Chinese can be segmented into words by formalizing the uncertainty using branching entropy at some point of a text. The entropy of a random variable X with m outcomes xi is defined as its mathematical expectation and is a measure of its overall uncertainty: 569 Table 1: Words ranked according to two different formulae. Formula (1) on the left, (2) on the right. − log Word z / $ q x l u w r & o [ h j n + f y d k Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 .. . C(w) N .. . / l(w) Value 21.81 21.08 20.08 19.94 19.70 19.40 19.40 19.15 19.15 19.15 18.94 18.5"
Y11-1061,2005.mtsummit-papers.11,0,0.11323,"7–576 567 Taking into account the knowledge in the bilingual corpus, analogical equation can be formed in the target language: programmes s´erieux : un programme s´erieux :: gros programmes et : x b Its solution is a candidate translation of the source chunk: x b = “un gros programme et” For such an EBMT system to work well, the more numerous the proportional analogies, the better the translation outputs are expected to be. The method can work on small sentences like the ones in the BTEC corpus (Lepage and Denoual, 2005a), but cannot handle long sentences like the ones in the Europarl corpus (Koehn, 2005). For long sentences, translating chunk by chunk could be a solution. We have inspected the quality of translation of chunks obtained by marker-based chunking in English and French in both directions in (Takeya and Lepage, 2011a; Takeya and Lepage, 2011b). Our results have shown that more than three quarters of the chunks can be translated by the one-step analogy-based translation method, and that a little bit less than half of the chunks has at least one translation that matches exactly with one of the references. As the number of analogies is the crucial point, this paper inspects ways of co"
Y11-1061,J10-4005,0,0.11347,"Missing"
Y11-1061,N03-1017,0,0.0251875,"Missing"
Y11-1061,2005.iwslt-1.4,1,0.91286,"of thousands of analogies between chunks extracted from sentences among which only very few analogies, if not none, were found. Keywords: Analogy, Marker Hypothesis, Marker-based Chunking, Branching Entropy 1 Introduction The example-based approach (Nagao, 1984) contrasts with the statistical approach (Brown et al., 1990; Brown et al., 1993) to machine translation in that it uses a bilingual corpus of aligned sentences as its main knowledge at run time. We aim at building an EBMT system based on proportional analogies. A translation method based on proportional analogies has been proposed by Lepage and Denoual (2005b). The following procedure gives the basic outline of the method to perform the translation of an input chunk. Let us suppose that we have a corpus of aligned chunks in two languages, German and French. Let x = “ein großes programm und” be a source chunk to be translated into one or more target chunks x b. Let the bilingual corpus consists of four chunks with their translations: ernste programme ein ernstes programm große programme und das ernste programm ↔ programmes s´erieux ↔ gros programmes et ↔ un programme s´erieux ↔ le programme s´erieux The method forms all possible analogies with all"
Y11-1061,2006.iwslt-evaluation.4,0,0.454135,"sed Chunking In order to be able to apply the previous proposed method to various languages, we want to segment in a fully automatic and universal way sentences in different languages into sub-sentential units like chunks. 2.1 The Marker Hypothesis We use the marker hypothesis for this. This hypothesis was first laid by Green (1979). The marker hypothesis states that all natural languages contain a small number of elements that signal the presence of particular syntactic constructions. We perform chunking based on this notion and use a method called marker-based chunking (Gough and Way, 2004; Stroppa and Way, 2006; Van Den Bosch et al., 2007). We define a chunk as a sequence of words delimited by markers. Markers should be words such as determiners (the), conjunctions (and, but, or), prepositions (in, from, to), possessive and personal pronouns (mine, you). A chunk can be created at each occurrence of a marker word. In addition, a further constraint requires that each chunk contains at least one non-marker word. Without non-marker words, a chunk would become meaningless as it would not contain any meaningful word. As result examples, the following English, French and German sentences were processed by"
Y11-1061,2011.mtsummit-papers.39,1,0.437077,"candidate translation of the source chunk: x b = “un gros programme et” For such an EBMT system to work well, the more numerous the proportional analogies, the better the translation outputs are expected to be. The method can work on small sentences like the ones in the BTEC corpus (Lepage and Denoual, 2005a), but cannot handle long sentences like the ones in the Europarl corpus (Koehn, 2005). For long sentences, translating chunk by chunk could be a solution. We have inspected the quality of translation of chunks obtained by marker-based chunking in English and French in both directions in (Takeya and Lepage, 2011a; Takeya and Lepage, 2011b). Our results have shown that more than three quarters of the chunks can be translated by the one-step analogy-based translation method, and that a little bit less than half of the chunks has at least one translation that matches exactly with one of the references. As the number of analogies is the crucial point, this paper inspects ways of counting sentences into chunks using different markers and examines the number of proportional analogies between them in 11 European languages. The rest of the paper is organized as follows. Section 2 describes the basic notion o"
Y11-1061,Y11-1061,1,0.0513221,"nd δ(A, B) stands for the edit distance between strings A and B with only insertion and deletion as edit operations. As B and C may be exchanged in an analogy, the constraint on edit distance has also to be verified for A : C :: B : D, i.e., δ(A, C) = δ(B, D). There is no need to verify the first constraint as, trivially, |A|a − |B|a = |C|a − |D|a ⇔ |A|a − |C|a = |B|a − |D|a . 4 4.1 Experimental Setting Experimental Protocol We present experiments similar to the ones reported for Japanese in (Lepage et al., 2009), but on 11 European languages. Another similar experiment also has been done in (Takeya et al., 2011). Here, we examine several sampling sizes and different numbers of markers. Our sampling sizes range from 10 to 100,000 sentences, and the number of markers ranges from 10 to 300 markers. 4.2 Experimental Data We use the Europarl corpus (Koehn, 2005) in our experiments because our ultimate goal is to apply the analogy-based EBMT method to this kind of data. The Europarl corpus is a collection of proceedings of the European Parliament. Since the corpus is not exactly aligned, we aligned nearly 400,000 sentences across 11 languages properly. Our corpus comprises of about 10 million words for eac"
Y11-1061,I05-1009,0,0.40368,"To summarize, the list of markers we use is the list of words with the smallest values for the following function: − log C(w) / l(w) (2) Table 1 shows markers obtained in accordance with the two proposed formulae. Those obtained with the latter formula (2) are true markers, on the contrary to those obtained with the former formula (1). Figure 1(a) and 1(b) visualize the better efficiency of formula (2) over formula formula (1) to isolate words that correspond to the intuitive notion of a marker. 2.3 Left or Right Cutting Following the famous intuition by Harris (1955) about branching entropy, Tanaka-Ishii (2005) and Jin and Tanaka-Ishii (2006) have shown how Japanese and Chinese can be segmented into words by formalizing the uncertainty using branching entropy at some point of a text. The entropy of a random variable X with m outcomes xi is defined as its mathematical expectation and is a measure of its overall uncertainty: 569 Table 1: Words ranked according to two different formulae. Formula (1) on the left, (2) on the right. − log Word z / $ q x l u w r & o [ h j n + f y d k Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 .. . C(w) N .. . / l(w) Value 21.81 21.08 20.08 19.94 19.70 19.40 19"
Y12-1038,I05-1059,0,0.0717706,"Missing"
Y12-1038,R09-1040,1,0.858159,"panese and Chinese word segmentation. The average length for the unsegmented Japanese sentences are 17 (std. dev. ±9.95) characters and 11 (std. dev. ±7.40) for Chinese. For pre-segmented text corpus, the average length is 10 (std. dev. ±5.93) words for Japanese and 8 (std. dev. ±4.99) for Chinese. Sentence length distributions in both presegmented and unsegmented corpora are shown in Figure 2 and Figure 3 respectively, 60 Sentence length (zh) in words 50 40 30 Aligners and Configurations Used In our experiments, we use the open source implementation of the sampling-based approach, Anymalign (Lardilleux and Lepage, 2009)1 , to perform subsentential extraction from the above-described bicorpus. Anymalign was run for three hours in its basic version (Anym b.) and with the option -i (Anym -i), where parameter i ranged from 1 to 10. The use of this option allows to extract longer phrases by enforcing n-grams to be considered as tokens. For pre-segmented texts, option -i allows to group words into phrases more easily. For unsegmented texts, as a token is a single character, the use of option -i allows to group characters into words, and then, into phrases, more easily. In order to compare the performance of our ph"
Y12-1038,P11-2028,0,0.0223582,"Missing"
Y12-1038,P98-2206,0,0.177204,"Missing"
Y12-1038,niessen-etal-2000-evaluation,0,0.0606355,"o Train Tune Test Sentences Avg. len(w) Avg. len(c) Sentences Avg. len(w) Avg. len(c) Sentences Avg. len(w) Avg. len(c) Japanese 9,500 10 (±5.93) 17 (±9.95) 500 10 (±5.96) 17 (±9.98) 500 10 (±5.88) 17 (±9.85) Chinese 9,500 8 (±4.99) 11(±7.40) 500 8 (±5.10) 11(±7.55) 500 8 (±5.19) 11(±7.94) Table 4: Statistics of the training, tuning and testing corpora. Avg. len(w) stands for the average number of words in each sentence. Avg. len(c) stands for the average number of characters in each sentence. perform our machine translation experiments. As for the evaluation, we use the standard metrics WER (Nießen et al., 2000), BLEU (Papineni et al., 2002), NIST (Doddington et al., 2000) and TER (Snover et al., 2006). Being a fast, automated and open source tool, the BLEU metric has been adopted as the main measure of fluency and adequacy (Akiba et al., 2004) in the domain of machine translation. It basically evaluates the precision of N-grams according to a reference translation. However, word-level BLEU metric has been challenged in recent years. Denoual and Lepage (2005) studied the equivalence of applying BLEU metrics in characters and suggested that the use of BLEU at the character level could eliminate the wo"
Y12-1038,I05-3027,0,0.0807988,"Missing"
Y12-1038,P02-1040,0,\N,Missing
Y12-1038,W03-1709,0,\N,Missing
Y12-1038,P07-2045,0,\N,Missing
Y12-1038,C98-2201,0,\N,Missing
Y12-1038,J03-1002,0,\N,Missing
Y12-1038,W04-1118,0,\N,Missing
Y12-1038,C10-1132,0,\N,Missing
Y13-1041,C04-1086,0,0.0255024,"es to map directly from source graphemes to target graphemes (Li et al., 2004; Sherif and Kondrak, 2007; Garain et al., 2012; Lehal and Saini, 2012b). In the phoneme-based model, phonetic information or pronunciation is used, and thus additional processing step of converting source grapheme to source phoneme is required. It tries to transform the source graphemes to target graphemes via phonemes as a pivot (Knight and Graehl, 1998; Gao et al., 2004; Ravi and Knight, 2009). A hybrid transliteration approach tries to use both the grapheme-based transliteration model and the phoneme-based model (Bilac and Tanaka, 2004; Lehal and Saini, 2012a). As described in (Oh et al., 2006), the correspondence-based transliteration model (Oh and Choi, 2002) is also considered as a hybrid approach. However, it differs from the others in that it takes into consideration of the correspondence between a source grapheme and a source phoneme, while a general hybrid approach simply uses a combination of graphemebased model and phoneme-based model through linear interpolation. Machine transliteration, especially those methods that adopt statistical models, rely on training data to learn transliteration rules. Several studies on"
Y13-1041,W04-2209,0,0.0955774,"n. The structure of the proposed method is summarized in Figure 2. 3.1 Dice(wx , wy ) = 2n(wx , wy ) n(wx ) + n(wy ) (2) where n(wx ) and n(wy ) are the number of bigram occurrences in word wx and wy respectively, and n(wx , wy ) represents the number of bigram occurrences found in both words. Acquisition of Word Pairs In this section, we will describe our method of obtaining katakana - English word pairs by making use of parallel corpus. The procedure consists of two stages. In the first stage, bilingual entries from a freely-available dictionary, JMdict (Japanese - Multilingual dictionary) (Breen, 2004), are first employed to construct a seed training data. By making use of this seed training set, a back-transliteration model 3.1.1 One-to-many Correspondence There is the case where a single katakana word may match a sequence of English words. Examples are shown in Table 1. In order to take into consideration of one-to-many match and extract those word pairs from parallel corpus, we pre401 PACLIC-27 processed the English part of the corpus. Given a katakana word, for its counterpart, the English sentence, we segment it into n-grams, where n ≤ 3. The Dice coefficient is then calculated between"
Y13-1041,I05-2014,1,0.815,"Missing"
Y13-1041,C12-2034,0,0.0269378,"ndency structure analyzer and the source (i.e., Japanese) part of a parallel corpus to build a model for normalizing orthographic variants and translate them into English words. use of machine transliteration. According to (Oh et al., 2006), machine transliteraion can be classified into four models: grapheme-based transliteration model, phoneme-based transliteration model, hybrid transliteration model, and correspondencebased transliteration model. A grapheme-based transliteration model tries to map directly from source graphemes to target graphemes (Li et al., 2004; Sherif and Kondrak, 2007; Garain et al., 2012; Lehal and Saini, 2012b). In the phoneme-based model, phonetic information or pronunciation is used, and thus additional processing step of converting source grapheme to source phoneme is required. It tries to transform the source graphemes to target graphemes via phonemes as a pivot (Knight and Graehl, 1998; Gao et al., 2004; Ravi and Knight, 2009). A hybrid transliteration approach tries to use both the grapheme-based transliteration model and the phoneme-based model (Bilac and Tanaka, 2004; Lehal and Saini, 2012a). As described in (Oh et al., 2006), the correspondence-based transliteration"
Y13-1041,W02-1206,0,0.447386,"ng translation rules and phrases, which are stored in “phrase tables”. Words that cannot be found in phrase tables thus result in out-of-vocabulary words (OOVs) for a machine translation system. The large number of loanwords and orthographic variants in Japanese makes the OOVs problem more severe than in other languages. As stated in (Oh et al., 2006), most of out-of-vocabulary words in translations from Japanese are made up of proper nouns and technical terms, which are phonetically transliterated from other languages. In addition, the highly irregular Japanese orthography as is analyzed in (Halpern, 2002) poses a challenge for machine translation tasks. Japanese is written in four different sets of scripts: kanji, hiragana, katakana, and romaji (Halpern, 2002). Kanji is a logographic Yves Lepage IPS Waseda University Fukuoka, Japan yves.lepage@waseda.jp system consisting of characters borrowed from the Chinese characters. Hiragana is a syllabary system used mainly for functional elements. Katakana is also a syllabary system. Along with hiragana, they are generally referred as kana. Katakana is used to write new words or loan words, i.e., words that are borrowed and transliterated from foreign"
Y13-1041,N03-1017,0,0.0107014,"and 6 deal with the experiments and error analysis. Conclusion and future directions are drawn in Section 7. 2 Related Work A number of works have been proposed to tackle the katakana out-of-vocabulary words by making 399 Copyright 2013 by Juan Luo, John Tinsley, and Yves Lepage 27th Pacific Asia Conference on Language, Information, and Computation pages 399－408 PACLIC-27 noisy channel error model was then employed to map and harvest (katakana, English) pairs. The method, however, failed to deal with compounds, i.e., a single katakana word may match more than one English words. Lee and Chang (2003) proposed using a statistical machine transliteration model to identify English - Chinese word pairs from parallel texts by exploiting phonetic similarities. Oh and Isahara (2006) presented a transliteration lexicon acquisition model to extract transliteration pairs from mining the web by relying on phonetic similarity and joint-validation. While many techniques have been proposed to handle Japanese katakana words and translate these words into English, few works have focused on kanji and hiragana. As is shown in (Halpern, 2002), the Japanese orthography is highly irregular, which contributes"
Y13-1041,W02-2016,0,0.0587396,"s. Patterns English Okurigana variants ‘moving’ ‘effort’ Kun homophones Reading Variants Figure 4: Sample of phonetic-to-standard Japanese parallel corpus /hikkoshi/ 引越し 引っ越し 引越 /torikumi/ 取り組み 取組み 取組 ‘bridge’ /hashi/ ‘chopsticks’ ‘account’ /kouza/ ‘course’ comprises two processes: (a) building a model; (b) normalizing and translating kanji-hiragana OOVs. In the first process, firstly, we use the Japanese part of the parallel corpus (the same Japanese-English parallel corpus used for training in the standard phrase-based SMT) as the input to the Japanese dependency structure analyzer CaboCha (Kudo and Matsumoto, 2002). A phonetic-to-standard Japanese parallel corpus (Figure 4) is then obtained to train a monolingual Japanese model which is also built upon a phrase-based statistical machine translation framework. In the second process, the dependency structure analyzer CaboCha 橋 箸 口座 講座 Table 2: Orthographic variants In this section, we will present our approach for tackling and normalizing out-of-vocabulary kanji and hiragana words. The architecture of the approach is summarized in Figure 3. The method 402 PACLIC-27 is applied to generate corresponding phonetics from a list of kanji-hiragana out-of-vocabul"
Y13-1041,W03-0317,0,0.0373026,"rds. Section 5 and 6 deal with the experiments and error analysis. Conclusion and future directions are drawn in Section 7. 2 Related Work A number of works have been proposed to tackle the katakana out-of-vocabulary words by making 399 Copyright 2013 by Juan Luo, John Tinsley, and Yves Lepage 27th Pacific Asia Conference on Language, Information, and Computation pages 399－408 PACLIC-27 noisy channel error model was then employed to map and harvest (katakana, English) pairs. The method, however, failed to deal with compounds, i.e., a single katakana word may match more than one English words. Lee and Chang (2003) proposed using a statistical machine transliteration model to identify English - Chinese word pairs from parallel texts by exploiting phonetic similarities. Oh and Isahara (2006) presented a transliteration lexicon acquisition model to extract transliteration pairs from mining the web by relying on phonetic similarity and joint-validation. While many techniques have been proposed to handle Japanese katakana words and translate these words into English, few works have focused on kanji and hiragana. As is shown in (Halpern, 2002), the Japanese orthography is highly irregular, which contributes"
Y13-1041,C12-2062,0,0.164396,"Missing"
Y13-1041,C12-2063,0,0.0395409,"Missing"
Y13-1041,P04-1021,0,0.0492951,"ry words, we propose to use a Japanese dependency structure analyzer and the source (i.e., Japanese) part of a parallel corpus to build a model for normalizing orthographic variants and translate them into English words. use of machine transliteration. According to (Oh et al., 2006), machine transliteraion can be classified into four models: grapheme-based transliteration model, phoneme-based transliteration model, hybrid transliteration model, and correspondencebased transliteration model. A grapheme-based transliteration model tries to map directly from source graphemes to target graphemes (Li et al., 2004; Sherif and Kondrak, 2007; Garain et al., 2012; Lehal and Saini, 2012b). In the phoneme-based model, phonetic information or pronunciation is used, and thus additional processing step of converting source grapheme to source phoneme is required. It tries to transform the source graphemes to target graphemes via phonemes as a pivot (Knight and Graehl, 1998; Gao et al., 2004; Ravi and Knight, 2009). A hybrid transliteration approach tries to use both the grapheme-based transliteration model and the phoneme-based model (Bilac and Tanaka, 2004; Lehal and Saini, 2012a). As described in (Oh et al.,"
Y13-1041,P11-2028,0,0.0599355,"Missing"
Y13-1041,P11-2093,0,0.0576504,"Missing"
Y13-1041,J03-1002,0,0.00340077,"ome katakana words, they are transliterated correctly as references. For other katakana words, it shows that the output of transliteration contain spelling errors. For example, the grapheme “アン” can be transliterated into “an”, “en”, or “un”. For the katakana word “アンハ ッ ピー” (unhappy), it is erroneously transliterated into “anhappy” . Katakana Transliteration Test To train a back-transliteration model which is built upon a phrase-based statistical machine translation framework, we used the state-of-the-art machine translation toolkit: Moses decoder (Koehn et al., 2007), alignment tool GIZA++ (Och and Ney, 2003), MERT (Minimum Error Rate Training) (Och, 2003) to tune the parameters, and the SRI Language Modeling toolkit (Stolcke, 2002) to build character-level target language model. The data set for training (499,871 entries) we used in the experiment contains the JMdict entries and word pairs extracted from parallel corpus. The JMdict consists of 166,794 Japanese English entries. 19,132 katakana - English entries are extracted from the dictionary. We also extracted 480,739 katakana - English word pairs from NTCIR Japanese - English parallel corpus. The development set is made of 500 word pairs, and"
Y13-1041,P03-1021,0,0.00485124,"references. For other katakana words, it shows that the output of transliteration contain spelling errors. For example, the grapheme “アン” can be transliterated into “an”, “en”, or “un”. For the katakana word “アンハ ッ ピー” (unhappy), it is erroneously transliterated into “anhappy” . Katakana Transliteration Test To train a back-transliteration model which is built upon a phrase-based statistical machine translation framework, we used the state-of-the-art machine translation toolkit: Moses decoder (Koehn et al., 2007), alignment tool GIZA++ (Och and Ney, 2003), MERT (Minimum Error Rate Training) (Och, 2003) to tune the parameters, and the SRI Language Modeling toolkit (Stolcke, 2002) to build character-level target language model. The data set for training (499,871 entries) we used in the experiment contains the JMdict entries and word pairs extracted from parallel corpus. The JMdict consists of 166,794 Japanese English entries. 19,132 katakana - English entries are extracted from the dictionary. We also extracted 480,739 katakana - English word pairs from NTCIR Japanese - English parallel corpus. The development set is made of 500 word pairs, and 500 entries are used for test set. The experimen"
Y13-1041,C02-1099,0,0.0494282,"and Saini, 2012b). In the phoneme-based model, phonetic information or pronunciation is used, and thus additional processing step of converting source grapheme to source phoneme is required. It tries to transform the source graphemes to target graphemes via phonemes as a pivot (Knight and Graehl, 1998; Gao et al., 2004; Ravi and Knight, 2009). A hybrid transliteration approach tries to use both the grapheme-based transliteration model and the phoneme-based model (Bilac and Tanaka, 2004; Lehal and Saini, 2012a). As described in (Oh et al., 2006), the correspondence-based transliteration model (Oh and Choi, 2002) is also considered as a hybrid approach. However, it differs from the others in that it takes into consideration of the correspondence between a source grapheme and a source phoneme, while a general hybrid approach simply uses a combination of graphemebased model and phoneme-based model through linear interpolation. Machine transliteration, especially those methods that adopt statistical models, rely on training data to learn transliteration rules. Several studies on the automatic acquisition of transliteration pairs for different language pairs (e.g., English Chinese, English - Japanese, Eng"
Y13-1041,P02-1040,0,0.0855847,"Missing"
Y13-1041,N09-1005,0,0.0165484,"sed transliteration model, hybrid transliteration model, and correspondencebased transliteration model. A grapheme-based transliteration model tries to map directly from source graphemes to target graphemes (Li et al., 2004; Sherif and Kondrak, 2007; Garain et al., 2012; Lehal and Saini, 2012b). In the phoneme-based model, phonetic information or pronunciation is used, and thus additional processing step of converting source grapheme to source phoneme is required. It tries to transform the source graphemes to target graphemes via phonemes as a pivot (Knight and Graehl, 1998; Gao et al., 2004; Ravi and Knight, 2009). A hybrid transliteration approach tries to use both the grapheme-based transliteration model and the phoneme-based model (Bilac and Tanaka, 2004; Lehal and Saini, 2012a). As described in (Oh et al., 2006), the correspondence-based transliteration model (Oh and Choi, 2002) is also considered as a hybrid approach. However, it differs from the others in that it takes into consideration of the correspondence between a source grapheme and a source phoneme, while a general hybrid approach simply uses a combination of graphemebased model and phoneme-based model through linear interpolation. Machine"
Y13-1041,P07-1119,0,0.0213034,"ose to use a Japanese dependency structure analyzer and the source (i.e., Japanese) part of a parallel corpus to build a model for normalizing orthographic variants and translate them into English words. use of machine transliteration. According to (Oh et al., 2006), machine transliteraion can be classified into four models: grapheme-based transliteration model, phoneme-based transliteration model, hybrid transliteration model, and correspondencebased transliteration model. A grapheme-based transliteration model tries to map directly from source graphemes to target graphemes (Li et al., 2004; Sherif and Kondrak, 2007; Garain et al., 2012; Lehal and Saini, 2012b). In the phoneme-based model, phonetic information or pronunciation is used, and thus additional processing step of converting source grapheme to source phoneme is required. It tries to transform the source graphemes to target graphemes via phonemes as a pivot (Knight and Graehl, 1998; Gao et al., 2004; Ravi and Knight, 2009). A hybrid transliteration approach tries to use both the grapheme-based transliteration model and the phoneme-based model (Bilac and Tanaka, 2004; Lehal and Saini, 2012a). As described in (Oh et al., 2006), the correspondence-"
Y13-1041,P07-2045,0,\N,Missing
Y13-1041,J98-4003,0,\N,Missing
Y15-1003,J94-4004,0,0.455718,"ning for English-to-Hindi. Introduction Over the last decade, phrase-based statistical machine translation (Koehn et al., 2003) systems have demonstrated that they can produce reasonable quality when ample training data is available, especially for language pairs with similar word order. However, the PB-SMT model has not yet been capable of satisfying the various translation tasks for very different languages (Isozaki et al., 2010). The existence of translation divergences makes the straightforward transfer from source sentences into target sentences hard. Though many previous pieces of work (Dorr, 1994; Habash et al., 2002; Dorr et al., 2004) have attempted to take account for divergences and to deal In the issue of translation using analogy, one of the main drawbacks should be addressed is the problem of ”over-generative”. Analogy is able to capture the most divergences of translation in the most cases, yet it generates a great number of solutions that are ungrammatical and incorrect. In this paper, we propose to translate useen bigrams as reconstructing with the principle of analogy learning. In machine learning, SVMs have been shown that it is efficient in performing a non-linear classif"
Y15-1003,D07-1092,0,0.0694043,"Missing"
Y15-1003,Y10-1041,0,0.0145917,"ed on an analogy learning method. We investigate the coverage of translated bigrams in the test set and inspect the probability of translating a bigram using analogy. Analogical learning has been investigated by several authors. To cite a few, Lepage et al. (2005) showed that proportional analogy can capture some syntactic and lexical structures across languages. Langlais et al. (2007) investigated the more specific task of translating unseen words. Bayoudh et al. (2007) explored generating new learning examples from very scarce original learning data using analogy to train an SVM classifier. Dandapat et al. (2010) performed transliteration by analogical learning for English-to-Hindi. Introduction Over the last decade, phrase-based statistical machine translation (Koehn et al., 2003) systems have demonstrated that they can produce reasonable quality when ample training data is available, especially for language pairs with similar word order. However, the PB-SMT model has not yet been capable of satisfying the various translation tasks for very different languages (Isozaki et al., 2010). The existence of translation divergences makes the straightforward transfer from source sentences into target sentence"
Y15-1003,P98-1120,1,0.534793,"this work. Verbal analogies are often written A : B :: C : D. They meaning A is to B as C is to D. For example: annual annual the statis: :: the taxes : taxes statistics tics The above example can be understood as follows: we reconstruct an unseen bigram annual taxes by a PACLIC 29 triple of known bigrams. All the elements in the unseen bigram is taken by similarity from the second (annual statistics) and third (the taxes) known bigrams and put together by difference with the fourth known bigram (the statistics). The definition of proportional analogy that we use in this paper is drawn from (Lepage, 1998) and we focus in this study on formal proportional analogies. A 4-tuple of n-grams A, B, C and D is said to be a proportional analogy if the following 3 constraints are verified. The lengths of the n-grams may be different, but should meet the following constraints: source target annual statistics input :annual taxes the statistics the taxes éléments annuels output: impôts annuels les éléments les impôts Figure 2: View of the harmonization parallelopiped: four terms in each language form a monolingual proportional analogy. 1. |A|a + |D|a = |C|a + |B|a , ∀a 2. d(A, B) = d(C, D) 3. d(A, C) = d(B"
Y15-1003,H01-1033,0,0.101819,"Missing"
Y15-1003,habash-dorr-2002-handling,0,0.140291,"Missing"
Y15-1003,J03-1002,0,0.0065873,"Missing"
Y15-1003,N03-1017,0,0.0334729,"Missing"
Y15-1003,P05-1032,0,0.0916234,"Missing"
Y15-1003,P05-1067,0,0.0181352,"oblem from an emerging and special point of view: bigrams and the corresponding translations. We first profile corpora and explore the constituents of bigrams in the source language. Then we translate unseen bigrams based on proportional analogy and filter the outputs using an Support Vector Machine (SVM) classifier. The experiment results also show that even a small set of features from analogous can provide meaningful information in translating by analogy. 1 Since sentence consists of bigrams, instead of analysing the syntactic structures of the whole sentence or part of the sentence as in (Ding and Palmer, 2005), we explore the possibilities of translating unseen bigrams based on an analogy learning method. We investigate the coverage of translated bigrams in the test set and inspect the probability of translating a bigram using analogy. Analogical learning has been investigated by several authors. To cite a few, Lepage et al. (2005) showed that proportional analogy can capture some syntactic and lexical structures across languages. Langlais et al. (2007) investigated the more specific task of translating unseen words. Bayoudh et al. (2007) explored generating new learning examples from very scarce o"
Y15-1003,2005.mtsummit-papers.11,0,0.0204335,"er to evaluate the ceiling coverage of ”attested translation”, we conduct the synchronous parsing for fast obtaining the examples. It is easy to obtain the alignments between A and A0 in the test set with some 19 Data profiling We first profile the test set by exploring the proportion of unseen bigrams in the source language. Then we investigate the reconstructiblility/bidirectional reconstructibility of unseen bigrams in the source language. Finally, we estimate the maximum of attested translation bigrams using this analogy-based approach. 3.1 Data preprocessing We use the Europarl Corpora1 (Koehn, 2005) to prepare the classification examples used to train and test the SVM classifier. We split the corpus into two parts: a training set and a test set. A set of 100,000 sentences which lengths less than 30 with the French translation are extracted as the training set. We also sample a set of 10,000 sentences from the remaining corpus not contained in training set as the test set. This corpus only offers aligned texts, however, it does not provide word alignment information for each language pair. Table 1 shows some statistic of bigrams and the proportion of unseen bigrams in the experiment data."
Y15-1003,2005.iwslt-1.23,0,0.0799747,"Missing"
Y15-1003,P05-1033,0,0.0301008,"sh sentence which is better for translation parameter training with j. The phrases with the same index are aligned. Based on these two sentences, different categories of alignments have been identified. For each category, examples are given: According to whether the translation is continuous or not, we divide the alignments into 2 categories: 1. both the n-gram and its translation in the target language are continuous. 2. the translation in the target language contains gaps because of syntactic divergence (Dorr et al., 2004). We define ”[X]” to stand for gaps in the target side as denoted by (Chiang, 2005) in syntax-based MT and we can have the following classifications: • Continuous Alignment – Bigram-to-ngram the translation in the target language is continuous ngram, e.g., 17 – Bigram-to-N-gram-with-gaps a large number of translations in the target language are not continuous. This is a common phenomenon is illustrated by (4). he saw to kara wa [X] mita. – Crossing-N-gram-with-gaps the bigram was aligned with dis-continuous words with gaps in the middle, at same time, the translation is in a different order, e.g., (5). sipo no neko to cat [X] tail. 2.2 Proportional analogy In this section, w"
Y15-1003,2006.amta-papers.11,0,0.0637662,"Missing"
Y15-1003,2007.mtsummit-papers.19,0,0.123853,"Missing"
Y15-1003,D07-1104,0,0.018801,"alignment a, we apply the formula of IBM Model 1 to compute the lexical translation probability of a phrase e given the foreign phrase f as (Koehn 3 https://www.csie.ntu.edu.tw/ cjlin/libsvm/ PACLIC 29 et al., 2003): Plex (e|f, a) = I Y i=1 X 1 w(ei |fj ) {j|(i, j) ∈ a} ∀(i,j)∈a (4) Here, we compute the score as the following equation without the word alignment: I 1X log max {w(ei |fj )} I {j|∀(i,j)∈a} i=1 (5) Length: the lengths of A0 in words, ’[X]’ should not be recognized as a word, because it can be ε. Plex (e|f ) = Frequency: we compile the data with the suffix array for fast searching (Lopez, 2007). We calculate the frequency of occurrence for each n-gram generated by analogy in French (with/without gaps). The complete French subset of Europarl corpus is used as the reference. sentences words avg.(words/sentence) stdev.(words/sentence) Reference (French) 386,237 12,175,424 31.52 ±6.24 Dice’s coefficient: Dice coefficient measures the presence/absence of data between to phrases, where |X |and |Y |are the number of words in set X and Y , respectively, and |X ∩Y | is the number of words shared by the two set. We import the following formula to compute the score of Dice coefficient among B"
Y15-1003,2005.mtsummit-ebmt.11,1,0.805991,"Missing"
Y15-1003,J06-3003,0,\N,Missing
Y15-1003,H05-1095,0,\N,Missing
Y15-1003,P07-2045,0,\N,Missing
Y15-1003,D10-1092,0,\N,Missing
Y15-1003,C98-1116,1,\N,Missing
Y15-1003,C08-1114,0,\N,Missing
Y15-1003,C12-2003,0,\N,Missing
Y15-2018,I05-3017,0,0.0535692,"inst segmentation and output the final results according to the vote results. Experiments 5.1 PKU Corpus R F Roov 90.7 87.4 6.9 94.6 95.0 78.7 89.9 90.4 60.7 Riv 95.8 95.6 91.6 Table 3: Performance of our system on the SIGHAN 2005 data set. Best05 refers to the best closed-set results in SIGHAN 2005 bakeoff. Table 1: Corpus details of PKU test set. 5 P 84.3 95.4 90.9 Data and Evaluation To evaluate the effectiveness of our proposed method, we conduct experiments on a widely used Chinese word-segmented corpora, namely PKU, from the second SIGHAN international Chinese word segmentation bakeoff (Emerson, 2005). The training set and the test set are publicly available from the official website2 . Table 1 shows some statistics on the data sets. All evaluation results in this paper are tested by the official scoring script, also downloaded from the official website. The segmentation accuracy is evaluated by test recall (R), test precision (P) and balanced F-score, as defines in Equation (2), (3) and (4). Effects of Length of n-grams and Edit Distance As discussed in section 4, long sentences are easier to miss hypotheses of segmentation. So the length of n-grams will influence the segmentation results"
Y15-2018,P07-2018,0,0.081835,"Missing"
Y15-2018,I05-3021,0,0.0947309,"Missing"
Y15-2018,I05-3027,0,0.0490421,"of n-grams. 5.3 Results We set length of n-grams to 3 and edit distance to 2 for approximate string match to perform our experiments. Table 3 shows our empirical results on the data set. Our system achieve a significantly better results than the baseline. Riv score shows that our method performs well on in vocabulary (IV) word recognition. Simultaneously, the Roov score shows that our method has certain ability to deal with outnumber of correctly segmented words R= of-vocabulary (OOV) word and guess their form. total number of words in gold standard segmentation (2) Compared with best result (Tseng et al., 2005) in SIGHAN 2005, our result still has a lot of room for improvement. But as a original method which do number of correctly segmented words P= (3) not need any pre-training or lexical knowledge, our total number of words in segmentation result method has a great potential in CWS. F = 2×P ×R P +R (4) Our experiments follow the closed track. It means that no extra resource other than training corpora is used. 2 http://www.sighan.org/bakeoff2005/ 155 6 Conclusion In this paper, we presented an approach to Chinese word segmentation based on proportional analogy and majority voting to make decision"
Y15-2018,P98-1120,1,\N,Missing
Y15-2018,C98-1116,1,\N,Missing
Y16-2010,P06-1067,0,0.0375123,"at learning a preordering model and its results are also reported. 1 Introduction One of the major common challenges for machine translation (MT) is the different order of the same conceptual units in the source and target languages. In order to get a ﬂuent and adequate translation in the target language, the default phrase-based statistical machine translation (PB-SMT) system implemented in MOSES has a simple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instan"
Y16-2010,J92-4003,0,0.607282,"tracted at random from the training set. We use three kinds of features, LEX, POS, and CLASS. LEX consists in the lexical items inside a given window around the current word in the source language. POS are the parts-of-speech of the lexical items of the LEX fea3 4 128 http://www.phontron.com/kftt/index.html http://www.phontron.com/kytea/ PACLIC 30 Proceedings ture words. The CLASS features are their semantic classes. The POS tagging information is provided by KyTea for Japanese, and the Lookahead Part-OfSpeech Tagger (Tsuruoka et al., 2011) for English.5 We use the Brown clustering algorithm (Brown et al., 1992; Liang, 2005) for word class information in English and Japanese. 6.2 Evaluation Metrics In order to evaluate the efﬁciency of reordering, we use a modiﬁed version of the Fuzzy Reordering Score (FRS) (Talbot et al., 2011) and Kendall’s τ (Kendall, 1938) as intrinsic evaluation metrics. The modiﬁed version of FRS (see Equation (7)) is inspired by (Nakagawa, 2015) because only two words are considered and the indices of the ﬁrst and the last words are also considered (Neubig et al., 2012). mod FRS = B |S |+ 1 (7) B represents the number of word bigrams which appear in both the reordered sentenc"
Y16-2010,P14-2026,0,0.0124797,"source sentence, and γ(S) stands for the set of all possible reordering of the source sentence. Syntax-based preordering based on the existence parsers has been proposed to pre-process the source sentences by using automatically learned rewriting patterns (Xia and McCord, 2004). Several methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preordering model. Several pieces of research (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) are mainly about using tree structures as latent"
Y16-2010,J07-2003,0,0.0653251,"ystem implemented in MOSES has a simple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (D"
Y16-2010,P04-1015,0,0.0861124,"can be regarded as ﬁnding the best parse tree. To assess the quality of a parse tree, we compare it with the tree structure output by the HSSA method. The best parse tree is the tree with the maximal score deﬁned by the following formula: dˆ = argmax  σ(m) d∈D(T ) m∈Nodes(T ) (6) where d represents one derivation in the set of all possible derivations D(T ) for the tree structure T ; m represents one node in the set of nodes Nodes(T ) of the tree structure T , and σ(m) represents the score of the node. The score of a node in a tree structure is computed by applying the perceptron algorithm (Collins and Roark, 2004), i.e., by taking each node of trees as a latent variable (Nakagawa, 2015). This algorithm is an online learning algorithm, and processes nodes in an available tree structure one by one, by using the following formula to calculate the score of each node σ(m): σ(m) = Λ · Φ(m), m ∈ Nodes(T ) where Φ(m) represents the feature vector of this node, and Λ represents the vector of feature weights. Due to iterated binary decomposition, an increasing number of iterations for one sentence results in many derivations that wait for being checked 127 Figure 6: Example of building and applying preordering m"
Y16-2010,P05-1066,0,0.182711,"Missing"
Y16-2010,D11-1018,0,0.0945961,") or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) learn a preordering model based on Bracketing Transduction Grammar (BTG) (Wu, 1997) from parallel texts to score permutations by using tree structures as latent variables. They build the needed tree structures and the preordering model (i.e., a BTG) at the same time using word alignments. However it is needed to check whether a given sentence can ﬁt the desired tree structures. It seems of course more difﬁcult to build both the tree structures and the preordering model at the same time than to build only a preordering model if the tree structures are give"
Y16-2010,W12-4207,0,0.019436,"of the sentence. Sˆ = argmax P (S  |S) S  ∈γ(S) (1) Sˆ represents the best reordered source sentence, and γ(S) stands for the set of all possible reordering of the source sentence. Syntax-based preordering based on the existence parsers has been proposed to pre-process the source sentences by using automatically learned rewriting patterns (Xia and McCord, 2004). Several methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preordering model. Several pieces of research (DeNero and Uszkoreit, 201"
Y16-2010,W11-2123,0,0.0204648,"mization (EM) algorithm on the training data. In the end, we obtain a preordering model with features and corresponding weights. We then apply the preordering model on all the source sentences of all three data sets, training, tuning, and test, to reorder their words. A standard PBSMT system is then built as usual with reordered source sentences in place of the original sources sentences, and with their corresponding target sentences. 6 Experiments 6.1 Experimental Settings We build our PB-SMT systems in a standard way using the Moses system (Koehn et al., 2007), KenLM for language modelling (Heaﬁeld, 2011), and standard lexical reordering model (Koehn et al., 2005). This lexical reordering model allows local reordering with a given distortion limit during decoding. The default of the distortion limit in Moses is 6. When set to 0, the system does not perform any lexical reordering. Train Tune Test Sentence Pairs 330,000 1,235 1,160 Words Japanese English 6.09 M 5.91 M 34.4 k 30.8 k 28.5 k 26.7 k Table 1: Number of sentences and words in the training, tuning and test sets of the KFTT corpus. The language pair we work on is Japanese– English in both directions. The data sets are the training, tuni"
Y16-2010,W10-1736,0,0.124678,"rdering of the source sentence. Syntax-based preordering based on the existence parsers has been proposed to pre-process the source sentences by using automatically learned rewriting patterns (Xia and McCord, 2004). Several methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preordering model. Several pieces of research (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) are mainly about using tree structures as latent variables for preordering models. This is detailed in the next subse"
Y16-2010,D10-1092,0,0.0620403,"Missing"
Y16-2010,N03-1017,0,0.0447613,"and 10 RIBES points respectively, when preordering the source sentences using the learnt preordering model and using a distortion limit of 0. An attempt at learning a preordering model and its results are also reported. 1 Introduction One of the major common challenges for machine translation (MT) is the different order of the same conceptual units in the source and target languages. In order to get a ﬂuent and adequate translation in the target language, the default phrase-based statistical machine translation (PB-SMT) system implemented in MOSES has a simple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 20"
Y16-2010,P07-2045,0,0.00639053,"their weight vectors by using the Expectation–Maximization (EM) algorithm on the training data. In the end, we obtain a preordering model with features and corresponding weights. We then apply the preordering model on all the source sentences of all three data sets, training, tuning, and test, to reorder their words. A standard PBSMT system is then built as usual with reordered source sentences in place of the original sources sentences, and with their corresponding target sentences. 6 Experiments 6.1 Experimental Settings We build our PB-SMT systems in a standard way using the Moses system (Koehn et al., 2007), KenLM for language modelling (Heaﬁeld, 2011), and standard lexical reordering model (Koehn et al., 2005). This lexical reordering model allows local reordering with a given distortion limit during decoding. The default of the distortion limit in Moses is 6. When set to 0, the system does not perform any lexical reordering. Train Tune Test Sentence Pairs 330,000 1,235 1,160 Words Japanese English 6.09 M 5.91 M 34.4 k 30.8 k 28.5 k 26.7 k Table 1: Number of sentences and words in the training, tuning and test sets of the KFTT corpus. The language pair we work on is Japanese– English in both di"
Y16-2010,2012.eamt-1.62,1,0.91879,"ions by using tree structures as latent variables. They build the needed tree structures and the preordering model (i.e., a BTG) at the same time using word alignments. However it is needed to check whether a given sentence can ﬁt the desired tree structures. It seems of course more difﬁcult to build both the tree structures and the preordering model at the same time than to build only a preordering model if the tree structures are given. In this paper, we rapidly obtain tree structures using word-to-word associations taking advantage of the hierarchical subsentential alignment (HSSA) method (Lardilleux et al., 2012). This method computes a recursive binary segmentation in both languages at the same 30th Pacific Asia Conference on Language, Information and Computation (PACLIC 30) Seoul, Republic of Korea, October 28-30, 2016 123 Figure 1: Example of preordering. time, judging whether two spans with the same concepts in both languages are inverted or not. We conduct oracle experiments to show that these tree structures may be beneﬁcial for PB-SMT. We then use these tree structures as the training data to build a preordering model without checking the validity by modifying the top-down BTG parsing method in"
Y16-2010,P15-1021,0,0.0893505,"Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) learn a preordering model based on Bracketing Transduction Grammar (BTG) (Wu, 1997) from parallel texts to score permutations by using tree structures as latent variables. They build the needed tree structures and the preordering model (i.e., a BTG) at the same time using word alignments. However it is needed to check whether a given sentence can ﬁt the desired tree structures. It seems of course more difﬁcult to build both the tree structures and the preordering model at the same time than to build only a preordering model if the tree structures are given. In this paper, we rapidly obtain tr"
Y16-2010,D12-1077,0,0.164821,"a and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) learn a preordering model based on Bracketing Transduction Grammar (BTG) (Wu, 1997) from parallel texts to score permutations by using tree structures as latent variables. They build the needed tree structures and the preordering model (i.e., a BTG) at the same time using word alignments. However it is needed to check whether a given sentence can ﬁt the desired tree structures. It seems of course more difﬁcult to build both the tree structures and the preordering model at the same time than to build only a preordering model if the tree structures are given. In this paper, we"
Y16-2010,P02-1040,0,0.101157,"endall’s τ to a normalized Kendall’s τ following (Isozaki et al., 2010). Equation (8) gives the deﬁnition. norm τ = 1 − E |S |× (|S |− 1)/2 (8) E represents the number of not increasing word pairs and |S |× (|S |− 1)/2 is the total number of pairs. Being a metric to evaluate the quality of machine translation, RIBES (Isozaki et al., 2010) is an extrinsic metric in our work. However, given the fact that RIBES takes order into account, it can also be considered an intrinsic metric in our work. As a matter of fact, RIBES bases on the computation of FRS and τ . In addition, we of course use BLEU (Papineni et al., 2002) for the evaluation of machine translation quality as it is the de facto standard metric. 5 http://www.logos.ic.i.u-tokyo.ac.jp/ tsuruoka/lapos/ ˜ 6.3 Experimental Results and Analysis Table 2 shows the evaluation results in all intrinsic evaluation metrics (modiﬁed FRS and normalized τ ), the intrinsic and extrinsic evaluation metric (RIBES) and in the extrinsic evaluation metric (BLEU). We use all these metrics in the language pair English–Japanese in both directions. In both directions, the seven other BLEU scores are all statistically signiﬁcantly different (p-value < 0.05) from the BLEU s"
Y16-2010,P07-1090,0,0.0306717,"oduction One of the major common challenges for machine translation (MT) is the different order of the same conceptual units in the source and target languages. In order to get a ﬂuent and adequate translation in the target language, the default phrase-based statistical machine translation (PB-SMT) system implemented in MOSES has a simple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Ma"
Y16-2010,W11-2102,0,0.0171693,"peech of the lexical items of the LEX fea3 4 128 http://www.phontron.com/kftt/index.html http://www.phontron.com/kytea/ PACLIC 30 Proceedings ture words. The CLASS features are their semantic classes. The POS tagging information is provided by KyTea for Japanese, and the Lookahead Part-OfSpeech Tagger (Tsuruoka et al., 2011) for English.5 We use the Brown clustering algorithm (Brown et al., 1992; Liang, 2005) for word class information in English and Japanese. 6.2 Evaluation Metrics In order to evaluate the efﬁciency of reordering, we use a modiﬁed version of the Fuzzy Reordering Score (FRS) (Talbot et al., 2011) and Kendall’s τ (Kendall, 1938) as intrinsic evaluation metrics. The modiﬁed version of FRS (see Equation (7)) is inspired by (Nakagawa, 2015) because only two words are considered and the indices of the ﬁrst and the last words are also considered (Neubig et al., 2012). mod FRS = B |S |+ 1 (7) B represents the number of word bigrams which appear in both the reordered sentence and the golden reference, and |S |represents the length of the source sentence S in words. We also change the formula for calculating Kendall’s τ to a normalized Kendall’s τ following (Isozaki et al., 2010). Equation (8)"
Y16-2010,N04-4026,0,0.0712088,"ering the source sentences using the learnt preordering model and using a distortion limit of 0. An attempt at learning a preordering model and its results are also reported. 1 Introduction One of the major common challenges for machine translation (MT) is the different order of the same conceptual units in the source and target languages. In order to get a ﬂuent and adequate translation in the target language, the default phrase-based statistical machine translation (PB-SMT) system implemented in MOSES has a simple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been propos"
Y16-2010,D09-1105,0,0.0188287,"the source sentences by using automatically learned rewriting patterns (Xia and McCord, 2004). Several methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preordering model. Several pieces of research (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) are mainly about using tree structures as latent variables for preordering models. This is detailed in the next subsection. 2.2 BTG-based Preordering BTG-based preordering is based on Bracketing Transduction Grammar (BTG), also called Invers"
Y16-2010,W11-0328,0,0.0289702,"er of iteration of 20 and 100,000 sentences pairs as preordering training extracted at random from the training set. We use three kinds of features, LEX, POS, and CLASS. LEX consists in the lexical items inside a given window around the current word in the source language. POS are the parts-of-speech of the lexical items of the LEX fea3 4 128 http://www.phontron.com/kftt/index.html http://www.phontron.com/kytea/ PACLIC 30 Proceedings ture words. The CLASS features are their semantic classes. The POS tagging information is provided by KyTea for Japanese, and the Lookahead Part-OfSpeech Tagger (Tsuruoka et al., 2011) for English.5 We use the Brown clustering algorithm (Brown et al., 1992; Liang, 2005) for word class information in English and Japanese. 6.2 Evaluation Metrics In order to evaluate the efﬁciency of reordering, we use a modiﬁed version of the Fuzzy Reordering Score (FRS) (Talbot et al., 2011) and Kendall’s τ (Kendall, 1938) as intrinsic evaluation metrics. The modiﬁed version of FRS (see Equation (7)) is inspired by (Nakagawa, 2015) because only two words are considered and the indices of the ﬁrst and the last words are also considered (Neubig et al., 2012). mod FRS = B |S |+ 1 (7) B represen"
Y16-2010,D11-1045,0,0.0182291,"methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preordering model. Several pieces of research (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) are mainly about using tree structures as latent variables for preordering models. This is detailed in the next subsection. 2.2 BTG-based Preordering BTG-based preordering is based on Bracketing Transduction Grammar (BTG), also called Inversion Transduction Grammar (ITG) (Wu, 1997). Whereas Chomsky Normal Form of context-free rules has two type"
Y16-2010,D07-1077,0,0.0783199,"Missing"
Y16-2010,J97-3002,0,0.83009,"lve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) learn a preordering model based on Bracketing Transduction Grammar (BTG) (Wu, 1997) from parallel texts to score permutations by using tree structures as latent variables. They build the needed tree structures and the preordering model (i.e., a BTG) at the same time using word alignments. However it is needed to check whether a given sentence can ﬁt the desired tree structures. It seems of course more difﬁcult to build both the tree structures and the preordering model at the same time than to build only a preordering model if the tree structures are given. In this paper, we rapidly obtain tree structures using word-to-word associations taking advantage of the hierarchical s"
Y16-2010,I11-1004,0,0.0205391,"tence that maximizes the probability among all possible reordering of the sentence. Sˆ = argmax P (S  |S) S  ∈γ(S) (1) Sˆ represents the best reordered source sentence, and γ(S) stands for the set of all possible reordering of the source sentence. Syntax-based preordering based on the existence parsers has been proposed to pre-process the source sentences by using automatically learned rewriting patterns (Xia and McCord, 2004). Several methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preo"
Y16-2010,C04-1073,0,0.291258,"oehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) learn a preorderi"
Y16-2010,N09-1028,0,0.0483108,"all possible reordering of the source sentence. Syntax-based preordering based on the existence parsers has been proposed to pre-process the source sentences by using automatically learned rewriting patterns (Xia and McCord, 2004). Several methods have been proposed methods, such as constituent parsing by automatically extracting preordering rules from a parallel corpus (Xia and McCord, 2004; Wu et al., 2011) or by creating rules manually (Wang et al., 2007; Han et al., 2012), or dependency parsing with automatically created rules (Habash, 2012; Cai et al., 2014) or manually generated rules (Xu et al., 2009; Isozaki et al., 2010). Another trend of research is to try to solve the preordering problem without relying on parsers. Tromble and Eisner (2009) propose sophisticated reordering models based on the Linear Ordering Problem. Visweswariah et al. (2011) learn a preordering model by similarity with the Traveling Salesman Problem. Lerner and Petrovs (2013) present a source-side classiﬁer-based preordering model. Several pieces of research (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015) are mainly about using tree structures as latent variables for preordering models. This is det"
Y16-2010,P01-1067,0,0.250244,"mple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean), Preordering is a pre-processing task that aims to rearrange the word order of a source sentence to ﬁt the word order of the target language. It is separated from the core translation task. Recent approaches (DeNero and Uszkoreit, 2011; Neubig et al., 2012"
Y16-2010,D07-1056,0,0.0326483,"erent order of the same conceptual units in the source and target languages. In order to get a ﬂuent and adequate translation in the target language, the default phrase-based statistical machine translation (PB-SMT) system implemented in MOSES has a simple distortion model using position (Koehn et al., 2003) and lexical information (Tillmann, 2004) to allow reordering during decoding. Other solutions exist: e.g., the distortion model in (Al-Onaizan and Papineni, 2006) handles n-gram language model limitations; Setiawan et al. (2007) propose a function word centered syntaxbased (FWS) solution; Zhang et al. (2007) propose a reordering model integrating syntactic knowledge. Also, other models than the phrase-based model have been proposed to address the reordering problem, like hierarchical phrase-based SMT (Chiang, 2007) or syntax-based SMT (Yamada and Knight, 2001). Preordering (Xia and McCord, 2004; Collins et al., 2005) has been proposed primarily to solve the problems encountered when translating between languages with widely divergent syntax, for instance, from a subject-verb-object (SVO) language (like English and Mandarin Chinese) to a subjectobject-verb (SOV) language (like Japanese and Korean)"
Y16-2010,2005.iwslt-1.8,0,\N,Missing
Y16-2012,C88-1016,0,0.718217,"ems combined with the state-of-the-art approaches. In addition, by feeding with word-to-word associations, it also can be a real-time word aligner. Our experiments show that, given a reliable lexicon translation table, this simple method can yield comparable results with state-of-theart approaches. 1 Introduction Since most of state-of-the-art Statistical Machine Translation (SMT) approaches require word-toword aligned data on a parallel corpus, word alignment is a fundamental issue to perform this task rapidly. In order to extract translation fragments for various purposes, e.g., word pairs (Brown et al., 1988), phrase pairs (Koehn et al., 2003), hierarchical rules (Chiang, 2005), tree-to-tree correspondences (Zhang et al., 2007), reliable and accurate word aligners are essential. There exist several problems in state-of-the-art methods for word alignment. Present word alignment approaches are usually based on IBM models (Brown et al., 1993), which parameters are estimated using the Expectation-Maximization (EM) algorithm. Sometimes, they are augmented with an HMM-based model (Vogel et al., 1996). Since IBM Models is the restriction to one-to-many alignments, some multi-word units cannot be correctl"
Y16-2012,N06-1014,0,0.116027,"Missing"
Y16-2012,J03-1002,0,0.0416599,"Missing"
Y16-2012,N03-1017,0,0.0599816,"Missing"
Y16-2012,P05-1033,0,0.151571,"ith word-to-word associations, it also can be a real-time word aligner. Our experiments show that, given a reliable lexicon translation table, this simple method can yield comparable results with state-of-theart approaches. 1 Introduction Since most of state-of-the-art Statistical Machine Translation (SMT) approaches require word-toword aligned data on a parallel corpus, word alignment is a fundamental issue to perform this task rapidly. In order to extract translation fragments for various purposes, e.g., word pairs (Brown et al., 1988), phrase pairs (Koehn et al., 2003), hierarchical rules (Chiang, 2005), tree-to-tree correspondences (Zhang et al., 2007), reliable and accurate word aligners are essential. There exist several problems in state-of-the-art methods for word alignment. Present word alignment approaches are usually based on IBM models (Brown et al., 1993), which parameters are estimated using the Expectation-Maximization (EM) algorithm. Sometimes, they are augmented with an HMM-based model (Vogel et al., 1996). Since IBM Models is the restriction to one-to-many alignments, some multi-word units cannot be correctly aligned. It is necessary to train models in both directions, and mer"
Y16-2012,P02-1040,0,0.102699,"Missing"
Y16-2012,P07-2045,0,0.0279794,"Missing"
Y16-2012,C96-2141,0,0.626384,"orm this task rapidly. In order to extract translation fragments for various purposes, e.g., word pairs (Brown et al., 1988), phrase pairs (Koehn et al., 2003), hierarchical rules (Chiang, 2005), tree-to-tree correspondences (Zhang et al., 2007), reliable and accurate word aligners are essential. There exist several problems in state-of-the-art methods for word alignment. Present word alignment approaches are usually based on IBM models (Brown et al., 1993), which parameters are estimated using the Expectation-Maximization (EM) algorithm. Sometimes, they are augmented with an HMM-based model (Vogel et al., 1996). Since IBM Models is the restriction to one-to-many alignments, some multi-word units cannot be correctly aligned. It is necessary to train models in both directions, and merge the outcome of mono-directional alignments using some symmetrization methods can overcome this deﬁciency to some degree. It results, even using the standard open source tool aligner, called GIZA++1 (Och, 2003), which consist of the widely used IBM models and their extensions, still will spend lots of time to obtain word alignments. A recent development of word alignment approach fast align2 (Dyer et al., 2013), based o"
Y16-2012,N13-1073,0,0.0479082,"model (Vogel et al., 1996). Since IBM Models is the restriction to one-to-many alignments, some multi-word units cannot be correctly aligned. It is necessary to train models in both directions, and merge the outcome of mono-directional alignments using some symmetrization methods can overcome this deﬁciency to some degree. It results, even using the standard open source tool aligner, called GIZA++1 (Och, 2003), which consist of the widely used IBM models and their extensions, still will spend lots of time to obtain word alignments. A recent development of word alignment approach fast align2 (Dyer et al., 2013), based on the variation of the IBM model 2, has been reported faster than baseline GIZA++ but with comparable results. However, both mentioned approaches generate asymmetric alignments. In order to obtain the symmetrical word alignments, these approaches symmetrize the alignments in both forward and reverse directions using a symmetrization heuristic called grow-diag-ﬁnal-and (Och, 2003). Starting with the intersection alignment points that occur in both of the two directional alignments, grow-diagﬁnal-and expands the alignment in the union of 1 2 http://www.statmt.org/moses/giza/GIZA++.html"
Y16-2012,P03-1021,0,0.557055,"t approaches are usually based on IBM models (Brown et al., 1993), which parameters are estimated using the Expectation-Maximization (EM) algorithm. Sometimes, they are augmented with an HMM-based model (Vogel et al., 1996). Since IBM Models is the restriction to one-to-many alignments, some multi-word units cannot be correctly aligned. It is necessary to train models in both directions, and merge the outcome of mono-directional alignments using some symmetrization methods can overcome this deﬁciency to some degree. It results, even using the standard open source tool aligner, called GIZA++1 (Och, 2003), which consist of the widely used IBM models and their extensions, still will spend lots of time to obtain word alignments. A recent development of word alignment approach fast align2 (Dyer et al., 2013), based on the variation of the IBM model 2, has been reported faster than baseline GIZA++ but with comparable results. However, both mentioned approaches generate asymmetric alignments. In order to obtain the symmetrical word alignments, these approaches symmetrize the alignments in both forward and reverse directions using a symmetrization heuristic called grow-diag-ﬁnal-and (Och, 2003). Sta"
Y16-2012,2007.mtsummit-papers.67,0,0.0503982,"s using a symmetrization heuristic called grow-diag-ﬁnal-and (Och, 2003). Starting with the intersection alignment points that occur in both of the two directional alignments, grow-diagﬁnal-and expands the alignment in the union of 1 2 http://www.statmt.org/moses/giza/GIZA++.html https://github.com/clab/fast align 30th Pacific Asia Conference on Language, Information and Computation (PACLIC 30) Seoul, Republic of Korea, October 28-30, 2016 143 the alignment in either of the two directional alignments. Although it has been shown to be most effective for phrase extraction for phrased-based SMT (Wu and Wang, 2007), there lacks a principled explanation. Recently, development in mining large parallel patent or document collections increase the needs in fast methods for word alignment. Besides, in the real scenario of Computer Assisted Translation (CAT) (Kay, 1997), in conjunction with SMT system (Farajian et al., 2014) for translation or post-editing (reference) (Guerberof, 2009), real-time word alignment methods become necessary. In this paper, we propose a novel method based on the use of F-measure for symmetrization of word alignment, at the same time which can be regarded as an real-time word alignme"
Y16-2012,C04-1032,0,0.0487147,"Y¯ ) (X, Straight Figure 2: Translation strengths on a logarithmic scale in a English-Japanese sentence pair matrix as a grey graph. ple and convincing justiﬁcation using F-measure for this symmetrical word alignment approach. 4 Proposed Method 4.2 Ncut can be computed as the following formula same as in (Zha et al., 2001), : N cut(X, Y ) = 4.1 Soft alignment matrices  cut(X ,Y ) cut(X ,Y )+2×W (X ,Y ) + cut(X ,Y ) cut(X ,Y )+2×W (X ,Y ) cut(X, Y ) = W (X, Y ) + W (X, Y ) We propose to regard the alignment associations between a source sentence S and a target word T as a contingency matrix (Matusov et al., 2004; Moore, 2005) as in Figure 2, noted as M(I, J), in which I is the length of source sentence in words and J for target side. We deﬁne a function w which measuring the strength of the translation link between any source and target pair of words (si , tj ). The symmetric alignment between word si and tj presents a greyed cell (i, j) in this matrix. In this paper, the score w(si , tj ) is deﬁned as the geometric mean of the bidirectional lexical translation probabilities p(si |tj ) and p(tj |si ). For a given sub-sentential alignment A(X, Y ) ⊆ I × J, we deﬁne the weight of this alignment W(X,Y)"
Y16-2012,2005.eamt-1.21,0,0.0703568,"Missing"
Y16-2012,W05-0801,0,0.0391166,"re 2: Translation strengths on a logarithmic scale in a English-Japanese sentence pair matrix as a grey graph. ple and convincing justiﬁcation using F-measure for this symmetrical word alignment approach. 4 Proposed Method 4.2 Ncut can be computed as the following formula same as in (Zha et al., 2001), : N cut(X, Y ) = 4.1 Soft alignment matrices  cut(X ,Y ) cut(X ,Y )+2×W (X ,Y ) + cut(X ,Y ) cut(X ,Y )+2×W (X ,Y ) cut(X, Y ) = W (X, Y ) + W (X, Y ) We propose to regard the alignment associations between a source sentence S and a target word T as a contingency matrix (Matusov et al., 2004; Moore, 2005) as in Figure 2, noted as M(I, J), in which I is the length of source sentence in words and J for target side. We deﬁne a function w which measuring the strength of the translation link between any source and target pair of words (si , tj ). The symmetric alignment between word si and tj presents a greyed cell (i, j) in this matrix. In this paper, the score w(si , tj ) is deﬁned as the geometric mean of the bidirectional lexical translation probabilities p(si |tj ) and p(tj |si ). For a given sub-sentential alignment A(X, Y ) ⊆ I × J, we deﬁne the weight of this alignment W(X,Y) as the summati"
Y16-2012,W11-2123,0,0.0216789,"ethod, we conducted translation experiments on two corpora: Europarl Corpus and KFTT corpus. For EnglishJapanese (en-ja) and Japanese-English (ja-en), we evaluated on the KFTT corpus. For English-Finnish (en-ﬁ), Spanish-Portuguese (es-pt) and EnglishFrench (en-fr), we measure the translation metrics on Europarl Corpus v75 . The baseline systems are using GIZA++ to train as generally. In our experiments, standard phrase-based statistical machine translation systems were built by using the Moses toolkit (Koehn et al., 2007), Minimum Error Rate Training (Och, 2003), and the KenLM language model (Heaﬁeld, 2011). Default training pipeline for phrase-based SMT in is adopt with default distortion-limit 6. For the evaluation of machine translation quality, some standard automatic evaluation metrics have been used, like BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and RIBES (Isozaki et al., 2010) in all experiments. When compared with the baseline system (GIZA++ + GDFA), there is no signiﬁcant difference on the ﬁnal results of machine translation between using the alignments output by the proposed approach and GIZA++. 6 Conclusion In this paper, we studied an ITG-based bilingual word alignment m"
Y16-2012,J93-2003,0,\N,Missing
Y17-1015,C04-1152,0,0.0602193,"Gr¨unwald, 2005). In this section, we mainly introduce applications. De Marcken (1996) tries to infer the monolingual grammar structure using MDL. Yu (2000) introduce unsupervised monolingual word induction approach using MDL. Approximately, Hewlett and Cohen (2011) implement a heuristic search algorithm and use MDL as criterion to produce the best monolingual segmentation scheme. Zhikov et al. (2010) also employ an MDL90 based as criterion with a more efficient greedy algorithm. Chen (2013) proposes a compression-based method using MDL and improve the performance of monolingual segmentation. Argamon et al. (2004) use an efficient recursive method on morphological segmentation using MDL. Those early works focus on exploiting MDL to achieve monolingual segmentation, and indicate that MDL-based method has an excellent performance on unsupervised monolingual segmentation. For bilingual NLP tasks using MDL, Saers et al. (2013) try to build an inversion transduction grammars with MDL. Gonz´alez-Rubio and Casacuberta (2015) try to improve the translation quality by inferring a phrase-based model using MDL. Actually, those works focus on achieving different NLP tasks using MDL. Our work employs the same techn"
Y17-1015,P13-2030,0,0.0177953,"implementing two parts in this principle. 2.2 Related works MDL has been used in common inductive inference tasks (Gr¨unwald, 2005). In this section, we mainly introduce applications. De Marcken (1996) tries to infer the monolingual grammar structure using MDL. Yu (2000) introduce unsupervised monolingual word induction approach using MDL. Approximately, Hewlett and Cohen (2011) implement a heuristic search algorithm and use MDL as criterion to produce the best monolingual segmentation scheme. Zhikov et al. (2010) also employ an MDL90 based as criterion with a more efficient greedy algorithm. Chen (2013) proposes a compression-based method using MDL and improve the performance of monolingual segmentation. Argamon et al. (2004) use an efficient recursive method on morphological segmentation using MDL. Those early works focus on exploiting MDL to achieve monolingual segmentation, and indicate that MDL-based method has an excellent performance on unsupervised monolingual segmentation. For bilingual NLP tasks using MDL, Saers et al. (2013) try to build an inversion transduction grammars with MDL. Gonz´alez-Rubio and Casacuberta (2015) try to improve the translation quality by inferring a phrase-b"
Y17-1015,P11-2095,0,0.0185759,"cture. As Gonz´alez-Rubio and Casacuberta (2015) said, the MDL provides a joint estimation of the structure and parameters (probability distribution) of the model. It naturally provides a mechanism against over-fitting or being too general by implementing two parts in this principle. 2.2 Related works MDL has been used in common inductive inference tasks (Gr¨unwald, 2005). In this section, we mainly introduce applications. De Marcken (1996) tries to infer the monolingual grammar structure using MDL. Yu (2000) introduce unsupervised monolingual word induction approach using MDL. Approximately, Hewlett and Cohen (2011) implement a heuristic search algorithm and use MDL as criterion to produce the best monolingual segmentation scheme. Zhikov et al. (2010) also employ an MDL90 based as criterion with a more efficient greedy algorithm. Chen (2013) proposes a compression-based method using MDL and improve the performance of monolingual segmentation. Argamon et al. (2004) use an efficient recursive method on morphological segmentation using MDL. Those early works focus on exploiting MDL to achieve monolingual segmentation, and indicate that MDL-based method has an excellent performance on unsupervised monolingua"
Y17-1015,P07-2045,0,0.00517063,"information theory has shown a good performance in finding units which could hold a trade-off on that aspect. More details about this 31st Pacific Asia Conference on Language, Information and Computation (PACLIC 31), pages 89–96 Cebu City, Philippines, November 16-18, 2017 c Copyright 2017 Bin Shan, Hao Wang and Yves Lepage technology are discussed in section 2.1. In this paper, we firstly introduce the main technology. Then we propose a bilingual model and an iterative search algorithm to generate the best model. To evaluate our approach, we put the segmented corpus by our method into Moses (Koehn et al., 2007) and use BLEU score and NIST score as an evaluated measure. 2 2.1 MDL-based segmentation Minimum description length The Minimum Description Length was first introduced by (Rissanen, 1978). In our method, we suppose to use Crude MDL (Gr¨unwald, 2005), which has two parts. M 0 = arg min DL(D, M ) M = arg min DL(M ) + DL(D|M ) (1) M Where DL(.) denotes the description length. The DL(D|M ) represents the description length of data given by model or data cost. DL(M ) is the description length of the model or model cost. The principle requires a minimum model, which can produce a lowest description"
Y17-1015,2005.mtsummit-papers.11,0,0.0945398,"ignificantly improved the translation quality on the Chinese–Japanese and Japanese–Chinese subtasks. 1 Introduction Words are generally the smallest processing units in varieties of NLP tasks. However, there is no guarantee that such smallest processing units can fit any NLP tasks. Especially in bilingual tasks (e.g. statistical machine translation), different languages have different writing systems or segmentation granularity. Such problem should be considered as a critical factor of performance in translation quality. For instance, in machine translation experiments on 11 Europarl corpora (Koehn, 2005), Finnish has the lowest translation accuracy as evaluated by BLEU scores when translated into English. French–Spanish has the highest BLEU scores. Finnish is a non-Indo-European and agglutinative 89 language. French and Spanish have very similar grammar. Thus, the problem arising from different grammatical structure could lead a poor generalization when training SMT system uses such data. This is one aspect. Another aspect, there still exists some problem even segmenting language to generate similar vocabulary. In our view, we suppose that similar units should have a proper size. If similar u"
Y17-1015,2012.eamt-1.62,1,0.749678,"ent unit. Every father node can be represented by the child node. 2. Input the candidates can be represented as two child nodes. 3. Two child nodes should be combined into a father node with two ways: INVERSE and STRAIGHT. 3.2 Bilingual segmentation As De Marcken (1996) showed, every sentence has a hierarchical structure and he calls the Viterbi representation for a sentence. He tries to search the best model by inputting possible candidates with two operations (add and delete). They represent candidates as a binary combination of two units which could be found in the current model. Likewise, Lardilleux et al. (2012) shows how to segment bilingual sentences by building the bilingual binary tree structure with a recursive binary splitting method. The same place in previous works, they all choose a binary combination or split way to search the best model. Actually, this measure is a common way to search the best model by using MDL principle. The binary representation brings an efficient path to search the best model. We just evaluate the changes in description length, when possible candidates are applied to the current model. So our problems can be converted to evaluate the changes in description length aft"
Y17-1015,P02-1040,0,0.119665,"Missing"
Y17-1015,W13-2810,0,0.0238356,"as criterion to produce the best monolingual segmentation scheme. Zhikov et al. (2010) also employ an MDL90 based as criterion with a more efficient greedy algorithm. Chen (2013) proposes a compression-based method using MDL and improve the performance of monolingual segmentation. Argamon et al. (2004) use an efficient recursive method on morphological segmentation using MDL. Those early works focus on exploiting MDL to achieve monolingual segmentation, and indicate that MDL-based method has an excellent performance on unsupervised monolingual segmentation. For bilingual NLP tasks using MDL, Saers et al. (2013) try to build an inversion transduction grammars with MDL. Gonz´alez-Rubio and Casacuberta (2015) try to improve the translation quality by inferring a phrase-based model using MDL. Actually, those works focus on achieving different NLP tasks using MDL. Our work employs the same technologies as previous works. However, we extend MDL-based monolingual model to bilingual. In addition, previous works using MDL on bilingual tasks did not give the bilingual segmentation method. However, we focus on simultaneously segmenting bilingual data. 3 3.1 Methodology Bilingual model Our method builds a bilin"
Y17-1015,2007.mtsummit-papers.65,0,0.0786064,"Missing"
Y17-1015,D10-1081,0,0.410263,"bution) of the model. It naturally provides a mechanism against over-fitting or being too general by implementing two parts in this principle. 2.2 Related works MDL has been used in common inductive inference tasks (Gr¨unwald, 2005). In this section, we mainly introduce applications. De Marcken (1996) tries to infer the monolingual grammar structure using MDL. Yu (2000) introduce unsupervised monolingual word induction approach using MDL. Approximately, Hewlett and Cohen (2011) implement a heuristic search algorithm and use MDL as criterion to produce the best monolingual segmentation scheme. Zhikov et al. (2010) also employ an MDL90 based as criterion with a more efficient greedy algorithm. Chen (2013) proposes a compression-based method using MDL and improve the performance of monolingual segmentation. Argamon et al. (2004) use an efficient recursive method on morphological segmentation using MDL. Those early works focus on exploiting MDL to achieve monolingual segmentation, and indicate that MDL-based method has an excellent performance on unsupervised monolingual segmentation. For bilingual NLP tasks using MDL, Saers et al. (2013) try to build an inversion transduction grammars with MDL. Gonz´alez"
Y17-1018,P04-1015,0,0.511755,"tatistical machine translation has been shown to improve when BTG-based preordering is applied as a preprocessing (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015). The idea behind preordering is to reduce the structural complexity. It is preferable to apply the reordering operations in advance rather than during decoding as this benefits the word alignment step. In this paper, following (Xiong et al., 2008), we propose to incorporate the BTG-based reordering model directly into the decoding step of a BTG-based SMT system using a simple Structured Perceptron (Rosenblatt, 1958; Collins and Roark, 2004). The rest of the paper is organized as follows. Section 2 briefly introduces previous BTG-based reordering methods both for preordering or determining the reorderings during decoding. Section 3 describes the principal model used in BTG-based machine translation. Section 4 gives the details of the 114 31st Pacific Asia Conference on Language, Information and Computation (PACLIC 31), pages 114–123 Cebu City, Philippines, November 16-18, 2017 c Copyright 2017 Hao Wang and Yves Lepage inverted straight En : : kyoto station was renamed as shichijo station shichijo station was renamed as as Ja: 京都"
Y17-1018,W02-1001,0,0.132567,"such a reordering model, they handled the derivations D as a latent variable directly from the source side linguistic contexts. The objective function in their work can be represented as: f˜′ = arg maxScore(f ′ , D|f ) f′ (8) Since their model is based on reorderings f ′ licensed by BTG derivations D, notes D → f ′ , the objective function also can be written as: ˜ = arg maxScore(D|f ) D D→f ′ (9) The learning problem defined here is fairly simple. With treating the derivation D as the latent variable, they want to find the derivation with maximal score of Score(D|f ). Furthermore, following (Collins, 2002; Collins and Roark, 2004), they assume that Score(D|f ) is the linear combination of feature functions defined over D and f . Because it is also possible to apply the score function Score(D|f ) as a reordering model during the BTG-based decoding, following (Neubig et al., 2012; Nakagawa, 2015), we propose to build such a reordering model with latent derivation for decoding instead of preordering. The natural difference between their works and our work is as follows: In (Neubig et al., 2012; Nakagawa, 2015), they train an incremental parser for preordering, following the order in the target la"
Y17-1018,D11-1018,0,0.112998,"al component, but it is often be criticized, especially when translating a language pair with widely divergent syntax like English-Japanese, as the na¨ıve distance-based lexical reordering model does not work so well when applied to longer reorderings. On the other hand, in syntax-based SMT method, word reordering is implicitly addressed by translation rules. The performance is thus directly subject to the parsing errors of the syntactic parser. In recent proposals, phrase-based statistical machine translation has been shown to improve when BTG-based preordering is applied as a preprocessing (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015). The idea behind preordering is to reduce the structural complexity. It is preferable to apply the reordering operations in advance rather than during decoding as this benefits the word alignment step. In this paper, following (Xiong et al., 2008), we propose to incorporate the BTG-based reordering model directly into the decoding step of a BTG-based SMT system using a simple Structured Perceptron (Rosenblatt, 1958; Collins and Roark, 2004). The rest of the paper is organized as follows. Section 2 briefly introduces previous BTG-based reordering methods b"
Y17-1018,2009.iwslt-evaluation.7,0,0.0234712,"{ΦRM s , ΦRM i } (10) Given a source sentence f , we define the score for R the weighted sum of the score P(d) of the subderivation d at each parse state defined over D given 117 f: kyoto station was renamed as shichijo station 1 2 3 4 5 6 7 Derivations:   1. f17 → f12 f37 2. f12 → [f1 f2 ]   3. f37 → f35 f67 4. f35 → f34 f5 5. f34 → hf3 f4 i 6. f67 → [f6 f7 ] Figure 3: Example of step-by-step atomic derivations. a source sentence f . R(D|f ) = ∑ d∈D P(d : X → γ) (11) Each atomic derivation d which belongs to D is weighted with various features in a log-linear form as (Xiong et al., 2008; Duan et al., 2009): P(d : X → γ) = ∑ π i ϕi (12) ϕi ∈d where ϕi is the ith feature function and πi is the ith weight can be trained on the training data. Suppose that we know the word alignment a. We want to train a parser which maximizes the number of times the source sentences in the training data are successfully parsed under the constraints of BTGs. Nakagawa (2015) propose an efficient topdown parser via online training for this problem. He uses a simple structured perceptron algorithm. We assume that the parser has an independent state in each step. We define the parse state as a triple ⟨X, r, d⟩, where X"
Y17-1018,D08-1089,0,0.0380202,"ge inverted straight En : : kyoto station was renamed as shichijo station shichijo station was renamed as as Ja: 京都 駅 を 七条 駅 に was renamed 改称 Figure 1: Example of translating a source sentence (English) into Japanese while reordering at the same time using a BTG tree. proposed method and the model combination in the system construction. Section 5 reports the results of the experiment on an English-to-Japanese translation task. We conclude in Section 7. 2 Using Linguistic Contexts for BTG-based Reordering A common problem in the distortion reordering models (Tillmann, 2004; Koehn et al., 2005; Galley and Manning, 2008) used in phrase-based SMT (PB-SMT) method is that they do not take contexts into account. Hence, we draw our attention on using linguistic-context information for reordering. Bracketing Transduction Grammar (BTG) (Wu, 1997) is a binary and simplified synchronous context-free grammar with only one non-terminal symbol. It has three types for the right hand side of the rules γ: S–straight keeps the order of child nodes, I–inverted reverses the order, and T – terminal generates a terminal symbol.  [X1 X2 ] straight  &lt; X1 X2 > inverted X→γ= (1)  f /e terminal where X, X1 , X2 are non-terminal sy"
Y17-1018,C10-1043,0,0.0295196,", 1992) for probabilistic context-free grammar (PCFG), monolingual bracketing representation (Klein and Manning, 2002) or bilingual bracketing grammar induction (Wu, 1995). The common problem is that these models suffer from a higher computational complexity. Some supervised versions focus on supervised approach, ranging from simple flat reordering model (Wu, 1997), maximum-entropy based model (Zens and Ney, 2006; Xiong et al., 2008) and Tree Kernel-based SVM (Zhang and Li, 2009). Other approaches, use pre-annotated treebanks to train a monolingual/synchronous parser (Collins and Roark, 2004; Genzel, 2010). In this case, the rules are learned directly from the treebank. The majority of works (Zhang and Gildea, 2005; Xiong et al., 2008) rely on syntactic parsers available in one of a source or target language. However, bilingual parallel treebanks are not always available. As to building a bilingual synchronous parser using the BTG formalism, there exist rare works without the use of such a constituency/dependency parser, and sometimes bilingual parallel treebanks are not always available. Zens and Ney (2006) and DeNero and Uszkoreit (2011) proposed semi-supervised approaches for synchronous gra"
Y17-1018,J99-4004,0,0.550511,"ned on the training data. Suppose that we know the word alignment a. We want to train a parser which maximizes the number of times the source sentences in the training data are successfully parsed under the constraints of BTGs. Nakagawa (2015) propose an efficient topdown parser via online training for this problem. He uses a simple structured perceptron algorithm. We assume that the parser has an independent state in each step. We define the parse state as a triple ⟨X, r, d⟩, where X is an unparsed span. For example, following the deductive proof system representations (Shieber et al., 1995; Goodman, 1999), [X, p, q] covers fp , . . . , fq . d = ⟨r, X → γ⟩ is the derivation at the current state with r is the splitting position between fr−1 and fr and X → γ is the applied BTG rule. To extract the features used to score the model, we assume that each word in a sentence has three types of features: lexical form, part-of-speech (POS) tag and word class (Brown et al., 1992) as (Nakagawa, 2015). We extract the unigrams, bigrams, and trigrams at each parse state and compute the model score defined in Equation 121 . 1 We use the same set of features described in (Nakagawa, 2015) derivations: Algorithm"
Y17-1018,W11-2123,0,0.0399865,"alignment, we train word alignments in both directions with the default settings, i.e., the standard bootstrap for IBM model 4 alignment in GIZA++ (15 H 5 33 43 ). We then symmetrize the word alignments using grow-diag-final-and (+gdfa) and the standard phrase extraction heuristic (Koehn et al., 2003) for all systems. In our experiment, the maximum length of phrases entered into phrase table 5 http://www.statmt.org/moses/ 120 (20) (21) (22) (23) is limited to 7, and we input only the top 20 translation candidates. The language model storage of target language uses the implementation in KenLM (Heafield, 2011) which is trained and queried as a 5-gram model. For distortion model in phrase-based SMT baseline, we set the distortion limit to 6. Word alignments used for training the reordering model are the intersection of both asymmetrical alignments in each mono-direction output by GIZA++6 (Och and Ney, 2003). For pos-tagging, we make use of the Stanford Log-linear POS Tagger7 (Toutanova and Manning, 2000). To produce word class tags for each source word, we use the implementation of (Liang, 2005) 8 of Brown’s clustering algorithm (Brown et al., 1992). The size of the class tags is fixed to 256. For t"
Y17-1018,P02-1017,0,0.0647991,"rted reverses the order, and T – terminal generates a terminal symbol.  [X1 X2 ] straight  &lt; X1 X2 > inverted X→γ= (1)  f /e terminal where X, X1 , X2 are non-terminal symbols and f /e is a source/target phrase pair. BTG provides an easy and simple mechanism for modeling word permutation across languages. Figure 1 illustrates this mechanism. There exists some solutions for BTG grammar induction, which typically focus on unsupervised ap115 proaches, like inside-outside algorithm (Pereira and Schabes, 1992) for probabilistic context-free grammar (PCFG), monolingual bracketing representation (Klein and Manning, 2002) or bilingual bracketing grammar induction (Wu, 1995). The common problem is that these models suffer from a higher computational complexity. Some supervised versions focus on supervised approach, ranging from simple flat reordering model (Wu, 1997), maximum-entropy based model (Zens and Ney, 2006; Xiong et al., 2008) and Tree Kernel-based SVM (Zhang and Li, 2009). Other approaches, use pre-annotated treebanks to train a monolingual/synchronous parser (Collins and Roark, 2004; Genzel, 2010). In this case, the rules are learned directly from the treebank. The majority of works (Zhang and Gildea"
Y17-1018,N03-1017,0,0.4978,"tention has been paid to incorporating such a reordering model into decoding directly. Our reordering model differs from previous models built using a syntactic parser or directly from annotated treebanks. Here, we train without using any syntactic information. The experiment results on an English–Japanese translation task show that our BTG-based decoder achieves comparable or better performance than the more complex state-of-the-art SMT decoders. 1 Yves Lepage Graduate School of Information, Production and Systems, Waseda University yves.lepage@waseda.jp Introduction The phrase-based method (Koehn et al., 2003) and the syntax-based method (Yamada and Knight, 2001) are two of the representative methods in statistical machine translation (SMT). On the one hand, in the phrase-based model, the lexical reordering model is a crucial component, but it is often be criticized, especially when translating a language pair with widely divergent syntax like English-Japanese, as the na¨ıve distance-based lexical reordering model does not work so well when applied to longer reorderings. On the other hand, in syntax-based SMT method, word reordering is implicitly addressed by translation rules. The performance is t"
Y17-1018,2005.iwslt-1.8,0,0.231539,"o Wang and Yves Lepage inverted straight En : : kyoto station was renamed as shichijo station shichijo station was renamed as as Ja: 京都 駅 を 七条 駅 に was renamed 改称 Figure 1: Example of translating a source sentence (English) into Japanese while reordering at the same time using a BTG tree. proposed method and the model combination in the system construction. Section 5 reports the results of the experiment on an English-to-Japanese translation task. We conclude in Section 7. 2 Using Linguistic Contexts for BTG-based Reordering A common problem in the distortion reordering models (Tillmann, 2004; Koehn et al., 2005; Galley and Manning, 2008) used in phrase-based SMT (PB-SMT) method is that they do not take contexts into account. Hence, we draw our attention on using linguistic-context information for reordering. Bracketing Transduction Grammar (BTG) (Wu, 1997) is a binary and simplified synchronous context-free grammar with only one non-terminal symbol. It has three types for the right hand side of the rules γ: S–straight keeps the order of child nodes, I–inverted reverses the order, and T – terminal generates a terminal symbol.  [X1 X2 ] straight  &lt; X1 X2 > inverted X→γ= (1)  f /e terminal where X,"
Y17-1018,P07-2045,0,0.0149336,"+ 1, q] : w2 [L(e1 + e2 )]λL X1 → f1 /e1 , X2 → f2 /e2 • Reordering models (RM): straight and inverted scores combined within the log-linear framework. • Penalties (PM): word penalty, phrase penalty, unknown word penalty. The weights for each feature are tuned and estimated using the minimum error rate training (MERT) algorithm (Och, 2003). 5 Experiment 5.1 Experimental Setup To evaluate our system, we conducted translation experiments on the KFTT Corpus (English–Japanese) and compared our system with baseline phrasebased (PB) and hierarchical phrase-based (HPB) SMT implementations in Moses5 (Koehn et al., 2007). For each language, the training corpus is around 330,000 sentences. The development set contains nearly 1,235 sentences and nearly 1,160 sentences used for testing. We use the default training set for training translation model, and traditional lexical (Koehn et al., 2005) reordering model or our proposed BTG-based reordering model, and also target language model. We use the default tuning set for tuning the parameters and the default test set for evaluation. For word alignment, we train word alignments in both directions with the default settings, i.e., the standard bootstrap for IBM model"
Y17-1018,W04-3250,0,0.0345683,"html 8 https://github.com/percyliang/brown-cluster 9 http://www.cs.jhu.edu/ ozaidan/zmert/ 7 BLEU Moses (PB-SMT) 20.81 Moses (HPB-SMT) 21.67 HieraTrans (BTG-SMT) (beam=40) 21.15 (beam=100) 21.24 RIBES 67.50 66.58 formance with state-of-the-art SMT approaches. For further improvements, we will work on towards higher-speed decoder and make the decoder open available. 65.80 66.33 Acknowledgments Table 1: Results on phrase-based baseline system, hierarchical phrase-based system and our BTG-based system. Bold scores indicate no statistically significant difference at p &lt; 0.05 from the best system (Koehn, 2004). References (BTG-SMT). 5.3 Analysis Compared with the PB-SMT, BTG-based SMT uses weak linguistic annotations on the source side which provides additional information for reordering. We found that this strategy does help tree structure construction and finding final translations. However, our BTG-based method underperformed the HPBSMT method. Increasing the beam size will gain improvement slightly. There are two explanations for the result: First, final machine translation performance is also related to the used tools, which is sensitive to parse errors, alignment errors or annotation errors."
Y17-1018,D13-1049,0,0.0184656,"require syntactic annotations in the training data, making training easier. Rather than developing a novel BTG-decoder incorporated with a BTG-based reordering model, using reordering models for preordering have been widely explored to improve the standard phrasebased statistical machine translation system. Neubig et al. (2012) present a bottom-up method for inducing a preorder for SMT by training a discriminative model to minimize the loss function on the hand-aligned corpus. Their method makes use of the general framework of large margin online structured prediction (Crammer et al., 2006). Lerner and Petrov (2013) present a simple classifier-based preordering approach using the source-side dependency tree. Nakagawa (2015) further develop a more efficient top-down incremental parser for preordering via online training using simple structured Perceptron algorithm. Differing from the mentioned methods to pre-reorder the sentence before the phase of decoding, in this paper; we propose to build a reordering model directly for building a BTG-based decoder. 3 BTG-based Machine Translation Given the three types of rules in Equation 1, we define a BTG derivation D as a sequence of independent operations d1 , ."
Y17-1018,P15-1021,0,0.231548,"cially when translating a language pair with widely divergent syntax like English-Japanese, as the na¨ıve distance-based lexical reordering model does not work so well when applied to longer reorderings. On the other hand, in syntax-based SMT method, word reordering is implicitly addressed by translation rules. The performance is thus directly subject to the parsing errors of the syntactic parser. In recent proposals, phrase-based statistical machine translation has been shown to improve when BTG-based preordering is applied as a preprocessing (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015). The idea behind preordering is to reduce the structural complexity. It is preferable to apply the reordering operations in advance rather than during decoding as this benefits the word alignment step. In this paper, following (Xiong et al., 2008), we propose to incorporate the BTG-based reordering model directly into the decoding step of a BTG-based SMT system using a simple Structured Perceptron (Rosenblatt, 1958; Collins and Roark, 2004). The rest of the paper is organized as follows. Section 2 briefly introduces previous BTG-based reordering methods both for preordering or determining the"
Y17-1018,D12-1077,0,0.266864,"n be criticized, especially when translating a language pair with widely divergent syntax like English-Japanese, as the na¨ıve distance-based lexical reordering model does not work so well when applied to longer reorderings. On the other hand, in syntax-based SMT method, word reordering is implicitly addressed by translation rules. The performance is thus directly subject to the parsing errors of the syntactic parser. In recent proposals, phrase-based statistical machine translation has been shown to improve when BTG-based preordering is applied as a preprocessing (DeNero and Uszkoreit, 2011; Neubig et al., 2012; Nakagawa, 2015). The idea behind preordering is to reduce the structural complexity. It is preferable to apply the reordering operations in advance rather than during decoding as this benefits the word alignment step. In this paper, following (Xiong et al., 2008), we propose to incorporate the BTG-based reordering model directly into the decoding step of a BTG-based SMT system using a simple Structured Perceptron (Rosenblatt, 1958; Collins and Roark, 2004). The rest of the paper is organized as follows. Section 2 briefly introduces previous BTG-based reordering methods both for preordering o"
Y17-1018,P02-1038,0,0.116804,"oratrue). If the system derivation D ∗ cle derivation D are not equivalent, we update the model weights π towards D∗ . Like all structured prediction learning frameworks, the online Structured Perceptron is costly to train as training complexity is proportional to inference, which is frequently non-linear in the length of example. To train the reordering model, we employ an in-house parser2 which uses Batch Perceptron. It is a modified and boosted version of the original topdown parser (Nakagawa, 2015), which allows us to train on the whole training set3 . 4.2 Decoding In decoding, we follow (Och and Ney, 2002; Chiang, 2007). That is, we remove the target side and use a more general linear model composition over 2 https://github.com/wang-h/HieraParser We skip the sentences which cannot be parsed under the constraints of BTGs. 3 118 Therefore, given an input sentence f = f1 , . . . , fn , notes f1n , the task to translate an input source sentence can be solved by finding the derivation with maximal score in Equation 14, which uniquely deˆ (em termines a target translation e 1 ) with this latent derivation D. The decoder needs to generate all derivations for each segment spanning from fi to fj (0 ≤ i"
Y17-1018,J03-1002,0,0.0332577,"03) for all systems. In our experiment, the maximum length of phrases entered into phrase table 5 http://www.statmt.org/moses/ 120 (20) (21) (22) (23) is limited to 7, and we input only the top 20 translation candidates. The language model storage of target language uses the implementation in KenLM (Heafield, 2011) which is trained and queried as a 5-gram model. For distortion model in phrase-based SMT baseline, we set the distortion limit to 6. Word alignments used for training the reordering model are the intersection of both asymmetrical alignments in each mono-direction output by GIZA++6 (Och and Ney, 2003). For pos-tagging, we make use of the Stanford Log-linear POS Tagger7 (Toutanova and Manning, 2000). To produce word class tags for each source word, we use the implementation of (Liang, 2005) 8 of Brown’s clustering algorithm (Brown et al., 1992). The size of the class tags is fixed to 256. For tuning, the optimal weights for each feature are estimated using the minimum error rate training (MERT) algorithm (Och, 2003) and parameter optimization with ZMERT9 (Zaidan, 2009). 5.2 Experiment Results For evaluation of machine translation quality, standard automatic evaluation metrics are used, like"
Y17-1018,P03-1021,0,0.167127,"⟨s⟩. 1 X → f /e [X, p, q] : w[L(e)]λL X → ⟨X1 , X2 ⟩ : X → [X1 , X2 ] : [exp P(X → ⟨X1 , X2 ⟩)]λR λR [X, p, q] : w1 w2 [exp R(X)] [exp P(X → [X1 , X2 ])]λR λR [X, p, q] : w1 w2 [exp R(X)] [X1 , p, r] : w1 [X2 , r + 1, q] : w2 [L(e2 + e1 )]λL [X1 , p, r] : w1 [X2 , r + 1, q] : w2 [L(e1 + e2 )]λL X1 → f1 /e1 , X2 → f2 /e2 • Reordering models (RM): straight and inverted scores combined within the log-linear framework. • Penalties (PM): word penalty, phrase penalty, unknown word penalty. The weights for each feature are tuned and estimated using the minimum error rate training (MERT) algorithm (Och, 2003). 5 Experiment 5.1 Experimental Setup To evaluate our system, we conducted translation experiments on the KFTT Corpus (English–Japanese) and compared our system with baseline phrasebased (PB) and hierarchical phrase-based (HPB) SMT implementations in Moses5 (Koehn et al., 2007). For each language, the training corpus is around 330,000 sentences. The development set contains nearly 1,235 sentences and nearly 1,160 sentences used for testing. We use the default training set for training translation model, and traditional lexical (Koehn et al., 2005) reordering model or our proposed BTG-based reo"
Y17-1018,P02-1040,0,0.101183,"os-tagging, we make use of the Stanford Log-linear POS Tagger7 (Toutanova and Manning, 2000). To produce word class tags for each source word, we use the implementation of (Liang, 2005) 8 of Brown’s clustering algorithm (Brown et al., 1992). The size of the class tags is fixed to 256. For tuning, the optimal weights for each feature are estimated using the minimum error rate training (MERT) algorithm (Och, 2003) and parameter optimization with ZMERT9 (Zaidan, 2009). 5.2 Experiment Results For evaluation of machine translation quality, standard automatic evaluation metrics are used, like BLEU (Papineni et al., 2002) and RIBES (Isozaki et al., 2010) in all experiments. BLEU is used as the default standard metric, RIBES takes more word order into consideration. Table 1 shows the performance of MT systems on the KFTT test data, which are (1) Moses, trained using the phrase-based model (PB-SMT). (2) Moses, trained using the hierarchical phrase-based model (HPB-SMT) and last one (3) HieraTrans, trained using the BTG-based model 6 http://www.statmt.org/moses/giza/GIZA++.html https://nlp.stanford.edu/software/tagger.shtml 8 https://github.com/percyliang/brown-cluster 9 http://www.cs.jhu.edu/ ozaidan/zmert/ 7 BL"
Y17-1018,P92-1017,0,0.635938,"bol. It has three types for the right hand side of the rules γ: S–straight keeps the order of child nodes, I–inverted reverses the order, and T – terminal generates a terminal symbol.  [X1 X2 ] straight  &lt; X1 X2 > inverted X→γ= (1)  f /e terminal where X, X1 , X2 are non-terminal symbols and f /e is a source/target phrase pair. BTG provides an easy and simple mechanism for modeling word permutation across languages. Figure 1 illustrates this mechanism. There exists some solutions for BTG grammar induction, which typically focus on unsupervised ap115 proaches, like inside-outside algorithm (Pereira and Schabes, 1992) for probabilistic context-free grammar (PCFG), monolingual bracketing representation (Klein and Manning, 2002) or bilingual bracketing grammar induction (Wu, 1995). The common problem is that these models suffer from a higher computational complexity. Some supervised versions focus on supervised approach, ranging from simple flat reordering model (Wu, 1997), maximum-entropy based model (Zens and Ney, 2006; Xiong et al., 2008) and Tree Kernel-based SVM (Zhang and Li, 2009). Other approaches, use pre-annotated treebanks to train a monolingual/synchronous parser (Collins and Roark, 2004; Genzel,"
Y17-1018,N04-4026,0,0.0712767,"opyright 2017 Hao Wang and Yves Lepage inverted straight En : : kyoto station was renamed as shichijo station shichijo station was renamed as as Ja: 京都 駅 を 七条 駅 に was renamed 改称 Figure 1: Example of translating a source sentence (English) into Japanese while reordering at the same time using a BTG tree. proposed method and the model combination in the system construction. Section 5 reports the results of the experiment on an English-to-Japanese translation task. We conclude in Section 7. 2 Using Linguistic Contexts for BTG-based Reordering A common problem in the distortion reordering models (Tillmann, 2004; Koehn et al., 2005; Galley and Manning, 2008) used in phrase-based SMT (PB-SMT) method is that they do not take contexts into account. Hence, we draw our attention on using linguistic-context information for reordering. Bracketing Transduction Grammar (BTG) (Wu, 1997) is a binary and simplified synchronous context-free grammar with only one non-terminal symbol. It has three types for the right hand side of the rules γ: S–straight keeps the order of child nodes, I–inverted reverses the order, and T – terminal generates a terminal symbol.  [X1 X2 ] straight  &lt; X1 X2 > inverted X→γ= (1)  f /"
Y17-1018,W00-1308,0,0.255831,"Missing"
Y17-1018,J97-3002,0,0.283555,"e same time using a BTG tree. proposed method and the model combination in the system construction. Section 5 reports the results of the experiment on an English-to-Japanese translation task. We conclude in Section 7. 2 Using Linguistic Contexts for BTG-based Reordering A common problem in the distortion reordering models (Tillmann, 2004; Koehn et al., 2005; Galley and Manning, 2008) used in phrase-based SMT (PB-SMT) method is that they do not take contexts into account. Hence, we draw our attention on using linguistic-context information for reordering. Bracketing Transduction Grammar (BTG) (Wu, 1997) is a binary and simplified synchronous context-free grammar with only one non-terminal symbol. It has three types for the right hand side of the rules γ: S–straight keeps the order of child nodes, I–inverted reverses the order, and T – terminal generates a terminal symbol.  [X1 X2 ] straight  &lt; X1 X2 > inverted X→γ= (1)  f /e terminal where X, X1 , X2 are non-terminal symbols and f /e is a source/target phrase pair. BTG provides an easy and simple mechanism for modeling word permutation across languages. Figure 1 illustrates this mechanism. There exists some solutions for BTG grammar induc"
Y17-1018,C08-1127,0,0.06022,"Missing"
Y17-1018,P01-1067,0,0.318247,"rdering model into decoding directly. Our reordering model differs from previous models built using a syntactic parser or directly from annotated treebanks. Here, we train without using any syntactic information. The experiment results on an English–Japanese translation task show that our BTG-based decoder achieves comparable or better performance than the more complex state-of-the-art SMT decoders. 1 Yves Lepage Graduate School of Information, Production and Systems, Waseda University yves.lepage@waseda.jp Introduction The phrase-based method (Koehn et al., 2003) and the syntax-based method (Yamada and Knight, 2001) are two of the representative methods in statistical machine translation (SMT). On the one hand, in the phrase-based model, the lexical reordering model is a crucial component, but it is often be criticized, especially when translating a language pair with widely divergent syntax like English-Japanese, as the na¨ıve distance-based lexical reordering model does not work so well when applied to longer reorderings. On the other hand, in syntax-based SMT method, word reordering is implicitly addressed by translation rules. The performance is thus directly subject to the parsing errors of the synt"
Y17-1018,W06-3108,0,0.0309903,"ages. Figure 1 illustrates this mechanism. There exists some solutions for BTG grammar induction, which typically focus on unsupervised ap115 proaches, like inside-outside algorithm (Pereira and Schabes, 1992) for probabilistic context-free grammar (PCFG), monolingual bracketing representation (Klein and Manning, 2002) or bilingual bracketing grammar induction (Wu, 1995). The common problem is that these models suffer from a higher computational complexity. Some supervised versions focus on supervised approach, ranging from simple flat reordering model (Wu, 1997), maximum-entropy based model (Zens and Ney, 2006; Xiong et al., 2008) and Tree Kernel-based SVM (Zhang and Li, 2009). Other approaches, use pre-annotated treebanks to train a monolingual/synchronous parser (Collins and Roark, 2004; Genzel, 2010). In this case, the rules are learned directly from the treebank. The majority of works (Zhang and Gildea, 2005; Xiong et al., 2008) rely on syntactic parsers available in one of a source or target language. However, bilingual parallel treebanks are not always available. As to building a bilingual synchronous parser using the BTG formalism, there exist rare works without the use of such a constituenc"
Y17-1018,P05-1059,0,0.0536708,"d Manning, 2002) or bilingual bracketing grammar induction (Wu, 1995). The common problem is that these models suffer from a higher computational complexity. Some supervised versions focus on supervised approach, ranging from simple flat reordering model (Wu, 1997), maximum-entropy based model (Zens and Ney, 2006; Xiong et al., 2008) and Tree Kernel-based SVM (Zhang and Li, 2009). Other approaches, use pre-annotated treebanks to train a monolingual/synchronous parser (Collins and Roark, 2004; Genzel, 2010). In this case, the rules are learned directly from the treebank. The majority of works (Zhang and Gildea, 2005; Xiong et al., 2008) rely on syntactic parsers available in one of a source or target language. However, bilingual parallel treebanks are not always available. As to building a bilingual synchronous parser using the BTG formalism, there exist rare works without the use of such a constituency/dependency parser, and sometimes bilingual parallel treebanks are not always available. Zens and Ney (2006) and DeNero and Uszkoreit (2011) proposed semi-supervised approaches for synchronous grammar induction based on sourceside information only when bilingual word alignments are given in advance, instea"
Y17-1018,D09-1073,0,0.0212047,"ons for BTG grammar induction, which typically focus on unsupervised ap115 proaches, like inside-outside algorithm (Pereira and Schabes, 1992) for probabilistic context-free grammar (PCFG), monolingual bracketing representation (Klein and Manning, 2002) or bilingual bracketing grammar induction (Wu, 1995). The common problem is that these models suffer from a higher computational complexity. Some supervised versions focus on supervised approach, ranging from simple flat reordering model (Wu, 1997), maximum-entropy based model (Zens and Ney, 2006; Xiong et al., 2008) and Tree Kernel-based SVM (Zhang and Li, 2009). Other approaches, use pre-annotated treebanks to train a monolingual/synchronous parser (Collins and Roark, 2004; Genzel, 2010). In this case, the rules are learned directly from the treebank. The majority of works (Zhang and Gildea, 2005; Xiong et al., 2008) rely on syntactic parsers available in one of a source or target language. However, bilingual parallel treebanks are not always available. As to building a bilingual synchronous parser using the BTG formalism, there exist rare works without the use of such a constituency/dependency parser, and sometimes bilingual parallel treebanks are"
Y17-1018,D10-1092,0,\N,Missing
Y17-1018,J07-2003,0,\N,Missing
Y18-1096,N16-2002,0,0.0278274,"er, that, because the two ˜ (D : B) and M ˜ (D : C) quasi-alignment matrices M are not perfect alignment matrices, there is a need for a dedicated algorithm. Fig. 1 pictures the overall flow of data. The following sections explain each step in the process. 2.1 Alignment Matrices An alignment matrix between two strings of characters shows the match points, i.e., the positions at which equal characters are to be found in the two strings. Figure 2 shows the alignment matrix between the strings office and offices (example in inflectional morphology, noun - regular plurals, from BATS 3.0 data set (Gladkova et al., 2016)). 2.2 ⇐ e Pre-Processing Step: Interpolation Alignment matrices between strings of different lengths obviously exhibit different lengths. Fully connected layers of neural networks require fixeddimension input. For our problem, the use of fully connected layers requires that alignment matrices of different lengths be cast into fixed-size matrices before being fed to such network layers. Figure 3: Linear matrix interpolation for the analogy law : laws :: office : offices. Original alignment matrices on the left; interpolated square matrices of size 5 × 5 on the right. On the left, the cells tak"
Y18-1096,P98-1120,1,0.180937,"the network are back transformed into quasi alignment matrices so as to obtain matrices of the sizes fitted to the lengths of strings B, C and D. To do so, we just apply the same interpolation technique to each of the matrices MDB and MDC to obtain the ma˜ (D : B) and M ˜ (D : C) with the desired trices M lengths as constraints. 834 32nd Pacific Asia Conference on Language, Information and Computation Hong Kong, 1-3 December 2018 Copyright 2018 by the authors PACLIC 32 2.4 Second Post-Processing Step: String Decoder V [c, i] = For an analogical equation A : B :: C : D where D is the unknown, (Lepage, 1998; Lepage, 2017) show that the properties of analogies of commutation between strings of symbols imply that the following features of the solution D can be computed in advance. • The length of the solution D: |D |=|B |+|C |−|A| (1) X ˜ (D : B)[i, j] M j/B[j]=c + X ˜ (D : C)[i, j] M j/C[j]=c We think that the selection should preferably identify only one point, either from B or from C, the one which has the largest contribution to character c for this given position in D. For this reason, our formula picks up the maximal value. This is defined in Eq. (4). Here, |S |stands for the length of a str"
