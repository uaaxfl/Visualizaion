2021.woah-1.14,Jibes {\\&} Delights: A Dataset of Targeted Insults and Compliments to Tackle Online Abuse,2021,-1,-1,3,0,61,ravsimar sodhi,Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021),0,"Online abuse and offensive language on social media have become widespread problems in today{'}s digital age. In this paper, we contribute a Reddit-based dataset, consisting of 68,159 insults and 51,102 compliments targeted at individuals instead of targeting a particular community or race. Secondly, we benchmark multiple existing state-of-the-art models for both classification and unsupervised style transfer on the dataset. Finally, we analyse the experimental results and conclude that the transfer task is challenging, requiring the models to understand the high degree of creativity exhibited in the data."
2021.wat-1.19,{V}i{TA}: Visual-Linguistic Translation by Aligning Object Tags,2021,-1,-1,3,0,364,kshitij gupta,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"Multimodal Machine Translation (MMT) enriches the source text with visual information for translation. It has gained popularity in recent years, and several pipelines have been proposed in the same direction. Yet, the task lacks quality datasets to illustrate the contribution of visual modality in the translation systems. In this paper, we propose our system under the team name Volta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We also participate in the textual-only subtask of the same language pair for which we use mBART, a pretrained multilingual sequence-to-sequence model. For multimodal translation, we propose to enhance the textual input by bringing the visual information to a textual domain by extracting object tags from the image. We also explore the robustness of our system by systematically degrading the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test set and challenge set of the multimodal task."
2021.wassa-1.13,"Analyzing Curriculum Learning for Sentiment Analysis along Task Difficulty, Pacing and Visualization Axes",2021,-1,-1,3,0,436,anvesh vijjini,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"While Curriculum Learning (CL) has recently gained traction in Natural language Processing Tasks, it is still not adequately analyzed. Previous works only show their effectiveness but fail short to explain and interpret the internal workings fully. In this paper, we analyze curriculum learning in sentiment analysis along multiple axes. Some of these axes have been proposed by earlier works that need more in-depth study. Such analysis requires understanding where curriculum learning works and where it does not. Our axes of analysis include Task difficulty on CL, comparing CL pacing techniques, and qualitative analysis by visualizing the movement of attention scores in the model as curriculum phases progress. We find that curriculum learning works best for difficult tasks and may even lead to a decrement in performance for tasks with higher performance without curriculum learning. We see that One-Pass curriculum strategies suffer from catastrophic forgetting and attention movement visualization within curriculum pacing. This shows that curriculum learning breaks down the challenging main task into easier sub-tasks solved sequentially."
2021.semeval-1.149,{V}olta at {S}em{E}val-2021 Task 6: Towards Detecting Persuasive Texts and Images using Textual and Multimodal Ensemble,2021,-1,-1,3,0,364,kshitij gupta,Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),0,"Memes are one of the most popular types of content used to spread information online. They can influence a large number of people through rhetorical and psychological techniques. The task, Detection of Persuasion Techniques in Texts and Images, is to detect these persuasive techniques in memes. It consists of three subtasks: (A) Multi-label classification using textual content, (B) Multi-label classification and span identification using textual content, and (C) Multi-label classification using visual and textual content. In this paper, we propose a transfer learning approach to fine-tune BERT-based models in different modalities. We also explore the effectiveness of ensembles of models trained in different modalities. We achieve an F1-score of 57.0, 48.2, and 52.1 in the corresponding subtasks."
2021.semeval-1.173,{IIITH} at {S}em{E}val-2021 Task 7: Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining,2021,-1,-1,3,0,2075,tathagata raha,Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),0,"This paper describes our approach (IIITH) for SemEval-2021 Task 5: HaHackathon: Detecting and Rating Humor and Offense. Our results focus on two major objectives: (i) Effect of task adaptive pretraining on the performance of transformer based models (ii) How does lexical and hurtlex features help in quantifying humour and offense. In this paper, we provide a detailed description of our approach along with comparisions mentioned above."
2021.ltedi-1.11,{EDIO}ne@{LT}-{EDI}-{EACL}2021: Pre-trained Transformers with Convolutional Neural Networks for Hope Speech Detection.,2021,-1,-1,2,1,5347,suman dowlagar,"Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion",0,"Hope is an essential aspect of mental health stability and recovery in every individual in this fast-changing world. Any tools and methods developed for detection, analysis, and generation of hope speech will be beneficial. In this paper, we propose a model on hope-speech detection to automatically detect web content that may play a positive role in diffusing hostility on social media. We perform the experiments by taking advantage of pre-processing and transfer-learning models. We observed that the pre-trained multilingual-BERT model with convolution neural networks gave the best results. Our model ranked first, third, and fourth ranks on English, Malayalam-English, and Tamil-English code-mixed datasets."
2021.ltedi-1.21,"Autobots@{LT}-{EDI}-{EACL}2021: One World, One Family: Hope Speech Detection with {BERT} Transformer Model",2021,-1,-1,2,1,5363,sunil gundapu,"Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion",0,"The rapid rise of online social networks like YouTube, Facebook, Twitter allows people to express their views more widely online. However, at the same time, it can lead to an increase in conflict and hatred among consumers in the form of freedom of speech. Therefore, it is essential to take a positive strengthening method to research on encouraging, positive, helping, and supportive social media content. In this paper, we describe a Transformer-based BERT model for Hope speech detection for equality, diversity, and inclusion, submitted for LT-EDI-2021 Task 2. Our model achieves a weighted averaged f1-score of 0.93 on the test set."
2021.ltedi-1.23,Hopeful Men@{LT}-{EDI}-{EACL}2021: Hope Speech Detection Using Indic Transliteration and Transformers,2021,-1,-1,4,0,2076,ishan upadhyay,"Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion",0,"This paper aims to describe the approach we used to detect hope speech in the HopeEDI dataset. We experimented with two approaches. In the first approach, we used contextual embeddings to train classifiers using logistic regression, random forest, SVM, and LSTM based models. The second approach involved using a majority voting ensemble of 11 models which were obtained by fine-tuning pre-trained transformer models (BERT, ALBERT, RoBERTa, IndicBERT) after adding an output layer. We found that the second approach was superior for English, Tamil and Malayalam. Our solution got a weighted F1 score of 0.93, 0.75 and 0.49 for English, Malayalam and Tamil respectively. Our solution ranked 1st in English, 8th in Malayalam and 11th in Tamil."
2021.dravidianlangtech-1.8,Graph Convolutional Networks with Multi-headed Attention for Code-Mixed Sentiment Analysis,2021,-1,-1,2,1,5347,suman dowlagar,Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages,0,"Code-mixing is a frequently observed phenomenon in multilingual communities where a speaker uses multiple languages in an utterance or sentence. Code-mixed texts are abundant, especially in social media, and pose a problem for NLP tools as they are typically trained on monolingual corpora. Recently, finding the sentiment from code-mixed text has been attempted by some researchers in SentiMix SemEval 2020 and Dravidian-CodeMix FIRE 2020 shared tasks. Mostly, the attempts include traditional methods, long short term memory, convolutional neural networks, and transformer models for code-mixed sentiment analysis (CMSA). However, no study has explored graph convolutional neural networks on CMSA. In this paper, we propose the graph convolutional networks (GCN) for sentiment analysis on code-mixed text. We have used the datasets from the Dravidian-CodeMix FIRE 2020. Our experimental results on multiple CMSA datasets demonstrate that the GCN with multi-headed attention model has shown an improvement in classification metrics."
2021.dravidianlangtech-1.19,{OFFL}ang{O}ne@{D}ravidian{L}ang{T}ech-{EACL}2021: Transformers with the Class Balanced Loss for Offensive Language Identification in {D}ravidian Code-Mixed text.,2021,-1,-1,2,1,5347,suman dowlagar,Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages,0,"The intensity of online abuse has increased in recent years. Automated tools are being developed to prevent the use of hate speech and offensive content. Most of the technologies use natural language and machine learning tools to identify offensive text. In a multilingual society, where code-mixing is a norm, the hate content would be delivered in a code-mixed form in social media, which makes the offensive content identification, further challenging. In this work, we participated in the EACL task to detect offensive content in the code-mixed social media scenario. The methodology uses a transformer model with transliteration and class balancing loss for offensive content identification. In this task, our model has been ranked 2nd in Malayalam-English and 4th in Tamil-English code-mixed languages."
2021.dialdoc-1.4,Automatic Learning Assistant in {T}elugu,2021,-1,-1,3,0,11214,meghana bommadi,Proceedings of the 1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021),0,"This paper presents a learning assistant that tests one{'}s knowledge and gives feedback that helps a person learn at a faster pace. A learning assistant (based on automated question generation) has extensive uses in education, information websites, self-assessment, FAQs, testing ML agents, research, etc. Multiple researchers, and companies have worked on Virtual Assistance, but majorly in English. We built our learning assistant for Telugu language to help with teaching in the mother tongue, which is the most efficient way of learning. Our system is built primarily based on Question Generation in Telugu. Many experiments were conducted on Question Generation in English in multiple ways. We have built the first hybrid machine learning and rule-based solution in Telugu, which proves efficient for short stories or short passages in children{'}s books. Our work covers the fundamental question forms with question types: adjective, yes/no, adverb, verb, when, where, whose, quotative, and quantitative (how many/how much). We constructed rules for question generation using Part of Speech (POS) tags and Universal Dependency (UD) tags along with linguistic information of the surrounding relevant context of the word. We used keyword matching, multilingual sentence embedding to evaluate the answer. Our system is primarily built on question generation in Telugu, and is also capable of evaluating the user{'}s answers to the generated questions."
2021.codi-main.2,Developing Conversational Data and Detection of Conversational Humor in {T}elugu,2021,-1,-1,2,0,11465,vaishnavi pamulapati,Proceedings of the 2nd Workshop on Computational Approaches to Discourse,0,"In the field of humor research, there has been a recent surge of interest in the sub-domain of Conversational Humor (CH). This study has two main objectives. (a) develop a conversational (humorous and non-humorous) dataset in Telugu. (b) detect CH in the compiled dataset. In this paper, the challenges faced while collecting the data and experiments carried out are elucidated. Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given. State-of-the-art results are observed with a 99.3{\%} accuracy and a 98.5{\%} f1 score achieved by BERT."
2021.calcs-1.1,Political Discourse Analysis: A Case Study of Code Mixing and Code Switching in Political Speeches,2021,-1,-1,3,0,12013,dama sravani,Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching,0,"Political discourse is one of the most interesting data to study power relations in the framework of Critical Discourse Analysis. With the increase in the modes of textual and spoken forms of communication, politicians use language and linguistic mechanisms that contribute significantly in building their relationship with people, especially in a multilingual country like India with many political parties with different ideologies. This paper analyses code-mixing and code-switching in Telugu political speeches to determine the factors responsible for their usage levels in various social settings and communicative contexts. We also compile a detailed set of rules capturing dialectal variations between Standard and Telangana dialects of Telugu."
2021.calcs-1.4,Gated Convolutional Sequence to Sequence Based Learning for {E}nglish-Hingilsh Code-Switched Machine Translation.,2021,-1,-1,2,1,5347,suman dowlagar,Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching,0,"Code-Switching is the embedding of linguistic units or phrases from two or more languages in a single sentence. This phenomenon is practiced in all multilingual communities and is prominent in social media. Consequently, there is a growing need to understand code-switched translations by translating the code-switched text into one of the standard languages or vice versa. Neural Machine translation is a well-studied research problem in the monolingual text. In this paper, we have used the gated convolutional sequences to sequence networks for English-Hinglish translation. The convolutions in the model help to identify the compositional structure in the sequences more easily. The model relies on gating and performs multiple attention steps at encoder and decoder layers."
2021.acl-srw.12,How do different factors Impact the Inter-language Similarity? A Case Study on {I}ndian languages,2021,-1,-1,4,0,377,sourav kumar,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop,0,"India is one of the most linguistically diverse nations of the world and is culturally very rich. Most of these languages are somewhat similar to each other on account of sharing a common ancestry or being in contact for a long period of time. Nowadays, researchers are constantly putting efforts in utilizing the language relatedness to improve the performance of various NLP systems such as cross lingual semantic search, machine translation, sentiment analysis systems, etc. So in this paper, we performed an extensive case study on similarity involving languages of the Indian subcontinent. Language similarity prediction is defined as the task of measuring how similar the two languages are on the basis of their lexical, morphological and syntactic features. In this study, we concentrate only on the approach to calculate lexical similarity between Indian languages by looking at various factors such as size and type of corpus, similarity algorithms, subword segmentation, etc. The main takeaways from our work are: (i) Relative order of the language similarities largely remain the same, regardless of the factors mentioned above, (ii) Similarity within the same language family is higher, (iii) Languages share more lexical features at the subword level."
2020.socialnlp-1.1,Enhancing Bias Detection in Political News Using Pragmatic Presupposition,2020,-1,-1,3,1,12014,lalitha kameswari,Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media,0,"Usage of presuppositions in social media and news discourse can be a powerful way to influence the readers as they usually tend to not examine the truth value of the hidden or indirectly expressed information. Fairclough and Wodak (1997) discuss presupposition at a discourse level where some implicit claims are taken for granted in the explicit meaning of a text or utterance. From the Gricean perspective, the presuppositions of a sentence determine the class of contexts in which the sentence could be felicitously uttered. This paper aims to correlate the type of knowledge presupposed in a news article to the bias present in it. We propose a set of guidelines to identify various kinds of presuppositions in news articles and present a dataset consisting of 1050 articles which are annotated for bias (positive, negative or neutral) and the magnitude of presupposition. We introduce a supervised classification approach for detecting bias in political news which significantly outperforms the existing systems."
2020.semeval-1.147,Gundapusunil at {S}em{E}val-2020 Task 8: Multimodal Memotion Analysis,2020,-1,-1,2,1,5363,sunil gundapu,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"Recent technological advancements in the Internet and Social media usage have resulted in the evolution of faster and efficient platforms of communication. These platforms include visual, textual and speech mediums and have brought a unique social phenomenon called Internet memes. Internet memes are in the form of images with witty, catchy, or sarcastic text descriptions. In this paper, we present a multi-modal sentiment analysis system using deep neural networks combining Computer Vision and Natural Language Processing. Our aim is different than the normal sentiment analysis goal of predicting whether a text expresses positive or negative sentiment; instead, we aim to classify the Internet meme as a positive, negative, or neutral, identify the type of humor expressed and quantify the extent to which a particular effect is being expressed. Our system has been developed using CNN and LSTM and outperformed the baseline score."
2020.semeval-1.166,Gundapusunil at {S}em{E}val-2020 Task 9: Syntactic Semantic {LSTM} Architecture for {SENTI}ment Analysis of Code-{MIX}ed Data,2020,-1,-1,2,1,5363,sunil gundapu,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"The phenomenon of mixing the vocabulary and syntax of multiple languages within the same utterance is called Code-Mixing. This is more evident in multilingual societies. In this paper, we have developed a system for SemEval 2020: Task 9 on Sentiment Analysis of Hindi-English code-mixed social media text. Our system first generates two types of embeddings for the social media text. In those, the first one is character level embeddings to encode the character level information and to handle the out-of-vocabulary entries and the second one is FastText word embeddings for capturing morphology and semantics. These two embeddings were passed to the LSTM network and the system outperformed the baseline model."
2020.lrec-1.339,Annotated Corpus for Sentiment Analysis in {O}dia Language,2020,-1,-1,3,1,17339,gaurav mohanty,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Given the lack of an annotated corpus of non-traditional Odia literature which serves as the standard when it comes sentiment analysis, we have created an annotated corpus of Odia sentences and made it publicly available to promote research in the field. Secondly, in order to test the usability of currently available Odia sentiment lexicon, we experimented with various classifiers by training and testing on the sentiment annotated corpus while using identified affective words from the same as features. Annotation and classification are done at sentence level as the usage of sentiment lexicon is best suited to sentiment analysis at this level. The created corpus contains 2045 Odia sentences from news domain annotated with sentiment labels using a well-defined annotation scheme. An inter-annotator agreement score of 0.79 is reported for the corpus."
2020.lrec-1.609,{M}anovaad: A Novel Approach to Event Oriented Corpus Creation Capturing Subjectivity and Focus,2020,-1,-1,2,1,12014,lalitha kameswari,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In today{'}s era of globalisation, the increased outreach for every event across the world has been leading to conflicting opinions, arguments and disagreements, often reflected in print media and online social platforms. It is necessary to distinguish factual observations from personal judgements in news, as subjectivity in reporting can influence the audience{'}s perception of reality. Several studies conducted on the different styles of reporting in journalism are essential in understanding phenomena such as media bias and multiple interpretations of the same event. This domain finds applications in fields such as Media Studies, Discourse Analysis, Information Extraction, Sentiment Analysis, and Opinion Mining. We present an event corpus Manovaad-v1.0 consisting of 1035 news articles corresponding to 65 events from 3 levels of newspapers viz., Local, National, and International levels. Using this novel format, we correlate the trends in the degree of subjectivity with the geographical closeness of reporting using a Bi-RNN model. We also analyse the role of background and focus in event reporting and capture the focus shift patterns within a global discourse structure for an event. We do this across different levels of reporting and compare the results with the existing work on discourse processing."
2020.lrec-1.617,"Dataset Creation and Evaluation of Aspect Based Sentiment Analysis in {T}elugu, a Low Resource Language",2020,-1,-1,3,0,17890,yashwanth regatte,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In recent years, sentiment analysis has gained popularity as it is essential to moderate and analyse the information across the internet. It has various applications like opinion mining, social media monitoring, and market research. Aspect Based Sentiment Analysis (ABSA) is an area of sentiment analysis which deals with sentiment at a finer level. ABSA classifies sentiment with respect to each aspect to gain greater insights into the sentiment expressed. Significant contributions have been made in ABSA, but this progress is limited only to a few languages with adequate resources. Telugu lags behind in this area of research despite being one of the most spoken languages in India and an enormous amount of data being created each day. In this paper, we create a reliable resource for aspect based sentiment analysis in Telugu. The data is annotated for three tasks namely Aspect Term Extraction, Aspect Polarity Classification and Aspect Categorisation. Further, we develop baselines for the tasks using deep learning methods demonstrating the reliability and usefulness of the resource."
2020.law-1.4,A Novel Annotation Schema for Conversational Humor: Capturing the Cultural Nuances in Kanyasulkam,2020,-1,-1,3,0,11465,vaishnavi pamulapati,Proceedings of the 14th Linguistic Annotation Workshop,0,"Humor research is a multifaceted field that has led to a better understanding of humor{'}s psychological effects and the development of different theories of humor. This paper{'}s main objective is to develop a hierarchical schema for a fine-grained annotation of Conversational Humor. Based on the Benign Violation Theory, the benignity or non-benignity of the interlocutor{'}s intentions is included within the framework. Under the categories mentioned above, in addition to different types of humor, the techniques utilized by these types are identified. Furthermore, a prominent play from Telugu, Kanyasulkam, is annotated to substantiate the work across cultures at multiple levels. The inter-annotator agreement is calculated to assess the accuracy and validity of the dataset. An in-depth analysis of the disagreement is performed to understand the subjectivity of humor better."
2020.icon-termtraction.2,Unsupervised Technical Domain Terms Extraction using Term Extractor,2020,-1,-1,2,1,5347,suman dowlagar,Proceedings of the 17th International Conference on Natural Language Processing (ICON): TermTraction 2020 Shared Task,0,"Terminology extraction, also known as term extraction, is a subtask of information extraction. The goal of terminology extraction is to extract relevant words or phrases from a given corpus automatically. This paper focuses on the unsupervised automated domain term extraction method that considers chunking, preprocessing, and ranking domain-specific terms using relevance and cohesion functions for ICON 2020 shared task 2: TermTraction."
2020.icon-techdofication.3,Multichannel {LSTM}-{CNN} for {T}elugu Text Classification,2020,-1,-1,2,1,5363,sunil gundapu,Proceedings of the 17th International Conference on Natural Language Processing (ICON): TechDOfication 2020 Shared Task,0,"With the instantaneous growth of text information, retrieving domain-oriented information from the text data has a broad range of applications in Information Retrieval and Natural language Processing. Thematic keywords give a compressed representation of the text. Usually, Domain Identification plays a significant role in Machine Translation, Text Summarization, Question Answering, Information Extraction, and Sentiment Analysis. In this paper, we proposed the Multichannel LSTM-CNN methodology for Technical Domain Identification for Telugu. This architecture was used and evaluated in the context of the ICON shared task {``}TechDOfication 2020{''} (task h), and our system got 69.9{\%} of the F1 score on the test dataset and 90.01{\%} on the validation set."
2020.icon-techdofication.4,Multilingual Pre-Trained Transformers and Convolutional {NN} Classification Models for Technical Domain Identification,2020,-1,-1,2,1,5347,suman dowlagar,Proceedings of the 17th International Conference on Natural Language Processing (ICON): TechDOfication 2020 Shared Task,0,"In this paper, we present a transfer learning system to perform technical domain identification on multilingual text data. We have submitted two runs, one uses the transformer model BERT, and the other uses XLM-ROBERTa with the CNN model for text classification. These models allowed us to identify the domain of the given sentences for the ICON 2020 shared Task, TechDOfication: Technical Domain Identification. Our system ranked the best for the subtasks 1d, 1g for the given TechDOfication dataset."
2020.icon-main.29,{SUKHAN}: Corpus of {H}indi Shayaris annotated with Sentiment Polarity Information,2020,-1,-1,3,0,378,salil aggarwal,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"Shayari is a form of poetry mainly popular in the Indian subcontinent, in which the poet expresses his emotions and feelings in a very poetic manner. It is one of the best ways to express our thoughts and opinions. Therefore, it is of prime importance to have an annotated corpus of Hindi shayaris for the task of sentiment analysis. In this paper, we introduce SUKHAN, a dataset consisting of Hindi shayaris along with sentiment polarity labels. To the best of our knowledge, this is the first corpus of Hindi shayaris annotated with sentiment polarity information. This corpus contains a total of 733 Hindi shayaris of various genres. Also, this dataset is of utmost value as all the annotation is done manually by five annotators and this makes it a very rich dataset for training purposes. This annotated corpus is also used to build baseline sentiment classification models using machine learning techniques."
2020.icon-main.36,Does a Hybrid Neural Network based Feature Selection Model Improve Text Classification?,2020,-1,-1,2,1,5347,suman dowlagar,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"Text classification is a fundamental problem in the field of natural language processing. Text classification mainly focuses on giving more importance to all the relevant features that help classify the textual data. Apart from these, the text can have redundant or highly correlated features. These features increase the complexity of the classification algorithm. Thus, many dimensionality reduction methods were proposed with the traditional machine learning classifiers. The use of dimensionality reduction methods with machine learning classifiers has achieved good results. In this paper, we propose a hybrid feature selection method for obtaining relevant features by combining various filter-based feature selection methods and fastText classifier. We then present three ways of implementing a feature selection and neural network pipeline. We observed a reduction in training time when feature selection methods are used along with neural networks. We also observed a slight increase in accuracy on some datasets."
2020.icon-main.48,Question and Answer pair generation for {T}elugu short stories,2020,-1,-1,3,0,11214,meghana bommadi,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"Question Answer pair generation is a task that has been worked upon by multiple researchers in many languages. It has been a topic of interest due to its extensive uses in different fields like self assessment, academics, business website FAQs etc. Many experiments were conducted on Question Answering pair generation in English, concentrating on basic Wh-questions with a rule-based approach. We have built the first hybrid machine learning and rule-based solution in Telugu which is efficient for short stories or short passages in children{'}s books. Our work covers the fundamental question forms with the question types: adjective, yes/no, adverb, verb, when, where, whose, quotative, and quantitative(how many/ how much). We constructed rules for question generation using POS tags and UD tags along with linguistic information of the surrounding context of the word."
2020.figlang-1.15,{D}etecting {S}arcasm in {C}onversation {C}ontext {U}sing {T}ransformer-{B}ased {M}odels,2020,-1,-1,3,0.714286,15193,adithya avvaru,Proceedings of the Second Workshop on Figurative Language Processing,0,"Sarcasm detection, regarded as one of the sub-problems of sentiment analysis, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting sarcasm in one single sentence and there is very limited research to detect sarcasm resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without attention to detect sarcasm in conversations. We showed that the models using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current models. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the sarcasm and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them."
2020.eamt-1.9,Leveraging Multilingual Resources for Language Invariant Sentiment Analysis,2020,-1,-1,4,0,20834,allen antony,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"Sentiment analysis is a widely researched NLP problem with state-of-the-art solutions capable of attaining human-like accuracies for various languages. However, these methods rely heavily on large amounts of labeled data or sentiment weighted language-specific lexical resources that are unavailable for low-resource languages. Our work attempts to tackle this data scarcity issue by introducing a neural architecture for language invariant sentiment analysis capable of leveraging various monolingual datasets for training without any kind of cross-lingual supervision. The proposed architecture attempts to learn language agnostic sentiment features via adversarial training on multiple resource-rich languages which can then be leveraged for inferring sentiment information at a sentence level on a low resource language. Our model outperforms the current state-of-the-art methods on the Multilingual Amazon Review Text Classification dataset [REF] and achieves significant performance gains over prior work on the low resource Sentiraama corpus [REF]. A detailed analysis of our research highlights the ability of our architecture to perform significantly well in the presence of minimal amounts of training data for low resource languages."
W19-4809,Detecting Political Bias in News Articles Using Headline Attention,2019,0,0,3,1,17891,rama gangula,Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP,0,"Language is a powerful tool which can be used to state the facts as well as express our views and perceptions. Most of the times, we find a subtle bias towards or against someone or something. When it comes to politics, media houses and journalists are known to create bias by shrewd means such as misinterpreting reality and distorting viewpoints towards some parties. This misinterpretation on a large scale can lead to the production of biased news and conspiracy theories. Automating bias detection in newspaper articles could be a good challenge for research in NLP. We proposed a headline attention network for this bias detection. Our model has two distinctive characteristics: (i) it has a structure that mirrors a person{'}s way of reading a news article (ii) it has attention mechanism applied on the article based on its headline, enabling it to attend to more critical content to predict bias. As the required datasets were not available, we created a dataset comprising of 1329 news articles collected from various Telugu newspapers and marked them for bias towards a particular political party. The experiments conducted on it demonstrated that our model outperforms various baseline methods by a substantial margin."
W19-1301,Stance Detection in Code-Mixed {H}indi-{E}nglish Social Media Data using Multi-Task Learning,2019,0,1,4,0,24841,sushmitha sane,"Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"Social media sites like Facebook, Twitter, and other microblogging forums have emerged as a platform for people to express their opinions and views on different issues and events. It is often observed that people tend to take a stance; in favor, against or neutral towards a particular topic. The task of assessing the stance taken by the individual became significantly important with the emergence in the usage of online social platforms. Automatic stance detection system understands the user{'}s stance by analyzing the standalone texts against a target entity. Due to the limited contextual information a single sentence provides, it is challenging to solve this task effectively. In this paper, we introduce a Multi-Task Learning (MTL) based deep neural network architecture for automatically detecting stance present in the code-mixed corpus. We apply our approach on Hindi-English code-mixed corpus against the target entity - {``}Demonetisation.{''} Our best model achieved the result with a stance prediction accuracy of 63.2{\%} which is a 4.5{\%} overall accuracy improvement compared to the current supervised classification systems developed using the benchmark dataset for code-mixed data stance detection."
W19-1307,Deep Learning Techniques for Humor Detection in {H}indi-{E}nglish Code-Mixed Tweets,2019,0,0,4,0,24841,sushmitha sane,"Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"We propose bilingual word embeddings based on word2vec and fastText models (CBOW and Skip-gram) to address the problem of Humor detection in Hindi-English code-mixed tweets in combination with deep learning architectures. We focus on deep learning approaches which are not widely used on code-mixed data and analyzed their performance by experimenting with three different neural network models. We propose convolution neural network (CNN) and bidirectional long-short term memory (biLSTM) (with and without Attention) models which take the generated bilingual embeddings as input. We make use of Twitter data to create bilingual word embeddings. All our proposed architectures outperform the state-of-the-art results, and Attention-based bidirectional LSTM model achieved an accuracy of 73.6{\%} which is an increment of more than 4{\%} compared to the current state-of-the-art results."
D19-6126,{S}amvaadhana: A {T}elugu Dialogue System in Hospital Domain,2019,0,0,3,0,24004,suma duggenpudi,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,"In this paper, a dialogue system for Hospital domain in Telugu, which is a resource-poor Dravidian language, has been built. It handles various hospital and doctor related queries. The main aim of this paper is to present an approach for modelling a dialogue system in a resource-poor language by combining linguistic and domain knowledge. Focusing on the question answering aspect of the dialogue system, we identified Question Classification and Query Processing as the two most important parts of the dialogue system. Our method combines deep learning techniques for question classification and computational rule-based analysis for query processing. Human evaluation of the system has been performed as there is no automated evaluation tool for dialogue systems in Telugu. Our system achieves a high overall rating along with a significantly accurate context-capturing method as shown in the results."
D19-5524,{S}mok{E}ng: Towards Fine-grained Classification of Tobacco-related Social Media Text,2019,33,0,4,0.625,62,kartikey pant,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"Contemporary datasets on tobacco consumption focus on one of two topics, either public health mentions and disease surveillance, or sentiment analysis on topical tobacco products and services. However, two primary considerations are not accounted for, the language of the demographic affected and a combination of the topics mentioned above in a fine-grained classification mechanism. In this paper, we create a dataset of 3144 tweets, which are selected based on the presence of colloquial slang related to smoking and analyze it based on the semantics of the tweet. Each class is created and annotated based on the content of the tweets such that further hierarchical methods can be easily applied. Further, we prove the efficacy of standard text classification methods on this dataset, by designing experiments which do both binary as well as multi-class classification. Our experiments tackle the identification of either a specific topic (such as tobacco product promotion), a general mention (cigarettes and related products) or a more fine-grained classification. This methodology paves the way for further analysis, such as understanding sentiment or style, which makes this dataset a vital contribution to both disease surveillance and tobacco use research."
2019.icon-1.28,Samajh-Boojh: A Reading Comprehension system in {H}indi,2019,-1,-1,3,0,27405,shalaka vaidya,Proceedings of the 16th International Conference on Natural Language Processing,0,"This paper presents a novel approach designed to answer questions on a reading comprehension passage. It is an end-to-end system which first focuses on comprehending the given passage wherein it converts unstructured passage into a structured data and later proceeds to answer the questions related to the passage using solely the aforementioned structured data. To the best of our knowledge, the proposed design is first of its kind which accounts for entire process of comprehending the passage and then answering the questions associated with the passage. The comprehension stage converts the passage into a Discourse Collection that comprises of the relation shared amongst logical sentences in given passage along with the key characteristics of each sentence. This design has its applications in academic domain , query comprehension in speech systems among others."
Y18-1007,Predicting the Genre and Rating of a Movie Based on its Synopsis,2018,0,0,5,0,27470,varshit battu,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
Y18-1021,Word Level Language Identification in {E}nglish {T}elugu Code Mixed Data,2018,0,0,2,1,5363,sunil gundapu,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
Y18-1028,Political Discourse Analysis : A Case Study of 2014 {A}ndhra {P}radesh State Assembly Election of Interpersonal Speech Choices,2018,-1,-1,2,1,12014,lalitha kameswari,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
Y18-1059,Affect in Tweets using Experts Model,2018,0,0,4,0,27535,subba oota,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
Y18-1080,Syllables for Sentence Classification in Morphologically Rich Languages,2018,0,1,2,0,27574,madhuri tummalapalli,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
W18-4005,Towards Enhancing Lexical Resource and Using Sense-annotations of {O}nto{S}ense{N}et for Sentiment Analysis,2018,11,2,3,0,28214,sreekavitha parupalli,Proceedings of the Third Workshop on Semantic Deep Learning,0,"This paper illustrates the interface of the tool we developed for crowd sourcing and we explain the annotation procedure in detail. Our tool is named as {`}à°ªà°¾à°°à±à°ªà°²à±à°²à°¿ à°ªà°¦à°à°¾à°²à°{'} (Parupalli Padajaalam) which means web of words by Parupalli. The aim of this tool is to populate the OntoSenseNet, sentiment polarity annotated Telugu resource. Recent works have shown the importance of word-level annotations on sentiment analysis. With this as basis, we aim to analyze the importance of sense-annotations obtained from OntoSenseNet in performing the task of sentiment analysis. We explain the features extracted from OntoSenseNet (Telugu). Furthermore we compute and explain the adverbial class distribution of verbs in OntoSenseNet. This task is known to aid in disambiguating word-senses which helps in enhancing the performance of word-sense disambiguation (WSD) task(s)."
W18-3511,Towards Automation of Sense-type Identification of Verbs in {O}nto{S}ense{N}et,2018,6,0,3,0,28214,sreekavitha parupalli,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,0,"In this paper, we discuss the enrichment of a manually developed resource, OntoSenseNet for Telugu. OntoSenseNet is a sense annotated resource that marks each verb of Telugu with a primary and a secondary sense. The area of research is relatively recent but has a large scope of development. We provide an introductory work to enrich the OntoSenseNet to promote further research in Telugu. Classifiers are adopted to learn the sense relevant features of the words in the resource and also to automate the tagging of sense-types for verbs. We perform a comparative analysis of different classifiers applied on OntoSenseNet. The results of the experiment prove that automated enrichment of the resource is effective using SVM classifiers and Adaboost ensemble."
P18-3014,{BCSAT} : A Benchmark Corpus for Sentiment Analysis in {T}elugu Using Word-level Annotations,2018,13,2,3,0,28214,sreekavitha parupalli,"Proceedings of {ACL} 2018, Student Research Workshop",0,"The presented work aims at generating a systematically annotated corpus that can support the enhancement of sentiment analysis tasks in Telugu using word-level sentiment annotations. From OntoSenseNet, we extracted 11,000 adjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by language experts. We discuss the methodology followed for the polarity annotations and validate the developed resource. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for sentiment predictions. The fundamental aim of this paper is to validate and study the possibility of utilizing machine learning algorithms, word-level sentiment annotations in the task of automated sentiment identification. Furthermore, accuracy is improved by annotating the bi-grams extracted from the target corpus."
P18-3017,Exploring Chunk Based Templates for Generating a subset of {E}nglish Text,2018,0,0,3,0,29008,nikhilesh bhatnagar,"Proceedings of {ACL} 2018, Student Research Workshop",0,"Natural Language Generation (NLG) is a research task which addresses the automatic generation of natural language text representative of an input non-linguistic collection of knowledge. In this paper, we address the task of the generation of grammatical sentences in an isolated context given a partial bag-of-words which the generated sentence must contain. We view the task as a search problem (a problem of choice) involving combinations of smaller chunk based templates extracted from a training corpus to construct a complete sentence. To achieve that, we propose a fitness function which we use in conjunction with an evolutionary algorithm as the search procedure to arrive at a potentially grammatical sentence (modeled by the fitness score) which satisfies the input constraints."
P18-3021,Automatic Spelling Correction for Resource-Scarce Languages using Deep Learning,2018,0,6,3,0,29009,pravallika etoori,"Proceedings of {ACL} 2018, Student Research Workshop",0,"Spelling correction is a well-known task in Natural Language Processing (NLP). Automatic spelling correction is important for many NLP applications like web search engines, text summarization, sentiment analysis etc. Most approaches use parallel data of noisy and correct word mappings from different sources as training data for automatic spelling correction. Indic languages are resource-scarce and do not have such parallel data due to low volume of queries and non-existence of such prior implementations. In this paper, we show how to build an automatic spelling corrector for resource-scarce languages. We propose a sequence-to-sequence deep learning model which trains end-to-end. We perform experiments on synthetic datasets created for Indic languages, Hindi and Telugu, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our model is competitive with the existing spell checking and correction techniques for Indic languages."
L18-1100,Resource Creation Towards Automated Sentiment Analysis in {T}elugu (a low resource language) and Integrating Multiple Domain Sources to Enhance Sentiment Prediction,2018,0,2,2,1,17891,rama gangula,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-7516,Handling Multi-Sentence Queries in a Domain Independent Dialogue System,2017,0,0,2,0,10971,prathyusha jwalapuram,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-5408,{ACTSA}: Annotated Corpus for {T}elugu Sentiment Analysis,2017,0,5,2,0,31528,sandeep mukku,Proceedings of the First Workshop on Building Linguistically Generalizable {NLP} Systems,0,"Sentiment analysis deals with the task of determining the polarity of a document or sentence and has received a lot of attention in recent years for the English language. With the rapid growth of social media these days, a lot of data is available in regional languages besides English. Telugu is one such regional language with abundant data available in social media, but it{'}s hard to find a labelled data of sentences for Telugu Sentiment Analysis. In this paper, we describe an effort to build a gold-standard annotated corpus of Telugu sentences to support Telugu Sentiment Analysis. The corpus, named ACTSA (Annotated Corpus for Telugu Sentiment Analysis) has a collection of Telugu sentences taken from different sources which were then pre-processed and manually annotated by native Telugu speakers using our annotation guidelines. In total, we have annotated 5457 sentences, which makes our corpus the largest resource currently available. The corpus and the annotation guidelines are made publicly available."
W17-5219,Building a {S}enti{W}ord{N}et for {O}dia,2017,7,2,3,1,17339,gaurav mohanty,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"As a discipline of Natural Language Processing, Sentiment Analysis is used to extract and analyze subjective information present in natural language data. The task of Sentiment Analysis has acquired wide commercial uses including social media monitoring tasks, survey responses, review systems, etc. Languages like English have several resources which aid in the task of Sentiment Analysis. SentiWordNet and Subjectivity WordList are examples of such tools and resources. With more data being available in native vernacular, language-specific SentiWordNet(s) have become essential. For resource poor languages, creating such SentiWordNet(s) is a difficult task to achieve. One solution is to use available resources in English and translate the final source lexicon to target lexicon via machine translation. Machine translation systems for the English-Odia language pair have not yet been developed. In this paper, we discuss a method to create a SentiWordNet for Odia, which is resource-poor, by only using resources which are currently available for Indian languages. The lexicon created, would serve as a tool for Sentiment Analysis related task specific to Odia data."
W17-2902,When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data,2017,-1,-1,2,0,31833,akshita jha,Proceedings of the Second Workshop on {NLP} and Computational Social Science,0,"Sexism is prevalent in today{'}s society, both offline and online, and poses a credible threat to social equality with respect to gender. According to ambivalent sexism theory (Glick and Fiske, 1996), it comes in two forms: Hostile and Benevolent. While hostile sexism is characterized by an explicitly negative attitude, benevolent sexism is more subtle. Previous works on computationally detecting sexism present online are restricted to identifying the hostile form. Our objective is to investigate the less pronounced form of sexism demonstrated online. We achieve this by creating and analyzing a dataset of tweets that exhibit benevolent sexism. By using Support Vector Machines (SVM), sequence-to-sequence models and FastText classifier, we classify tweets into {`}Hostile{'}, {`}Benevolent{'} or {`}Others{'} class depending on the kind of sexism they exhibit. We have been able to achieve an F1-score of 87.22{\%} using FastText classifier. Our work helps analyze and understand the much prevalent ambivalent sexism in social media."
P17-3012,Automatic Generation of Jokes in {H}indi,2017,8,0,2,0,32543,srishti aggarwal,"Proceedings of {ACL} 2017, Student Research Workshop",0,None
W16-6305,Towards Building a {S}enti{W}ord{N}et for {T}amil,2016,9,0,3,0,31551,abishek kannan,Proceedings of the 13th International Conference on Natural Language Processing,0,None
S16-1158,{IIIT} at {S}em{E}val-2016 Task 11: Complex Word Identification using Nearest Centroid Classification,2016,3,0,2,1,34311,ashish palakurthi,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
N16-1159,Shallow Parsing Pipeline - {H}indi-{E}nglish Code-Mixed Social Media Text,2016,19,14,6,0,34729,arnav sharma,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed. We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to attempt shallow parsing on CSMT. The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT. The pipeline is accessible at 1 ."
W15-5928,Resolution of Pronominal Anaphora for {T}elugu Dialogues,2015,2,1,2,0,36386,hemanth jonnalagadda,Proceedings of the 12th International Conference on Natural Language Processing,0,None
W15-5953,A Semi Supervised Dialog Act Tagging for {T}elugu,2015,3,3,2,1,5347,suman dowlagar,Proceedings of the 12th International Conference on Natural Language Processing,0,None
R15-1042,Statistical Sandhi Splitter and its Effect on {NLP} Applications,2015,7,0,3,0,37361,prathyusha kuncham,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"This paper revisits the work of (Kuncham et al., 2015) which developed a statistical sandhi splitter (SSS) for agglutinative languages that was tested for Telugu and Malayalam languages. Handling compound words is a major challenge for Natural Language Processing (NLP) applications for agglutinative languages. Hence, in this paper we concentrate on testing the effect of SSS on the NLP applications like Machine Translation, Dialogue System and Anaphora Resolution and show that the accuracy of these applications is consistently improved by using SSS. We shall also discuss in detail the performance of SSS on these applications."
R15-1065,Classification of Attributes in a Natural Language Query into Different {SQL} Clauses,2015,31,2,4,1,34311,ashish palakurthi,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"Attribute information in a natural language query is one of the key features for converting a natural language query into a Structured Query Language 1 (SQL) in Natural Language Interface to Database systems. In this paper, we explore the task of classifying the attributes present in a natural language query into different SQL clauses in a SQL query. In particular, we investigate the effectiveness of various features and Conditional Random Fields for this task. Our system uses a statistical classifier trained on manually prepared data. We report our results on three different domains and also show how our system can be used for generating a complete SQL query."
W14-5312,Statistical Morph Analyzer ({SMA}++) for {I}ndian Languages,2014,9,2,3,0,38268,saikrishna srirampur,"Proceedings of the First Workshop on Applying {NLP} Tools to Similar Languages, Varieties and Dialects",0,"Statistical morph analyzers have proved to be highly accurate while being comparatively easier to maintain than rule based approaches. Our morph analyzer (SMA) is an improvement over the statistical morph analyzer (SMA) described in Malladi and Mannem (2013). SMA predicts the gender, number, person, case (GNPC) and the lemma (L) of a given token. We modified the SMA in Malladi and Mannem (2013), by adding some rich machine learning features. The feature set was chosen specifically to suit the characteristics of Indian Languages. In this paper we apply SMA to four Indian languages viz. Hindi, Urdu, Telugu and Tamil. Hindi and Urdu belong to the Indic 1 language family. Telugu and Tamil belong to the Dravidian 2 language family. We"
W14-5119,Learning phrase-level vocabulary in second language using pictures/gestures and voice,2014,1,0,3,0,38310,lavanya prahallad,Proceedings of the 11th International Conference on Natural Language Processing,0,None
W14-5123,Identification of Karaka relations in an {E}nglish sentence,2014,0,0,3,0,38315,sai gorthi,Proceedings of the 11th International Conference on Natural Language Processing,0,None
W13-4008,Stance Classification in Online Debates by Recognizing Users{'} Intentions,2013,20,1,3,0,40709,sarvesh ranade,Proceedings of the {SIGDIAL} 2013 Conference,0,"Online debate forums provide a rich collection of differing opinions on various topics. In dual-sided debates, users present their opinions or judge otherxe2x80x99s opinions to support their stance. In this paper, we examine the use of usersxe2x80x99 intentions and debate structure for stance classification of the debate posts. We propose a domain independent approach to capture usersxe2x80x99 intent at sentence level using its dependency parse and sentiWordNet and to build the intention structure of the post to identify its stance. To aid the task of classification, we define the health of the debate structure and show that maximizing its value leads to better stance classification accuracies."
I13-1173,A Novel Approach Towards Incorporating Context Processing Capabilities in {NLIDB} System,2013,15,5,3,0.952381,8966,arjun akula,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"This paper presents a novel approach to categorize, model and identify contextual information in natural language interface to database (NLIDB) systems. The interactions between user and system are categorized and modeled based on the way in which the contextual information is utilized in the interactions. A relationship schema among the responses (user and system responses) is proposed. We present a novel method to identify contextual information in one specific type of usersystem interaction. We report on results of experiments with the university related queries."
W12-5810,A template matching approach for detecting pronunciation mismatch,2012,5,0,2,0,38310,lavanya prahallad,Proceedings of the Workshop on Speech and Language Processing Tools in Education,0,"In this paper, we study the usefulness of the best path and the complete trellis in dynamic programming based template matching approach for detecting pronunciation mismatch. We show that there exists cues in trellis (a matrix representing all paths), which could be exploited for detecting pronunciation mismatch. Such an approach could be used to build a template based approach for detecting pronunciation mismatch independent of the language."
