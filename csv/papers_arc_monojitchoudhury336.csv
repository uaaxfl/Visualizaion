2021.wnut-1.18,Comparing Grammatical Theories of Code-Mixing,2021,-1,-1,2,0.851064,153,adithya pratapa,Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),0,"Code-mixed text generation systems have found applications in many downstream tasks, including speech recognition, translation and dialogue. A paradigm of these generation systems relies on well-defined grammatical theories of code-mixing, and there is a lack of comparison of these theories. We present a large-scale human evaluation of two popular grammatical theories, Matrix-Embedded Language (ML) and Equivalence Constraint (EC). We compare them against three heuristic-based models and quantitatively demonstrate the effectiveness of the two grammatical theories."
2021.sigmorphon-1.7,Sample-efficient Linguistic Generalizations through Program Synthesis: Experiments with Phonology Problems,2021,-1,-1,3,0,1302,saujas vaduguru,"Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"Neural models excel at extracting statistical patterns from large amounts of data, but struggle to learn patterns or reason about language from only a few examples. In this paper, we ask: Can we learn explicit rules that generalize well from only a few examples? We explore this question using program synthesis. We develop a synthesis model to learn phonology rules as programs in a domain-specific language. We test the ability of our models to generalize from few training examples using our new dataset of problems from the Linguistics Olympiad, a challenging set of tasks that require strong linguistic reasoning ability. In addition to being highly sample-efficient, our approach generates human-readable programs, and allows control over the generalizability of the learnt programs."
2021.mrl-1.8,Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer Performance,2021,-1,-1,4,0,5208,karthikeyan,Proceedings of the 1st Workshop on Multilingual Representation Learning,0,"Multilingual language models achieve impressive zero-shot accuracies in many languages in complex tasks such as Natural Language Inference (NLI). Examples in NLI (and equivalent complex tasks) often pertain to various types of sub-tasks, requiring different kinds of reasoning. Certain types of reasoning have proven to be more difficult to learn in a monolingual context, and in the crosslingual context, similar observations may shed light on zero-shot transfer efficiency and few-shot sample selection. Hence, to investigate the effects of types of reasoning on transfer performance, we propose a category-annotated multilingual NLI dataset and discuss the challenges to scale monolingual annotations to multiple languages. We statistically observe interesting effects that the confluence of reasoning types and language similarities have on transfer performance."
2021.law-1.7,A Linguistic Annotation Framework to Study Interactions in Multilingual Healthcare Conversational Forums,2021,-1,-1,4,0,4491,ishani mondal,Proceedings of The Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop,0,"In recent years, remote digital healthcare using online chats has gained momentum, especially in the Global South. Though prior work has studied interaction patterns in online (health) forums, such as TalkLife, Reddit and Facebook, there has been limited work in understanding interactions in small, close-knit community of instant messengers. In this paper, we propose a linguistic annotation framework to facilitate analysis of health-focused WhatsApp groups. The primary aim of the framework is to understand interpersonal relationships among peer supporters in order to help develop NLP solutions for remote patient care and reduce burden of overworked healthcare providers. Our framework consists of fine-grained peer support categorization and message-level sentiment tagging. Additionally, due to the prevalence of code-mixing in such groups, we incorporate word-level language annotations. We use the proposed framework to study two WhatsApp groups in Kenya for youth living with HIV, facilitated by a healthcare provider."
2021.findings-acl.414,Use of Formal Ethical Reviews in {NLP} Literature: {H}istorical Trends and Current Practices,2021,-1,-1,3,1,8462,sebastin santy,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.eacl-demos.24,{GCM}: A Toolkit for Generating Synthetic Code-mixed Text,2021,-1,-1,4,0,11072,mohd rizvi,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations,0,"Code-mixing is common in multilingual communities around the world, and processing it is challenging due to the lack of labeled and unlabeled data. We describe a tool that can automatically generate code-mixed data given parallel data in two languages. We implement two linguistic theories of code-mixing, the Equivalence Constraint theory and the Matrix Language theory to generate all possible code-mixed sentences in the language-pair, followed by sampling of the generated data to generate natural code-mixed sentences. The toolkit provides three modes: a batch mode, an interactive library mode and a web-interface to address the needs of researchers, linguists and language experts. The toolkit can be used to generate unlabeled text data for pre-trained models, as well as visualize linguistic theories of code-mixing. We plan to release the toolkit as open source and extend it by adding more implementations of linguistic theories, visualization techniques and better sampling techniques. We expect that the release of this toolkit will help facilitate more research in code-mixing in diverse language pairs."
2021.adaptnlp-1.12,{BERT}ologi{C}o{M}ix: How does Code-Mixing interact with Multilingual {BERT}?,2021,-1,-1,3,1,8462,sebastin santy,Proceedings of the Second Workshop on Domain Adaptation for NLP,0,"Models such as mBERT and XLMR have shown success in solving Code-Mixed NLP tasks even though they were not exposed to such text during pretraining. Code-Mixed NLP models have relied on using synthetically generated data along with naturally occurring data to improve their performance. Finetuning mBERT on such data improves it{'}s code-mixed performance, but the benefits of using the different types of Code-Mixed data aren{'}t clear. In this paper, we study the impact of finetuning with different types of code-mixed data and outline the changes that occur to the model during such finetuning. Our findings suggest that using naturally occurring code-mixed data brings in the best performance improvement after finetuning and that finetuning with any type of code-mixed text improves the responsivity of it{'}s attention heads to code-mixed text inputs."
2020.lrec-1.343,Crowdsourcing Speech Data for Low-Resource Languages from Low-Income Workers,2020,-1,-1,6,0,17351,basil abraham,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Voice-based technologies are essential to cater to the hundreds of millions of new smartphone users. However, most of the languages spoken by these new users have little to no labelled speech data. Unfortunately, collecting labelled speech data in any language is an expensive and resource-intensive task. Moreover, existing platforms typically collect speech data only from urban speakers familiar with digital technology whose dialects are often very different from low-income users. In this paper, we explore the possibility of collecting labelled speech data directly from low-income workers. In addition to providing diversity to the speech dataset, we believe this approach can also provide valuable supplemental earning opportunities to these communities. To this end, we conducted a study where we collected labelled speech data in the Marathi language from three different user groups: low-income rural users, low-income urban users, and university students. Overall, we collected 109 hours of data from 36 participants. Our results show that the data collected from low-income participants is of comparable quality to the data collected from university students (who are typically employed to do this work) and that crowdsourcing speech data from low-income rural and urban workers is a viable method of gathering speech data."
2020.conll-1.4,{T}axi{NLI}: Taking a Ride up the {NLU} Hill,2020,-1,-1,4,1,17355,pratik joshi,Proceedings of the 24th Conference on Computational Natural Language Learning,0,"Pre-trained Transformer-based neural architectures have consistently achieved state-of-the-art performance in the Natural Language Inference (NLI) task. Since NLI examples encompass a variety of linguistic, logical, and reasoning phenomena, it remains unclear as to which specific concepts are learnt by the trained systems and where they can achieve strong generalization. To investigate this question, we propose a taxonomic hierarchy of categories that are relevant for the NLI task. We introduce TaxiNLI, a new dataset, that has 10k examples from the MNLI dataset with these taxonomic labels. Through various experiments on TaxiNLI, we observe that whereas for certain taxonomic categories SOTA neural models have achieved near perfect accuracies{---}a large jump over the previous models{---}some categories still remain difficult. Our work adds to the growing body of literature that shows the gaps in the current NLI systems and datasets through a systematic presentation and analysis of reasoning categories."
2020.calcs-1.2,A New Dataset for Natural Language Inference from Code-mixed Conversations,2020,21,0,4,0,8125,simran khanuja,Proceedings of the The 4th Workshop on Computational Approaches to Code Switching,0,"Natural Language Inference (NLI) is the task of inferring the logical relationship, typically entailment or contradiction, between a premise and hypothesis. Code-mixing is the use of more than one language in the same conversation or utterance, and is prevalent in multilingual communities all over the world. In this paper, we present the first dataset for code-mixed NLI, in which both the premises and hypotheses are in code-mixed Hindi-English. We use data from Hindi movies (Bollywood) as premises, and crowd-source hypotheses from Hindi-English bilinguals. We conduct a pilot annotation study and describe the final annotation protocol based on observations from the pilot. Currently, the data collected consists of 400 premises in the form of code-mixed conversation snippets and 2240 code-mixed hypotheses. We conduct an extensive analysis to infer the linguistic phenomena commonly observed in the dataset obtained. We evaluate the dataset using a standard mBERT-based pipeline for NLI and report results."
2020.calcs-1.5,Understanding Script-Mixing: A Case Study of {H}indi-{E}nglish Bilingual {T}witter Users,2020,-1,-1,3,0,22193,abhishek srivastava,Proceedings of the The 4th Workshop on Computational Approaches to Code Switching,0,"In a multi-lingual and multi-script society such as India, many users resort to code-mixing while typing on social media. While code-mixing has received a lot of attention in the past few years, it has mostly been studied within a single-script scenario. In this work, we present a case study of Hindi-English bilingual Twitter users while considering the nuances that come with the intermixing of different scripts. We present a concise analysis of how scripts and languages interact in communities and cultures where code-mixing is rampant and offer certain insights into the findings. Our analysis shows that both intra-sentential and inter-sentential script-mixing are present on Twitter and show different behavior in different contexts. Examples suggest that script can be employed as a tool for emphasizing certain phrases within a sentence or disambiguating the meaning of a word. Script choice can also be an indicator of whether a word is borrowed or not. We present our analysis along with examples that bring out the nuances of the different cases."
2020.calcs-1.8,Code-mixed parse trees and how to find them,2020,-1,-1,3,1,11073,anirudh srinivasan,Proceedings of the The 4th Workshop on Computational Approaches to Code Switching,0,"In this paper, we explore the methods of obtaining parse trees of code-mixed sentences and analyse the obtained trees. Existing work has shown that linguistic theories can be used to generate code-mixed sentences from a set of parallel sentences. We build upon this work, using one of these theories, the Equivalence-Constraint theory to obtain the parse trees of synthetically generated code-mixed sentences and evaluate them with a neural constituency parser. We highlight the lack of a dataset non-synthetic code-mixed constituency parse trees and how it makes our evaluation difficult. To complete our evaluation, we convert a code-mixed dependency parse tree set into {``}pseudo constituency trees{''} and find that a parser trained on synthetically generated trees is able to decently parse these as well."
2020.acl-main.329,{GLUEC}o{S}: An Evaluation Benchmark for Code-Switched {NLP},2020,30,0,5,0,8125,simran khanuja,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Code-switching is the use of more than one language in the same conversation or utterance. Recently, multilingual contextual embedding models, trained on multiple monolingual corpora, have shown promising results on cross-lingual and multilingual tasks. We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish. Specifically, our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference. We present results on all these tasks using cross-lingual word embedding models and multilingual models. In addition, we fine-tune multilingual models on artificially generated code-switched data. Although multilingual models perform significantly better than cross-lingual models, our results show that in most tasks, across both language pairs, multilingual models fine-tuned on code-switched data perform best, showing that multilingual models can be further optimized for code-switching tasks."
2020.acl-main.560,The State and Fate of Linguistic Diversity and Inclusion in the {NLP} World,2020,12,3,5,1,17355,pratik joshi,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the {``}language agnostic{''} status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind."
D19-3018,{INMT}: Interactive Neural Machine Translation Prediction,2019,0,0,3,1,8462,sebastin santy,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations,0,"In this paper, we demonstrate an Interactive Machine Translation interface, that assists human translators with on-the-fly hints and suggestions. This makes the end-to-end translation process faster, more efficient and creates high-quality translations. We augment the OpenNMT backend with a mechanism to accept the user input and generate conditioned translations."
D19-2002,Processing and Understanding Mixed Language Data,2019,0,0,1,1,154,monojit choudhury,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): Tutorial Abstracts,0,"Multilingual communities exhibit code-mixing, that is, mixing of two or more socially stable languages in a single conversation, sometimes even in a single utterance. This phenomenon has been widely studied by linguists and interaction scientists in the spoken language of such communities. However, with the prevalence of social media and other informal interactive platforms, code-switching is now also ubiquitously observed in user-generated text. As multilingual communities are more the norm from a global perspective, it becomes essential that code-switched text and speech are adequately handled by language technologies and NUIs.Code-mixing is extremely prevalent in all multilingual societies. Current studies have shown that as much as 20{\%} of user generated content from some geographies, like South Asia, parts of Europe, and Singapore, are code-mixed. Thus, it is very important to handle code-mixed content as a part of NLP systems and applications for these geographies.In the past 5 years, there has been an active interest in computational models for code-mixing with a substantive research outcome in terms of publications, datasets and systems. However, it is not easy to find a single point of access for a complete and coherent overview of the research. This tutorial is expecting to fill this gap and provide new researchers in the area with a foundation in both linguistic and computational aspects of code-mixing. We hope that this then becomes a starting point for those who wish to pursue research, design, development and deployment of code-mixed systems in multilingual societies."
2019.icon-1.25,Unsung Challenges of Building and Deploying Language Technologies for Low Resource Language Communities,2019,20,1,9,1,17355,pratik joshi,Proceedings of the 16th International Conference on Natural Language Processing,0,"In this paper, we examine and analyze the challenges associated with developing and introducing language technologies to low-resource language communities. While doing so we bring to light the successes and failures of past work in this area, challenges being faced in doing so, and what have they achieved. Throughout this paper, we take a problem-facing approach and describe essential factors which the success of such technologies hinges upon. We present the various aspects in a manner which clarify and lay out the different tasks involved, which can aid organizations looking to make an impact in this area. We take the example of Gondi, an extremely-low resource Indian language, to reinforce and complement our discussion."
W18-3202,Phone Merging For Code-Switched Speech Recognition,2018,0,2,5,0,28336,sunit sivasankaran,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Speakers in multilingual communities often switch between or mix multiple languages in the same conversation. Automatic Speech Recognition (ASR) of code-switched speech faces many challenges including the influence of phones of different languages on each other. This paper shows evidence that phone sharing between languages improves the Acoustic Model performance for Hindi-English code-switched speech. We compare baseline system built with separate phones for Hindi and English with systems where the phones were manually merged based on linguistic knowledge. Encouraged by the improved ASR performance after manually merging the phones, we further investigate multiple data-driven methods to identify phones to be merged across the languages. We show detailed analysis of automatic phone merging in this language pair and the impact it has on individual phone accuracies and WER. Though the best performance gain of 1.2{\%} WER was observed with manually merged phones, we show experimentally that the manual phone merge is not optimal."
W18-3210,Accommodation of Conversational Code-Choice,2018,0,0,2,0,28341,anshul bawa,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Bilingual speakers often freely mix languages. However, in such bilingual conversations, are the language choices of the speakers coordinated? How much does one speaker{'}s choice of language affect other speakers? In this paper, we formulate code-choice as a linguistic style, and show that speakers are indeed sensitive to and accommodating of each other{'}s code-choice. We find that the saliency or markedness of a language in context directly affects the degree of accommodation observed. More importantly, we discover that accommodation of code-choices persists over several conversational turns. We also propose an alternative interpretation of conversational accommodation as a retrieval problem, and show that the differences in accommodation characteristics of code-choices are based on their markedness in context."
P18-1143,Language Modeling for Code-Mixing: The Role of Linguistic Theory based Synthetic Data,2018,0,15,3,1,153,adithya pratapa,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Training language models for Code-mixed (CM) language is known to be a difficult problem because of lack of data compounded by the increased confusability due to the presence of more than one language. We present a computational technique for creation of grammatically valid artificial CM data based on the Equivalence Constraint Theory. We show that when training examples are sampled appropriately from this synthetic data and presented in certain order (aka training curriculum) along with monolingual and real CM data, it can significantly reduce the perplexity of an RNN-based language model. We also show that randomly generated CM data does not help in decreasing the perplexity of the LMs."
L18-1256,An Integrated Representation of Linguistic and Social Functions of Code-Switching,2018,0,0,2,0,29793,silvana hartmann,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1455,Discovering Canonical {I}ndian {E}nglish Accents: A Crowdsourcing-based Approach,2018,0,0,4,1,6024,sunayana sitaram,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D18-1344,Word Embeddings for Code-Mixed Language Processing,2018,0,5,2,1,153,adithya pratapa,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We compare three existing bilingual word embedding approaches, and a novel approach of training skip-grams on synthetic code-mixed text generated through linguistic models of code-mixing, on two tasks - sentiment analysis and POS tagging for code-mixed text. Our results show that while CVM and CCA based embeddings perform as well as the proposed embedding technique on semantic and syntactic tasks respectively, the proposed approach provides the best performance for both tasks overall. Thus, this study demonstrates that existing bilingual embedding techniques are not ideal for code-mixed text processing and there is a need for learning multilingual word embedding from the code-mixed text."
W17-7509,Curriculum Design for Code-switching: Experiments with Language Identification and Language Modeling with Deep Neural Networks,2017,0,10,1,1,154,monojit choudhury,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-7510,Quantitative Characterization of Code Switching Patterns in Complex Multi-Party Conversations: A Case Study on {H}indi Movie Scripts,2017,0,2,2,1,153,adithya pratapa,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
P17-1180,Estimating Code-Switching on {T}witter with a Novel Generalized Word-Level Language Detection Technique,2017,19,15,3,1,9800,shruti rijhwani,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Word-level language detection is necessary for analyzing code-switched text, where multiple languages could be mixed within a sentence. Existing models are restricted to code-switching between two specific languages and fail in real-world scenarios as text input rarely has a priori information on the languages used. We present a novel unsupervised word-level language detection technique for code-switched text for an arbitrarily large number of languages, which does not require any manually annotated training data. Our experiments with tweets in seven languages show a 74{\%} relative error reduction in word-level labeling with respect to competitive baselines. We then use this system to conduct a large-scale quantitative analysis of code-switching patterns on Twitter, both global as well as region-specific, with 58M tweets."
D17-1240,All that is {E}nglish may be {H}indi: Enhancing language identification through automatic ranking of the likeliness of word borrowing in social media,2017,0,5,6,0,10939,jasabanta patro,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"n this paper, we present a set of computational methods to identify the likeliness of a word being borrowed, based on the signals from social media. In terms of Spearman{'}s correlation values, our methods perform more than two times better (â¼ 0.62) in predicting the borrowing likeliness compared to the best performing baseline (â¼ 0.26) reported in literature. Based on this likeliness estimate we asked annotators to re-annotate the language tags of foreign words in predominantly native contexts. In 88{\%} of cases the annotators felt that the foreign language tag should be replaced by native language tag, thus indicating a huge scope for improvement of automatic language identification systems."
L16-1260,Functions of Code-Switching in Tweets: An Annotation Framework and Some Initial Experiments,2016,14,4,3,0,34994,rafiya begum,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Code-Switching (CS) between two languages is extremely common in communities with societal multilingualism where speakers switch between two or more languages when interacting with each other. CS has been extensively studied in spoken language by linguists for several decades but with the popularity of social-media and less formal Computer Mediated Communication, we now see a big rise in the use of CS in the text form. This poses interesting challenges and a need for computational processing of such code-switched data. As with any Computational Linguistic analysis and Natural Language Processing tools and applications, we need annotated data for understanding, processing, and generation of code-switched language. In this study, we focus on CS between English and Hindi Tweets extracted from the Twitter stream of Hindi-English bilinguals. We present an annotation scheme for annotating the pragmatic functions of CS in Hindi-English (Hi-En) code-switched tweets based on a linguistic analysis and some initial experiments."
D16-1121,Understanding Language Preference for Expression of Opinion and Sentiment: What do {H}indi-{E}nglish Speakers do on {T}witter?,2016,24,13,5,0,34995,koustav rudra,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
W15-5936,{POS} Tagging of {H}indi-{E}nglish Code Mixed Text from Social Media: Some Machine Learning Experiments,2015,14,7,2,0,32665,royal sequiera,Proceedings of the 12th International Conference on Natural Language Processing,0,None
W14-5149,Hierarchical Recursive Tagset for Annotating Cooking Recipes,2014,10,0,3,0,38336,sharath gunamgari,Proceedings of the 11th International Conference on Natural Language Processing,0,"Several natural language annotation schemas have been proposed for different natural language understanding tasks. In this paper we present a hierarchical and recursive tagset for annotating natural language recipes. Our recipe annotation tagset is developed to capture both syntactic and semantic information in the text. First, we propose our hierarchical recursive tagset that captures cooking attributes and relationships among them. Furthermore, we develop different heuristics to automatically annotate natural language recipes using our proposed tagset. These heuristics use surface-level and syntactic information from the text and the association between words. We are able to annotate the recipe text with 91% accuracy in an ideal situation."
W14-5151,{``}ye word kis lang ka hai bhai?{''} Testing the Limits of Word level Language Identification,2014,20,11,3,0,9729,spandana gella,Proceedings of the 11th International Conference on Natural Language Processing,0,"Language identification is a necessary prerequisite for processing any user generated text, where the language is unknown. It becomes even more challenging when the text is code-mixed, i.e., two or more languages are used within the same text. Such data is commonly seen in social media, where further challenges might arise due to contractions and transliterations. The existing language identification systems are not designed to deal with codemixed text, and as our experiments show, perform poorly on a synthetically created code-mixed dataset for 28 languages.We propose extensions to an existing approach for word level language identification. Our technique not only outperforms the existing methods, but also makes no assumption about the language pairs mixed in the text a common requirement of the existing word level language identification systems.This study shows that word level language identification is most likely to confuse between languages which are linguistically related (e.g., Hindi and Gujarati, Czech and Slovak), for which special disambiguation techniques might be required."
W14-3908,Word-level Language Identification using {CRF}: Code-switching Shared Task Report of {MSR} {I}ndia System,2014,15,24,4,0,38513,gokul chittaranjan,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"We describe a CRF based system for word-level language identification of code-mixed text. Our method uses lexical, contextual, character n-gram, and special character features, and therefore, can easily be replicated across languages. Its performance is benchmarked against the test sets provided by the shared task on code-mixing (Solorio et al., 2014) for four language pairs, namely, EnglishSpanish (En-Es), English-Nepali (En-Ne), English-Mandarin (En-Cn), and Standard Arabic-Arabic (Ar-Ar) Dialects. The experimental results show a consistent performance across the language pairs."
W14-3914,{``}{I} am borrowing ya mixing ?'' An Analysis of {E}nglish-{H}indi Code Mixing in {F}acebook,2014,19,43,3,0.845845,5433,kalika bali,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"Code-Mixing is a frequently observed phenomenon in social media content generated by multi-lingual users. The processing of such data for linguistic analysis as well as computational modelling is challenging due to the linguistic complexity resulting from the nature of the mixing as well as the presence of non-standard variations in spellings and grammar, and transliteration. Our analysis shows the extent of Code-Mixing in English-Hindi data. The classification of Code-Mixed words based on frequency and linguistic typology underline the fact that while there are easily identifiable cases of borrowing and mixing at the two ends, a large majority of the words form a continuum in the middle, emphasizing the need to handle these at different levels for automatic processing of the data."
D14-1105,{POS} Tagging of {E}nglish-{H}indi Code-Mixed Social Media Content,2014,23,85,5,0,3434,yogarshi vyas,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Code-mixing is frequently observed in user generated content on social media, especially from multilingual users. The linguistic complexity of such content is compounded by presence of spelling variations, transliteration and non-adherance to formal grammar. We describe our initial efforts to create a multi-level annotated corpus of Hindi-English codemixed text collated from Facebook forums, and explore language identification, back-transliteration, normalization and POS tagging of this data. Our results show that language identification and transliteration for Hindi are two major challenges that impact POS tagging accuracy."
C14-1098,Automatic Discovery of Adposition Typology,2014,28,0,4,0,26065,rishiraj roy,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,None
W13-2306,{E}ntailment: An Effective Metric for Comparing and Evaluating Hierarchical and Non-hierarchical Annotation Schemes,2013,14,1,2,0,39155,rohan ramanath,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"Hierarchical or nested annotation of linguistic data often co-exists with simpler non-hierarchical or flat counterparts, a classic example being that of annotations used for parsing and chunking. In this work, we propose a general strategy for comparing across these two schemes of annotation using the concept of entailment that formalizes a correspondence between them. We use crowdsourcing to obtain query and sentence chunking and show that entailment can not only be used as an effective evaluation metric to assess the quality of annotations, but it can also be employed to filter out noisy annotations."
P13-1168,Crowd Prefers the Middle Path: A New {IAA} Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation,2013,23,8,2,0,39155,rohan ramanath,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Query segmentation, like text chunking, is the first step towards query understanding. In this study, we explore the effectiveness of crowdsourcing for this task. Through carefully designed control experiments and Inter Annotator Agreement metrics for analysis of experimental data, we show that crowdsourcing may not be a suitable approach for query segmentation because the crowd seems to have a very strong bias towards dividing the query into roughly equal (often only two) parts. Similarly, in the case of hierarchical or nested segmentation, turkers have a strong preference towards balanced binary trees."
saravanan-etal-2012-empirical,An Empirical Study of the Occurrence and Co-Occurrence of Named Entities in Natural Language Corpora,2012,14,3,2,0,42938,saravanan,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Named Entities (NEs) that occur in natural language text are important especially due to the advent of social media, and they play a critical role in the development of many natural language technologies. In this paper, we systematically analyze the patterns of occurrence and co-occurrence of NEs in standard large English news corpora - providing valuable insight for the understanding of the corpus, and subsequently paving way for the development of technologies that rely critically on handling NEs. We use two distinctive approaches: normal statistical analysis that measure and report the occurrence patterns of NEs in terms of frequency, growth, etc., and a complex networks based analysis that measures the co-occurrence pattern in terms of connectivity, degree-distribution, small-world phenomenon, etc. Our analysis indicates that: (i) NEs form an open-set in corpora and grow linearly, (ii) presence of a kernel and peripheral NE's, with the large periphery occurring rarely, and (iii) a strong evidence of small-world phenomenon. Our findings may suggest effective ways for construction of NE lexicons to aid efficient development of several natural language technologies."
gupta-etal-2012-mining,Mining {H}indi-{E}nglish Transliteration Pairs from Online {H}indi Lyrics,2012,10,28,2,0,42959,kanika gupta,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper describes a method to mine Hindi-English transliteration pairs from online Hindi song lyrics. The technique is based on the observations that lyrics are transliterated word-by-word, maintaining the precise word order. The mining task is nevertheless challenging because the Hindi lyrics and its transliterations are usually available from different, often unrelated, websites. Therefore, it is a non-trivial task to match the Hindi lyrics to their transliterated counterparts. Moreover, there are various types of noise in lyrics data that needs to be appropriately handled before songs can be aligned at word level. The mined data of 30823 unique Hindi-English transliteration pairs with an accuracy of more than 92{\%} is available publicly. Although the present work reports mining of Hindi-English word pairs, the same technique can be easily adapted for other languages for which song lyrics are available online in native and Roman scripts."
W11-3501,Challenges in Designing Input Method Editors for {I}ndian Lan-guages: The Role of Word-Origin and Context,2011,9,21,3,0,44079,umair ahmed,Proceedings of the Workshop on Advances in Text Input Methods ({WTIM} 2011),0,"Back-transliteration based Input Method Editors are very popular for Indian Languages. In this paper we evaluate two such Indic language systems to help understand the challenge of designing a back-transliteration based IME. Through a detailed error-analysis of Hindi, Bangla and Telugu data, we study the role of phonological features of Indian scripts that are reflected as variations and ambiguity in the transliteration. The impact of word-origin on back-transliteration is discussed in the context of codeswitching. We also explore the role of word-level context to help overcome some of these challenges."
b-etal-2010-resource,Resource Creation for Training and Testing of Transliteration Systems for {I}ndian Languages,2010,6,23,2,0,45916,sowmya,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Machine transliteration is used in a number of NLP applications ranging from machine translation and information retrieval to input mechanisms for non-roman scripts. Many popular Input Method Editors for Indian languages, like Baraha, Akshara, Quillpad etc, use back-transliteration as a mechanism to allow users to input text in a number of Indian language. The lack of a standard dataset to evaluate these systems makes it difficult to make any meaningful comparisons of their relative accuracies. In this paper, we describe the methodology for the creation of a dataset of {\textasciitilde}2500 transliterated sentence pairs each in Bangla, Hindi and Telugu. The data was collected across three different modes from a total of 60 users. We believe that this dataset will prove useful not only for the evaluation and training of back-transliteration systems but also help in the linguistic analysis of the process of transliterating Indian languages from native scripts to Roman."
C10-2019,Global topology of word co-occurrence networks: Beyond the two-regime power-law,2010,14,29,1,1,154,monojit choudhury,Coling 2010: Posters,0,"Word co-occurrence networks are one of the most common linguistic networks studied in the past and they are known to exhibit several interesting topological characteristics. In this article, we investigate the global topological properties of word co-occurrence networks and, in particular, present a detailed study of their spectrum. Our experiments reveal certain universal trends found across the networks for seven different languages from three different language families, which are neither reported nor explained by any of the previous studies and models of word-cooccurrence networks. We hypothesize that since word co-occurrences are governed by syntactic properties of a language, the network has much constrained topology than that predicted by the previously proposed growth model. A deeper empirical and theoretical investigation into the evolution of these networks further suggests that they have a coreperiphery structure, where the core hardly evolves with time and new words are only attached to the periphery of the network. These properties are fundamental to the nature of word co-occurrence across languages."
W09-3002,Complex Linguistic Annotation {--} No Easy Way Out! A Case from {B}angla and {H}indi {POS} Labeling Tasks,2009,9,21,3,0.292218,6023,sandipan dandapat,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"Alternative paths to linguistic annotation, such as those utilizing games or exploiting the web users, are becoming popular in recent times owing to their very high benefit-to-cost ratios. In this paper, however, we report a case study on POS annotation for Bangla and Hindi, where we observe that reliable linguistic annotation requires not only expert annotators, but also a great deal of supervision. For our hierarchical POS annotation scheme, we find that close supervision and training is necessary at every level of the hierarchy, or equivalently, complexity of the tagset. Nevertheless, an intelligent annotation tool can significantly accelerate the annotation process and increase the inter-annotator agreement for both expert and non-expert annotators. These findings lead us to believe that reliable annotation requiring deep linguistic knowledge (e.g., POS, chunking, Treebank, semantic role labeling) requires expertise and supervision. The focus, therefore, should be on design and development of appropriate annotation tools equipped with machine learning based predictive modules that can significantly boost the productivity of the annotators."
W09-0907,Language Diversity across the Consonant Inventories: A Study in the Framework of Complex Networks,2009,33,2,1,1,154,monojit choudhury,Proceedings of the {EACL} 2009 Workshop on Cognitive Aspects of Computational Language Acquisition,0,"In this paper, we attempt to explain the emergence of the linguistic diversity that exists across the consonant inventories of some of the major language families of the world through a complex network based growth model. There is only a single parameter for this model that is meant to introduce a small amount of randomness in the otherwise preferential attachment based growth process. The experiments with this model parameter indicates that the choice of consonants among the languages within a family are far more preferential than it is across the families. Furthermore, our observations indicate that this parameter might bear a correlation with the period of existence of the language families under investigation. These findings lead us to argue that preferential attachement seems to be an appropriate high level abstraction for language acquisition and change."
P09-2062,Syntax is from {M}ars while Semantics from {V}enus! Insights from Spectral Analysis of Distributional Similarity Networks,2009,10,6,2,0,2565,chris biemann,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"We study the global topology of the syntactic and semantic distributional similarity networks for English through the technique of spectral analysis. We observe that while the syntactic network has a hierarchical structure with strong communities and their mixtures, the semantic network has several tightly knit communities along with a large core without any such well-defined community structure."
E09-1015,Large-Coverage Root Lexicon Extraction for {H}indi,2009,13,7,2,0,33378,cohan carlos,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"This paper describes a method using morphological rules and heuristics, for the automatic extraction of large-coverage lexicons of stems and root word-forms from a raw text corpus. We cast the problem of high-coverage lexicon extraction as one of stemming followed by root word-form selection. We examine the use of POS tagging to improve precision and recall of stemming and thereby the coverage of the lexicon. We present accuracy, precision and recall scores for the system on a Hindi corpus."
E09-1067,Discovering Global Patterns in Linguistic Networks through Spectral Analysis: A Case Study of the Consonant Inventories,2009,18,8,2,1,11177,animesh mukherjee,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Recent research has shown that language and the socio-cognitive phenomena associated with it can be aptly modeled and visualized through networks of linguistic entities. However, most of the existing works on linguistic networks focus only on the local properties of the networks. This study is an attempt to analyze the structure of languages via a purely structural technique, namely spectral analysis, which is ideally suited for discovering the global correlations in a network. Application of this technique to PhoNet, the co-occurrence network of consonants, not only reveals several natural linguistic principles governing the structure of the consonant inventories, but is also able to quantify their relative importance. We believe that this powerful technique can be successfully applied, in general, to study the structure of natural languages."
nath-etal-2008-unsupervised,Unsupervised Parts-of-Speech Induction for {B}engali,2008,26,5,2,0,48163,joydeep nath,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present a study of the word interaction networks of Bengali in the framework of complex networks. The topological properties of these networks reveal interesting insights into the morpho-syntax of the language, whereas clustering helps in the induction of the natural word classes leading to a principled way of designing POS tagsets. We compare different network construction techniques and clustering algorithms based on the cohesiveness of the word clusters. Cohesiveness is measured against two gold-standard tagsets by means of the novel metric of tag-entropy. The approach presented here is a generic one that can be easily extended to any language."
sankaran-etal-2008-common,A Common Parts-of-Speech Tagset Framework for {I}ndian Languages,2008,3,29,3,0,35509,baskaran sankaran,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present a universal Parts-of-Speech (POS) tagset framework covering most of the Indian languages (ILs) following the hierarchical and decomposable tagset schema. In spite of significant number of speakers, there is no workable POS tagset and tagger for most ILs, which serve as fundamental building blocks for NLP research. Existing IL POS tagsets are often designed for a specific language; the few that have been designed for multiple languages cover only shallow linguistic features ignoring linguistic richness and the idiosyncrasies. The new framework that is proposed here addresses these deficiencies in an efficient and principled manner. We follow a hierarchical schema similar to that of EAGLES and this enables the framework to be flexible enough to capture rich features of a language/ language family, even while capturing the shared linguistic structures in a methodical way. The proposed common framework further facilitates the sharing and reusability of scarce resources in these languages and ensures cross-linguistic compatibility."
I08-3003,Invited Talk: Breaking the {Z}ipfian Barrier of {NLP},2008,0,1,1,1,154,monojit choudhury,Proceedings of the {IJCNLP}-08 Workshop on {NLP} for Less Privileged Languages,0,None
I08-2135,Social Network Inspired Models of {NLP} and Language Evolution,2008,0,0,1,1,154,monojit choudhury,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"Human language with all its intricacies is perhaps one of the finest examples of a complex system. Therefore, it becomes absolutely necessary to study the faculty of language from the perspective of a complex system. Of late, there has been an upsurge in the use of networks in modeling the complex dynamics of various natural and artificial systems. While some of these works aim at using social network techniques to build certain enduser applications, others are more fundamental in the sense that they employ these techniques to explain the emergent properties of a complex system as a whole. A substantial amount of research have also been done in the field of linguistics to employ social networks in the design of efficient solutions for numerous problems in NLP and language evolution. The objective of this tutorial is to show how language and its dynamics can be successfully studied in the framework of social networks. The tutorial will particularly demonstrate the relevance of social network-based methods in the development of a large variety of NLP applications and in understanding the dynamics of language evolution and change. The tutorial is divided into two parts. Part I begins with a brief introduction to this field showing how linguistic entities and the interactions between them can be respectively represented through the nodes and edges of a network. This will be followed by a comprehensive survey of the general theory of social networks with a special emphasis on the methods of analysis and models of synthesis for such networks. Part II presents three case studies. The first case study is on unsupervised POS tagging, the second one involves modeling of the mental lexicon and applications of such models in spell checking and word sense disambiguation. The third case study demonstrates the usefulness of social networks in explaining some of the evolutionary dynamics of language pertaining to the sound inventories. The tutorial is concluded by (a) comparing the above methods with more traditional methods of doing NLP, (b) providing pointers as to where to look for/publish materials in this area, and, (c) indicating some of the future research directions."
C08-1076,Modeling the Structure and Dynamics of the Consonant Inventories: A Complex Network Approach,2008,20,5,2,1,11177,animesh mukherjee,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"We study the self-organization of the consonant inventories through a complex network approach. We observe that the distribution of occurrence as well as co-occurrence of the consonants across languages follow a power-law behavior. The co-occurrence network of consonants exhibits a high clustering coefficient. We propose four novel synthesis models for these networks (each of which is a refinement of the earlier) so as to successively match with higher accuracy (a) the above mentioned topological properties as well as (b) the linguistic property of feature economy exhibited by the consonant inventories. We conclude by arguing that a possible interpretation of this mechanism of network growth is the process of child language acquisition. Such models essentially increase our understanding of the structure of languages that is influenced by their evolutionary dynamics and this, in turn, can be extremely useful for building future NLP applications."
W07-1309,"Evolution, Optimization, and Language Change: The Case of {B}engali Verb Inflections",2007,26,6,1,1,154,monojit choudhury,Proceedings of Ninth Meeting of the {ACL} Special Interest Group in Computational Morphology and Phonology,0,"The verb inflections of Bengali underwent a series of phonological change between 10th and 18th centuries, which gave rise to several modern dialects of the language. In this paper, we offer a functional explanation for this change by quantifying the functional pressures of ease of articulation, perceptual contrast and learnability through objective functions or constraints, or both. The multi-objective and multi-constraint optimization problem has been solved through genetic algorithm, whereby we have observed the emergence of Pareto-optimal dialects in the system that closely resemble some of the real ones."
W07-1313,Emergence of Community Structures in Vowel Inventories: An Analysis Based on Complex Networks,2007,13,5,2,1,11177,animesh mukherjee,Proceedings of Ninth Meeting of the {ACL} Special Interest Group in Computational Morphology and Phonology,0,"In this work, we attempt to capture patterns of co-occurrence across vowel systems and at the same time figure out the nature of the force leading to the emergence of such patterns. For this purpose we define a weighted network where the vowels are the nodes and an edge between two nodes (read vowels) signify their co-occurrence likelihood over the vowel inventories. Through this network we identify communities of vowels, which essentially reflect their patterns of co-occurrence across languages. We observe that in the assortative vowel communities the constituent nodes (read vowels) are largely uncorrelated in terms of their features indicating that they are formed based on the principle of maximal perceptual contrast. However, in the rest of the communities, strong correlations are reflected among the constituent vowels with respect to their features indicating that it is the principle of feature economy that binds them together."
W07-0212,How Difficult is it to Develop a Perfect Spell-checker? A Cross-Linguistic Analysis through Complex Network Approach,2007,13,11,1,1,154,monojit choudhury,Proceedings of the Second Workshop on {T}ext{G}raphs: Graph-Based Algorithms for Natural Language Processing,0,"The difficulties involved in spelling error detection and correction in a language have been investigated in this work through the conceptualization of SpellNet xe2x80x90 the weighted network of words, where edges indicate orthographic proximity between two words. We construct SpellNets for three languages - Bengali, English and Hindi. Through appropriate mathematical analysis and/or intuitive justification, we interpret the different topological metrics of SpellNet from the perspective of the issues related to spell-checking. We make many interesting observations, the most significant among them being that the probability of making a real word error in a language is propotionate to the average weighted degree of SpellNet, which is found to be highest for Hindi, followed by Bengali and English."
P07-1014,Redundancy Ratio: An Invariant Property of the Consonant Inventories of the World{'}s Languages,2007,10,7,2,1,11177,animesh mukherjee,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"In this paper, we put forward an information theoretic definition of the redundancythat is observed across the sound inventories of the worldxe2x80x99s languages. Through rigorous statistical analysis, we find that this redundancy is an invariant property of the consonant inventories. The statistical analysis further unfolds that the vowel inventories do not exhibit any such property, which in turn points to the fact that the organizing principles of the vowel and the consonant inventories are quite different in nature."
P06-2017,Analysis and Synthesis of the Distribution of Consonants over Languages: A Complex Network Approach,2006,20,17,1,1,154,monojit choudhury,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Cross-linguistic similarities are reflected by the speech sound systems of languages all over the world. In this work we try to model such similarities observed in the consonant inventories, through a complex bipartite network. We present a systematic study of some of the appealing features of these inventories with the help of the bipartite network. An important observation is that the occurrence of consonants follows a two regime power law distribution. We find that the consonant inventory size distribution together with the principle of preferential attachment are the main reasons behind the emergence of such a two regime behavior. In order to further support our explanation we present a synthesis model for this network based on the general theory of preferential attachment."
W04-0103,A Diachronic Approach for Schwa Deletion in {I}ndo {A}ryan Languages,2004,10,14,1,1,154,monojit choudhury,Proceedings of the 7th Meeting of the {ACL} Special Interest Group in Computational Phonology: Current Themes in Computational Phonology and Morphology,0,"Schwa deletion is an important issue in grapheme-to-phoneme conversion for Indo-Aryan languages (IAL). In this paper, we describe a syllable minimization based algorithm for dealing with this that outperforms the existing methods in terms of efficiency and accuracy. The algorithm is motivated by the fact that deletion of schwa is a diachronic and sociolinguistic phenomenon that facilitates faster communication through syllable economy. The contribution of the paper is not just a better algorithm for schwa deletion; rather we describe here a constrained optimization based framework that can partly model the evolution of languages, and hence, can be used for solving many problems in computational linguistics that call for diachronic explanations."
