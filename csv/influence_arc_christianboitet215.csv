1986.tc-1.16,C82-1034,0,0.0607043,"Missing"
1986.tc-1.16,P84-1100,1,0.890903,"Missing"
1986.tc-1.16,P84-1067,0,0.316749,"Missing"
1986.tc-1.16,1985.tmi-1.3,1,0.421152,"Missing"
1986.tc-1.16,C86-1150,0,0.0601481,"Missing"
1988.tmi-1.23,1985.tmi-1.3,1,0.83356,"Missing"
1988.tmi-1.23,C88-1013,0,0.0134143,"1,S($F1)),(α/a1α1b1β1c1γ1)) [a1,a1] [b1,b1] [c1,c1] [S($F1),α1β1γ1] by R2 with {($F/$F1), ($F1 /a2,b2,c2,S($F2)), (α / α1β1γ1), (α1 / a2a3), (β1 / b2b3), (γ1/c2c3)} [a2,a2] [b2,b2] [c2,c2] [S($F1). a3b3c3] by Rl with {($F1 / a3,b3,c3)] [a3,a3] [b3,b3] [c3,c3] Here, we have used indices to make the subcorrespondences clear. It is easy to augment slightly the formalism to describe them within the rules, by indicating on each node to which substring it corresponds, and to which substring the subtree rooted at it corresponds, the substrings being possibly discontinuous, as in the previous example [69]. 8 1985- : towards a new treatment of ambiguity In NLP, the omnipresent and fundamental problem of ambiguity is often maltreated, badly treated, or not treated. The first technique consists, as soon as an ambiguity appears, in deciding for a solution on the spot, without possibility of ulterior correction. It is that of 1G MT systems. If backtracking is introduced, as in many Prolog-based analyzers, the first correct solution is obtained, but nothing guarantees that it is the best, or even a good one. The second approach, known as the ""filter"" approach, is combinatorial : all possibilities ar"
1988.tmi-1.23,C86-1121,0,0.0452917,"Missing"
1988.tmi-1.23,1985.tmi-1.6,1,0.822449,"Missing"
1988.tmi-1.23,J82-2005,0,0.0639954,"Missing"
1988.tmi-1.23,C86-1155,0,0.0409767,"Missing"
1988.tmi-1.23,1985.tmi-1.12,0,0.109743,"Missing"
1988.tmi-1.23,C82-1034,0,0.0411771,"Missing"
1988.tmi-1.23,P84-1069,0,0.0333346,"Missing"
1988.tmi-1.23,C86-1149,0,0.036493,"Missing"
1988.tmi-1.23,C86-1150,0,0.0638746,"Missing"
1988.tmi-1.23,1987.mtsummit-1.23,0,0.0734798,"Missing"
1988.tmi-1.23,1985.tmi-1.22,0,0.0413724,"Missing"
1988.tmi-1.23,C86-1030,0,0.209196,"grammar) has since been proposed. Hundreds of boards have been written, for several languages, and in particular for French and English, in the framework of the MAT-NP (French MAT National Project, 1983-87), and used for writing analyzers and generators. This is an example of a clearly useful formalism, which has quite clear ""intuitive"" semantics, but for which adequate formal semantics have been difficult to formulate (this has entailed modifications of the initial formalism), perhaps because of the original practice-oriented motivation. This is a part of Zaharin's contribution in his thesis [129]. Based on this modified model, an interpreter is now being implemented. Let us give a flavor of SCSG by using an example involving the strictly context-sensitive formal language L = {anbncn}, which can be used to model natural language constructs of the ""respectively"" type, such as : Linguists, lexicographers and engineers describe, index and implement grammars, dictionaries and NLP-systems. 7 At least two structural descriptors seem ""natural"" for the string wn = anbncn, namely (Tl) S(A(a1,A(a2,...A(an)...)), B(b1,B(b2,...B(bn)...)), C(c1,C(c2,...C(cn)...))) (T2) S(a1,b1,c1,S(a2,b2,c2,...S(an"
1988.tmi-1.23,C86-1093,0,0.0300254,"Missing"
1993.mtsummit-1.15,C90-2045,0,0.297674,"Missing"
1993.mtsummit-1.15,C92-3164,0,0.0589862,"Missing"
1994.bcs-1.22,C90-3008,0,0.0439954,"Missing"
1994.bcs-1.22,C90-3074,0,0.316292,"Missing"
1994.bcs-1.22,C86-1155,0,0.232856,"Missing"
1994.bcs-1.22,C94-1057,0,0.0454599,"Missing"
1994.bcs-1.22,C90-2045,0,0.29104,"Missing"
1994.bcs-1.22,C82-1034,0,0.215464,"Missing"
1994.bcs-1.22,C92-3168,0,0.239277,"Missing"
1994.bcs-1.22,C94-1044,0,0.0538256,"Missing"
1994.bcs-1.22,C90-3048,0,0.287191,"Missing"
1994.bcs-1.22,C92-3129,0,0.135861,"Missing"
1994.bcs-1.22,C86-1077,0,0.148694,"Missing"
1994.bcs-1.22,C88-2155,0,0.265656,"Missing"
1995.mtsummit-1.7,J82-2005,0,0.0145282,"Missing"
1995.mtsummit-1.7,C82-1034,0,0.0667957,"s frameworks where they can integrate a variety of ""microtheories"". I.3 MT for translators (1975—) Tools for individual translators have been available since the beginning of office automation. Note that ALPS has proposed a “groupware”, local network environment very early. Operational and commercial success has been met only by systems running on standard platforms and integrated with 8 Although it could perhaps have been a viable method for tasks such as the translation of screen messages, no attempt seems to have been done in this direction. several text processors. The case of TWS and MTX [7, 10], both produced by Linguatech, is a good example. SISKEP (English-Malay) offers helps in the target language, Malay, because it aims at translators who are native speakers of Malay, but may be terminologically more competent in English. Since 1988, quite a few tools for professional teams have appeared on the market. Here are some of them. A remark here is that the most recent tools include translation memories. They have been quite successful operationally: tests have always shown a significant decrease in translation time. Commercial success is still doubtful, and reasons for that are not so"
1995.mtsummit-1.7,J85-1003,1,0.797572,"Missing"
1995.mtsummit-1.7,1985.tmi-1.4,0,0.0856639,"Missing"
1995.mtsummit-1.7,1985.tmi-1.20,0,0.0717292,"to distinguish a third wave in 1982-87. Why these dates? They correspond to the beginning and end of two national projects (Japan, France) and of the Eurotra project per se, all aiming at triggering such products. They also almost coincide with the development period of METAL. Finally, the first MT Summit was held in Hakone in 1987 and was the occasion to see many Japanese products together for the first time. The French MAT national project (projet national TAO [25]) was clearly a conceptual and engineering success: - lingware engineering improved on the grammatical level (“static grammars” [17] as a specification level) and on the lexical level (“neutral” lexical database). - Ariane-78 was extended to Ariane-85 and then Ariane-G5, and made accessible from a PC for submitting translations from Word™ and developing terminological dictionaries. - The first version of an industrial French-English system for aviation maintenance manuals gave very impressive results. However, the project was a commercial and communicative failure. This is because of: - bad project set-up: the direction of the project was given by the funding agency, ADI, to SG2, a firm with no experience at all in NLP, an"
1995.mtsummit-1.7,J85-1001,0,0.0291163,"t complete and surely not perfectly accurate, gives an idea of the systems, makers, users, platforms, starting dates and success/failure at various levels (our appreciation). Some of these systems have achieved conceptual success. For example, Fujitsu and NEC have boldly chosen the interlingua approach, more elegant but more costly than the transfer approach. Toshiba has presented very interesting improvements to an otherwise quite classical semantic transfer design at several conferences. B'Vital/SITE has used the multilevel transfer approach for the first time in an industrial system. METAL [18], although linguistically not very advanced (syntactic transfer with no clear separation between transfer and generation), was entirely programmed in a Lisp environment, with a very advanced user and developer's interface and quite a few interesting innovations in software design (levels of analysis CF grammars, external specification and internal organization of dictionaries). DUET-II made it possible for experienced users to control the style of the output to a certain extent. A remarkable point is that commercial success was achieved only when users were allowed to become co-developers. The"
1995.mtsummit-1.7,C86-1150,0,0.0309664,"technical decisions: SG2 implemented the revisor's workbench on an expensive and specific equipment (Questar 400) instead of going for PCs. - no sufficient duration: as ADI was disbanded by the conservative government in late 1986, the last year of the project was not obtained. This is in sharp contrast with the Japanese MU project [21], who was excellently organized under the direction of Pr. Nagao at Kyoto University, got a secure funding for full 4 years, and included at least 15 companies (instead of giving a monopoly to one as in France). Note the existence of a French-Malaysian project [20] during the same period, which, using a minimal amount of funding, successfully produced a large-scale laboratory prototype in 1985-86. This clearly shows the critical importance of non-scientific and non-technical factors. Eurotra was officially launched in December 1982 after several years of preparation [12]. Many things have already been said about that project. Although there were some conceptual successes, notably experimental studies of linguistic phenomena across European languages, it was quite a failure on engineering, operational and communicative levels. There are several reasons f"
1995.mtsummit-1.7,C86-1155,0,0.0327016,"ncial situation, instead of CAP-Sogeti, with which a pilot project had just been conducted. - inadequate financing: funding amounted to only about 25 man-years, was to be negotiated year by year or even phase by phase, and came always with considerable delay. - bad technical decisions: SG2 implemented the revisor's workbench on an expensive and specific equipment (Questar 400) instead of going for PCs. - no sufficient duration: as ADI was disbanded by the conservative government in late 1986, the last year of the project was not obtained. This is in sharp contrast with the Japanese MU project [21], who was excellently organized under the direction of Pr. Nagao at Kyoto University, got a secure funding for full 4 years, and included at least 15 companies (instead of giving a monopoly to one as in France). Note the existence of a French-Malaysian project [20] during the same period, which, using a minimal amount of funding, successfully produced a large-scale laboratory prototype in 1985-86. This clearly shows the critical importance of non-scientific and non-technical factors. Eurotra was officially launched in December 1982 after several years of preparation [12]. Many things have alre"
1995.mtsummit-1.7,C86-1077,0,0.050123,"Missing"
1995.mtsummit-1.7,C88-2155,0,0.0194456,"specialists of the system and language(s). All other systems or prototypes are intended for authors. TITUS [31], used operationally for many years at the Textile Institute of France, relied on a controlled language and interactive input. The DLT project [41] gave rise to interesting demonstrators and publications. It is quite surprising that the management of BSO, an industrial firm, has allowed researchers to embark on a completely different paradigm (EBMT) in 1988, instead of starting an experimental phase and trying to put the system in use. R&D there has been abandoned around 1992. N-Tran [34] was an Alvey project. The basic idea of writing in Japanese without knowing it was extremely interesting, but not enough attention was paid to the intended users: implementation was done on workstations, and dialogues were both modal (the user is under the control of the system and must answer) and used specialized linguistic terminology. ITS-2 and LIDIA are also research products, and try to show how to build disambiguation dialogues understandable by general users. Much more development is needed before operational use can be envisaged. Ambassador™, available in English-Japanese, English-Fr"
1995.mtsummit-1.7,1989.mtsummit-1.18,0,0.123833,"Missing"
1995.mtsummit-1.7,C90-3008,0,0.0549588,"Missing"
1995.mtsummit-1.7,C90-3074,0,0.0572524,"Missing"
1995.mtsummit-1.7,C90-2045,0,0.0287739,"ts: the number of words per sentence must be less than 10-12, and the correspondence between words can only be 1→n (n≤3?), but not m—>n (m, n>l). This “NLP without linguistics” approach seems to have been abandoned8 in favor of an approach mixing symbolic and stochastic techniques. - Example-Based MT (EBMT), based on “analogies” between aligned translations, seems a much more promising approach, or class of approaches, pioneered essentially in Japan, at Kyoto & Nara universities (Nagao), IBM and ATR [59]. They are usually integrated in a classical LBMT design. For instance, JETS at IBM-Japan) [48] uses subtree pairs only at transfer time. Although there remain several problems, success has been clearly achieved at the conceptual and engineering levels. - Knowledge-Based MT (KBMT) has finally been demonstrated to be possible by CMU with the KBMT-89 prototype [38, 43]. The KANT industrial system [52] has also shown the potential and limits of this approach: the translations are very good, but the language is controlled interactively at input time to fit into a small sublanguage, and the creation of the “ontology” (formal description of the domain) is more costly than that of the linguist"
1995.mtsummit-1.7,C90-3048,0,0.0393798,"Missing"
1995.mtsummit-1.7,1991.mtsummit-papers.12,0,0.0451658,"vice. This is happening in Japan, but not only there. Networking has actually been pioneered by Systran SA on the French minitel since around 1980. Access to Japanese data bases from Europe using commercial MT systems has followed a few years later [28]. Since around 1990, JICST (Tokyo) is also offering access to its data base of Japanese and English abstract data base in both languages through the MAJESTIC system. This last operation is not as cost effective as it could be because, at least in our opinion, too much revision is done on the machine output (see I.2.4 below). Toshiba (AS-Transac [50]) was the first firm to offer MT on a small hardware, around 1983. Since then many Japanese companies have offered MT on portable workstations with optional OCR input, first on proprietary architectures, then on Unix-based architectures, and for some of them on PCs. Workstation-based systems are almost always presented as good for watchers (J-E) as well as for revisors (E-J), while PC-based systems seem to be used almost only for MT-W, or as a kind of extended dictionary help for personal translation into a foreign language. Until now, sales of workstation-based systems did not reach expectati"
1995.mtsummit-1.7,C92-4198,0,0.0258766,"Missing"
1995.mtsummit-1.7,C92-3168,0,0.0299926,"), based on “analogies” between aligned translations, seems a much more promising approach, or class of approaches, pioneered essentially in Japan, at Kyoto & Nara universities (Nagao), IBM and ATR [59]. They are usually integrated in a classical LBMT design. For instance, JETS at IBM-Japan) [48] uses subtree pairs only at transfer time. Although there remain several problems, success has been clearly achieved at the conceptual and engineering levels. - Knowledge-Based MT (KBMT) has finally been demonstrated to be possible by CMU with the KBMT-89 prototype [38, 43]. The KANT industrial system [52] has also shown the potential and limits of this approach: the translations are very good, but the language is controlled interactively at input time to fit into a small sublanguage, and the creation of the “ontology” (formal description of the domain) is more costly than that of the linguistic knowledge base, based on an interlingua. The linguistic knowledge base itself is in turn costlier than that of less ambitious semantic transfer systems. Although this is clearly a conceptual success, it is not yet clear whether it will be judged as operationally and commercially successful. The conclusi"
1995.mtsummit-1.7,C92-3129,0,0.0605883,"Missing"
1995.mtsummit-1.7,C94-1015,0,0.0296396,"to those on Systran, not developed for that kind of corpus. Also, there are combinatorial limits: the number of words per sentence must be less than 10-12, and the correspondence between words can only be 1→n (n≤3?), but not m—>n (m, n>l). This “NLP without linguistics” approach seems to have been abandoned8 in favor of an approach mixing symbolic and stochastic techniques. - Example-Based MT (EBMT), based on “analogies” between aligned translations, seems a much more promising approach, or class of approaches, pioneered essentially in Japan, at Kyoto & Nara universities (Nagao), IBM and ATR [59]. They are usually integrated in a classical LBMT design. For instance, JETS at IBM-Japan) [48] uses subtree pairs only at transfer time. Although there remain several problems, success has been clearly achieved at the conceptual and engineering levels. - Knowledge-Based MT (KBMT) has finally been demonstrated to be possible by CMU with the KBMT-89 prototype [38, 43]. The KANT industrial system [52] has also shown the potential and limits of this approach: the translations are very good, but the language is controlled interactively at input time to fit into a small sublanguage, and the creatio"
1999.mtsummit-1.19,C92-4198,0,0.0402331,"Missing"
1999.mtsummit-1.19,C94-1017,0,0.0581443,"Missing"
1999.mtsummit-1.19,1994.bcs-1.22,1,0.868513,"Missing"
1999.mtsummit-1.19,C86-1100,0,0.0465716,"a of multi-application MLDB has been stressed by most recent projects on multilingual dictionaries. However, it has been implemented only partially. MToriented MLDB have been built to be independent of a particular MT system4, but no MLDB integrating the terms and informations necessary for MT (general terms as well as terminology, morpho-syntactic categories, predicative frames, syntactico-semantic valencies, semantic features, derivations, word sense identifiers...) and those useful for TA (definitions, examples of use...). Building such data bases supposes a very open software organization [11, 30], which is delicate but possible to implement with current techniques. Another reason why they do not really exist yet is perhaps that they could only be built in contexts where TA and MT techniques would be tightly integrated, as in the above scenario. Note again that, for such a scenario to succeed, the MT provider should adopt an open, not proprietary, policy. If that is impossible for private companies, publicly funded MT groups should play that role. 3 Interaction with authors in a SAFQMT approach 3.1 Limits of automatic disambiguation One very important aspect of quality MT democratizati"
1999.mtsummit-1.19,C96-1022,1,0.858031,"Missing"
1999.mtsummit-1.19,C90-3008,0,0.0209636,"Missing"
1999.mtsummit-1.19,C90-3074,0,0.0729864,"Missing"
1999.mtsummit-1.19,C86-1155,0,0.112983,"Missing"
1999.mtsummit-1.19,C90-2045,0,0.0535206,"Missing"
1999.mtsummit-1.19,C82-1034,0,0.235415,"Missing"
1999.mtsummit-1.19,C80-1064,0,0.0683668,"Missing"
1999.mtsummit-1.19,C92-3168,0,0.159745,"Missing"
1999.mtsummit-1.19,C94-1044,0,0.0747145,"a of multi-application MLDB has been stressed by most recent projects on multilingual dictionaries. However, it has been implemented only partially. MToriented MLDB have been built to be independent of a particular MT system4, but no MLDB integrating the terms and informations necessary for MT (general terms as well as terminology, morpho-syntactic categories, predicative frames, syntactico-semantic valencies, semantic features, derivations, word sense identifiers...) and those useful for TA (definitions, examples of use...). Building such data bases supposes a very open software organization [11, 30], which is delicate but possible to implement with current techniques. Another reason why they do not really exist yet is perhaps that they could only be built in contexts where TA and MT techniques would be tightly integrated, as in the above scenario. Note again that, for such a scenario to succeed, the MT provider should adopt an open, not proprietary, policy. If that is impossible for private companies, publicly funded MT groups should play that role. 3 Interaction with authors in a SAFQMT approach 3.1 Limits of automatic disambiguation One very important aspect of quality MT democratizati"
1999.mtsummit-1.19,C90-3048,0,0.0346647,"Missing"
1999.mtsummit-1.19,C86-1150,0,0.0956695,"Missing"
1999.mtsummit-1.19,1987.mtsummit-1.23,0,0.0688361,"Missing"
1999.mtsummit-1.19,1989.mtsummit-1.5,0,0.0422272,"Missing"
1999.mtsummit-1.19,J85-1003,1,0.732445,"Missing"
1999.mtsummit-1.19,C92-3129,0,0.137049,"Missing"
1999.mtsummit-1.19,C86-1077,0,0.136759,"Missing"
1999.mtsummit-1.19,C88-2155,0,0.0894467,"Missing"
1999.mtsummit-1.19,C86-1030,0,0.332715,"Missing"
1999.mtsummit-1.33,C94-1017,0,0.103656,"Multilevel Concrete (UMC) structure. By concrete, we mean that the structure is projective, hence the corresponding French text may be obtained by a standard left to right traversal of the leaves and simple morphological and graphemic rules. The result of these phases is a surface French utterance. - 224- 3.1 On-line interaction in the current French deconverter 3.1.1 Rationale Person-system interaction in MT systems has almost exclusively been used for disambiguation, during controlled input (as in [9, 15]), during analysis (on-line mode, as in [10, 12, 18]) or after it (off-line mode, as in [2, 6, 8, 11, 14]). This is because it is felt that, if the intermediate structure produced after analysis or transfer is perfect, a state of the art generator can produce high quality output purely automatically. In the UNL framework, however, nothing is known about the quality of the input UNL graph, which may have been produced automatically, manually, or interactively. Moreover, some precisions necessary for the target language (sex, aspect, modality, determination...) may not be relevant in the source language and not have been put in the UNL graph. Finally, although there is a central knowledge base (KB)"
1999.mtsummit-1.33,1994.bcs-1.22,1,0.829591,"} is defined as a set of directed labelled arcs. We use an association list 3 strictly speaking, the same collection of interlingual word senses (acceptions). fully automatic high quality deconversion. -223- MT Summit VII ________________________________________________________________Sept. 1999 , where we memorize the correspondence between nodes of the tree and nodes of the graph. 2.2.5 Structural transfer 3 Improving deconversion quality by human interaction The purpose of the structural transfer is to transform the tree obtained so far into a Generating Multilevel Abstract (GMA) structure [4]. In this structure, non-interlingual linguistic levels (syntactic functions, syntagmatic categories...) are underspecified, and (if present), are used only as a set of hints for the generation stage. 2.3 Generation 2.3.1 Paraphrase choice The next phase is in charge of the paraphrase choice. During this phase, decisions are taken regarding the derivation applied to each lexical unit in order to obtain the correct syntagmatic category for each node. During this phase, the order of appearance and the syntactic functions of each parts of the utterance is also decided The resulting structure is c"
1999.mtsummit-1.33,C80-1064,0,0.25304,"c. The role of this phase is to create a Unique Multilevel Concrete (UMC) structure. By concrete, we mean that the structure is projective, hence the corresponding French text may be obtained by a standard left to right traversal of the leaves and simple morphological and graphemic rules. The result of these phases is a surface French utterance. - 224- 3.1 On-line interaction in the current French deconverter 3.1.1 Rationale Person-system interaction in MT systems has almost exclusively been used for disambiguation, during controlled input (as in [9, 15]), during analysis (on-line mode, as in [10, 12, 18]) or after it (off-line mode, as in [2, 6, 8, 11, 14]). This is because it is felt that, if the intermediate structure produced after analysis or transfer is perfect, a state of the art generator can produce high quality output purely automatically. In the UNL framework, however, nothing is known about the quality of the input UNL graph, which may have been produced automatically, manually, or interactively. Moreover, some precisions necessary for the target language (sex, aspect, modality, determination...) may not be relevant in the source language and not have been put in the UNL graph. Fin"
1999.mtsummit-1.33,C92-3168,0,0.0560624,", and non connex compounds such as ne...pas, etc. The role of this phase is to create a Unique Multilevel Concrete (UMC) structure. By concrete, we mean that the structure is projective, hence the corresponding French text may be obtained by a standard left to right traversal of the leaves and simple morphological and graphemic rules. The result of these phases is a surface French utterance. - 224- 3.1 On-line interaction in the current French deconverter 3.1.1 Rationale Person-system interaction in MT systems has almost exclusively been used for disambiguation, during controlled input (as in [9, 15]), during analysis (on-line mode, as in [10, 12, 18]) or after it (off-line mode, as in [2, 6, 8, 11, 14]). This is because it is felt that, if the intermediate structure produced after analysis or transfer is perfect, a state of the art generator can produce high quality output purely automatically. In the UNL framework, however, nothing is known about the quality of the input UNL graph, which may have been produced automatically, manually, or interactively. Moreover, some precisions necessary for the target language (sex, aspect, modality, determination...) may not be relevant in the source"
1999.mtsummit-1.33,C92-3129,0,0.169734,"c. The role of this phase is to create a Unique Multilevel Concrete (UMC) structure. By concrete, we mean that the structure is projective, hence the corresponding French text may be obtained by a standard left to right traversal of the leaves and simple morphological and graphemic rules. The result of these phases is a surface French utterance. - 224- 3.1 On-line interaction in the current French deconverter 3.1.1 Rationale Person-system interaction in MT systems has almost exclusively been used for disambiguation, during controlled input (as in [9, 15]), during analysis (on-line mode, as in [10, 12, 18]) or after it (off-line mode, as in [2, 6, 8, 11, 14]). This is because it is felt that, if the intermediate structure produced after analysis or transfer is perfect, a state of the art generator can produce high quality output purely automatically. In the UNL framework, however, nothing is known about the quality of the input UNL graph, which may have been produced automatically, manually, or interactively. Moreover, some precisions necessary for the target language (sex, aspect, modality, determination...) may not be relevant in the source language and not have been put in the UNL graph. Fin"
2001.mtsummit-road.1,1994.bcs-1.22,1,0.814272,"Missing"
2001.mtsummit-road.1,C92-3168,0,0.0956924,"Missing"
2001.mtsummit-road.1,1999.mtsummit-1.33,1,0.929115,"Missing"
2001.mtsummit-road.1,1999.mtsummit-1.34,0,0.0430411,"Missing"
2001.mtsummit-road.1,C92-3129,0,0.0184123,"maintenance, and evolution prices, and through consideration of the human time needed to obtain a professional result. I have proposed elsewhere the formula &quot;Quality x Coverage = Constant&quot;, with the constant depending on the particular system. To augment the translation quality, then, there are three combinable ways: • specialize to a sublanguage (domain, grammar; this is known as the &quot;suboptimization approach&quot; (Lehrberger & al., 1988)), • involve the user on the source side (using controlled language as in KANT-CATALYST (Nyberg & al., 1992), or interactive disambiguation (Boitet & al., 1994, Wehrli, 1992)), • improve the overall approach, e.g. by introducing more abstract linguistic levels (functional, relational, logical, etc.), more &quot;felicitous&quot; data structures (decorated trees, typed feature structures, charts, hypergraphs, etc.), non-determinism, scoring, etc. As the needs are real, in particular for technical 1—>N translations, there is still some activity in the quality translation field, but far less than was hoped ten years ago. Technically, these systems almost always have a separate analysis component, producing a syntactic or syntactico-semantic descriptor of the source UT (usually"
2001.mtsummit-road.1,J85-2003,0,\N,Missing
2001.mtsummit-road.1,C00-2111,1,\N,Missing
2001.mtsummit-road.1,1999.mtsummit-1.19,1,\N,Missing
2002.jeptalnrecital-long.25,C00-1013,0,0.054646,"Missing"
2002.jeptalnrecital-long.25,C88-1013,0,0.0510683,"lication. On peut aussi tirer parti du fait qu'on a une structure de plus en l'enrichissant avec des unités lexicales de L0. La correspondance est maintenant divisée en 3 parties : • texte-L0 ↔ MS-L0 (une treille ou une carte), • MS-L0 ↔ arbre-UNL+L0 (un arbre abstrait non ordonné proche d'un arbre de dépendance), et • arbre-UNL+L0 ↔ graphe-UNL (les liaisons peuvent être produites en modifiant la transformation réversible standard graphe→arbre). Un autre avantage de l'introduction de cette structure d'arbre est que les correspondances entre les chaînes et les arbres ont été beaucoup étudiées (Boitet & Zaharin 1988, Vauquois & Chappuy 1985, Zaharin 1986). Elles peuvent être encodées par deux attributs exprimant ce qu'un nœud couvre lexicalement (SNODE) et syntagmatiquement, en tant que racine d'un sous-arbre (STREE). 3 État d'avancement et recherches voisines 3.1 Plate-forme expérimentale Nous avons implémenté un site web appelé SWIIVRE-UNL (Site Web pour l'Initiation, l'Information, la Validation, la Recherche et l'Expérimentation sur UNL (Tsai 2001)) pour servir de base expérimentale à notre recherche. Il permet pour l'instant : • d'obtenir de l'information dynamique sur les sites de déconversion UNL"
2002.jeptalnrecital-long.25,1999.mtsummit-1.19,1,0.929929,"lors d'une étape précédente. L'approche la meilleure et la plus simple nous semble être d'utiliser un interlingua formel IL et : • de répercuter les modifications de L0 vers l'IL, • de regénérer vers L1,… Ln depuis l'IL. Il faudra cependant permettre des améliorations manuelles, car la forme interlingue ne sera pas toujours présente, ou pas assez améliorable par défaut d'expressivité, et les générateurs ne seront jamais parfaits. La cooédition langue↔UNL pour partager la révision entre les langues d'un document multilingue Nous choisissons UNL (Blanc 2001, Boguslavsky, et al. 2000, Sérasset & Boitet 1999, 2000) comme interlingua pour différentes raisons : (1) il est spécialement conçu pour le traitement linguistique et sémantique par ordinateur, (2) il a été dérivé avec beaucoup d'améliorations du langage pivot de H. Uchida utilisé dans ATLAS-II de Fujitsu (Uchida 1989), toujours évalué comme le système de TA anglais-japonais de meilleure qualité, avec une très grande couverture (586.000 entrées par langue), (3) les participants du projet UNL1 ont construit des &quot;déconvertisseurs&quot; d'UNL vers environ 12 langues, parmi lesquels au moins ceux allant vers l'arabe, l'indonésien, l'italien, le franç"
2002.jeptalnrecital-long.25,1999.mtsummit-1.33,1,0.901387,"nuellement lors d'une étape précédente. L'approche la meilleure et la plus simple nous semble être d'utiliser un interlingua formel IL et : • de répercuter les modifications de L0 vers l'IL, • de regénérer vers L1,… Ln depuis l'IL. Il faudra cependant permettre des améliorations manuelles, car la forme interlingue ne sera pas toujours présente, ou pas assez améliorable par défaut d'expressivité, et les générateurs ne seront jamais parfaits. La cooédition langue↔UNL pour partager la révision entre les langues d'un document multilingue Nous choisissons UNL (Blanc 2001, Boguslavsky, et al. 2000, Sérasset & Boitet 1999, 2000) comme interlingua pour différentes raisons : (1) il est spécialement conçu pour le traitement linguistique et sémantique par ordinateur, (2) il a été dérivé avec beaucoup d'améliorations du langage pivot de H. Uchida utilisé dans ATLAS-II de Fujitsu (Uchida 1989), toujours évalué comme le système de TA anglais-japonais de meilleure qualité, avec une très grande couverture (586.000 entrées par langue), (3) les participants du projet UNL1 ont construit des &quot;déconvertisseurs&quot; d'UNL vers environ 12 langues, parmi lesquels au moins ceux allant vers l'arabe, l'indonésien, l'italien, le franç"
2002.jeptalnrecital-long.25,1985.tmi-1.20,0,0.0886269,"tirer parti du fait qu'on a une structure de plus en l'enrichissant avec des unités lexicales de L0. La correspondance est maintenant divisée en 3 parties : • texte-L0 ↔ MS-L0 (une treille ou une carte), • MS-L0 ↔ arbre-UNL+L0 (un arbre abstrait non ordonné proche d'un arbre de dépendance), et • arbre-UNL+L0 ↔ graphe-UNL (les liaisons peuvent être produites en modifiant la transformation réversible standard graphe→arbre). Un autre avantage de l'introduction de cette structure d'arbre est que les correspondances entre les chaînes et les arbres ont été beaucoup étudiées (Boitet & Zaharin 1988, Vauquois & Chappuy 1985, Zaharin 1986). Elles peuvent être encodées par deux attributs exprimant ce qu'un nœud couvre lexicalement (SNODE) et syntagmatiquement, en tant que racine d'un sous-arbre (STREE). 3 État d'avancement et recherches voisines 3.1 Plate-forme expérimentale Nous avons implémenté un site web appelé SWIIVRE-UNL (Site Web pour l'Initiation, l'Information, la Validation, la Recherche et l'Expérimentation sur UNL (Tsai 2001)) pour servir de base expérimentale à notre recherche. Il permet pour l'instant : • d'obtenir de l'information dynamique sur les sites de déconversion UNL disponibles, • d'accéder"
2002.jeptalnrecital-long.25,C86-1030,0,0.0273889,"n a une structure de plus en l'enrichissant avec des unités lexicales de L0. La correspondance est maintenant divisée en 3 parties : • texte-L0 ↔ MS-L0 (une treille ou une carte), • MS-L0 ↔ arbre-UNL+L0 (un arbre abstrait non ordonné proche d'un arbre de dépendance), et • arbre-UNL+L0 ↔ graphe-UNL (les liaisons peuvent être produites en modifiant la transformation réversible standard graphe→arbre). Un autre avantage de l'introduction de cette structure d'arbre est que les correspondances entre les chaînes et les arbres ont été beaucoup étudiées (Boitet & Zaharin 1988, Vauquois & Chappuy 1985, Zaharin 1986). Elles peuvent être encodées par deux attributs exprimant ce qu'un nœud couvre lexicalement (SNODE) et syntagmatiquement, en tant que racine d'un sous-arbre (STREE). 3 État d'avancement et recherches voisines 3.1 Plate-forme expérimentale Nous avons implémenté un site web appelé SWIIVRE-UNL (Site Web pour l'Initiation, l'Information, la Validation, la Recherche et l'Expérimentation sur UNL (Tsai 2001)) pour servir de base expérimentale à notre recherche. Il permet pour l'instant : • d'obtenir de l'information dynamique sur les sites de déconversion UNL disponibles, • d'accéder à une collectio"
2003.mtsummit-papers.45,2001.mtsummit-papers.56,1,0.732828,"Missing"
2003.mtsummit-papers.45,2001.mtsummit-papers.39,0,\N,Missing
2004.iwslt-evaluation.3,2002.jeptalnrecital-long.26,0,0.0377017,"Missing"
2004.iwslt-evaluation.3,takezawa-etal-2002-toward,0,0.0582757,"Missing"
2004.iwslt-evaluation.3,W03-2804,0,0.0423251,"Missing"
2004.iwslt-evaluation.3,W03-2800,0,0.178329,"Missing"
2004.iwslt-evaluation.3,2003.mtsummit-papers.51,0,0.0873221,"Missing"
2004.iwslt-evaluation.3,2003.mtsummit-papers.32,0,0.0823767,"Missing"
2004.iwslt-papers.1,P04-1077,0,0.0797235,"italized and unknown words, polite and direct forms of address (please … / I would like you to…). between the translation produced by the system and a gold translation associated with a set of paraphrases. We can also cite the GMT [24] score which is the harmonic mean (F-measure) of a new proposed precision and recall measures based on a maximum match size between a candidate and a reference translation. Recently, the R O U G E (Recall-Oriented Understudy for Gisting Evaluation) [12] framework, proposed t o automatically determine the quality of summaries, has also been used for MT evaluation [13]. The same authors also proposed O RANGE (Oracle Ranking for Gisting Evaluation), for evaluating evaluation metrics for machine translation [14]. 4.2.2. For the primary condition, there is an inconsistent ranking for system 5 with BLEU (3rd) and NIST (5th). This system outputs are significantly shorter than the output of the other systems. It impact strongly on the results with a brevity penalty for NIST. A fourth parameter came to us when checking the actual strings produced by the each system. We found different use of case (“Tokyo”, vs. “tokyo”), punctuation (“juice, please” vs. “juice plea"
2004.iwslt-papers.1,C04-1072,0,0.133457,"and a gold translation associated with a set of paraphrases. We can also cite the GMT [24] score which is the harmonic mean (F-measure) of a new proposed precision and recall measures based on a maximum match size between a candidate and a reference translation. Recently, the R O U G E (Recall-Oriented Understudy for Gisting Evaluation) [12] framework, proposed t o automatically determine the quality of summaries, has also been used for MT evaluation [13]. The same authors also proposed O RANGE (Oracle Ranking for Gisting Evaluation), for evaluating evaluation metrics for machine translation [14]. 4.2.2. For the primary condition, there is an inconsistent ranking for system 5 with BLEU (3rd) and NIST (5th). This system outputs are significantly shorter than the output of the other systems. It impact strongly on the results with a brevity penalty for NIST. A fourth parameter came to us when checking the actual strings produced by the each system. We found different use of case (“Tokyo”, vs. “tokyo”), punctuation (“juice, please” vs. “juice please”), digits (spelled-out vs. numerals), abbreviations (“OK” vs. “okay”), compound words (“duty-free” vs. “duty free”), sentence boundaries, and"
2004.iwslt-papers.1,N03-2021,0,0.0529929,"Missing"
2004.iwslt-papers.1,niessen-etal-2000-evaluation,0,0.0927176,"Missing"
2004.iwslt-papers.1,C92-2067,0,0.11536,"Missing"
2004.iwslt-papers.1,takezawa-etal-2002-toward,0,0.0345848,"racters. The MT outputs and the references translation were normalized. We observed differences of ±0.15 on the BLEU scores and ±1.8 on the NIST scores. Those differences are quite important. In the future, system outputs and references will be normalized for common evaluation. Under the secondary condition, the ranking is still inconsistent with BLEU and NIST. For both conditions, C-STAR III systems outperformed Systran systems available free of charge on the web. 4.2. A new evaluation framework from C-STAR III Nonetheless, we would like to promote comparative evaluation on the same data set [22] in the C - STAR III framework. This would enable us to tackle some of the questions raised above. 4.2.1. Pilot closed evaluation (2002) The C-STAR III partners ran a pilot evaluation experiment in year 2003 on our common BTEC corpus for two conditions. Development and test data were picked up for BTEC. For development purposes every kind of resources could be used. The test set consisted of 500 English sentences that had their translation into Italian, Japanese, Korean and Chinese within BTEC. Subjective evaluation followed the L inguistic D ata C onsortium evaluation guidelines for the DARPA"
2004.iwslt-papers.1,2003.mtsummit-papers.51,0,0.061178,"lian. This is mainly due to the characteristics of the 98 4/8 Free Systran® MT systems available on the web have been evaluated on the same test set. All systems scores were inferior to those of the C-STAR partners. However, nothing was done to tune them to that particular task, although that is possible on systranet: choice and order of dictionaries, handling of capitalized and unknown words, polite and direct forms of address (please … / I would like you to…). between the translation produced by the system and a gold translation associated with a set of paraphrases. We can also cite the GMT [24] score which is the harmonic mean (F-measure) of a new proposed precision and recall measures based on a maximum match size between a candidate and a reference translation. Recently, the R O U G E (Recall-Oriented Understudy for Gisting Evaluation) [12] framework, proposed t o automatically determine the quality of summaries, has also been used for MT evaluation [13]. The same authors also proposed O RANGE (Oracle Ranking for Gisting Evaluation), for evaluating evaluation metrics for machine translation [14]. 4.2.2. For the primary condition, there is an inconsistent ranking for system 5 with"
2004.iwslt-papers.1,2001.mtsummit-papers.3,0,0.0226989,"Missing"
2004.iwslt-papers.1,2003.mtsummit-papers.9,0,0.013347,"S4 2,59 (5) 2,30 (5) 0,2733 (5) 5,6830 (4) S5 3,21 (3) 3,74 (3) 0,5542 (3) 3,4013 (5) 4.2.3. 4.3. Problems and proposals 4.3.1. NIST [0..∞[ 0.5542 (1) 3.4013 (3) S2 0,3884 (2) 8.1383 (1) S3 0.2733 (3) 5.6830 (2) Table 9: results of the C-STAR III pilot evaluation under the secondary condition 1 Problems 4.3.1.1 Current metrics don&apos;t measure linguistic quality A first problem is that the figures produced with these techniques are not directly interpretable in terms of translation quality2. A lot of work has been done t o correlate objective evaluation results with subjective evaluation results [6, 7, 19], but the results are inconsistent. BLEU is said to correlate well with human judgments of quality, NIST is said to be better than BLEU for theoretical reasons, but BLEU and NIST give contradictory rankings (see above). Hence, if correlation with human judgments is a measure of the quality of a metrics, NIST cannot be better than BLEU… or the correlation is too weak to be meaningful. Another trouble is that, as reported in ACL-03, these metrics often give quite bad scores to high quality human translations. An experiment has been reported, where each of 15 (human) paraphrases had been tested,"
2004.iwslt-papers.1,2003.mtsummit-papers.32,0,0.207577,"Missing"
2004.iwslt-papers.1,W04-1013,0,0.0121128,"m to that particular task, although that is possible on systranet: choice and order of dictionaries, handling of capitalized and unknown words, polite and direct forms of address (please … / I would like you to…). between the translation produced by the system and a gold translation associated with a set of paraphrases. We can also cite the GMT [24] score which is the harmonic mean (F-measure) of a new proposed precision and recall measures based on a maximum match size between a candidate and a reference translation. Recently, the R O U G E (Recall-Oriented Understudy for Gisting Evaluation) [12] framework, proposed t o automatically determine the quality of summaries, has also been used for MT evaluation [13]. The same authors also proposed O RANGE (Oracle Ranking for Gisting Evaluation), for evaluating evaluation metrics for machine translation [14]. 4.2.2. For the primary condition, there is an inconsistent ranking for system 5 with BLEU (3rd) and NIST (5th). This system outputs are significantly shorter than the output of the other systems. It impact strongly on the results with a brevity penalty for NIST. A fourth parameter came to us when checking the actual strings produced by"
2004.iwslt-papers.1,P02-1040,0,\N,Missing
2004.iwslt-papers.5,W02-1602,1,0.887563,"Missing"
2004.jeptalnrecital-long.11,1994.bcs-1.22,1,0.778889,"Missing"
2006.iwslt-evaluation.3,2004.iwslt-papers.1,1,0.892477,"Missing"
2006.iwslt-evaluation.3,2003.mtsummit-papers.32,0,0.0610239,"Missing"
2006.iwslt-evaluation.3,takezawa-etal-2002-toward,0,0.0825889,"Missing"
2006.iwslt-evaluation.3,W03-2804,0,0.0573321,"Missing"
2006.iwslt-evaluation.3,2003.mtsummit-papers.51,0,0.0787107,"Missing"
2006.iwslt-evaluation.3,E06-1032,0,\N,Missing
2007.jeptalnrecital-long.12,H94-1026,0,0.0224189,"Missing"
2008.jeptalnrecital-long.24,J85-1003,1,0.61372,"Missing"
2009.mtsummit-btm.3,huynh-etal-2008-sectra,1,0.837123,"Missing"
2009.mtsummit-btm.3,2003.mtsummit-papers.30,0,0.0882,"Missing"
2009.mtsummit-btm.3,2005.mtsummit-papers.11,0,0.0177828,"Missing"
2009.mtsummit-btm.3,2009.jeptalnrecital-recital.6,0,0.0951026,"Missing"
2009.mtsummit-btm.3,takezawa-etal-2002-toward,0,0.0398942,"Missing"
2010.jeptalnrecital-court.7,W09-3536,1,0.859817,"Missing"
2010.jeptalnrecital-court.7,C08-1068,1,0.872671,"Missing"
2011.jeptalnrecital-court.39,2007.mtsummit-papers.24,0,0.114143,"Missing"
2011.jeptalnrecital-court.39,W01-1413,0,0.104381,"Missing"
2011.tc-1.10,huynh-etal-2008-sectra,1,0.892695,"Missing"
2013.mtsummit-wptp.12,P02-1040,0,0.128479,"Missing"
2013.mtsummit-wptp.12,P07-2045,0,0.00548221,"dicated to an elected website S, or rather to the sublanguage empirically defined by the textual content of one or more URLs constituting S. The iMAG-S contains a translation memory (TM) and if possible a specific, pre-terminological dictionary (pTD) (Daoud et al., 2009), both dedicated to the elected sublanguage. Segments are pre-translated not by a unique MT system, but by a (selectable) set of MT systems. Systran, Reverso and Google Translate have been mainly used as well as Neon for Chinese-English, but specialized systems developed from the post-edited part of the TM, and based on Moses (Koehn et al., 2007), are also used in our gateway. The online contributive platforms SECTra_w (Huynh et al., 2008) and PIVAX (Nguyen et al., 2007) are used to support the TMs and pTDs. Translated pages are built with the best segment translations available so far. While reading a translated page, it is possible not only to directly post-edit the segment under the cursor, but also to seamlessly switch to SECTra_w online postediting (PE) environment, equipped with filtering and search-and-replace functions, and then to go back to the reading context. To illustrate our points, we will use an iMAG created for the we"
2020.jeptalnrecital-demos.1,C12-1046,1,0.793764,"Missing"
2020.jeptalnrecital-demos.1,2012.amta-papers.5,1,0.854719,"Missing"
2020.jeptalnrecital-demos.1,W08-1003,0,0.0930352,"Missing"
C00-2111,C94-1017,0,0.261981,"Missing"
C00-2111,1994.bcs-1.22,1,0.943229,"Missing"
C00-2111,C90-2045,0,0.27642,"Missing"
C00-2111,C80-1064,0,0.489987,"Missing"
C00-2111,C92-3168,0,0.31107,"Missing"
C00-2111,C92-3129,0,0.593923,"Missing"
C00-2111,C82-1004,0,\N,Missing
C08-1068,W98-1005,0,0.342414,"ose languages. We introduce UIT (universal intermediate transcription) for the same pair on the basis of their common phonetic repository in such a way that it can be extended to other languages like Arabic, Chinese, English, French, etc. We describe a transliteration model based on FST and UIT, and evaluate it on Hindi and Urdu corpora. 1 Introduction Transliteration is mainly used to transcribe a word written in one language in the writing system of the other language, thereby keeping an approximate phonetic equivalence. It is useful for MT (to create possible equivalents of unknown words) (Knight and Stall, 1998; Paola and Sanjeev, 2003), cross-lingual information retrieval (Pirkola et al, 2003), the development of multilingual resources (Yan et al, 2003) and multilingual text and speech processing. Inter-dialectal translation without lexical changes is quite useful and sometimes even necessary when the dialects in question use different scripts; it can be achieved by transliteration alone. That is the case of HUMT (Hindi-Urdu Machine Transliteration) where each word has to be transliterated from Hindi to Urdu and vice versa, irrespective of its © 2008. Licensed under the Creative Commons Attribution"
C08-1068,P06-1143,0,0.0126056,"Conference on Computational Linguistics (Coling 2008), pages 537–544 Manchester, August 2008 2 HUMT 3 There exist three languages at the border between India and Pakistan: Kashmiri, Punjabi and Sindhi. All of them are mainly written in two scripts, one being a derivation of the Persio-Arabic script and the other being Devanagari script. A person using the Persio-Arabic script cannot understand the Devanagari script and vice versa. The same is true for Hindi and Urdu which are varieties or dialects of the same language, called Hindustani by Platts (1909). PMT (Punjabi Machine Transliteration) (Malik, 2006) was a first effort to bridge this scriptural divide between the two scripts of Punjabi namely Shahmukhi (a derivation of Perio-Arabic script) and Gurmukhi (a derivation of Landa, Shardha and Takri, old Indian scripts). HUMT is a logical extension of PMT. Our HUMT system is generic and flexible such that it will be extendable to handle similar cases like Kashmiri, Punjabi, Sindhi, etc. HUMT is also a special type of machine transliteration like PMT. A brief account of Hindi and Urdu is first given for unacquainted readers. 2.1 Hindi The Devanagari (literally “godly urban”) script, a simplified"
C08-1068,W04-1613,0,0.115926,"هh] = [ ﮐﻬkʰ], [ بb] + [ هh] = ﺑﻬ [bʰ], [ لl] + [ هh] = [ ﻟﻬlʰ], etc. The UIT mapping for aspirated consonants is given in Table 2. Xì y6[6Ei ÌòâF¯ ÌÐ y636G6[6 zEegEZ [ʊrḓu pɑkɪstɑn ki qɔmi zubɑn hæ] (Urdu is the National Language of Pakistan.) 538 Hindi भ [ ﺑﻬbʰ] Urdu UIT b_h Hindi हर [ رهrʰ] Urdu UIT r_h फ [ ﭘﻬpʰ] p_h ढ़ [ ڑهɽʰ] r`_h थ [ ﺗﻬṱʰ] t_d_h ख [ ﮐﻬkʰ] k_h ठ [ ﭨﻬʈʰ] t`_h घ [ ﮔﻬgʰ] g_h झ [ ﺟﻬʤʰ] d_Z_h लह [ ﻟﻬlʰ] l_h छ [ ﭼﻬʧʰ] t_S_h मह [ ﻣﻬmʰ] m_h ध [ دهḓʰ] d_d_h नह [ ﻧﻬnʰ] n_h ढ Urdu contains 10 vowels and 7 of them have nasalized forms (Hussain, 2004; Khan, 1997). Urdu vowels are represented using four long vowels (Alef Madda ()ﺁ, Alef ()ا, Vav ( )وand Choti Yeh ( ))ﯼand three short vowels (Arabic Fatha – Zabar َ-, Arabic Damma – Pesh ُ- and Arabic Kasra – Zer ِ-). Vowel representation is contextsensitive in Urdu. Vav ( )وand Choti Yeh ( )ﯼare also used as consonants. Hamza ( )ءis a place holder between two successive vowel sounds, e.g. in [ ﮐﻤﺎﺋﯽkəmɑi] (earning), Hamza ( )ءseparates the two vowel sounds Alef ([ )اɑ] and Choti Yeh ([ )ﯼi]. Noonghunna ( )ںis used as nasalization marker. Analysis and mapping of Hindi"
C08-1068,J98-4003,0,\N,Missing
C08-1068,Y06-1050,0,\N,Missing
C10-2091,kang-choi-2000-automatic,0,0.0523799,"n to objective evaluations. 1 Introduction Transliteration refers to phonetic translation across two languages with different writing systems, such as Arabic to English (Arbabi et al., 1994; Stall and Knight, 1998; Al-Onaizan and Knight, 2002; AbdulJaleel and Larkey, 2003). Most prior work on transliteration has been done for MT of English, Arabic, Japanese, Chinese, Korean, etc., for CLIR (Lee and Choi., 1998; Jeong et al., 1999; Fujii and Ishikawa, 2001; Sakai et al., 2002; Pirkola et al., 2003; Virga and Khudanpur, 2003; Yan et al., 2003), and for the development of multilingual resources (Kang and Choi, 2000; Yan, Gregory et al., 2003). The terms transliteration and transcription are often used as generic terms for various processes like transliteration, transcription, romanization, transcribing and technography (Halpern, 2002). In general, the speech processing community uses the term transcription to denote a process of conversion from the script or writing system to the sound (phonetic representation). For examPushpak Bhattacharyya IIT Bombay pb@iitb.ac.in ple, the transcription of the word “love” in the International Phonetic Alphabet (IPA) is [ləv]. While the text processing community uses t"
C10-2091,J94-3001,0,0.0919442,"4: System Architecture of fintie-state scriptural translation ज़ [ ذz] z1 म [ مm] m 5.1 र [ رr] r न [ نn] n उ [ ڑɽ] r` व [ وv] v ज़ [ زz] z ह [ ﮦh] h ज़ [ ژʒ] Z य [ ﯼj] j स [ سs] s त [ ةṱ] t_d2 श [ شʃ] S ण - [ɳ] n` Both conversions of the source language text into the UIT encoded text and from the UIT encoded text into the target language text are regular relations on strings. Moreover, regular relations are closed under serial composition and a finite set of conversion relations when applied to each other’s output in a specific order, also defines a regular expression (Kaplan and Kay, 1994). Thus we model the conversions from the source language to UIT and from UIT to the target language as finite-state transducers. These translational transducers can be deterministic and nondeterministic. Character Mappings: Table 5 shows regular relations for converting Hindi and Urdu aspirated consonants into UIT. ष ◌ं S1 ~ [ شʃ] [ ںŋ] Table 4: UIT encodings of Urdu non-aspirated consonants 5 tokens using the UIT to target language conversion transducer from the repertoire of Transducers. Finally, Text Generator generates the target language text from the translated target language tokens"
C10-2091,W09-3536,1,0.818499,"ndard code page for Shahmukhi does not exist. Similar problems also exist for the Kashmiri and Seraiki languages. 3.3 Absence of necessary information There are cases where the necessary and indispensable information for scriptural translation are missing in the source text. For example, the first word [ دﻧﻴﺎḓʊnɪjɑ] (world) of the example sentence of Figure 1 misses crucial diacritical information, mandatory to perform Urdu to Hindi scriptural translation. Like in Arabic, diacritical marks are part of the Urdu writing system but are sparingly used in writings (Zia, 1999; Malik et al., 2008; Malik et al., 2009). Figure 2(a) shows the example word without diacritical marks and its wrong Hindi conversion according to conversion rules (explained later). The Urdu community can understand the word in its context or without the context because people are tuned to understand the Urdu text or word without diacritical marks, but the Hindi conversion of Figure 2(a) is not at all acceptable or readable in the Hindi community. Figure 2(b) shows the example word with diacritical marks and its correct Hindi conversion according to conversion rules. Similar problems also arise for the other Indo-Pak languages. The"
C10-2091,C08-1068,1,0.794573,"and till date, a standard code page for Shahmukhi does not exist. Similar problems also exist for the Kashmiri and Seraiki languages. 3.3 Absence of necessary information There are cases where the necessary and indispensable information for scriptural translation are missing in the source text. For example, the first word [ دﻧﻴﺎḓʊnɪjɑ] (world) of the example sentence of Figure 1 misses crucial diacritical information, mandatory to perform Urdu to Hindi scriptural translation. Like in Arabic, diacritical marks are part of the Urdu writing system but are sparingly used in writings (Zia, 1999; Malik et al., 2008; Malik et al., 2009). Figure 2(a) shows the example word without diacritical marks and its wrong Hindi conversion according to conversion rules (explained later). The Urdu community can understand the word in its context or without the context because people are tuned to understand the Urdu text or word without diacritical marks, but the Hindi conversion of Figure 2(a) is not at all acceptable or readable in the Hindi community. Figure 2(b) shows the example word with diacritical marks and its correct Hindi conversion according to conversion rules. Similar problems also arise for the other In"
C10-2091,W98-1005,0,\N,Missing
C10-2091,W02-1206,0,\N,Missing
C10-2091,W02-0505,0,\N,Missing
C10-2091,knight-al-onaizan-1998-translation,0,\N,Missing
C10-2120,1999.tc-1.8,0,0.307592,"Missing"
C10-2120,J03-3005,0,0.0982174,"Missing"
C10-2120,J03-3001,0,0.204183,"Missing"
C10-2120,2005.mtsummit-papers.11,0,0.0656565,"Missing"
C10-2120,W06-1208,0,0.260743,"Missing"
C10-2120,ramisch-etal-2010-mwetoolkit,1,0.585795,"ate techniques for the combination of n-gram counts from heterogeneous sources. Therefore, we will use the insights about the vocabulary differences presented in the previous section. In this evaluation, we measure the impact of the suggested techniques in the identification of noun–noun compounds in corpora. Noun compounds are very frequent in general-purpose and specialised texts (e.g. bus stop, European Union and gene activation). We extract them automatically from ep and from genia using a standard method based on POS patterns and association measures (Evert and Krenn, 2005; Pecina, 2008; Ramisch et al., 2010). 5.1 Experimental setup The evaluation task consists of, given a corpus of N words, extract all occurrences of adjacent pairs of nouns8 and then rank them using a standard statistical measure that estimates the association strength between the two nouns. Analogously to the formalism adopted in section 4.2, we assume that, for each corpus, we generate a set NN containing n-grams v1...n ∈ NN 9 for which we obtain n-gram counts from four sources. The elements in NN are generated by comparing the POS pattern noun–noun against all the bigrams in the corpus and keeping only those pairs of adjacent"
C10-2120,D07-1110,1,0.9292,"Missing"
C10-2120,J01-1001,0,0.12675,"percase words at the beginning of sentences were lowercased; • other words were not modified. 3 Genia contains manual POS tag annotation. Europarl was tagged using the TreeTagger (www.ims.uni-stuttgart.de/projekte/ corplex/TreeTagger). 1043 This lowercasing algorithm helps to deal with the massive use of abbreviations, acronyms, named entities, and formulae found in specialised corpora, such as those containing biomedical (and other specialised) scientific articles. For calculating arbitrary-sized n-grams in large textual corpora efficiently, we implemented a structure based on suffix arrays (Yamamoto and Church, 2001). While suffix trees are often used in LM tools, where n-grams have a fixed size, they are not fit for arbitrary length n-gram searches and can consume quite large amounts of memory to store all the node pointers. Suffix arrays, on the other hand, allow for arbitrary length n-grams to be counted in a time that is proportional to log(N), where N is the number of words (which is equivalent to the number of suffixes) in the corpus. Suffix arrays use a constant amount of memory proportional to N. In our implementation, where every word and every word position in the corpus are encoded as a 4-byte"
C10-3015,ramisch-etal-2010-mwetoolkit,1,0.700251,"rds can be considered synonyms to transmit the idea of completeness? This is an example of a collocation, i.e. a sequence of words that tend to occur together and whose interpretation generally crosses the boundaries between words (Smadja, 1993). More generally, collocations are a frequent type of multiword expression (MWE), a sequence of words that presents some lexical, syntactic, semantic, pragmatic or statistical idiosyncrasies (Sag et al., 2002). The definition of MWE also includes a wide range of constructions like phrasal verbs (go 2 1 The first version of the toolkit was presented in (Ramisch et al., 2010b), where we described a language- and type-independent methodology. Inside the black box MWE identification is composed of two phases: first, we automatically generate a list of candi57 Coling 2010: Demonstration Volume, pages 57–60, Beijing, August 2010 c(w1 . . . wn ) N n × c(w1 . . . wn ) dice = ∑ni=1 c(wi ) c(w1 . . . wn ) pmi = log2 E(w1 . . . wn ) c(w1 . . . wn ) − E(w1 . . . wn ) p t-score = c(w1 . . . wn ) mle candidate = fEP fgoogle class status quo 137 US navy 4 International Cooperation 2 Cooperation Agreement 188 Panama Canal 2 security institution 5 lending institution 4 human ri"
C10-3015,C10-2120,1,0.605893,"rds can be considered synonyms to transmit the idea of completeness? This is an example of a collocation, i.e. a sequence of words that tend to occur together and whose interpretation generally crosses the boundaries between words (Smadja, 1993). More generally, collocations are a frequent type of multiword expression (MWE), a sequence of words that presents some lexical, syntactic, semantic, pragmatic or statistical idiosyncrasies (Sag et al., 2002). The definition of MWE also includes a wide range of constructions like phrasal verbs (go 2 1 The first version of the toolkit was presented in (Ramisch et al., 2010b), where we described a language- and type-independent methodology. Inside the black box MWE identification is composed of two phases: first, we automatically generate a list of candi57 Coling 2010: Demonstration Volume, pages 57–60, Beijing, August 2010 c(w1 . . . wn ) N n × c(w1 . . . wn ) dice = ∑ni=1 c(wi ) c(w1 . . . wn ) pmi = log2 E(w1 . . . wn ) c(w1 . . . wn ) − E(w1 . . . wn ) p t-score = c(w1 . . . wn ) mle candidate = fEP fgoogle class status quo 137 US navy 4 International Cooperation 2 Cooperation Agreement 188 Panama Canal 2 security institution 5 lending institution 4 human ri"
C10-3015,J93-1007,0,0.652141,"t of selected examples, comparing it with related work on MWE extraction. 1 MWEs in a nutshell One of the factors that makes Natural Language Processing (NLP) a challenging area is the fact that some linguistic phenomena are not entirely compositional or predictable. For instance, why do we prefer to say full moon instead of total moon or entire moon if all these words can be considered synonyms to transmit the idea of completeness? This is an example of a collocation, i.e. a sequence of words that tend to occur together and whose interpretation generally crosses the boundaries between words (Smadja, 1993). More generally, collocations are a frequent type of multiword expression (MWE), a sequence of words that presents some lexical, syntactic, semantic, pragmatic or statistical idiosyncrasies (Sag et al., 2002). The definition of MWE also includes a wide range of constructions like phrasal verbs (go 2 1 The first version of the toolkit was presented in (Ramisch et al., 2010b), where we described a language- and type-independent methodology. Inside the black box MWE identification is composed of two phases: first, we automatically generate a list of candi57 Coling 2010: Demonstration Volume, pag"
C12-2012,P84-1067,0,0.667989,"Missing"
C12-2012,1985.tmi-1.3,1,0.52804,"Missing"
C12-2012,1986.tc-1.16,1,0.390218,"Missing"
C12-2012,1999.mtsummit-1.19,1,0.783546,"Missing"
C12-2012,2008.jeptalnrecital-long.24,1,0.480147,"Missing"
C12-3002,P84-1067,0,0.715198,"Missing"
C12-3002,1985.tmi-1.3,1,0.577937,"Missing"
C12-3002,1986.tc-1.16,1,0.423721,"Missing"
C12-3002,1999.mtsummit-1.19,1,0.726986,"Missing"
C12-3002,2008.jeptalnrecital-long.24,1,0.845838,"Missing"
C12-3018,2009.mtsummit-btm.3,1,0.838622,"Missing"
C12-3018,huynh-etal-2008-sectra,1,0.871487,"Missing"
C12-3018,2001.mtsummit-road.1,1,\N,Missing
C12-3060,2010.jeptalnrecital-demonstration.3,1,0.870676,"Missing"
C12-3060,huynh-etal-2008-sectra,1,0.900631,"Missing"
C90-2006,C88-2160,0,\N,Missing
C90-3006,1989.mtsummit-1.30,0,0.030788,"currently studying and prototyping in the LIDIA project Ideally, a PMT system should run on PCs and be usable by everybody. To get his/her text translated into one or several languages, the writer would accept to cooperate with the system in order to standardize and clarify his/her document. There are many interesting aspects in the design of such a system. The paper briefly presents some of them (HyperText, distributed architecture, guided language, hybrid transfer/interlingua, the goes on to study in more detail the structure of the dialogue with the writer and the place of speech synthesis [1]. core knowledge about the language ; specific knowledge about the corpus (domain, typology) ; intrinsic semantics (a term coined by J.P. Desclds to cover all information formally marked in a natural language, but which refers to its interpretation, such as semantic features or relations : concreteness, location, cause, instrument... ) ; but not : Keywords extrinsic semantics (static knowledge de~ribing the domain(s) of the text, e.g. in terms of facts and rules) ; Personal Machine Translation, dialogue-based Machine Translation, Man-Machine Dialogue, Ambiguity Resolution, Speech Synthesis. si"
C90-3006,1988.tmi-1.23,1,0.828276,"Missing"
C90-3006,C88-2160,0,\N,Missing
C94-1070,P93-1013,0,0.0234775,"potential is not used in KASUGA. 4. S i m u l a t e i n c r e m e n t a l p r o c e s s i n g In real life, simullanexms interpretation is often preferred over consecutive interpretation: although it may be less exact, one is not forced to wait, and one can react even before the end of tile speaker&apos;s utterance. Incremental processing will thus be an iinportant aspect of future machine interpretation systems. For instance, a sem.&apos;mlic processor might begin working on the syntactic structures hypothesized for early parts of an utterance while later parts ,are still being syntactically an,&apos;dyzed [19]. Even if a component (e.g., a W cun&apos;ently existing speech recognizer) has to get to file end of the utterance before producing any result, its nmnager may still m;tke its processing appear incremental, by delivering its result piecewise and iu the desired order. I lence, this organiz&apos;~tion makes it possible to siintfiate future incremental components. 11. TIlE KASUGA PROTOTYI&apos;E 1. External level The coordinator (KAS.COORD) is writtcn in KEK TM, au object-oriented expert system shell with excellent interfacebuilding tools. The whiteboard is declared ill KEF]s object language. KEE itself is wri"
C94-1070,J85-1002,0,\N,Missing
C94-1070,C92-3164,0,\N,Missing
C94-1070,C90-1012,0,\N,Missing
C96-1022,C90-2045,0,\N,Missing
C96-1022,1993.mtsummit-1.15,1,\N,Missing
C96-1022,C94-1017,0,\N,Missing
E85-1011,C82-1004,0,\N,Missing
F13-2032,P98-2123,0,0.163797,"Missing"
F14-2003,D11-1084,0,0.0492518,"Missing"
F14-2003,D12-1026,0,0.0295358,"Missing"
F14-2003,N09-2056,0,0.067541,"Missing"
F14-2003,P13-2066,0,0.0381499,"Missing"
F14-2003,2013.mtsummit-wptp.12,1,0.732079,"Missing"
F14-2003,P07-1108,0,0.0286491,"Missing"
F14-2003,P09-1018,0,0.0460949,"Missing"
fafiotte-etal-2004-collecting,C94-1017,0,\N,Missing
huynh-etal-2008-sectra,2004.iwslt-papers.1,1,\N,Missing
huynh-etal-2008-sectra,2006.iwslt-evaluation.3,1,\N,Missing
J85-1003,P84-1067,0,0.0707342,"Missing"
J85-1003,C82-1004,0,\N,Missing
J85-1003,P84-1100,1,\N,Missing
lafourcade-boitet-2002-unl,C90-2045,0,\N,Missing
lafourcade-boitet-2002-unl,C92-3168,0,\N,Missing
lafourcade-boitet-2002-unl,C92-3129,0,\N,Missing
lafourcade-boitet-2002-unl,C00-2111,1,\N,Missing
lafourcade-boitet-2002-unl,C94-1017,0,\N,Missing
lafourcade-boitet-2002-unl,C80-1064,0,\N,Missing
O06-5003,C94-1089,0,0.118657,"Missing"
O06-5003,Y05-1005,1,0.430488,"Missing"
O06-5003,2001.mtsummit-papers.66,0,0.369205,"Missing"
P84-1100,C82-1004,0,0.149387,"Missing"
P84-1100,T87-1035,0,0.0401729,"Missing"
P84-1100,P84-1067,0,\N,Missing
ramisch-etal-2010-mwetoolkit,pearce-2002-comparative,0,\N,Missing
ramisch-etal-2010-mwetoolkit,messiant-etal-2008-lexschem,0,\N,Missing
ramisch-etal-2010-mwetoolkit,copestake-etal-2002-multiword,1,\N,Missing
ramisch-etal-2010-mwetoolkit,J93-1007,0,\N,Missing
ramisch-etal-2010-mwetoolkit,W03-1806,0,\N,Missing
ramisch-etal-2010-mwetoolkit,D07-1110,1,\N,Missing
ramisch-etal-2010-mwetoolkit,W06-1206,1,\N,Missing
ramisch-etal-2010-mwetoolkit,calzolari-etal-2002-towards,0,\N,Missing
ramisch-etal-2010-mwetoolkit,W02-1030,0,\N,Missing
ramisch-etal-2010-mwetoolkit,W08-2107,1,\N,Missing
ramisch-etal-2010-mwetoolkit,P07-1115,0,\N,Missing
ramisch-etal-2010-mwetoolkit,C02-1013,0,\N,Missing
W02-1602,1999.mtsummit-1.33,1,0.845689,"Missing"
W02-1602,1985.tmi-1.20,0,0.0207998,"Missing"
W02-1602,C86-1030,0,0.0202753,"Missing"
W02-1602,C88-1013,0,\N,Missing
W02-1602,C00-1013,0,\N,Missing
W02-1602,C00-2111,1,\N,Missing
W02-1602,1999.mtsummit-1.19,1,\N,Missing
W02-1602,2001.mtsummit-road.1,1,\N,Missing
W02-1602,J85-2003,0,\N,Missing
W02-1705,C94-1044,1,\N,Missing
W04-2215,W02-1602,1,\N,Missing
W09-3536,W04-1613,0,0.210166,"Missing"
W09-3536,C08-1068,1,0.795735,"Missing"
W09-3536,W98-1005,0,\N,Missing
W09-3536,J98-4003,0,\N,Missing
W10-3303,2008.tc-1.3,0,0.0351409,"Missing"
W10-3303,2007.mtsummit-papers.24,0,0.111395,"Missing"
W10-4009,lavie-etal-2002-nespole,0,0.0174981,"uting the angular distance between two conceptual vectors (Schwab and Lafourcade, 2007). In our case, conceptual vectors are used for automatic disambiguation of texts. Using this method, we calculate confidence score for each UW hypothesis appearing in the Q-Graph. 5 Ontology driven content extraction The content extraction has to be leaded by a “knowledge base” containing the informations we want to retrieve. 5.1 Previous works in content extraction This approach has its roots in machine translation projects such as C-Star II (1993-1999) (Blanchon and Boitet, 2000) and Nespole! (2000-2002) (Metze et al., 2002), for on the fly translation of oral speech acts in the domain of tourism. In these projects, semantic transfer was achieved through an IF (Inter-exchange Format), that is a semantic pivot dedicated to the domain. This IF allows to store information extracted from texts but is although used to lead the content extraction process by giving a formal representation of the relevant informations to extract, according to the domain. The Nespole! IF consists of 123 concepts from the tourism domain, associated with several arguments and associable with speech acts markers. The extraction process is ba"
W13-4706,W09-3510,0,0.035093,"Missing"
W13-4706,J07-3002,0,0.0220739,"as Urdu computational linguistics (Zia 1999). Like in Arabic, diacritical marks are sparingly used in written Urdu (Zia 1999). To model this unfortunate situation, we developed another From these two types of Urdu – Hindi parallel data, we developed two types of character alignments using GIZA++ (Och and Ney 2003) in both directions:  Hindi and Urdu with diacritics character alignment,  Hindi and Urdu without diacritics character alignment. 45 3.1.2 # Sentence pair (167) source length 9 target length 7 alignment score : 3.20243e‐05 Cluster alignments Alignment plays a critical role in SMT (Fraser and Marcu 2007; Kumar, Och and Macherey 2007; Huang 2009). The quality of parallel data and the word alignment have a significant impact on learning the translation model and consequently on the quality of the SMT system (Fraser and Marcu 2007; Huang 2009). It is always better do an analysis of the alignment and correct the alignment errors to reduce the Alignment Error Rate (AER). We also analyzed the alignments produced by GIZA++. We found that we can improve our alignments to reduce the AER. The incorrect alignments are highlighted in Table 4 (below) that shows Hindi to Urdu with diacritics alignments of"
W13-4706,P09-1105,0,0.0159907,"n Arabic, diacritical marks are sparingly used in written Urdu (Zia 1999). To model this unfortunate situation, we developed another From these two types of Urdu – Hindi parallel data, we developed two types of character alignments using GIZA++ (Och and Ney 2003) in both directions:  Hindi and Urdu with diacritics character alignment,  Hindi and Urdu without diacritics character alignment. 45 3.1.2 # Sentence pair (167) source length 9 target length 7 alignment score : 3.20243e‐05 Cluster alignments Alignment plays a critical role in SMT (Fraser and Marcu 2007; Kumar, Och and Macherey 2007; Huang 2009). The quality of parallel data and the word alignment have a significant impact on learning the translation model and consequently on the quality of the SMT system (Fraser and Marcu 2007; Huang 2009). It is always better do an analysis of the alignment and correct the alignment errors to reduce the Alignment Error Rate (AER). We also analyzed the alignments produced by GIZA++. We found that we can improve our alignments to reduce the AER. The incorrect alignments are highlighted in Table 4 (below) that shows Hindi to Urdu with diacritics alignments of our sample words of Table 3. The vowel rep"
W13-4706,W04-1613,0,0.0374663,"on learning the translation model and consequently on the quality of the SMT system (Fraser and Marcu 2007; Huang 2009). It is always better do an analysis of the alignment and correct the alignment errors to reduce the Alignment Error Rate (AER). We also analyzed the alignments produced by GIZA++. We found that we can improve our alignments to reduce the AER. The incorrect alignments are highlighted in Table 4 (below) that shows Hindi to Urdu with diacritics alignments of our sample words of Table 3. The vowel representation in Urdu/PersioArabic script is highly complex and contextsensitive (Hussain 2004; Malik, Boitet and Bhattacharyya 2008; Malik et al. 2009). This highly complex and contextual representation leads to wrong character alignments, highlighted in Table 4. In the second row of Table 4, the Hindi vowel इ [ɪ] is aligned with ALEF ( )اand ZER ( ِ◌) is aligned to NULL. The alignment is not completely incorrect, but the vowel इ [ɪ] must be aligned with both ALEF ( )اand ZER (◌ِ ). Similarly, the Hindi vowel उ [ʊ] must be aligned with ALEF ( )اand PESH ( ُ◌) in the third row. In these examples, one character in Hindi must be aligned with a sequence of characters in Urdu. Intere"
W13-4706,P06-1067,0,0.0251764,"2 for Hindi and 4 for Urdu. Another set of 6 target language models are developed by combining the corresponding word and sentence language models. Target Language Models A target language model Ρ is a probabilistic model that scores the well-formedness of different translation solutions produced by the translation model (Koehn, Och and Marcu 2003; Zens and Ney 2003; Och and Ney 2004; AlOnaizan and Papineni 2006). It generates a probability distribution over possible sequences of words and computes the probability of producing a given word given all the words that precede it in the sentence (Al-Onaizan and Papineni 2006). We developed multiple target language models depending on the type of alignments used in the transliteration models and the target language. We broadly categorize them into word language models and sentence language models, discussed below. 3.3.1 Sentence Language Models (SLM) Word Language Models (WLM) A word language model is a 6-gram statistical model that gives a probability distribution over possible sequences of characters and computes the probability of producing a given character or cluster C1, given the 5 characters or clusters that precede it in the word. We developed Hindi – Urdu"
W13-4706,J90-2002,0,0.656839,"Missing"
W13-4706,E09-1050,0,0.0389601,"Missing"
W13-4706,J93-2003,0,0.0897074,"Missing"
W13-4706,W09-3522,0,0.068881,"Missing"
W13-4706,J03-1002,0,0.00591785,"he Urdu words that we have generated from the Roman transcriptions from the DSAL dictionary data contain all required diacritical marks, clearly shown in Table 2. Diacritical marks are the back bone of the Urdu vowel system and they are mandatory for the correct pronunciation of an Urdu word, as well as Urdu computational linguistics (Zia 1999). Like in Arabic, diacritical marks are sparingly used in written Urdu (Zia 1999). To model this unfortunate situation, we developed another From these two types of Urdu – Hindi parallel data, we developed two types of character alignments using GIZA++ (Och and Ney 2003) in both directions:  Hindi and Urdu with diacritics character alignment,  Hindi and Urdu without diacritics character alignment. 45 3.1.2 # Sentence pair (167) source length 9 target length 7 alignment score : 3.20243e‐05 Cluster alignments Alignment plays a critical role in SMT (Fraser and Marcu 2007; Kumar, Och and Macherey 2007; Huang 2009). The quality of parallel data and the word alignment have a significant impact on learning the translation model and consequently on the quality of the SMT system (Fraser and Marcu 2007; Huang 2009). It is always better do an analysis of the alignment"
W13-4706,D07-1005,0,0.0560221,"Missing"
W13-4706,J04-4002,0,0.0575552,"r and then by applying clustering. Finally, we developed character-level and cluster-level Urdu Sentence Language Models using the SRILM toolkit. Similar to word language model, We have developed total 6 sentence language models, 2 for Hindi and 4 for Urdu. Another set of 6 target language models are developed by combining the corresponding word and sentence language models. Target Language Models A target language model Ρ is a probabilistic model that scores the well-formedness of different translation solutions produced by the translation model (Koehn, Och and Marcu 2003; Zens and Ney 2003; Och and Ney 2004; AlOnaizan and Papineni 2006). It generates a probability distribution over possible sequences of words and computes the probability of producing a given word given all the words that precede it in the sentence (Al-Onaizan and Papineni 2006). We developed multiple target language models depending on the type of alignments used in the transliteration models and the target language. We broadly categorize them into word language models and sentence language models, discussed below. 3.3.1 Sentence Language Models (SLM) Word Language Models (WLM) A word language model is a 6-gram statistical model"
W13-4706,W09-3536,1,0.906635,"n the quality of the SMT system (Fraser and Marcu 2007; Huang 2009). It is always better do an analysis of the alignment and correct the alignment errors to reduce the Alignment Error Rate (AER). We also analyzed the alignments produced by GIZA++. We found that we can improve our alignments to reduce the AER. The incorrect alignments are highlighted in Table 4 (below) that shows Hindi to Urdu with diacritics alignments of our sample words of Table 3. The vowel representation in Urdu/PersioArabic script is highly complex and contextsensitive (Hussain 2004; Malik, Boitet and Bhattacharyya 2008; Malik et al. 2009). This highly complex and contextual representation leads to wrong character alignments, highlighted in Table 4. In the second row of Table 4, the Hindi vowel इ [ɪ] is aligned with ALEF ( )اand ZER ( ِ◌) is aligned to NULL. The alignment is not completely incorrect, but the vowel इ [ɪ] must be aligned with both ALEF ( )اand ZER (◌ِ ). Similarly, the Hindi vowel उ [ʊ] must be aligned with ALEF ( )اand PESH ( ُ◌) in the third row. In these examples, one character in Hindi must be aligned with a sequence of characters in Urdu. Interestingly, we have observed that GIZA++ correctly aligns suc"
W13-4706,C08-1068,1,0.933314,"Missing"
W13-4706,P04-1021,0,\N,Missing
W13-4706,W98-1005,0,\N,Missing
W13-4706,W02-0505,0,\N,Missing
W13-4706,P07-2045,0,\N,Missing
W13-4706,P06-2025,0,\N,Missing
W13-4706,P10-1048,0,\N,Missing
W13-4706,N03-1017,0,\N,Missing
W13-4706,P97-1017,0,\N,Missing
W13-4706,P03-1019,0,\N,Missing
W14-4713,W04-2209,0,0.101345,"Missing"
W14-4713,C10-3014,0,0.0111007,"ade and Joubert, 2010) or RFL (Lexical Network of French (Lux-Pogodalla, Polguère 2011)). Lexical networks are traditionally represented as graphs. Nodes represent the lexemes of one or more languages, and links represent the relationships between these lexemes (translation, synonymy, etc.). A lexical network can be monolingual or multilingual. One can create syntactic, morphological and semantic relations between lexemes. Although lexical networks have many advantages, they are not suitable for all usages. For example, lexical networks like WordNet (Diller & al., 1990; Vossen, 1998), HowNet (Dong et al., 2010) and MindNet (Dolan and Richardson, 1996) (Richardson et al., 1998) are not browsable in alphabetical order. But we need that possibility to have an idea of the content of a lexical repository, whatever its nature, or to play word games, or to find a word one has on the tip of the tongue8. On the other hand, in a lexical network, the concept of volume is missing, which prevents to create a resource in a simple way when studying a new language. For example, the lexical network DBNary (Sérasset, 2012), which is based on the Lemon model (McCrae et al., 2011), contains millions of terms, but does"
W14-4713,mangeot-chalvin-2006-dictionary,1,0.770323,"et-reseaux-lexicaux.pdf For that kind of functionality, multiple sorting on subsets of inflected forms and on arbitray types of information seems to be a necessary first level of computer aid. 8 89 information in the form of rich links that will bring them closer to lexical networks. An important point is that these links may bear arbitrary labels. 3.1 Presentation of the Jibiki platform Jibiki is a generic platform that enables the construction of contributive websites dedicated to the construction of multilingual lexical databases. That platform has been developed mainly by Mathieu Mangeot (Mangeot & Chalvin, 2006) and Gilles Sérasset (Sérasset & Mangeot, 2001). It has been used in various projects (EU LexALP project, Papillon project, GDEF project, etc.). The code is available in open source, and freely downloadable by SVN from ligforge.imag.fr. With this platform, one can perform import, export, edit and search operations in lexical databases. One can also manage the contributions. Jibiki allows handling almost all lexical resources of XML type, by using different microstructures and macrostructures. In the Jibiki approach, resources are organized in volumes, which makes it easier to achieve the equiv"
W14-4713,P98-2180,0,0.0759371,"-Pogodalla, Polguère 2011)). Lexical networks are traditionally represented as graphs. Nodes represent the lexemes of one or more languages, and links represent the relationships between these lexemes (translation, synonymy, etc.). A lexical network can be monolingual or multilingual. One can create syntactic, morphological and semantic relations between lexemes. Although lexical networks have many advantages, they are not suitable for all usages. For example, lexical networks like WordNet (Diller & al., 1990; Vossen, 1998), HowNet (Dong et al., 2010) and MindNet (Dolan and Richardson, 1996) (Richardson et al., 1998) are not browsable in alphabetical order. But we need that possibility to have an idea of the content of a lexical repository, whatever its nature, or to play word games, or to find a word one has on the tip of the tongue8. On the other hand, in a lexical network, the concept of volume is missing, which prevents to create a resource in a simple way when studying a new language. For example, the lexical network DBNary (Sérasset, 2012), which is based on the Lemon model (McCrae et al., 2011), contains millions of terms, but does not allow labelling the links. To navigate in this system, one must"
W14-4713,serasset-2012-dbnary,0,0.0315636,"ages. For example, lexical networks like WordNet (Diller & al., 1990; Vossen, 1998), HowNet (Dong et al., 2010) and MindNet (Dolan and Richardson, 1996) (Richardson et al., 1998) are not browsable in alphabetical order. But we need that possibility to have an idea of the content of a lexical repository, whatever its nature, or to play word games, or to find a word one has on the tip of the tongue8. On the other hand, in a lexical network, the concept of volume is missing, which prevents to create a resource in a simple way when studying a new language. For example, the lexical network DBNary (Sérasset, 2012), which is based on the Lemon model (McCrae et al., 2011), contains millions of terms, but does not allow labelling the links. To navigate in this system, one must write SPARQL queries, which is not within the reach of everyone. 2.5 Conclusion: features, limitations and hard problems Research efforts focus today mainly on lexical networks, but much remains to be done on the preceding types (pivot, multilevel). In particular, the import of lexical databases in lexical networks causes a loss of information, especially information born by the attributes of rich links. For example, what concerns t"
W14-4713,C98-2175,0,\N,Missing
W15-5947,2011.eamt-1.6,0,0.0938611,"Missing"
W15-5947,C12-3032,1,0.846488,"alyzes why PE time, typLike the proponents of the Bologna project, we ically between 15 and 30 mn/page, was considerthink the real need is that foreign students get acably longer for the 3 Indian languages (bn, hi, mr). 326 4 3 Language code ISO639-2: https://www.loc.gov/standards/iso639-2/php/code list.php Test of English for International Communication Test of English as a Foreign Language 6 International English Language Testing System 5 cess not only to courses and tutorials, but also to notes from fellow students, in their respective languages, and possibly in parallel with the original (Kalitvianski et al., 2012). Simultaneously, they should also be invited to participate and improve the translations as time progresses. A subgoal is also that they learn better the language of their host university. 2.2 Obstacles The Bologna project started well, with clearly defined goals, and produced the beginning of a web service. However, very few syllabi were accessible, and the quality was not comparable with that of GT (Google Translate), Systran or Reverso. As no collaborative PE framework was included in the design, it could not be added afterwards and also could not produce a long-lasting service. This is no"
W15-5947,2011.tc-1.2,0,0.0271395,"essary coining, the terms in the target languages. 1 Introduction We are interested by using existing Machine Translation (MT) systems in the situations where their output does not (and often cannot, because, in its general form, MT is an ”AI-complete” problem) provide ”good enough” results. Post-editing MT results has been a professional activity in Japan since about 1985 (Nagao et al., 1985), and professional translators have begun to adopt that approach in other countries. Speaking of ”translation accelerators”, see for example the systems deployed at WIPO1 and UN2 (Pouliquen et al., 2013; Pouliquen and Mazenc, 2011a; Pouliquen and Mazenc, 2011b). There are other situations in which MT outputs could be brought to a quality ”good enough” for goals requiring a high level of precision and reliability. One of them is making pedagogical material accessible to foreign students in their own language. Cooperative post-editing (PE) of free MT pre-translations by the foreign students themselves is a good way to produce the ”target” versions, if the students find it rewarding, and not too timeconsuming., that is, if PE takes them no longer than about 15-20 minutes per standard page (of 325 1400 characters or 250 wo"
W15-5947,2011.mtsummit-plenaries.5,0,0.0560146,"Missing"
W15-5947,2013.mtsummit-user.7,0,0.035243,"Missing"
W15-5947,2013.mtsummit-wptp.12,1,0.684105,"f a segment is deemed to be ”good enough” if its quality score is higher or equal to 12/20. 2.3 Hypotheses and motivations behind the experiment Our first hypothesis is that the objective is reachable only if PE is put at the center of the approach, and if foreign students that can benefit from it, do it themselves in a voluntary fashion. Our second hypothesis is that we need to consider many more target languages than English and Chinese, including languages that are terminologically less equipped, for instance Arabic and South and South-East languages. Having the knowledge of an experiment (Wang and Boitet, 2013) in fr-zh for 1 year (in which the authors did not take part), we wanted to investigate the possiblity to do it for many languages, and to isolate the positive and negative factors, according to the target languages and to the profiles of the contributors. 3 Experiment 3.1 Setting We considered the following constraints: • to translate into as many target languages as possible, some of them being ”distant” from English, • to have as participants mostly PhD students, and all native speakers of the target languages, • to tackle a text of significant length, in a representative document, • to use"
W15-5947,J85-2001,0,\N,Missing
W16-4915,2010.jeptalnrecital-demonstration.3,1,0.885043,"Missing"
W16-4915,eisele-chen-2010-multiun,0,0.0796261,"Missing"
W16-5324,W05-0909,0,0.0608958,"Missing"
W16-5324,2001.mtsummit-papers.68,0,0.132221,"Missing"
W18-3815,W16-5324,1,0.892942,"Missing"
Y05-1005,1983.tc-1.13,0,0.395224,"er translator communities consist mainly of two types: Mission-oriented translators communities: mission-oriented, strongly-coordinated group of volunteers involved in translating clearly defined sets of documents. These communities cover loosely technical documentation like translation of Linux documentation [15], W3C specifications [17], and open source Mozilla localization software [9]. Subject-oriented translators network communities: individual translators who translate online documents such as news, analysis, and reports and make translations available in personal or group web pages [4] [11]. They form groups of translators without any orientation in advance, and they share similar opinions about events (antiwar humanitarian communities, report translation, news translation, humanitarian help, etc.). For instance, almost all online translators show similar behavior. As for the first communities (henceforth “Linux communities”), volunteer translators in both the Traduc and Mozilla projects are invited to translate a list of documents available on web sites (of each project) in different formats (XML, SGML, HTML, HLP, plain text, etc.). Firstly, they check whether the relevant docu"
Y07-1008,O06-5003,1,0.887934,"ppear in this translation community. In this case, they are related to the organization of translators and to data manipulation, and reflect separated and group functions. It is very difficult to delimit such behaviors either at translator or group level. But some lacks and needed functionalities are common to this and other communities (FRENCHMOZILLA, W3C, etc.). These functionalities, which correspond to the practices (i) and (ii) cited above, can be categorized as follows: a. Functionalities for translator who operates on translation in autonomous way and disposing of private environments (Bey et al., 2006 (a)) (Abekawa et al., 2007). b. Functionalities for collaboration and work between translators (Bey et al., 2006 (b)). 89 In the next section, details of these two categories of practice are described and the specification for functionalities implementation is given. 3. Description of integrated functionalities: the first step toward a solution In the process of translation, a volunteer translator will want individually exploit the potential of various automatic linguistic functionalities (e.g., dictionaries and MT suggestions) and at the same time interact with her/his counterparts by using"
Y07-1008,2001.mtsummit-papers.66,0,0.00924938,"unctionalities (e.g. asking for translation community aid when linguistic aids aren’t sufficient). From this point of view, translator and community functionalities should be implemented as follows. 3.1. Individual translator functionalities The environment should be open to all volunteers without any restriction. Individual translators should be able to take advantage at the following different functionalities: • Text extraction and tokenization: documents to be translated undergo a process of text extraction and tokenization for the identification of Translation Units (TU) (LINGPIPE, 2007) (Walker et al., 2001). • Linguistic aids: linguistic aids are integrated and activated automatically in an online asynchronous manner (see 4.3). • Online translator-oriented editor: translators read the source TUs synchronized with their corresponding target TUs and input the translation in the source TU in order, segment by segment, or jumping to the segment they wish to work on. The target TUs are replaced in fact automatically or manually by the &quot;best&quot; pre-translations of MT or TM – 3.2. Translator community functionalities Extended functionalities for the translation community have been implemented using the W"
Y11-1050,C88-1013,0,0.625593,"Missing"
Y11-1050,kawahara-kurohashi-2010-acquiring,0,0.0226273,"Missing"
Y11-1050,W01-1406,0,0.106699,"Missing"
Y11-1050,2001.mtsummit-papers.53,0,\N,Missing
Y11-1050,Y95-1034,1,\N,Missing
Y11-1050,2001.mtsummit-ebmt.4,0,\N,Missing
Y11-1050,W02-1601,1,\N,Missing
Y11-1050,C90-3101,0,\N,Missing
