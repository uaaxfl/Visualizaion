Y16-3001,Retrieval Term Prediction Using Deep Learning Methods,2016,27,0,1,1,33252,qing ma,"Proceedings of the 30th Pacific Asia Conference on Language, Information and Computation: Posters",0,None
Y14-1040,Retrieval Term Prediction Using Deep Belief Networks,2014,24,1,1,1,33252,qing ma,"Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing",0,"This paper presents a method to predict retrieval terms from relevant/surrounding words or descriptive texts in Japanese by using deep belief networks (DBN), one of two typical types of deep learning. To determine the effectiveness of using DBN for this task, we tested it along with baseline methods using examplebased approaches and conventional machine learning methods, i.e., multi-layer perceptron (MLP) and support vector machines (SVM), for comparison. The data for training and testing were obtained from the Web in manual and automatic manners. Automatically created pseudo data was also used. A grid search was adopted for obtaining the optimal hyperparameters of these machine learning methods by performing cross-validation on training data. Experimental results showed that (1) using DBN has far higher prediction precisions than using baseline methods and higher prediction precisions than using either MLP or SVM; (2) adding automatically gathered data and pseudo data to the manually gathered data as training data is an effective measure for further improving the prediction precisions; and (3) DBN is able to deal with noisier training data than MLP, i.e., the prediction precision of DBN can be improved by adding noisy training data, but that of MLP cannot be."
Y11-1062,"Extraction of Broad-Scale, High-Precision {J}apanese-{E}nglish Parallel Translation Expressions Using Lexical Information and Rules",2011,8,3,1,1,33252,qing ma,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"Extraction was attempted of broad-scale, high-precision Japanese-English paral- lel translation expressions from large aligned parallel corpora. To acquire broad-scale parallel translation expressions, a new method was used to extract single Japanese and English word n-grams, by which as many parallel translation expressions as possible could then be ex- tracted. To achieve high extraction precision, first, hand-crafted rules were used to prune the unnecessary words often found in expressions extracted on the basis of word n-grams, and lexical information was used to refine the parallel translation expressions. Computer exper- iments with aligned parallel corpora consisting of about 280,000 pairs of Japanese-English parallel sentences found that more than 125,000 pairs of parallel translation expressions could be extracted with a precision of 0.96. These figures show that the proposed methods for ex- tracting a broad range of parallel translation expressions have reached a level high enough for practical use."
zhang-etal-2008-word,Word Alignment Annotation in a {J}apanese-{C}hinese Parallel Corpus,2008,5,0,4,1,9062,yujie zhang,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Parallel corpora are critical resources for machine translation research and development since parallel corpora contain translation equivalences of various granularities. Manual annotation of word {\&} phrase alignment is of significance to provide gold-standard for developing and evaluating both example-based machine translation model and statistical machine translation model. This paper presents the work of word {\&} phrase alignment annotation in the NICT Japanese-Chinese parallel corpus, which is constructed at the National Institute of Information and Communications Technology (NICT). We describe the specification of word alignment annotation and the tools specially developed for the manual annotation. The manual annotation on 17,000 sentence pairs has been completed. We examined the manually annotated word alignment data and extracted translation knowledge from the word {\&} phrase aligned corpus."
ma-etal-2008-selection,Selection of {J}apanese-{E}nglish Equivalents by Integrating High-quality Corpora and Huge Amounts of Web Data,2008,5,1,1,1,33252,qing ma,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"As a first step to developing systems that enable non-native speakers to output near-perfect English sentences for given mixed English-Japanese sentences, we propose new approaches for selecting English equivalents by using the number of hits for various contexts in large English corpora. As the large English corpora, we not only used the huge amounts of Web data but also the manually compiled large, high-quality English corpora. Using high-quality corpora enables us to accurately select equivalents, and using huge amounts of Web data enables us to resolve the problem of the shortage of hits that normally occurs when using only high-quality corpora. The types and lengths of contexts used to select equivalents are variable and optimally determined according to the number of hits in the corpora, so that performance can be further refined. Computer experiments showed that the precision of our methods was much higher than that of the existing methods for equivalent selection."
I08-2100,Non-Factoid {J}apanese Question Answering through Passage Retrieval that Is Weighted Based on Types of Answers,2008,16,2,4,0,16788,masaki murata,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"We constructed a system for answering nonfactoid Japanese questions. We used various methods of passage retrieval for the system. We extracted paragraphs based on terms from an input question and output them as the preferred answers. We classified the non-factoid questions into six categories. We used a particular method for each category. For example, we increased the scores of paragraphs including the word xe2x80x9creasonxe2x80x9d for questions including the word xe2x80x9cwhy.xe2x80x9d We participated at NTCIR-6 QAC-4, where our system obtained the most correct answers out of all the eight participating teams. The rate of accuracy was 0.77, which indicates that our methods were effective."
2007.mtsummit-papers.73,Building {J}apanese-{C}hinese translation dictionary based on {EDR} {J}apanese-{E}nglish bilingual dictionary,2007,2,6,2,1,9062,yujie zhang,Proceedings of Machine Translation Summit XI: Papers,0,"We launched a 5-year-project in 2006 to develop a Japanese-Chinese machine translation system for translating scientific and technical papers. As part of that project, we are currently building a Japanese-Chinese translation dictionary based on the EDR Japanese-English bilingual dictionary. This paper presents the design and construction of the Japanese-Chinese translation dictionary, including specifications for translating Japanese information into Chinese and annotating related information, tools developed for assisting manual annotation, and some result that have already been achieved."
W06-0201,Development of an Automatic Trend Exploration System using the {M}u{ST} Data Collection,2006,5,3,3,0.47713,16788,masaki murata,Proceedings of the Workshop on Information Extraction Beyond The Document,0,"The automatic extraction of trend information from text documents such as newspaper articles would be useful for exploring and examining trends. To enable this, we used data sets provided by a workshop on multimodal summarization for trend information (the MuST Workshop) to construct an automatic trend exploration system. This system first extracts units, temporals, and item expressions from newspaper articles, then it extracts sets of expressions as trend information, and finally it arranges the sets and displays them in graphs. For example, when documents concerning the politics are given, the system extracts % and Cabinet approval rating as a unit and an item expression including temporal expressions. It next extracts values related to %. Finally, it makes a graph where temporal expressions are used for the horizontal axis and the value of percentage is shown on the vertical axis. This graph indicates the trend of Cabinet approval rating and is useful for investigating Cabinet approval rating. Graphs are obviously easy to recognize and useful for understanding information described in documents. In experiments, when we judged the extraction of a correct graph as the top output to be correct, the system accuracy was 0.2500 in evaluation A and 0.3334 in evaluation B. (In evaluation A, a graph where 75% or more of the points were correct was judged to be correct; in evaluation B, a graph where 50% or more of the points were correct was judged to be correct.) When we judged the extraction of a correct graph in the top five outputs to be correct, accuracy rose to 0.4167 in evaluation A and 0.6250 in evaluation B. Our system is convenient and effective because it can output a graph that includes trend information at these levels of accuracy when given only a set of documents as input."
kanzaki-etal-2006-semantic,Semantic Analysis of Abstract Nouns to Compile a Thesaurus of Adjectives,2006,10,1,2,1,15923,kyoko kanzaki,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Aiming to compile a thesaurus of adjectives, we discuss how to extract abstract nouns categorizing adjectives, clarify the semantic and syntactic functions of these abstract nouns, and manually evaluate the capability to extract the Âinstance-categoryÂ relations. We focused on some Japanese syntactic structures and utilized possibility of omission of abstract noun to decide whether or not a semantic relation between an adjective and an abstract noun is an Âinstance-categoryÂ relation. For 63{\%} of the adjectives (57 groups/90 groups) in our experiments, our extracted categories were found to be most suitable. For 22 {\%} of the adjectives (20/90), the categories in the EDR lexicon were found to be most suitable. For 14{\%} of the adjectives (13/90), neither our extracted categories nor those in EDR were found to be suitable, or examineesÂ own categories were considered to be more suitable. From our experimental results, we found that the correspondence between a group of adjectives and their category name was more suitable in our method than in the EDR lexicon."
Y05-1014,"Analysis of Machine Translation Systems{'} Errors in Tense, Aspect, and Modality",2005,10,8,3,0.546856,16788,masaki murata,"Proceedings of the 19th Pacific Asia Conference on Language, Information and Computation",0,"Errors of the translation of tense, aspect, and modality by machine translation systems were analyzed for six translation systems on the market and our new systems for translating tense, aspect, and modality. The results showed that our systems outperformed the other systems. They also showed that the other systems often produced progressive forms rather than the correct present forms. Our systems rarely made this mistake. Translation systems on the market could thus be improved by incorporating the methods used in our systems. Moreover, error analysis of the translation systems on the market identified information that would be useful for improving them."
I05-2015,Building an Annotated {J}apanese-{C}hinese Parallel Corpus - A Part of {NICT} Multilingual Corpora,2005,9,9,3,1,9062,yujie zhang,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We are constricting a Japanese-Chinese parallel corpus, which is a part of the NICT Multilingual Corpora. The corpus is general domain, of large scale of about 40,000 sentence pairs, long sentences, annotated with detailed information and high quality. To the best of our knowledge, this will be the first annotated JapaneseChinese parallel corpus in the world. We created the corpus by selecting Japanese sentences from Mainichi Newspaper and then manually translating them into Chinese. We then annotated the corpus with morphological and syntactic structures and alignments at word and phrase levels. This paper describes the specification in human translation and the scheme of detailed information annotation, and the tools we developed in the corpus construction. The experience we obtained and points we paid special attentions are also introduced for share with other researches in corpora construction."
I05-2024,Information Retrieval Capable of Visualization and High Precision,2005,7,2,1,1,33252,qing ma,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"We present a neural-network based selforganizing approach that enables visualization of the information retrieval while at the same time improving its precision. In computer experiments, two-dimensional documentary maps in which queries and documents were mapped in topological order according to their similarities were created. The ranking of the results retrieved using the maps was better than that of the results obtained using a conventional TFIDF method. Furthermore, the precision of the proposed method was much higher than that of the conventional TFIDF method when the process was focused on retrieving highly relevant documents, suggesting that the proposed method might be especially suited to information retrieval tasks in which precision is more critical than recall."
I05-2043,Trend Survey on {J}apanese Natural Language Processing Studies over the Last Decade,2005,0,3,3,0.546856,16788,masaki murata,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"Using natural language processing, we carried out a trend survey on Japanese natural language processing studies that have been done over the last ten years. We determined the changes in the number of papers published for each research organization and on each research area as well as the relationship between research organizations and research areas. This paper is useful for both recognizing trends in Japanese NLP and constructing a method of supporting trend surveys using NLP."
2005.mtsummit-papers.10,Building an Annotated {J}apanese-{C}hinese Parallel Corpus {--} A Part of {NICT} Multilingual Corpora,2005,9,9,3,1,9062,yujie zhang,Proceedings of Machine Translation Summit X: Papers,0,"We are constricting a Japanese-Chinese parallel corpus, which is a part of the NICT Multilingual Corpora. The corpus is general domain, of large scale of about 40,000 sentence pairs, long sentences, annotated with detailed information and high quality. To the best of our knowledge, this will be the first annotated Japanese-Chinese parallel corpus in the world. We created the corpus by selecting Japanese sentences from Mainichi Newspaper and then manually translating them into Chinese. We then annotated the corpus with morphological and syntactic structures and alignments at word and phrase levels. This paper describes the specification in human translation and detailed information annotation, and the tools we developed in the project. The experience we obtained and points we paid special attentions are also introduced for share with other researches in corpora construction."
2005.mtsummit-papers.18,A Multi-aligner for {J}apanese-{C}hinese Parallel Corpora,2005,-1,-1,3,1,9062,yujie zhang,Proceedings of Machine Translation Summit X: Papers,0,"Automatic word alignment is an important technology for extracting translation knowledge from parallel corpora. However, automatic techniques cannot resolve this problem completely because of variances in translations. We therefore need to investigate the performance potential of automatic word alignment and then decide how to suitably apply it. In this paper we first propose a lexical knowledge-based approach to word alignment on a Japanese-Chinese corpus. Then we evaluate the performance of the proposed approach on the corpus. At the same time we also apply a statistics-based approach, the well-known toolkit GIZA++, to the same test data. Through comparison of the performances of the two approaches, we propose a multi-aligner, exploiting the lexical knowledge-based aligner and the statistics-based aligner at the same time. Quantitative results confirmed the effectiveness of the multi-aligner."
kanzaki-etal-2004-extraction,Extraction of Hyperonymy of Adjectives from Large Corpora by Using the Neural Network Model,2004,1,2,2,1,15923,kyoko kanzaki,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this research, we extract hierarchical abstract concepts of adjectives automatically from large corpora by using the Neural Network Model. We show the hierarchies on the Semantic Map and compare the hierarchies in the Semantic Map and a manually prepared thesaurus. We recognized five types of distributions on the map. By comparing the Semantic Map and a manual thesaurus, we found that the word that the abstract noun belongs to, whether a person, thing or event, is introduced as the standard of classification in the manual thesaurus. On the other hand, in the Semantic Map, we found that abstract nouns belonging to people or events are distributed together. We also found that the hierarchies of sokumen (side), imi (meaning), and kanten (viewpoint) are necessary for a category of adjectives."
C04-1165,Construction of an Objective Hierarchy of Abstract Concepts via Directional Similarity,2004,7,5,3,1,15923,kyoko kanzaki,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"The method of organization of word meanings is a crucial issue with lexical databases. Our purpose in this research is to extract word hierarchies from corpora automatically. Our initial task to this end is to determine adjective hyperonyms. In order to find adjective hyperonyms, we utilize abstract nouns. We constructed linguistic data by extracting semantic relations between abstract nouns and adjectives from corpus data and classifying abstract nouns based on adjective similarity using a self-organizing semantic map, which is a neural network model (Kohonen 1995). In this paper we describe how to hierarchically organize abstract nouns (adjective hyperonyms) in a semantic map mainly using CSM. We compare three hierarchical organizations of abstract nouns, according to CSM, frequency (Tf.CSM) and an alternative similarity measure based on coefficient overlap, to estimate hyperonym relations between words."
W03-1714,Semantic Maps for Word Alignment in Bilingual Parallel Corpora,2003,11,4,1,1,33252,qing ma,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,"Effective self-organizing techniques for constructing monolingual semantic maps of Japanese and Chinese have already been developed. By extending the monolingual map to a bilingual semantic map, we have proposed a semantics-based approach for word alignment in a Japanese/Chinese bilingual corpus."
W02-1107,Classification of Adjectival and Non-adjectival Nouns Based on their Semantic Behavior by Using a Self-Organizing Semantic Map,2002,7,3,2,1,15923,kyoko kanzaki,{COLING}-02: {SEMANET}: Building and Using Semantic Networks,0,"We treat nouns that behave adjectively, which we call adjectival nouns, extracted from large corpora. For example, in financial world and world of finance, financial and finance are different parts of speech, but their semantic behaviors are similar to each other. We investigate how adjectival nouns are similar to adjectives and different from non-adjectival nouns by using self-organizing semantic maps. We create five kinds of semantic maps, i.e., semantic maps of abstract nouns organized via (1) adjectives, (2) adjectival nouns, (3) non-adjectival nouns and (4) adjectival and adjectival nouns and a semantic map of adjectives, adjectival nouns and non-adjectival nouns organized via collocated abstract nouns, and compare them with each other to find similarities and differences."
C02-1060,Self-Organizing {C}hinese and {J}apanese Semantic Maps,2002,14,3,1,1,33252,qing ma,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper describes a corpus-based connectionist approach to the development of self-organizing Chinese and Japanese semantic maps, proposing an improved coding method using TFIDF term-weighting and newly introducing a numerical evaluation for objectively judging the results. The adaption of TFIDF term-weighting is proved to be effective by experimental comparisons with five other coding methods. The effectiveness and necessity of the proposed method for creating semantic maps are clarified by comparisons with a conventional clustering technique and multivariate statistical analysis."
2002.tmi-papers.14,Correction of errors in a modality corpus used for machine translation using machine-learning,2002,-1,-1,4,0.718013,16788,masaki murata,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
W01-1415,"Using a Support-Vector Machine for {J}apanese-to-{E}nglish Translation of Tense, Aspect, and Modality",2001,7,12,3,0.886975,16788,masaki murata,Proceedings of the {ACL} 2001 Workshop on Data-Driven Methods in Machine Translation,0,"This paper describes experiments carried out using a variety of machine-learning methods, including the k-nearest neighborhood method that was used in a previous study, for the translation of tense, aspect, and modality. It was found that the support-vector machine method was the most precise of all the methods tested."
S01-1033,{J}apanese Word Sense Disambiguation using the Simple {B}ayes and Support Vector Machine Methods,2001,2,16,4,0.886975,16788,masaki murata,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"We submitted four systems to the Japanese dictionary-based lexical-sample task of Senseval-2. They were i) the support vector machine method ii) the simple Bayes method, iii) a method combining the two, and iv) a method combining two kinds of each. The combined methods obtained the best precision among the submitted systems. After the contest, we tuned the parameter used in the simple Bayes method, and it obtained higher precision. An explanation of these systems used in Japanese word sense disambiguation was provided."
W00-0110,Similarities and Differences among Semantic Behaviors of {J}apanese Adnominal Constituents,2000,5,6,2,1,15923,kyoko kanzaki,{NAACL}-{ANLP} 2000 Workshop: Syntactic and Semantic Complexity in Natural Language Processing Systems,0,"This paper treats the classification of the semantic functions performed by adnominal constituents in Japanese, where many parts of speech act as adnominal constituents. In order to establish a formal treatment of the semantic roles, the similarities and differences among adnominal constituents, i.e. adjectives and noun  NO (in English of  noun) structures, which have a broad range of semantic functions, are discussed. This paper also proposes an objective method of classifying these constructs using a large amount of linguistic data. The feasibility of this was verified with a self-organizing semantic map based on a neural network model."
P00-1042,Named Entity Extraction Based on A Maximum Entropy Model and Transformation Rules,2000,13,63,2,0.775194,30019,kiyotaka uchimoto,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes named entity (NE) extraction based on a maximum entropy (M. E.) model and transformation rules. There are two types of named entities when focusing on the relationship between morphemes and NEs as defined in the NE task of the IREX competition held in 1999. Each NE consists of one or more morphemes, or includes a substring of a morpheme. We extract the former type of NE by using the M. E. model. We then extract the latter type of NE by applying transformation rules to the text."
C00-2126,Word Order Acquisition from Corpora,2000,2,18,3,0.775194,30019,kiyotaka uchimoto,{COLING} 2000 Volume 2: The 18th International Conference on Computational Linguistics,0,"In this paper we describe a method of acquiring word order from corpora. Word order is defined as the order of modifiers, or the order of phrasal units called 'bunsetsu' which depend on the same modifiee. The method uses a model which automatically discovers what the tendency of the word order in Japanese is by using various kinds of information in and around the target bunsetsus. This model shows us to what extent each piece of information contributes to deciding the word order and which word order tends to be selected when several kinds of information conflict. The contribution rate of each piece of information in deciding word order is efficiently learned by a model within a maximum entropy framework. The performance of this trained model can be evaluated by checking how many instances of word order selected by the model agree with those in the original text. In this paper, we show that even a raw corpus that has not been tagged can be used to train the model, if it is first analyzed by a parser. This is possible because the word order of the text in the corpus is correct."
C00-1074,Hybrid Neuro and Rule-Based Part of Speech Taggers,2000,6,13,1,1,33252,qing ma,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"A hybrid system for tagging part of speech is described that consists of a neuro tagger and a rule-based corrector. The neuro tagger is an initial-state annotator that uses different lengths of context based on longest context priority. Its inputs are weighted by information gains that are obtained by information maximization. The rule-based corrector is constructed by a set of transformation rules to make up for the shortcomings of the neuro tagger. Computer experiments show that almost 20% of the errors made by the neuro tagger are corrected by these transformation rules, so that the hybrid system can reach an accuracy of 95.5% counting only the ambiguous words and 99.1% counting all words when a small Thai corpus with 22,311 ambiguous words is used for training. This accuracy is far higher than that using an HMM and is also higher than that using a rule-based model."
C00-1082,Bunsetsu Identification Using Category-Exclusive Rules,2000,11,8,3,0.886975,16788,masaki murata,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"This paper describes two new bunsetsu identification methods using supervised learning. Since Japanese syntactic analysis is usually done after bunsetsu identification, bunsetsu identification is important for analyzing Japanese sentences. In experiments comparing the four previously available machine-learning methods (decision tree, maximum-entropy method, example-based approach and decision list) and two new methods using category-exclusive rules, the new method using the category-exclusive rules with the highest similarity performed best."
1999.tmi-1.7,"An example-based approach to {J}apanese-to-{E}nglish translation of tense, aspect, and modality",1999,3,16,2,0.772253,16788,masaki murata,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"We have developed a new method for Japanese-to-English translation of tense, aspect, and modality that uses an example-based method. In this method the similarity between input and example sentences is defined as the degree of semantic matching between the expressions at the ends of the sentences. Our method also uses the k-nearest neighbor method in order to exclude the effects of noise; for example, wrongly tagged data in the bilingual corpora. Experiments show that our method can translate tenses, aspects, and modalities more accurately than the top-level MT software currently available on the market can. Moreover, it does not require hand-craft rules."
P98-2131,A Multi-Neuro Tagger Using Variable Lengths of Contexts,1998,7,14,7,0,55263,susann luperfoy,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"This paper presents a multi-neuro tagger that uses variable lengths of contexts and weighted inputs (with information gains) for part of speech tagging. Computer experiments show that it has a correct rate of over 94% for tagging ambiguous words when a small Thai corpus with 22,311 ambiguous words is used for training. This result is better than any of the results obtained using the single-neuro taggers with fixed but different lengths of contexts, which indicates that the multi-neuro tagger can dynamically find a suitable length of contexts in tagging."
C98-2127,A Multi-Neuro Tagger Using Variable Lengths of Contexts,1998,7,14,1,1,33252,qing ma,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"This paper presents a multi-neuro tagger that uses variable lengths of contexts and weighted inputs (with information gains) for part of speech tagging. Computer experiments show that it has a correct rate of over 94% for tagging ambiguous words when a small Thai corpus with 22,311 ambiguous words is used for training. This result is better than any of the results obtained using the single-neuro taggers with fixed but different lengths of contexts, which indicates that the multi-neuro tagger can dynamically find a suitable length of contexts in tagging."
