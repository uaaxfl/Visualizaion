2021.wat-1.1,Overview of the 8th Workshop on {A}sian Translation,2021,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"This paper presents the results of the shared tasks from the 8th workshop on Asian translation (WAT2021). For the WAT2021, 28 teams participated in the shared tasks and 24 teams submitted their translation results for the human evaluation. We also accepted 5 research papers. About 2,100 translation results were submitted to the automatic evaluation server, and selected submissions were manually evaluated."
2021.wat-1.11,Zero-pronoun Data Augmentation for {J}apanese-to-{E}nglish Translation,2021,-1,-1,2,1,337,ryokan ri,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"For Japanese-to-English translation, zero pronouns in Japanese pose a challenge, since the model needs to infer and produce the corresponding pronoun in the target side of the English sentence. However, although fully resolving zero pronouns often needs discourse context, in some cases, the local context within a sentence gives clues to the inference of the zero pronoun. In this study, we propose a data augmentation method that provides additional training signals for the translation model to learn correlations between local context and zero pronouns. We show that the proposed method significantly improves the accuracy of zero pronoun translation with machine translation experiments in the conversational domain."
2021.mtsummit-research.19,Modeling Target-side Inflection in Placeholder Translation,2021,-1,-1,2,1,337,ryokan ri,Proceedings of Machine Translation Summit XVIII: Research Track,0,Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence. The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token. However and this approach could result in ungrammatical sentences because it is often the case that the specified term needs to be inflected according to the context of the output and which is unknown before the translation. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence. We extend the seq2seq architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output a correct inflected form of the lemma. We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain and and show our model can incorporate specified terms in a correct form more successfully than other comparable models.
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,18,0,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.wmt-1.74,Document-aligned {J}apanese-{E}nglish Conversation Parallel Corpus,2020,-1,-1,4,1,13897,matiss rikters,Proceedings of the Fifth Conference on Machine Translation,0,"Sentence-level (SL) machine translation (MT) has reached acceptable quality for many high-resourced languages, but not document-level (DL) MT, which is difficult to 1) train with little amount of DL data; and 2) evaluate, as the main methods and data sets focus on SL evaluation. To address the first issue, we present a document-aligned Japanese-English conversation corpus, including balanced, high-quality business conversation data for tuning and testing. As for the second issue, we manually identify the main areas where SL MT fails to produce adequate translations in lack of context. We then create an evaluation set where these phenomena are annotated to alleviate automatic evaluation of DL systems. We train MT models using our corpus to demonstrate how using context leads to improvements."
2020.wat-1.1,Overview of the 7th Workshop on {A}sian Translation,2020,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of the 7th Workshop on Asian Translation,0,"This paper presents the results of the shared tasks from the 7th workshop on Asian translation (WAT2020). For the WAT2020, 20 teams participated in the shared tasks and 14 teams submitted their translation results for the human evaluation. We also received 12 research paper submissions out of which 7 were accepted. About 500 translation results were submitted to the automatic evaluation server, and selected submissions were manually evaluated."
2020.wat-1.18,The {U}niversity of {T}okyo{'}s Submissions to the {WAT} 2020 Shared Task,2020,-1,-1,2,1,13897,matiss rikters,Proceedings of the 7th Workshop on Asian Translation,0,"The paper describes the development process of the The University of Tokyo{'}s NMT systems that were submitted to the WAT 2020 Document-level Business Scene Dialogue Translation sub-task. We describe the data processing workflow, NMT system training architectures, and automatic evaluation results. For the WAT 2020 shared task, we submitted 12 systems (both constrained and unconstrained) for English-Japanese and Japanese-English translation directions. The submitted systems were trained using Transformer models and one was a SMT baseline."
2020.lrec-1.447,Evaluation Dataset for Zero Pronoun in {J}apanese to {E}nglish Translation,2020,-1,-1,3,0,17595,sho shimazu,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In natural language, we often omit some words that are easily understandable from the context. In particular, pronouns of subject, object, and possessive cases are often omitted in Japanese; these are known as zero pronouns. In translation from Japanese to other languages, we need to find a correct antecedent for each zero pronoun to generate a correct and coherent translation. However, it is difficult for conventional automatic evaluation metrics (e.g., BLEU) to focus on the success of zero pronoun resolution. Therefore, we present a hand-crafted dataset to evaluate whether translation models can resolve the zero pronoun problems in Japanese to English translations. We manually and statistically validate that our dataset can effectively evaluate the correctness of the antecedents selected in translations. Through the translation experiments using our dataset, we reveal shortcomings of an existing context-aware neural machine translation model."
2020.lrec-1.459,{TDDC}: Timely Disclosure Documents Corpus,2020,-1,-1,3,0,17604,nobushige doi,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper, we describe the details of the Timely Disclosure Documents Corpus (TDDC). TDDC was prepared by manually aligning the sentences from past Japanese and English timely disclosure documents in PDF format published by companies listed on the Tokyo Stock Exchange. TDDC consists of approximately 1.4 million parallel sentences in Japanese and English. TDDC was used as the official dataset for the 6th Workshop on Asian Translation to encourage the development of machine translation."
D19-5201,Overview of the 6th Workshop on {A}sian Translation,2019,0,1,1,1,283,toshiaki nakazawa,Proceedings of the 6th Workshop on Asian Translation,0,"This paper presents the results of the shared tasks from the 6th workshop on Asian translation (WAT2019) including JaâEn, JaâZh scientific paper translation subtasks, JaâEn, JaâKo, JaâEn patent translation subtasks, HiâEn, MyâEn, KmâEn, TaâEn mixed domain subtasks and RuâJa news commentary translation task. For the WAT2019, 25 teams participated in the shared tasks. We also received 10 research paper submissions out of which 61 were accepted. About 400 translation results were submitted to the automatic evaluation server, and selected submis- sions were manually evaluated."
D19-5204,Designing the Business Conversation Corpus,2019,0,0,4,1,13897,matiss rikters,Proceedings of the 6th Workshop on Asian Translation,0,"While the progress of machine translation of written text has come far in the past several years thanks to the increasing availability of parallel corpora and corpora-based training technologies, automatic translation of spoken text and dialogues remains challenging even for modern systems. In this paper, we aim to boost the machine translation quality of conversational texts by introducing a newly constructed Japanese-English business conversation parallel corpus. A detailed analysis of the corpus is provided along with challenging examples for automatic translation. We also experiment with adding the corpus in a machine translation training scenario and show how the resulting system benefits from its use."
Y18-3001,Overview of the 5th Workshop on {A}sian Translation,2018,0,5,1,1,283,toshiaki nakazawa,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation: 5th Workshop on Asian Translation: 5th Workshop on Asian Translation",0,None
W17-5701,Overview of the 4th Workshop on {A}sian Translation,2017,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of the 4th Workshop on {A}sian Translation ({WAT}2017),0,"This paper presents the results of the shared tasks from the 4th workshop on Asian translation (WAT2017) including JâE, JâC scientific paper translation subtasks, CâJ, KâJ, EâJ patent translation subtasks, HâE mixed domain subtasks, JâE newswire subtasks and JâE recipe subtasks. For the WAT2017, 12 institutions participated in the shared tasks. About 300 translation results have been submitted to the automatic evaluation server, and selected submissions were manually evaluated."
W17-5714,{K}yoto {U}niversity Participation to {WAT} 2017,2017,-1,-1,3,0.790475,17599,fabien cromieres,Proceedings of the 4th Workshop on {A}sian Translation ({WAT}2017),0,"We describe here our approaches and results on the WAT 2017 shared translation tasks. Following our good results with Neural Machine Translation in the previous shared task, we continue this approach this year, with incremental improvements in models and training methods. We focused on the ASPEC dataset and could improve the state-of-the-art results for Chinese-to-Japanese and Japanese-to-Chinese translations."
I17-5004,"Neural Machine Translation: Basics, Practical Aspects and Recent Trends",2017,0,0,2,0.790475,17599,fabien cromieres,"Proceedings of the {IJCNLP} 2017, Tutorial Abstracts",0,"Machine Translation (MT) is a sub-field of NLP which has experienced a number of paradigm shifts since its inception. Up until 2014, Phrase Based Statistical Machine Translation (PBSMT) approaches used to be the state of the art. In late 2014, Neural Machine Translation (NMT) was introduced and was proven to outperform all PBSMT approaches by a significant margin. Since then, the NMT approaches have undergone several transformations which have pushed the state of the art even further. This tutorial is primarily aimed at researchers who are either interested in or are fairly new to the world of NMT and want to obtain a deep understanding of NMT fundamentals. Because it will also cover the latest developments in NMT, it should also be useful to attendees with some experience in NMT."
W16-5407,{SCTB}: A {C}hinese Treebank in Scientific Domain,2016,0,0,2,1,293,chenhui chu,Proceedings of the 12th Workshop on {A}sian Language Resources ({ALR}12),0,"Treebanks are curial for natural language processing (NLP). In this paper, we present our work for annotating a Chinese treebank in scientific domain (SCTB), to address the problem of the lack of Chinese treebanks in this domain. Chinese analysis and machine translation experiments conducted using this treebank indicate that the annotated treebank can significantly improve the performance on both tasks. This treebank is released to promote Chinese NLP research in scientific domain."
W16-4601,Overview of the 3rd Workshop on {A}sian Translation,2016,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of the 3rd Workshop on {A}sian Translation ({WAT}2016),0,"This paper presents the results of the shared tasks from the 3rd workshop on Asian translation (WAT2016) including J â E, J â C scientific paper translation subtasks, C â J, K â J, E â J patent translation subtasks, I â E newswire subtasks and H â E, H â J mixed domain subtasks. For the WAT2016, 15 institutions participated in the shared tasks. About 500 translation results have been submitted to the automatic evaluation server, and selected submissions were manually evaluated."
W16-4616,{K}yoto {U}niversity Participation to {WAT} 2016,2016,0,11,3,0.790475,17599,fabien cromieres,Proceedings of the 3rd Workshop on {A}sian Translation ({WAT}2016),0,"We describe here our approaches and results on the WAT 2016 shared translation tasks. We tried to use both an example-based machine translation (MT) system and a neural MT system. We report very good translation results, especially when using neural MT for Chinese-to-Japanese translation."
P16-3002,Dependency Forest based Word Alignment,2016,20,0,3,0,34384,hitoshi otsuki,Proceedings of the {ACL} 2016 Student Research Workshop,0,"A hierarchical word alignment model that searches for k-best partial alignments on target constituent 1-best parse trees has been shown to outperform previous models. However, relying solely on 1-best parses trees might hinder the search for good alignments because 1-best trees are not necessarily the best for word alignment tasks in practice. This paper introduces a dependency forest based word alignment model, which utilizes target dependency forests in an attempt to minimize the impact on limitations attributable to 1-best parse trees. We present how k-best alignments are constructed over target-side dependency forests. Alignment experiments on the Japanese-English language pair show a relative error reduction of 4% of the alignment score compared to a model with 1-best parse trees."
N16-1002,Flexible Non-Terminals for Dependency Tree-to-Tree Reordering,2016,0,1,3,1,30411,john richardson,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
L16-1348,Simultaneous Sentence Boundary Detection and Alignment with Pivot-based Machine Translation Generated Lexicons,2016,10,1,3,0,35088,antoine bourlon,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Sentence alignment is a task that consists in aligning the parallel sentences in a translated article pair. This paper describes a method to perform sentence boundary detection and alignment simultaneously, which significantly improves the alignment accuracy on languages like Chinese with uncertain sentence boundaries. It relies on the definition of hard (certain) and soft (uncertain) punctuation delimiters, the latter being possibly ignored to optimize the alignment result. The alignment method is used in combination with lexicons automatically generated from the input article pairs using pivot-based MT, achieving better coverage of the input words with fewer entries than pre-existing dictionaries. Pivot-based MT makes it possible to build dictionaries for language pairs that have scarce parallel data. The alignment method is implemented in a tool that will be freely available in the near future."
L16-1350,{ASPEC}: {A}sian Scientific Paper Excerpt Corpus,2016,0,24,1,1,283,toshiaki nakazawa,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we describe the details of the ASPEC (Asian Scientific Paper Excerpt Corpus), which is the first large-size parallel corpus of scientific paper domain. ASPEC was constructed in the Japanese-Chinese machine translation project conducted between 2006 and 2010 using the Special Coordination Funds for Promoting Science and Technology. It consists of a Japanese-English scientific paper abstract corpus of approximately 3 million parallel sentences (ASPEC-JE) and a Chinese-Japanese scientific paper excerpt corpus of approximately 0.68 million parallel sentences (ASPEC-JC). ASPEC is used as the official dataset for the machine translation evaluation workshop WAT (Workshop on Asian Translation)."
D16-1049,{IRT}-based Aggregation Model of Crowdsourced Pairwise Comparison for Evaluating Machine Translations,2016,13,0,2,0,20394,naoki otani,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
D16-1247,Insertion Position Selection Model for Flexible Non-Terminals in Dependency Tree-to-Tree Machine Translation,2016,13,1,1,1,283,toshiaki nakazawa,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
Y15-1033,Large-scale Dictionary Construction via Pivot-based Statistical Machine Translation with Significance Pruning and Neural Network Features,2015,15,0,4,0.487805,286,raj dabre,"Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation",0,"We present our ongoing work on large-scale Japanese-Chinese bilingual dictionary construction via pivot-based statistical machine translation. We utilize statistical significance pruning to control noisy translation pairs that are induced by pivoting. We construct a large dictionary which we manually verify to be of a high quality. We then use this dictionary and a parallel corpus to learn bilingual neural network language models to obtain features for reranking the n-best list, which leads to an absolute improvement of 5% in accuracy when compared to a setting that does not use significance pruning and reranking."
Y15-1042,Pivot-Based Topic Models for Low-Resource Lexicon Extraction,2015,15,1,2,1,30411,john richardson,"Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation",0,"This paper proposes a range of solutions to the challenges of extracting large and highquality bilingual lexicons for low-resource language pairs. In such scenarios there is often no parallel or even comparable data available. We design three effective pivotbased approaches inspired by the state-ofthe-art technique of bilingual topic modelling, extending previous work to take advantage of trilingual data. The proposed models are shown to outperform traditional methods significantly and can be adapted based upon the nature of available training data. We demonstrate the accuracy of these pivot-based approaches in a realistic scenario generating an IcelandicKorean lexicon from Wikipedia."
W15-5001,Overview of the 2nd Workshop on {A}sian Translation,2015,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of the 2nd Workshop on {A}sian Translation ({WAT}2015),0,None
W15-5006,{K}yoto{EBMT} System Description for the 2nd Workshop on {A}sian Translation,2015,-1,-1,5,1,30411,john richardson,Proceedings of the 2nd Workshop on {A}sian Translation ({WAT}2015),0,None
2015.mtsummit-wpslt.5,Promoting science and technology exchange using machine translation,2015,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of the 6th Workshop on Patent and Scientific Literature Translation,0,None
2015.mtsummit-wpslt.7,Enhancing function word translation with syntax-based statistical post-editing,2015,-1,-1,2,1,30411,john richardson,Proceedings of the 6th Workshop on Patent and Scientific Literature Translation,0,None
2015.mtsummit-papers.20,{K}orean-{C}hinese word translation using {C}hinese character knowledge,2015,-1,-1,2,0,37941,yuanmei lu,Proceedings of Machine Translation Summit XV: Papers,0,None
Y14-1032,Improving Statistical Machine Translation Accuracy Using Bilingual Lexicon Extractionwith Paraphrases,2014,30,2,2,1,293,chenhui chu,"Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing",0,"Statistical machine translation (SMT) suffers from theaccuracy problemthat the translation pairs and their feature scores in the transla- tion model can be inaccurate. Theaccuracy problemis caused by the quality of the unsu- pervised methods used for translation model learning. Previous studies propose estimating comparable features for the translation pairs in the translation model from comparable cor- pora, to improve the accuracy of the transla- tion model. Comparable feature estimation is based on bilingual lexicon extraction (BLE) technology. However, BLE suffers from the data sparseness problem, which makes the comparable features inaccurate. In this paper, we propose using paraphrases to address this problem. Paraphrases are used to smooth the vectors used in comparable feature estimation with BLE. In this way, we improve the qual- ity of comparable features, which can improve the accuracy of the translation model thus im- prove SMT performance. Experiments con- ducted on Chinese-English phrase-based SMT (PBSMT) verify the effectiveness of our pro- posed method."
W14-7001,Overview of the 1st Workshop on {A}sian Translation,2014,26,27,1,1,283,toshiaki nakazawa,Proceedings of the 1st Workshop on {A}sian Translation ({WAT}2014),0,None
W14-7012,{K}yoto{EBMT} System Description for the 1st Workshop on {A}sian Translation,2014,17,2,3,1,30411,john richardson,Proceedings of the 1st Workshop on {A}sian Translation ({WAT}2014),0,"This paper introduces the KyotoEBMT Example-Based Machine Translation framework. Our system uses a tree-to-tree approach, employing syntactic dependency analysis for both source and target languages in an attempt to preserve non-local structure. The effectiveness of our system is maximized with online example matching and a flexible decoder. Evaluation demonstrates BLEU scores competitive with state-of-the-art SMT baselines. The system implementation is available as open-source."
P14-5014,{K}yoto{EBMT}: An Example-Based Dependency-to-Dependency Translation Framework,2014,16,5,3,1,30411,john richardson,Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"This paper introduces the KyotoEBMT Example-Based Machine Translation framework. Our system uses a tree-to-tree approach, employing syntactic dependency analysis for both source and target languages in an attempt to preserve non-local structure. The effectiveness of our system is maximized with online example matching and a flexible decoder. Evaluation demonstrates BLEU scores competitive with state-of-the-art SMT systems such as Moses. The current implementation is intended to be released as open-source in the near future."
richardson-etal-2014-bilingual,Bilingual Dictionary Construction with Transliteration Filtering,2014,9,1,2,1,30411,john richardson,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper we present a bilingual transliteration lexicon of 170K Japanese-English technical terms in the scientific domain. Translation pairs are extracted by filtering a large list of transliteration candidates generated automatically from a phrase table trained on parallel corpora. Filtering uses a novel transliteration similarity measure based on a discriminative phrase-based machine translation approach. We demonstrate that the extracted dictionary is accurate and of high recall (F1 score 0.8). Our lexicon contains not only single words but also multi-word expressions, and is freely available. Our experiments focus on Katakana-English lexicon construction, however it would be possible to apply the proposed methods to transliteration extraction for a variety of language pairs."
chu-etal-2014-constructing,Constructing a {C}hinese{---}{J}apanese Parallel Corpus from {W}ikipedia,2014,11,9,2,1,293,chenhui chu,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Parallel corpora are crucial for statistical machine translation (SMT). However, they are quite scarce for most language pairs, such as ChineseâJapanese. As comparable corpora are far more available, many studies have been conducted to automatically construct parallel corpora from comparable corpora. This paper presents a robust parallel sentence extraction system for constructing a ChineseâJapanese parallel corpus from Wikipedia. The system is inspired by previous studies that mainly consist of a parallel sentence candidate filter and a binary classifier for parallel sentence identification. We improve the system by using the common Chinese characters for filtering and two novel feature sets for classification. Experiments show that our system performs significantly better than the previous studies for both accuracy in parallel sentence extraction and SMT performance. Using the system, we construct a ChineseâJapanese parallel corpus with more than 126k highly accurate parallel sentences from Wikipedia. The constructed parallel corpus is freely available at http://orchid.kuee.kyoto-u.ac.jp/{\textasciitilde}chu/resource/wiki{\_}zh{\_}ja.tgz."
2014.amta-wptp.15,Post-editing user interface using visualization of a sentence structure,2014,-1,-1,2,0,16897,yudai kishimoto,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas,0,"Translation has become increasingly important by virtue of globalization. To reduce the cost of translation, it is necessary to use machine translation and further to take advantage of post-editing based on the result of a machine translation for accurate information dissemination. Such post-editing (e.g., PET [Aziz et al., 2012]) can be used practically for translation between European languages, which has a high performance in statistical machine translation. However, due to the low accuracy of machine translation between languages with different word order, such as Japanese-English and Japanese-Chinese, post-editing has not been used actively."
W13-2505,{C}hinese{--}{J}apanese Parallel Sentence Extraction from Quasi{--}Comparable Corpora,2013,18,8,2,1,293,chenhui chu,Proceedings of the Sixth Workshop on Building and Using Comparable Corpora,0,"Parallel sentences are crucial for statistical machine translation (SMT). However, they are quite scarce for most language pairs, such as Chinesexe2x80x90Japanese. Many studies have been conducted on extracting parallel sentences from noisy parallel or comparable corpora. We extract Chinesexe2x80x90Japanese parallel sentences from quasixe2x80x90comparable corpora, which are available in far larger quantities. The task is significantly more difficult than the extraction from noisy parallel or comparable corpora. We extend a previous study that treats parallel sentence identification as a binary classification problem. Previous method of classifier training by the Cartesian product is not practical, because it differs from the real process of parallel sentence extraction. We propose a novel classifier training method that simulates the real sentence extraction process. Furthermore, we use linguistic knowledge of Chinese character features. Experimental results on quasixe2x80x90 comparable corpora indicate that our proposed approach performs significantly better than the previous study."
I13-1030,Robust Transliteration Mining from Comparable Corpora with Bilingual Topic Models,2013,25,6,2,1,30411,john richardson,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We present a high-precision, languageindependent transliteration framework applicable to bilingual lexicon extraction. Our approach is to employ a bilingual topic model to enhance the output of a state-of-the-art graphemebased transliteration baseline. We demonstrate that this method is able to extract a high-quality bilingual lexicon from a comparable corpus, and we extend the topic model to propose a solution to the out-of-domain problem."
I13-1163,Accurate Parallel Fragment Extraction from Quasi{--}Comparable Corpora using Alignment Model and Translation Lexicon,2013,15,10,2,1,293,chenhui chu,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Although parallel sentences rarely exist in quasixe2x80x90comparable corpora, there could be parallel fragments that are also helpful for statistical machine translation (SMT). Previous studies cannot accurately extract parallel fragments from quasixe2x80x90comparable corpora. To solve this problem, we propose an accurate parallel fragment extraction system that uses an alignment model to locate the parallel fragment candidates, and uses an accurate lexicon filter to identify the truly parallel ones. Experimental results indicate that our system can accurately extract parallel fragments, and our proposed method significantly outperforms a statexe2x80x90ofxe2x80x90thexe2x80x90art approach. Furthermore, we investigate the factors that may affect the performance of our system in detail."
chu-etal-2012-chinese,"{C}hinese Characters Mapping Table of {J}apanese, Traditional {C}hinese and Simplified {C}hinese",2012,6,7,2,1,293,chenhui chu,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Chinese characters are used both in Japanese and Chinese, which are called Kanji and Hanzi respectively. Chinese characters contain significant semantic information, a mapping table between Kanji and Hanzi can be very useful for many Japanese-Chinese bilingual applications, such as machine translation and cross-lingual information retrieval. Because Kanji characters are originated from ancient China, most Kanji have corresponding Chinese characters in Hanzi. However, the relation between Kanji and Hanzi is quite complicated. In this paper, we propose a method of making a Chinese characters mapping table of Japanese, Traditional Chinese and Simplified Chinese automatically by means of freely available resources. We define seven categories for Kanji based on the relation between Kanji and Hanzi, and classify mappings of Chinese characters into these categories. We use a resource from Wiktionary to show the completeness of the mapping table we made. Statistical comparison shows that our proposed method makes a more complete mapping table than the current version of Wiktionary."
C12-1120,Alignment by Bilingual Generation and Monolingual Derivation,2012,21,8,1,1,283,toshiaki nakazawa,Proceedings of {COLING} 2012,0,"One of the main issues in a word alignment task is the difficulty of handling function words that do not have direct translations which we call unique function words. They are often aligned to some words in the other language incorrectly. This is prominent in language pairs with very different sentence structures. In this paper, we propose a novel approach for handling unique function words. The proposed model monolingually derives unique function words from bilingually generated treelet pairs. The monolingual derivation prevents incorrect alignments for unique function words. The derivation probabilities are estimated from a large monolingual corpus, which is much easier to acquire than a parallel corpus. Also, the proposed alignment model uses semantic-head dependency trees where dependency relations between words become similar in each language. Experimental results on an English-Japanese corpus show that the proposed model achieves better alignment and translation quality compared with the baseline models."
2012.iwslt-evaluation.12,{EBMT} system of {K}yoto {U}niversity in {OLYMPICS} task at {IWSLT} 2012,2012,15,1,2,1,293,chenhui chu,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the EBMT system of Kyoto University that participated in the OLYMPICS task at IWSLT 2012. When translating very different language pairs such as Chinese-English, it is very important to handle sentences in tree structures to overcome the difference. Many recent studies incorporate tree structures in some parts of translation process, but not all the way from model training (alignment) to decoding. Our system is a fully tree-based translation system where we use the Bayesian phrase alignment model on dependency trees and example-based translation. To improve the translation quality, we conduct some special processing for the IWSLT 2012 OLYMPICS task, including sub-sentence splitting, non-parallel sentence filtering, adoption of an optimized Chinese segmenter and rule-based decoding constraints."
2012.eamt-1.7,Exploiting Shared {C}hinese Characters in {C}hinese Word Segmentation Optimization for {C}hinese-{J}apanese Machine Translation,2012,14,15,2,1,293,chenhui chu,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"Unknown words and word segmentation granularity are two main problems in Chinese word segmentation for ChineseJapanese Machine Translation (MT). In this paper, we propose an approach of exploiting common Chinese characters shared between Chinese and Japanese in Chinese word segmentation optimization for MT aiming to solve these problems. We augment the system dictionary of a Chinese segmenter by extracting Chinese lexicons from a parallel training corpus. In addition, we adjust the granularity of the training data for the Chinese segmenter to that of Japanese. Experimental results of Chinese-Japanese MT on a phrase-based SMT system show that our approach improves MT performance significantly."
I11-1089,{B}ayesian Subtree Alignment Model based on Dependency Trees,2011,19,11,1,1,283,toshiaki nakazawa,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Word sequential alignment models work well for similar language pairs, but they are quite inadequate for distant language pairs. It is difficult to align words or phrases of distant languages with high accuracy without structural information of the sentences. In this paper, we pro- pose a Bayesian subtree alignment model that incorporates dependency relations be- tween subtrees in dependency tree struc- tures on both sides. The dependency re- lation model is a kind of tree-based re- ordering model, and can handle non-local reorderings, which sequential word-based models often cannot handle properly. The model is also capable of handling multilevel structures, making it possible to find many-to-many correspondences automatically without any heuristic rules. The size of the structures is controlled by nonparametric Bayesian priors. Experimental alignment results show that our model achieves 3.5 points better alignment error rate for English-Japanese than the word sequential alignment model, thereby verifying that the use of dependency information is effective for structurally different language pairs."
2011.mtsummit-papers.53,{J}apanese-{C}hinese Phrase Alignment Using Common {C}hinese Characters Information,2011,-1,-1,2,1,293,chenhui chu,Proceedings of Machine Translation Summit XIII: Papers,0,None
W09-2302,Statistical Phrase Alignment Model Using Dependency Relation Probability,2009,14,4,1,1,283,toshiaki nakazawa,Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation ({SSST}-3) at {NAACL} {HLT} 2009,0,"When aligning very different language pairs, the most important needs are the use of structural information and the capability of generating one-to-many or many-to-many correspondences. In this paper, we propose a novel phrase alignment method which models word or phrase dependency relations in dependency tree structures of source and target languages. The dependency relation model is a kind of tree-based reordering model, and can handle non-local reorderings which sequential word-based models often cannot handle properly. The model is also capable of estimating phrase correspondences automatically without any heuristic rules. Experimental results of alignment show that our model could achieve F-measure 1.7 points higher than the conventional word alignment model with symmetrization algorithms"
2008.amta-papers.15,Linguistically-motivated Tree-based Probabilistic Phrase Alignment,2008,17,5,1,1,283,toshiaki nakazawa,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In this paper, we propose a probabilistic phrase alignment model based on dependency trees. This model is linguistically-motivated, using syntactic information during alignment process. The main advantage of this model is that the linguistic difference between source and target languages is successfully absorbed. It is composed of two models: Model1 is using content word translation probability and function word translation probability; Model2 uses dependency relation probability which is defined for a pair of positional relations on dependency trees. Relation probability acts as tree-based phrase reordering model. Since this model is directed, we combine two alignment results from bi-directional training by symmetrization heuristics to get definitive alignment. We conduct experiments on a Japanese-English corpus, and achieve reasonably high quality of alignment compared with word-based alignment model."
2007.mtsummit-papers.45,Structural phrase alignment based on consistency criteria,2007,-1,-1,1,1,283,toshiaki nakazawa,Proceedings of Machine Translation Summit XI: Papers,0,None
W06-0123,{C}hinese Word Segmentation and Named Entity Recognition by Character Tagging,2006,10,2,4,0,44132,kun yu,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper describes our word segmentation system and named entity recognition (NER) system for participating in the third SIGHAN Bakeoff. Both of them are based on character tagging, but use different tag sets and different features. Evaluation results show that our word segmentation system achieved 93.3% and 94.7% F-score in UPUC and MSRA open tests, and our NER system got 70.84% and 81.32% F-score in LDC and MSRA open tests."
2006.iwslt-evaluation.9,Example-based machine translation based on deeper {NLP},2006,11,15,1,1,283,toshiaki nakazawa,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,This paper describes our Kyoto-U system that attended the IWSLT06 Japanese-English machine translation task. Example-based machine translation is applied in this system to integrate our study on both structural NLP and machine translation.
I05-1060,Automatic Acquisition of Basic Katakana Lexicon from a Given Corpus,2005,7,8,1,1,283,toshiaki nakazawa,Second International Joint Conference on Natural Language Processing: Full Papers,0,"Katakana, Japanese phonogram mainly used for loan words, is a troublemaker in Japanese word segmentation. Since Katakana words are heavily domain-dependent and there are many Katakana neologisms, it is almost impossible to construct and maintain Katakana word dictionary by hand. This paper proposes an automatic segmentation method of Japanese Katakana compounds, which makes it possible to construct precise and concise Katakana word dictionary automatically, given only a medium or large size of Japanese corpus of some domain."
2005.iwslt-1.27,Example-based Machine Translation Pursuing Fully Structural {NLP},2005,7,6,2,0,297,sadao kurohashi,Proceedings of the Second International Workshop on Spoken Language Translation,0,We are conducting Example-Based Machine Translation research aiming at the improvement both of structural NLP and machine translation. This paper describes UTokyo system challenged IWSLT05 Japanese-English translation tasks.
