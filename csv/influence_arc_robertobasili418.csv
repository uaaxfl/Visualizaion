2020.acl-main.191,P17-1032,1,0.853053,"gh-quality representations of input texts and to adopt unlabeled material to help the network in 1 The code is available at https://github.com/ crux82/ganbert. 2114 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2114–2119 c July 5 - 10, 2020. 2020 Association for Computational Linguistics generalizing its representations for the final tasks. At the best of our knowledge, using SS-GANs in NLP has been investigated only by (Croce et al., 2019) with the so-called Kernel-based GAN. In that work, authors extend a Kernel-based Deep Architecture (KDA, (Croce et al., 2017)) with an SS-GAN perspective. Sentences are projected into low-dimensional embeddings, which approximate the implicit space generated by using a Semantic Tree Kernel function. However, it only marginally investigated how the GAN perspective could extend deep architecture for NLP tasks. In particular, a KGAN operates in a pre-computed embedding space by approximating a kernel function (Annesi et al., 2014). While the SS-GAN improves the quality of the Multi-layered Perceptron used in the KDA, it does not affect the input representation space, which is statically derived by the kernel space appr"
2020.acl-main.191,N19-1423,0,0.406846,"t the requirement for annotated examples can be drastically reduced (up to only 50-100 annotated examples), still obtaining good performances in several sentence classification tasks. 1 Roberto Basili Dept. of Enterprise Engineering University of Rome, Tor Vergata Roma, Italy Introduction In recent years, Deep Learning methods have become very popular in Natural Language Processing (NLP), e.g., they reach high performances by relying on very simple input representations (for example, in (Kim, 2014; Goldberg, 2016; Kim et al., 2016)). In particular, Transformer-based architectures, e.g., BERT (Devlin et al., 2019), provide representations of their inputs as a result of a pre-training stage. These are, in fact, trained over large scale corpora and then effectively finetuned over a targeted task achieving state-of-the-art results in different and heterogeneous NLP tasks. These achievements are obtained when thousands of annotated examples exist for the final tasks. As experimented in this work, the quality of BERT fine-tuned over less than 200 annotated instances shows significant drops, especially in classification tasks involving many categories. Unfortunately, obtaining annotated data is a time-consum"
2020.acl-main.191,D13-1170,0,0.0117729,"following, we will refer to this architecture as GAN-BERT. 4 Experimental Results In this section, we assess the impact of GAN-BERT over sentence classification tasks characterized by different training conditions, i.e., number of examples and number of categories. We report measures of our approach to support the development of deep learning models when exposed to few labeled examples over the following tasks: Topic Classification over the 20 News Group (20N) dataset (Lang, 1995), Question Classification (QC) on the UIUC dataset (Li and Roth, 2006), Sentiment Analysis over the SST-5 dataset (Socher et al., 2013). We 2 During the forward step, when real instances are sampled (i.e., h∗ = hCLS ), D should classify them in one of the k categories; when h∗ = hf ake , it should classify each example in the k + 1 category. As discussed in section 2, the training process tries G From a computational perspective, the additional cost of G is negligible in terms of network parameters: it is an MLP which takes in input random vectors of 100 dimensions and produces in output vectors in the same 768-dimensional space of BERT. In other words, it is characterized by about 100 thousand parameters that are much less t"
2020.acl-main.191,D14-1181,0,0.0305448,"T-like architectures with unlabeled data in a generative adversarial setting. Experimental results show that the requirement for annotated examples can be drastically reduced (up to only 50-100 annotated examples), still obtaining good performances in several sentence classification tasks. 1 Roberto Basili Dept. of Enterprise Engineering University of Rome, Tor Vergata Roma, Italy Introduction In recent years, Deep Learning methods have become very popular in Natural Language Processing (NLP), e.g., they reach high performances by relying on very simple input representations (for example, in (Kim, 2014; Goldberg, 2016; Kim et al., 2016)). In particular, Transformer-based architectures, e.g., BERT (Devlin et al., 2019), provide representations of their inputs as a result of a pre-training stage. These are, in fact, trained over large scale corpora and then effectively finetuned over a targeted task achieving state-of-the-art results in different and heterogeneous NLP tasks. These achievements are obtained when thousands of annotated examples exist for the final tasks. As experimented in this work, the quality of BERT fine-tuned over less than 200 annotated instances shows significant drops,"
2020.acl-main.191,N18-1101,0,0.0678599,"Missing"
2021.acl-short.106,P15-1166,0,0.0362307,"ed to Computer Vision, is still nascent (Greco et al., 2019; Sun et al., 2020). This reflects in the small number of proposed methods to alleviate CF, as discussed in Biesialska et al. (2020). In this context, some works focus on the Online Learning aspect of the CL (Filice et al., 2014). In NLP, KD has been mainly adopted to compress models (Kim and Rush, 2016; Sanh et al., 2019), and was only recently applied for CL in Named Entity Recognition (Monaikul et al., 2021). In the context of multilingual analysis, most of the works leverage Domain Adaptation techniques within Machine Translation (Dong et al., 2015; Firat et al., 2016; Ha et al., 2016; Johnson et al., 2017; Tan et al., 2019) in order to apply a machine translation model to an increasing set of languages. To the best of our knowledge, this is the first work adopting CL to mitigate CF when training Transformer-based models in an incremental number of languages for semantic processing tasks. 3 CL for Multilingual processing Multilingual Continual Learning. In the targeted scenario, we have a multilingual neural model, namely MLA , originally pre-trained on a set of languages LP = {l1 , l2 , . . .} (such as multilingual BERT (Pires et al.,"
2021.acl-short.106,N16-1101,0,0.0208345,"on, is still nascent (Greco et al., 2019; Sun et al., 2020). This reflects in the small number of proposed methods to alleviate CF, as discussed in Biesialska et al. (2020). In this context, some works focus on the Online Learning aspect of the CL (Filice et al., 2014). In NLP, KD has been mainly adopted to compress models (Kim and Rush, 2016; Sanh et al., 2019), and was only recently applied for CL in Named Entity Recognition (Monaikul et al., 2021). In the context of multilingual analysis, most of the works leverage Domain Adaptation techniques within Machine Translation (Dong et al., 2015; Firat et al., 2016; Ha et al., 2016; Johnson et al., 2017; Tan et al., 2019) in order to apply a machine translation model to an increasing set of languages. To the best of our knowledge, this is the first work adopting CL to mitigate CF when training Transformer-based models in an incremental number of languages for semantic processing tasks. 3 CL for Multilingual processing Multilingual Continual Learning. In the targeted scenario, we have a multilingual neural model, namely MLA , originally pre-trained on a set of languages LP = {l1 , l2 , . . .} (such as multilingual BERT (Pires et al., 2019)) and already f"
2021.acl-short.106,P19-1350,0,0.0282072,"Missing"
2021.acl-short.106,2020.acl-main.740,0,0.0556723,"Missing"
2021.acl-short.106,2020.emnlp-main.369,0,0.0218729,"denoted with Self-Training: at step k, Mk−1 is used to annotate the dataset (1) using Sk = S{lk } ∪ S˜k with the task loss LT . We denote with CL-KD the strategy we propose, where at step k, Mk−1 is used as the teacher in our proposed KD schema2 . Mk−1 is used to derive the target output distribution of the dataset Experimental Evaluation This section presents the results of the proposed CL strategy over three semantic processing tasks, involving text classification and sequence tagging. In particular, we report the Mean Absolute Error (MAE) over the Multilingual Amazon Review Corpus (MARC) (Keung et al., 2020), i.e., a 5 category Sentiment Analysis task in 6 languages. We report the Accuracy over a sentence-pair classification task, i.e., Paraphrase Identification on the PAWS-X dataset (Yang et al., 2019) in 6 languages1 . Finally, we report the F1 for the Named Entity Recognition (NER) in 4 languages by merging the CoNLL 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003) datasets. Additional details about the datasets are in Appendix. Experimental Setup. We foresee a setting where a BERT-based model is incrementally trained using annotated datasets in multiple languages. At"
2021.acl-short.106,D16-1139,0,0.0266478,"orgetting (Goodfellow et al., 2013). Previous work has mostly focused on Computer Vision (Shmelkov et al., 2017; Li and Hoiem, 2018; Rannen et al., 2017) by using Knowledge Distillation (KD) (Hinton et al., 2015) as the base framework. CL in NLP, as opposed to Computer Vision, is still nascent (Greco et al., 2019; Sun et al., 2020). This reflects in the small number of proposed methods to alleviate CF, as discussed in Biesialska et al. (2020). In this context, some works focus on the Online Learning aspect of the CL (Filice et al., 2014). In NLP, KD has been mainly adopted to compress models (Kim and Rush, 2016; Sanh et al., 2019), and was only recently applied for CL in Named Entity Recognition (Monaikul et al., 2021). In the context of multilingual analysis, most of the works leverage Domain Adaptation techniques within Machine Translation (Dong et al., 2015; Firat et al., 2016; Ha et al., 2016; Johnson et al., 2017; Tan et al., 2019) in order to apply a machine translation model to an increasing set of languages. To the best of our knowledge, this is the first work adopting CL to mitigate CF when training Transformer-based models in an incremental number of languages for semantic processing tasks"
2021.acl-short.106,P19-1493,0,0.0682881,"ework where the existing model “teaches” to a student model its knowledge about the languages it supports, while the student is also trained on a new language. We report an experimental evaluation in several tasks including Sentence Classification, Relational Learning and Sequence Labeling. 1 Introduction In Natural Language Processing (NLP), multilingualism refers to the capability of a single model to cope with multiple languages. Recently, different Transformer-based architectures have been extended to operate over multiple languages, as in Conneau et al. (2020); Conneau and Lample (2019); Pires et al. (2019). Despite these models can be applied in the zero-shot setting (Xian et al., 2019; Artetxe and Schwenk, 2019), in many practical applications their quality will not be satisfactory. Instead, fine-tuning over annotated material in each target language is needed to obtain competitive results, as the experimental results in Lewis et al. In this paper, we propose a CL strategy for updating a model over an incremental number of languages, so that at each step the model requires only annotated examples of the new language(s). Our goal is to remove the dependency on the original fine-tuning material"
2021.acl-short.106,P19-1015,0,0.0274818,"Missing"
2021.acl-short.106,W02-2024,0,0.398865,"presents the results of the proposed CL strategy over three semantic processing tasks, involving text classification and sequence tagging. In particular, we report the Mean Absolute Error (MAE) over the Multilingual Amazon Review Corpus (MARC) (Keung et al., 2020), i.e., a 5 category Sentiment Analysis task in 6 languages. We report the Accuracy over a sentence-pair classification task, i.e., Paraphrase Identification on the PAWS-X dataset (Yang et al., 2019) in 6 languages1 . Finally, we report the F1 for the Named Entity Recognition (NER) in 4 languages by merging the CoNLL 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003) datasets. Additional details about the datasets are in Appendix. Experimental Setup. We foresee a setting where a BERT-based model is incrementally trained using annotated datasets in multiple languages. At each step, the model is fine-tuned using a dataset in one specific language, while the annotated material used up to that point is discarded. 1 PAWS-X contains 7 languages. We were not able to reproduce the results of Yang et al. (2019) for the Korean language. Thus, we removed this language in our evaluation. 839 Uk = k−1 S j=1 (k−j+1) {U{lj"
2021.acl-short.106,W03-0419,0,0.737625,"Missing"
2021.acl-short.106,D19-6132,0,0.113907,"ent framework where the existing model “teaches” to a student model its knowledge about the languages it supports, while the student is also trained on a new language. We report an experimental evaluation in several tasks including Sentence Classification, Relational Learning and Sequence Labeling. 1 Introduction In Natural Language Processing (NLP), multilingualism refers to the capability of a single model to cope with multiple languages. Recently, different Transformer-based architectures have been extended to operate over multiple languages, as in Conneau et al. (2020); Conneau and Lample (2019); Pires et al. (2019). Despite these models can be applied in the zero-shot setting (Xian et al., 2019; Artetxe and Schwenk, 2019), in many practical applications their quality will not be satisfactory. Instead, fine-tuning over annotated material in each target language is needed to obtain competitive results, as the experimental results in Lewis et al. In this paper, we propose a CL strategy for updating a model over an incremental number of languages, so that at each step the model requires only annotated examples of the new language(s). Our goal is to remove the dependency on the original"
2021.acl-short.106,D19-1382,0,0.016779,"used as the teacher in our proposed KD schema2 . Mk−1 is used to derive the target output distribution of the dataset Experimental Evaluation This section presents the results of the proposed CL strategy over three semantic processing tasks, involving text classification and sequence tagging. In particular, we report the Mean Absolute Error (MAE) over the Multilingual Amazon Review Corpus (MARC) (Keung et al., 2020), i.e., a 5 category Sentiment Analysis task in 6 languages. We report the Accuracy over a sentence-pair classification task, i.e., Paraphrase Identification on the PAWS-X dataset (Yang et al., 2019) in 6 languages1 . Finally, we report the F1 for the Named Entity Recognition (NER) in 4 languages by merging the CoNLL 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003) datasets. Additional details about the datasets are in Appendix. Experimental Setup. We foresee a setting where a BERT-based model is incrementally trained using annotated datasets in multiple languages. At each step, the model is fine-tuned using a dataset in one specific language, while the annotated material used up to that point is discarded. 1 PAWS-X contains 7 languages. We were not able to repro"
A92-1013,J89-1002,0,\N,Missing
A92-1013,J90-1003,0,\N,Missing
A92-1013,H91-1067,0,\N,Missing
A92-1013,P91-1036,0,\N,Missing
A92-1013,E87-1040,1,\N,Missing
A92-1013,C90-1005,0,\N,Missing
A92-1013,E87-1006,0,\N,Missing
A92-1013,P91-1030,0,\N,Missing
A92-1013,P91-1019,0,\N,Missing
A92-1013,P90-1034,0,\N,Missing
A92-1013,P91-1027,0,\N,Missing
A92-1013,W91-0212,0,\N,Missing
A92-1013,C90-3010,0,\N,Missing
A92-1013,P89-1022,0,\N,Missing
A92-1013,P90-1032,0,\N,Missing
A94-1029,A92-1013,1,0.82651,"Missing"
A94-1029,A88-1019,0,0.0123663,"Missing"
A94-1029,A88-1018,0,0.0431337,"Missing"
A94-1029,C92-2099,0,\N,Missing
basili-etal-2000-tuning,1995.iwpt-1.15,0,\N,Missing
basili-etal-2000-tuning,C92-2070,0,\N,Missing
basili-etal-2004-a2q,W02-0404,0,\N,Missing
basili-etal-2004-a2q,P02-1040,0,\N,Missing
basili-etal-2004-a2q,P98-1013,0,\N,Missing
basili-etal-2004-a2q,C98-1013,0,\N,Missing
basili-etal-2004-similarity,P95-1026,0,\N,Missing
bastianelli-etal-2014-huric,N07-1070,0,\N,Missing
bastianelli-etal-2014-huric,P03-1054,0,\N,Missing
bastianelli-etal-2014-huric,P98-1013,0,\N,Missing
bastianelli-etal-2014-huric,C98-1013,0,\N,Missing
bastianelli-etal-2014-huric,C08-1050,0,\N,Missing
bastianelli-etal-2014-huric,S12-1048,0,\N,Missing
bastianelli-etal-2014-huric,W13-2322,0,\N,Missing
bastianelli-etal-2014-huric,S13-2044,0,\N,Missing
C02-1129,2000.iwpt-1.7,0,\N,Missing
C14-1221,E09-1004,0,0.0211812,"on 2. Then, Section 3 provides an account of the context-based models: conversation, topic-based and user sentiment profiling. The experimental evaluation into Section 4 prove the positive impact of social dynamics on the SA task. 2 Related Work Sentiment Analysis has been described as a Natural Language Processing task at many levels of granularity. Starting from being mapped into a document level classification task (Turney, 2002; Pang and Lee, 2004), it has been also applied at sentence level (Hu and Liu, 2004; Kim and Hovy, 2004) and more recently at the phrase level (Wilson et al., 2005; Agarwal et al., 2009). The spreading of microblog services where users post real-time opinions about “everything”, poses newer and different challenges. Indeed, classical approaches to Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the se"
C14-1221,W11-0705,0,0.0500193,"008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011; Si et al., 2013; Agarwal et al., 2011). Specific approaches and feature modeling are used to improve accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in (Barbosa and Feng, 2346 2010; Agarwal et al., 2011; Castellucci et al., 2013), are mostly employed. An interesting perspective, where"
C14-1221,C10-2005,0,0.0212206,"oaches to Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011; Si et al., 2013; Agarwal et al., 2011). Specific approaches and feature modeling are used to improve accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in (Barbosa and Feng, 2346 2010; Agarwal et al., 2011; Castellucci et al."
C14-1221,S13-2060,1,0.699943,"osa and Feng, 2010; Zanzotto et al., 2011; Si et al., 2013; Agarwal et al., 2011). Specific approaches and feature modeling are used to improve accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in (Barbosa and Feng, 2346 2010; Agarwal et al., 2011; Castellucci et al., 2013), are mostly employed. An interesting perspective, where a kind of contextual information is studied, is presented in (Mukherjee and Bhattacharyya, 2012): the sentiment detection of tweets is here modeled according to lexical features as well as discourse relations like the presence of connectives, conditionals and semantic operators like modals and negations. Nevertheless, in all the above approaches, features are derived only from lexical resources or from the tweet itself and no contextual information is exploited. However, given one tweet targeted for sentiment detection, more awareness ab"
C14-1221,W10-2802,1,0.784443,"plied through the Chaos parser (Basili et al., 1998; Basili and Zanzotto, 2002). In particular, each tweet, with its pseudo-tokens produced by the normalization step, is mapped into a sequence of POS tagged lemmas. Emoticons are treated as nouns. In order to feed the LSK, lexical vectors correspond to a Word Space derived from a corpus of about 1.5 million tweets, downloaded during the experimental period and using the topic names from the trial material as query terms. Every word w in such corpus is represented as one co-occurrence vector as in (Sahlgren, 2006) with the setting discussed in (Croce and Previtali, 2010): left and right co-occurrence scores are obtained in a window of size n = ±5 around each w. Vector components wf correspond to Pointwise Mutual Information values pmi(w, f ) between the word w (the row) and the feature f . Dimensionality reduction is applied to the co-occurrence matrix, through SVD, with a dimensionality cut of k = 250. Existing state-of-the-art approaches neglect the tweet context, so that datasets with labeled contexts are not available: USPK or the markovian approach would not be applicable. The solution consisted in creating a semi-supervised Gold-Standard by training the"
C14-1221,C10-2028,0,0.0257761,"ything”, poses newer and different challenges. Indeed, classical approaches to Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011; Si et al., 2013; Agarwal et al., 2011). Specific approaches and feature modeling are used to improve accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in"
C14-1221,C04-1200,0,0.406166,"Missing"
C14-1221,C12-1113,0,0.0630965,"accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in (Barbosa and Feng, 2346 2010; Agarwal et al., 2011; Castellucci et al., 2013), are mostly employed. An interesting perspective, where a kind of contextual information is studied, is presented in (Mukherjee and Bhattacharyya, 2012): the sentiment detection of tweets is here modeled according to lexical features as well as discourse relations like the presence of connectives, conditionals and semantic operators like modals and negations. Nevertheless, in all the above approaches, features are derived only from lexical resources or from the tweet itself and no contextual information is exploited. However, given one tweet targeted for sentiment detection, more awareness about its content is available to writers and readers by the entire stream of related posts immediately preceding it. In order to exploit this wider inform"
C14-1221,S13-2052,0,0.117068,"Missing"
C14-1221,pak-paroubek-2010-twitter,0,0.0181903,"s where users post real-time opinions about “everything”, poses newer and different challenges. Indeed, classical approaches to Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011; Si et al., 2013; Agarwal et al., 2011). Specific approaches and feature modeling are used to improve accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2"
C14-1221,P04-1035,0,0.0223881,"Missing"
C14-1221,W02-1011,0,0.0202184,"dynamics on the SA task. 2 Related Work Sentiment Analysis has been described as a Natural Language Processing task at many levels of granularity. Starting from being mapped into a document level classification task (Turney, 2002; Pang and Lee, 2004), it has been also applied at sentence level (Hu and Liu, 2004; Kim and Hovy, 2004) and more recently at the phrase level (Wilson et al., 2005; Agarwal et al., 2009). The spreading of microblog services where users post real-time opinions about “everything”, poses newer and different challenges. Indeed, classical approaches to Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011;"
C14-1221,P13-2005,0,0.00726099,"; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Zanzotto et al., 2011; Si et al., 2013; Agarwal et al., 2011). Specific approaches and feature modeling are used to improve accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicons and tweet specific features (e.g. hashtags, re-tweets) are some of the component exploited by these works, in combination with different machine learning algorithms: among these latter, probabilistic paradigms, e.g. Naive Bayes (Pak and Paroubek, 2010), or Kernel-based machines, as discussed in (Barbosa and Feng, 2346 2010; Agarwal et al., 2011; Castellucci et al., 2013), are mostly employed. An interes"
C14-1221,P02-1053,0,0.00812933,"Missing"
C14-1221,H05-1044,0,0.21749,"presented into Section 2. Then, Section 3 provides an account of the context-based models: conversation, topic-based and user sentiment profiling. The experimental evaluation into Section 4 prove the positive impact of social dynamics on the SA task. 2 Related Work Sentiment Analysis has been described as a Natural Language Processing task at many levels of granularity. Starting from being mapped into a document level classification task (Turney, 2002; Pang and Lee, 2004), it has been also applied at sentence level (Hu and Liu, 2004; Kim and Hovy, 2004) and more recently at the phrase level (Wilson et al., 2005; Agarwal et al., 2009). The spreading of microblog services where users post real-time opinions about “everything”, poses newer and different challenges. Indeed, classical approaches to Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: while most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained lexical analysis is required. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. Recent work"
C14-1221,D11-1061,0,\N,Missing
D08-1048,C96-1005,0,0.0284295,"W N is a WordNet-based similarity measure. In the following subsections we will describe how we build sub-graphs and model the similarity measure for the different part of speech. Figure 1 reports an excerpt of the noun subgraph for the frame P EOPLE BY AGE, covering the suitable senses of its nominal LUs {adult, baby, boy, kid, youngster, youth}. The relevant senses (e.g. sense 1 of youth out of the 6 potential ones) are generally selected, as they share the most specific generalizations in WordNet with the other words. Nouns. To compute similarity for nouns we adopt conceptual density (cd) (Agirre and Rigau, 1996), a semantic similarity model previously applied to word sense disambiguation tasks. Given a frame f and its set of nominal lexical units Fn , the nominal subgraph Sfn is built as follows. All senses of all words in Fn are activated in WordNet. All hypernyms Hfn of these senses are then retrieved. Every synset σ ∈ Hfn is given a cd score, representing the density of the WordNet subhierarchy rooted at σ in representing the set of nouns Fn . The intuition behind this model is that the larger the number of LUs in Fn that are generalized by σ is, the better it captures the lexical semantics intend"
D08-1048,P98-1013,0,0.460895,"lexical units. Experimental results show that our distributional and WordNet-based models achieve good level of accuracy and coverage, especially when combined. 1 Introduction Most inference-based NLP tasks require a large amount of semantic knowledge at the predicateargument level. This type of knowledge allows to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in several linguistic inferences. Recently, the integration of NLP systems with manually-built resources at the predicate argument-level, such as FrameNet (Baker et al., 1998) and PropBank (Palmer et al., 2005) has received growing interest. For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system. Similarly, several other studies (e.g. (Bar-Haim et al., 2005; Garoufi, 2007)) indicate that frame semantics plays a central role in Recognizing Textual Entailment (RTE). Unfortunately, most attempts to integrate FrameNet or similar resources in QA and RTE systems have so far failed, as reviewed respectively in (Shen and Lapata, 2007) and (Burchardt and Frank, 2006). These studies in"
D08-1048,S07-1018,0,0.262501,"Missing"
D08-1048,W05-1210,0,0.0161983,"ment level. This type of knowledge allows to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in several linguistic inferences. Recently, the integration of NLP systems with manually-built resources at the predicate argument-level, such as FrameNet (Baker et al., 1998) and PropBank (Palmer et al., 2005) has received growing interest. For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system. Similarly, several other studies (e.g. (Bar-Haim et al., 2005; Garoufi, 2007)) indicate that frame semantics plays a central role in Recognizing Textual Entailment (RTE). Unfortunately, most attempts to integrate FrameNet or similar resources in QA and RTE systems have so far failed, as reviewed respectively in (Shen and Lapata, 2007) and (Burchardt and Frank, 2006). These studies indicate limited coverage as the main reason of insuccess. Indeed, the FrameNet database only contains 10,000 lexical units (LUs), far less than the 210,000 entries in WordNet 3.0. Also, frames are based on more complex information than word senses, so that their manual develo"
D08-1048,basili-etal-2004-similarity,1,0.858067,"Missing"
D08-1048,burchardt-etal-2006-salsa,0,0.0409171,"Missing"
D08-1048,J93-1003,0,0.0753841,"esent results for the following models and parametrizations (further parametrizations have revealed comparable performance). Dist-word : the word-based space described in Section 3. Contextual features correspond to the set of the 4,000 most frequent words in the BNC.4 The association measure between LUs and contexts is the pointwise mutual information. Valid contexts for LUs are fixed to a 20-window. Dist-syntax : the syntax-based space described in Section 3. Context features are the 10,000 most frequent syntactic relations in the BNC5 . As association measure we apply log-likelihood ratio (Dunning, 1993) to normalized frequency. Syntactic relations are extracted using the Minipar parser. Dist-mixed : the mixed space described in Sec3 In the distributional model, we recompute the centroids for each frame f in which the LU appeared, applying Eq. 2 to the set F − {l}. 4 We didn’t use the FrameNet corpus directly, as it is too small to obtain reliable statistics. 5 Specifically, we use the minimum context selection function and the plain path value function described in Pado (2007). tion 3. As for the Dist-word model, contextual features are 4,000 and pointwise mutual information is the associati"
D08-1048,J05-1004,0,0.0799121,"ts show that our distributional and WordNet-based models achieve good level of accuracy and coverage, especially when combined. 1 Introduction Most inference-based NLP tasks require a large amount of semantic knowledge at the predicateargument level. This type of knowledge allows to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in several linguistic inferences. Recently, the integration of NLP systems with manually-built resources at the predicate argument-level, such as FrameNet (Baker et al., 1998) and PropBank (Palmer et al., 2005) has received growing interest. For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system. Similarly, several other studies (e.g. (Bar-Haim et al., 2005; Garoufi, 2007)) indicate that frame semantics plays a central role in Recognizing Textual Entailment (RTE). Unfortunately, most attempts to integrate FrameNet or similar resources in QA and RTE systems have so far failed, as reviewed respectively in (Shen and Lapata, 2007) and (Burchardt and Frank, 2006). These studies indicate limited coverage as the main"
D08-1048,J98-1004,0,0.354058,"Missing"
D08-1048,D07-1002,0,0.198823,"good level of accuracy and coverage, especially when combined. 1 Introduction Most inference-based NLP tasks require a large amount of semantic knowledge at the predicateargument level. This type of knowledge allows to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in several linguistic inferences. Recently, the integration of NLP systems with manually-built resources at the predicate argument-level, such as FrameNet (Baker et al., 1998) and PropBank (Palmer et al., 2005) has received growing interest. For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system. Similarly, several other studies (e.g. (Bar-Haim et al., 2005; Garoufi, 2007)) indicate that frame semantics plays a central role in Recognizing Textual Entailment (RTE). Unfortunately, most attempts to integrate FrameNet or similar resources in QA and RTE systems have so far failed, as reviewed respectively in (Shen and Lapata, 2007) and (Burchardt and Frank, 2006). These studies indicate limited coverage as the main reason of insuccess. Indeed, the FrameNet database only contains 1"
D08-1048,C98-1013,0,\N,Missing
D08-1048,J06-1003,0,\N,Missing
D08-1048,N04-3012,0,\N,Missing
D08-1048,P98-2127,0,\N,Missing
D08-1048,C98-2122,0,\N,Missing
D11-1096,W05-0601,1,0.814389,". PTK is more general than the STK as if we only consider the contribution of shared subsequences containing all children of nodes, we implement the STK kernel. The computational complexity of PTK is O(pρ2 |NT1 ||NT2 |) (Moschitti, 2006a), where p is the largest subsequence of children that we want consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 ∈ D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1 , d2 ) = X w1 ∈d1 ,w2 ∈d2 (ω1 ω2 ) × σ(w1 , w2 ) (1) where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2 , respectively, and σ is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any σ can be used, provided that the resulting Gram matrix, G = K(d1 , d2 ) ∀d1 , d2 ∈ D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional"
D11-1096,H05-1091,0,0.0608426,", 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leave"
D11-1096,A00-2018,0,0.0533177,"Missing"
D11-1096,P06-2010,0,0.0389822,"Missing"
D11-1096,P02-1034,0,0.796148,"rsen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) i"
D11-1096,W05-1203,0,0.0465447,"consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 ∈ D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1 , d2 ) = X w1 ∈d1 ,w2 ∈d2 (ω1 ω2 ) × σ(w1 , w2 ) (1) where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2 , respectively, and σ is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any σ can be used, provided that the resulting Gram matrix, G = K(d1 , d2 ) ∀d1 , d2 ∈ D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of se"
D11-1096,H92-1046,0,0.190264,"of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity 1034 over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature enginee"
D11-1096,P04-1054,0,0.313426,"Missing"
D11-1096,W04-3233,0,0.0623579,"Missing"
D11-1096,D09-1002,0,0.0122799,"Missing"
D11-1096,P06-1117,1,0.855736,"Missing"
D11-1096,P05-1050,0,0.0125296,"red in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies"
D11-1096,O97-1002,0,0.0807278,"-art. Additionally, semantic role classification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity 1034 over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focu"
D11-1096,C10-1059,1,0.788535,"Missing"
D11-1096,W10-2910,1,0.715725,"Missing"
D11-1096,W08-2123,0,0.0548567,"Missing"
D11-1096,C08-1050,0,0.092654,"Missing"
D11-1096,P03-1004,0,0.0162247,"itsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragment"
D11-1096,P05-1024,0,0.0278,"; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lo"
D11-1096,C02-1150,0,0.133231,"ally, to build the matrix M, POS tagging is first applied to build rows with pairs hlemma, ::POSi, or lemma::POS in brief. The contexts of such items are the columns of M and are short windows of size [−3, +3], centered on the items. This allows for better capturing syntactic properties of words. The most frequent 20,000 items are selected along with their 20k contexts. The entries of M are the point-wise mutual information between them. The SVD reduction is then applied to M, with a dimensionality cut of l = 250. The second approach uses the similarity based on word list (WL) as provided in (Li and Roth, 2002). Models: SVM-LightTK is applied to the different tree representations discussed in Section 4. Since PTK and SPTK are typically used in our experiments, to have a more compact acronym for each model, we associate the latter with the name of the structure, i.e. this indicates that PTK is applied to it. Then the presence of the subscript W L and LSA indicates that SPTK is applied along with the corresponding similarity, e.g. LCTW L is the SPTK kernel applied to LCT structure, using WL similarity. We experiment with multi-classification, which we model through one-vs-all scheme by selecting the c"
D11-1096,N10-1146,1,0.822543,"rees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fragments. Although this kernel achieves state-of-the-art performance in NLP tasks, such as Question ClassificaProceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1034–1046, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics tion (Bloehdorn and Moschitti, 2007b) and Textual Entailment (Mehdad et al., 2010), it offers clearly possibility of improvement: (i) better possibility to exploit semantic smoothing since, e.g., trivially STK only matches the syntactic structure apple/orange when comparing the big beautiful apple to a nice large orange; and (ii) STK cannot be effectively applied to dependency structures, e.g. see experiments and motivation in (Moschitti, 2006a). Additionally, to our knowledge, there is no previous study that clearly describes how dependency structures should be converted in trees to be fully and effectively exploitable by convolution kernels. Indeed, although the work in ("
D11-1096,H05-1052,0,0.178003,"n semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity 1034 over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005;"
D11-1096,P07-1098,1,0.895631,"Missing"
D11-1096,J08-2003,1,0.903654,"Missing"
D11-1096,P04-1043,1,0.905891,"Missing"
D11-1096,E06-1015,1,0.523335,"rence on Empirical Methods in Natural Language Processing, pages 1034–1046, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics tion (Bloehdorn and Moschitti, 2007b) and Textual Entailment (Mehdad et al., 2010), it offers clearly possibility of improvement: (i) better possibility to exploit semantic smoothing since, e.g., trivially STK only matches the syntactic structure apple/orange when comparing the big beautiful apple to a nice large orange; and (ii) STK cannot be effectively applied to dependency structures, e.g. see experiments and motivation in (Moschitti, 2006a). Additionally, to our knowledge, there is no previous study that clearly describes how dependency structures should be converted in trees to be fully and effectively exploitable by convolution kernels. Indeed, although the work in (Culotta and Sorensen, 2004) defines a dependency tree also using node similarity, it is not a convolution kernel: this results in a much poorer feature space. In this paper, we propose a study of convolution kernels for dependency structures aiming at jointly modeling syntactic and lexical semantic similarity. More precisely, we define several dependency trees ex"
D11-1096,J07-2002,0,0.0473797,"eir similarity as: K(d1 , d2 ) = X w1 ∈d1 ,w2 ∈d2 (ω1 ω2 ) × σ(w1 , w2 ) (1) where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2 , respectively, and σ is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any σ can be used, provided that the resulting Gram matrix, G = K(d1 , d2 ) ∀d1 , d2 ∈ D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of semantic relatedness, i.e. two words close in the space are likely to be either in paradigmatic or syntagmatic relation as in (Sahlgren, 2006). The original word-by-word context matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965) into the product of three new matrices: U , S, and V so that S"
D11-1096,N04-3012,0,0.173068,"ification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity 1034 over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two st"
D11-1096,J98-1004,0,0.339096,"tic role classification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity 1034 over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechani"
D11-1096,W03-1012,0,0.0643693,"h similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surfac"
D11-1096,W06-2902,0,0.036538,"; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on th"
D11-1096,W04-3222,0,0.0364774,", e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they ha"
D11-1096,C08-1121,1,0.389195,"orm lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (Mehdad et al., 2010). SPTK may provide further"
D11-1096,P94-1019,0,0.0214503,"usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity 1034 over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or"
D11-1096,P06-1006,0,0.0103659,"els (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (Mehdad et al., 2010). SP"
D11-1096,C00-2137,0,0.156371,"Missing"
D11-1096,W02-1010,0,0.0367616,"09; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity"
D11-1096,N06-1037,0,0.176688,"ious work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fr"
D11-1096,J06-1003,0,\N,Missing
D19-1415,P17-1032,1,0.926476,". Recent work has been inspired by efforts in improving model’s interpretability in image processing tasks, in particular by the Layerwise Relevance Propagation (LRP) (Bach et al., 2015). In LRP the classification decision of a deep neural network is decomposed backward across the network layers and evidence about the contribution to the final decision brought by individual input fragments (i.e., pixels of the input image) is gathered. In this paper, we propose to extend the LRP application to the linguistically motivated network architectures, known as Kernel-Based Deep Architectures (KDAs) (Croce et al., 2017), which frames semantic information captured by linguistic Tree Kernel methods (Collins and Duffy, 2001) within the neural-based learning paradigm. The result is a mechanism that, for each system’s prediction such as in question classification, generates an argument-by-analogy explanation based on real training examples, not necessarily similar to the input. We also propose a novel approach to evaluate numerically the interpretability of any explanation-enriched model applied in semantic inference tasks. By defining a specific audit process, we derive a synthetic metric, i.e. Auditing Accuracy"
D19-1415,D11-1096,1,0.88738,"ressed through the Nystr¨om 1 ˜ is the inmatrix HN y = U S − 2 . The resulting ~x put to one or more hidden layers. Clearly, the first ˜ = ~cHN y . Finally, hidden layer receives in input ~x the classification layer computes a linear classification function with a softmax operator, as shown in Figure 1. A KDA optimizes the standard crossentropy function with L2 regularization. It is worth recalling that the network is triggered by an input vector ~c expressing the kernel evaluations K(x, li ) between the example and the landmarks. When using linguistic kernels (such as Semantic Tree Kernels, (Croce et al., 2011)), this measure corresponds to the grammatical and lexical semantic similarity between x and the subset of landmarks. The expected explanation is obtained from the network output by applying LRP to re1 Note that, while any sampling policy for landmarks is admissible, in (Kumar et al., 2012) it is demonstrated that uniform sampling without replacement achieves results comparable with alternative, more resource-consuming policies. Generating explanations in Kernel-based Deep Architectures Justifications for the KDA emissions can be obtained by exploiting landmarks {`} as the evidence in favour o"
D19-1415,W18-5403,1,0.260762,"fect of the quality and the coherence of the features selection: this can be very hard in tasks where boundaries between classes are not well defined. Another strategy is pairing the decision model with a generative model to produce verbose explanations (Krening et al., 2017). Sometimes explanations are associated to vector representations as in (Ribeiro et al., 2016), i.e., bag-of-words in case of text classification, that are clearly weak at capturing significant linguistic abstractions, such as the involved syntactic relations. In this work, we systematically extend the model presented in (Croce et al., 2018) which allows to provide explanations that are easily interpretable even by non-expert users, as they are expressed in natural language. Moreover, the investigated approach is is computationally affordable, as it roughly corresponds to a forward pass across the network. In addition, we also provide a systematic way to evaluate the provided explanations with a methodology able to support the audit of the targeted AI systems. 3 Layer-wise Relevance Propagation in Kernel-based Deep Architectures In this section, we will review the Layer-wise Relevance Propagation technique (LRP, as in (Bach et al"
D19-1415,J08-2003,1,0.765718,"Missing"
D19-1415,N16-3020,0,0.786404,"in a wide variety of applications, with several levels of societal impact, and are expected to be soon deployed in safetycritical fields, e.g., autonomous driving. The definition of codes of conduct in the development of AI applications to ensure their ethical sustainability across dimensions, such as fairness, reliability and beneficialness (Kroll et al., 2016; Garfinkel et al., 2017; Dignum, 2017) is becoming a crucial issue. Hence, a natural need for the ethical accountability of such systems is gaining importance. A central issue lies in designing systems whose decisions are transparent (Ribeiro et al., 2016; Doshi-Velez et al., 2017), i.e., they must be easily interpretable by humans, as users must be able to suitably weight and trust the assistance of such systems. Deep neural networks are clearly problematic in this regard: their high non-linearity, despite allowing for state-of-the-art performances in several challenging problems, amplifies the epistemological opaqueness of the decision-flow and limits its interpretability. The concept of transparency of a machine learning model spans multiple definitions, focusing on different aspects, from the simplicity of the model, e.g., the number of no"
de-cao-etal-2010-extensive,D07-1002,0,\N,Missing
de-cao-etal-2010-extensive,basili-etal-2004-similarity,1,\N,Missing
de-cao-etal-2010-extensive,C96-1005,0,\N,Missing
de-cao-etal-2010-extensive,W07-1409,0,\N,Missing
de-cao-etal-2010-extensive,W09-1127,0,\N,Missing
de-cao-etal-2010-extensive,D08-1048,1,\N,Missing
de-cao-etal-2010-extensive,W08-2208,1,\N,Missing
de-cao-etal-2010-extensive,C08-1084,0,\N,Missing
de-cao-etal-2010-extensive,P98-1013,0,\N,Missing
de-cao-etal-2010-extensive,C98-1013,0,\N,Missing
guthrie-etal-2004-large,H93-1051,0,\N,Missing
guthrie-etal-2004-large,A97-1035,1,\N,Missing
guthrie-etal-2004-large,J01-3001,0,\N,Missing
guthrie-etal-2004-large,C96-1079,0,\N,Missing
J03-4005,N01-1025,0,0.015143,"ecall trade-off. Linguistically justified features have the inherent benefit of supporting natural explanations of the system induction, although evaluation usually does not account for them. In my view, the (linguistic) interpretation of different aspects of SVM learning in TC is an important research direction. The study of the relationship between training materials (as represented under a linguistic perspective) and the choice of kernel functions optimal for the task is a promising research line. 4. Late Reflections Support vector machines are widely adopted today for several tasks (e.g., Kudo and Matsumoto 2001). They seem to reproduce effectively the induction of separation functions from training data. The SVM inductive setting (of which the transductive one is just a derivation) is a straightforward approach to TC induction, and this book is proof. Although it leaves a large set of open problems, the book must be seen as a relevant contribution in the area of machine learning for natural language. It is a powerful means of getting acquainted with theoretical and methodological knowledge for text classification. Unfortunately, obvious gaps highly affect its completeness as a handbook in courses on"
J03-4005,J94-4002,0,0.199498,"Missing"
J03-4005,J01-4004,0,0.0776062,"Missing"
J03-4005,J00-4003,0,0.05796,"Missing"
J03-4005,M95-1005,0,0.0978105,"Missing"
J08-2003,P98-1013,0,0.0722972,"Missing"
J08-2003,W04-2412,0,0.0326685,"Missing"
J08-2003,W05-0620,0,0.302447,"Missing"
J08-2003,P04-1054,0,0.894351,"complexity is the adoption of syntactic tree kernels (Collins and Duffy 2002). For example, in Moschitti (2004), the predicate–argument relation is represented by means of the minimal subtree that includes both of them. The similarity between two instances is evaluated by a tree kernel function in terms of common substructures. Such an approach is in line with current research on kernels for natural language learning, for example, syntactic parsing re-ranking (Collins and Duffy 2002), relation extraction (Zelenko, Aone, and Richardella 2003), and named entity recognition (Cumby and Roth 2003; Culotta and Sorensen 2004). Furthermore, recent work (Haghighi, Toutanova, and Manning 2005; Punyakanok et al. 2005) has shown that, to achieve high labeling accuracy, joint inference should be applied on the whole predicate–argument structure. For this purpose, we need to extract features from the sentence syntactic parse tree that encodes the relationships governing complex semantic structures. This task is rather difﬁcult because we do not exactly know which syntactic clues effectively capture the relation between the predicate and its arguments. For example, to detect the interesting context, the modeling of syntax"
J08-2003,J02-3001,0,0.876438,"itkowski 2004), for which the most important features encoding predicate–argument relations are derived from (shallow or deep) syntactic information. The outcome of this research brings wide empirical evidence in favor of the linking theories between semantics and syntax, for example, Jackendoff (1990). Nevertheless, as no such theory provides a sound and complete treatment, the choice and design of syntactic features to represent semantic structures requires remarkable research effort and intuition. For example, earlier studies on feature design for semantic role labeling were carried out by Gildea and Jurafsky (2002) and Thompson, Levy, and Manning (2003). Since then, researchers have proposed several syntactic feature sets, where the more recent sets slightly enhanced the older ones. A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a viable way to alleviate the feature design complexity is the adoption of syntactic tree kernels (Collins and Duffy 2002). For example, in Moschitti (2004), the predicate–argument relation is represented by means of the minimal subtree that includes both of them. The similarity between two instances is eval"
J08-2003,W05-0623,0,0.0156739,"Missing"
J08-2003,H05-1018,0,0.28038,"h is mainly based on diverse natural language learning problems tackled by means of tree kernels. In Collins and Duffy (2002), the SST kernel was experimented with using the voted perceptron for the parse tree re-ranking task. A combination with the original PCFG model improved the syntactic parsing. Another interesting kernel for re-ranking was deﬁned in Toutanova, Markova, and Manning (2004). This represents parse trees as lists of paths (leaf projection paths) from leaves to the top level of the tree. It is worth noting that the PT kernel includes tree fragments identical to such paths. In Kazama and Torisawa (2005), an interesting algorithm that speeds up the average running time is presented. This algorithm looks for node pairs in which the rooted subtrees share many substructures (malicious nodes) and applies a transformation to the trees rooted in such nodes to make the kernel computation faster. The results show a several-hundred-fold speed increase with respect to the basic implementation. 201 Computational Linguistics Volume 34, Number 2 In Zelenko, Aone, and Richardella (2003), two kernels over syntactic shallow parser structures were devised for the extraction of linguistic relations, for exampl"
J08-2003,P03-1004,0,0.130984,"t sets which constitute back-off models for important syntactic features. Using them, the learning algorithm generalizes 194 Moschitti, Pighin, and Basili Tree Kernels for Semantic Role Labeling better and produces a more accurate classiﬁer, especially when the amount of training data is scarce. Finally, once the learning algorithm using tree kernels has converged, we can identify the most important structured features of the generated model. One approach for such a reverse engineering process relies on the computation of the explicit feature space, at least for the highest-weighted features (Kudo and Matsumoto 2003). Once the most relevant fragments are available, they can be used to design novel effective attribute–value features (which in turn can be used to design more efﬁcient classiﬁers, e. g., with linear kernels) and inspire new linguistic theories. These points suggest that tree kernels should always be applied, at least for an initial study of the problem. Unfortunately, they suffer from two main limitations: (a) poor impact on boundary detection as, in this task, correct and incorrect arguments may share a large portion of the encoding trees (Moschitti 2004); and (b) more expensive running time"
J08-2003,W04-0803,0,0.0171574,"revised submission received: 1 May 2007; accepted for publication: 19 June 2007. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 2 and Kingsbury 2005), inspired by Levin’s verb classes. To annotate natural language sentences, such systems generally require (1) the detection of the target word embodying the predicate and (2) the detection and classiﬁcation of the word sequences constituting the predicate’s arguments. Previous work has shown that these steps can be carried out by applying machine learning techniques (Carreras and M`arquez 2004, 2005; Litkowski 2004), for which the most important features encoding predicate–argument relations are derived from (shallow or deep) syntactic information. The outcome of this research brings wide empirical evidence in favor of the linking theories between semantics and syntax, for example, Jackendoff (1990). Nevertheless, as no such theory provides a sound and complete treatment, the choice and design of syntactic features to represent semantic structures requires remarkable research effort and intuition. For example, earlier studies on feature design for semantic role labeling were carried out by Gildea and Jur"
J08-2003,J93-2004,0,0.0303277,"Missing"
J08-2003,P04-1043,1,0.891709,"quires remarkable research effort and intuition. For example, earlier studies on feature design for semantic role labeling were carried out by Gildea and Jurafsky (2002) and Thompson, Levy, and Manning (2003). Since then, researchers have proposed several syntactic feature sets, where the more recent sets slightly enhanced the older ones. A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a viable way to alleviate the feature design complexity is the adoption of syntactic tree kernels (Collins and Duffy 2002). For example, in Moschitti (2004), the predicate–argument relation is represented by means of the minimal subtree that includes both of them. The similarity between two instances is evaluated by a tree kernel function in terms of common substructures. Such an approach is in line with current research on kernels for natural language learning, for example, syntactic parsing re-ranking (Collins and Duffy 2002), relation extraction (Zelenko, Aone, and Richardella 2003), and named entity recognition (Cumby and Roth 2003; Culotta and Sorensen 2004). Furthermore, recent work (Haghighi, Toutanova, and Manning 2005; Punyakanok et al."
J08-2003,E06-1015,1,0.256007,"we provide a comprehensive study of the use of tree kernels for semantic role labeling. For this purpose, we deﬁne tree kernels based on the composition of two different feature functions: canonical mappings, which map sentence-parse trees in tree structures encoding semantic information, and feature extraction functions, which encode these trees in the actual feature space. The latter functions explode the canonical trees into all their substructures and, in the literature, are usually referred to as tree kernels. For instance, in Collins and Duffy (2002), Vishwanathan and Smola (2002), and Moschitti (2006a) different tree kernels extract different types of tree fragments. Given the heuristic nature of canonical mappings, we studied their properties by experimenting with them within support vector machines and with the data set provided by CoNLL shared tasks (Carreras and M`arquez 2005). The results show that carefully engineered tree kernels always boost the accuracy of the basic systems. Most importantly, in complex tasks such as the re-ranking of semantic role annotations, they provide an easy way to engineer new features which enhance the state-of-the-art in SRL. In the remainder of this ar"
J08-2003,W05-0407,1,0.931043,"uickly as the feature extractor module only requires the writing of a general procedure for subtree extraction. In contrast, traditional SRL systems use more than thirty features (e. g., Pradhan, Hacioglu, Krugler et al. 2005), each of which requires the writing of a dedicated procedure. Second, their combination with traditional attribute–value models produces more accurate systems, also when using the same machine learning algorithm in the combination, because the feature spaces are very different. Third, we can carry out feature engineering using kernel combinations and marking strategies (Moschitti et al. 2005a; Moschitti, Pighin, and Basili 2006). This allows us to boost the SRL accuracy in a relatively simple way. Next, tree kernels generate large tree fragment sets which constitute back-off models for important syntactic features. Using them, the learning algorithm generalizes 194 Moschitti, Pighin, and Basili Tree Kernels for Semantic Role Labeling better and produces a more accurate classiﬁer, especially when the amount of training data is scarce. Finally, once the learning algorithm using tree kernels has converged, we can identify the most important structured features of the generated model"
J08-2003,W05-0630,1,0.869915,"uickly as the feature extractor module only requires the writing of a general procedure for subtree extraction. In contrast, traditional SRL systems use more than thirty features (e. g., Pradhan, Hacioglu, Krugler et al. 2005), each of which requires the writing of a dedicated procedure. Second, their combination with traditional attribute–value models produces more accurate systems, also when using the same machine learning algorithm in the combination, because the feature spaces are very different. Third, we can carry out feature engineering using kernel combinations and marking strategies (Moschitti et al. 2005a; Moschitti, Pighin, and Basili 2006). This allows us to boost the SRL accuracy in a relatively simple way. Next, tree kernels generate large tree fragment sets which constitute back-off models for important syntactic features. Using them, the learning algorithm generalizes 194 Moschitti, Pighin, and Basili Tree Kernels for Semantic Role Labeling better and produces a more accurate classiﬁer, especially when the amount of training data is scarce. Finally, once the learning algorithm using tree kernels has converged, we can identify the most important structured features of the generated model"
J08-2003,W06-2607,1,0.842129,"Missing"
J08-2003,J05-1004,0,0.193615,"Missing"
J08-2003,W05-0634,0,0.0288306,"Missing"
J08-2003,P05-1072,0,0.0133556,"Missing"
J08-2003,N04-1030,0,0.24239,"constituents surrounding the argument node Temporal markers which are very distinctive of some roles 197 Computational Linguistics Volume 34, Number 2 overlapping tree nodes, namely, one dominating the other, are classiﬁed as positive boundaries. The simplest solution relies on the application of heuristics that take into account the whole predicate–argument structure to remove the incorrect labels (e. g., Moschitti et al. 2005a; Tjong Kim Sang et al. 2005). A much more complex solution consists in the application of some joint inference model to the whole predicate–argument structure, as in Pradhan et al. (2004). As an example, Haghighi, Toutanova, and Manning (2005) associate a posterior probability with each argument node role assignment, estimate the likelihood of the alternative labeling schemes, and employ a re-ranking mechanism to select the best annotation. Additionally, the most accurate systems participating in CoNLL 2005 shared task (Pradhan, Hacioglu, Ward et al. 2005; Punyakanok et al. 2005) use different syntactic views of the same input sentence. This allows the SRL system to recover from syntactic parser errors; for example, a prepositional phrase specifying the direct object of the pr"
J08-2003,W05-0625,0,0.0439545,"Missing"
J08-2003,W03-1012,0,0.451243,"Missing"
J08-2003,W05-0637,0,0.0993094,"Missing"
J08-2003,P05-1073,0,0.0519196,"Missing"
J08-2003,W04-3222,0,0.302742,"Missing"
J08-2003,W04-3212,0,0.12312,"Missing"
J08-2003,N06-1037,0,0.194298,"Missing"
J08-2003,W03-1006,0,\N,Missing
J08-2003,C98-1013,0,\N,Missing
J08-2003,P02-1034,0,\N,Missing
J96-4006,W93-0107,1,0.829092,"Missing"
J96-4006,1995.tmi-1.8,0,0.0319317,"Missing"
L16-1007,W10-0204,0,0.267438,"oducts or people. In particular, SA deals with the problem of deciding whether a portion of a text, e.g. a sentence or a phrase, is expressing a trend towards specific feelings, e.g. positivity or negativity. Polarity lexicons are list of words each associated to one or more values, indicating their trend towards specific feelings, e.g. a single value in [−1, +1] can be used to indicate negativity (−1), neutrality (0) or positivity (+1). Such lexicons have been defined to support the development of automatic systems for detecting subjective phrases or sentences and recognizing their polarity (Mohammad and Turney, 2010). For example, in these lexicons, “good” can be associated to a prior positive sentiment in contrast to “sad”, considered negative in every domain. The occurrence of such words in a sentence can be adopted as an indicator of the polarity trends that are expressed in the sentence. These lexicons are often hand-compiled; however, from a linguistic point of view, a-priori membership of words to polarity classes can be considered too restrictive, as sentiment expressions are often topic dependent: the occurrences of the word mouse, for example, are mostly neutral in the consumer electronics domain"
L16-1007,S13-2052,0,0.0329361,"an be acquired without any supervision, and the provided heuristics do not have any bias with respect to languages or domains. Thus, polarity lexicons can be generated in multiple languages, without the need of expensive manual supervision. We generated large-scale polarity lexicons for English and Italian and we released them to the research community2 . Their contribution is measured against different SA tasks in the two languages. In particular, our evaluation is based on Twitter Sentiment Analysis, as recently it has been the focus of highly participated challenges, as the recent SemEval (Nakov et al., 2013; Rosenthal et al., 2014) and Evalita (Basile et al., 2014) tasks demonstrate. Sentiment Analysis (SA) and Opinion Mining systems (Pang and Lee, 2008) aim at tracking the opinions expressed in texts with respect to specific topics, e.g. products or people. In particular, SA deals with the problem of deciding whether a portion of a text, e.g. a sentence or a phrase, is expressing a trend towards specific feelings, e.g. positivity or negativity. Polarity lexicons are list of words each associated to one or more values, indicating their trend towards specific feelings, e.g. a single value in [−1,"
L16-1007,E09-1077,0,0.0377308,"crete strength (strong or weak) value. The NRC Emotion Lexicon (Mohammad and Turney, 2010) is composed by frequent English nouns, verbs, adjectives, and adverbs annotated through Amazon Mechanical Turk system with respect to eight emotions (e.g. joy, sadness, trust) and sentiment. Lexicons acquired over graphs. Graph based approaches exploit an underlying semantic structure that can be built upon words. In (Esuli and Sebastiani, 2006) the WordNet (Miller, 1995) synset glosses are exploited to derive three scores describing the positivity, negativity and neutrality of the synsets. The work in (Rao and Ravichandran, 2009) generates a lexicon as graph label propagation problem. Each node in the graph represents a word. Each weighted edge encodes a relation between words derived from WordNet (Miller, 1995). The graph is constructed starting from a set of manually defined seeds. The polarity for the other words is determined by exploiting graph-based methods. Corpus-based lexicons. Statistics based approaches are more general, as they mainly exploit corpus processing techniques. (Turney and Littman, 2003) proposed a minimally supervised approach to associate a polarity tendency to a word by determining if it co-o"
L16-1007,S14-2009,0,0.0249349,"ut any supervision, and the provided heuristics do not have any bias with respect to languages or domains. Thus, polarity lexicons can be generated in multiple languages, without the need of expensive manual supervision. We generated large-scale polarity lexicons for English and Italian and we released them to the research community2 . Their contribution is measured against different SA tasks in the two languages. In particular, our evaluation is based on Twitter Sentiment Analysis, as recently it has been the focus of highly participated challenges, as the recent SemEval (Nakov et al., 2013; Rosenthal et al., 2014) and Evalita (Basile et al., 2014) tasks demonstrate. Sentiment Analysis (SA) and Opinion Mining systems (Pang and Lee, 2008) aim at tracking the opinions expressed in texts with respect to specific topics, e.g. products or people. In particular, SA deals with the problem of deciding whether a portion of a text, e.g. a sentence or a phrase, is expressing a trend towards specific feelings, e.g. positivity or negativity. Polarity lexicons are list of words each associated to one or more values, indicating their trend towards specific feelings, e.g. a single value in [−1, +1] can be used to indic"
L16-1007,H05-1044,0,0.498766,"en lexical items and polarity biased sentences. Related Works Polarity lexicon generation has been tackled in many researches and three main approaches can be pointed out for producing a polarity lexicon. Manually annotated lexicons. Earlier works in lexicon generation are based on manual annotations of terms with respect to emotional or sentiment categories. For example, in (Stone et al., 1966) sentiment labels are manually associated to 3600 English terms. In (Hu and Liu, 2004) a list of positive and negative words are manually extracted from customer reviews. The MPQA Subjectivity Lexicon (Wilson et al., 2005) contains words, each with its prior polarity (positive or negative) and a discrete strength (strong or weak) value. The NRC Emotion Lexicon (Mohammad and Turney, 2010) is composed by frequent English nouns, verbs, adjectives, and adverbs annotated through Amazon Mechanical Turk system with respect to eight emotions (e.g. joy, sadness, trust) and sentiment. Lexicons acquired over graphs. Graph based approaches exploit an underlying semantic structure that can be built upon words. In (Esuli and Sebastiani, 2006) the WordNet (Miller, 1995) synset glosses are exploited to derive three scores desc"
L16-1007,P14-1051,0,0.0179577,"in the graph represents a word. Each weighted edge encodes a relation between words derived from WordNet (Miller, 1995). The graph is constructed starting from a set of manually defined seeds. The polarity for the other words is determined by exploiting graph-based methods. Corpus-based lexicons. Statistics based approaches are more general, as they mainly exploit corpus processing techniques. (Turney and Littman, 2003) proposed a minimally supervised approach to associate a polarity tendency to a word by determining if it co-occurs more with positive words than negative ones. More recently, (Zhang and Singh, 2014) proposed a semi-supervised framework for generating a domain-specific sentiment lexicon. Their system is initialized with a small set of labeled reviews, from which segments whose polarity is known are extracted. It exploits the relationships between consecutive segments to automatically generate a domain-specific sentiment lexicon. In (Kiritchenko et al., 2014) a minimally-supervised approach based on Social Media data is proposed by exploiting hashtags or emoticons related to positivity and negativity, e.g., #happy, #sad, :) or :(. They compute a score, reflecting the polarity of each word,"
L16-1007,P14-1023,0,0.0132783,", e.g. (Landauer and Dumais, 1997; Sahlgren, 2006), and then, optionally, applying dimensionality reduction techniques, such as Singular Value Decomposition (Golub and Kahan, 1965) in Latent Semantic Analysis (Landauer and Dumais, 1997). Another popular method for the acquisition of word spaces relies on a supervised setting, where the prediction of context-based task is exploited (examples are (Bengio et al., 2003; Mikolov et al., 2013a)). These are intended to capture more syntagmatic aspects during the word space construction. 3 For an in-depth comparison between the two methods, refer to (Baroni et al., 2014) 39 Despite the specific algorithm used for the space acquisition4 , all these approaches allow to derive a projection function Φ(·) of words into a geometrical space, i.e. the d-dimensional vector representation for a word wk ∈ W is obtained through w~k = Φ(wk ). Geometrical regularities are exploited to determine the prior sentiment for words, i.e. the main assumption is that words carrying sentiment lie in specific sub-spaces. In the following, we discuss how polarity transfer can be applied from sentences (whose polarity is known) to single words by exploiting those subspaces. Polarized wo"
L16-1007,W13-1614,0,0.0474908,"Missing"
L16-1007,esuli-sebastiani-2006-sentiwordnet,0,0.0140574,"egative words are manually extracted from customer reviews. The MPQA Subjectivity Lexicon (Wilson et al., 2005) contains words, each with its prior polarity (positive or negative) and a discrete strength (strong or weak) value. The NRC Emotion Lexicon (Mohammad and Turney, 2010) is composed by frequent English nouns, verbs, adjectives, and adverbs annotated through Amazon Mechanical Turk system with respect to eight emotions (e.g. joy, sadness, trust) and sentiment. Lexicons acquired over graphs. Graph based approaches exploit an underlying semantic structure that can be built upon words. In (Esuli and Sebastiani, 2006) the WordNet (Miller, 1995) synset glosses are exploited to derive three scores describing the positivity, negativity and neutrality of the synsets. The work in (Rao and Ravichandran, 2009) generates a lexicon as graph label propagation problem. Each node in the graph represents a word. Each weighted edge encodes a relation between words derived from WordNet (Miller, 1995). The graph is constructed starting from a set of manually defined seeds. The polarity for the other words is determined by exploiting graph-based methods. Corpus-based lexicons. Statistics based approaches are more general,"
L16-1007,P15-4004,1,0.86947,"Missing"
L16-1007,N13-1090,0,0.401805,"nces to words. The approach is mostly unsupervised, and experimental evaluations on Sentiment Analysis tasks in two languages show the benefits of the generated resources. The generated DPLs are publicly available in English and Italian. Keywords: Polarity Lexicon Generation, Sentiment Analysis, Distributional Models 1. Introduction supervised methodology to derive large-scale polarity lexicons, which exploits the extra-linguistic information within Social Media data, e.g. the presence of emoticons in messages. The approach relies on Distributional Models of Lexical Semantics (Sahlgren, 2006; Mikolov et al., 2013b), where the equivalence in sentences and words representations available in some distributional models (e.g. the dual LSA space for words and texts introduced in (Landauer and Dumais, 1997)) is exploited to transfer sentiment information from sentences to words. In fact, as sentences can be clearly related to polarity, a classifier can always be trained in such spaces and used to transfer sentiment information from sentences to words. Specifically, we train a polarity classifier by observing sentences expressing some polarity and we adopt it to classify words in order to populate a polarity"
moschitti-basili-2006-tree,A00-2018,0,\N,Missing
moschitti-basili-2006-tree,W05-0407,1,\N,Missing
moschitti-basili-2006-tree,C02-1150,0,\N,Missing
moschitti-basili-2006-tree,P04-1054,0,\N,Missing
moschitti-basili-2006-tree,P02-1034,0,\N,Missing
moschitti-basili-2006-tree,E06-1015,1,\N,Missing
P07-1098,P02-1034,0,0.930157,"various lexical, syntactic and semantic features. The retrieval and answer extraction phases consist in retrieving relevant documents (Collins-Thompson et al., 2004) and selecting candidate answer passages 776 from them. A further answer re-ranking phase is optionally applied. Here, too, the syntactic structure of a sentence appears to provide more useful information than a bag of words (Chen et al., 2006), although the correct way to exploit it is still an open problem. An effective way to integrate syntactic structures in machine learning algorithms is the use of tree kernel (TK) functions (Collins and Duffy, 2002), which have been successfully applied to question classification (Zhang and Lee, 2003; Moschitti, 2006) and other tasks, e.g. relation extraction (Zelenko et al., 2003; Moschitti, 2006). In more complex tasks such as computing the relatedness between questions and answers in answer re-ranking, to our knowledge no study uses kernel functions to encode syntactic information. Moreover, the study of shallow semantic information such as predicate argument structures annotated in the PropBank (PB) project (Kingsbury and Palmer, 2002) (www.cis.upenn.edu/∼ace) is a promising research direction. We ar"
P07-1098,kingsbury-palmer-2002-treebank,0,0.643429,"achine learning algorithms is the use of tree kernel (TK) functions (Collins and Duffy, 2002), which have been successfully applied to question classification (Zhang and Lee, 2003; Moschitti, 2006) and other tasks, e.g. relation extraction (Zelenko et al., 2003; Moschitti, 2006). In more complex tasks such as computing the relatedness between questions and answers in answer re-ranking, to our knowledge no study uses kernel functions to encode syntactic information. Moreover, the study of shallow semantic information such as predicate argument structures annotated in the PropBank (PB) project (Kingsbury and Palmer, 2002) (www.cis.upenn.edu/∼ace) is a promising research direction. We argue that semantic structures can be used to characterize the relation between a question and a candidate answer. In this paper, we extensively study new structural representations, encoding parse trees, bag-of-words, POS tags and predicate argument structures (PASs) for question classification and answer re-ranking. We define new tree representations for both simple and nested PASs, i.e. PASs whose arguments are other predicates (Section 2). Moreover, we define new kernel functions to exploit PASs, which we automatically derive"
P07-1098,W05-0630,1,0.767863,"Missing"
P07-1098,P06-1136,0,\N,Missing
P10-1025,W08-2123,0,0.234871,"of Roma, Tor Vergata Abstract work of (Gildea and Jurafsky, 2002) and the successful CoNLL evaluation campaigns (Carreras and M`arquez, 2005). Statistical machine learning methods, ranging from joint probabilistic models to support vector machines, have been successfully adopted to provide very accurate semantic labeling, e.g. (Carreras and M`arquez, 2005). SRL based on FrameNet is thus not a novel task, although very few systems are known capable of completing a general frame-based annotation process over raw texts, noticeable exceptions being discussed for example in (Erk and Pado, 2006), (Johansson and Nugues, 2008b) and (Coppola et al., 2009). Some critical limitations have been outlined in literature, some of them independent from the underlying semantic paradigm. Parsing Accuracy. Most of the employed learning algorithms are based on complex sets of syntagmatic features, as deeply investigated in (Johansson and Nugues, 2008b). The resulting recognition is thus highly dependent on the accuracy of the underlying parser, whereas wrong structures returned by the parser usually imply large misclassification errors. Annotation costs. Statistical learning approaches applied to SRL are very demanding with re"
P10-1025,P98-1013,0,0.0996075,"make use of the FrameNet database but fail to show suitable generalization capabilities in out-of-domain scenarios. In this paper, a state-of-art system for frame-based SRL is extended through the encapsulation of a distributional model of semantic similarity. The resulting argument classification model promotes a simpler feature space that limits the potential overfitting effects. The large scale empirical study here discussed confirms that state-of-art accuracy can be obtained for out-of-domain evaluations. 1 Introduction The availability of large scale semantic lexicons, such as FrameNet (Baker et al., 1998), allowed the adoption of a wide family of learning paradigms in the automation of semantic parsing. Building upon the so called frame semantic model (Fillmore, 1985), the Berkeley FrameNet project has developed a semantic lexicon for the core vocabulary of English, since 1997. A frame is evoked in texts through the occurrence of its lexical units (LU ), i.e. predicate words such verbs, nouns, or adjectives, and specifies the participants and properties of the situation it describes, the so called frame elements (F Es). Semantic Role Labeling (SRL) is the task of automatic recognition of indiv"
P10-1025,C08-1050,0,0.559607,"of Roma, Tor Vergata Abstract work of (Gildea and Jurafsky, 2002) and the successful CoNLL evaluation campaigns (Carreras and M`arquez, 2005). Statistical machine learning methods, ranging from joint probabilistic models to support vector machines, have been successfully adopted to provide very accurate semantic labeling, e.g. (Carreras and M`arquez, 2005). SRL based on FrameNet is thus not a novel task, although very few systems are known capable of completing a general frame-based annotation process over raw texts, noticeable exceptions being discussed for example in (Erk and Pado, 2006), (Johansson and Nugues, 2008b) and (Coppola et al., 2009). Some critical limitations have been outlined in literature, some of them independent from the underlying semantic paradigm. Parsing Accuracy. Most of the employed learning algorithms are based on complex sets of syntagmatic features, as deeply investigated in (Johansson and Nugues, 2008b). The resulting recognition is thus highly dependent on the accuracy of the underlying parser, whereas wrong structures returned by the parser usually imply large misclassification errors. Annotation costs. Statistical learning approaches applied to SRL are very demanding with re"
P10-1025,S07-1018,0,0.0932062,"Missing"
P10-1025,W05-0620,0,0.143991,"Missing"
P10-1025,J08-2003,1,0.867947,"Missing"
P10-1025,N09-2022,0,0.0997563,"k of (Gildea and Jurafsky, 2002) and the successful CoNLL evaluation campaigns (Carreras and M`arquez, 2005). Statistical machine learning methods, ranging from joint probabilistic models to support vector machines, have been successfully adopted to provide very accurate semantic labeling, e.g. (Carreras and M`arquez, 2005). SRL based on FrameNet is thus not a novel task, although very few systems are known capable of completing a general frame-based annotation process over raw texts, noticeable exceptions being discussed for example in (Erk and Pado, 2006), (Johansson and Nugues, 2008b) and (Coppola et al., 2009). Some critical limitations have been outlined in literature, some of them independent from the underlying semantic paradigm. Parsing Accuracy. Most of the employed learning algorithms are based on complex sets of syntagmatic features, as deeply investigated in (Johansson and Nugues, 2008b). The resulting recognition is thus highly dependent on the accuracy of the underlying parser, whereas wrong structures returned by the parser usually imply large misclassification errors. Annotation costs. Statistical learning approaches applied to SRL are very demanding with respect to the amount and quali"
P10-1025,J07-2002,0,0.0432403,"eneralization and promotes fine grained clusters. An interesting result is that a per-node accuracy of 86.3 (i.e. only 3 points under the state of-the art on the same data set, (Johansson and Nugues, 2008b)) is achieved. All the remaining tests have been run with the clustering configuration characterized by Eq. (5) and σ = 0.85. (ANC)5 . Table 2 shows the predicates and arguments in each data set. All null-instantiated arguments were removed from the training and test sets. Vectors ~h representing semantic heads have been computed according to the ”dependencybased” vector space discussed in (Pado and Lapata, 2007). The entire BNC corpus has been parsed and the dependency graphs derived from individual sentences provided the basic observable contexts: every co-occurrence is thus syntactically justified by a dependency arc. The most frequent 30,000 basic features, i.e. (syntactic relation,lemma) pairs, have been used to build the matrix M , vector components corresponding to point-wise mutual information scores. Finally, the final space is obtained by applying the SVD reduction over M , with a dimensionality cut of l = 250. In the evaluation of the AC task, accuracy is computed over the nodes of the depe"
P10-1025,D09-1003,0,0.388666,"Missing"
P10-1025,J05-1004,0,0.0754266,"exicon for the core vocabulary of English, since 1997. A frame is evoked in texts through the occurrence of its lexical units (LU ), i.e. predicate words such verbs, nouns, or adjectives, and specifies the participants and properties of the situation it describes, the so called frame elements (F Es). Semantic Role Labeling (SRL) is the task of automatic recognition of individual predicates together with their major roles (e.g. frame elements) as they are grammatically realized in input sentences. It has been a popular task since the availability of the PropBank and FrameNet annotated corpora (Palmer et al., 2005), the seminal 237 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 237–246, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics and Lapata, 2007). As we will see, the accuracy reachable through a restricted feature space is still quite close to the state-of-art, but interestingly the performance drops in out-of-domain tests are avoided. In the following, after discussing existing approaches to SRL (Section 2), a distributional approach is defined in Section 3. Section 3.2 discusses the proposed HMM-based treatment of"
P10-1025,J08-2006,0,0.0324909,"f (Collobert and Weston, 2008) to obtain an embedding of lexical information by acquiring a language model from unlabeled data is an interesting approach to the problem of performance degradation in out-of-domain tests, as already pursued by (Deschacht and Moens, 2009). The extensive use of unlabeled texts allows to achieve a significant level of lexical generalization that seems better capitalize the smaller annotated data sets. component is thus shown to be heavily domaindependent whereas the inclusion of grammatical function features is just able to mitigate this sensitivity. In line with (Pradhan et al., 2008), it is suggested that lexical features are domain specific and their suitable generalization is not achieved. The lack of suitable lexical information is also discussed in (F¨urstenau and Lapata, 2009) through an approach aiming to support the creation of novel annotated resources. Accordingly a semisupervised approach for reducing the costs of the manual annotation effort is proposed. Through a graph alignment algorithm triggered by annotated resources, the method acquires training instances from an unlabeled corpus also for verbs not listed as existing FrameNet predicates. 2.1 3 A Distribut"
P10-1025,W09-1109,0,0.0162592,"hi ) is thus estimated through Eq. 6. nlp.cs.swarthmore.edu/semeval/tasks/task19/data/train.tar.gz 242 training Corpus FN-BNC Predicates 134,697 Arguments 271,560 test in-domain FN-BNC 14,952 30,173 NTI ANC 8,208 760 14,422 1,389 out-of-domain Eq. - σ (5) - .85 (4) - .5 (4) - .1 Table 3: Accuracy on Arg classification tasks wrt different clustering policies Table 2: Training and Testing data sets σ ≈ 1 then many singleton clusters are promoted (i.e. one cluster for each example). By varying the threshold σ we thus account for prototype-based as well exemplar-based strategies, as discussed in (Erk, 2009). We measured the performance on the argument classification tasks of different models obtained by combing different choices of σ with Eq. (4) or (5). Results are reported in Table 3. The leftmost column reports the different clustering settings, while in the remaining columns we see performances over test sentences related to different frames: we selected frames for which an increasing number of annotated examples are available: from all frames (for more than 0 examples) to the only frame (i.e. S ELF MOTION) that has more than 5,000 examples in our training data set. The reported accuracies s"
P10-1025,W00-0726,0,0.0359456,"Missing"
P10-1025,D09-1002,0,0.0316934,"Missing"
P10-1025,J08-2002,0,0.0278736,"Missing"
P10-1025,J02-3001,0,0.661794,"Missing"
P10-1025,D09-1119,0,0.119237,"ed material lack of a clear grammatical status. The limited level of linguistic generalization outlined above is still an open research problem. Existing solutions have been proposed in literature along different lines. Learning from richer linguistic descriptions of more complex structures is proposed in (Toutanova et al., 2008). Limiting the cost required for developing large domainspecific training data sets has been also studied, e.g., (F¨urstenau and Lapata, 2009). Finally, the application of semi-supervised learning is attempted to increase the lexical expressiveness of the model, e.g. (Goldberg and Elhadad, 2009). In this paper, this last direction is pursued. A semi-supervised statistical model exploiting useful lexical information from unlabeled corpora is proposed. The model adopts a simple feature space by relying on a limited set of grammatical properties, thus reducing its learning capacity. Moreover, it generalizes lexical information about the annotated examples by applying a geometrical model, in a Latent Semantic Analysis style, inspired by a distributional paradigm (Pado 238 proposes an embedding of lexical information using Wikipedia as source, and exploiting the resulting language model w"
P10-1025,N07-1070,0,\N,Missing
P10-1025,C98-1013,0,\N,Missing
P12-1028,P98-1013,0,0.214058,"t something like in: ... Michelle blabs about it to a sandwich man while ordering lunch over the phone . Introduction Verb classification is a fundamental topic of computational linguistics research given its importance for understanding the role of verbs in conveying semantics of natural language (NL). Additionally, generalization based on verb classification is central to many NL applications, ranging from shallow semantic parsing to semantic search or information extraction. Currently, a lot of interest has been paid to two verb categorization schemes: VerbNet (Schuler, 2005) and FrameNet (Baker et al., 1998), which has also fostered production of many automatic approaches to predicate argument extraction. Such work has shown that syntax is necessary for helping to predict the roles of verb arguments and consequently their verb sense (Gildea and Jurasfky, 2002; Pradhan et al., 2005; Gildea and Palmer, 2002). However, the definition of models for optimally combining lexical and syntactic constraints is Clearly, the syntactic realization can be used to discern the cases above but it would not be enough to correctly classify the following verb occurrence: .. ordered the lunch to be delivered .. in Ve"
P12-1028,W11-0110,1,0.906954,"in a specific argument position and the above verb order is a clear example. In the direct object position of the example sentence for the first sense 60.1 of order, we found 264 commission in the role PATIENT of the predicate. It clearly satisfies the +A NIMATE/+O RGANIZATION restriction on the PATIENT role. This is not true for the direct object dependency of the alternative sense 13.5.1, which usually expresses the T HEME role, with unrestricted type selection. When properly generalized, the direct object information has thus been shown highly predictive about verb sense distinctions. In (Brown et al., 2011), the so called dynamic dependency neighborhoods (DDN), i.e., the set of verbs that are typically collocated with a direct object, are shown to be more helpful than lexical information (e.g., WordNet). The set of typical verbs taking a noun n as a direct object is in fact a strong characterization for semantic similarity, as all the nouns m similar to n tend to collocate with the same verbs. This is true also for other syntactic dependencies, among which the direct object dependency is possibly the strongest cue (as shown for example in (Dligach and Palmer, 2008)). In order to generalize the a"
P12-1028,H05-1091,0,0.0169362,"Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classifiers by exploiting previous technology for kernel methods. In particular, we design new models for verb classification by adopting algorithms for structural similarity, known as Smoothed Partial Tree Kernels (SPTKs) (Croce et al., 20"
P12-1028,A00-2018,0,0.147273,"Missing"
P12-1028,P02-1034,0,0.405859,"006), define contexts as the words appearing in a n-sized window, centered around a target word. Cooccurrence counts are thus collected in a words-bywords matrix, where each element records the number of times two words co-occur within a single window of word tokens. Moreover, robust weighting schemas are used to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Mosch"
P12-1028,P10-1025,1,0.852968,"ity, as all the nouns m similar to n tend to collocate with the same verbs. This is true also for other syntactic dependencies, among which the direct object dependency is possibly the strongest cue (as shown for example in (Dligach and Palmer, 2008)). In order to generalize the above DDN feature, distributional models are ideal, as they are designed to model all the collocations of a given noun, according to large scale corpus analysis. Their ability to capture lexical similarity is well established in WSD tasks (e.g. (Schutze, 1998)), thesauri harvesting (Lin, 1998), semantic role labeling (Croce et al., 2010)) as well as information retrieval (e.g. (Furnas et al., 1988)). Distributional Models (DMs). These models follow the distributional hypothesis (Firth, 1957) and characterize lexical meanings in terms of context of use, (Wittgenstein, 1953). By inducing geometrical notions of vectors and norms through corpus analysis, they provide a topological definition of semantic similarity, i.e., distance in a space. DMs can capture the similarity between words such as delegation, deputation or company and commission. In case of sense 60.1 of the verb order, DMs can be used to suggest that the role PATIEN"
P12-1028,D11-1096,1,0.930454,"tov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classifiers by exploiting previous technology for kernel methods. In particular, we design new models for verb classification by adopting algorithms for structural similarity, known as Smoothed Partial Tree Kernels (SPTKs) (Croce et al., 2011). We define new innovative structures and similarity functions based on LSA. The main idea of SPTK is rather simple: (i) measuring the similarity between two trees in terms of the number of shared subtrees; and (ii) such number also includes similar fragments whose lexical nodes 265 are just"
P12-1028,W04-3233,0,0.0650439,"Missing"
P12-1028,P08-2008,1,0.873656,"e about verb sense distinctions. In (Brown et al., 2011), the so called dynamic dependency neighborhoods (DDN), i.e., the set of verbs that are typically collocated with a direct object, are shown to be more helpful than lexical information (e.g., WordNet). The set of typical verbs taking a noun n as a direct object is in fact a strong characterization for semantic similarity, as all the nouns m similar to n tend to collocate with the same verbs. This is true also for other syntactic dependencies, among which the direct object dependency is possibly the strongest cue (as shown for example in (Dligach and Palmer, 2008)). In order to generalize the above DDN feature, distributional models are ideal, as they are designed to model all the collocations of a given noun, according to large scale corpus analysis. Their ability to capture lexical similarity is well established in WSD tasks (e.g. (Schutze, 1998)), thesauri harvesting (Lin, 1998), semantic role labeling (Croce et al., 2010)) as well as information retrieval (e.g. (Furnas et al., 1988)). Distributional Models (DMs). These models follow the distributional hypothesis (Firth, 1957) and characterize lexical meanings in terms of context of use, (Wittgenste"
P12-1028,J02-3001,0,0.0553081,"verbs in conveying semantics of natural language (NL). Additionally, generalization based on verb classification is central to many NL applications, ranging from shallow semantic parsing to semantic search or information extraction. Currently, a lot of interest has been paid to two verb categorization schemes: VerbNet (Schuler, 2005) and FrameNet (Baker et al., 1998), which has also fostered production of many automatic approaches to predicate argument extraction. Such work has shown that syntax is necessary for helping to predict the roles of verb arguments and consequently their verb sense (Gildea and Jurasfky, 2002; Pradhan et al., 2005; Gildea and Palmer, 2002). However, the definition of models for optimally combining lexical and syntactic constraints is Clearly, the syntactic realization can be used to discern the cases above but it would not be enough to correctly classify the following verb occurrence: .. ordered the lunch to be delivered .. in Verb class 13.5.1. For such a case, selectional restrictions are needed. These have also been shown to be useful for semantic role classification (Zapirain et al., 2010). Note that their coding in learning algorithms is rather complex: we need to take into a"
P12-1028,P02-1031,1,0.652564,"(NL). Additionally, generalization based on verb classification is central to many NL applications, ranging from shallow semantic parsing to semantic search or information extraction. Currently, a lot of interest has been paid to two verb categorization schemes: VerbNet (Schuler, 2005) and FrameNet (Baker et al., 1998), which has also fostered production of many automatic approaches to predicate argument extraction. Such work has shown that syntax is necessary for helping to predict the roles of verb arguments and consequently their verb sense (Gildea and Jurasfky, 2002; Pradhan et al., 2005; Gildea and Palmer, 2002). However, the definition of models for optimally combining lexical and syntactic constraints is Clearly, the syntactic realization can be used to discern the cases above but it would not be enough to correctly classify the following verb occurrence: .. ordered the lunch to be delivered .. in Verb class 13.5.1. For such a case, selectional restrictions are needed. These have also been shown to be useful for semantic role classification (Zapirain et al., 2010). Note that their coding in learning algorithms is rather complex: we need to take into account syntactic structures, which may require a"
P12-1028,P06-1117,1,0.924782,"Missing"
P12-1028,P05-1050,0,0.0134613,"to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classifiers by exploiting previous technology for kernel methods. In particular, we design new models for verb classification by adopting algorithms for structu"
P12-1028,W08-2123,0,0.0663246,"Missing"
P12-1028,P03-1004,0,0.046988,"matrix, where each element records the number of times two words co-occur within a single window of word tokens. Moreover, robust weighting schemas are used to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classif"
P12-1028,P05-1024,0,0.023694,"ntered around a target word. Cooccurrence counts are thus collected in a words-bywords matrix, where each element records the number of times two words co-occur within a single window of word tokens. Moreover, robust weighting schemas are used to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 20"
P12-1028,N10-1146,1,0.878723,"Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classifiers by exploiting previous technology for kernel methods. In particular, we design new models for verb classification by adopting algorithms for structural similarity, known as Smoothed Partial Tree Kernels (SPTKs) (Croce et al., 2011). We define new innovative structures and similarity functions based on LSA. The main idea of SPTK is rather simple: (i) measuring the similarity between two trees in terms of the number of shared subtrees; and (ii) such number also includes similar fragments whose lexica"
P12-1028,N07-1071,0,0.0210915,"eometrical notions of vectors and norms through corpus analysis, they provide a topological definition of semantic similarity, i.e., distance in a space. DMs can capture the similarity between words such as delegation, deputation or company and commission. In case of sense 60.1 of the verb order, DMs can be used to suggest that the role PATIENT can be inherited by all these words, as suitable Organisations. In supervised language learning, when few examples are available, DMs support cost-effective lexical generalizations, often outperforming knowledge based resources (such as WordNet, as in (Pantel et al., 2007)). Obviously, the choice of the context type determines the type of targeted semantic properties. Wider contexts (e.g., entire documents) are shown to suggest topical relations. Smaller contexts tend to capture more specific semantic aspects, e.g. the syntactic behavior, and better capture paradigmatic relations, such as synonymy. In particular, word space models, as described in (Sahlgren, 2006), define contexts as the words appearing in a n-sized window, centered around a target word. Cooccurrence counts are thus collected in a words-bywords matrix, where each element records the number of t"
P12-1028,W09-1106,1,0.879694,"Missing"
P12-1028,D09-1012,1,0.868753,"Missing"
P12-1028,W10-2926,1,0.864629,"Missing"
P12-1028,J98-1004,0,0.201143,"a direct object is in fact a strong characterization for semantic similarity, as all the nouns m similar to n tend to collocate with the same verbs. This is true also for other syntactic dependencies, among which the direct object dependency is possibly the strongest cue (as shown for example in (Dligach and Palmer, 2008)). In order to generalize the above DDN feature, distributional models are ideal, as they are designed to model all the collocations of a given noun, according to large scale corpus analysis. Their ability to capture lexical similarity is well established in WSD tasks (e.g. (Schutze, 1998)), thesauri harvesting (Lin, 1998), semantic role labeling (Croce et al., 2010)) as well as information retrieval (e.g. (Furnas et al., 1988)). Distributional Models (DMs). These models follow the distributional hypothesis (Firth, 1957) and characterize lexical meanings in terms of context of use, (Wittgenstein, 1953). By inducing geometrical notions of vectors and norms through corpus analysis, they provide a topological definition of semantic similarity, i.e., distance in a space. DMs can capture the similarity between words such as delegation, deputation or company and commission. In case o"
P12-1028,W03-1012,0,0.0171574,"the words appearing in a n-sized window, centered around a target word. Cooccurrence counts are thus collected in a words-bywords matrix, where each element records the number of times two words co-occur within a single window of word tokens. Moreover, robust weighting schemas are used to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehd"
P12-1028,W06-2902,0,0.0182858,"get word. Cooccurrence counts are thus collected in a words-bywords matrix, where each element records the number of times two words co-occur within a single window of word tokens. Moreover, robust weighting schemas are used to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 S"
P12-1028,W04-3222,0,0.0290889,"in a n-sized window, centered around a target word. Cooccurrence counts are thus collected in a words-bywords matrix, where each element records the number of times two words co-occur within a single window of word tokens. Moreover, robust weighting schemas are used to smooth counts against too frequent co-occurrence pairs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b"
P12-1028,C00-2137,0,0.0355617,"Missing"
P12-1028,N10-1058,0,0.0368592,"Missing"
P12-1028,W02-1010,0,0.0339909,"irs: Pointwise Mutual Information (PMI) scores (Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classifiers by exploiting previous technology for kernel methods. In particular, we design new models for verb classification by adopting algorithms for structural similarity, known as Smoothed Partial Tree Kernels"
P12-1028,N06-1037,0,0.0976457,"Turney and Pantel, 2010) are commonly adopted. Structural Kernels. Tree and sequence kernels have been successfully used in many NLP applications, e.g., parse reranking and adaptation, (Collins and Duffy, 2002; Shen et al., 2003; Toutanova et al., 2004; Kudo et al., 2005; Titov and Henderson, 2006), chunking and dependency parsing, e.g., (Kudo and Matsumoto, 2003; Daum´e III and Marcu, 2004), named entity recognition, (Cumby and Roth, 2003), text categorization, e.g., (Cancedda et al., 2003; Gliozzo et al., 2005), and relation extraction, e.g., (Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). Recently, DMs have been also proposed in integrated syntactic-semantic structures that feed advanced learning functions, such as the semantic tree kernels discussed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Mehdad et al., 2010; Croce et al., 2011). 3 Structural Similarity Functions In this paper we model verb classifiers by exploiting previous technology for kernel methods. In particular, we design new models for verb classification by adopting algorithms for structural similarity, known as Smoothed Partial Tree Kernels (SPTKs) (Croce et al., 2011). We define new in"
P12-1028,C98-1013,0,\N,Missing
P12-1028,P98-2127,0,\N,Missing
P12-1028,C98-2122,0,\N,Missing
P15-4004,C02-1150,0,0.0243144,"Missing"
P15-4004,W05-0620,0,0.0356226,"Missing"
P15-4004,S13-2052,0,0.0195026,"s and use of the learning platform are shown. We apply K E LP to very different NLP tasks, i.e. Sentiment Analysis in Twitter, Text Categorization and Question Classification, providing examples of kernel-based and linear learning algorithms. Further examples are available on the K E LP website7 where it is shown how to instantiate each algorithm or kernel via JSON and how to add new algorithms, representations and kernels. Task LibLinear Pegasos Passive Aggressive Sentiment Analysis in Twitter The task of Sentiment Analysis in Twitter has been proposed in 2013 during the SemEval competition (Nakov et al., 2013). We built a classifier for the subtask B, i.e. the classification of a tweet with respect to the positive, negative and neutral classes. The contribution of different kernel functions is evaluated using the Support Vector Machine learning algorithm. As shown in Table 1, we apply linear (Lin), polynomial (Poly) and Gaussian (Rbf) kernels on two different data representations: a Bag-Of-Words model of tweets (BoW ) and a distributional representation (W S). The last is obtained by linearly combining the distributional vectors corresponding to the words of a message; these vectors are obtained by"
P15-4004,D13-1044,0,0.0408869,"LP supports both vectorial and structured data to model learning instances. For example, SparseVector can host a Bag-ofWords model, while DenseVector can represent data derived from low dimensional embeddings. TreeRepresentation can model a parse tree and SequenceRepresentation can be adopted to represent sequences of characters or sequences of words. Moreover, the platform enables the definition of more complex forms of data such as pairs, which are useful in modeling those problems where instances can be naturally represented as pairs of texts, such as question and answer in Q/A re-ranking (Severyn and Moschitti, 2013), text and hypothesis in textual entailment (Zanzotto et al., 2009) or sentence pairs in paraphrasing detection (Filice et al., 2015). 2.2 Kernels Many ML algorithms rely on the notion of similarity between examples. Kernel methods (ShaweTaylor and Cristianini, 2004) leverage on the so-called kernel functions, which compute the similarity between instances in an implicit highdimensional feature space without explicitly computing the coordinates of the data in that space. The kernel operation is often cheaper from a computational perspective and specific kernels have been defined for sequences,"
P15-4004,D11-1096,1,0.612683,"me. This flexibility is completely supported by K E LP, which is also easy to extend with new kernels. Among the currently available implementations of kernels, there are various standard kernels, such as LinearKernel, PolynomialKernel or RbfKernel. A large set of kernels specifically designed for NLP applications will be described in the following section. 2.2.1 Many tasks in NLP cannot be properly tackled considering only a Bag-of-Words approach and require the exploration of deep syntactic aspects. In question classification the syntactic information is crucial has largely demonstrated in (Croce et al., 2011). In Textual Entailment Recognition or in Paraphrase Detection a pure lexical similarity between text and hypothesis cannot capture any difference between Federer won against Nadal and Nadal won against Federer. A manual definition of an artificial feature set accounting for syntax is a very expensive operation that requires a deep knowledge of the linguistic phenomena characterizing a specific task. Moreover, every task has specific patterns that must be considered, making a manual feature engineering an extremely complex and not portable operation. How can linguistic patterns characterizing"
P15-4004,P15-1097,1,0.0334202,"seVector can represent data derived from low dimensional embeddings. TreeRepresentation can model a parse tree and SequenceRepresentation can be adopted to represent sequences of characters or sequences of words. Moreover, the platform enables the definition of more complex forms of data such as pairs, which are useful in modeling those problems where instances can be naturally represented as pairs of texts, such as question and answer in Q/A re-ranking (Severyn and Moschitti, 2013), text and hypothesis in textual entailment (Zanzotto et al., 2009) or sentence pairs in paraphrasing detection (Filice et al., 2015). 2.2 Kernels Many ML algorithms rely on the notion of similarity between examples. Kernel methods (ShaweTaylor and Cristianini, 2004) leverage on the so-called kernel functions, which compute the similarity between instances in an implicit highdimensional feature space without explicitly computing the coordinates of the data in that space. The kernel operation is often cheaper from a computational perspective and specific kernels have been defined for sequences, graphs, trees, texts, images, as well as vectors. Kernels can be combined and composed to create richer similarity metrics, where in"
P15-4004,W03-0402,0,0.0963898,"pted implementation allows to easily extend the notion of similarity between nodes, enabling the implementation of more expressive kernels, as the Compositionally Smoothed Partial Tree Kernel (CSPTK) that embeds algebraic operators of Distributional Compositional Semantics (Annesi et al., 2014). Moreover, the SequenceKernel (Bunescu and Mooney, 2005) is included in the library, and it allows to compare two texts evaluating the number of common sub-sequences. This implicitly corresponds to operate on the space of all possible N-grams. Kernels operating over pairs, such as the PreferenceKernel (Shen and Joshi, 2003) for re-ranking, are also included in K E LP. 2.3 Listing 1: A JSON example. {""algorithm"" : ""oneVsAll"", ""baseAlgorithm"" : { ""algorithm"" : ""binaryCSvmClassification"", ""c"" : 10, ""kernel"" : { ""kernelType"" : ""linearComb"", ""weights"" : [1,1], ""toCombine"" : [ { ""kernelType"" : ""norm"", ""baseKernel"" : { ""kernelType"" : ""ptk"", ""mu"" : 0.4, ""lambda"" : 0.4, ""representation"" : ""parseTree"" } }, { ""kernelType"" : ""linear"", ""representation"" : ""Bag-of-Words"" } ] } } } 2.4 A JSON example Kernel functions and algorithms are serializable in JSON or XML. This is useful for instantiating a new algorithm without writing"
P17-1032,D11-1096,1,0.957423,"ee fragments. Such kernels corresponds to dot products in the (implicit) feature space made of all possible tree fragments (Haussler, 1999). Notice that the number of tree fragments in a tree bank is combinatorial with the number of tree nodes and gives rise to billions of features, i.e., dimensions. In this high-dimensional space, kernel-based algorithms, such as SVMs, can implicitly learn robust prediction models (Shawe-Taylor and Cristianini, 2004), resulting in state-of-the-art approaches in several NLP tasks, e.g., Semantic Role Labeling (Moschitti et al., 2008), Question Classification (Croce et al., 2011) or Paraphrase Identification (Filice et al., 2015). As the feature space generated by the structural kernels depends on the input structures, different tree representations can be adopted to reflect more or less expressive syntactic/semantic feature spaces. While constituency parse trees have been early used (e.g., (Collins and Duffy, 2001)), dependency parse trees correspond to graph structures. TKs usually rely on their tree conversions, where grammatical edge labels corresponds to nodes. An expressive tree representation of dependency graphs is the Grammatical Relation Centered Tree (GRCT)"
P17-1032,S16-1172,1,0.86962,"tate-of-the-art results in many tasks, their adoption can be problematic. In kernel-based Support Vector Machine (SVM) the classification model corresponds to the set of support vectors (SVs) and weights justifying the maximal margin hyperplane: the classification cost crucially depends on their number, as classifying a new instance requires a kernel computation against all SVs, making their adoption in large data settings prohibitive. This scalability issue is evident in many NLP and Information Retrieval applications, such as in answer re-ranking in question answering (Severyn et al., 2013; Filice et al., 2016), where the number of SVs is typically very large. Improving the efficiency of kernel-based methods is a largely studied topic. The reduction of computational costs has been early designed by imposing a budget (Dekel and Singer, 2006; Wang and Vucetic, 2010), that is limiting the maximum number of SVs in a model. However, in complex tasks, such methods still require large budgets to reach Kernel methods enable the direct usage of structured representations of textual data during language learning and inference tasks. Expressive kernels, such as Tree Kernels, achieve excellent performance in NL"
P17-1032,P15-1097,1,0.854098,"ucts in the (implicit) feature space made of all possible tree fragments (Haussler, 1999). Notice that the number of tree fragments in a tree bank is combinatorial with the number of tree nodes and gives rise to billions of features, i.e., dimensions. In this high-dimensional space, kernel-based algorithms, such as SVMs, can implicitly learn robust prediction models (Shawe-Taylor and Cristianini, 2004), resulting in state-of-the-art approaches in several NLP tasks, e.g., Semantic Role Labeling (Moschitti et al., 2008), Question Classification (Croce et al., 2011) or Paraphrase Identification (Filice et al., 2015). As the feature space generated by the structural kernels depends on the input structures, different tree representations can be adopted to reflect more or less expressive syntactic/semantic feature spaces. While constituency parse trees have been early used (e.g., (Collins and Duffy, 2001)), dependency parse trees correspond to graph structures. TKs usually rely on their tree conversions, where grammatical edge labels corresponds to nodes. An expressive tree representation of dependency graphs is the Grammatical Relation Centered Tree (GRCT). As illustrated in Figure 1, PoS-Tags and grammati"
P17-1032,P98-1013,0,0.357869,"Missing"
P17-1032,J02-3001,0,0.546607,"Missing"
P17-1032,C08-1050,0,0.0512891,"Missing"
P17-1032,D14-1181,0,0.0114224,"Missing"
P17-1032,P15-1150,0,0.150467,"Missing"
P17-1032,J08-2003,1,0.958681,"t in similarity metrics directly operating over tree fragments. Such kernels corresponds to dot products in the (implicit) feature space made of all possible tree fragments (Haussler, 1999). Notice that the number of tree fragments in a tree bank is combinatorial with the number of tree nodes and gives rise to billions of features, i.e., dimensions. In this high-dimensional space, kernel-based algorithms, such as SVMs, can implicitly learn robust prediction models (Shawe-Taylor and Cristianini, 2004), resulting in state-of-the-art approaches in several NLP tasks, e.g., Semantic Role Labeling (Moschitti et al., 2008), Question Classification (Croce et al., 2011) or Paraphrase Identification (Filice et al., 2015). As the feature space generated by the structural kernels depends on the input structures, different tree representations can be adopted to reflect more or less expressive syntactic/semantic feature spaces. While constituency parse trees have been early used (e.g., (Collins and Duffy, 2001)), dependency parse trees correspond to graph structures. TKs usually rely on their tree conversions, where grammatical edge labels corresponds to nodes. An expressive tree representation of dependency graphs is"
P17-1032,S16-1083,0,0.0444297,"Missing"
P17-1032,D13-1170,0,0.0404605,"l Politecnico 1, 00133, Rome, Italy {croce,filice,basili}@info.uniroma2.it castellucci@ing.uniroma2.it Abstract 2008)). Although ad-hoc features are adopted by many successful approaches to language learning (e.g., (Gildea and Jurafsky, 2002)), kernels provide a natural way to capture textual generalizations directly operating over (possibly complex) linguistic structures. Sequence (Cancedda et al., 2003) or tree kernels (Collins and Duffy, 2001) are of particular interest as the feature space they implicitly generate reflects linguistic patterns. On the other hand, Recursive Neural Networks (Socher et al., 2013) have been shown to learn dense feature representations of the nodes in a structure, thus exploiting similarities between nodes and sub-trees. Also, Long-Short Term Memory (Hochreiter and Schmidhuber, 1997) networks build intermediate representations of sequences, resulting in similarity estimates over sequences and their inner sub-sequences. While such methods are highly effective and reach state-of-the-art results in many tasks, their adoption can be problematic. In kernel-based Support Vector Machine (SVM) the classification model corresponds to the set of support vectors (SVs) and weights"
P17-1032,C98-1013,0,\N,Missing
P17-1032,S16-1138,0,\N,Missing
pennacchiotti-etal-2008-towards,burchardt-etal-2006-salsa,0,\N,Missing
pennacchiotti-etal-2008-towards,C04-1146,0,\N,Missing
pennacchiotti-etal-2008-towards,W07-1409,0,\N,Missing
pennacchiotti-etal-2008-towards,J07-2002,0,\N,Missing
pennacchiotti-etal-2008-towards,H01-1035,0,\N,Missing
pennacchiotti-etal-2008-towards,P07-1025,0,\N,Missing
pennacchiotti-etal-2008-towards,P98-1013,0,\N,Missing
pennacchiotti-etal-2008-towards,C98-1013,0,\N,Missing
pennacchiotti-etal-2008-towards,W07-1401,0,\N,Missing
pennacchiotti-etal-2008-towards,J06-1003,0,\N,Missing
pennacchiotti-etal-2008-towards,J02-3001,0,\N,Missing
pennacchiotti-etal-2008-towards,J05-1004,0,\N,Missing
pennacchiotti-etal-2008-towards,W05-1210,0,\N,Missing
pennacchiotti-etal-2008-towards,P98-2127,0,\N,Missing
pennacchiotti-etal-2008-towards,C98-2122,0,\N,Missing
pennacchiotti-etal-2008-towards,N04-1041,0,\N,Missing
S07-1062,P02-1034,0,0.0211455,"b basis. In order to build a development set (Dev), we sampled about one tenth, i. e. 1,606 annotations, of the original training set. For the final evaluation on the test set (Test), consisting of 3,094 annotations, we trained our classifiers on the whole training data. Statistics on the dataset composition are shown in Table 1. The evaluations were carried out with the SVMLight-TK2 software (Moschitti, 2004) which extends the SVM-Light package (Joachims, 1999) with tree kernel functions. We used the default polynomial kernel (degree=3) for the linear features and a SubSet Tree (SST) kernel (Collins and Duffy, 2002) for the comparison of ASTm 1 structured features. The kernels are normalized and summed by assigning a weight of 0.3 to the TK contribution. Training all the 50 boundary classifiers and the 619 role classifiers on the whole dataset took about 4 hours on a 64 bits machine (2.2GHz, 1GB RAM)3 . 4.2 Evaluation All the evaluations were carried out using the CoNLL2005 evaluator tool available at http://www.lsi.upc.es/∼srlconll/soft.html. Table 2 shows the aggregate results on boundary detection (BD) and the complete SRL task (BD+RC) on the development set using the polynomial kernel alone (poly) or"
S07-1062,W06-2909,1,0.925753,"ed by each individual role classifier. The role label associated with the maximum among the scores provided by the individual classifiers is eventually selected. To make the annotations consistent with the underlying linguistic model, we employ a few simple heuristics to resolve the overlap situations that may occur, e. g. both “charter” and “the charter” in Figure 1 may be assigned a role: • if more than two nodes are involved, i. e. a node d and two or more of its descendants ni are classified as arguments, then assume that d is not an argument. This choice is justified by previous studies (Moschitti et al., 2006b) showing that the accuracy of classification is higher for lower nodes; • if only two nodes are involved, i. e. they dominate each other, then keep the one with the highest classification score. 3 Features for Semantic Role Labeling We explicitly represent as attribute-value pairs the following features of each Fp,a pair: • Phrase Type, Predicate Word, Head Word, Position and Voice as defined in (Gildea and Jurasfky, 2002); • Partial Path, No Direction Path, Head Word POS, First and Last Word/POS in Constituent and SubCategorization as proposed in (Pradhan et al., 2005); 289 a) S NP VP DT NN"
S07-1062,W06-2607,1,0.875194,"ed by each individual role classifier. The role label associated with the maximum among the scores provided by the individual classifiers is eventually selected. To make the annotations consistent with the underlying linguistic model, we employ a few simple heuristics to resolve the overlap situations that may occur, e. g. both “charter” and “the charter” in Figure 1 may be assigned a role: • if more than two nodes are involved, i. e. a node d and two or more of its descendants ni are classified as arguments, then assume that d is not an argument. This choice is justified by previous studies (Moschitti et al., 2006b) showing that the accuracy of classification is higher for lower nodes; • if only two nodes are involved, i. e. they dominate each other, then keep the one with the highest classification score. 3 Features for Semantic Role Labeling We explicitly represent as attribute-value pairs the following features of each Fp,a pair: • Phrase Type, Predicate Word, Head Word, Position and Voice as defined in (Gildea and Jurasfky, 2002); • Partial Path, No Direction Path, Head Word POS, First and Last Word/POS in Constituent and SubCategorization as proposed in (Pradhan et al., 2005); 289 a) S NP VP DT NN"
S07-1062,W04-3212,0,0.0688974,"Missing"
S07-1062,P04-1043,1,\N,Missing
S07-1062,J02-3001,0,\N,Missing
S12-1088,P07-1038,0,0.0251284,"rove the effectiveness of a semantic search engine (Sahami and Heilman, 2006), or databases, where text similarity can be used in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. Regression learning has been already applied to different NLP tasks. In (Pang and Lee, 2005) it is applied to Opinion Mining, in particular to the rating-inference problem, wherein one must determine an author evaluation with respect to a multi-point scale. In (Albrecht and Hwa, 2007) a method is proposed for developing sentence-level MT evaluation metrics using regression learning without directly relying on human reference translations. In (Biadsy et al., 2008) it has been used to rank candidate sentences for the task of producing biographies from Wikipedia. Finally, in (Becker et al., 2011) SV regressor has been used to rank questions within their context in the multimodal tutorial dialogue problem. In this paper, the semantic relatedness between two sentences is modeled as a combination of different similarity functions, each describing the analogy between the two text"
S12-1088,P08-1092,0,0.0240254,"and Inkpen, 2008). STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. Regression learning has been already applied to different NLP tasks. In (Pang and Lee, 2005) it is applied to Opinion Mining, in particular to the rating-inference problem, wherein one must determine an author evaluation with respect to a multi-point scale. In (Albrecht and Hwa, 2007) a method is proposed for developing sentence-level MT evaluation metrics using regression learning without directly relying on human reference translations. In (Biadsy et al., 2008) it has been used to rank candidate sentences for the task of producing biographies from Wikipedia. Finally, in (Becker et al., 2011) SV regressor has been used to rank questions within their context in the multimodal tutorial dialogue problem. In this paper, the semantic relatedness between two sentences is modeled as a combination of different similarity functions, each describing the analogy between the two texts according to a specific semantic perspective: in this way, we aim at capturing syntactic and lexical equivalences between sentences and exploiting either topical relatedness or par"
S12-1088,W10-2802,1,0.888027,"milarity to depend on the set of individual compounds, e.g. subject-verb relationship instances. While basic lexical information can still be obtained by distributional analysis, phrase level 598 Figure 1: Example of dependency graph similarity can be here modeled as a specific function of the co-occurring words, i.e. a complex algebraic composition of their corresponding word vectors. Differently from the document-oriented case used in the LSA function, base lexical vectors are here derived from co-occurrence counts in a word space, built according to the method discussed in (Sahlgren, 2006; Croce and Previtali, 2010). In order to keep dimensionality as low as possible, SVD is also applied here (Annesi et al., 2012). The result is that every noun, verb, adjective and adverb is then projected in the reduced word space and then different composition functions can be applied as discussed in (Mitchell and Lapata, 2010) or (Annesi et al., 2012). Convolution kernel-based similarity. The similarity function is here the Smoothed Partial Tree Kernel (SPTK) proposed in (Croce et al., 2011). This convolution kernel estimates the similarity between sentences, according to the syntactic and lexical information in both"
S12-1088,D11-1096,1,0.925286,"s are here derived from co-occurrence counts in a word space, built according to the method discussed in (Sahlgren, 2006; Croce and Previtali, 2010). In order to keep dimensionality as low as possible, SVD is also applied here (Annesi et al., 2012). The result is that every noun, verb, adjective and adverb is then projected in the reduced word space and then different composition functions can be applied as discussed in (Mitchell and Lapata, 2010) or (Annesi et al., 2012). Convolution kernel-based similarity. The similarity function is here the Smoothed Partial Tree Kernel (SPTK) proposed in (Croce et al., 2011). This convolution kernel estimates the similarity between sentences, according to the syntactic and lexical information in both sentences. Syntactic representation of a sentence like “A man is riding a bicycle” is derived from the dependency parse tree, as shown in Fig. 1. It allows to define different tree structures over which the SPTK operates. First, a tree including only lexemes, where edges encode their dependencies, is generated and called Lexical Only Centered Tree (LOCT), see Fig. 2. Then, we add to each lexical node two leftmost children, encoding the grammatical function and the PO"
S12-1088,S07-1048,0,0.0188296,"d Partial Tree Kernel (SPTK) is made available by an extended version of SVM-LightTK software1 (Mos1 http://disi.unitn.it/moschitti/Tree-Kernel.htm 600 chitti, 2006) implementing the smooth matching between tree nodes. The tree representation described in Sec. 2.1 allows to define 3 different kernels, i.e. SPTKLOCT , SPTKLCT and SPTKGRCT . Similarity between lexical nodes is estimated as the cosine similarity in the co-occurrence Word Space described above, as in (Croce et al., 2011). In all corpus analysis and experiments, sentences are processed with the LTH dependency parser, described in (Johansson and Nugues, 2007), for Partof-speech tagging and lemmatization. Dependency parsing of datasets is required for the SPTK application. Finally, SVM-LightTK is employed for the SV regression learning to combine specific similarity functions. 3.2 Evaluating the impact of unsupervised models Table 1 compares the Pearson Correlation of different similarity functions described in Section 2.1, i.e. mainly the results of the unsupervised approaches, against the challenge training data. Regarding to MSRvid dataset, the topical similarity (LSA function) achieves the best result, i.e. 0.748. Paradigmatic lexical informati"
S12-1088,P05-1015,0,0.0592975,"compute similarity between short texts or sentences has many applications in Natural Language Processing (Mihalcea et al., 2006) and related areas such as Information Retrieval, e.g. to improve the effectiveness of a semantic search engine (Sahami and Heilman, 2006), or databases, where text similarity can be used in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). STS is here modeled as a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. Regression learning has been already applied to different NLP tasks. In (Pang and Lee, 2005) it is applied to Opinion Mining, in particular to the rating-inference problem, wherein one must determine an author evaluation with respect to a multi-point scale. In (Albrecht and Hwa, 2007) a method is proposed for developing sentence-level MT evaluation metrics using regression learning without directly relying on human reference translations. In (Biadsy et al., 2008) it has been used to rank candidate sentences for the task of producing biographies from Wikipedia. Finally, in (Becker et al., 2011) SV regressor has been used to rank questions within their context in the multimodal tutoria"
S13-1007,S12-1051,0,0.0534626,"., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2 , participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2 , containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea et al., 2012; Croce et al., ˇ c et al., 2012), STS is here modeled as 2012a; Sari´ a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. The"
S13-1007,S13-1004,0,0.0295316,"equivalence between two phrases or texts. An effective method to compute similarity between sentences or semi-structured material has many applications in Natural Language Processing (Mihalcea et al., 2006) and related areas such as Information Retrieval, improving the effectiveness of semantic search engines (Sahami and Heilman, 2006), or databases, using text similarity in schema matching to solve semantic heterogeneity (Islam and Inkpen, 2008). This paper describes the UNITOR system participating in both tasks of the *SEM 2013 shared task on Semantic Textual Similarity (STS), described in (Agirre et al., 2013): • the Core STS tasks: given two sentences, s1 and s2 , participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2 , containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea"
S13-1007,S12-1094,0,0.0226443,"2013): • the Core STS tasks: given two sentences, s1 and s2 , participants are asked to provide a score reflecting the corresponding text similarity. It is the same task proposed in (Agirre et al., 2012). • the Typed-similarity STS task: given two semi-structured records t1 and t2 , containing several typed fields with textual values, participants are asked to provide multiple similarity scores: the types of similarity to be studied include location, author, people involved, time, events or actions, subject and description. In line with several participants of the STS 2012 challenge, such as (Banea et al., 2012; Croce et al., ˇ c et al., 2012), STS is here modeled as 2012a; Sari´ a Support Vector (SV) regression problem, where a SV regressor learns the similarity function over text pairs. The semantic relatedness between two sentences is first modeled in an unsupervised fashion by several similarity functions, each describing the analogy between the two texts according to a specific semantic perspective. We aim at capturing separately syntactic and lexical equivalences between sentences and exploiting either topical relatedness or paradigmatic similarity between individual words. Such information is"
S13-1007,W10-2802,1,0.84365,"occurring in two generic texts ta and tb , LO is estimated as the Jaccard Similarity between the sets, i.e. a ∩Wb | LO= |W |Wa ∪Wb |. In order to reduce data sparseness, lemmatization is applied and each word is enriched with its POS to avoid the confusion between words 60 from different grammatical classes. Compositional Distributional Semantics. Other similarity functions are obtained by accounting for the syntactic composition of the lexical information involved in the sentences. Basic lexical information is obtained by a co-occurrence Word Space that is built according to (Sahlgren, 2006; Croce and Previtali, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et"
S13-1007,D11-1096,1,0.927828,"es contain the same kind of information. Given the sets of triples A and B extracted from the two candidate sentences, our approach estimates a syntactically restricted soft cardinality operator, the Syntactic Soft 2|A∩B|0 Cardinality (SSC) as SSC(A, B) = |A| 0 +|B|0 , as a “soft approximation” of Dice’s coefficient calculated on both sets1 . capture::v lord::n drug::n NSUBJ NN NN NN marine::n ROOT VBN mexico::n PREP-BY NNS PREP-IN NNP Figure 1: Lexical Centered Tree (LCT) Convolution kernel-based similarity. The similarity function is here the Smoothed Partial Tree Kernel (SPTK) proposed in (Croce et al., 2011). SPTK is a generalized formulation of a Convolution Kernel function (Haussler, 1999), i.e. the Tree Kernel (TK), by extending the similarity between tree structures with a function of node similarity. The main characteristic of SPTK is its ability to measure the similarity between syntactic tree structures, which are partially similar and whose nodes can differ but are semantically related. One of the most important outcomes is that SPTK allows “embedding” external lexical information in the kernel function only through a similarity function among lexical nodes, namely words. Moreover, SPTK o"
S13-1007,S12-1088,1,0.889753,"li, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et al., 2012c) has been applied. It is based on space projection operations over basic geometric lexical representations: syntactic bigrams are projected in the so called Support Subspace (Annesi et al., 2012), aimed at emphasizing the semantic features shared by the compound words. The aim is to model semantics of syntactic bi-grams as projections in lexically-driven subspaces. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic"
S13-1007,P12-1028,1,0.916847,"li, 2010). Every word appearing in a sentence is then projected in such space. A sentence can be thus represented neglecting its syntactic structure, by applying an additive linear combination, i.e. the socalled SUM operator. The similarity function between two sentences is then the cosine similarity between their corresponding vectors. A second function is obtained by applying a Distributional Compositional Semantics operator, in line with the approaches introduced in (Mitchell and Lapata, 2010), and it is adopted to account for semantic composition. In particular, the approach described in (Croce et al., 2012c) has been applied. It is based on space projection operations over basic geometric lexical representations: syntactic bigrams are projected in the so called Support Subspace (Annesi et al., 2012), aimed at emphasizing the semantic features shared by the compound words. The aim is to model semantics of syntactic bi-grams as projections in lexically-driven subspaces. In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic"
S13-1007,S12-1061,0,0.403474,"In order to extend this approach to handle entire sentences, we need to convert them in syntactic representations compatible with the compositional operators proposed. A dependency grammar based formalism captures binary syntactic relations between the words, expressed as nodes in a dependency graph. Given a sentence, the parse structure is acquired and different triples (w1 , w2 , r) are generated, where w1 is the relation governor, w2 is the dependent and r is the grammatical type. In (Croce et al., 2012c) a simple approach is defined, and it is inspired by the notion of Soft Cardinality, (Jimenez et al., 2012). Given a triple set T = {t1 , . . . , tn } extracted from a sentence S and a similarity sim(ti , tj ), the Soft Cardinality is estimated P|T |P|T | as |S|0sim u ti ( tj sim(ti , tj )p )−1 , where parameter p controls the “softness” of the cardinality: with p = 1 element similarities are unchanged while higher value will tend to the Classical Cardinality measure. Notice that differently from the previous usage of the Soft Cardinality notion, we did not apply it to sets of individual words, but to the sets of dependencies (i.e. triples) derived from the two sentences. The sim function here can"
S13-1007,S12-1060,0,0.169897,"Missing"
S13-2060,W11-0705,0,0.18532,"g. retweets (“RT”), user references (“@”), hashtags (“#”) or other typical web abbreviations, such as emoticons or acronyms. Classical approaches to sentiment analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: most of them focus on relatively large texts, e.g. movie or product reviews, and performance drops are experimented in tweets scenario. Some recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Agarwal et al., 2011). Specific approaches and feature modeling are used to achieve good accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicon and tweet specific features (e.g. hashtag, retweet) are some of the component exploited by these works in combination with different machine learning algorithms (e.g. Naive Bayes (Pak and Paroubek, 2010), k-NN strategies (Davidov et al., 2010), SVM and Tree Kernels (Agarwal et al., 2011)). In this paper, the UNITOR system participating 369 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Se"
S13-2060,C10-2005,0,0.0811816,"ith “Twitter syntax”, e.g. retweets (“RT”), user references (“@”), hashtags (“#”) or other typical web abbreviations, such as emoticons or acronyms. Classical approaches to sentiment analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: most of them focus on relatively large texts, e.g. movie or product reviews, and performance drops are experimented in tweets scenario. Some recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Agarwal et al., 2011). Specific approaches and feature modeling are used to achieve good accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicon and tweet specific features (e.g. hashtag, retweet) are some of the component exploited by these works in combination with different machine learning algorithms (e.g. Naive Bayes (Pak and Paroubek, 2010), k-NN strategies (Davidov et al., 2010), SVM and Tree Kernels (Agarwal et al., 2011)). In this paper, the UNITOR system participating 369 Second Joint Conference on Lexical and Computational Semanti"
S13-2060,W10-2802,1,0.419966,"function that reflects the lexical overlap between tweets. Each text is represented as a vector whose dimensions correspond to different words. Each dimension represents a boolean indicator of the presence or not of a word in the text. The kernel function is the cosine similarity between vector pairs. Lexical Semantic Kernel (LSK) A kernel function is obtained to generalize the lexical information of tweets, without exploiting any manually coded resource. Basic lexical information is obtained by a co-occurrence Word Space built accordingly to the methodology described in (Sahlgren, 2006) and (Croce and Previtali, 2010). A word-by-context matrix M is obtained through a large scale corpus analysis. Then the Latent Semantic Analysis (Landauer and Dumais, 1997) technique is applied as follows. The matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965) into the product of three new matrices: U , S, and V so that S is diagonal and M = U SV T . M is then approximated by Mk = Uk Sk VkT , where only the first k columns of U and V are used, corresponding to the first k greatest singular values. The original statistical information about M is captured by the new k-dimensional space,"
S13-2060,D11-1096,1,0.91129,"et al., 2013) models the sentiment analysis stage as a classification task. A Support Vector Machine (SVM) classifier learns the association between short texts and polarity classes (i.e. positive, negative, neutral). Different kernel functions (Shawe-Taylor and Cristianini, 2004) have been used: each kernel aims at capturing specific aspects of the semantic similarity between two tweets, according to syntactic and lexical information. In particular, in line with the idea of using convolution tree kernels to model complex semantic tasks, e.g. (Collins and Duffy, 2001; Moschitti et al., 2008; Croce et al., 2011), we adopted the Smoothed Partial Tree Kernel (Croce et al., 2011) (SPTK). It is a state-of-the-art convolution kernel that allows to measure the similarity between syntactic structures, which are partially similar and whose nodes can differ but are nevertheless semantically related. Moreover, a Bag-of-Word and a Latent Semantic Kernel (Cristianini et al., 2002) are also combined with the SPTK in a multi-kernel approach. Our aim is to design a system that exhibits wide applicability and robustness. This objective is pursued by adopting an approach that avoids the use of any manually coded reso"
S13-2060,C10-2028,0,0.0807529,"short, informal and characterized by their own particular language with “Twitter syntax”, e.g. retweets (“RT”), user references (“@”), hashtags (“#”) or other typical web abbreviations, such as emoticons or acronyms. Classical approaches to sentiment analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: most of them focus on relatively large texts, e.g. movie or product reviews, and performance drops are experimented in tweets scenario. Some recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Agarwal et al., 2011). Specific approaches and feature modeling are used to achieve good accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicon and tweet specific features (e.g. hashtag, retweet) are some of the component exploited by these works in combination with different machine learning algorithms (e.g. Naive Bayes (Pak and Paroubek, 2010), k-NN strategies (Davidov et al., 2010), SVM and Tree Kernels (Agarwal et al., 2011)). In this paper, the UNITOR system partici"
S13-2060,J08-2003,1,0.839925,"in Twitter task (Wilson et al., 2013) models the sentiment analysis stage as a classification task. A Support Vector Machine (SVM) classifier learns the association between short texts and polarity classes (i.e. positive, negative, neutral). Different kernel functions (Shawe-Taylor and Cristianini, 2004) have been used: each kernel aims at capturing specific aspects of the semantic similarity between two tweets, according to syntactic and lexical information. In particular, in line with the idea of using convolution tree kernels to model complex semantic tasks, e.g. (Collins and Duffy, 2001; Moschitti et al., 2008; Croce et al., 2011), we adopted the Smoothed Partial Tree Kernel (Croce et al., 2011) (SPTK). It is a state-of-the-art convolution kernel that allows to measure the similarity between syntactic structures, which are partially similar and whose nodes can differ but are nevertheless semantically related. Moreover, a Bag-of-Word and a Latent Semantic Kernel (Cristianini et al., 2002) are also combined with the SPTK in a multi-kernel approach. Our aim is to design a system that exhibits wide applicability and robustness. This objective is pursued by adopting an approach that avoids the use of an"
S13-2060,pak-paroubek-2010-twitter,0,0.369473,"009). 1 (1) http://www.twitter.com (2) Tweets are short, informal and characterized by their own particular language with “Twitter syntax”, e.g. retweets (“RT”), user references (“@”), hashtags (“#”) or other typical web abbreviations, such as emoticons or acronyms. Classical approaches to sentiment analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: most of them focus on relatively large texts, e.g. movie or product reviews, and performance drops are experimented in tweets scenario. Some recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Agarwal et al., 2011). Specific approaches and feature modeling are used to achieve good accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarity lexicon and tweet specific features (e.g. hashtag, retweet) are some of the component exploited by these works in combination with different machine learning algorithms (e.g. Naive Bayes (Pak and Paroubek, 2010), k-NN strategies (Davidov et al., 2010), SVM and Tree Kernels (Agarwal et al., 2"
S13-2060,W02-1011,0,0.0138913,"adjust their strategies. In such a scenario, the interest in the analysis of the sentiment expressed by people is rapidly growing. Twitter1 represents an intriguing source of information as it is used to share opinions and sentiments about brands, products, or situations (Jansen et al., 2009). 1 (1) http://www.twitter.com (2) Tweets are short, informal and characterized by their own particular language with “Twitter syntax”, e.g. retweets (“RT”), user references (“@”), hashtags (“#”) or other typical web abbreviations, such as emoticons or acronyms. Classical approaches to sentiment analysis (Pang et al., 2002; Pang and Lee, 2008) are not directly applicable to tweets: most of them focus on relatively large texts, e.g. movie or product reviews, and performance drops are experimented in tweets scenario. Some recent works tried to model the sentiment in tweets (Go et al., 2009; Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Bifet and Frank, 2010; Croce and Basili, 2012; Barbosa and Feng, 2010; Agarwal et al., 2011). Specific approaches and feature modeling are used to achieve good accuracy levels in tweet polarity recognition. For example, the use of n-grams, POS tags, polarit"
S13-2060,W00-0726,0,0.0161045,"this function emphasizes lexical nodes. It computes the similarity between lexical nodes as the similarity between words in the Word Space. So, this kernel allows a generalization both from the syntactic and the lexical point of view. However, tree kernel methods are biased by parsing accuracy and standard NLP parsers suffer accuracy loss in this scenario (Foster et al., 2011). It is mainly due to the complexities of the language adopted in tweets. In this work, we do not use a representation that depends on full parse trees. A syntactic representation derived from tweets chunking (Tjong Kim Sang and Buchholz, 2000) is here adopted, as shown in Figure 1. 371 Notice that no explicit manual feature engineering is applied. On the contrary we expect that discriminative lexical and syntactic information (e.g. negation) is captured by the kernel in the implicit feature space, as discussed in (Collins and Duffy, 2001). A multiple kernel approach Kernel methods are appealing as they can be integrated in various machine learning algorithms, such as SVM. Moreover a combination of kernels is still a kernel function (Shawe-Taylor and Cristianini, 2004). We employed a linear combination αBOWK + βLSK + γSPTK in order"
S13-2060,S13-2052,0,0.145295,"Missing"
S13-2060,D11-1061,0,0.118354,"Missing"
S13-2096,P10-1025,1,0.818624,"ly analyzed and a Word Space, (Sahlgren, 2006), is acquired as follows. A word-by-context matrix M is obtained through a large scale corpus analysis. 575 Then the Latent Semantic Analysis (Landauer and Dumais, 1997) technique is applied to reduce the space dimensionality. Moreover it provides a way to project a generic word wi into a k-dimensional space where each row corresponds to the representation vector w ~i . In such a space, the distance between vectors reflects the similarity between corresponding words. The resulting feature vector representing wi is then augmented with w ~i , as in (Croce et al., 2010), where the benefits of such information have been reported in the FrameNet-based Semantic Role Labeling task. 3 Relation identification The UNITOR-HMM-TK system tackles Relation Identification task by determining which spatial roles, discovered in the previous classification phase, can be combined to determine valid spatial relations. Our method is inspired by the work of (Roberts and Harabagiu, 2012), where all possible spatial roles are first generated through heuristics and then combinatorially combined to acquire candidate relations; valid spatial relations are finally determined using a"
S13-2096,D11-1096,1,0.812433,"similar vectors. As an example, we expect that a word like “table”, maybe a L ANDMARK in a training example, is more similar to “chair” as compared with “phone”. In the second step, all roles found in a sentence are combined to generate candidate relations, which are then verified by a Support Vector Machine (SVM) classifier. As the entire sentence is informative to determine the proper conjunction of all roles, we apply a kernel function within the classifier, that enhances both syntactic and lexical information of the examples. We adopted the Smoothed Partial Tree Kernel (SPTK), defined in (Croce et al., 2011): it is convolution kernel that allows to measure the similarity between syntactic structures, which are partially similar and whose nodes can differ, but are semantically related. Each example is represented as a tree structure directly derived from the sentence dependency parse, thus avoiding the manual definition of features. Similarity between lexical nodes is measured in the same Word Space mentioned above. In the rest of the paper, Section 2 discusses the SVMhmm based approach. The SPTK-based learning algorithm will be presented in Section 3. Finally, results obtained in the competition"
S13-2096,S13-2044,0,0.64334,"es this task very challenging. For example, in the same Example 1, another preposition “on” can be considered, but the phrase “the phone” is not a spatial role, as it refers to a communication mean. This mainly depends on the semantics of the grammatical head words, i.e. chair and phone. Such phenomena are crucial in many learning frameworks, as in kernel-based learning (Shawe-Taylor and Cristianini, 2004), where the decision is based on the similarity between training and testing data. This paper describes the UNITOR-HMM-TK system participating in the Semeval 2013 Spatial Role Labeling Task (Kolomiyets et al., 2013), addressing three of the five defined sub-tasks: In this paper the UNITOR-HMM-TK system participating in the Spatial Role Labeling task at SemEval 2013 is presented. The spatial roles classification is addressed as a sequence-based word classification problem: the SVMhmm learning algorithm is applied, based on a simple feature modeling and a robust lexical generalization achieved through a Distributional Model of Lexical Semantics. In the identification of spatial relations, roles are combined to generate candidate relations, later verified by a SVM classifier. The Smoothed Partial Tree Kerne"
S13-2096,kordjamshidi-etal-2010-spatial,0,0.28728,"Missing"
S13-2096,S12-1048,0,0.511317,"h the problems of identifying spatial roles and relations as a sequence of two main classification steps. 573 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic c Evaluation (SemEval 2013), pages 573–579, Atlanta, Georgia, June 14-15, 2013. 2013 Association for Computational Linguistics In the first step, each word in the sentence is classified by a sequence-based classifier with respect to the possible spatial roles. It is in line with other methods based on sequence-based classifier for SpRL (Kordjamshidi et al., 2011; Kordjamshidi et al., 2012b). Our labeling has been inspired by the work in (Croce et al., 2012), where the SVMhmm learning algorithm, formulated in (Altun et al., 2003), has been applied to the classical FrameNet-based Semantic Role Labeling. The main contribution in (Croce et al., 2012) is the adoption of shallow grammatical features (e.g. POStag sequences) instead of the full syntax of the sentence, in order to avoid over-fitting over training data. Moreover, lexical information has been generalized through the use of a Word Space, in line with (Schutze, 1998; Sahlgren, 2006): it consists in a Distributional Model o"
S13-2096,S12-1056,0,0.167085,"entation vector w ~i . In such a space, the distance between vectors reflects the similarity between corresponding words. The resulting feature vector representing wi is then augmented with w ~i , as in (Croce et al., 2010), where the benefits of such information have been reported in the FrameNet-based Semantic Role Labeling task. 3 Relation identification The UNITOR-HMM-TK system tackles Relation Identification task by determining which spatial roles, discovered in the previous classification phase, can be combined to determine valid spatial relations. Our method is inspired by the work of (Roberts and Harabagiu, 2012), where all possible spatial roles are first generated through heuristics and then combinatorially combined to acquire candidate relations; valid spatial relations are finally determined using a SVM classifier. We aim at reducing the potentially huge search space, by considering only spatial roles proposed by our sequential tagging approach, described in Section 2. Most importantly, we avoid the manual feature engineering phase of (Roberts and Harabagiu, 2012). Candidate relations are not represented as vectors, whose dimensions are manually defined features useful for the target classificatio"
S13-2096,J98-1004,0,0.197671,"assifier for SpRL (Kordjamshidi et al., 2011; Kordjamshidi et al., 2012b). Our labeling has been inspired by the work in (Croce et al., 2012), where the SVMhmm learning algorithm, formulated in (Altun et al., 2003), has been applied to the classical FrameNet-based Semantic Role Labeling. The main contribution in (Croce et al., 2012) is the adoption of shallow grammatical features (e.g. POStag sequences) instead of the full syntax of the sentence, in order to avoid over-fitting over training data. Moreover, lexical information has been generalized through the use of a Word Space, in line with (Schutze, 1998; Sahlgren, 2006): it consists in a Distributional Model of Lexical Semantics derived from the unsupervised analysis of an unlabeled large-scale corpus. The result is a geometrical space where words with similar meaning, e.g. involved in a paradigmatic or almost-synonymic relations, will be projected in similar vectors. As an example, we expect that a word like “table”, maybe a L ANDMARK in a training example, is more similar to “chair” as compared with “phone”. In the second step, all roles found in a sentence are combined to generate candidate relations, which are then verified by a Support"
S13-2096,N04-3012,0,\N,Missing
S14-2135,J08-2003,1,0.806929,"details: http://creativecommons.org/licenses/by/4.0/ 1 2 (1) http://www.amazon.com 3 http://www.tripadvisor.com http://alt.qcri.org/semeval2014/task4/ 761 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 761–767, Dublin, Ireland, August 23-24, 2014. order to decide what is an aspect term . All the remaining tasks are modeled as multi-kernel classification problems based on Support Vector Machines (SVMs). Various representation have been exploited using proper kernel functions (ShaweTaylor and Cristianini, 2004a). Tree Kernels (Collins and Duffy, 2001; Moschitti et al., 2008; Croce et al., 2011) are adopted in order to capture structural sentence information derived from the parse tree. Moreover, corpus-driven methods are used in order to acquire meaning generalizations in an unsupervised fashion (e.g. see (Pado and Lapata, 2007)) through the analysis of distributions of word occurrences in texts. It is obtained by the construction of a Word Space (Sahlgren, 2006), which provides a distributional model of lexical semantics. Latent Semantic Kernel (Cristianini et al., 2002) is thus applied within such space. In the remaining, in Section 2 and 3 we will explain our"
S14-2135,S13-2060,1,0.852558,"ce x = (x1 . . . xl ) ∈ X of feature vectors x1 . . . xl , the model predicts a tag sequence y = (y1 . . . yl ) ∈ Y after learning a linear discriminant function F : X × Y → R over inputoutput pairs. The labeling f (x) is thus defined as: f (x) = arg maxy∈Y F (x, y; w) and it is obtained by maximizing F over the response variable, y, for a specific given input x. F is linear in some 4 Modeling Features for ATE 3 Multiple Kernel Approach for Polarity and Category Detection We approached the remaining three subtasks of the pipeline as classification problems with multiple kernels, in line with (Castellucci et al., 2013). We used Support Vector Machines (SVMs) (Joachims, 1999), a maximum-margin classifier that realizes a linear discriminative model. The kernelized version of SVM learns from instances xi exploiting rich similarity measures (i.e.the kernel functions) K(xi , xj ) = hφ(xi ) · φ(xj )i. In this way projection functions φ(·) can be implicitly used in order to transform the initial feature space into a more expressive one, where a hyperplane that separates the data with the widest margin can be found. Kernels can directly operate on variegate forms of representation, such as feature vectors, trees, s"
S14-2135,J07-2002,0,0.0149582,"n, Ireland, August 23-24, 2014. order to decide what is an aspect term . All the remaining tasks are modeled as multi-kernel classification problems based on Support Vector Machines (SVMs). Various representation have been exploited using proper kernel functions (ShaweTaylor and Cristianini, 2004a). Tree Kernels (Collins and Duffy, 2001; Moschitti et al., 2008; Croce et al., 2011) are adopted in order to capture structural sentence information derived from the parse tree. Moreover, corpus-driven methods are used in order to acquire meaning generalizations in an unsupervised fashion (e.g. see (Pado and Lapata, 2007)) through the analysis of distributions of word occurrences in texts. It is obtained by the construction of a Word Space (Sahlgren, 2006), which provides a distributional model of lexical semantics. Latent Semantic Kernel (Cristianini et al., 2002) is thus applied within such space. In the remaining, in Section 2 and 3 we will explain our approach in more depth. Section 4 discusses the results in the SemEval-2014 challenge. 2 combined feature representation of inputs and outputs Φ(x, y), i.e. F (x, y; w) = hw, Φ(x, y)i. In SV M hmm the observations x1 . . . xl can be naturally expressed in ter"
S14-2135,W02-1011,0,0.0158648,"spect is recognized, i.e. a positive polarity is expressed with respect to fried rice. In the Aspect Category Detection (ACD) task the category evoked in a sentence is identified, e.g. the food category in sentence 1). In the Aspect Category Polarity (ACP) task the polarity of each expressed category is recognized, e.g. a positive category polarity is expressed in sentence 1. Different strategies have been experimented in recent years. Classical approaches are based on machine learning techniques and rely on simple representation features, such as unigrams, bigrams, Part-Of-Speech (POS) tags (Pang et al., 2002; Pang and Lee, 2008; Wiebe et al., 1999). Other approaches adopt sentiment lexicons in order to exploit some sort of prior knowledge about the polar orientation of words. These resources are usually semi-automatically compiled and provide scores associating individual words to sentiments or polarity orientation. In this paper, the UNITOR system participating to the SemEval-2014 Aspect Based Sentiment Analysis task (Pontiki et al., 2014) is presented. The ATE task is modeled as a sequential labeling problem. A sentence is considered as a sequence of tokens: a Markovian algorithm is adopted in"
S14-2135,S14-2004,0,0.0575855,"s. Classical approaches are based on machine learning techniques and rely on simple representation features, such as unigrams, bigrams, Part-Of-Speech (POS) tags (Pang et al., 2002; Pang and Lee, 2008; Wiebe et al., 1999). Other approaches adopt sentiment lexicons in order to exploit some sort of prior knowledge about the polar orientation of words. These resources are usually semi-automatically compiled and provide scores associating individual words to sentiments or polarity orientation. In this paper, the UNITOR system participating to the SemEval-2014 Aspect Based Sentiment Analysis task (Pontiki et al., 2014) is presented. The ATE task is modeled as a sequential labeling problem. A sentence is considered as a sequence of tokens: a Markovian algorithm is adopted in Introduction In recent years, many websites started offering a high level interaction with users, who are no more a passive audience, but can actively produce new contents. For instance, platforms like Amazon1 or TripAdvisor2 allow people to express their opinions on products, such as food, electronic items or clothes. Obviously, companies are interested in understanding what customers think about their brands and products, in order to i"
S14-2135,W10-2802,1,0.855939,"rate on variegate forms of representation, such as feature vectors, trees, sequences or graphs. Then, modeling instances in different representations, specific kernels can be defined in order to explore different linguistic information. These variety of kernel functions www.cs.cornell.edu/People/tj/svm light/svm hmm.html 762 K1 . . . Kn can be independently defined and the combinations K1 + K2 + . . . of multiple functions can be integrated into SVM as they are still kernels. The next section describes the representations as well as the kernel functions. 3.1 described in (Sahlgren, 2006) and (Croce and Previtali, 2010). A word-by-context matrix M is obtained through a large scale corpus analysis. Then the Latent Semantic Analysis (Landauer and Dumais, 1997) technique is applied as follows. The matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965) into the product of three new matrices: U , S, and V so that S is diagonal and M = U SV T . M is then approximated by Mk = Uk Sk VkT , where only the first k columns of U and V are used, corresponding to the first k greatest singular values. This approximation supplies a way to project a generic word wi into the k-dimensional spa"
S14-2135,D11-1096,1,0.934088,"commons.org/licenses/by/4.0/ 1 2 (1) http://www.amazon.com 3 http://www.tripadvisor.com http://alt.qcri.org/semeval2014/task4/ 761 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 761–767, Dublin, Ireland, August 23-24, 2014. order to decide what is an aspect term . All the remaining tasks are modeled as multi-kernel classification problems based on Support Vector Machines (SVMs). Various representation have been exploited using proper kernel functions (ShaweTaylor and Cristianini, 2004a). Tree Kernels (Collins and Duffy, 2001; Moschitti et al., 2008; Croce et al., 2011) are adopted in order to capture structural sentence information derived from the parse tree. Moreover, corpus-driven methods are used in order to acquire meaning generalizations in an unsupervised fashion (e.g. see (Pado and Lapata, 2007)) through the analysis of distributions of word occurrences in texts. It is obtained by the construction of a Word Space (Sahlgren, 2006), which provides a distributional model of lexical semantics. Latent Semantic Kernel (Cristianini et al., 2002) is thus applied within such space. In the remaining, in Section 2 and 3 we will explain our approach in more dep"
S14-2135,C10-1039,0,0.0320168,"as it occurs on a left or right window of 3 tokens around a target. Left contexts of targets are distinguished from the right ones, in order to capture asymmetric syntactic behaviors 6 Each word is lemmatized to reduce data sparseness, but they are enriched with POS tags. 764 (e.g., useful for verbs): 40,000 dimensional vectors are thus derived for each target. The Singular Value Decomposition is applied and the space dimensionality is reduced to k = 250. Two corpora are used for generating two different Word Spaces, one for the laptop and one for the restaurant domain. The Opinosis dataset (Ganesan et al., 2010) is used to build the electronic domain Word Space, while the restaurant domain corpus adopted is the TripAdvisor dataset7 . Both provided data and indomain data are first pre-processed through the Stanford Parser (Klein and Manning, 2003) in order to obtain POS tags or Dependency Trees. A modified version of LibSVM has been adopted to implement Tree Kernel. Parameters such as the SVM regularization coefficient C, the kernel parameters (for instance the degree of the polynomial kernel) have been selected after a tuning stage based on a 5-fold cross validation. 4.1 Table 1: Aspect Term Extracti"
S14-2135,P99-1032,0,0.124235,"Missing"
S14-2135,H05-1044,0,0.0193953,". they represent a boolean indicator of the presence or not of a word in the text. The resulting kernel function is the cosine similarity (or linear kernel) between vector pairs, i.e. linBoW . In line with (Shawe-Taylor and Cristianini, 2004b) we investigated the contribution of the Polynomial Kernel of degree 2, poly2BoW as it defines an implicit space where also feature pairs, i.e. words pairs, are considered. In the polarity detection tasks, several polarity lexicons have been exploited in order to have useful hints of the intrinsic polarity of words. We adopted MPQA Subjectivity Lexicon5 (Wilson et al., 2005) and NRC Emotion Lexicon (Mohammad and Turney, 2013): they are large collection of words provided with the underlying emotion they generally evoke. While the former considers only positive and negative sentiments, the latter considers also eight primary emotions, organized in four opposing pairs, joy-sadness, angerfear, trust-disgust, and anticipation-surprise. We define the Lexicon Based (LB) vectors as follows. For each lexicon, let E = {e1 , ..., e|E |} be the emotion vocabulary defined in it. Let w ∈ s be a word occurring in sentence s, with I(w, i) being the indicator function whose outpu"
S14-2135,P03-1054,0,0.00943904,"but they are enriched with POS tags. 764 (e.g., useful for verbs): 40,000 dimensional vectors are thus derived for each target. The Singular Value Decomposition is applied and the space dimensionality is reduced to k = 250. Two corpora are used for generating two different Word Spaces, one for the laptop and one for the restaurant domain. The Opinosis dataset (Ganesan et al., 2010) is used to build the electronic domain Word Space, while the restaurant domain corpus adopted is the TripAdvisor dataset7 . Both provided data and indomain data are first pre-processed through the Stanford Parser (Klein and Manning, 2003) in order to obtain POS tags or Dependency Trees. A modified version of LibSVM has been adopted to implement Tree Kernel. Parameters such as the SVM regularization coefficient C, the kernel parameters (for instance the degree of the polynomial kernel) have been selected after a tuning stage based on a 5-fold cross validation. 4.1 Table 1: Aspect Term Extraction Results - Laptop. System (Rank) UNITOR-C (10/28) UNITOR-U (6/28) Best-System-C (1/28) Best-System-U (2/28) R .5764 .6162 .6651 .6712 F1 .6608 .6795 .7455 .7403 Table 2: Aspect Term Extraction - Restaurants. System (Rank) UNITOR-C (5/29)"
S14-2135,P94-1019,0,\N,Missing
S16-1172,P15-2113,1,0.5406,"Missing"
S16-1172,D11-1096,1,0.278223,"agated to their upper constituents). This method discriminates aligned sub-fragments from non-aligned ones, allowing the learning algorithm to capture relational patterns, e.g., the REL-best beach and the RELbest option. Thus, given two pairs of sentences pa = ha1 , a2 i and pb = hb1 , b2 i, some tree kernel combinations can be defined: TK+ (pa , pb ) = × (pa , pb ) AllTK = TK(a1 , b1 ) + TK(a2 , b2 ) TK(a1 , b1 ) × TK(a2 , b2 ) + TK(a1 , b2 ) × TK(a2 , b1 ), where TK is a generic tree kernel, such as the Partial Tree Kernel (PTK) (Moschitti, 2006), or the Smoothed Partial Tree Kernel (SPTK) (Croce et al., 2011). Tree kernels, computing the shared substructures between parse trees, are effective in evaluating the syntactic similarity between two texts. The proposed tree kernel combinations extend such reasoning to text pairs, and can capture emerging pairwise patterns. Therefore this method can be effective in recognizing valid question/answer pairs, or similar questions, even in those cases in which the two texts have few words in common that would cause the failure of any intra-pair approach. 4 Task Specific Features In this section, we describe features specifically developed for cQA. A single fea"
S16-1172,P15-4004,1,0.505629,"ns, q1 , . . . , q10 , (retrieved by a search engine), each one associated with its first 10 comments, cq1 , . . . , cq10 , appearing in its thread, re-rank the 100 comments according to their relevance with respect to o, i.e., the good comments are to be ranked above potential or bad comments. All the above subtasks have been modeled as binary classification problems: kernel-based classifiers are trained and the classification score is used to sort the instances and produce the final ranking. All classifiers and kernels have been implemented within the Kernel-based Learning Platform2 (KeLP) (Filice et al., 2015b), thus determining the team’s name. The proposed solution provides three main contributions: (i) we employ the approach proposed in (Severyn and Moschitti, 2012), which applies tree kernels directly to question and answer texts modeled as pairs of linked syntactic trees. We further improve the methods using the kernels proposed in (Filice et al., 2015c). (ii) we extended the features developed in (Barr´on-Cede˜no et al., 2015), by adopting several features (also derived from Word Embeddings (Mikolov et al., 2013)). (iii) we propose 2 http://www.qatarliving.com/forum https://github.com/SAG-Ke"
S16-1172,P15-1097,1,0.834522,"ns, q1 , . . . , q10 , (retrieved by a search engine), each one associated with its first 10 comments, cq1 , . . . , cq10 , appearing in its thread, re-rank the 100 comments according to their relevance with respect to o, i.e., the good comments are to be ranked above potential or bad comments. All the above subtasks have been modeled as binary classification problems: kernel-based classifiers are trained and the classification score is used to sort the instances and produce the final ranking. All classifiers and kernels have been implemented within the Kernel-based Learning Platform2 (KeLP) (Filice et al., 2015b), thus determining the team’s name. The proposed solution provides three main contributions: (i) we employ the approach proposed in (Severyn and Moschitti, 2012), which applies tree kernels directly to question and answer texts modeled as pairs of linked syntactic trees. We further improve the methods using the kernels proposed in (Filice et al., 2015c). (ii) we extended the features developed in (Barr´on-Cede˜no et al., 2015), by adopting several features (also derived from Word Embeddings (Mikolov et al., 2013)). (iii) we propose 2 http://www.qatarliving.com/forum https://github.com/SAG-Ke"
S16-1172,P07-1098,1,0.29818,"a score corresponding to a certain type of shared information or similarity between the elements within a pair. These intra-pair similarity approaches cannot capture complex relational pattern between the elements in the pair, such as a rewriting rule characterizing a valid paraphrase, or a questionanswer pattern. Such information might be manually encoded into specific features, but it would require a complex feature engineering and a deep knowledge of the linguistic involved phenomena. To automatize relational learning between pairs of texts, e.g., in case of QA, one of the early works is (Moschitti et al., 2007; Moschitti, 2008). This approach was improved in several subsequent researches (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b; Severyn and Moschitti, 2013; Tymoshenko et al., 2014; Tymoshenko and Moschitti, 2015), exploiting relational tags and linked open data. In particular, in (Filice et al., 2015c), we propose new inter-pair methods to directly employ text pairs into a kernel-based learning framework. In the proposed approach, we integrate the information derived from simple intra-pair similarity functions (Section 3.1) and from the structural analogies (Sectio"
S16-1172,D13-1044,1,0.0518673,"ational pattern between the elements in the pair, such as a rewriting rule characterizing a valid paraphrase, or a questionanswer pattern. Such information might be manually encoded into specific features, but it would require a complex feature engineering and a deep knowledge of the linguistic involved phenomena. To automatize relational learning between pairs of texts, e.g., in case of QA, one of the early works is (Moschitti et al., 2007; Moschitti, 2008). This approach was improved in several subsequent researches (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b; Severyn and Moschitti, 2013; Tymoshenko et al., 2014; Tymoshenko and Moschitti, 2015), exploiting relational tags and linked open data. In particular, in (Filice et al., 2015c), we propose new inter-pair methods to directly employ text pairs into a kernel-based learning framework. In the proposed approach, we integrate the information derived from simple intra-pair similarity functions (Section 3.1) and from the structural analogies (Section 3.2). 3.1 Intra-pair similarities In subtasks A and C, a good comment is likely to share similar terms with the question. In subtask B a question that is relevant to another probabl"
S16-1172,W13-3509,1,0.824988,"milarity approaches cannot capture complex relational pattern between the elements in the pair, such as a rewriting rule characterizing a valid paraphrase, or a questionanswer pattern. Such information might be manually encoded into specific features, but it would require a complex feature engineering and a deep knowledge of the linguistic involved phenomena. To automatize relational learning between pairs of texts, e.g., in case of QA, one of the early works is (Moschitti et al., 2007; Moschitti, 2008). This approach was improved in several subsequent researches (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b; Severyn and Moschitti, 2013; Tymoshenko et al., 2014; Tymoshenko and Moschitti, 2015), exploiting relational tags and linked open data. In particular, in (Filice et al., 2015c), we propose new inter-pair methods to directly employ text pairs into a kernel-based learning framework. In the proposed approach, we integrate the information derived from simple intra-pair similarity functions (Section 3.1) and from the structural analogies (Section 3.2). 3.1 Intra-pair similarities In subtasks A and C, a good comment is likely to share similar terms with the question. In sub"
S16-1172,E14-1070,1,0.784325,"lements in the pair, such as a rewriting rule characterizing a valid paraphrase, or a questionanswer pattern. Such information might be manually encoded into specific features, but it would require a complex feature engineering and a deep knowledge of the linguistic involved phenomena. To automatize relational learning between pairs of texts, e.g., in case of QA, one of the early works is (Moschitti et al., 2007; Moschitti, 2008). This approach was improved in several subsequent researches (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b; Severyn and Moschitti, 2013; Tymoshenko et al., 2014; Tymoshenko and Moschitti, 2015), exploiting relational tags and linked open data. In particular, in (Filice et al., 2015c), we propose new inter-pair methods to directly employ text pairs into a kernel-based learning framework. In the proposed approach, we integrate the information derived from simple intra-pair similarity functions (Section 3.1) and from the structural analogies (Section 3.2). 3.1 Intra-pair similarities In subtasks A and C, a good comment is likely to share similar terms with the question. In subtask B a question that is relevant to another probably shows common words. Fol"
W01-1005,J96-1001,0,\N,Missing
W01-1005,J96-3009,0,\N,Missing
W01-1005,W97-0314,1,\N,Missing
W01-1013,2000.iwpt-1.7,0,0.155609,"Missing"
W01-1013,P00-1064,0,0.0912682,"Missing"
W01-1013,O98-4002,1,0.865745,"Missing"
W01-1013,W98-0705,0,0.144557,"Missing"
W01-1013,M95-1017,0,\N,Missing
W04-2510,A97-1012,0,0.0453747,"Missing"
W04-2510,M98-1007,0,0.0923267,"Missing"
W04-2510,W01-1205,0,0.0851294,"Missing"
W04-2510,P01-1037,0,\N,Missing
W04-2510,M95-1017,0,\N,Missing
W05-0407,P02-1034,0,0.332912,"e selection techniques (Kohavi and Sommerfield, 1995) are not so useful since the critical problem relates to feature generation rather than selection. For example, the design of features for a natural language syntactic parse-tree re-ranking problem (Collins, 2000) cannot be carried out without a deep knowledge about automatic syntactic parsing. The modeling of syntactic/semantic based features should take into account linguistic aspects to detect the interesting context, e.g. the ancestor nodes or the semantic dependencies (Toutanova et al., 2004). A viable alternative has been proposed in (Collins and Duffy, 2002), where convolution kernels were used to implicitly define a tree substructure space. The selection of the relevant structural features was left to the voted perceptron learning algorithm. Another interesting model for parsing re-ranking based on tree kernel is presented in (Taskar et al., 2004). The good results show that tree kernels are very promising for automatic feature engineering, especially when the available knowledge about the phenomenon is limited. Along the same line, automatic learning tasks that rely on syntactic information may take advantage of a tree kernel approach. One of s"
W05-0407,P04-1054,0,0.0852124,"feature descriptors to generate different feature type. The descriptors, which are quantified logical prepositions, are instantiated by means of a concept graph which encodes the structural data. In the case of relation extraction the concept graph is associated with a syntactic shallow parse and the extracted propositional features express fragments of a such syntactic structure. The experiments over the named entity class categorization show that when the description language selects an adequate set of tree fragments the Voted Perceptron algorithm increases its classification accuracy. In (Culotta and Sorensen, 2004) a dependency tree kernel is used to detect the Named Entity classes in natural language texts. The major novelty was the combination of the contiguous and sparse kernels with the word kernel. The results show that the contiguous outperforms the sparse kernel and the bag-of-words. 7 Conclusions The feature design for new natural language learning tasks is difficult. We can take advantage from the kernel methods to model our intuitive knowledge about the target linguistic phenomenon. In this paper we have shown that we can exploit the properties of tree kernels to engineer syntactic features fo"
W05-0407,W03-1008,0,0.0144628,"ally from Arg0 to Arg9, ArgA and ArgM. Figure 1 shows an example of the PB predicate annotation of the sentence: John Predicates in PB are only embodied by verbs whereas most of the times Arg0 is the subject, Arg1 is the direct object and ArgM indicates locations, as in our example. S VP N John Arg. 0 V NP rented D Predicate a PP N IN N room in Boston Arg. 1 Arg. M Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for automatic predicate argument extraction have been developed, e.g. (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003; Pradhan et al., 2004). Their common characteristic is the adoption of feature spaces that model predicateargument structures in a flat feature representation. In the next section, we present the common parse tree-based approach to this problem. 2.1 Predicate Argument Extraction Given a sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments. This problem is usually divided in two subtasks: (a) the detection of the target argument boundaries, i.e. the span of its words in the sentence, and (b) the classification of the argume"
W05-0407,J02-3001,0,0.417786,"edicate, the expected arguments are labeled sequentially from Arg0 to Arg9, ArgA and ArgM. Figure 1 shows an example of the PB predicate annotation of the sentence: John Predicates in PB are only embodied by verbs whereas most of the times Arg0 is the subject, Arg1 is the direct object and ArgM indicates locations, as in our example. S VP N John Arg. 0 V NP rented D Predicate a PP N IN N room in Boston Arg. 1 Arg. M Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for automatic predicate argument extraction have been developed, e.g. (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003; Pradhan et al., 2004). Their common characteristic is the adoption of feature spaces that model predicateargument structures in a flat feature representation. In the next section, we present the common parse tree-based approach to this problem. 2.1 Predicate Argument Extraction Given a sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments. This problem is usually divided in two subtasks: (a) the detection of the target argument boundaries, i.e. the span of its words in"
W05-0407,P02-1031,0,0.0841262,"ents are labeled sequentially from Arg0 to Arg9, ArgA and ArgM. Figure 1 shows an example of the PB predicate annotation of the sentence: John Predicates in PB are only embodied by verbs whereas most of the times Arg0 is the subject, Arg1 is the direct object and ArgM indicates locations, as in our example. S VP N John Arg. 0 V NP rented D Predicate a PP N IN N room in Boston Arg. 1 Arg. M Figure 1: A predicate argument structure in a parse-tree representation. Several machine learning approaches for automatic predicate argument extraction have been developed, e.g. (Gildea and Jurasfky, 2002; Gildea and Palmer, 2002; Gildea and Hockenmaier, 2003; Pradhan et al., 2004). Their common characteristic is the adoption of feature spaces that model predicateargument structures in a flat feature representation. In the next section, we present the common parse tree-based approach to this problem. 2.1 Predicate Argument Extraction Given a sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments. This problem is usually divided in two subtasks: (a) the detection of the target argument boundaries, i.e. the span of its words in the sentence, and (b) th"
W05-0407,kingsbury-palmer-2002-treebank,0,0.0612761,"the relevant structural features was left to the voted perceptron learning algorithm. Another interesting model for parsing re-ranking based on tree kernel is presented in (Taskar et al., 2004). The good results show that tree kernels are very promising for automatic feature engineering, especially when the available knowledge about the phenomenon is limited. Along the same line, automatic learning tasks that rely on syntactic information may take advantage of a tree kernel approach. One of such tasks is the automatic boundary detection of predicate arguments of the kind defined in PropBank (Kingsbury and Palmer, 2002). For this purpose, given a predicate p in a sentence s, we can define the notion of predicate argument spanning trees (P AST s) as those syntactic subtrees of s which exactly cover all and only the p’s arguments (see Section 4.1). The set of nonspanning trees can be then associated with all the remaining subtrees of s. An automatic classifier which recognizes the spanning trees can potentially be used to detect the predicate argument boundaries. Unfortunately, the application of such classifier to all possible sentence subtrees would require an exponential execution time. As a consequence, we"
W05-0407,J93-2004,0,0.0282553,"Missing"
W05-0407,P04-1043,1,0.872609,"f the argument spanning trees and (2) how to deal with the exponential number of N ST s. For the first problem, the use of tree kernels over the P AST s can be an alternative to the manual features design as the learning machine, (e.g. SVMs) can select the most relevant features from a high dimensional feature space. In other words, we can use Eq. 1 to estimate the similarity between two P AST s avoiding to define explicit features. The same idea has been successfully applied to the parse-tree reranking task (Taskar et al., 2004; Collins and Duffy, 2002) and predicate argument classification (Moschitti, 2004). For the second problem, i.e. the high computational complexity, we can cut the search space by us52 ing a traditional boundary classifier (tbc), e.g. (Pradhan et al., 2004), which provides a small set of potential argument nodes. Let PA be the set of nodes located by tbc as arguments. We may consider the set P of the N ST s associated with any subset of PA, i.e. P = {ps : s ⊆ PA}. However, also the classification of P may be computationally problematic since theoretically there are |P |= 2|PA| members. In order to have a very efficient procedure, we applied pastc to only the PA sets associat"
W05-0407,W04-3201,0,0.194639,"eep knowledge about automatic syntactic parsing. The modeling of syntactic/semantic based features should take into account linguistic aspects to detect the interesting context, e.g. the ancestor nodes or the semantic dependencies (Toutanova et al., 2004). A viable alternative has been proposed in (Collins and Duffy, 2002), where convolution kernels were used to implicitly define a tree substructure space. The selection of the relevant structural features was left to the voted perceptron learning algorithm. Another interesting model for parsing re-ranking based on tree kernel is presented in (Taskar et al., 2004). The good results show that tree kernels are very promising for automatic feature engineering, especially when the available knowledge about the phenomenon is limited. Along the same line, automatic learning tasks that rely on syntactic information may take advantage of a tree kernel approach. One of such tasks is the automatic boundary detection of predicate arguments of the kind defined in PropBank (Kingsbury and Palmer, 2002). For this purpose, given a predicate p in a sentence s, we can define the notion of predicate argument spanning trees (P AST s) as those syntactic subtrees of s which"
W05-0407,W04-3222,0,0.0995259,"Missing"
W05-0601,C96-1005,0,0.0243895,"ss pieces and this impacts on the similarity score that should be used in IR applications. Methods to solve the above problems attempt to map a priori the terms to specific generalizations levels, i.e. to cuts in the hierarchy (e.g. (Li and Abe, 1998; Resnik, 1997)), and use corpus statistics for weighting the resulting mappings. For several tasks (e.g. in TC) this is unsatisfactory: different contexts of the same corpus (e.g. documents) may require different generalizations of the same word as they independently impact on the document similarity. On the contrary, the Conceptual Density (CD) (Agirre and Rigau, 1996) is a flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hierarchy. The CD defines a metrics according to the topological structure of WordNet and can be seemingly applied to two or more words. The measure formalized hereafter adapt to word pairs a more general definition given in (Basili et al., 2004). We denote by s¯ the set of nodes of the hierarchy rooted in the synset s, i.e. {c ∈ S|c isa s}, where S is the set of WN synsets. By definition ∀s ∈ S, s ∈ s¯. CD makes a guess about the proximity of the senses, s1 and s2 , o"
W05-0601,basili-etal-2004-similarity,1,0.81781,"ideal tree must contain 4 nodes, i.e. the grandfather which has a bf of 1 and the father which has bf of 2 for an average of 1.5. When bf is 1 the Eq. 1 degenerates to the inverse of the number of nodes in the path between s1 and s2 , i.e. the simple proximity measure used in (Siolas and d’Alch Buc, 2000). It is worth noting that for each pair CD(u1 , u2 ) determines the similarity according to the closest lexical senses, s1 , s2 ∈ s¯: the remaining senses of u1 and u2 are irrelevant, with a resulting semantic disambiguation side effect. CD has been successfully applied to semantic tagging ((Basili et al., 2004)). As the WN hierarchies for other POS classes (i.e. verb and adjectives) have topological properties different from the noun hyponimy network, their semantics is not suitably captured by Eq. 1. In this paper, Eq. 1 has thus been only applied to noun pairs. As the high number of such pairs increases the computational complexity of the target learning algorithm, efficient approaches are needed. The next section describes how kernel methods can make practical the use of the Conceptual Density in Text Categorization. 3 A WordNet Kernel for document similarity Term similarities are used to design"
W05-0601,J02-2003,0,0.0233708,"lly Section 6 derives the conclusions. 2 Term similarity based on general knowledge In IR, any similarity metric in the vector space models is driven by lexical matching. When small training material is available, few words can be effectively used and the resulting document similarity metrics may be inaccurate. Semantic generalizations overcome data sparseness problems as contributions from different but semantically similar words are made available. Methods for the induction of semantically inspired word clusters have been widely used in language modeling and lexical acquisition tasks (e.g. (Clark and Weir, 2002)). The resource employed in most works is WordNet (Fellbaum, 1998) which contains three subhierarchies: for nouns, verbs and adjectives. Each hierarchy represents lexicalized concepts (or senses) organized according to an ”isa-kind-of ” relation. A concept s is described by a set of words syn(s) called synset. The words w ∈ syn(s) are synonyms according to the sense s. For example, the words line, argumentation, logical argument and line of reasoning describe a synset which expresses the methodical process of logical reasoning (e.g. ”I can’t follow your line of reasoning”). Each word/term may"
W05-0601,J98-2002,0,0.0374322,"stance is unclear. The pervasive lexical ambiguity is also problematic as it impacts on the measure of conceptual distances between word pairs. Second, the approximation of a set of concepts by means of their generalization in the hierarchy implies a conceptual loss that affects the target IR (or NLP) tasks. For example, black and white are colors but are also chess pieces and this impacts on the similarity score that should be used in IR applications. Methods to solve the above problems attempt to map a priori the terms to specific generalizations levels, i.e. to cuts in the hierarchy (e.g. (Li and Abe, 1998; Resnik, 1997)), and use corpus statistics for weighting the resulting mappings. For several tasks (e.g. in TC) this is unsatisfactory: different contexts of the same corpus (e.g. documents) may require different generalizations of the same word as they independently impact on the document similarity. On the contrary, the Conceptual Density (CD) (Agirre and Rigau, 1996) is a flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hierarchy. The CD defines a metrics according to the topological structure of WordNet and can be see"
W05-0601,W97-0209,0,0.0322557,"The pervasive lexical ambiguity is also problematic as it impacts on the measure of conceptual distances between word pairs. Second, the approximation of a set of concepts by means of their generalization in the hierarchy implies a conceptual loss that affects the target IR (or NLP) tasks. For example, black and white are colors but are also chess pieces and this impacts on the similarity score that should be used in IR applications. Methods to solve the above problems attempt to map a priori the terms to specific generalizations levels, i.e. to cuts in the hierarchy (e.g. (Li and Abe, 1998; Resnik, 1997)), and use corpus statistics for weighting the resulting mappings. For several tasks (e.g. in TC) this is unsatisfactory: different contexts of the same corpus (e.g. documents) may require different generalizations of the same word as they independently impact on the document similarity. On the contrary, the Conceptual Density (CD) (Agirre and Rigau, 1996) is a flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hierarchy. The CD defines a metrics according to the topological structure of WordNet and can be seemingly applied"
W05-0630,W05-0620,0,0.154804,"Missing"
W05-0630,J02-3001,0,0.712927,"arquez, 2005), we capitalized on our experience on the semantic shallow parsing by extending our system, widely experimented on PropBank and FrameNet (Giuglea and Moschitti, 2004) data, with a twostep boundary detection and a hierarchical argument classification strategy. Currently, the system can work in both basic and enhanced configuration. Given the parse tree of an input sentence, the basic system applies (1) a boundary classifier to select the nodes associated with correct arguments and (2) a multi-class labeler to assign the role type. For such models, we used some of the linear (e.g. (Gildea and Jurasfky, 2002; Pradhan et al., 2005)) and structural (Moschitti, 2004) features developed in previous studies. In the enhanced configuration, the boundary annotation is subdivided in two steps: a first pass in which we label argument boundary and a second pass in which we apply a simple heuristic to eliminate the argument overlaps. We have also tried some strategies to learn such heuristics automatically. In order to do this we used a tree kernel to classify the subtrees associated with correct predicate argument structures (see (Moschitti et al., 2005)). The rationale behind such an attempt was to exploit"
W05-0630,W05-0407,1,0.90299,"For such models, we used some of the linear (e.g. (Gildea and Jurasfky, 2002; Pradhan et al., 2005)) and structural (Moschitti, 2004) features developed in previous studies. In the enhanced configuration, the boundary annotation is subdivided in two steps: a first pass in which we label argument boundary and a second pass in which we apply a simple heuristic to eliminate the argument overlaps. We have also tried some strategies to learn such heuristics automatically. In order to do this we used a tree kernel to classify the subtrees associated with correct predicate argument structures (see (Moschitti et al., 2005)). The rationale behind such an attempt was to exploit the correlation among potential arguments. Also, the role labeler is divided into two steps: (1) we assign to the arguments one out of four possible class labels: Core Roles, Adjuncts, Continuation Arguments and Co-referring Arguments, and (2) in each of the above class we apply the set of its specific classifiers, e.g. A0,..,A5 within the Core Role class. As such grouping is relatively new, the traditional features may not be sufficient to characterize each class. Thus, to generate a large set of features automatically, we again applied t"
W05-0630,W04-3212,0,0.156334,"ding to the ONE-vs.ALL scheme. To implement the multi-class classifiers we select the argument associated with the maximum among the SVM scores. To represent the Fp,a pairs we used the following features: - the Phrase Type, Predicate Word, Head Word, Governing Category, Position and Voice defined in (Gildea and Jurasfky, 2002); - the Partial Path, Compressed Path, No Direction Path, Constituent Tree Distance, Head Word POS, First and Last Word/POS in Constituent, SubCategorization and Head Word of Prepositional Phrases proposed in (Pradhan et al., 2005); and - the Syntactic Frame designed in (Xue and Palmer, 2004). 202 Figure 1: Architecture of the Hierarchical Semantic Role Labeler. 3 Hierarchical Semantic Role Labeler Having two phases for argument labeling provides two main advantages: (1) the efficiency is increased as the negative boundary examples, which are almost all parse-tree nodes, are used with one classifier only (i.e. the boundary classifier), and (2) as arguments share common features that do not occur in the non-arguments, a preliminary classification between arguments and non-arguments advantages the boundary detection of roles with fewer training examples (e.g. A4). Moreover, it may b"
W05-0630,P04-1043,1,\N,Missing
W05-1002,P97-1003,0,0.0257275,"Missing"
W05-1002,W03-1008,0,0.0225516,"nts or semantic roles are arguments of target words that can be verbs or nouns or adjectives. In FrameNet, the argument names are local to the target frames. For example, assuming that attach is the target word and Attaching is the target frame, a typical sentence annotation is the following. [Agent They] attachT gt [Item themselves] [Connector with their mouthparts] and then release a digestive enzyme secretion which eats into the skin. Several machine learning approaches for argument identification and classification have been developed, e.g. (Gildea and Jurasfky, 2002; Gildea and Palmer, ; Gildea and Hockenmaier, 2003; Pradhan et al., 2004). Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat feature representation. In the next section we present the common parse tree-based approach to this problem. 2.1 Predicate Argument Extraction Given a sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments. This problem can be divided into two subtasks: (a) the detection of the target argument boundaries, i.e. all its compounding words, and (b) the classification of the argument type, e.g."
W05-1002,J02-3001,0,0.708378,"which a word may be typically used. Frame elements or semantic roles are arguments of target words that can be verbs or nouns or adjectives. In FrameNet, the argument names are local to the target frames. For example, assuming that attach is the target word and Attaching is the target frame, a typical sentence annotation is the following. [Agent They] attachT gt [Item themselves] [Connector with their mouthparts] and then release a digestive enzyme secretion which eats into the skin. Several machine learning approaches for argument identification and classification have been developed, e.g. (Gildea and Jurasfky, 2002; Gildea and Palmer, ; Gildea and Hockenmaier, 2003; Pradhan et al., 2004). Their common characteristic is the adoption of feature spaces that model predicate-argument structures in a flat feature representation. In the next section we present the common parse tree-based approach to this problem. 2.1 Predicate Argument Extraction Given a sentence in natural language, all the predicates associated with the verbs have to be identified along with their arguments. This problem can be divided into two subtasks: (a) the detection of the target argument boundaries, i.e. all its compounding words, and"
W05-1002,kingsbury-palmer-2002-treebank,0,0.0180014,"ilarity with such functions applied to the two trees. This approach determines a more syntactically motivated verb partition than the traditional method based on flat SCF representations (e.g. the NP-PP of Figure 1). The subtrees associated with SCF group the verbs which have similar syntactic realizations, in turn, according to Levin’s theories, this would suggest that they are semantically related. A preliminary study on the benefit of such kernels was measured on the classification accuracy of semantic arguments in (Moschitti, 2004). In such work, the improvement on the PropBank arguments (Kingsbury and Palmer, 2002) classification suggests that SK adds information to the prediction of semantic structures. On the contrary, the performance decrease on the FrameNet data classification shows the limit of such approach, i.e. when the syntactic structures are shared among several semantic roles SK seems to be useless. In this article, we use Support Vector Machines (SVMs) to deeply analyze the role of SK in the automatic predicate argument classification. The major novelty of the article relates to the extensive experimentation carried out on the PropBank (Kingsbury and Palmer, 2002) and FrameNet (Fillmore, 19"
W05-1002,J93-2004,0,0.0383657,"Missing"
W05-1002,P04-1043,1,0.73144,"uments: Arg0, Arg1 and ArgM. The SCF of such verb, i.e. NP-PP, provides a synthesis of the predicate argument structure. Currently, the systems which aim to derive semantic shallow information from texts recognize the SCF of a target verb and represent it as a flat feature (e.g. (Xue and Palmer, 2004; Pradhan et al., 2004)) in the learning algorithm. To achieve this goal, a lexicon which describes the SCFs for each verb, is required. Such a resource is difficult to find especially for specific domains, thus, several methods to automatically extract SCF have been proposed (Korhonen, 2003). In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). The subcategorization frame of verbs was implicitly represented by means of the syntactic subtrees which include the predicate with its arguments. The similarity between such syntactic structures was evaluated by means of convolution kernels. Convolution kernels are machine learning approaches which aim to describe structured data in 10 Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 10–17, c Ann Arbor, June 2005. 2005 Association for Computational Linguistics terms of its substructures. Th"
W05-1002,W04-3212,0,0.0154816,"fferent syntactic alternations, thus, it plays a central role in the linking theory between verb semantics and their syntactic structures. Figure 1 shows the parse tree for the sentence &quot;John rented a room in Boston&quot; along with the semantic shallow information embodied by the verbal predicate to rent and its three arguments: Arg0, Arg1 and ArgM. The SCF of such verb, i.e. NP-PP, provides a synthesis of the predicate argument structure. Currently, the systems which aim to derive semantic shallow information from texts recognize the SCF of a target verb and represent it as a flat feature (e.g. (Xue and Palmer, 2004; Pradhan et al., 2004)) in the learning algorithm. To achieve this goal, a lexicon which describes the SCFs for each verb, is required. Such a resource is difficult to find especially for specific domains, thus, several methods to automatically extract SCF have been proposed (Korhonen, 2003). In (Moschitti, 2004), an alternative to the SCF extraction was proposed, i.e. the SCF kernel (SK). The subcategorization frame of verbs was implicitly represented by means of the syntactic subtrees which include the predicate with its arguments. The similarity between such syntactic structures was evalua"
W05-1002,P02-1031,0,\N,Missing
W06-2607,W05-0620,0,0.0712622,"Missing"
W06-2607,A00-2018,0,0.00678118,"sign of performant SRL systems entirely based on tree kernels. In the remainder of this paper, Section 2 introduces basic notions on SRL systems and tree kernels. Section 3 illustrates our new kernels for both boundary and classification tasks. Section 4 shows the experiments of SVMs with the above tree kernel based classifiers. 2 Preliminary Concepts In this section we briefly define the SRL model that we intend to design and the kernel function that we use to evaluate the similarity between subtrees. 2.1 Basic SRL approach The SRL approach that we adopt is based on the deep syntactic parse (Charniak, 2000) of the sentence that we intend to annotate semantically. The standard algorithm is to classify the tree node pair hp, ai, where p and a are the nodes that exactly cover the target predicate and a potential argument, respectively. If hp, ai is labeled with an argument, then the terminal nodes dominated by a will be considered as the words constituting such argument. The number of pairs for each sentence can be hundreds, thus, if we consider training corpora of thousands of sentences, we have to deal with millions of training instances. The usual solution to limit such complexity is to divide t"
W06-2607,P02-1034,0,0.633604,"ez, 2005). A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a natural way to represent them is the adoption of tree kernels as described in (Moschitti, 2004). The idea is to associate with each argument the minimal subtree that includes the target predicate with one of its arguments, and to use a tree kernel function to evaluate the number of common substructures between two such trees. Such approach is in line with current research on the use of tree kernels for natural language learning, e.g. syntactic parsing re-ranking (Collins and Duffy, 2002), relation extraction (Zelenko et al., 2003) and named entity recognition (Cumby and Roth, 2003; Culotta and Sorensen, 2004). Regarding the use of tree kernels for SRL, in (Moschitti, 2004) two main drawbacks have been 49 pointed out: • Highly accurate boundary detection cannot be carried out by a tree kernel model since correct and incorrect arguments may share a large portion of the encoding trees, i.e. they may share many substructures. • Manually derived features (extended with a polynomial kernel) have been shown to be superior to tree kernel approaches. Nevertheless, we believe that mode"
W06-2607,P04-1054,0,0.113272,"es, thus a natural way to represent them is the adoption of tree kernels as described in (Moschitti, 2004). The idea is to associate with each argument the minimal subtree that includes the target predicate with one of its arguments, and to use a tree kernel function to evaluate the number of common substructures between two such trees. Such approach is in line with current research on the use of tree kernels for natural language learning, e.g. syntactic parsing re-ranking (Collins and Duffy, 2002), relation extraction (Zelenko et al., 2003) and named entity recognition (Cumby and Roth, 2003; Culotta and Sorensen, 2004). Regarding the use of tree kernels for SRL, in (Moschitti, 2004) two main drawbacks have been 49 pointed out: • Highly accurate boundary detection cannot be carried out by a tree kernel model since correct and incorrect arguments may share a large portion of the encoding trees, i.e. they may share many substructures. • Manually derived features (extended with a polynomial kernel) have been shown to be superior to tree kernel approaches. Nevertheless, we believe that modeling a completely kernelized SRL system is useful for the following reasons: • We can implement it very quickly as the featu"
W06-2607,J02-3001,0,0.510469,"r the SRL task have shown that (shallow or deep) syntactic information is necessary to achieve a good labeling accuracy. This research brings a wide empirical evidence in favor of the linking theories between semantics and syntax, e.g. (Jackendoff, 1990). However, as no theory provides a sound and complete treatment of such issue, the choice and design of syntactic features for the automatic learning of semantic structures requires remarkable research efforts and intuition. For example, the earlier studies concerning linguistic features suitable for semantic role labeling were carried out in (Gildea and Jurasfky, 2002). Since then, researchers have proposed diverse syntactic feature sets that only slightly enhance the previous ones, e.g. (Xue and Palmer, 2004) or (Carreras and M`arquez, 2005). A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a natural way to represent them is the adoption of tree kernels as described in (Moschitti, 2004). The idea is to associate with each argument the minimal subtree that includes the target predicate with one of its arguments, and to use a tree kernel function to evaluate the number of common substructu"
W06-2607,A00-2008,0,0.0289784,"etection and argument classification. The comparative experiments on Support Vector Machines with such kernels on the CoNLL 2005 dataset show that very simple tree manipulations trigger automatic feature engineering that highly improves accuracy and efficiency in both phases. Moreover, the use of different classifiers for internal and pre-terminal nodes maintains the same accuracy and highly improves efficiency. 1 Introduction A lot of attention has been recently devoted to the design of systems for the automatic labeling of semantic roles (SRL) as defined in two important projects: FrameNet (Johnson and Fillmore, 2000), inspired by Frame Semantics, and PropBank (Kingsbury and Palmer, 2002) based on Levin’s verb classes. In general, given a sentence in natural language, the annotation of a predicate’s semantic roles requires (1) the detection of the target word that embodies the predicate and (2) the detection and classification of the word sequences constituting the predicate’s arguments. In particular, step (2) can be divided into two different phases: (a) boundary detection, in which the words of the sequence are detected and (b) argument classification, in which the type of the argument is selected. Most"
W06-2607,kingsbury-palmer-2002-treebank,0,0.0340346,"port Vector Machines with such kernels on the CoNLL 2005 dataset show that very simple tree manipulations trigger automatic feature engineering that highly improves accuracy and efficiency in both phases. Moreover, the use of different classifiers for internal and pre-terminal nodes maintains the same accuracy and highly improves efficiency. 1 Introduction A lot of attention has been recently devoted to the design of systems for the automatic labeling of semantic roles (SRL) as defined in two important projects: FrameNet (Johnson and Fillmore, 2000), inspired by Frame Semantics, and PropBank (Kingsbury and Palmer, 2002) based on Levin’s verb classes. In general, given a sentence in natural language, the annotation of a predicate’s semantic roles requires (1) the detection of the target word that embodies the predicate and (2) the detection and classification of the word sequences constituting the predicate’s arguments. In particular, step (2) can be divided into two different phases: (a) boundary detection, in which the words of the sequence are detected and (b) argument classification, in which the type of the argument is selected. Most machine learning models adopted for the SRL task have shown that (shall"
W06-2607,J93-2004,0,0.0293122,"less training data used when applying two distinct type classifiers for internal and pre-terminal nodes and (b) a more adequate feature space which allows SVMs to converge faster to a model containing a smaller number of support vectors, i.e. faster training and classification. 4.1 Experimental set up The empirical evaluations were carried out within the setting defined in the CoNLL-2005 Shared Task (Carreras and M`arquez, 2005). We used as a target dataset the PropBank corpus available at www.cis.upenn.edu/∼ace, along with the Penn TreeBank 2 for the gold trees (www.cis.upenn.edu/∼treebank) (Marcus et al., 1993), which includes about 53,700 sentences. Since the aim of this study was to design a real SRL system we adopted the Charniak parse trees from the CoNLL 2005 Shared Task data (available at www.lsi.upc.edu/∼srlconll/). We used Section 02, 03 and 24 from the Penn TreeBank in most of the experiments. Their characteristics are shown in Table 1. Pos and Neg indicate the number of nodes corresponding or not to a correct argument boundary. Rows 3 and 4 report such number for the internal and pre-terminal nodes separately. We note that the latter are much fewer than the former; this results in a very f"
W06-2607,P04-1043,1,0.927903,"f semantic structures requires remarkable research efforts and intuition. For example, the earlier studies concerning linguistic features suitable for semantic role labeling were carried out in (Gildea and Jurasfky, 2002). Since then, researchers have proposed diverse syntactic feature sets that only slightly enhance the previous ones, e.g. (Xue and Palmer, 2004) or (Carreras and M`arquez, 2005). A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a natural way to represent them is the adoption of tree kernels as described in (Moschitti, 2004). The idea is to associate with each argument the minimal subtree that includes the target predicate with one of its arguments, and to use a tree kernel function to evaluate the number of common substructures between two such trees. Such approach is in line with current research on the use of tree kernels for natural language learning, e.g. syntactic parsing re-ranking (Collins and Duffy, 2002), relation extraction (Zelenko et al., 2003) and named entity recognition (Cumby and Roth, 2003; Culotta and Sorensen, 2004). Regarding the use of tree kernels for SRL, in (Moschitti, 2004) two main draw"
W06-2607,W05-0407,1,0.828913,"classify the tree node pair hp, ai, where p and a are the nodes that exactly cover the target predicate and a potential argument, respectively. If hp, ai is labeled with an argument, then the terminal nodes dominated by a will be considered as the words constituting such argument. The number of pairs for each sentence can be hundreds, thus, if we consider training corpora of thousands of sentences, we have to deal with millions of training instances. The usual solution to limit such complexity is to divide the labeling task in two subtasks: In this paper, we carry out tree kernel engineering (Moschitti et al., 2005) to increase both accuracy and speed of the boundary detection and argument classification phases. The engineering approach relates to marking the nodes of the encoding subtrees in order to generate substructures more strictly correlated with a particular argument, boundary or predicate. For example, marking the node that exactly covers the target argument helps tree kernels to generate different substructures for correct and incorrect argument boundaries. The other technique that we applied to engineer different kernels is the subdivision of internal and pre-terminal nodes. We show that desig"
W06-2607,E06-1015,1,0.901911,"re-terminal nodes separately. We note that the latter are much fewer than the former; this results in a very fast pre-terminal classifier. As the automatic parse trees contain errors, some arguments cannot be associated with any covering node. This prevents us to extract a tree representation for them. Consequently, we do not consider them in our evaluation. In sections 2, 3 and 24 there are 454, 347 and 731 such cases, respectively. The experiments were carried out with the SVM-light-TK software available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes fast tree kernel evaluation (Moschitti, 2006) in the SVM-light software (Joachims, 1999). We used a regularization parameter (option -c) equal to 1 and λ = 0.4 (see (Moschitti, 2004)). 4.2 Boundary Detection Results In these experiments, we used Section 02 for training and Section 24 for testing. The results using the PAF and the MPAF based kernels are reported in Table 2 in rows 2 and 3, respectively. Columns 3 and 4 show the CPU testing time (in seconds) and the F1 of the monolithic boundary classifier. The next 3 columns show the CPU time for the internal (Int) and pre-terminal (Pre) node classifiers, as well as their total (All). The"
W06-2607,W05-0639,0,0.0124545,"ta of the same classifier. However, the use of different classifiers is motivated also by the fact that many argument types can be found mostly in pre-terminal nodes, e.g. modifier or negation arguments, and do not necessitate training data extracted from internal nodes. Consequently, it is more convenient (at least from a computational point of view) to use two different boundary classifiers, hereinafter referred to as combined classifier. 3.2 Kernels on complete predicate argument structures The type of a target argument strongly depends on the type and number of the predicate’s arguments1 (Punyakanok et al., 2005; Toutanova et al., 2005). Consequently, to correctly label an argument, we should extract features from the complete predicate argument structure it belongs to. In contrast, PAFs completely neglect the information (i.e. the tree portions) related to non-target arguments. One way to use this further information with tree kernels is to use the minimum subtree that spans all the predicate’s arguments. The whole parse tree in Figure 1 is an example of such Minimum Spanning Tree (MST) as it includes all and only the argument structures of the predicate ”to deliver”. However, MSTs pose some problem"
W06-2607,P05-1073,0,0.0341479,". However, the use of different classifiers is motivated also by the fact that many argument types can be found mostly in pre-terminal nodes, e.g. modifier or negation arguments, and do not necessitate training data extracted from internal nodes. Consequently, it is more convenient (at least from a computational point of view) to use two different boundary classifiers, hereinafter referred to as combined classifier. 3.2 Kernels on complete predicate argument structures The type of a target argument strongly depends on the type and number of the predicate’s arguments1 (Punyakanok et al., 2005; Toutanova et al., 2005). Consequently, to correctly label an argument, we should extract features from the complete predicate argument structure it belongs to. In contrast, PAFs completely neglect the information (i.e. the tree portions) related to non-target arguments. One way to use this further information with tree kernels is to use the minimum subtree that spans all the predicate’s arguments. The whole parse tree in Figure 1 is an example of such Minimum Spanning Tree (MST) as it includes all and only the argument structures of the predicate ”to deliver”. However, MSTs pose some problems: • We cannot use them f"
W06-2607,W04-3212,0,0.0743486,"empirical evidence in favor of the linking theories between semantics and syntax, e.g. (Jackendoff, 1990). However, as no theory provides a sound and complete treatment of such issue, the choice and design of syntactic features for the automatic learning of semantic structures requires remarkable research efforts and intuition. For example, the earlier studies concerning linguistic features suitable for semantic role labeling were carried out in (Gildea and Jurasfky, 2002). Since then, researchers have proposed diverse syntactic feature sets that only slightly enhance the previous ones, e.g. (Xue and Palmer, 2004) or (Carreras and M`arquez, 2005). A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a natural way to represent them is the adoption of tree kernels as described in (Moschitti, 2004). The idea is to associate with each argument the minimal subtree that includes the target predicate with one of its arguments, and to use a tree kernel function to evaluate the number of common substructures between two such trees. Such approach is in line with current research on the use of tree kernels for natural language learning, e.g. syntac"
W06-2909,W05-0620,0,0.0133417,"Missing"
W06-2909,P02-1034,0,0.78843,"respectively. In P|F |l(fi ) turn ∆(n1 , n2 ) = Ii (n1 )Ii (n2 ), where i=1 λ 0 ≤ λ ≤ 1 and l(fi ) is the height of the subtree fi . Thus λl(fi ) assigns a lower weight to larger fragSentence Parse-Tree took{ARG0, ARG1} S S NP VP PRP VP John took NP CC VB read{ARG0, ARG1} NP DT NN the book and read VP PRP VP VB NP S NP VP PRP VB PRP$ NN its title John took VP NP VP VB DT NN the book John read NP PRP$ NN its title Figure 1: A sentence parse tree with two argument spanning trees (AST s) ments. When λ = 1, ∆ is equal to the number of common fragments rooted at nodes n1 and n2 . As described in (Collins and Duffy, 2002), ∆ can be computed in O(|Nt1 |× |Nt2 |). 3 Tree kernel-based classification of Predicate Argument Structures Traditional semantic role labeling systems extract features from pairs of nodes corresponding to a predicate and one of its argument, respectively. Thus, they focus on only binary relations to make classification decisions. This information is poorer than the one expressed by the whole predicate argument structure. As an alternative we can select the set of potential arguments (potential argument nodes) of a predicate and extract features from them. The number of the candidate argument"
W06-2909,J02-3001,0,0.874413,"ructured learning allows SVMs to reach the state-of-the-art accuracy. The paper is organized as follows: Section 2 introduces the Semantic Role Labeling based on SVMs and the tree kernel spaces; Section 3 formally defines the AST s and the algorithm for their classification and re-ranking; Section 4 shows the comparative results between our approach and the traditional one; Section 5 presents the related work; and finally, Section 6 summarizes the conclusions. 2 Semantic Role Labeling In the last years, several machine learning approaches have been developed for automatic role labeling, e.g. (Gildea and Jurasfky, 2002; Pradhan et al., 2005a). Their common characteristic is the adoption of attribute-value representations for predicate-argument structures. Accordingly, our basic system is similar to the one proposed in (Pradhan et al., 2005a) and it is hereby described. We use a boundary detection classifier (for any role type) to derive the words compounding an argument and a multiclassifier to assign the roles (e.g. Arg0 or ArgM) described in PropBank (Kingsbury and Palmer, 2002)). To prepare the training data for both classifiers, we used the following algorithm: 1. Given a sentence from the training-set,"
W06-2909,kingsbury-palmer-2002-treebank,0,0.0968357,"d its arguments. For example, to detect the interesting context, the modeling of syntax/semantics-based features should take into account linguistic aspects like ancestor nodes or semantic dependencies (Toutanova et al., 2004). In a similar way, we can model SRL systems with tree kernels to generate large feature spaces. More in detail, most SRL systems split the labeling process into two different steps: Boundary Detection (i.e. to determine the text boundaries of predicate arguments) and Role Classification (i.e. labeling such arguments with a semantic role, e.g. Arg0 or Arg1 as defined in (Kingsbury and Palmer, 2002)). The former relates to the detection of syntactic parse tree nodes associated with constituents that correspond to arguments, whereas the latter considers the boundary nodes for the assignment of the suitable label. Both steps require the design and extraction of features from parse trees. As capturing the tightly interdependent relations among a predicate and its arguments is a complex task, we can apply tree kernels on the subtrees that span the whole predicate argument structure to generate the feature space of all the possible subtrees. In this paper, we apply the traditional boundary (T"
W06-2909,W05-0630,1,0.831404,"Missing"
W06-2909,P04-1043,1,0.912284,"used to train a boundary classifier (e.g. an SVM). Regarding the argument type classifier, a binary labeler for a role r (e.g. an SVM) can be trained on the Tr+ , i.e. its positive examples and Tr− , i.e. its negative examples, where T + = Tr+ ∪ Tr− , according to the ONE-vsALL scheme. The binary classifiers are then used to build a general role multiclassifier by simply selecting the argument associated with the maximum among the SVM scores. Regarding the design of features for predicateargument pairs, we can use the attribute-values defined in (Gildea and Jurasfky, 2002) or tree structures (Moschitti, 2004). Although we focus on the latter approach, a short description of the former is still relevant as they are used by T BC and T RC. They include the Phrase Type, Predicate Word, Head Word, Governing Category, Position and Voice features. For example, the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument and the Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase, expressed as a sequence of nonterminal labels linked by direction (up or down) symbols, e.g. V ↑ VP ↓ NP. A viable alternative to manual design of synta"
W06-2909,E06-1015,1,0.862676,"Missing"
W06-2909,P05-1072,0,0.142293,"tion of syntactic parse tree nodes associated with constituents that correspond to arguments, whereas the latter considers the boundary nodes for the assignment of the suitable label. Both steps require the design and extraction of features from parse trees. As capturing the tightly interdependent relations among a predicate and its arguments is a complex task, we can apply tree kernels on the subtrees that span the whole predicate argument structure to generate the feature space of all the possible subtrees. In this paper, we apply the traditional boundary (T BC) and role (T RC) classifiers (Pradhan et al., 2005a), which are based on binary predicate/argument relations, to label all parse tree nodes corresponding to potential arguments. Then, we ex61 Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X), c pages 61–68, New York City, June 2006. 2006 Association for Computational Linguistics tract the subtrees which span the predicate-argument dependencies of such arguments, i.e. Argument Spanning Trees (AST s). These are used in a tree kernel function to generate all possible substructures that encode n-ary argument relations, i.e. we carry out an automatic feature e"
W06-2909,W05-0639,0,0.135635,"the AST metaclassifier, which can be used with any of the best figure CoNLL systems. Finally, the overall results suggest that the tree kernel model is robust to parse tree errors since preserves the same improvement across trees derived with different accuracy, i.e. the semi-automatic trees of Section 21 and the automatic tree of Section 23. Moreover, it shows a high accuracy for the classification of correct and incorrect AST s. This last property is quite interesting as the best SRL systems 1 We needed to remove the overlaps from the baseline outcome in order to apply the CoNLL evaluator. (Punyakanok et al., 2005; Toutanova et al., 2005; Pradhan et al., 2005b) were obtained by exploiting the information on the whole predicate argument structure. Next section shows our preliminary experiments on re-ranking using the AST kernel based approach. 4.2 Re-ranking based on Tree Kernels In these experiments, we used the output of T BC and T RC 2 to provide an SVM tree kernel with a ranked list of predicate argument structures. More in detail, we applied a Viterbi-like algorithm to generate the 20 most likely annotations for each predicate structure, according to the joint probabilistic model of T BC and T RC."
W06-2909,W03-1012,0,0.130056,"To make faster the learning process and to try to only capture the most relevant features, we also experimented with a compact version of the AST which is pruned at the level of argument nodes. (b) Attribute value features (standard features) related to the whole predicate structure. These include the features for each arguments (Gildea and Jurasfky, 2002) and global features like the sequence of argument labels, e.g. hArg0, Arg1, ArgM i. Finally, we prepare the training examples for the re-ranker considering the m best annotations of each predicate structure. We use the approach adopted in (Shen et al., 2003), which generates all possible ¡m¢ pairs from the m examples, i.e. 2 pairs. Each pair is assigned to a positive example if the first member of the pair has a higher score than the second member. The score that we use is the F1 measure of the annotated structure with respect to the gold standard. More in detail, given training/testing examples ei = ht1i , t2i , vi1 , vi2 i, where t1i and t2i are two AST s and vi1 and vi2 are two feature vectors associated with two candidate predicate structures s1 and s2 , we define the following kernels: 1) Ktr (e1 , e2 ) = Kt (t11 , t12 ) + Kt (t21 , t22 ) −K"
W06-2909,W04-3222,0,0.120387,"has shown that to achieve high labeling accuracy a joint inference on the whole predicate argument structure should be applied. For this purpose, we need to extract features from the sentence’s syntactic parse tree that encodes the target semantic structure. This task is rather complex since we do not exactly know which are the syntactic clues that capture the relation between the predicate and its arguments. For example, to detect the interesting context, the modeling of syntax/semantics-based features should take into account linguistic aspects like ancestor nodes or semantic dependencies (Toutanova et al., 2004). In a similar way, we can model SRL systems with tree kernels to generate large feature spaces. More in detail, most SRL systems split the labeling process into two different steps: Boundary Detection (i.e. to determine the text boundaries of predicate arguments) and Role Classification (i.e. labeling such arguments with a semantic role, e.g. Arg0 or Arg1 as defined in (Kingsbury and Palmer, 2002)). The former relates to the detection of syntactic parse tree nodes associated with constituents that correspond to arguments, whereas the latter considers the boundary nodes for the assignment of t"
W06-2909,P05-1073,0,0.479237,"ional Linguistics tract the subtrees which span the predicate-argument dependencies of such arguments, i.e. Argument Spanning Trees (AST s). These are used in a tree kernel function to generate all possible substructures that encode n-ary argument relations, i.e. we carry out an automatic feature engineering process. To validate our approach, we experimented with our model and Support Vector Machines for the classification of valid and invalid AST s. The results show that this classification problem can be learned with high accuracy. Moreover, we modeled SRL as a re-ranking task in line with (Toutanova et al., 2005). The large number of complex features provided by tree kernels for structured learning allows SVMs to reach the state-of-the-art accuracy. The paper is organized as follows: Section 2 introduces the Semantic Role Labeling based on SVMs and the tree kernel spaces; Section 3 formally defines the AST s and the algorithm for their classification and re-ranking; Section 4 shows the comparative results between our approach and the traditional one; Section 5 presents the related work; and finally, Section 6 summarizes the conclusions. 2 Semantic Role Labeling In the last years, several machine learn"
W08-2208,C96-1005,0,0.0532778,"tative of a frame F. This is what is hereafter referred to as the paradigmatic similarity model between words senses and frames. Paradigmatic Similarity measures Given the WordNet hierarchy separation on part-of-speaches, the similarity function simW N is independently defined for verbs, nouns and adjectives. 1 In the following, we will use the same notation for a frame F and for the set of its known lexical units, as in our approach we use LU membership as a basic definition of a frame. Combining Word Sense and Usage for Modeling Frame Semantics 89 For nouns we adopt conceptual density (cd) (Agirre and Rigau, 1996; Basili et al., 2004), a semantic similarity measure defined for word sense disambiguation tasks. The cd score for a sense σ ∈ SF is the density of the WordNet sub-hierarchy rooted at σ in representing the set of nouns in F. The intuition behind this model is that the larger is the number of all and only LUs in F that are generalized by σ, the better it captures the lexical semantics intended by the frame. Coarse generalizations (i.e. synsets higher in the hierarchy) are penalized, as they give rise to bushy hierarchies, covering too many words not in the target F. The greedy algorithm propos"
W08-2208,P98-1013,0,0.144199,"rom WordNet and corpus-based distributional information. We report a large scale evaluation over the English FrameNet, and results on extending FrameNet to the Italian language, as the basis of the development of a full FrameNet for Italian. 85 86 De Cao, Croce, Pennacchiotti, and Basili 1 Introduction and Related Work Models of lexical meaning are explicit or implicit basic components of any text processing system devoted to information extraction, question answering or dialogue. Several paradigms proposed for a variety of notions, such as word sense (Miller et al., 1990) or frame semantics (Baker et al., 1998), have given rise to large scale resources, respectively WordNet and FrameNet. Recent studies (e.g. Shen and Lapata (2007)) show that the use of FrameNet can potentially improve the performance of Question Answering systems. Yet, Shen and Lapata (2007) also point out that the low coverage of the current version of FrameNet significantly limits the expected boost in performance. Other studies have shown similar evidences for Recognizing Textual Entailment (RTE) (Clark et al., 2007; Burchardt et al., 2008): most examples of the RTE challenges corpora can be solved at the predicate-argument struc"
W08-2208,basili-etal-2004-similarity,1,0.851187,"s is what is hereafter referred to as the paradigmatic similarity model between words senses and frames. Paradigmatic Similarity measures Given the WordNet hierarchy separation on part-of-speaches, the similarity function simW N is independently defined for verbs, nouns and adjectives. 1 In the following, we will use the same notation for a frame F and for the set of its known lexical units, as in our approach we use LU membership as a basic definition of a frame. Combining Word Sense and Usage for Modeling Frame Semantics 89 For nouns we adopt conceptual density (cd) (Agirre and Rigau, 1996; Basili et al., 2004), a semantic similarity measure defined for word sense disambiguation tasks. The cd score for a sense σ ∈ SF is the density of the WordNet sub-hierarchy rooted at σ in representing the set of nouns in F. The intuition behind this model is that the larger is the number of all and only LUs in F that are generalized by σ, the better it captures the lexical semantics intended by the frame. Coarse generalizations (i.e. synsets higher in the hierarchy) are penalized, as they give rise to bushy hierarchies, covering too many words not in the target F. The greedy algorithm proposed in Basili et al. (2"
W08-2208,burchardt-etal-2006-salsa,0,0.00548036,"ions (namely, Latent Semantic Analysis) to expand FrameNet, but the investigation is too limited in scope to draw relevant conclusions. Finally, Padó et al. (2008) propose a method to automatically label unknown semantic roles of event nominalizations in FrameNet, but their method needs a large amount of annotated verbal data. Another important limitation of FrameNet is the limited support to multilinguality, which is becoming a critical issue in real NLP applications. In recent years, some efforts have focused on the manual adaptation of the English FrameNet to other languages (e.g., German (Burchardt et al., 2006) and Spanish (Subirats and Petruck, 2003)). Unlike PropBank, FrameNet is in fact suitable to cross-lingual induction, as frames are mostly defined at the conceptual level, thus allowing cross-lingual interpretation. Yet, all these efforts consist in manually defining frame linguistic knowledge (e.g. lexical units) in the specific language, and in annotating a large corpus, thus requiring a large human effort. While attempts to automate the annotation process are quite promising (Pado and Lapata, 2007), they require the availability of a parallel corpus, and leave open the issue of inducing the"
W08-2208,W07-1409,0,0.0261532,"Several paradigms proposed for a variety of notions, such as word sense (Miller et al., 1990) or frame semantics (Baker et al., 1998), have given rise to large scale resources, respectively WordNet and FrameNet. Recent studies (e.g. Shen and Lapata (2007)) show that the use of FrameNet can potentially improve the performance of Question Answering systems. Yet, Shen and Lapata (2007) also point out that the low coverage of the current version of FrameNet significantly limits the expected boost in performance. Other studies have shown similar evidences for Recognizing Textual Entailment (RTE) (Clark et al., 2007; Burchardt et al., 2008): most examples of the RTE challenges corpora can be solved at the predicate-argument structure level, but FrameNet coverage is still a major problem. Approaches to (semi-)automatically acquire frame information are then today a priority to solve these problems. Despite this, not many efforts have been paid so far in this direction. Burchardt et al. (2005) presented Detour, a system for predicting frame assignment of potential lexical units not covered by FrameNet, by using the paradigmatic information enclosed in WordNet. Although the authors do not fully solve the pr"
W08-2208,J07-2002,0,0.0244372,"e focused on the manual adaptation of the English FrameNet to other languages (e.g., German (Burchardt et al., 2006) and Spanish (Subirats and Petruck, 2003)). Unlike PropBank, FrameNet is in fact suitable to cross-lingual induction, as frames are mostly defined at the conceptual level, thus allowing cross-lingual interpretation. Yet, all these efforts consist in manually defining frame linguistic knowledge (e.g. lexical units) in the specific language, and in annotating a large corpus, thus requiring a large human effort. While attempts to automate the annotation process are quite promising (Pado and Lapata, 2007), they require the availability of a parallel corpus, and leave open the issue of inducing the resource as a whole in a new language. In this work, we investigate novel methods for automatically expanding the English FrameNet, and supporting the creation of new ones in other languages (namely Italian), thus tackling the abovementioned problems of coverage and multilinguality. The proposed methods are inspired by the basic hypothesis that FrameNet can be automatically modeled by a fruitful interaction between advanced distributional techniques, and paradigmatic properties derived from WordNet."
W08-2208,C08-1084,1,0.793873,"do not fully solve the problem related to the fuzzy relationships between senses and frames, they propose an empirical association measure for ranking frame candidates according to sense information as stored in WordNet. To our knowledge, this is the only work trying to bridge frame membership to referential properties of lexical senses. Pitel (2006) presents a preliminary study on the applicability of semantic spaces and space geometrical transformations (namely, Latent Semantic Analysis) to expand FrameNet, but the investigation is too limited in scope to draw relevant conclusions. Finally, Padó et al. (2008) propose a method to automatically label unknown semantic roles of event nominalizations in FrameNet, but their method needs a large amount of annotated verbal data. Another important limitation of FrameNet is the limited support to multilinguality, which is becoming a critical issue in real NLP applications. In recent years, some efforts have focused on the manual adaptation of the English FrameNet to other languages (e.g., German (Burchardt et al., 2006) and Spanish (Subirats and Petruck, 2003)). Unlike PropBank, FrameNet is in fact suitable to cross-lingual induction, as frames are mostly d"
W08-2208,D07-1002,0,0.041177,"and results on extending FrameNet to the Italian language, as the basis of the development of a full FrameNet for Italian. 85 86 De Cao, Croce, Pennacchiotti, and Basili 1 Introduction and Related Work Models of lexical meaning are explicit or implicit basic components of any text processing system devoted to information extraction, question answering or dialogue. Several paradigms proposed for a variety of notions, such as word sense (Miller et al., 1990) or frame semantics (Baker et al., 1998), have given rise to large scale resources, respectively WordNet and FrameNet. Recent studies (e.g. Shen and Lapata (2007)) show that the use of FrameNet can potentially improve the performance of Question Answering systems. Yet, Shen and Lapata (2007) also point out that the low coverage of the current version of FrameNet significantly limits the expected boost in performance. Other studies have shown similar evidences for Recognizing Textual Entailment (RTE) (Clark et al., 2007; Burchardt et al., 2008): most examples of the RTE challenges corpora can be solved at the predicate-argument structure level, but FrameNet coverage is still a major problem. Approaches to (semi-)automatically acquire frame information a"
W08-2208,C98-1013,0,\N,Missing
W08-2208,tonelli-pianta-2008-frame,0,\N,Missing
W10-2304,C96-1005,0,0.0850391,"y reducing the requested processing time. Experimental analysis over well-known benchmarks will be presented in the paper and the results confirm our hypothesis. 1 The best accuracy is reached by WSD based on supervised methods that exploit large amounts of hand-tagged data to train discriminative or generative disambiguation models. The common alternative to supervised systems are knowledgebased WSD systems that try to exploit information made available by large Lexical Knowledge Bases (LKB). They enable the definition of several metrics to estimate semantic similarity (e.g. (Lesk, 1986) or (Agirre and Rigau, 1996), (Basili et al., 2004) methods) and then use it to rank the alternative senses according to the incoming context. Moreover they make available large relationship sets between pairs of lexical meaning units, such as synonymy, hyponymy or meronymy. The resulting networks represent at various grains and degrees of approximation models of the mental lexicons. It is not by chance that early research on WSD based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (Cowie et al., 1992)) for precise and fast disambiguation. Introducti"
W10-2304,P97-1010,0,0.017717,"activation processes (in particular simulated annealing as in (Cowie et al., 1992)) for precise and fast disambiguation. Introduction Lexical ambiguity is a fundamental aspect of natural language. Word Sense Disambiguation (WSD) investigates methods to automatically determine the intended sense of a word in a given context according to a predefined set of sense definitions, provided by a semantic lexicon. Intuitively, WSD can be usefully exploited in a variety of NLP (e.g. Machine Translation (Chan et al., 2007; Carpuat and Wu, 2007)) and Information Retrieval tasks such as ad hoc retrieval (Krovetz, 1997; Kim et al., 2004) or Question Answering (Beale et al., 2004). However controversial results have been often obtained, as for example the study on text classification reported in (Moschitti and Basili, 2004). The impact of WSD on IR tasks is still an open issue and large scale assessment is needed. For this reason, unsupervised approaches to inductive WSD are appealing. In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in IR resea"
W10-2304,agirre-soroa-2008-using,0,0.194415,"itti and Basili, 2004). The impact of WSD on IR tasks is still an open issue and large scale assessment is needed. For this reason, unsupervised approaches to inductive WSD are appealing. In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in IR research. It has been more recently that graph-based methods for knowledge-based WSD have gained much attention in the NLP community ((Sinha and Mihalcea, 2007), (Navigli and Lapata, 2007), (Agirre and Soroa, 2008), (Agirre and Soroa, 2009)). In these methods a graph representation for senses (nodes) and relation (edges) is first built. Then graph-based techniques that are sensible to the structural properties of the graph are used to find the best senses for words in the incoming contexts. The relation employed by the different methods are of several types such as synonymy, antonymy but also co-occurrence based lexical similarity computed externally over a corpus. These give rise to real-valued weights that determine large weighted directed graphs. Usu24 Proceedings of the 2010 Workshop on Graph-based"
W10-2304,E09-1005,0,0.0570957,"e impact of WSD on IR tasks is still an open issue and large scale assessment is needed. For this reason, unsupervised approaches to inductive WSD are appealing. In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in IR research. It has been more recently that graph-based methods for knowledge-based WSD have gained much attention in the NLP community ((Sinha and Mihalcea, 2007), (Navigli and Lapata, 2007), (Agirre and Soroa, 2008), (Agirre and Soroa, 2009)). In these methods a graph representation for senses (nodes) and relation (edges) is first built. Then graph-based techniques that are sensible to the structural properties of the graph are used to find the best senses for words in the incoming contexts. The relation employed by the different methods are of several types such as synonymy, antonymy but also co-occurrence based lexical similarity computed externally over a corpus. These give rise to real-valued weights that determine large weighted directed graphs. Usu24 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Langua"
W10-2304,basili-etal-2004-similarity,1,0.790552,"rocessing time. Experimental analysis over well-known benchmarks will be presented in the paper and the results confirm our hypothesis. 1 The best accuracy is reached by WSD based on supervised methods that exploit large amounts of hand-tagged data to train discriminative or generative disambiguation models. The common alternative to supervised systems are knowledgebased WSD systems that try to exploit information made available by large Lexical Knowledge Bases (LKB). They enable the definition of several metrics to estimate semantic similarity (e.g. (Lesk, 1986) or (Agirre and Rigau, 1996), (Basili et al., 2004) methods) and then use it to rank the alternative senses according to the incoming context. Moreover they make available large relationship sets between pairs of lexical meaning units, such as synonymy, hyponymy or meronymy. The resulting networks represent at various grains and degrees of approximation models of the mental lexicons. It is not by chance that early research on WSD based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (Cowie et al., 1992)) for precise and fast disambiguation. Introduction Lexical ambiguity is"
W10-2304,W04-0906,0,0.024686,"as in (Cowie et al., 1992)) for precise and fast disambiguation. Introduction Lexical ambiguity is a fundamental aspect of natural language. Word Sense Disambiguation (WSD) investigates methods to automatically determine the intended sense of a word in a given context according to a predefined set of sense definitions, provided by a semantic lexicon. Intuitively, WSD can be usefully exploited in a variety of NLP (e.g. Machine Translation (Chan et al., 2007; Carpuat and Wu, 2007)) and Information Retrieval tasks such as ad hoc retrieval (Krovetz, 1997; Kim et al., 2004) or Question Answering (Beale et al., 2004). However controversial results have been often obtained, as for example the study on text classification reported in (Moschitti and Basili, 2004). The impact of WSD on IR tasks is still an open issue and large scale assessment is needed. For this reason, unsupervised approaches to inductive WSD are appealing. In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examples for all words and can thus support realistic (large scale) benchmarks, as needed in IR research. It has been more recently that graph-based methods for kn"
W10-2304,D07-1007,0,0.0207159,"ly research on WSD based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (Cowie et al., 1992)) for precise and fast disambiguation. Introduction Lexical ambiguity is a fundamental aspect of natural language. Word Sense Disambiguation (WSD) investigates methods to automatically determine the intended sense of a word in a given context according to a predefined set of sense definitions, provided by a semantic lexicon. Intuitively, WSD can be usefully exploited in a variety of NLP (e.g. Machine Translation (Chan et al., 2007; Carpuat and Wu, 2007)) and Information Retrieval tasks such as ad hoc retrieval (Krovetz, 1997; Kim et al., 2004) or Question Answering (Beale et al., 2004). However controversial results have been often obtained, as for example the study on text classification reported in (Moschitti and Basili, 2004). The impact of WSD on IR tasks is still an open issue and large scale assessment is needed. For this reason, unsupervised approaches to inductive WSD are appealing. In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examples for all words and c"
W10-2304,S07-1006,0,0.0249488,"vocabulary to compute the lexical expansion of σ, i.e. the set of terms − that are enough similar to → σ in the k dimensional space. Let D be the vocabulary of all terms, we − define as the lexical expansion T (σ) ⊂ D of → σ as follows: →j , → − T (σ) = {wj ∈ D : sim(− w σ ) > τ} (2) the efficiency of the algorithm and its impact in a sentence (i.e. P P R) or word oriented (i.e. w2w) perspective. This will allow to asses its applicability to realistic tasks, such as query processing or document indexing. Experimental Set-up In order to measure accuracy, the Senseval 2007 coarse WSD dataset2 (Navigli et al., 2007) has been employed. It includes 245 sentences for a total number of 2,269 ambiguous words. In line with the results reported in (Agirre and Soroa, 2009), experiments against two different WordNet versions, 1.7 and 3.0, have been carried out. Notice that the best results in (Agirre and Soroa, 2009) were obtained over the enriched version of the LKB, i.e. the combination of WordNet and extra information supplied by extended WordNet (Harabagiu and Moldovan, 1999). The adopted vector space has been acquired over a significant subset of the BNC 2.0 corpus, made of 923k sentences. The most frequent"
W10-2304,P07-1005,0,0.0267901,"by chance that early research on WSD based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (Cowie et al., 1992)) for precise and fast disambiguation. Introduction Lexical ambiguity is a fundamental aspect of natural language. Word Sense Disambiguation (WSD) investigates methods to automatically determine the intended sense of a word in a given context according to a predefined set of sense definitions, provided by a semantic lexicon. Intuitively, WSD can be usefully exploited in a variety of NLP (e.g. Machine Translation (Chan et al., 2007; Carpuat and Wu, 2007)) and Information Retrieval tasks such as ad hoc retrieval (Krovetz, 1997; Kim et al., 2004) or Question Answering (Beale et al., 2004). However controversial results have been often obtained, as for example the study on text classification reported in (Moschitti and Basili, 2004). The impact of WSD on IR tasks is still an open issue and large scale assessment is needed. For this reason, unsupervised approaches to inductive WSD are appealing. In contrast with supervised methods that strongly rely on manually labeled data sets, those methods do not require annotated examp"
W10-2304,S01-1005,0,0.0334407,"Missing"
W10-2304,H92-1046,0,0.014996,"e semantic similarity (e.g. (Lesk, 1986) or (Agirre and Rigau, 1996), (Basili et al., 2004) methods) and then use it to rank the alternative senses according to the incoming context. Moreover they make available large relationship sets between pairs of lexical meaning units, such as synonymy, hyponymy or meronymy. The resulting networks represent at various grains and degrees of approximation models of the mental lexicons. It is not by chance that early research on WSD based on semantic dictionaries were applying models of network activation processes (in particular simulated annealing as in (Cowie et al., 1992)) for precise and fast disambiguation. Introduction Lexical ambiguity is a fundamental aspect of natural language. Word Sense Disambiguation (WSD) investigates methods to automatically determine the intended sense of a word in a given context according to a predefined set of sense definitions, provided by a semantic lexicon. Intuitively, WSD can be usefully exploited in a variety of NLP (e.g. Machine Translation (Chan et al., 2007; Carpuat and Wu, 2007)) and Information Retrieval tasks such as ad hoc retrieval (Krovetz, 1997; Kim et al., 2004) or Question Answering (Beale et al., 2004). Howeve"
W10-2304,S07-1016,0,0.0440276,"Missing"
W10-2304,W04-0811,0,0.0406025,"Missing"
W10-2304,S07-1048,0,0.0150437,"rted in (Agirre and Soroa, 2009), experiments against two different WordNet versions, 1.7 and 3.0, have been carried out. Notice that the best results in (Agirre and Soroa, 2009) were obtained over the enriched version of the LKB, i.e. the combination of WordNet and extra information supplied by extended WordNet (Harabagiu and Moldovan, 1999). The adopted vector space has been acquired over a significant subset of the BNC 2.0 corpus, made of 923k sentences. The most frequent 200k words (i.e. the contextual features) were acquired through LSA. The corpus has been processed with the LTH parser (Johansson and Nugues, 2007) to obtain POS tags for every token. Moreover, a dimensionality reduction factor of k = 100 was applied. In subsection 4.1, a comparative analysis of the accuracy achieved in the disambiguation task is discussed. Subsection 4.2 presents a corresponding study of the execution times aiming to compare the relative efficiency of the methods and their application into a document semantic tagging task. where τ represents a real-valued threshold in the set [0, 1). In order to improve precision it is also possible to impose a limit on the cardinality of T (σ) and discard terms characterized by lower s"
W13-3814,S13-1004,0,0.0175046,"In some cases, the boost between SPTKct and CSPTKcct is remarkable, switching from .18 to .65 in MSRvid and from .24 to .37 in OnWN. The above difference is mainly due to the increasing sensitivity of PTK, SPTK and CSPTK to the incrementally rich lexical information. This is especially evident in sentence pairs with very The Semantic Text Similarity task The first experiment aims to evaluate the contribution of the Kernel-based operators in a STS task. In the Core STS task given two sentences, s1 and s2 , participants are asked to provide a score reflecting the corresponding text similarity (Agirre et al., 2013). PTK, SPTK and CSPTK similarity functions are employed over the dataset of the *SEM 2013 shared task. In Table 1 results of Pearson Correlations between the Kernels operators and the human scores are shown. We considered all datasets composing the challenge training set, i.e. MSRvid, MSRpar, SMTeuroparl, surprise.OnWn and surprise.SMTnews as well as the test set Headlines, FNWN and SMTnews. We did not report any comparison with the best results of 2 PTKct SPTKct CSPTKcct 3 For the SPTK, we selected the parameters λ = 0.1, µ = 0.1 and lexical weight = 100 that provided best results in (Croce e"
W13-3814,C02-1150,0,0.174626,"Missing"
W13-3814,P08-1028,0,0.04648,"onal Compositional Semantics. Vector-based models typically represent isolated words and ignore grammatical structure (Turney and Pantel, 2010). They have thus a limited capability to model compositional operations over phrases and sentences. In order to overcome these limitations, Distributional Compositional Semantics (DCS) models have been investigated. In (Smolensky, 1990) compositionality of two vector !u and !v is accounted by the tensor product !u ⊗ !v , while in (Foltz et al., 1998) lexical vectors are summed, keeping the resulting vector with the same dimension of the input ones. In (Mitchell and Lapata, 2008) two general classes of compositional models have been defined: a linear additive model p! = A!u + B!v and a multiplicative model p! = C!u!v . A and B are weight matrices and C is a weight tensor that project lexical vectors !u and !v onto the space of p!, i.e. the vector resulting from the composition. These models usually assume that composition is a symmetric function of the constituents. While this might be reasonable for certain structures, such as lists, a model of composition based on syntactic structure requires some way of differentiating the contributions of each constituent. In (Erk"
W13-3814,J98-1004,0,0.141611,"Missing"
W13-3814,P13-1045,0,0.0503895,"fective modeling of lexical information is proposed by (Croce et al., 2011), in the so called Smoothed Partial Tree Kernel (SPTK). In SPTK, the TK extends the similarity between tree structures allowing a smoothed function of node similarity. The aim of SPTK is to measure the similarity between syntactic tree structures, which are semantically related, i.e. partially similar, even when nodes, e.g. words at the leaves, differ. This is achieved with the following formulation of the function ∆ over nodes ni ∈ Ti : Recently, Compositional Semantics has been used in syntactic parsing, as shown in (Socher et al., 2013) where Compositional Vector Grammars (CVGs) have been defined to extend small-state Probabilistic Context-Free Grammars, introducing distributional semantic constraints in constituency parsing: interestingly, CVGs allows to estimate the plausibility of the corresponding syntactic constituent within a Recursive Neural Network, by assigning scores to nodes in the parse tree. A similar integrated contribution of lexical information (i.e. word vectors) and syntactic constituency is proposed in semantic extensions of TKs, as introduced in (Croce et al., 2011). As they offer a framework to define si"
W13-3814,D11-1096,1,0.560162,"ic similarity between linguistic instances. While the modeling of DCS for complex phrases is still an open research issue, TKs do not account for compositionality. In this paper, a novel kernel called Compositionally Smoothed Partial Tree Kernel is proposed integrating DCS operators into the TK estimation. Empirical results over Semantic Text Similarity and Question Classification tasks show the contribution of semantic compositions with respect to traditional TKs. 1 In this paper, we investigate the combination of DCS and Convolution Kernels. We extend a kernel function recently proposed in (Croce et al., 2011), called Smoothed Partial Tree Kernel (SPTK), that enriches the similarity between tree structures with a function of node similarity. As words are leaves in constituency syntactic trees, the lexical semantic similarity can be easily evaluated in term of similarity between their vector counterparts. In our DCS perspective, this lexical semantic information will be distributed across all the parse tree, as a carrier of the lexical composition, e.g. head/modifier relations, already explicit in dependency formalisms. The idea here is to propagate lexical semantic information over the entire parse"
W13-3814,S12-1088,1,0.900374,"Missing"
W13-3814,C10-1142,0,0.0202074,"in Section 4 the CSPTK similarity function is presented. Finally, in Section 5, the CSPTK model is investigated in Semantic Text Similarity (STS) and Question Classification tasks. 2 ent syntactic dependencies. Noun component of a composition between verb and noun is here given by an average of verbs that the noun is typically object of. In (Guevara, 2010) a regressor is trained for adjective-noun (AN) compositionality: pairs of adjective-noun vector concatenations are used as input in training data, whilst corpus-derived AN vectors as output. A similar approach was previously undertaken by (Zanzotto et al., 2010). A specific linear model of semantic composition based on the idea of space projection is proposed in (Annesi et al., 2012) for simple grammatical structures, i.e. syntactically typed bi-grams. Given a phrase such as “buy car” they project the ! and car, source vectors buy ! into a so-called Support Subspace, that is a subset of the original feature space. Space Projection depends on both the two involved lexicals and selects only their ”common” features: these concurrently constraint the suitable lexical interpretation local to the phrase. Given two phases p1 and p2 , semantic similarity can"
W13-3814,D08-1094,0,0.0312578,"08) two general classes of compositional models have been defined: a linear additive model p! = A!u + B!v and a multiplicative model p! = C!u!v . A and B are weight matrices and C is a weight tensor that project lexical vectors !u and !v onto the space of p!, i.e. the vector resulting from the composition. These models usually assume that composition is a symmetric function of the constituents. While this might be reasonable for certain structures, such as lists, a model of composition based on syntactic structure requires some way of differentiating the contributions of each constituent. In (Erk and Pado, 2008), the concept of a structured vector space is introduced, where each word is associated to a set of vectors corresponding to differ! ! Φ(◦) (p1 , p2 ) = (M!u · M!u ) ◦ (M!v · M!v ) (1) where first cosine similarity (·) between the vectors projected in the selected support subspaces is computed and then a composition function ◦, such as the sum or the product, is applied. Notice how projection M may depend on the involved pairs in complex ways. A Support Subspace can be derived from just one pair pi and then being imposed to the other with a corresponding asymmetric behavior of the Φ metrics, d"
W13-3814,W10-2805,0,0.0201947,"n-terminal labels. The resulting model has been called Compositionally Smoothed Partial Tree Kernel (CSPTK). In Section 2, a summary of approaches for DCS and TKs is presented. The entire process of marking parse trees is described in Section 3. Therefore in Section 4 the CSPTK similarity function is presented. Finally, in Section 5, the CSPTK model is investigated in Semantic Text Similarity (STS) and Question Classification tasks. 2 ent syntactic dependencies. Noun component of a composition between verb and noun is here given by an average of verbs that the noun is typically object of. In (Guevara, 2010) a regressor is trained for adjective-noun (AN) compositionality: pairs of adjective-noun vector concatenations are used as input in training data, whilst corpus-derived AN vectors as output. A similar approach was previously undertaken by (Zanzotto et al., 2010). A specific linear model of semantic composition based on the idea of space projection is proposed in (Annesi et al., 2012) for simple grammatical structures, i.e. syntactically typed bi-grams. Given a phrase such as “buy car” they project the ! and car, source vectors buy ! into a so-called Support Subspace, that is a subset of the o"
W13-3814,D11-1129,0,\N,Missing
W13-3814,P07-1098,1,\N,Missing
W13-3814,D13-1144,0,\N,Missing
W13-3814,J10-4006,0,\N,Missing
W13-3814,D12-1050,0,\N,Missing
W13-3820,P98-1013,0,0.392904,"Missing"
W13-3820,W13-2322,0,0.177027,"specifically focuses on the spatial relations involved. It enables a planning and reasoning module to correctly disambiguate objects in the world the robot is acting into. We propose the use of a general structure to represent all the semantics we are interested in. In fact, a typical problem when working with different representations, is that they are totally independent each other. They are not designed to work together in a more general semantic framework. In order to do it, we investigate the use of a new and appealing representation formalism, i.e. Abstract Meaning Representation (AMR) (Banarescu et al., 2013). It allows to express semantics without imposing any strong bias to the original sentence or syntactic structure. The final instantiated AMR annotation could be easily mapped to the commands expressed in the robot language (e.g. the logic form), in a way similar to the one proposed in (Thomas and Jenkins, 2012). In order to prove the effectiveness of the proposed idea, we evaluated existing natural language technologies not customized to the target HRI scenario. In the rest of the paper, in Section 2 different Natural Language Processing tasks are discussed with respect the HRI area. Finally,"
W13-3820,S13-2096,1,0.816146,"position “on” is the S PATIAL I NDICATOR of the relation between “book” and “table”, respectively 2 The system is not domain specific, since it is trained on the FrameNet 1.5 dataset SI TR TD Precision 0.78 0.80 0.75 Recall 0.84 0.61 0.75 F1-Measure 0.81 0.70 0.75 Table 2: Spatial Role Labeling results. a T RAJECTOR and a L ANDMARK. These information should help a robotic system to correctly determine which book has to be taken within the physical world, i.e. the one on the table. In table 2 we report performance measures in terms of Precision, Recall and F1-Measure of a Spatial Role Labeler (Bastianelli et al., 2013). These results refer to the S PATIAL I NDICATOR (SI), T RAJECTOR (TR) and L ANDMARK (LD) (Kordjamshidi et al., 2011) labeling on the 20 test sentences used above. Expressing Rich Semantic Information through AMR. In order to integrate the information conveyed by the Frame Semantics and the Spatial Semantics, we want to propose a representation flexible and as much as possible close to the domotic domain, i.e. the robot language. The Abstract Meaning Representation (AMR) (Banarescu et al., 2013) is a novel semantic representation language that allows to represent semantics in an abstract way,"
W13-3820,P03-1054,0,0.0128343,"Missing"
W13-3820,S12-1048,0,0.057957,"Missing"
W13-3820,C98-1013,0,\N,Missing
W17-2804,P98-1013,0,0.120674,"y decoupled from the robot, enabling for an easy and fast deployment on every platform1 . As the aforementioned approaches rely on realistic data, in this work we also present an extended version of HuRIC - a Human Robot Interaction Corpus, originally introduced in (Bastianelli et al., 2014) This resource is a collection of realistic spoken commands that users might express towards generic service robots. In this resource, each sentence is labeled with morphosyntactic information (e.g., dependency relations, POS tags, . . . ), along with its correct interpretation in terms of semantic frames (Baker et al., 1998). In our extension, each annotated sentence is paired with a semantic representation of the world, that justifies the command itself. To the best of our knowledge this is the first corpus providing such a rich representation of a robotic spoken command2 . 1 LU4R can be downloaded This extension of HuRIC supports a broader evaluation of LU4R chain against the information introduced by perceptual knowledge. We observed a significant increase in performance w.r.t. inherent ambiguities of the language, whose outcomes are encouraging for the deployment of such system in realistic applications. The"
W17-2804,bastianelli-etal-2014-huric,1,0.89637,"the vast plethora of existing robotic platforms. Such methodologies have been implemented in a free and ready-to-use framework, here presented, whose name is LU4R - an adaptive spoken Language Understanding framework for(4) Robots. LU4R is entirely coded in Java and, thanks to its Client/Server architectural design, it is completely decoupled from the robot, enabling for an easy and fast deployment on every platform1 . As the aforementioned approaches rely on realistic data, in this work we also present an extended version of HuRIC - a Human Robot Interaction Corpus, originally introduced in (Bastianelli et al., 2014) This resource is a collection of realistic spoken commands that users might express towards generic service robots. In this resource, each sentence is labeled with morphosyntactic information (e.g., dependency relations, POS tags, . . . ), along with its correct interpretation in terms of semantic frames (Baker et al., 1998). In our extension, each annotated sentence is paired with a semantic representation of the world, that justifies the command itself. To the best of our knowledge this is the first corpus providing such a rich representation of a robotic spoken command2 . 1 LU4R can be dow"
W17-2804,C02-1095,0,0.0226306,"bout its integration with a generic robot. Section 5 describes the extension of HuRIC, while in Section 6 we provide empirical evidence demonstrating the applicability of the proposed system in the interpretation of robotic commands, by reporting our experimental results. In Section 7 we draw some conclusions. 2 In Robotics, some solutions for the interpretation of spoken commands have been modeled using grammar-based approaches. In general, they provide mechanisms to enrich the syntactic structure with semantic information, to build a semantic representation during the transcription process (Bos, 2002; Bos and Oka, 2007). Other approaches are based on formal languages, as in (Kruijff et al., 2007; Thomason et al., 2015), where Combinatory Categorial Grammar (CCG) are applied for spoken dialogues in Human-Robot Interaction, and in (Perera and Veloso, 2015) where template-based algorithms allow extracting semantic interpretations of robotic commands by applying specific templates over the corresponding syntactic trees. Data-driven methods have been also applied to command interpretation for robotic applications. Examples are (MacMahon et al., 2006) and (Chen and Mooney, 2011), where the pars"
W17-2804,H89-2010,0,0.0548446,"Missing"
W17-2804,C98-1013,0,\N,Missing
W18-5403,bastianelli-etal-2014-huric,1,0.797217,"and G OAL for ”onto the dining table”. Argument classification corresponds to the subtask of assigning labels to the sentence fragments spanning individual roles. As proposed in (Moschitti et al., 2008), SRL can be modeled as a multi classification task over each parse tree node n, where argument spans reflect sub-sentences covered by the tree rooted at n. Consistently with (Croce et al., 2011), in our experiments the KDA has been empowered with a Smoothed Partial Tree Kernel, operating over Grammatical Relation Centered Tree (GRCT) derived from dependency grammar. We used the HuRIC dataset (Bastianelli et al., 2014), including over 650 annotated transcriptions of spoken robotic commands, organized in 18 frames and about 60 arguments4 . We extracted single arguments from each HuRIC example, for a total of 1, 300 instances. We run experiments with a methodology similar to the one described in Sec 4 THEME of BRINGING since different from ”the jar” in ”TAKE the jar to the table of the kitchen”. I think ”me” is the BENEFICIARY of BRINGING in ”I would like some cutlery can you GET me some?” since similar to ”me” in ”BRING me a fork from the press.” and it is not the COTHEME of COTHEME since different from ”me”"
W18-5403,J08-2003,1,0.82579,"and it is not the Semantic role labeling (SRL (Palmer et al., 2010)) consists in detecting the semantic arguments associated with the predicate of a sentence and their classification into their specific roles (Fillmore (1985)). For example, given the sentence ”Bring the fruit onto the dining table”, the task would be to recognize the verb ”bring” as evoking the B RINGING frame, with its roles, T HEME for ”the fruit” and G OAL for ”onto the dining table”. Argument classification corresponds to the subtask of assigning labels to the sentence fragments spanning individual roles. As proposed in (Moschitti et al., 2008), SRL can be modeled as a multi classification task over each parse tree node n, where argument spans reflect sub-sentences covered by the tree rooted at n. Consistently with (Croce et al., 2011), in our experiments the KDA has been empowered with a Smoothed Partial Tree Kernel, operating over Grammatical Relation Centered Tree (GRCT) derived from dependency grammar. We used the HuRIC dataset (Bastianelli et al., 2014), including over 650 annotated transcriptions of spoken robotic commands, organized in 18 frames and about 60 arguments4 . We extracted single arguments from each HuRIC example,"
W18-5403,N16-3020,0,0.232186,"ibing the target of a request is relevant in question answering to optimize the later 16 Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 16–24 c Brussels, Belgium, November 1, 2018. 2018 Association for Computational Linguistics tive of providing explanations of a neural classifier, often by focusing into highlighting an handful of crucial features (Baehrens et al., 2010) or deriving simpler, more readable models from a complex one, e.g. a binary decision tree (Frosst and Hinton, 2017), or by local approximation with linear models (Ribeiro et al., 2016). However, although they can explicitly show the representations learned in the specific hidden neurons (Frosst and Hinton, 2017), these approaches base their effectiveness on the user ability to study the quality of the reasoning and of the accountability as a side effect of the quality of the selected features: this can be very hard in tasks where boundaries between classes are not well defined. Sometimes, explanations are associated to vector representations as in (Ribeiro et al., 2016), i.e. bag-of-word in case of text classification, which is clearly weak at capturing significant linguist"
W18-5403,P17-1032,1,0.706775,"h, the classification decisions of a multilayer perceptron are decomposed backward across the network layers, and evidence about the contribution of individual input fragments (i.e. layer 0) to the final decision is gathered. Evaluation against images (i.e. the MNIST and ILSVRC data sets) suggests that LRP activates meaningful associations between input and output fragments, and this corresponds to tracing back meaningful causal connections. In this paper, we propose the use of a similar mechanism over the linguistically motivated network architectures, as they have been recently proposed in (Croce et al., 2017): Kernel-based Deep network architectures aim at integrating syntactic/semantic information derived from the adoption of Tree Kernels (Collins and Duffy, Nonlinear methods such as deep neural networks achieve state-of-the-art performances in several semantic NLP tasks. However epistemologically transparent decisions are not provided as for the limited interpretability of the underlying acquired neural models. In neuralbased semantic inference tasks epistemological transparency corresponds to the ability of tracing back causal connections between the linguistic properties of a input instance an"
W18-5403,D11-1096,1,0.876596,"ific roles (Fillmore (1985)). For example, given the sentence ”Bring the fruit onto the dining table”, the task would be to recognize the verb ”bring” as evoking the B RINGING frame, with its roles, T HEME for ”the fruit” and G OAL for ”onto the dining table”. Argument classification corresponds to the subtask of assigning labels to the sentence fragments spanning individual roles. As proposed in (Moschitti et al., 2008), SRL can be modeled as a multi classification task over each parse tree node n, where argument spans reflect sub-sentences covered by the tree rooted at n. Consistently with (Croce et al., 2011), in our experiments the KDA has been empowered with a Smoothed Partial Tree Kernel, operating over Grammatical Relation Centered Tree (GRCT) derived from dependency grammar. We used the HuRIC dataset (Bastianelli et al., 2014), including over 650 annotated transcriptions of spoken robotic commands, organized in 18 frames and about 60 arguments4 . We extracted single arguments from each HuRIC example, for a total of 1, 300 instances. We run experiments with a methodology similar to the one described in Sec 4 THEME of BRINGING since different from ”the jar” in ”TAKE the jar to the table of the"
W93-0107,P90-1034,0,0.032756,"nature of the event they describe, that is better expressed by the roles played by its arguments in a sentence. Psycholinguistie studies on verb semantics outline the relevance of thematic roles, especially in eategorisation activities Keil, (1989), Jackendoff (1983) and indicate the argument structure of verbs as playing a central role in language acquisition Pinker (1989). In NLP, representing verb semantics with their thematic roles is a consolidated practice, even though theoretical researches (Pustejovski (1991)) propose more rich and formal representation frameworks. More recent papers Hindle (1990), Pereira and Tishby (1992) proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts. Both papers use as a source of information large corpora, but differ in the type of statistical approach used to determine word similarity. These studies, though valuable, leave several open problems: 1) 2) 3) 4) A metric of conceptual closeness based on mere syntactic similarity is questionable, particularly if applied to verbs. In fact, the argument structure of verbs is variegated and poorly overlapping. Furthermore, subject and object relati"
W93-0107,J91-4003,0,0.0247141,"Missing"
W94-0102,P88-1013,0,0.0206968,"ried over to a Multi-parser. Instead of a CLAWS-style Markovian tagger, for each target parsing scheme a grammar and parser can be extracted directly from the corresponding training Treebank. A Context-Free Grammar can be elicited directly by extracting each non-terminal and its immediate-daughterscqu~&apos;nce, to become the left-hand-side and right-handside respectively of a context-free grammar rule [6]; frequencies of constituents in the training treebank can be used to make this a Probabilistic Context Free Grammar [49], useable in a treebank-trained probabilistic parser such as those in [2], [29], [9], [50]. Rather than producing a single, fully correct parse-tree for each input sentence, these probabilistic Treebank-trained p~rser generally output an ordered list of possible parsetrees, with a probability or weight attached to each. As with the procedure for developing a partial tagmapping, we need only devise source-to-target parsetree-constituent mappings in cases where the targetparser&apos;s &apos;best&apos; parsetree is not fully correct. A s s e s s m e n t o f t h e M u l t i - T r e e b a n k as a Benchmark for Grammars &apos;this requires analysis of the substantive differences beetw,&apos;en differ"
W97-0211,C94-2195,0,0.061124,"Missing"
W97-0211,W96-0306,0,0.0297374,"Missing"
W97-0211,C94-2119,0,0.0340737,"Missing"
W97-0211,J92-1001,0,0.44279,"Missing"
W97-0211,W95-0105,0,0.0776649,"Missing"
W97-0211,J93-1005,0,\N,Missing
W97-0211,C92-2070,0,\N,Missing
W97-0211,P93-1024,0,\N,Missing
W97-0314,C92-3150,0,0.0719348,"Missing"
W97-0314,C94-2195,0,0.0553412,"Missing"
W97-0314,A88-1019,0,0.115121,"Missing"
W97-0314,J96-4006,1,\N,Missing
W97-0314,J93-1005,0,\N,Missing
W98-0711,H92-1001,0,0.0228412,"Missing"
W98-0711,W95-0105,0,0.0354099,"Missing"
W98-0711,C96-1005,0,0.0554083,"Missing"
W98-0711,C96-1038,0,0.0622062,"Missing"
W98-0711,A97-1055,1,0.877498,"Missing"
W98-0711,C94-2113,0,0.0754246,"Missing"
W98-0711,W97-0206,0,0.039865,"Missing"
W98-0711,W93-0106,0,0.0490201,"Missing"
W98-0711,C92-2070,0,0.145979,"Missing"
W98-0711,W99-0624,0,0.0752319,"Missing"
W98-0711,H92-1045,0,0.0690167,"Missing"
