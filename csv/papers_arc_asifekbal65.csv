2021.wat-1.18,{IITP} at {WAT} 2021: System description for {E}nglish-{H}indi Multimodal Translation Task,2021,-1,-1,3,0,361,baban gain,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"Neural Machine Translation (NMT) is a predominant machine translation technology nowadays because of its end-to-end trainable flexibility. However, NMT still struggles to translate properly in low-resource settings specifically on distant language pairs. One way to overcome this is to use the information from other modalities if available. The idea is that despite differences in languages, both the source and target language speakers see the same thing and the visual representation of both the source and target is the same, which can positively assist the system. Multimodal information can help the NMT system to improve the translation by removing ambiguity on some phrases or words. We participate in the 8th Workshop on Asian Translation (WAT - 2021) for English-Hindi multimodal translation task and achieve 42.47 and 37.50 BLEU points for Evaluation and Challenge subset, respectively."
2021.wat-1.29,{IITP}-{MT} at {WAT}2021: Indic-{E}nglish Multilingual Neural Machine Translation using {R}omanized Vocabulary,2021,-1,-1,3,0,390,ramakrishna appicharla,Proceedings of the 8th Workshop on Asian Translation (WAT2021),0,"This paper describes the systems submitted to WAT 2021 MultiIndicMT shared task by IITP-MT team. We submit two multilingual Neural Machine Translation (NMT) systems (Indic-to-English and English-to-Indic). We romanize all Indic data and create subword vocabulary which is shared between all Indic languages. We use back-translation approach to generate synthetic data which is appended to parallel corpus and used to train our models. The models are evaluated using BLEU, RIBES and AMFM scores with Indic-to-English model achieving 40.08 BLEU for Hindi-English pair and English-to-Indic model achieving 34.48 BLEU for English-Hindi pair. However, we observe that the shared romanized subword vocabulary is not helping English-to-Indic model at the time of generation, leading it to produce poor quality translations for Tamil, Telugu and Malayalam to English pairs with BLEU score of 8.51, 6.25 and 3.79 respectively."
2021.mtsummit-research.2,Investigating Active Learning in Interactive Neural Machine Translation,2021,-1,-1,4,1,391,kamal gupta,Proceedings of Machine Translation Summit XVIII: Research Track,0,Interactive-predictive translation is a collaborative iterative process and where human translators produce translations with the help of machine translation (MT) systems interactively. Various sampling techniques in active learning (AL) exist to update the neural MT (NMT) model in the interactive-predictive scenario. In this paper and we explore term based (named entity count (NEC)) and quality based (quality estimation (QE) and sentence similarity (Sim)) sampling techniques {--} which are used to find the ideal candidates from the incoming data {--} for human supervision and MT model{'}s weight updation. We carried out experiments with three language pairs and viz. German-English and Spanish-English and Hindi-English. Our proposed sampling technique yields 1.82 and 0.77 and 0.81 BLEU points improvements for German-English and Spanish-English and Hindi-English and respectively and over random sampling based baseline. It also improves the present state-of-the-art by 0.35 and 0.12 BLEU points for German-English and Spanish-English and respectively. Human editing effort in terms of number-of-words-changed also improves by 5 and 4 points for German-English and Spanish-English and respectively and compared to the state-of-the-art.
2021.mtsummit-research.13,Sentiment Preservation in Review Translation using Curriculum-based Re-inforcement Framework,2021,-1,-1,4,0,5056,divya kumari,Proceedings of Machine Translation Summit XVIII: Research Track,0,Machine Translation (MT) systems often fail to preserve different stylistic and pragmatic properties of the source text (e.g. sentiment and emotion and gender traits and etc.) to the target and especially in a low-resource scenario. Such loss can affect the performance of any downstream Natural Language Processing (NLP) task and such as sentiment analysis and that heavily relies on the output of the MT systems. The susceptibility to sentiment polarity loss becomes even more severe when an MT system is employed for translating a source content that lacks a legitimate language structure (e.g. review text). Therefore and we must find ways to minimize the undesirable effects of sentiment loss in translation without compromising with the adequacy. In our current work and we present a deep re-inforcement learning (RL) framework in conjunction with the curriculum learning (as per difficulties of the reward) to fine-tune the parameters of a pre-trained neural MT system so that the generated translation successfully encodes the underlying sentiment of the source without compromising the adequacy unlike previous methods. We evaluate our proposed method on the English{--}Hindi (product domain) and French{--}English (restaurant domain) review datasets and and found that our method brings a significant improvement over several baselines in the machine translation and and sentiment classification tasks.
2021.mtsummit-research.20,Product Review Translation using Phrase Replacement and Attention Guided Noise Augmentation,2021,-1,-1,4,1,391,kamal gupta,Proceedings of Machine Translation Summit XVIII: Research Track,0,Product reviews provide valuable feedback of the customers and however and they are available today only in English on most of the e-commerce platforms. The nature of reviews provided by customers in any multilingual country poses unique challenges for machine translation such as code-mixing and ungrammatical sentences and presence of colloquial terms and lack of e-commerce parallel corpus etc. Given that 44{\%} of Indian population speaks and operates in Hindi language and we address the above challenges by presenting an English{--}to{--}Hindi neural machine translation (NMT) system to translate the product reviews available on e-commerce websites by creating an in-domain parallel corpora and handling various types of noise in reviews via two data augmentation techniques and viz. (i). a novel phrase augmentation technique (PhrRep) where the syntactic noun phrases in sentences are replaced by the other noun phrases carrying different meanings but in similar context; and (ii). a novel attention guided noise augmentation (AttnNoise) technique to make our NMT model robust towards various noise. Evaluation shows that using the proposed augmentation techniques we achieve a 6.67 BLEU score improvement over the baseline model. In order to show that our proposed approach is not language-specific and we also perform experiments for two other language pairs and viz. En-Fr (MTNT18 corpus) and En-De (IWSLT17) that yield the improvements of 2.55 and 0.91 BLEU points and respectively and over the baselines.
2021.inlg-1.39,{SEPRG}: Sentiment aware Emotion controlled Personalized Response Generation,2021,-1,-1,3,1,5987,mauajama firdaus,Proceedings of the 14th International Conference on Natural Language Generation,0,"Social chatbots have gained immense popularity, and their appeal lies not just in their capacity to respond to the diverse requests from users, but also in the ability to develop an emotional connection with users. To further develop and promote social chatbots, we need to concentrate on increasing user interaction and take into account both the intellectual and emotional quotient in the conversational agents. Therefore, in this work, we propose the task of sentiment aware emotion controlled personalized dialogue generation giving the machine the capability to respond emotionally and in accordance with the persona of the user. As sentiment and emotions are highly co-related, we use the sentiment knowledge of the previous utterance to generate the correct emotional response in accordance with the user persona. We design a Transformer based Dialogue Generation framework, that generates responses that are sensitive to the emotion of the user and corresponds to the persona and sentiment as well. Moreover, the persona information is encoded by a different Transformer encoder, along with the dialogue history, is fed to the decoder for generating responses. We annotate the PersonaChat dataset with sentiment information to improve the response quality. Experimental results on the PersonaChat dataset show that the proposed framework significantly outperforms the existing baselines, thereby generating personalized emotional responses in accordance with the sentiment that provides better emotional connection and user satisfaction as desired in a social chatbot."
2021.findings-emnlp.151,Towards Developing a Multilingual and Code-Mixed Visual Question Answering System by Knowledge Distillation,2021,-1,-1,3,0,6810,humair khan,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Pre-trained language-vision models have shown remarkable performance on the visual question answering (VQA) task. However, most pre-trained models are trained by only considering monolingual learning, especially the resource-rich language like English. Training such models for multilingual setups demand high computing resources and multilingual language-vision dataset which hinders their application in practice. To alleviate these challenges, we propose a knowledge distillation approach to extend an English language-vision model (teacher) into an equally effective multilingual and code-mixed model (student). Unlike the existing knowledge distillation methods, which only use the output from the last layer of the teacher network for distillation, our student model learns and imitates the teacher from multiple intermediate layers (language and vision encoders) with appropriately designed distillation objectives for incremental knowledge extraction. We also create the large-scale multilingual and code-mixed VQA dataset in eleven different language setups considering the multiple Indian and European languages. Experimental results and in-depth analysis show the effectiveness of the proposed VQA model over the pre-trained language-vision models on eleven diverse language setups."
2021.ecnlp-1.21,Product Review Translation: Parallel Corpus Creation and Robustness towards User-generated Noisy Text,2021,-1,-1,4,1,391,kamal gupta,Proceedings of The 4th Workshop on e-Commerce and NLP,0,"Reviews written by the users for a particular product or service play an influencing role for the customers to make an informative decision. Although online e-commerce portals have immensely impacted our lives, available contents predominantly are in English language- often limiting its widespread usage. There is an exponential growth in the number of e-commerce users who are not proficient in English. Hence, there is a necessity to make these services available in non-English languages, especially in a multilingual country like India. This can be achieved by an in-domain robust machine translation (MT) system. However, the reviews written by the users pose unique challenges to MT, such as misspelled words, ungrammatical constructions, presence of colloquial terms, lack of resources such as in-domain parallel corpus etc. We address the above challenges by presenting an English{--}Hindi review domain parallel corpus. We train an English{--}to{--}Hindi neural machine translation (NMT) system to translate the product reviews available on e-commerce websites. By training the Transformer based NMT model over the generated data, we achieve a score of 33.26 BLEU points for English{--}to{--}Hindi translation. In order to make our NMT model robust enough to handle the noisy tokens in the reviews, we integrate a character based language model to generate word vectors and map the noisy tokens with their correct forms. Experiments on four language pairs, viz. English-Hindi, English-German, English-French, and English-Czech show the BLUE scores of 35.09, 28.91, 34.68 and 14.52 which are the improvements of 1.61, 1.05, 1.63 and 1.94, respectively, over the baseline."
2021.eacl-main.255,Modelling Context Emotions using Multi-task Learning for Emotion Controlled Dialog Generation,2021,-1,-1,2,0,10884,deeksha varshney,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"A recent topic of research in natural language generation has been the development of automatic response generation modules that can automatically respond to a user{'}s utterance in an empathetic manner. Previous research has tackled this task using neural generative methods by augmenting emotion classes with the input sequences. However, the outputs by these models may be inconsistent. We employ multi-task learning to predict the emotion label and to generate a viable response for a given utterance using a common encoder with multiple decoders. Our proposed encoder-decoder model consists of a self-attention based encoder and a decoder with dot product attention mechanism to generate response with a specified emotion. We use the focal loss to handle imbalanced data distribution, and utilize the consistency loss to allow coherent decoding by the decoders. Human evaluation reveals that our model produces more emotionally pertinent responses. In addition, our model outperforms multiple strong baselines on automatic evaluation measures such as F1 and BLEU scores, thus resulting in more fluent and adequate responses."
2021.calcs-1.5,{IITP}-{MT} at {CALCS}2021: {E}nglish to {H}inglish Neural Machine Translation using Unsupervised Synthetic Code-Mixed Parallel Corpus,2021,-1,-1,3,0,390,ramakrishna appicharla,Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching,0,This paper describes the system submitted by IITP-MT team to Computational Approaches to Linguistic Code-Switching (CALCS 2021) shared task on MT for EnglishâHinglish. We submit a neural machine translation (NMT) system which is trained on the synthetic code-mixed (cm) English-Hinglish parallel corpus. We propose an approach to create code-mixed parallel corpus from a clean parallel corpus in an unsupervised manner. It is an alignment based approach and we do not use any linguistic resources for explicitly marking any token for code-switching. We also train NMT model on the gold corpus provided by the workshop organizers augmented with the generated synthetic code-mixed parallel corpus. The model trained over the generated synthetic cm data achieves 10.09 BLEU points over the given test set.
2020.semeval-1.261,{IITP}-{AINLPML} at {S}em{E}val-2020 Task 12: Offensive Tweet Identification and Target Categorization in a Multitask Environment,2020,-1,-1,2,0,15366,soumitra ghosh,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"In this paper, we describe the participation of IITP-AINLPML team in the SemEval-2020 SharedTask 12 on Offensive Language Identification and Target Categorization in English Twitter data. Our proposed model learns to extract textual features using a BiGRU-based deep neural network supported by a Hierarchical Attention architecture to focus on the most relevant areas in the text. We leverage the effectiveness of multitask learning while building our models for sub-task A and B. We do necessary undersampling of the over-represented classes in the sub-tasks A and C.During training, we consider a threshold of 0.5 as the separation margin between the instances belonging to classes OFF and NOT in sub-task A and UNT and TIN in sub-task B. For sub-task C, the class corresponding to the maximum score among the given confidence scores of the classes(IND, GRP and OTH) is considered as the final label for an instance. Our proposed model obtains the macro F1-scores of 90.95{\%}, 55.69{\%} and 63.88{\%} in sub-task A, B and C, respectively."
2020.lrec-1.201,"{CEASE}, a Corpus of Emotion Annotated Suicide notes in {E}nglish",2020,-1,-1,2,0,15366,soumitra ghosh,Proceedings of the 12th Language Resources and Evaluation Conference,0,"A suicide note is usually written shortly before the suicide and it provides a chance to comprehend the self-destructive state of mind of the deceased. From a psychological point of view, suicide notes have been utilized for recognizing the motive behind the suicide. To the best of our knowledge, there is no openly accessible suicide note corpus at present, making it challenging for the researchers and developers to deep dive into the area of mental health assessment and suicide prevention. In this paper, we create a fine-grained emotion annotated corpus (CEASE) of suicide notes in English and develop various deep learning models to perform emotion detection on the curated dataset. The corpus consists of 2393 sentences from around 205 suicide notes collected from various sources. Each sentence is annotated with a particular emotion class from a set of 15 fine-grained emotion labels, namely (forgiveness, happiness{\_}peacefulness, love, pride, hopefulness, thankfulness, blame, anger, fear, abuse, sorrow, hopelessness, guilt, information, instructions). For the evaluation, we develop an ensemble architecture, where the base models correspond to three supervised deep learning models, namely Convolutional Neural Network (CNN), Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM). We obtain the highest test accuracy of 60.17{\%} and cross-validation accuracy of 60.32{\%}"
2020.lrec-1.273,A Platform for Event Extraction in {H}indi,2020,-1,-1,3,0,17198,sovan sahoo,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Event Extraction is an important task in the widespread field of Natural Language Processing (NLP). Though this task is adequately addressed in English with sufficient resources, we are unaware of any benchmark setup in Indian languages. Hindi is one of the most widely spoken languages in the world. In this paper, we present an Event Extraction framework for Hindi language by creating an annotated resource for benchmarking, and then developing deep learning based models to set as the baselines. We crawl more than seventeen hundred disaster related Hindi news articles from the various news sources. We also develop deep learning based models for Event Trigger Detection and Classification, Argument Detection and Classification and Event-Argument Linking."
2020.lrec-1.514,Incorporating Politeness across Languages in Customer Care Responses: Towards building a Multi-lingual Empathetic Dialogue Agent,2020,-1,-1,2,1,5987,mauajama firdaus,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Customer satisfaction is an essential aspect of customer care systems. It is imperative for such systems to be polite while handling customer requests/demands. In this paper, we present a large multi-lingual conversational dataset for English and Hindi. We choose data from Twitter having both generic and courteous responses between customer care agents and aggrieved users. We also propose strong baselines that can induce courteous behaviour in generic customer care response in a multi-lingual scenario. We build a deep learning framework that can simultaneously handle different languages and incorporate polite behaviour in the customer care agent{'}s responses. Our system is competent in generating responses in different languages (here, English and Hindi) depending on the customer{'}s preference and also is able to converse with humans in an empathetic manner to ensure customer satisfaction and retention. Experimental results show that our proposed models can converse in both the languages and the information shared between the languages helps in improving the performance of the overall system. Qualitative and quantitative analysis shows that the proposed method can converse in an empathetic manner by incorporating courteousness in the responses and hence increasing customer satisfaction."
2020.lrec-1.621,Multi-domain Tweet Corpora for Sentiment Analysis: Resource Creation and Evaluation,2020,-1,-1,2,0,17896,mamta,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Due to the phenomenal growth of online content in recent time, sentiment analysis has attracted attention of the researchers and developers. A number of benchmark annotated corpora are available for domains like movie reviews, product reviews, hotel reviews, etc.The pervasiveness of social media has also lead to a huge amount of content posted by users who are misusing the power of social media to spread false beliefs and to negatively influence others. This type of content is coming from the domains like terrorism, cybersecurity, technology, social issues, etc. Mining of opinions from these domains is important to create a socially intelligent system to provide security to the public and to maintain the law and order situations. To the best of our knowledge, there is no publicly available tweet corpora for such pervasive domains. Hence, we firstly create a multi-domain tweet sentiment corpora and then establish a deep neural network based baseline framework to address the above mentioned issues. Annotated corpus has Cohen{'}s Kappa measurement for annotation quality of 0.770, which shows that the data is of acceptable quality. We are able to achieve 84.65{\%} accuracy for sentiment analysis by using an ensemble of Convolutional Neural Network (CNN), Long Short Term Memory (LSTM), and Gated Recurrent Unit(GRU)."
2020.lrec-1.675,{S}cholarly{R}ead: A New Dataset for Scientific Article Reading Comprehension,2020,-1,-1,2,1,17998,tanik saikh,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present ScholarlyRead, span-of-word-based scholarly articles{'} Reading Comprehension (RC) dataset with approximately 10K manually checked passage-question-answer instances. ScholarlyRead was constructed in semi-automatic way. We consider the articles from two popular journals of a reputed publishing house. Firstly, we generate questions from these articles in an automatic way. Generated questions are then manually checked by the human annotators. We propose a baseline model based on Bi-Directional Attention Flow (BiDAF) network that yields the F1 score of 37.31{\%}. The framework would be useful for building Question-Answering (QA) systems on scientific articles."
2020.icon-main.60,Only text? only image? or both? Predicting sentiment of internet memes,2020,-1,-1,3,0,19198,pranati behera,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"Nowadays, the spread of Internet memes on online social media platforms such as Instagram, Facebook, Reddit, and Twitter is very fast. Analyzing the sentiment of memes can provide various useful insights. Meme sentiment classification is a new area of research that is not explored yet. Recently SemEval provides a dataset for meme sentiment classification. As this dataset is highly imbalanced, we extend this dataset by annotating new instances and use a sampling strategy to build a meme sentiment classifier. We propose a multi-modal framework for meme sentiment classification by utilizing textual and visual features of the meme. We found that for meme sentiment classification, only textual or only visual features are not sufficient. Our proposed framework utilizes textual as well as visual features together. We propose to use the attention mechanism to improve meme classification performance. Our proposed framework achieves macro F1 and accuracy of 34.23 and 50.02, respectively. It increases the accuracy by 6.77 and 7.86 compared to only textual and visual features, respectively."
2020.icon-main.62,Annotated Corpus of Tweets in {E}nglish from Various Domains for Emotion Detection,2020,-1,-1,2,0,15366,soumitra ghosh,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"Emotion recognition is a very well-attended problem in Natural Language Processing (NLP). Most of the existing works on emotion recognition focus on the general domain and in some cases to specific domains like fairy tales, blogs, weather, Twitter etc. But emotion analysis systems in the domains of security, social issues, technology, politics, sports, etc. are very rare. In this paper, we create a benchmark setup for emotion recognition in these specialised domains. First, we construct a corpus of 18,921 tweets in English annotated with Paul Ekman{'}s six basic emotions (Anger, Disgust, Fear, Happiness, Sadness, Surprise) and a non-emotive class Others. Thereafter, we propose a deep neural framework to perform emotion recognition in an end-to-end setting. We build various models based on Convolutional Neural Network (CNN), Bi-directional Long Short Term Memory (Bi-LSTM), Bi-directional Gated Recurrent Unit (Bi-GRU). We propose a Hierarchical Attention-based deep neural network for Emotion Detection (HAtED). We also develop multiple systems by considering different sets of emotion classes for each system and report the detailed comparative analysis of the results. Experiments show the hierarchical attention-based model achieves best results among the considered baselines with accuracy of 69{\%}."
2020.icon-main.66,"Leveraging Multi-domain, Heterogeneous Data using Deep Multitask Learning for Hate Speech Detection",2020,-1,-1,2,1,19203,prashant kapil,Proceedings of the 17th International Conference on Natural Language Processing (ICON),0,"With the exponential rise in user-generated web content on social media, the proliferation of abusive languages towards an individual or a group across the different sections of the internet is also rapidly increasing. It is very challenging for human moderators to identify the offensive contents and filter those out. Deep neural networks have shown promise with reasonable accuracy for hate speech detection and allied applications. However, the classifiers are heavily dependent on the size and quality of the training data. Such a high-quality large data set is not easy to obtain. Moreover, the existing data sets that have emerged in recent times are not created following the same annotation guidelines and are often concerned with different types and sub-types related to hate. To solve this data sparsity problem, and to obtain more global representative features, we propose a Convolution Neural Network (CNN) based multi-task learning models (MTLs) to leverage information from multiple sources. Empirical analysis performed on three benchmark datasets shows the efficacy of the proposed approach with the significant improvement in accuracy and F-score to obtain state-of-the-art performance with respect to the existing systems."
2020.findings-emnlp.206,A Semi-supervised Approach to Generate the Code-Mixed Text using Pre-trained Encoder and Transfer Learning,2020,-1,-1,2,1,6811,deepak gupta,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Code-mixing, the interleaving of two or more languages within a sentence or discourse is ubiquitous in multilingual societies. The lack of code-mixed training data is one of the major concerns for the development of end-to-end neural network-based models to be deployed for a variety of natural language processing (NLP) applications. A potential solution is to either manually create or crowd-source the code-mixed labelled data for the task at hand, but that requires much human efforts and often not feasible because of the language specific diversity in the code-mixed text. To circumvent the data scarcity issue, we propose an effective deep learning approach for automatically generating the code-mixed text from English to multiple languages without any parallel data. In order to train the neural network, we create synthetic code-mixed texts from the available parallel corpus by modelling various linguistic properties of code-mixing. Our codemixed text generator is built upon the encoder-decoder framework, where the encoder is augmented with the linguistic and task-agnostic features obtained from the transformer based language model. We also transfer the knowledge from a neural machine translation (NMT) to warm-start the training of code-mixed generator. Experimental results and in-depth analysis show the effectiveness of our proposed code-mixed text generation on eight diverse language pairs."
2020.findings-emnlp.210,{M}ulti{DM}-{GCN}: Aspect-guided Response Generation in Multi-domain Multi-modal Dialogue System using Graph Convolutional Network,2020,-1,-1,3,1,5987,mauajama firdaus,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"In the recent past, dialogue systems have gained immense popularity and have become ubiquitous. During conversations, humans not only rely on languages but seek contextual information through visual contents as well. In every task-oriented dialogue system, the user is guided by the different aspects of a product or service that regulates the conversation towards selecting the product or service. In this work, we present a multi-modal conversational framework for a task-oriented dialogue setup that generates the responses following the different aspects of a product or service to cater to the user{'}s needs. We show that the responses guided by the aspect information provide more interactive and informative responses for better communication between the agent and the user. We first create a Multi-domain Multi-modal Dialogue (MDMMD) dataset having conversations involving both text and images belonging to the three different domains, such as restaurants, electronics, and furniture. We implement a Graph Convolutional Network (GCN) based framework that generates appropriate textual responses from the multi-modal inputs. The multi-modal information having both textual and image representation is fed to the decoder and the aspect information for generating aspect guided responses. Quantitative and qualitative analyses show that the proposed methodology outperforms several baselines for the proposed task of aspect-guided response generation."
2020.eamt-1.21,Modelling Source- and Target- Language Syntactic Information as Conditional Context in Interactive Neural Machine Translation,2020,-1,-1,3,1,391,kamal gupta,Proceedings of the 22nd Annual Conference of the European Association for Machine Translation,0,"In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, which is seen as an effective way to improve the productivity gain in translation. In this study, we model source-language syntactic constituency parse and target-language syntactic descriptions in the form of supertags as conditional context for interactive prediction in neural MT (NMT). We found that the supertags significantly improve productivity gain in translation in interactive-predictive NMT (INMT), while syntactic parsing somewhat found to be effective in reducing human effort in translation. Furthermore, when we model this source- and target-language syntactic information together as the conditional context, both types complement each other and our fully syntax-informed INMT model statistically significantly reduces human efforts in a French{--}to{--}English translation task, achieving 4.30 points absolute (corresponding to 9.18{\%} relative) improvement in terms of word prediction accuracy (WPA) and 4.84 points absolute (corresponding to 9.01{\%} relative) reduction in terms of word stroke ratio (WSR) over the baseline."
2020.coling-main.249,Reinforced Multi-task Approach for Multi-hop Question Generation,2020,42,0,4,1,6811,deepak gupta,Proceedings of the 28th International Conference on Computational Linguistics,0,"Question generation (QG) attempts to solve the inverse of question answering (QA) problem by generating a natural language question given a document and an answer. While sequence to sequence neural models surpass rule-based systems for QG, they are limited in their capacity to focus on more than one supporting fact. For QG, we often require multiple supporting facts to generate high-quality questions. Inspired by recent works on multi-hop reasoning in QA, we take up Multi-hop question generation, which aims at generating relevant questions based on supporting facts in the context. We employ multitask learning with the auxiliary task of answer-aware supporting fact prediction to guide the question generator. In addition, we also proposed a question-aware reward function in a Reinforcement Learning (RL) framework to maximize the utilization of the supporting facts. We demonstrate the effectiveness of our approach through experiments on the multi-hop question answering dataset, HotPotQA. Empirical evaluation shows our model to outperform the single-hop neural question generation models on both automatic evaluation metrics such as BLEU, METEOR, and ROUGE and human evaluation metrics for quality and coverage of the generated questions."
2020.coling-main.393,"{MEISD}: A Multimodal Multi-Label Emotion, Intensity and Sentiment Dialogue Dataset for Emotion Recognition and Sentiment Analysis in Conversations",2020,-1,-1,3,1,5987,mauajama firdaus,Proceedings of the 28th International Conference on Computational Linguistics,0,"Emotion and sentiment classification in dialogues is a challenging task that has gained popularity in recent times. Humans tend to have multiple emotions with varying intensities while expressing their thoughts and feelings. Emotions in an utterance of dialogue can either be independent or dependent on the previous utterances, thus making the task complex and interesting. Multi-label emotion detection in conversations is a significant task that provides the ability to the system to understand the various emotions of the users interacting. Sentiment analysis in dialogue/conversation, on the other hand, helps in understanding the perspective of the user with respect to the ongoing conversation. Along with text, additional information in the form of audio and video assist in identifying the correct emotions with the appropriate intensity and sentiments in an utterance of a dialogue. Lately, quite a few datasets have been made available for dialogue emotion and sentiment classification, but these datasets are imbalanced in representing different emotions and consist of an only single emotion. Hence, we present at first a large-scale balanced Multimodal Multi-label Emotion, Intensity, and Sentiment Dialogue dataset (MEISD), collected from different TV series that has textual, audio and visual features, and then establish a baseline setup for further research."
2020.acl-main.401,"Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis",2020,-1,-1,3,1,22893,dushyant chauhan,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we hypothesize that sarcasm is closely related to sentiment and emotion, and thereby propose a multi-task deep learning framework to solve all these three problems simultaneously in a multi-modal conversational scenario. We, at first, manually annotate the recently released multi-modal MUStARD sarcasm dataset with sentiment and emotion classes, both implicit and explicit. For multi-tasking, we propose two attention mechanisms, viz. Inter-segment Inter-modal Attention (Ie-Attention) and Intra-segment Inter-modal Attention (Ia-Attention). The main motivation of Ie-Attention is to learn the relationship between the different segments of the sentence across the modalities. In contrast, Ia-Attention focuses within the same segment of the sentence across the modalities. Finally, representations from both the attentions are concatenated and shared across the five classes (i.e., sarcasm, implicit sentiment, explicit sentiment, implicit emotion, explicit emotion) for multi-tasking. Experimental results on the extended version of the MUStARD dataset show the efficacy of our proposed approach for sarcasm detection over the existing state-of-the-art systems. The evaluation also shows that the proposed multi-task framework yields better performance for the primary task, i.e., sarcasm detection, with the help of two secondary tasks, emotion and sentiment analysis."
2020.aacl-main.31,"All-in-One: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes",2020,-1,-1,3,1,22893,dushyant chauhan,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"In this paper, we aim at learning the relationships and similarities of a variety of tasks, such as humour detection, sarcasm detection, offensive content detection, motivational content detection and sentiment analysis on a somewhat complicated form of information, i.e., memes. We propose a multi-task, multi-modal deep learning framework to solve multiple tasks simultaneously. For multi-tasking, we propose two attention-like mechanisms viz., Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM). The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other. In contrast, iCRM develops relations between the different classes of tasks. Finally, representations from both the attentions are concatenated and shared across the five tasks (i.e., humour, sarcasm, offensive, motivational, and sentiment) for multi-tasking. We use the recently released dataset in the Memotion Analysis task @ SemEval 2020, which consists of memes annotated for the classes as mentioned above. Empirical results on Memotion dataset show the efficacy of our proposed approach over the existing state-of-the-art systems (Baseline and SemEval 2020 winner). The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning."
2020.aacl-main.33,Unsupervised Aspect-Level Sentiment Controllable Style Transfer,2020,-1,-1,3,0,12111,mukuntha sundararaman,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"Unsupervised style transfer in text has previously been explored through the sentiment transfer task. The task entails inverting the overall sentiment polarity in a given input sentence, while preserving its content. From the Aspect-Based Sentiment Analysis (ABSA) task, we know that multiple sentiment polarities can often be present together in a sentence with multiple aspects. In this paper, the task of aspect-level sentiment controllable style transfer is introduced, where each of the aspect-level sentiments can individually be controlled at the output. To achieve this goal, a BERT-based encoder-decoder architecture with saliency weighted polarity injection is proposed, with unsupervised training strategies, such as ABSA masked-language-modelling. Through both automatic and manual evaluation, we show that the system is successful in controlling aspect-level sentiments."
2020.aacl-main.90,A Unified Framework for Multilingual and Code-Mixed Visual Question Answering,2020,-1,-1,3,1,6811,deepak gupta,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"In this paper, we propose an effective deep learning framework for multilingual and code- mixed visual question answering. The pro- posed model is capable of predicting answers from the questions in Hindi, English or Code- mixed (Hinglish: Hindi-English) languages. The majority of the existing techniques on Vi- sual Question Answering (VQA) focus on En- glish questions only. However, many applica- tions such as medical imaging, tourism, visual assistants require a multilinguality-enabled module for their widespread usages. As there is no available dataset in English-Hindi VQA, we firstly create Hindi and Code-mixed VQA datasets by exploiting the linguistic properties of these languages. We propose a robust tech- nique capable of handling the multilingual and code-mixed question to provide the answer against the visual information (image). To better encode the multilingual and code-mixed questions, we introduce a hierarchy of shared layers. We control the behaviour of these shared layers by an attention-based soft layer sharing mechanism, which learns how shared layers are applied in different ways for the dif- ferent languages of the question. Further, our model uses bi-linear attention with a residual connection to fuse the language and image fea- tures. We perform extensive evaluation and ablation studies for English, Hindi and Code- mixed VQA. The evaluation shows that the proposed multilingual model achieves state-of- the-art performance in all these settings."
W19-5440,Parallel Corpus Filtering Based on Fuzzy String Matching,2019,0,0,2,1,5731,sukanta sen,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",0,"In this paper, we describe the IIT Patna{'}s submission to WMT 2019 shared task on parallel corpus filtering. This shared task asks the participants to develop methods for scoring each parallel sentence from a given noisy parallel corpus. Quality of the scoring method is judged based on the quality of SMT and NMT systems trained on smaller set of high-quality parallel sentences sub-sampled from the original noisy corpus. This task has two language pairs. We submit for both the Nepali-English and Sinhala-English language pairs. We define fuzzy string matching score between English and the translated (into English) source based on Levenshtein distance. Based on the scores, we sub-sample two sets (having 1 million and 5 millions English tokens) of parallel sentences from each parallel corpus, and train SMT systems for development purpose only. The organizers publish the official evaluation using both SMT and NMT on the final official test set. Total 10 teams participated in the shared task and according the official evaluation, our scoring method obtains 2nd position in the team ranking for 1-million NepaliEnglish NMT and 5-million Sinhala-English NMT categories."
W19-5346,{IITP}-{MT} System for {G}ujarati-{E}nglish News Translation Task at {WMT} 2019,2019,-1,-1,3,1,5731,sukanta sen,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"We describe our submission to WMT 2019 News translation shared task for Gujarati-English language pair. We submit constrained systems, i.e, we rely on the data provided for this language pair and do not use any external data. We train Transformer based subword-level neural machine translation (NMT) system using original parallel corpus along with synthetic parallel corpus obtained through back-translation of monolingual data. Our primary systems achieve BLEU scores of 10.4 and 8.1 for GujaratiâEnglish and EnglishâGujarati, respectively. We observe that incorporating monolingual data through back-translation improves the BLEU score significantly over baseline NMT and SMT systems for this language pair."
W19-5056,"{IITP} at {MEDIQA} 2019: Systems Report for Natural Language Inference, Question Entailment and Question Answering",2019,8,0,4,0,362,dibyanayan bandyopadhyay,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"This paper presents the experiments accomplished as a part of our participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We participated in all the three tasks defined in this particular shared task. The tasks are viz. i. Natural Language Inference (NLI) ii. Recognizing Question Entailment(RQE) and their application in medical Question Answering (QA). We submitted runs using multiple deep learning based systems (runs) for each of these three tasks. We submitted five system results in each of the NLI and RQE tasks, and four system results for the QA task. The systems yield encouraging results in all the three tasks. The highest performance obtained in NLI, RQE and QA tasks are 81.8{\%}, 53.2{\%}, and 71.7{\%}, respectively."
W19-0413,Language-Agnostic Model for Aspect-Based Sentiment Analysis,2019,0,0,3,1,7352,md akhtar,Proceedings of the 13th International Conference on Computational Semantics - Long Papers,0,"In this paper, we propose a language-agnostic deep neural network architecture for aspect-based sentiment analysis. The proposed approach is based on Bidirectional Long Short-Term Memory (Bi-LSTM) network, which is further assisted with extra hand-crafted features. We define three different architectures for the successful combination of word embeddings and hand-crafted features. We evaluate the proposed approach for six languages (i.e. English, Spanish, French, Dutch, German and Hindi) and two problems (i.e. aspect term extraction and aspect sentiment classification). Experiments show that the proposed model attains state-of-the-art performance in most of the settings."
S19-2105,{NLP} at {S}em{E}val-2019 Task 6: Detecting Offensive language using Neural Networks,2019,0,1,2,1,19203,prashant kapil,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"In this paper we built several deep learning architectures to participate in shared task OffensEval: Identifying and categorizing Offensive language in Social media by semEval-2019. The dataset was annotated with three level annotation schemes and task was to detect between offensive and not offensive, categorization and target identification in offensive contents. Deep learning models with POS information as feature were also leveraged for classification. The three best models that performed best on individual sub tasks are stacking of CNN-Bi-LSTM with Attention, BiLSTM with POS information added with word features and Bi-LSTM for third task. Our models achieved a Macro F1 score of 0.7594, 0.5378 and 0.4588 in Task(A,B,C) respectively with rank of 33rd, 54th and 52nd out of 103, 75 and 65 submissions.The three best models that performed best on individual sub task are using Neural Networks."
P19-1106,{D}eep{S}enti{P}eer: Harnessing Sentiment in Review Texts to Recommend Peer Review Decisions,2019,0,0,3,1,1804,tirthankar ghosal,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Automatically validating a research artefact is one of the frontiers in Artificial Intelligence (AI) that directly brings it close to competing with human intellect and intuition. Although criticised sometimes, the existing peer review system still stands as the benchmark of research validation. The present-day peer review process is not straightforward and demands profound domain knowledge, expertise, and intelligence of human reviewer(s), which is somewhat elusive with the current state of AI. However, the peer review texts, which contains rich sentiment information of the reviewer, reflecting his/her overall attitude towards the research in the paper, could be a valuable entity to predict the acceptance or rejection of the manuscript under consideration. Here in this work, we investigate the role of reviewer sentiment embedded within peer review texts to predict the peer review outcome. Our proposed deep neural architecture takes into account three channels of information: the paper, the corresponding reviews, and review{'}s polarity to predict the overall recommendation score as well as the final decision. We achieve significant performance improvement over the baselines (â¼ 29{\%} error reduction) proposed in a recently released dataset of peer reviews. An AI of this kind could assist the editors/program chairs as an additional layer of confidence, especially when non-responding/missing reviewers are frequent in present day peer review."
P19-1297,Multilingual Unsupervised {NMT} using Shared Encoder and Language-Specific Decoders,2019,0,0,3,1,5731,sukanta sen,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we propose a multilingual unsupervised NMT scheme which jointly trains multiple languages with a shared encoder and multiple decoders. Our approach is based on denoising autoencoding of each language and back-translating between English and multiple non-English languages. This results in a universal encoder which can encode any language participating in training into an inter-lingual representation, and language-specific decoders. Our experiments using only monolingual corpora show that multilingual unsupervised model performs better than the separately trained bilingual models achieving improvement of up to 1.48 BLEU points on WMT test sets. We also observe that even if we do not train the network for all possible translation directions, the network is still able to translate in a many-to-many fashion leveraging encoder{'}s ability to generate interlingual representation."
P19-1516,A Unified Multi-task Adversarial Learning Framework for Pharmacovigilance Mining,2019,0,1,2,1,8271,shweta yadav,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"The mining of adverse drug reaction (ADR) has a crucial role in the pharmacovigilance. The traditional ways of identifying ADR are reliable but time-consuming, non-scalable and offer a very limited amount of ADR relevant information. With the unprecedented growth of information sources in the forms of social media texts (Twitter, Blogs, Reviews etc.), biomedical literature, and Electronic Medical Records (EMR), it has become crucial to extract the most pertinent ADR related information from these free-form texts. In this paper, we propose a neural network inspired multi- task learning framework that can simultaneously extract ADRs from various sources. We adopt a novel adversarial learning-based approach to learn features across multiple ADR information sources. Unlike the other existing techniques, our approach is capable to extracting fine-grained information (such as {`}Indications{'}, {`}Symptoms{'}, {`}Finding{'}, {`}Disease{'}, {`}Drug{'}) which provide important cues in pharmacovigilance. We evaluate our proposed approach on three publicly available real- world benchmark pharmacovigilance datasets, a Twitter dataset from PSB 2016 Social Me- dia Shared Task, CADEC corpus and Medline ADR corpus. Experiments show that our unified framework achieves state-of-the-art performance on individual tasks associated with the different benchmark datasets. This establishes the fact that our proposed approach is generic, which enables it to achieve high performance on the diverse datasets."
P19-1540,Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System,2019,0,0,3,0,21345,hardik chauhan,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Multimodal dialogue systems have opened new frontiers in the traditional goal-oriented dialogue systems. The state-of-the-art dialogue systems are primarily based on unimodal sources, predominantly the text, and hence cannot capture the information present in the other sources such as videos, audios, images etc. With the availability of large scale multimodal dialogue dataset (MMD) (Saha et al., 2018) on the fashion domain, the visual appearance of the products is essential for understanding the intention of the user. Without capturing the information from both the text and image, the system will be incapable of generating correct and desirable responses. In this paper, we propose a novel position and attribute aware attention mechanism to learn enhanced image representation conditioned on the user utterance. Our evaluation shows that the proposed model can generate appropriate responses while preserving the position and attribute information. Experimental results also prove that our proposed approach attains superior performance compared to the baseline models, and outperforms the state-of-the-art approaches on text similarity based evaluation metrics."
N19-1034,Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis,2019,0,4,5,1,7352,md akhtar,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Related tasks often have inter-dependence on each other and perform better when solved in a joint framework. In this paper, we present a deep multi-task learning framework that jointly performs sentiment and emotion analysis both. The multi-modal inputs (i.e. text, acoustic and visual frames) of a video convey diverse and distinctive information, and usually do not have equal contribution in the decision making. We propose a context-level inter-modal attention framework for simultaneously predicting the sentiment and expressed emotions of an utterance. We evaluate our proposed approach on CMU-MOSEI dataset for multi-modal sentiment and emotion analysis. Evaluation results suggest that multi-task learning framework offers improvement over the single-task framework. The proposed approach reports new state-of-the-art performance for both sentiment analysis and emotion analysis."
N19-1091,Courteously Yours: Inducing courteous behavior in Customer Care responses using Reinforced Pointer Generator Network,2019,0,0,3,0,26106,hitesh golchha,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"In this paper, we propose an effective deep learning framework for inducing courteous behavior in customer care responses. The interaction between a customer and the customer care representative contributes substantially to the overall customer experience. Thus it is imperative for customer care agents and chatbots engaging with humans to be personal, cordial and emphatic to ensure customer satisfaction and retention. Our system aims at automatically transforming neutral customer care responses into courteous replies. Along with stylistic transfer (of courtesy), our system ensures that responses are coherent with the conversation history, and generates courteous expressions consistent with the emotional state of the customer. Our technique is based on a reinforced pointer-generator model for the sequence to sequence task. The model is also conditioned on a hierarchically encoded and emotionally aware conversational context. We use real interactions on Twitter between customer care professionals and aggrieved customers to create a large conversational dataset having both forms of agent responses: {`}generic{'} and {`}courteous{'}. We perform quantitative and qualitative analyses on established and task-specific metrics, both automatic and human evaluation based. Our evaluation shows that the proposed models can generate emotionally-appropriate courteous expressions while preserving the content. Experimental results also prove that our proposed approach performs better than the baseline models."
D19-1566,Context-aware Interactive Attention for Multi-modal Sentiment and Emotion Analysis,2019,0,2,3,1,22893,dushyant chauhan,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"In recent times, multi-modal analysis has been an emerging and highly sought-after field at the intersection of natural language processing, computer vision, and speech processing. The prime objective of such studies is to leverage the diversified information, (e.g., textual, acoustic and visual), for learning a model. The effective interaction among these modalities often leads to a better system in terms of performance. In this paper, we introduce a recurrent neural network based approach for the multi-modal sentiment and emotion analysis. The proposed model learns the inter-modal interaction among the participating modalities through an auto-encoder mechanism. We employ a context-aware attention module to exploit the correspondence among the neighboring utterances. We evaluate our proposed approach for five standard multi-modal affect analysis datasets. Experimental results suggest the efficacy of the proposed model for both sentiment and emotion analysis over various existing state-of-the-art systems."
2019.icon-1.2,A Deep Ensemble Framework for Fake News Detection and Multi-Class Classification of Short Political Statements,2019,-1,-1,3,0,27372,arjun roy,Proceedings of the 16th International Conference on Natural Language Processing,0,"Fake news, rumor, incorrect information, and misinformation detection are nowadays crucial issues as these might have serious consequences for our social fabrics. Such information is increasing rapidly due to the availability of enormous web information sources including social media feeds, news blogs, online newspapers etc. In this paper, we develop various deep learning models for detecting fake news and classifying them into the pre-defined fine-grained categories. At first, we develop individual models based on Convolutional Neural Network (CNN), and Bi-directional Long Short Term Memory (Bi-LSTM) networks. The representations obtained from these two models are fed into a Multi-layer Perceptron Model (MLP) for the final classification. Our experiments on a benchmark dataset show promising results with an overall accuracy of 44.87{\%}, which outperforms the current state of the arts."
2019.icon-1.16,Multi-linguality helps: Event-Argument Extraction for Disaster Domain in Cross-lingual and Multi-lingual setting,2019,-1,-1,3,0,23229,zishan ahmad,Proceedings of the 16th International Conference on Natural Language Processing,0,"Automatic extraction of disaster-related events and their arguments from natural language text is vital for building a decision support system for crisis management. Event extraction from various news sources is a well-explored area for this objective. However, extracting events alone, without any context, provides only partial help for this purpose. Extracting related arguments like Time, Place, Casualties, etc., provides a complete picture of the disaster event. In this paper, we create a disaster domain dataset in Hindi by annotating disaster-related event and arguments. We also obtain equivalent datasets for Bengali and English from a collaboration. We build a multi-lingual deep learning model for argument extraction in all the three languages. We also compare our multi-lingual system with a similar baseline mono-lingual system trained for each language separately. It is observed that a single multi-lingual system is able to compensate for lack of training data, by using joint training of dataset from different languages in shared space, thus giving a better overall result."
2019.icon-1.19,A Multi-task Model for Multilingual Trigger Detection and Classification,2019,-1,-1,3,0,17198,sovan sahoo,Proceedings of the 16th International Conference on Natural Language Processing,0,"In this paper we present a deep multi-task learning framework for multilingual event and argument trigger detection and classification. In our current work, we identify detection and classification of both event and argument triggers as related tasks and follow a multi-tasking approach to solve them simultaneously in contrast to the previous works where these tasks were solved separately or learning some of the above mentioned tasks jointly. We evaluate the proposed approach with multiple low-resource Indian languages. As there were no datasets available for the Indian languages, we have annotated disaster related news data crawled from the online news portal for different low-resource Indian languages for our experiments. Our empirical evaluation shows that multi-task model performs better than the single task model, and classification helps in trigger detection and vice-versa."
2019.icon-1.27,A Deep Learning Approach for Automatic Detection of Fake News,2019,-1,-1,3,1,17998,tanik saikh,Proceedings of the 16th International Conference on Natural Language Processing,0,"Fake news detection is a very prominent and essential task in the field of journalism. This challenging problem is seen so far in the field of politics, but it could be even more challenging when it is to be determined in the multi-domain platform. In this paper, we propose two effective models based on deep learning for solving fake news detection problem in online news contents of multiple domains. We evaluate our techniques on the two recently released datasets, namely Fake News AMT and Celebrity for fake news detection. The proposed systems yield encouraging performance, outperforming the current hand-crafted feature engineering based state-of-the-art system with a significant margin of 3.08{\%} and 9.3{\%} by the two models, respectively. In order to exploit the datasets, available for the related tasks, we perform cross-domain analysis (model trained on FakeNews AMT and tested on Celebrity and vice versa) to explore the applicability of our systems across the domains."
Y18-3012,{IITP}-{MT} at {WAT}2018: Transformer-based Multilingual Indic-{E}nglish Neural Machine Translation System,2018,0,1,3,1,5731,sukanta sen,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation: 5th Workshop on Asian Translation: 5th Workshop on Asian Translation",0,None
W18-4408,An Ensemble Approach for Aggression Identification in {E}nglish and {H}indi Text,2018,0,1,4,0,27372,arjun roy,"Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying ({TRAC}-2018)",0,"This paper describes our system submitted in the shared task at COLING 2018 TRAC-1: Aggression Identification. The objective of this task was to predict online aggression spread through online textual post or comment. The dataset was released in two languages, English and Hindi. We submitted a single system for Hindi and a single system for English. Both the systems are based on an ensemble architecture where the individual models are based on Convoluted Neural Network and Support Vector Machine. Evaluation shows promising results for both the languages.The total submission for English was 30 and Hindi was 15. Our system on English facebook and social media obtained F1 score of 0.5151 and 0.5099 respectively where Hindi facebook and social media obtained F1 score of 0.5599 and 0.3790 respectively."
N18-2044,Multi-Task Learning Framework for Mining Crowd Intelligence towards Clinical Treatment,2018,0,6,2,1,8271,shweta yadav,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"In recent past, social media has emerged as an active platform in the context of healthcare and medicine. In this paper, we present a study where medical user{'}s opinions on health-related issues are analyzed to capture the medical sentiment at a blog level. The medical sentiments can be studied in various facets such as medical condition, treatment, and medication that characterize the overall health status of the user. Considering these facets, we treat analysis of this information as a multi-task classification problem. In this paper, we adopt a novel adversarial learning approach for our multi-task learning framework to learn the sentiment{'}s strengths expressed in a medical blog. Our evaluation shows promising results for our target tasks."
N18-1053,Solving Data Sparsity for Aspect Based Sentiment Analysis Using Cross-Linguality and Multi-Linguality,2018,0,4,4,1,7352,md akhtar,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Efficient word representations play an important role in solving various problems related to Natural Language Processing (NLP), data mining, text mining etc. The issue of data sparsity poses a great challenge in creating efficient word representation model for solving the underlying problem. The problem is more intensified in resource-poor scenario due to the absence of sufficient amount of corpus. In this work we propose to minimize the effect of data sparsity by leveraging bilingual word embeddings learned through a parallel corpus. We train and evaluate Long Short Term Memory (LSTM) based architecture for aspect level sentiment classification. The neural network architecture is further assisted by the hand-crafted features for the prediction. We show the efficacy of the proposed model against state-of-the-art methods in two experimental setups i.e. multi-lingual and cross-lingual."
N18-1061,Fine-Grained Temporal Orientation and its Relationship with Psycho-Demographic Correlates,2018,0,0,3,1,29421,sabyasachi kamila,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Temporal orientation refers to an individual{'}s tendency to connect to the psychological concepts of past, present or future, and it affects personality, motivation, emotion, decision making and stress coping processes. The study of the social media users{'} psycho-demographic attributes from the perspective of human temporal orientation can be of utmost interest and importance to the business and administrative decision makers as it can provide an extra precious information for them to make informed decisions. In this paper, we propose a very first study to demonstrate the association between the sentiment view of the temporal orientation of the users and their different psycho-demographic attributes by analyzing their tweets. We first create a temporal orientation classifier in a minimally supervised way which classifies each tweet of the users in one of the three temporal categories, namely past, present, and future. A deep Bi-directional Long Short Term Memory (BLSTM) is used for the tweet classification task. Our tweet classifier achieves an accuracy of 78.27{\%} when tested on a manually created test set. We then determine the users{'} overall temporal orientation based on their tweets on the social media. The sentiment is added to the tweets at the fine-grained level where each temporal tweet is given a sentiment with either of the positive, negative or neutral. Our experiment reveals that depending upon the sentiment view of temporal orientation, a user{'}s attributes vary. We finally measure the correlation between the users{'} sentiment view of temporal orientation and their different psycho-demographic factors using regression."
L18-1049,Sentence Level Temporality Detection using an Implicit Time-sensed Resource,2018,0,1,2,1,29421,sabyasachi kamila,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1278,A Deep Neural Network based Approach for Entity Extraction in Code-Mixed {I}ndian Social Media Text,2018,0,5,2,1,6811,deepak gupta,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1440,{MMQA}: A Multi-domain Multi-lingual Question-Answering Framework for {E}nglish and {H}indi,2018,0,6,3,1,6811,deepak gupta,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1442,Medical Sentiment Analysis using Social Media: Towards building a Patient Assisted System,2018,0,5,2,1,8271,shweta yadav,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1559,{TAP}-{DLND} 1.0 : A Corpus for Document Level Novelty Detection,2018,20,2,4,1,1804,tirthankar ghosal,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Detecting novelty of an entire document is an Artificial Intelligence (AI) frontier problem that has widespread NLP applications, such as extractive document summarization, tracking development of news events, predicting impact of scholarly articles, etc. Important though the problem is, we are unaware of any benchmark document level data that correctly addresses the evaluation of automatic novelty detection techniques in a classification framework. To bridge this gap, we present here a resource for benchmarking the techniques for document level novelty detection. We create the resource via event-specific crawling of news documents across several domains in a periodic manner. We release the annotated corpus with necessary statistics and show its use with a developed system for the problem in concern."
K18-1012,Uncovering Code-Mixed Challenges: A Framework for Linguistically Driven Question Generation and Neural Based Question Answering,2018,0,4,3,1,6811,deepak gupta,Proceedings of the 22nd Conference on Computational Natural Language Learning,0,"Existing research on question answering (QA) and comprehension reading (RC) are mainly focused on the resource-rich language like English. In recent times, the rapid growth of multi-lingual web content has posed several challenges to the existing QA systems. Code-mixing is one such challenge that makes the task more complex. In this paper, we propose a linguistically motivated technique for code-mixed question generation (CMQG) and a neural network based architecture for code-mixed question answering (CMQA). For evaluation, we manually create the code-mixed questions for Hindi-English language pair. In order to show the effectiveness of our neural network based CMQA technique, we utilize two benchmark datasets, SQuAD and MMQA. Experiments show that our proposed model achieves encouraging performance on CMQG and CMQA."
D18-1377,{IARM}: Inter-Aspect Relation Modeling with Memory Networks in Aspect-Based Sentiment Analysis,2018,0,21,6,0,1535,navonil majumder,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Sentiment analysis has immense implications in e-commerce through user feedback mining. Aspect-based sentiment analysis takes this one step further by enabling businesses to extract aspect specific sentimental information. In this paper, we present a novel approach of incorporating the neighboring aspects related information into the sentiment classification of the target aspect using memory networks. We show that our method outperforms the state of the art by 1.6{\%} on average in two distinct domains: restaurant and laptop."
D18-1382,Contextual Inter-modal Attention for Multi-modal Sentiment Analysis,2018,0,7,5,1,1532,deepanway ghosal,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Multi-modal sentiment analysis offers various challenges, one being the effective combination of different input modalities, namely text, visual and acoustic. In this paper, we propose a recurrent neural network based multi-modal attention framework that leverages the contextual information for utterance-level sentiment prediction. The proposed approach applies attention on multi-modal multi-utterance representations and tries to learn the contributing features amongst them. We evaluate our proposed approach on two multi-modal sentiment analysis benchmark datasets, viz. CMU Multi-modal Opinion-level Sentiment Intensity (CMU-MOSI) corpus and the recently released CMU Multi-modal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) corpus. Evaluation results show the effectiveness of our proposed approach with the accuracies of 82.31{\%} and 79.80{\%} for the MOSI and MOSEI datasets, respectively. These are approximately 2 and 1 points performance improvement over the state-of-the-art models for the datasets."
C18-1042,Can Taxonomy Help? Improving Semantic Question Matching using Question Taxonomy,2018,0,3,3,1,6811,deepak gupta,Proceedings of the 27th International Conference on Computational Linguistics,0,"In this paper, we propose a hybrid technique for semantic question matching. It uses a proposed two-layered taxonomy for English questions by augmenting state-of-the-art deep learning models with question classes obtained from a deep learning based question classifier. Experiments performed on three open-domain datasets demonstrate the effectiveness of our proposed approach. We achieve state-of-the-art results on partial ordering question ranking (POQR) benchmark dataset. Our empirical analysis shows that coupling standard distributional features (provided by the question encoder) with knowledge from taxonomy is more effective than either deep learning or taxonomy-based knowledge alone."
C18-1237,Novelty Goes Deep. A Deep Neural Solution To Document Level Novelty Detection,2018,0,1,3,1,1804,tirthankar ghosal,Proceedings of the 27th International Conference on Computational Linguistics,0,The rapid growth of documents across the web has necessitated finding means of discarding redundant documents and retaining novel ones. Capturing redundancy is challenging as it may involve investigating at a deep semantic level. Techniques for detecting such semantic redundancy at the document level are scarce. In this work we propose a deep Convolutional Neural Networks (CNN) based model to classify a document as novel or redundant with respect to a set of relevant documents already seen by the system. The system is simple and do not require any manual feature engineering. Our novel scheme encodes relevant and relative information from both source and target texts to generate an intermediate representation which we coin as the Relative Document Vector (RDV). The proposed method outperforms the existing state-of-the-art on a document-level novelty detection dataset by a margin of â¼5{\%} in terms of accuracy. We further demonstrate the effectiveness of our approach on a standard paraphrase detection dataset where paraphrased passages closely resemble to semantically redundant documents.
W17-7517,Document Level Novelty Detection: Textual Entailment Lends a Helping Hand,2017,0,1,3,1,17998,tanik saikh,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-7529,Supervised Methods For Ranking Relations In Web Search,2017,0,0,2,0,31204,sumit asthana,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-5229,{IITP} at {E}mo{I}nt-2017: Measuring Intensity of Emotions using Sentence Embeddings and Optimized Features,2017,0,3,3,1,7352,md akhtar,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"This paper describes the system that we submitted as part of our participation in the shared task on Emotion Intensity (EmoInt-2017). We propose a Long short term memory (LSTM) based architecture cascaded with Support Vector Regressor (SVR) for intensity prediction. We also employ Particle Swarm Optimization (PSO) based feature selection algorithm for obtaining an optimized feature set for training and evaluation. System evaluation shows interesting results on the four emotion datasets i.e. anger, fear, joy and sadness. In comparison to the other participating teams our system was ranked 5th in the competition."
S17-2009,{IIT}-{UHH} at {S}em{E}val-2017 Task 3: Exploring Multiple Features for Community Question Answering and Implicit Dialogue Identification,2017,0,6,6,0,32227,titas nandi,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"In this paper we present the system for Answer Selection and Ranking in Community Question Answering, which we build as part of our participation in SemEval-2017 Task 3. We develop a Support Vector Machine (SVM) based system that makes use of textual, domain-specific, word-embedding and topic-modeling features. In addition, we propose a novel method for dialogue chain identification in comment threads. Our primary submission won subtask C, outperforming other systems in all the primary evaluation metrics. We performed well in other English subtasks, ranking third in subtask A and eighth in subtask B. We also developed open source toolkits for all the three English subtasks by the name cQARank [\url{https://github.com/TitasNandi/cQARank}]."
S17-2087,{IITP} at {S}em{E}val-2017 Task 8 : A Supervised Approach for Rumour Evaluation,2017,8,10,4,0,32316,vikram singh,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes our system participation in the SemEval-2017 Task 8 {`}RumourEval: Determining rumour veracity and support for rumours{'}. The objective of this task was to predict the stance and veracity of the underlying rumour. We propose a supervised classification approach employing several lexical, content and twitter specific features for learning. Evaluation shows promising results for both the problems."
S17-2153,{IITPB} at {S}em{E}val-2017 Task 5: Sentiment Prediction in Financial Text,2017,0,5,4,1,24889,abhishek kumar,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper reports team IITPB{'}s participation in the SemEval 2017 Task 5 on {`}Fine-grained sentiment analysis on financial microblogs and news{'}. We developed 2 systems for the two tracks. One system was based on an ensemble of Support Vector Classifier and Logistic Regression. This system relied on Distributional Thesaurus (DT), word embeddings and lexicon features to predict a floating sentiment value between -1 and +1. The other system was based on Support Vector Regression using word embeddings, lexicon features, and PMI scores as features. The system was ranked 5th in track 1 and 8th in track 2."
S17-2154,{IITP} at {S}em{E}val-2017 Task 5: An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis,2017,0,6,4,1,1532,deepanway ghosal,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,In this paper we propose an ensemble based model which combines state of the art deep learning sentiment analysis algorithms like Convolution Neural Network (CNN) and Long Short Term Memory (LSTM) along with feature based models to identify optimistic or pessimistic sentiments associated with companies and stocks in financial texts. We build our system to participate in a competition organized by Semantic Evaluation 2017 International Workshop. We combined predictions from various models using an artificial neural network to determine the opinion towards an entity in (a) Microblog Messages and (b) News Headlines data. Our models achieved a cosine similarity score of 0.751 and 0.697 for the above two tracks giving us the rank of 2nd and 7th best team respectively.
P17-2104,Temporal Orientation of Tweets for Predicting Income of Users,2017,7,4,5,0.714286,15356,mohammed hasanuzzaman,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Automatically estimating a user{'}s socio-economic profile from their language use in social media can significantly help social science research and various downstream applications ranging from business to politics. The current paper presents the first study where user cognitive structure is used to build a predictive model of income. In particular, we first develop a classifier using a weakly supervised learning framework to automatically time-tag tweets as past, present, or future. We quantify a user{'}s overall temporal orientation based on their distribution of tweets, and use it to build a predictive model of income. Our analysis uncovers a correlation between future temporal orientation and income. Finally, we measure the predictive power of future temporal orientation on income by performing regression."
I17-4031,{IITP} at {IJCNLP}-2017 Task 4: Auto Analysis of Customer Feedback using {CNN} and {GRU} Network,2017,0,0,4,1,6811,deepak gupta,"Proceedings of the {IJCNLP} 2017, Shared Tasks",0,"Analyzing customer feedback is the best way to channelize the data into new marketing strategies that benefit entrepreneurs as well as customers. Therefore an automated system which can analyze the customer behavior is in great demand. Users may write feedbacks in any language, and hence mining appropriate information often becomes intractable. Especially in a traditional feature-based supervised model, it is difficult to build a generic system as one has to understand the concerned language for finding the relevant features. In order to overcome this, we propose deep Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) based approaches that do not require handcrafting of features. We evaluate these techniques for analyzing customer feedback sentences on four languages, namely English, French, Japanese and Spanish. Our empirical analysis shows that our models perform well in all the four languages on the setups of IJCNLP Shared Task on Customer Feedback Analysis. Our model achieved the second rank in French, with an accuracy of 71.75{\%} and third ranks for all the other languages."
E17-1109,Entity Extraction in Biomedical Corpora: An Approach to Evaluate Word Embedding Features with {PSO} based Feature Selection,2017,30,7,2,1,8271,shweta yadav,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"Text mining has drawn significant attention in recent past due to the rapid growth in biomedical and clinical records. Entity extraction is one of the fundamental components for biomedical text mining. In this paper, we propose a novel approach of feature selection for entity extraction that exploits the concept of deep learning and Particle Swarm Optimization (PSO). The system utilizes word embedding features along with several other features extracted by studying the properties of the datasets. We obtain an interesting observation that compact word embedding features as determined by PSO are more effective compared to the entire word embedding feature set for entity extraction. The proposed system is evaluated on three benchmark biomedical datasets such as GENIA, GENETAG, and AiMed. The effectiveness of the proposed approach is evident with significant performance gains over the baseline models as well as the other existing systems. We observe improvements of 7.86{\%}, 5.27{\%} and 7.25{\%} F-measure points over the baseline models for GENIA, GENETAG, and AiMed dataset respectively."
D17-1057,A Multilayer Perceptron based Ensemble Technique for Fine-grained Financial Sentiment Analysis,2017,21,11,4,1,7352,md akhtar,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we propose a novel method for combining deep learning and classical feature based models using a Multi-Layer Perceptron (MLP) network for financial sentiment analysis. We develop various deep learning models based on Convolutional Neural Network (CNN), Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU). These are trained on top of pre-trained, autoencoder-based, financial word embeddings and lexicon features. An ensemble is constructed by combining these deep learning models and a classical supervised model based on Support Vector Regression (SVR). We evaluate our proposed technique on a benchmark dataset of SemEval-2017 shared task on financial sentiment analysis. The propose model shows impressive results on two datasets, i.e. microblogs and news headlines datasets. Comparisons show that our proposed model performs better than the existing state-of-the-art systems for the above two datasets by 2.0 and 4.1 cosine points, respectively."
W16-6303,Can {SMT} and {RBMT} Improve each other{'}s Performance?- An Experiment with {E}nglish-{H}indi Translation,2016,0,3,3,0,33360,debajyoty banik,Proceedings of the 13th International Conference on Natural Language Processing,0,None
W16-6308,Biomolecular Event Extraction using a Stacked Generalization based Classifier,2016,0,2,2,0,33366,amit majumder,Proceedings of the 13th International Conference on Natural Language Processing,0,None
W16-6311,Improving Document Ranking using Query Expansion and Classification Techniques for Mixed Script Information Retrieval,2016,0,0,4,0,15327,subham kumar,Proceedings of the 13th International Conference on Natural Language Processing,0,None
W16-6325,A Recurrent Neural Network Architecture for De-identifying Clinical Records,2016,0,7,3,0,33377,shweta,Proceedings of the 13th International Conference on Natural Language Processing,0,None
W16-6331,Opinion Mining in a Code-Mixed Environment: A Case Study with Government Portals,2016,26,2,3,1,6811,deepak gupta,Proceedings of the 13th International Conference on Natural Language Processing,0,None
W16-4622,{IITP} {E}nglish-{H}indi Machine Translation System at {WAT} 2016,2016,0,3,3,1,5731,sukanta sen,Proceedings of the 3rd Workshop on {A}sian Translation ({WAT}2016),0,"In this paper we describe the system that we develop as part of our participation in WAT 2016. We develop a system based on hierarchical phrase-based SMT for English to Hindi language pair. We perform re-ordering and augment bilingual dictionary to improve the performance. As a baseline we use a phrase-based SMT model. The MT models are fine-tuned on the development set, and the best configurations are used to report the evaluation on the test set. Experiments show the BLEU of 13.71 on the benchmark test data. This is better compared to the official baseline BLEU score of 10.79."
W16-4205,Semi-supervised Clustering of Medical Text,2016,10,0,2,0,33603,pracheta sahoo,Proceedings of the Clinical Natural Language Processing Workshop ({C}linical{NLP}),0,"Semi-supervised clustering is an attractive alternative for traditional (unsupervised) clustering in targeted applications. By using the information of a small annotated dataset, semi-supervised clustering can produce clusters that are customized to the application domain. In this paper, we present a semi-supervised clustering technique based on a multi-objective evolutionary algorithm (NSGA-II-clus). We apply this technique to the task of clustering medical publications for Evidence Based Medicine (EBM) and observe an improvement of the results against unsupervised and other semi-supervised clustering techniques."
W16-4206,Deep Learning Architecture for Patient Data De-identification in Clinical Records,2016,0,14,2,1,8271,shweta yadav,Proceedings of the Clinical Natural Language Processing Workshop ({C}linical{NLP}),0,"Rapid growth in Electronic Medical Records (EMR) has emerged to an expansion of data in the clinical domain. The majority of the available health care information is sealed in the form of narrative documents which form the rich source of clinical information. Text mining of such clinical records has gained huge attention in various medical applications like treatment and decision making. However, medical records enclose patient Private Health Information (PHI) which can reveal the identities of the patients. In order to retain the privacy of patients, it is mandatory to remove all the PHI information prior to making it publicly available. The aim is to de-identify or encrypt the PHI from the patient medical records. In this paper, we propose an algorithm based on deep learning architecture to solve this problem. We perform de-identification of seven PHI terms from the clinical records. Experiments on benchmark datasets show that our proposed approach achieves encouraging performance, which is better than the baseline model developed with Conditional Random Field."
S16-1174,{IIT}-{TUDA} at {S}em{E}val-2016 Task 5: Beyond Sentiment Lexicon: Combining Domain Dependency and Distributional Semantics Features for Aspect Based Sentiment Analysis,2016,15,24,4,1,12110,ayush kumar,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
L16-1429,Aspect based Sentiment Analysis in {H}indi: Resource Creation and Evaluation,2016,19,15,2,1,7352,md akhtar,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Due to the phenomenal growth of online product reviews, sentiment analysis (SA) has gained huge attention, for example, by online service providers. A number of benchmark datasets for a wide range of domains have been made available for sentiment analysis, especially in resource-rich languages. In this paper we assess the challenges of SA in Hindi by providing a benchmark setup, where we create an annotated dataset of high quality, build machine learning models for sentiment analysis in order to show the effective usage of the dataset, and finally make the resource available to the community for further advancement of research. The dataset comprises of Hindi product reviews crawled from various online sources. Each sentence of the review is annotated with aspect term and its associated sentiment. As classification algorithms we use Conditional Random Filed (CRF) and Support Vector Machine (SVM) for aspect term extraction and sentiment analysis, respectively. Evaluation results show the average F-measure of 41.07{\%} for aspect term extraction and accuracy of 54.05{\%} for sentiment classification."
L16-1595,Building Tempo-{H}indi{W}ord{N}et: A resource for effective temporal information access in {H}indi,2016,0,1,3,0,35311,dipawesh pawar,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we put forward a strategy that supplements Hindi WordNet entries with information on the temporality of its word senses. Each synset of Hindi WordNet is automatically annotated to one of the five dimensions: past, present, future, neutral and atemporal. We use semi-supervised learning strategy to build temporal classifiers over the glosses of manually selected initial seed synsets. The classification process is iterated based on the repetitive confidence based expansion strategy of the initial seed list until cross-validation accuracy drops. The resource is unique in its nature as, to the best of our knowledge, still no such resource is available for Hindi."
C16-1047,A Hybrid Deep Learning Architecture for Sentiment Analysis,2016,0,20,3,1,7352,md akhtar,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"In this paper, we propose a novel hybrid deep learning archtecture which is highly efficient for sentiment analysis in resource-poor languages. We learn sentiment embedded vectors from the Convolutional Neural Network (CNN). These are augmented to a set of optimized features selected through a multi-objective optimization (MOO) framework. The sentiment augmented optimized vector obtained at the end is used for the training of SVM for sentiment classification. We evaluate our proposed approach for coarse-grained (i.e. sentence level) as well as fine-grained (i.e. aspect level) sentiment analysis on four Hindi datasets covering varying domains. In order to show that our proposed method is generic in nature we also evaluate it on two benchmark English datasets. Evaluation shows that the results of the proposed method are consistent across all the datasets and often outperforms the state-of-art systems. To the best of our knowledge, this is the very first attempt where such a deep learning model is used for less-resourced languages such as Hindi."
W15-5942,Simultaneous Feature Selection and Parameter Optimization Using Multi-objective Optimization for Sentiment Analysis,2015,28,0,2,0,36404,mohammed khan,Proceedings of the 12th International Conference on Natural Language Processing,0,"In this paper, we propose a method of feature selection and parameter optimization for sentiment analysis in Twitter messages. Appropriate features and parameter combinations have significant effect to the performance of any classifier. As base learning algorithms we make use of Random Forest and Support Vector Machines. We perform sentiment analysis at the message level, and use the platform of SemEval-2014 shared task. We achieve substantial performance improvement with our proposed model over the systems that are developed with random feature subsets and default parameter combinations."
W15-4308,{IITP}: Multiobjective Differential Evolution based {T}witter Named Entity Recognition,2015,11,5,3,1,7352,md akhtar,Proceedings of the Workshop on Noisy User-generated Text,0,"In this paper we propose a differential evolution (DE) based named entity recognition (NER) system in twitter data. In the first step, we develop various NER systems using different combinations of the features. We implemented these features without using any domain-specific features and/or resources. As a base classifier we use Conditional Random Field (CRF). In the second step, we propose a DE based feature selection approach to determine the most relevant set of features and its context information. The optimized feature set applied to the training set yields the precision, recall and Fmeasure values of 60.68%, 29.65% and 39.84%, respectively for the fine-grained named entity (NE) types. When we consider only the coarse-grained NE types, it shows the precision, recall and F-measure values of 63.43%, 51.44% and 56.81%, respectively."
W15-4316,{IITP}: Hybrid Approach for Text Normalization in {T}witter,2015,8,8,3,1,7352,md akhtar,Proceedings of the Workshop on Noisy User-generated Text,0,"In this paper we report our work for normalization of noisy text in Twitter data. The method we propose is hybrid in nature that combines machine learning with rules. In the first step, supervised approach based on conditional random field is developed, and in the second step a set of heuristics rules is applied to the candidate wordforms for the normalization. The classifier is trained with a set of features which were are derived without the use of any domain-specific feature and/or resource. The overall system yields the precision, recall and F-measure values of 90.26%, 71.91% and 80.05% respectively for the test dataset."
S15-2100,{IITPS}em{E}val: Sentiment Discovery from 140 Characters,2015,19,0,3,1,12110,ayush kumar,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper presents an overview of the system developed and submitted as a part of our participation to the SemEval-2015 Task 10 that deals with Sentiment Analysis in Twitter. We build a Support Vector Machine (SVM) based supervised learning model for Subtask A (term level task) and Subtask B (message level task). We also participate in Subtask E viz., determining degree of polarity, and build a very simple system by employing the available lexical resources. Experiments with the 2015 official datasets show F1 scores of 81.31% and 58.80% for Task A and Task B, respectively. For Subtask E, our model achieves a score of 0.413 on Kendalxe2x80x99s Tau metric."
W14-5117,Multiobjective Optimization and Unsupervised Lexical Acquisition for Named Entity Recognition and Classification,2014,0,2,2,0,38305,govind,Proceedings of the 11th International Conference on Natural Language Processing,0,None
W14-5130,Determing Trustworthiness in {E}-Commerce Customer Reviews,2014,13,0,2,0,13666,dhruv gupta,Proceedings of the 11th International Conference on Natural Language Processing,0,None
S14-2052,{IITP}: A Supervised Approach for Disorder Mention Detection and Disambiguation,2014,4,0,2,1,28345,utpal sikdar,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In this paper we briefly describe our supervised machine learning approach for disorder mention detection system that we submitted as part of our participation in the SemEval-2014 Shared task. The main goal of this task is to build a system that automatically identifies mentions of clinical conditions from the clinical texts. The main challenge lies due in the fact that the same mention of concept may be represented in many surface forms. We develop the system based on the supervised machine learning algorithms, namely Conditional Random Field and Support Vector Machine. One appealing characteristics of our system is that most of the features for learning are extracted automatically from the given training or test datasets without using deep domain specific resources and/or tools. We submitted three runs, and best performing system is based on Conditional Random Field. For task A, it shows the precision, recall and F-measure values of 50.00%, 47.90% and 48.90%, respectively under the strict matching criterion. When the matching criterion is relaxed, it shows the precision, recall and F-measure of 81.50%, 79.70% and 80.60%, respectively. For task B, we obtain the accuracies of 33.30% and 69.60% for the relaxed and strict matches, respectively."
S14-2053,{IITP}: Supervised Machine Learning for Aspect based Sentiment Analysis,2014,8,6,2,1,6811,deepak gupta,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"The shared task on Aspect based Sentiment Analysis primarily focuses on mining relevant information from the thousands of online reviews available for a popular product or service. In this paper we report our works on aspect term extraction and sentiment classification with respect to our participation in the SemEval-2014 shared task. The aspect term extraction method is based on supervised learning algorithm, where we use different classifiers, and finally combine their outputs using a majority voting technique. For sentiment classification we use Random Forest classifier. Our system for aspect term extraction shows the F-scores of 72.13% and 62.84% for the restaurants and laptops reviews, respectively. Due to some technical problems our submission on sentiment classification was not evaluated. However we evaluate the submitted system with the same evaluation metrics, and it shows the accuracies of 67.37% and 67.07% for the restaurants and laptops reviews, respectively."
S14-2054,{IITP}atna: Supervised Approach for Sentiment Analysis in {T}witter,2014,13,0,2,0,38970,raja selvarajan,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In this paper we report our works for SemEval-2014 Sentiment Analysis in Twitter evaluation challenge. This is the first time we attempt for this task, and our submissions are based on supervised machine learning algorithm. We use Support Vector Machine for both the tasks, viz. contextual polarity disambiguation and message polarity classification. We identify and implement a small set of features for each the tasks, and did not make use of any external resources and/or tools. The systems are tuned on the development sets and finally blind evaluation is performed on the respective test set, which consists of the datasets of five different domains. Our submission for the first task shows the F-score values of 76.3%, 77.04%, 70.91%, 72.25% and 66.32% for LiveJournal2014, SMS2013, Twitter2013, Twitter2014 and Twitter2014Sarcasm datasets, respectively. The system developed for the second task yields the F-score values of 54.68%, 40.56%, 50.32%, 48.22% and 36.73%, respectively for the five different test datasets."
S14-2057,{I}ndian Institute of Technology-Patna: Sentiment Analysis in {T}witter,2014,16,0,3,0,32316,vikram singh,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper is an overview of the system submitted to the SemEval-2014 shared task on sentiment analysis in twitter. For the very first time we participated in both the tasks, viz contextual polarity disambiguation and message polarity classification. Our approach is supervised in nature and we use sequential minimal optimization classifier. We implement the features for sentiment analysis without using deep domain-specific resources and/or tools. Experiments within the benchmark setup of SemEval-14 shows the F-scores of 77.99%, 75.99%, 76.54 %, 76.43% and 71.43% for LiveJournal2014, SMS2013, Twitter2013, Twitter2014 and Twitter2014Sarcasm, respectively for Subtask A. For Subtask B we obtain the F-scores of 60.39%, 51.96%, 52.58%, 57.25%, 41.33% for five different test sets, respectively."
W13-4305,Event and Event Actor Alignment in Phrase Based Statistical Machine Translation,2013,25,0,3,1,40689,anup kolya,Proceedings of the 11th Workshop on {A}sian Language Resources,0,"This paper proposes the impacts of event and event actor alignment in English and Bengali phrase based Statistical Machine Translation (PB-SMT) System. Initially, events and event actors are identified from English and Bengali parallel corpus. For events and event actor identification in English we proposed a hybrid technique and it was carried out within the TimeML framework. Events in Bengali are identified based on the concept of complex predicate structures. There can be one-to-one and one-to-many mappings between English and Bengali events and event actors. We preprocess the parallel corpus by single tokenizing the multiword events and event-actors which reflects some significant gain on the PB-SMT system. We represent a hybrid alignment approach of events and event-actors in both English-Bengali training corpus by defining a rule based aligner and a statistical hybrid aligner. The rule base aligner assumes a heuristic that the sequence of events and event actors on the source (English) side are also maintained in the target (Bengali) side. The performance of PB-SMT system could vary depending on the number of events and event-actors that are identified in the parallel training data. The proposed system achieves significant improvements (5.79 BLEU points absolute, 53.02% relative improvement) over the baseline system on an English-Bengali translation task."
U13-1008,Multi-Objective Optimization for Clustering of Medical Publications,2013,25,3,1,1,363,asif ekbal,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"Clustering the results of a search can help a multi-document summarizer present a summary for evidence based medicine (EBM). In this work, we introduce a clustering technique that is based on multiobjective (MOO) optimization. MOO is a technique that shows promise in the areas of machine learning and natural language processing. In our approach we show how MOO based semi-supervised clustering technique can be effectively used for EBM."
S13-2011,"{JU}{\\_}{CSE}: A {CRF} Based Approach to Annotation of Temporal Expression, Event and Temporal Relations",2013,8,6,4,1,40689,anup kolya,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"In this paper, we present the JUCSE system, designed for the TempEval-3 shared task. The system extracts events and temporal information from natural text in English. We have participated in all the tasks of TempEval-3, namely Task A, Task B & Task C. We have primarily utilized the Conditional Random Field (CRF) based machine learning technique, for all the above tasks. Our system seems to perform quite competitively in Task A and Task B. In Task C, the systemxe2x80x99s performance is comparatively modest at the initial stages of system development. We have incorporated various features based on different lexical, syntactic and semantic information, using Stanford CoreNLP and Wordnet based tools."
I13-1099,Adapting a State-of-the-art Anaphora Resolution System for Resource-poor Language,2013,16,7,2,1,28345,utpal sikdar,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"In this paper we present our work on adapting a state-of-the-art anaphora resolution system for a resource poor language, namely Bengali. Performance of any anaphoric resolver greatly depends on the quality of a high accurate mention detector. We develop a number of models for mention detection based on heuristics and machine learning. Our experiments show that, a language-dependent system can attain reasonably good performance when re-trained on a new language with a proper subset of features. The system yields the MUC recall, precision and F-measure values of 57.80%, 79.00% and 66.70%, respectively. Our experiments with other available scorers show the F-measure values of 59.47%, 49.83%, 31.81% and 70.82% for BCUB, CEAFM, CEAFE and BLANC, respectively."
C12-1151,Differential Evolution Based Feature Selection and Classifier Ensemble for Named Entity Recognition,2012,24,14,2,1,28345,utpal sikdar,Proceedings of {COLING} 2012,0,"In this paper, we propose a differential evolution (DE) based two-stage evolutionary approach for named entity recognition (NER). The first stage concerns with the problem of relevant feature selection for NER within the frameworks of two popular machine learning algorithms, namely Conditional Random Field (CRF) and Support Vector Machine (SVM). The solutions of the final best population provides different diverse set of classifiers; some are effective with respect to recall whereas some are effective with respect to precision. In the second stage we propose a novel technique for classifier ensemble for combining these classifiers. The approach is very general and can be applied for any classification problem. Currently we evaluate the proposed algorithm for NER in three popular Indian languages, namely Bengali, Hindi and Telugu. In order to maintain the domain-independence property the features are selected and developed mostly without using any deep domain knowledge and/or language dependent resources. Experimental results show that the proposed two stage technique attains the final F-measure values of 88.89%, 88.09% and 76.63% for Bengali, Hindi and Telugu, respectively. The key contributions of this work are two-fold, viz. (i). proposal of differential evolution (DE) based feature selection and classifier ensemble methods that can be applied to any classification problem; and (ii). scope of the development of language independent NER systems in a resource-poor"
W11-1908,Multi-metric optimization for coreference: The {U}ni{TN} / {IITP} / {E}ssex submission to the 2011 {CONLL} Shared Task,2011,17,10,3,0,28598,olga uryupina,Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,0,"Because there is no generally accepted metric for measuring the performance of anaphora resolution systems, a combination of metrics was proposed to evaluate submissions to the 2011 CONLL Shared Task (Pradhan et al., 2011). We investigate therefore Multi-objective function Optimization (moo) techniques based on Genetic Algorithms to optimize models according to multiple metrics simultaneously."
W11-0904,Identifying Event-Sentiment Association using Lexical Equivalence and Co-reference Approaches,2011,24,9,3,1,40689,anup kolya,Proceedings of the {ACL} 2011 Workshop on Relational Models of Semantics,0,"In this paper, we have identified event and sentiment expressions at word level from the sentences of TempEval-2010 corpus and evaluated their association in terms of lexical equivalence and co-reference. A hybrid approach that consists of Conditional Random Field (CRF) based machine learning framework in conjunction with several rule based strategies has been adopted for event identification within the TimeML framework. The strategies are based on semantic role labeling, WordNet relations and some handcrafted rules. The sentiment expressions are identified simply based on the cues that are available in the sentiment lexicons such as Subjectivity Wordlist, SentiWordNet and WordNet Affect. The identification of lexical equivalence between event and sentiment expressions based on the part-of-speech (POS) categories is straightforward. The emotional verbs from VerbNet have also been employed to improve the coverage of lexical equivalence. On the other hand, the association of sentiment and event has been analyzed using the notion of co-reference. The parsed dependency relations along with basic rhetoric knowledge help to identify the co-reference between event and sentiment expressions. Manual evaluation on the 171 sentences of TempEval-2010 dataset yields the precision, recall and F-Score values of 61.25%, 70.29% and 65.23% respectively."
R11-1084,A Hybrid Approach for Event Extraction and Event Actor Identification,2011,14,6,2,1,40689,anup kolya,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"This paper, we propose an approach for event extraction and corresponding event actor identificationwithin the TimeML framework. Firstly, for event extraction , we develop SVM based hybrid approach and for event actor identification the baseline model is developed based on the subject information of the dependency-parsed event sentences. Then we develop an unsupervised syntax based model that is based on the relationship of the event verbs with their argu ment structure extracted from the head information of the chunks in the parsed sentences. Evaluation on a col lection of TempEval-2 corpus shows the precision, recall and F-measure values for the baseline model as 64.31%, 67.74% and 65.98%, respectively and the syntax based model as 69.12%, 66.90% and 67.99%, respectively."
I11-1011,Single and multi-objective optimization for feature selection in anaphora resolution,2011,22,9,2,1,4603,sriparna saha,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"There is no generally accepted metric for measuring the performance of anaphora resolution systems, and the existing metricsxe2x80x94MUC, B3, CEAF, Blanc, among othersxe2x80x94tend to reward significantly different behaviors. Systems optimized according to one metric tend to perform poorly with respect to other ones, making it very difficult to compare anaphora resolution systems, as clearly shown by the results of the SEMEVAL 2010 Multilingual Coreference task. One solution would be to find a single completely satisfactory metric, but itxe2x80x99s not clear whether this is possible and at any rate it is not going to happen any time soon. An alternative is to optimize models according to multiple metrics simultaneously. In this paper, we show, first of all, that this is possible to develop such models using Multi-objective Optimization (MOO) techniques based on Genetic Algorithms. Secondly, we show that optimizing according to multiple metrics simultaneously may result in better results with respect to each individual metric than optimizing according to that metric only."
Y10-1015,Finding Appropriate Subset of Votes Per Classifier Using Multiobjective Optimization: Application to Named Entity Recognition,2010,11,0,1,1,363,asif ekbal,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,"In this paper, we report a multiobjective optimization (MOO) based technique to select the appropriate subset of votes per classifier in an ensemble system. We hypothesize that the reliability of prediction of each classifier differs among the various output classes. Thus, it is necessary to find out the subset of classes for which any particular classifier is most suitable. Rather than optimizing a single measure of classification quality, we simultaneously optimize two different measures of classification quality using the search capability of MOO. We use our proposed technique to solve the problem of Named Entity Recognition (NER). Maximum Entropy (ME) model is used as a base to build a number of classifiers depending upon the various representations of the contextual, orthographic word-level and semantically motivated features. Evaluation results with a resource constrained language like Bengali yield the recall, precision and F-measure values of 87.98%, 93.00%, and 90.42%, respectively. Experimental results suggest that the use of semantic feature can significantly improve the overall system performance. Results also reveal that the classifier ensemble identified by the proposed MOO based approach performs better in comparison to the individual classifiers, two different baseline ensembles and the classifier ensemble identified by a single objective genetic algorithm (GA) based approach."
Y10-1019,Feature Subset Selection Using Genetic Algorithm for Named Entity Recognition,2010,15,7,3,0,25303,md hasanuzzaman,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,"In this paper, genetic algorithm (GA) is utilized to search for the appropriate feature combination for constructing a maximum entropy (ME) based classifier for named entity recognition (NER). Features are encoded in the chromosomes. The ME classifier is evaluated for the 3-fold cross validation with the features, encoded in a particular chromosome, and its average F-measure value is used as the fitness value of the corresponding chromosome. The proposed technique is evaluated for determining the suitable feature combinations for NER in three resource-constrained languages, namely Bengali, Hindi and Telugu. Evaluation results show the effectiveness of the proposed approach with the overall recall, precision and F-measure values of 71.27%, 83.95% and 77.09%, respectively for Bengali, 74.72%, 87.15% and 80.46%, respectively for Hindi and 60.91%, 94.15% and 73.97%, respectively for Telugu."
Y10-1051,A Supervised Machine Learning Approach for Event-Event Relation Identification,2010,0,1,2,1,40689,anup kolya,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,None
W10-2411,{E}nglish to {I}ndian Languages Machine Transliteration System at {NEWS} 2010,2010,12,8,4,0.444444,14329,amitava das,Proceedings of the 2010 Named Entities Workshop,0,"This paper reports about our work in the NEWS 2010 Shared Task on Transliteration Generation held as part of ACL 2010. One standard run and two non-standard runs were submitted for English to Hindi and Bengali transliteration while one standard and one non-standard run were submitted for Kannada and Tamil. The transliteration systems are based on Orthographic rules and Phoneme based technology. The system has been trained on the NEWS 2010 Shared Task on Transliteration Generation datasets. For the standard run, the system demonstrated mean F-Score values of 0.818 for Bengali, 0.714 for Hindi, 0.663 for Kannada and 0.563 for Tamil. The reported mean F-Score values of non-standard runs are 0.845 and 0.875 for Bengali non-standard run-1 and 2, 0.752 and 0.739 for Hindi non-standard run-1 and 2, 0.662 for Kannada non-standard run-1 and 0.760 for Tamil non-standard run-1. Non-Standard Run-2 for Bengali has achieved the highest score among all the submitted runs. Hindi Non-Standard Run-1 and Run-2 runs are ranked as the 5th and 6th among all submitted Runs."
W10-2415,Assessing the Challenge of Fine-Grained Named Entity Recognition and Classification,2010,31,26,1,1,363,asif ekbal,Proceedings of the 2010 Named Entities Workshop,0,Named Entity Recognition and Classification (NERC) is a well-studied NLP task typically focused on coarse-grained named entity (NE) classes. NERC for more fine-grained semantic NE classes has not been systematically studied. This paper quantifies the difficulty of fine-grained NERC (FG-NERC) when performed at large scale on the people domain. We apply unsupervised acquisition methods to construct a gold standard dataset for FG-NERC. This dataset is used to benchmark methods for classifying NEs at various levels of fine-grainedness using classical NERC techniques and global contextual information inspired from Word Sense Disambiguation approaches. Our results indicate high difficulty of the task and provide a 'strong' baseline for future research.
S10-1077,"{JU}{\\_}{CSE}{\\_}{TEMP}: A First Step towards Evaluating Events, Time Expressions and Temporal Relations",2010,7,20,2,1,40689,anup kolya,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"Temporal information extraction is a popular and interesting research field in the area of Natural Language Processing (NLP). In this paper, we report our works on TempEval-2 shared task. This is our first participation and we participated in all the tasks, i. e., A, B, C, D, E and F. We develop rule-based systems for Tasks A and B, whereas the remaining tasks are based on a machine learning approach, namely Conditional Random Field (CRF). All our systems are still in their development stages, and we report the very initial results. Evaluation results on the shared task English datasets yield the precision, recall and F-measure values of 55%, 17% and 26%, respectively for Task A and 48%, 56% and 52%, respectively for Task B (event recognition). The rest of tasks, namely C, D, E and F were evaluated with a relatively simpler metric: the number of correct answers divided by the number of answers. Experiments on the English datasets yield the accuracies of 63%, 80%, 56% and 56% for tasks C, D, E and F, respectively."
ekbal-saha-2010-maximum,Maximum Entropy Classifier Ensembling using Genetic Algorithm for {NER} in {B}engali,2010,22,5,1,1,363,asif ekbal,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we propose classifier ensemble selection for Named Entity Recognition (NER) as a single objective optimization problem. Thereafter, we develop a method based on genetic algorithm (GA) to solve this problem. Our underlying assumption is that rather than searching for the best feature set for a particular classifier, ensembling of several classifiers which are trained using different feature representations could be a more fruitful approach. Maximum Entropy (ME) framework is used to generate a number of classifiers by considering the various combinations of the available features. In the proposed approach, classifiers are encoded in the chromosomes. A single measure of classification quality, namely F-measure is used as the objective function. Evaluation results on a resource constrained language like Bengali yield the recall, precision and F-measure values of 71.14{\%}, 84.07{\%} and 77.11{\%}, respectively. Experiments also show that the classifier ensemble identified by the proposed GA based approach attains higher performance than all the individual classifiers and two different conventional baseline ensembles."
Y09-2045,Named Entity Recognition for {M}anipuri Using Support Vector Machine,2009,10,18,3,0,13982,thoudam singh,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 2",0,"This paper reports about the development of a Manipuri NER system, a less computerized Indian language. Two different models, one using an active learning technique based on the context patterns generated from an unlabeled news corpus and the other based on the well known Support Vector Machine (SVM), have been developed. The active learning technique has been considered as the baseline system. The Manipuri news corpus has been manually annotated with the major NE tags, namely Person name , Location name , Organization name and Miscellaneous name to apply SVM. The SVM based system makes use of the different contextual information of the words along with the variety of orthographic word-level features which are helpful in predicting the NE classes. In addition, lexical context patterns generated using the active learning technique have been used as the features of SVM in order to improve performance. The system has been trained and tested with 28,629 and 4,763 wordforms, respectively. Experimental results show the effectiveness of the proposed approach with the overall average Recall , Precision and F-Score values of 93.91%, 95.32% and 94.59% respectively."
Y09-1014,Voted Approach for Part of Speech Tagging in {B}engali,2009,14,15,1,1,363,asif ekbal,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 1",0,"Part of Speech (POS) tagging is the task of labeling each word in a sentence with its appropriate syntactic category called part of speech. POS tagging is a very important preprocessing task for language processing activities. In this paper, we report about our work on POS tagging for Bengali by combining different POS tagging systems using three weighted voting techniques. The individual POS taggers are based on Maximum Entropy (ME), Conditional Random Field (CRF) and Support Vector Machine (SVM) frameworks. The POS taggers use a tag set of 27 POS tags, defined for the Indian languages. The individual system makes use of the different contextual information of the words along with the variety of word3level features that are helpful in predicting the various POS classes. The POS tagger has been trained and tested with 57,341 and 35K tokens, respectively. It has been experimentally verified that the lexicon, named entity recognizer and different word suffixes are effective in handling the unknown word problems and improve the accuracy of the POS tagger significantly. Experimental results show the effectiveness of the proposed voted POS tagger with an accuracy of 92.35%, which is an improvement of 5.29% over the least performing ME based system and 2.23% over the best performing SVM based system."
W09-3517,{E}nglish to {H}indi Machine Transliteration System at {NEWS} 2009,2009,13,11,2,0.444444,14329,amitava das,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"This paper reports about our work in the NEWS 2009 Machine Transliteration Shared Task held as part of ACL-IJCNLP 2009. We submitted one standard run and two non-standard runs for English to Hindi transliteration. The modified joint source-channel model has been used along with a number of alternatives. The system has been trained on the NEWS 2009 Machine Transliteration Shared Task datasets. For standard run, the system demonstrated an accuracy of 0.471 and the mean F-Score of 0.861. The non-standard runs yielded the accuracy and mean F-scores of 0.389 and 0.831 respectively in the first one and 0.384 and 0.828 respectively in the second one. The non-standard runs resulted in substantially worse performance than the standard run. The reasons for this are the ranking algorithm used for the output and the types of tokens present in the test set."
W09-3539,Voted {NER} System using Appropriate Unlabeled Data,2009,15,26,1,1,363,asif ekbal,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"This paper reports a voted Named Entity Recognition (NER) system with the use of appropriate unlabeled data. The proposed method is based on the classifiers such as Maximum Entropy (ME), Conditional Random Field (CRF) and Support Vector Machine (SVM) and has been tested for Bengali. The system makes use of the language independent features in the form of different contextual and orthographic word level features along with the language dependent features extracted from the Part of Speech (POS) tagger and gazetteers. Context patterns generated from the unlabeled data using an active learning method have been used as the features in each of the classifiers. A semi-supervised method has been used to describe the measures to automatically select effective documents and sentences from unlabeled data. Finally, the models have been combined together into a final system by weighted voting technique. Experimental results show the effectiveness of the proposed approach with the overall Recall, Precision, and F-Score values of 93.81%, 92.18% and 92.98%, respectively. We have shown how the language dependent features can improve the system performance."
Y08-1016,Multi-Engine Approach for Named Entity Recognition in {B}engali,2008,16,0,1,1,363,asif ekbal,"Proceedings of the 22nd Pacific Asia Conference on Language, Information and Computation",0,"This paper reports about a multi-engine approach for the development of a NER system in Bengali by combining the classifiers such as Maximum Entropy (ME), Conditional Random Field (CRF) and Support Vector Machine (SVM) with the help of weighted voting approach. The training set consists of approximately 272K wordforms, out of which 150K wordforms have been manually annotated with the four major named entity (NE) tags such as Person, Location, Organization and Miscellaneous tags. An appropriate tag conversion routine has been defined in order to convert the 122K wordforms of the IJCNLP-08 NER shared task, into the desired forms. The classifiers make use of the different contextual information of the words along with the variety of features that are helpful in predicting the various NE classes. Lexical context patterns, which are generated from an unlabeled corpus of 3 million wordforms in a semi-automatic way, have been used as the features of the classifiers in order to improve their performance. In addition, we have developed a number of techniques to post-process the output of each of the classifiers in order to reduce the errors and to improve the performance. Finally, we have applied weighted voting approach to combine the systems. Results show the effectiveness of the proposed approach with the overall average recall, precision, and f-score values of 93.98%, 90.63%, and 92.28%, respectively, which shows an improvement of 14.92% in f-score over the best performing baseline SVM based system and an improvement of 18.36% in f-score over the least performing baseline ME based system. The proposed system also outperforms the other existing Bengali NER system."
I08-7001,Development of {B}engali Named Entity Tagged Corpus and its Use in {NER} Systems,2008,14,7,1,1,363,asif ekbal,Proceedings of the 6th Workshop on {A}sian Language Resources,0,"The rapid development of language tools using machine learning techniques for less computerized languages requires appropriately tagged corpus. A Bengali news corpus has been developed from the web archive of a widely read Bengali newspaper. A web crawler retrieves the web pages in Hyper Text Markup Language (HTML) format from the news archive. At present, the corpus contains approximately 34 million wordforms. The date, location, reporter and agency tags present in the web pages have been automatically named entity (NE) tagged. A portion of this partially NE tagged corpus has been manually annotated with the sixteen NE tags with the help of Sanchay Editor 1 , a text editor for Indian languages. This NE tagged corpus contains 150K wordforms. Additionally, 30K wordforms have been manually annotated with the twelve NE tags as part of the IJCNLP08 NER Shared Task for South and South East Asian Languages 2 . A table driven semi-automatic NE tag conversion routine has been developed in order to convert the sixteen-NE tagged corpus to the twelve-NE tagged corpus. The 150K NE tagged corpus has been used to develop Named Entity Recognition (NER) system in Bengali using pattern directed shallow parsing approach, Hidden Markov Model (HMM), Maximum Entropy (ME) Model, Condi"
I08-6011,"{B}engali, {H}indi and {T}elugu to {E}nglish Ad-hoc Bilingual Task",2008,0,6,4,0,360,sivaji bandyopadhyay,Proceedings of the 2nd workshop on Cross Lingual Information Access ({CLIA}) Addressing the Information Need of Multilingual Societies,0,"This paper presents the experiments carried out at Jadavpur University as part of participation in the CLEF 2007 ad-hoc bilingual task. This is our first participation in the CLEF evaluation task and we have considered Bengali, Hindi and Telugu as query languages for the retrieval from English document collection. We have discussed our Bengali, Hindi and Telugu to English CLIR system as part of the ad-hoc bilingual task, English IR system for the ad-hoc monolingual task and the associated experiments at CLEF. Query construction was manual for Telugu-English ad-hoc bilingual task, while it was automatic for all other tasks."
I08-5006,Language Independent Named Entity Recognition in {I}ndian Languages,2008,15,49,1,1,363,asif ekbal,Proceedings of the {IJCNLP}-08 Workshop on Named Entity Recognition for South and South East {A}sian Languages,0,"This paper reports about the development of a Named Entity Recognition (NER) system for South and South East Asian languages, particularly for Bengali, Hindi, Telugu, Oriya and Urdu as part of the IJCNLP-08 NER Shared Task 1 . We have"
I08-5008,{B}engali Named Entity Recognition Using Support Vector Machine,2008,19,72,1,1,363,asif ekbal,Proceedings of the {IJCNLP}-08 Workshop on Named Entity Recognition for South and South East {A}sian Languages,0,"Named Entity Recognition (NER) aims to classify each word of a document into predefined target named entity classes and is nowadays considered to be fundamental for many Natural Language Processing (NLP) tasks such as information retrieval, machine translation, information extraction, question answering systems and others. This paper reports about the development of a NER system for Bengali using Support Vector Machine (SVM). Though this state of the art machine learning method has been widely applied to NER in several well-studied languages, this is our first attempt to use this method to Indian languages (ILs) and particularly for Bengali. The system makes use of the different contextual information of the words along with the variety of features that are helpful in predicting the various named entity (NE) classes. A portion of a partially NE tagged Bengali news corpus, developed from the archive of a leading Bengali newspaper available in the web, has been used to develop the SVM-based NER system. The training set consists of approximately 150K words and has been manually annotated with the sixteen NE tags. Experimental results of the 10-fold cross validation test show the effectiveness of the proposed SVM based NER system with the overall average Recall, Precision and F-Score of 94.3%, 89.4% and 91.8%, respectively. It has been shown that this system outperforms other existing Bengali NER systems."
I08-2077,Named Entity Recognition in {B}engali: A Conditional Random Field Approach,2008,7,50,1,1,363,asif ekbal,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper reports about the development of a Named Entity Recognition (NER) system for Bengali using the statistical Conditional Random Fields (CRFs). The system makes use of the different contextual information of the words along with the variety of features that are helpful in predicting the various named entity (NE) classes. A portion of the partially NE tagged Bengali news corpus, developed from the archive of a leading Bengali newspaper available in the web, has been used to develop the system. The training set consists of 150K words and has been manually annotated with a NE tagset of seventeen tags. Experimental results of the 10-fold cross validation test show the effectiveness of the proposed CRF based NER system with an overall average Recall, Precision and F-Score values of 93.8%, 87.8% and 90.7%, respectively."
P06-2025,A Modified Joint Source-Channel Model for Transliteration,2006,12,52,1,1,363,asif ekbal,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,Most machine transliteration systems transliterate out of vocabulary (OOV) words through intermediate phonemic mapping. A framework has been presented that allows direct orthographical mapping between two languages that are of different origins employing different alphabet sets. A modified joint source-channel model along with a number of alternatives have been proposed. Aligned transliteration units along with their context are automatically derived from a bilingual training corpus to generate the collocational statistics. The transliteration units in Bengali words take the pattern CM where C represents a vowel or a consonant or a conjunct and M represents the vowel modifier or matra. The English transliteration units are of the form C*V* where C represents a consonant and V represents a vowel. A Bengali-English machine transliteration system has been developed based on the proposed models. The system has been trained to transliterate person names from Bengali to English. It uses the linguistic knowledge of possible conjuncts and diphthongs in Bengali and their equivalents in English. The system has been evaluated and it has been observed that the modified joint source-channel model performs best with a Word Agreement Ratio of 69.3% and a Transliteration Unit Agreement Ratio of 89.8%.
