2019.rocling-1.12,P00-1037,0,0.573902,"Missing"
2019.rocling-1.12,D14-1179,0,0.0295159,"Missing"
2019.rocling-1.12,N19-4009,0,0.0492684,"Missing"
2019.rocling-1.13,D16-1264,0,0.104344,"Missing"
2019.rocling-1.13,L18-1431,0,0.0369997,"Missing"
2019.rocling-1.13,D18-1259,0,0.0424039,"Missing"
2019.rocling-1.13,Q17-1010,0,0.0761851,"Missing"
2019.rocling-1.13,P16-1008,0,0.0528016,"Missing"
2019.rocling-1.13,P19-1617,0,0.0250795,"Missing"
2019.rocling-1.30,pleva-juhar-2014-tuke,1,0.879236,"already built [10, 11]. Of course, the speech parameters different for children speech because of different vocal tract sizes [12], and they are many algorithms (Vocal-Tract Length Normalization - VTLN) how to handle it [13]. For children's speech, the formant frequencies are higher, the speech rate is slower or higher than in adult speech, and the language contains more home slang, garbled and imaginary words. The Slovak language belongs to a group of Slavic languages, which are typical of inflection and free word order, which means it is morphologically rich and uses a very large vocabulary [10, 14]. These features make the Slovak automatic speech recognition task very complicated, and a large amount of data is required for automatic large vocabulary spontaneous speech recognition [14]. This article describes the first step, the collection of the first data, manual annotation, and testing of the current ASR system with children and adult speech recordings. 2. Building the database For children's speech, there are very few freely available recordings on the Internet, especially in the form suitable for speech recognition system acoustic model training. We decided to use the TV series' rec"
2019.rocling-1.30,H91-1098,0,0.774634,"Figure 2. Transcriber window for speaker turn metadata. 4. Evaluation of the current subtitling system with children recordings The current automatic subtitling system for Slovak TV broadcasters was developed thanks to many years of Slovak automatic speech recognition development of Technical University of Kosice and Slovak Academy of Sciences consortium. The previous system was based on Julius [10] mainly prepared for speech dictation into word processing editor. The next generation was built on Time Delay Deep Neural Network (TDNN) models based on Kaldi [11] for broadcast news transcription [17]. This version was also made online for public testing and evaluation on [18] as seen in Figure 3. 329 Figure 3. SARRA web user interface of automatically subtitled content The SARRA system is built to work in multitasking and scaling environment, so the user’s task could run on more instances of the recognition toolkit at once. The first part of the process is voice activity detection and speaker diarization for better segmentation of the large audio uploads. The smaller segmented parts of the audio could be scaled better. The next part is the primary automatic speech recognition process buil"
2020.ijclclp-2.5,O99-3003,0,0.212761,"Missing"
I17-4020,N16-1066,0,0.025744,"at could modify or even turn over the sentiment words in different degrees. For example, the word “爽” by itself describes a person in a pleasure mood. And the phrase “好 爽” means the man is feeling so good. But the phrase “不 爽” in fact indicates that person is unhappy. Moreover, the order of words is critical. Comparing the two phrases “完全 不 同意” and “不 完全 同意”, the first one means “totally disagree”, but the latter one to some extent represents “agree”. Introduction Recently, sentiment analysis has been approached from many different views. Among them, the two-dimensional valence-arousal space (Yu, et al., 2016) (as in Fig. 1) is promising. In this framework, the valence dimension describes the degree to which an emotion is pleasant or unpleasant, and the arousal dimension describes the degree to which an emotion is associated with high or low energy. To promote this framework to Chinese language, a series of dimensional sentiment analysis shared tasks (Yu, et al., 2016) had been established since 2016. This paper reports our entry to the second one, i.e., the IJCNLP 2017 Shared 1 Yuan-Fu Liao Department of Electronic Engineering, National Taipei University of Technology Taipei, Taiwan, ROC yfliao@nt"
I17-4020,W12-6340,1,0.795169,"n Fig. 4. There are three main modules in this system, including (1) text normalization, (2) word segmentation and (3) part of speech (POS) tagging. The whole system was trained using error-corrected version of Sinica Balanced Corpus ver. 4.0 2. Deep Regression Neural Network Figure 2: The Block Diagram of the proposed VA ratings prediction of Chinese Phrases approach. It is worth mentioning that, the purpose of this study is not only to build an effective VA ratings prediction of Chinese phrases system but also to test the performance of our condition random field (CRF)-based Chinese parser (Wang and Liao, 2012). Because a good Chinese word segmentation frontend plays an important role in the success of this task. 2 Chinese Word Segmentation Characters seSymbols NormalizaCharacters seCorrection of Frequently ErWords Word Segmentation The Proposed VA Prediction System SysLexiCorrection of Frequently ErWords The procedures to build the proposed VA ratings system are shown in Fig. 3. First of all, a CRF-based Chinese parser is applied for word segmentation. Then an order-aware Word2Vec and a Phrase2Vec model are trained. Finally, a regression model is adopted to predict the VA ratings of Chinese phrases"
I17-4020,N15-1142,0,0.0304659,"Missing"
O17-1021,D14-1179,0,0.00867027,"Missing"
O17-1021,W13-4412,1,0.896587,"Missing"
O17-1021,P16-1160,0,0.0780121,"Missing"
W12-6340,P06-2013,0,0.0718021,"Missing"
W12-6340,J96-1002,0,0.0279646,"Missing"
W12-6340,W06-0127,0,\N,Missing
W13-4412,J96-1002,0,0.0187618,"Missing"
W13-4412,P79-1022,0,0.156268,"Missing"
W13-4412,W10-4129,0,\N,Missing
W14-6834,W13-4406,0,0.0372672,"Missing"
W14-6834,W13-4412,1,\N,Missing
W14-6834,W06-0127,0,\N,Missing
W15-3108,W13-4406,0,0.190421,"Missing"
W15-3108,W13-4412,1,\N,Missing
W15-3108,W06-0127,0,\N,Missing
W16-4910,W15-4402,0,0.0610654,"Missing"
W16-4910,C14-1028,0,0.0309944,"ese sentences written by CFLs. Lee et al. (2014) then further implemented a sentence judgement system that integrated both rule-based an and n-gram statistical methods to detect grammatical errors in Chinese sentences. Lin and Chen (2015) proposed a system which measured the likelihood of sentences generated by deleting, inserting, or exchanging characters or words in which two sentence likelihood functions were proposed based on frequencies of space removed version of Google n-grams. On the other hand, Xiang (2015) utilized an ensemble classifier random feature subspace method for CGED task. Cheng et al. (2014) proposed a CRF-based method to detect word ordering errors and a ranking SVM-based model to suggest the proper corrections. Finally, Chen et al. (2015) and Yeh et al. (2015) also adopt CRFs and collected a set of common grammatical error rules for building CGED systems. Among these two methods, the classification-based approach, especially the CRF-based one is quite promising. Because, CRFs treat the CGED problem as a sequence-to-sequence mapping task, it could then model well the word ordering and sentence structure. However, traditional CRF-based approaches often only take current and few n"
W16-4910,C14-2015,0,0.0137265,"brid linguistic rules+language modelling and (2) pure classification-based methods. 1 http://www.sc-top.org.tw/english/eng_index.php This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/ 73 Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications, pages 73–81, Osaka, Japan, December 12 2016. For example, Lee et al. (2013) applied a set of handcrafted linguistic rules with syntactic information to detect errors occurred in Chinese sentences written by CFLs. Lee et al. (2014) then further implemented a sentence judgement system that integrated both rule-based an and n-gram statistical methods to detect grammatical errors in Chinese sentences. Lin and Chen (2015) proposed a system which measured the likelihood of sentences generated by deleting, inserting, or exchanging characters or words in which two sentence likelihood functions were proposed based on frequencies of space removed version of Google n-grams. On the other hand, Xiang (2015) utilized an ensemble classifier random feature subspace method for CGED task. Cheng et al. (2014) proposed a CRF-based method"
W16-4910,W15-4401,0,0.0134153,"ents, the effectiveness of the error-prone word templates was first checked. Then the performance of the new “CWindow” and “Structured Skip-gram” were compared with the original “Skip-gram” and the “CBOW” models. Finally, the official evaluation results of our three CWindow-based submissions were discussed. 3.1 TOCFL learner database The TOCFL learner database (NLP-TEA3) provided by the organizers was used to develop our CGED system. In order to enlarge the pool of training samples, the data sets of the two previous editions of this shared task, i.e., NLP-TEA1 (Yu et al. (2014)) and NLP-TEA2 (Lee et al. (2015)) are also added together. In the end, there are in total 63,462 sentences for system development. Table 2 shows the statistics of different grammatical error types on the development dataset. Error-type Disorder Redundant Missing Selection Correct #. of errors 1,980 4,971 90 10,686 35,141 Table 2: Statistics of the numbers of error-types made by CFLs on our training corpus. The development data was further divided into a training and a testing subsets by a ratio of 9:1. Therefore, there are 57,116 and 6,346 sentences in the training and testing subsets, respectively. 3.2 Model Settings Four t"
W16-4910,N13-1090,0,0.0602384,"Missing"
W16-4910,N15-1142,0,0.0718858,"Missing"
W16-4910,W15-3108,1,0.852125,"Missing"
W16-4910,W15-4415,0,0.0217817,"Missing"
