2020.lrec-1.86,Dialogue-{AMR}: {A}bstract {M}eaning {R}epresentation for Dialogue,2020,-1,-1,7,0.28339,5184,claire bonial,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper describes a schema that enriches Abstract Meaning Representation (AMR) in order to provide a semantic representation for facilitating Natural Language Understanding (NLU) in dialogue systems. AMR offers a valuable level of abstraction of the propositional content of an utterance; however, it does not capture the illocutionary force or speaker{'}s intended contribution in the broader dialogue context (e.g., make a request or ask a question), nor does it capture tense or aspect. We explore dialogue in the domain of human-robot interaction, where a conversational robot is engaged in search and navigation tasks with a human partner. To address the limitations of standard AMR, we develop an inventory of speech acts suitable for our domain, and present {``}Dialogue-AMR{''}, an enhanced AMR that represents not only the content of an utterance, but the illocutionary force behind it, as well as tense and aspect. To showcase the coverage of the schema, we use both manual and automatic methods to construct the {``}DialAMR{''} corpus{---}a corpus of human-robot dialogue annotated with standard AMR and our enriched Dialogue-AMR schema. Our automated methods can be used to incorporate AMR into a larger NLU pipeline supporting human-robot dialogue."
W19-3322,Augmenting {A}bstract {M}eaning {R}epresentation for Human-Robot Dialogue,2019,0,1,5,0.295571,5184,claire bonial,Proceedings of the First International Workshop on Designing Meaning Representations,0,"We detail refinements made to Abstract Meaning Representation (AMR) that make the representation more suitable for supporting a situated dialogue system, where a human remotely controls a robot for purposes of search and rescue and reconnaissance. We propose 36 augmented AMRs that capture speech acts, tense and aspect, and spatial information. This linguistic information is vital for representing important distinctions, for example whether the robot has moved, is moving, or will move. We evaluate two existing AMR parsers for their performance on dialogue data. We also outline a model for graph-to-graph conversion, in which output from AMR parsers is converted into our refined AMRs. The design scheme presented here, though task-specific, is extendable for broad coverage of speech acts using AMR in future task-independent work."
W18-5012,Consequences and Factors of Stylistic Differences in Human-Robot Dialogue,2018,0,0,6,0.726318,16783,stephanie lukin,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"This paper identifies stylistic differences in instruction-giving observed in a corpus of human-robot dialogue. Differences in verbosity and structure (i.e., single-intent vs. multi-intent instructions) arose naturally without restrictions or prior guidance on how users should speak with the robot. Different styles were found to produce different rates of miscommunication, and correlations were found between style differences and individual user variation, trust, and interaction experience with the robot. Understanding potential consequences and factors that influence style can inform design of dialogue systems that are robust to natural variation from human users."
W18-4701,{D}ial{E}dit: Annotations for Spoken Conversational Image Editing,2018,0,3,5,0,28126,ramesh manuvirakurike,Proceedings 14th Joint {ACL} - {ISO} Workshop on Interoperable Semantic Annotation,0,None
L18-1017,Dialogue Structure Annotation for Multi-Floor Interaction,2018,0,2,4,0,16786,david traum,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1463,"The Niki and Julie Corpus: Collaborative Multimodal Dialogues between Humans, Robots, and Virtual Agents",2018,0,0,1,1,16785,ron artstein,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1532,Chahta Anumpa: A multimodal corpus of the {C}hoctaw Language,2018,0,0,3,1,17329,jacqueline brixey,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1683,Edit me: A Corpus and a Framework for Understanding Natural Language Image Editing,2018,0,5,6,0,1597,ramesh manuvinakurike,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-5541,Lessons in Dialogue System Deployment,2017,5,1,2,0,16800,anton leuski,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,We analyze deployment of an interactive dialogue system in an environment where deep technical expertise might not be readily available. The initial version was created using a collection of research tools. We summarize a number of challenges with its deployment at two museums and describe a new system that simplifies the installation and user interface; reduces reliance on 3rd-party software; and provides a robust data collection mechanism.
W17-5544,{SHIH}bot: A {F}acebook chatbot for Sexual Health Information on {HIV}/{AIDS},2017,0,12,7,1,17329,jacqueline brixey,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"We present the implementation of an autonomous chatbot, SHIHbot, deployed on Facebook, which answers a wide variety of sexual health questions on HIV/AIDS. The chatbot{'}s response database is com-piled from professional medical and public health resources in order to provide reliable information to users. The system{'}s backend is NPCEditor, a response selection platform trained on linked questions and answers; to our knowledge this is the first retrieval-based chatbot deployed on a large public social network."
W17-2808,Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task,2017,27,4,7,0,1549,matthew marge,Proceedings of the First Workshop on Language Grounding for Robotics,0,"Robot-directed communication is variable, and may change based on human perception of robot capabilities. To collect training data for a dialogue system and to investigate possible communication changes over time, we developed a Wizard-of-Oz study that (a) simulates a robot{'}s limited understanding, and (b) collects dialogues where human participants build a progressively better mental model of the robot{'}s understanding. With ten participants, we collected ten hours of human-robot dialogue. We analyzed the structure of instructions that participants gave to a remote robot before it responded. Our findings show a general initial preference for including metric information (e.g., move forward 3 feet) over landmarks (e.g., move to the desk) in motion commands, but this decreased over time, suggesting changes in perception."
W16-3614,Language Portability for Dialogue Systems: Translating a Question-Answering System from {E}nglish into {T}amil,2016,17,0,2,0,33718,satheesh ravi,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"A training and test set for a dialogue system in the form of linked questions and responses is translated from English into Tamil. Accuracy of identifying an appropriate response in Tamil is 79%, compared to the English accuracy of 89%, suggesting that translation can be useful to start up a dialogue system. Machine translation of Tamil inputs into English also results in 79% accuracy. However, machine translation of the English training data into Tamil results in a drop in accuracy to 54% when tested on manually authored Tamil, indicating that there is still a large gap before machine translated dialogue systems can interact with human users."
N16-3007,New Dimensions in Testimony Demonstration,2016,12,1,1,1,16785,ron artstein,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,"New Dimensions in Testimony is a prototype dialogue system that allows users to conduct a conversation with a real person who is not available for conversation in real time. Users talk to a persistent representation of Holocaust survivor Pinchas Gutter on a screen, while a dialogue agent selects appropriate responses to user utterances from a set of pre-recorded video statements, simulating a live conversation. The technology is similar to existing conversational agents, but to our knowledge this is the first system to portray a real person. The demonstration will show the system on a range of screens (from mobile phones to large TVs), and allow users to have individual conversations with Mr. Gutter."
L16-1326,{ARRAU}: Linguistically-Motivated Annotation of Anaphoric Descriptions,2016,0,5,2,0,28598,olga uryupina,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents a second release of the ARRAU dataset: a multi-domain corpus with thorough linguistically motivated annotation of anaphora and related phenomena. Building upon the first release almost a decade ago, a considerable effort had been invested in improving the data both quantitatively and qualitatively. Thus, we have doubled the corpus size, expanded the selection of covered phenomena to include referentiality and genericity and designed and implemented a methodology for enforcing the consistency of the manual annotation. We believe that the new release of ARRAU provides a valuable material for ongoing research in complex cases of coreference as well as for a variety of related tasks. The corpus is publicly available through LDC."
L16-1501,The Negochat Corpus of Human-agent Negotiation Dialogues,2016,11,2,2,0,35222,vasily konovalov,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Annotated in-domain corpora are crucial to the successful development of dialogue systems of automated agents, and in particular for developing natural language understanding (NLU) components of such systems. Unfortunately, such important resources are scarce. In this work, we introduce an annotated natural language human-agent dialogue corpus in the negotiation domain. The corpus was collected using Amazon Mechanical Turk following the {`}Wizard-Of-Oz{'} approach, where a {`}wizard{'} human translates the participants{'} natural language utterances in real time into a semantic language. Once dialogue collection was completed, utterances were annotated with intent labels by two independent annotators, achieving high inter-annotator agreement. Our initial experiments with an SVM classifier show that automatically inferring such labels from the utterances is far from trivial. We make our corpus publicly available to serve as an aid in the development of dialogue systems for negotiation agents, and suggest that analogous corpora can be created following our methodology and using our available source code. To the best of our knowledge this is the first publicly available negotiation dialogue corpus."
W15-4629,Evaluating Spoken Dialogue Processing for Time-Offset Interaction,2015,10,11,3,0,16786,david traum,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper presents the first evaluation of a full automated prototype system for time-offset interaction, that is, conversation between a live person and recordings of someone who is not temporally copresent. Speech recognition reaches word error rates as low as 5% with generalpurpose language models and 19% with domain-specific models, and language understanding can identify appropriate direct responses to 60xe2x80x9066% of user utterances while keeping errors to 10xe2x80x9016% (the remainder being indirect, or off-topic responses). This is sufficient to enable a natural flow and relatively open-ended conversations, with a collection of under 2000 recorded statements."
W14-4334,A Demonstration of Dialogue Processing in {S}im{S}ensei Kiosk,2014,7,1,4,1,33320,fabrizio morbini,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"This demonstration highlights the dialogue processing in SimSensei Kiosk, a virtual human dialogue system that conducts interviews related to psychological distress conditions such as depression, anxiety, and post-traumatic stress disorder (PTSD). The dialogue processing in SimSensei Kiosk allows the system to conduct coherent spoken interviews of human users that are 15-25 minutes in length, and in which users feel comfortable talking and openly sharing information. We present the design of the individual dialogue components, and show examples of natural conversation flow between the system and users, including expressions of empathy, follow-up responses and continuation prompts, and turn-taking."
gratch-etal-2014-distress,The Distress Analysis Interview Corpus of human and computer interviews,2014,30,95,2,0,4007,jonathan gratch,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Distress Analysis Interview Corpus (DAIC) contains clinical interviews designed to support the diagnosis of psychological distress conditions such as anxiety, depression, and post traumatic stress disorder. The interviews are conducted by humans, human controlled agents and autonomous agents, and the participants include both distressed and non-distressed individuals. Data collected include audio and video recordings and extensive questionnaire responses; parts of the corpus have been transcribed and annotated for a variety of verbal and non-verbal features. The corpus has been used to support the creation of an automated interviewer agent, and for research on the automatic identification of psychological distress."
W13-4032,Verbal indicators of psychological distress in interactive dialogue with a virtual human,2013,16,28,3,0.517624,31518,david devault,Proceedings of the {SIGDIAL} 2013 Conference,0,"We explore the presence of indicators of psychological distress in the linguistic behavior of subjects in a corpus of semistructured virtual human interviews. At the level of aggregate dialogue-level features, we identify several significant differences between subjects with depression and PTSD when compared to nondistressed subjects. At a more fine-grained level, we show that significant differences can also be found among features that represent subject behavior during specific moments in the dialogues. Finally, we present statistical classification results that suggest the potential for automatic assessment of psychological distress in individual interactions with a virtual human dialogue system."
W13-4064,Which {ASR} should {I} choose for my dialogue system?,2013,36,36,4,1,33320,fabrizio morbini,Proceedings of the {SIGDIAL} 2013 Conference,0,"We present an analysis of several publicly available automatic speech recognizers (ASRs) in terms of their suitability for use in different types of dialogue systems. We focus in particular on cloud based ASRs that recently have become available to the community. We include features of ASR systems and desiderata and requirements for different dialogue systems, taking into account the dialogue genre, type of user, and other features. We then present speech recognition results for six different dialogue systems. The most interesting result is that different ASR systems perform best on the data sets. We also show that there is an improvement over a previous generation of recognizers on some of these data sets. We also investigate language understanding (NLU) on the ASR output, and explore the relationship between ASR and NLU performance."
aggarwal-etal-2012-twins,The Twins Corpus of Museum Visitor Questions,2012,8,8,2,0,43100,priti aggarwal,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The Twins corpus is a collection of utterances spoken in interactions with two virtual characters who serve as guides at the Museum of Science in Boston. The corpus contains about 200,000 spoken utterances from museum visitors (primarily children) as well as from trained handlers who work at the museum. In addition to speech recordings, the corpus contains the outputs of speech recognition performed at the time of utterance as well as the system interpretation of the utterances. Parts of the corpus have been manually transcribed and annotated for question interpretation. The corpus has been used for improving performance of the museum characters and for a variety of research projects, such as phonetic-based Natural Language Understanding, creation of conversational characters from text resources, dialogue policy learning, and research on patterns of user interaction. It has the potential to be used for research on children's speech and on language used when talking to a virtual human."
W11-2030,An Annotation Scheme for Cross-Cultural Argumentation and Persuasion Dialogues,2011,30,6,2,0.447264,16796,kallirroi georgila,Proceedings of the {SIGDIAL} 2011 Conference,0,"We present a novel annotation scheme for cross-cultural argumentation and persuasion dialogues. This scheme is an adaptation of existing coding schemes on negotiation, following a review of literature on cross-cultural differences in negotiation styles. The scheme has been refined through application to coding both two-party and multi-party negotiation dialogues in three different domains, and is general enough to be applicable to different domains with few if any extensions. Dialogues annotated with the scheme have been used to successfully learn culture-specific dialogue policies for argumentation and persuasion."
W11-2037,Error Return Plots,2011,10,7,1,1,16785,ron artstein,Proceedings of the {SIGDIAL} 2011 Conference,0,"Error-return plots show the rate of error (misunderstanding) against the rate of non-return (non-understanding) for Natural Language Processing systems. They are a useful visual tool for judging system performance when other measures such as recall/precision and detection-error tradeoff are less informative, specifically when a system is judged on the correctness of its responses, but may elect to not return a response."
W10-4333,Don{'}t tell anyone! Two Experiments on Gossip Conversations,2010,14,2,2,0,45094,jenny brusk,Proceedings of the {SIGDIAL} 2010 Conference,0,"The purpose of this study is to get a working definition that matches people's intuitive notion of gossip and is sufficiently precise for computational implementation. We conducted two experiments investigating what type of conversations people intuitively understand and interpret as gossip, and whether they could identify three proposed constituents of gossip conversations: third person focus, pejorative evaluation and substantiating behavior. The results show that (1) conversations are very likely to be considered gossip if all elements are present, no intimate relationships exist between the participants, and the person in focus is unambiguous. (2) Conversations that have at most one gossip element are not considered gossip. (3) Conversations that lack one or two elements or have an ambiguous element lead to inconsistent judgments."
yao-etal-2010-practical,Practical Evaluation of Speech Recognizers for Virtual Human Dialogue Systems,2010,15,8,5,0,37412,xuchen yao,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We perform a large-scale evaluation of multiple off-the-shelf speech recognizers across diverse domains for virtual human dialogue systems. Our evaluation is aimed at speech recognition consumers and potential consumers with limited experience with readily available recognizers. We focus on practical factors to determine what levels of performance can be expected from different available recognizers in various projects featuring different types of conversational utterances. Our results show that there is no single recognizer that outperforms all other recognizers in all domains. The performance of each recognizer may vary significantly depending on the domain, the size and perplexity of the corpus, the out-of-vocabulary rate, and whether acoustic and language model adaptation has been used or not. We expect that our evaluation will prove useful to other speech recognition consumers, especially in the dialogue community, and will shed some light on the key problem in spoken dialogue systems of selecting the most suitable available speech recognition system for a particular application, and what impact training will have."
W08-1111,Practical Grammar-Based {NLG} from Examples,2008,25,19,3,0.369226,31518,david devault,Proceedings of the Fifth International Natural Language Generation Conference,0,"We present a technique that opens up grammar-based generation to a wider range of practical applications by dramatically reducing the development costs and linguistic expertise that are required. Our method infers the grammatical resources needed for generation from a set of declarative examples that link surface expressions directly to the application's available semantic representations. The same examples further serve to optimize a run-time search strategy that generates the best output that can be found within an application-specific time frame. Our method offers substantially lower development costs than hand-crafted grammars for application-specific NLG, while maintaining high output quality and diversity."
W08-0130,Making Grammar-Based Generation Easier to Deploy in Dialogue Systems,2008,20,18,3,0.369226,31518,david devault,Proceedings of the 9th {SIG}dial Workshop on Discourse and Dialogue,0,"We present a development pipeline and associated algorithms designed to make grammarbased generation easier to deploy in implemented dialogue systems. Our approach realizes a practical trade-off between the capabilities of a system's generation component and the authoring and maintenance burdens imposed on the generation content author for a deployed system. To evaluate our approach, we performed a human rating study with system builders who work on a common largescale spoken dialogue system. Our results demonstrate the viability of our approach and illustrate authoring/performance trade-offs between hand-authored text, our grammar-based approach, and a competing shallow statistical NLG technique."
poesio-artstein-2008-anaphoric,Anaphoric Annotation in the {ARRAU} Corpus,2008,20,67,2,0,1743,massimo poesio,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Arrau is a new corpus annotated for anaphoric relations, with information about agreement and explicit representation of multiple antecedents for ambiguous anaphoric expressions and discourse antecedents for expressions which refer to abstract entities such as events, actions and plans. The corpus contains texts from different genres: task-oriented dialogues from the Trains-91 and Trains-93 corpus, narratives from the English Pear Stories corpus, newspaper articles from the Wall Street Journal portion of the Penn Treebank, and mixed text from the Gnome corpus."
J08-4004,Survey Article: Inter-Coder Agreement for Computational Linguistics,2008,130,709,1,1,16785,ron artstein,Computational Linguistics,0,"This article is a survey of methods for measuring agreement among corpus annotators. It exposes the mathematics and underlying assumptions of agreement coefficients, covering Krippendorff's alpha as well as Scott's pi and Cohen's kappa; discusses the use of coefficients in several annotation tasks; and argues that weighted, alpha-like coefficients, traditionally less used than kappa-like measures in computational linguistics, may be more appropriate for many corpus annotation tasks---but that their use makes the interpretation of the value of the coefficient even harder."
W05-0311,"The Reliability of Anaphoric Annotation, Reconsidered: Taking Ambiguity into Account",2005,21,53,2,0,1743,massimo poesio,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"We report the results of a study of the reliability of anaphoric annotation which (i) involved a substantial number of naive subjects, (ii) used Krippendorff's xcexb1 instead of K to measure agreement, as recently proposed by Passonneau, and (iii) allowed annotators to mark anaphoric expressions as ambiguous."
