2021.emnlp-demo.13,Semantic Context Path Labeling for Semantic Exploration of User Reviews,2021,-1,-1,2,0,10312,salah aitmokhtar,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,0,"In this paper we present a prototype demonstrator showcasing a novel method to perform semantic exploration of user reviews. The system enables effective navigation in a rich contextual semantic schema with a large number of structured classes indicating relevant information. In order to identify instances of the structured classes in the reviews, we defined a new Information Extraction task called Semantic Context Path (SCP) labeling, which simultaneously assigns types and semantic roles to entity mentions. Reviews can rapidly be explored based on the fine-grained and structured semantic classes. As a proof-of-concept, we have implemented this system for reviews on Points-of-Interest, in English and Korean."
2019.jeptalnrecital-demo.5,{``}Sentiment Aware Map{''} : exploration cartographique de points d{'}int{\\'e}r{\\^e}t via l{'}analyse de sentiments au niveau des aspects (),2019,-1,-1,2,0,11398,ioan calapodescu,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume IV : D{\\'e}monstrations,0,
W18-6217,Aspect Based Sentiment Analysis into the Wild,2018,0,1,1,1,10313,caroline brun,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"In this paper, we test state-of-the-art Aspect Based Sentiment Analysis (ABSA) systems trained on a widely used dataset on actual data. We created a new manually annotated dataset of user generated data from the same domain as the training dataset, but from other sources and analyse the differences between the new and the standard ABSA dataset. We then analyse the results in performance of different versions of the same system on both datasets. We also propose light adaptation methods to increase system robustness."
2018.jeptalnrecital-court.39,"Transfert de ressources s{\\'e}mantiques pour l{'}analyse de sentiments au niveau des aspects (In this paper, we address the problem of automatic polarity detection in the context of Aspect Based)",2018,-1,-1,1,1,10313,caroline brun,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Dans cet article, nous abordons le probl{\`e}me de la d{\'e}tection de la polarit{\'e} pour l{'}analyse de sentiments au niveau des aspects dans un contexte bilingue : nous proposons d{'}adapter le composant de d{\'e}tection de polarit{\'e} d{'}un syst{\`e}me pr{\'e}existant d{'}analyse de sentiments au niveau des aspects, tr{\`e}s performant pour la t{\^a}che, et reposant sur l{'}utilisation de ressources s{\'e}mantiques riches pour une langue donn{\'e}e, {\`a} une langue s{\'e}mantiquement moins richement dot{\'e}e. L{'}id{\'e}e sous-jacente est de r{\'e}duire le besoin de supervision n{\'e}cessaire {\`a} la construction des ressources s{\'e}mantiques essentielles {\`a} notre syst{\`e}me. {\`A} cette fin, la langue source, peu dot{\'e}e, est traduite vers la langue cible, et les traductions parall{\`e}les sont ensuite align{\'e}es mot {\`a} mot. Les informations s{\'e}mantiques riches sont alors extraites de la langue cible par le syst{\`e}me de d{\'e}tection de polarit{\'e}, et ces informations sont ensuite align{\'e}es vers la langue source. Nous pr{\'e}sentons les diff{\'e}rentes {\'e}tapes de cette exp{\'e}rience, ainsi que l{'}{\'e}valuation finale. Nous concluons par quelques perspectives."
W16-6205,Steps Toward Automatic Understanding of the Function of Affective Language in Support Groups,2016,17,0,2,0,33401,amit navindgi,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,"Understanding expressions of emotions in support forums has considerable value and NLP methods are key to automating this. Many approaches understandably use subjective categories which are more fine-grained than a straightforward polarity-based spectrum. However, the definition of such categories is non-trivial and, in fact, we argue for a need to incorporate communicative elements even beyond subjectivity. To support our position, we report experiments on a sentiment-labelled corpus of posts taken from a medical support forum. We argue that not only is a more fine-grained approach to text analysis important, but simultaneously recognising the social function behind affective expressions enable a more accurate and valuable level of understanding."
S16-1044,{XRCE} at {S}em{E}val-2016 Task 5: Feedbacked Ensemble Modeling on Syntactico-Semantic Knowledge for Aspect Based Sentiment Analysis,2016,8,18,1,1,10313,caroline brun,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
D15-1130,Motivating Personality-aware Machine Translation,2015,40,21,3,0,27123,shachar mirkin,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Language use is known to be influenced by personality traits as well as by sociodemographic characteristics such as age or mother tongue. As a result, it is possible to automatically identify these traits of the author from her texts. It has recently been shown that knowledge of such dimensions can improve performance in NLP tasks such as topic and sentiment modeling. We posit that machine translation is another application that should be personalized. In order to motivate this, we explore whether translation preserves demographic and psychometric traits. We show that, largely, both translation of the source training data into the target language, and the target test data into the source language has a detrimental effect on the accuracy of predicting author traits. We argue that this supports the need for personal and personality-aware machine translation models."
2015.jeptalnrecital-demonstration.5,Etude de l{'}image de marque d{'}entit{\\'e}s dans le cadre d{'}une plateforme de veille sur le Web social,2015,-1,-1,2,0,37963,leila khouas,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,"Ce travail concerne l{'}int{\'e}gration {\`a} une plateforme de veille sur internet d{'}outils permettant l{'}analyse des opinions {\'e}mises par les internautes {\`a} propos d{'}une entit{\'e}, ainsi que la mani{\`e}re dont elles {\'e}voluent dans le temps. Les entit{\'e}s consid{\'e}r{\'e}es peuvent {\^e}tre des personnes, des entreprises, des marques, etc. Les outils impl{\'e}ment{\'e}s sont le produit d{'}une collaboration impliquant plusieurs partenaires industriels et acad{\'e}miques dans le cadre du projet ANR ImagiWeb."
2015.jeptalnrecital-court.34,Un syst{\\`e}me hybride pour l{'}analyse de sentiments associ{\\'e}s aux aspects,2015,-1,-1,1,1,10313,caroline brun,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Cet article pr{\'e}sente en d{\'e}tails notre participation {\`a} la t{\^a}che 4 de SemEval2014 (Analyse de Sentiments associ{\'e}s aux Aspects). Nous pr{\'e}sentons la t{\^a}che et d{\'e}crivons pr{\'e}cis{\'e}ment notre syst{\`e}me qui consiste en une combinaison de composants linguistiques et de modules de classification. Nous exposons ensuite les r{\'e}sultats de son {\'e}valuation, ainsi que les r{\'e}sultats des meilleurs syst{\`e}mes. Nous concluons par la pr{\'e}sentation de quelques nouvelles exp{\'e}riences r{\'e}alis{\'e}es en vue de l{'}am{\'e}lioration de ce syst{\`e}me."
S14-2149,{XRCE}: Hybrid Classification for Aspect-based Sentiment Analysis,2014,10,29,1,1,10313,caroline brun,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In this paper, we present the system we have developed for the SemEval-2014 Task 4 dedicated to Aspect-Based Sentiment Analysis. The system is based on a robust parser that provides information to feed different classifiers with linguistic features dedicated to aspect categories and aspect categories polarity classification. We mainly present the work which has been done on the restaurant domain 1 for the four subtasks, aspect term and category detection and aspect term and category polarity."
velcin-etal-2014-investigating,Investigating the Image of Entities in Social Media: Dataset Design and First Results,2014,11,8,3,0,8602,julien velcin,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The objective of this paper is to describe the design of a dataset that deals with the image (i.e., representation, web reputation) of various entities populating the Internet: politicians, celebrities, companies, brands etc. Our main contribution is to build and provide an original annotated French dataset. This dataset consists of 11527 manually annotated tweets expressing the opinion on specific facets (e.g., ethic, communication, economic project) describing two French policitians over time. We believe that other researchers might benefit from this experience, since designing and implementing such a dataset has proven quite an interesting challenge. This design comprises different processes such as data selection, formal definition and instantiation of an image. We have set up a full open-source annotation platform. In addition to the dataset design, we present the first results that we obtained by applying clustering methods to the annotated dataset in order to extract the entity images."
F14-2015,Decomposing Hashtags to Improve Tweet Polarity Classification (D{\\'e}composition des Â« hash tags Â» pour l{'}am{\\'e}lioration de la classification en polarit{\\'e} des Â« tweets Â») [in {F}rench],2014,-1,-1,1,1,10313,caroline brun,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
C14-1166,Part of Speech Tagging for {F}rench Social Media Data,2014,29,6,2,0,7007,farhad nooralahzadeh,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In the context of Social Media Analytics, Natural Language Processing tools face new chal- lenges on on-line conversational text, such as microblogs, chat, or text messages, because of the specificity of the language used in these channels. This work addresses the problem of Part- Of-Speech tagging (initially for French but also for English) on noisy language usage from the popular social media services like Twitter, Facebook and forums. We employ a linear-chain con- ditional random fields (CRFs) model, enriched with several morphological, orthographic, lexical and large-scale word clustering features. Our experiments used different feature configurations to train the model. We achieved a higher tagging performance with these features, compared to baseline results on French social media bank. Moreover, experiments on English social media content show that our model improves over previous works on these data."
W12-1009,Linguistically-Adapted Structural Query Annotation for Digital Libraries in the Social Sciences,2012,12,4,1,1,10313,caroline brun,"Proceedings of the 6th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",0,"Query processing is an essential part of a range of applications in the social sciences and cultural heritage domain. However, out-of-the-box natural language processing tools originally developed for full phrase analysis are inappropriate for query analysis. In this paper, we propose an approach to solving this problem by adapting a complete and integrated chain of NLP tools, to make it suitable for queries analysis. Using as a case study the automatic translation of queries posed to the Europeana library, we demonstrate that adapted linguistic processing can lead to improvements in translation quality."
W12-0608,Opinion and Suggestion Analysis for Expert Recommendations,2012,-1,-1,2,0,42522,anna stavrianou,Proceedings of the Workshop on Semantic Analysis in Social Media,0,None
N12-3002,A Graphical User Interface for Feature-Based Opinion Mining,2012,7,2,2,0,37014,pedro filho,Proceedings of the Demonstration Session at the Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In this paper, we present XOpin, a graphical user interface that have been developed to provide a smart access to the results of a feature-based opinion detection system, build on top of a parser."
F12-2045,Propagation de polarit{\\'e}s dans des familles de mots : impact de la morphologie dans la construction d{'}un lexique pour l{'}analyse de sentiments (Spreading Polarities among Word Families: Impact of Morphology on Building a Lexicon for Sentiment Analysis) [in {F}rench],2012,-1,-1,2,0,15665,nuria gala,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
C12-2017,Learning Opinionated Patterns for Contextual Opinion Detection,2012,14,9,1,1,10313,caroline brun,Proceedings of {COLING} 2012: Posters,0,"This paper tackles the problem of polar vocabulary ambiguity. While some opinionated words keep their polarity in any context and/or across any domain (except for the ironic style that goes beyond the present article), some other have an ambiguous polarity which is highly dependent of the context or the domain: in this case, the opinion is generally carried by complex expressions (xe2x80x9cpatternsxe2x80x9d) rather than single words. In this paper, we propose and evaluate an original hybrid method, based on syntactic information extraction and clustering techniques, to learn automatically such patterns and integrate them into an opinion detection system."
R11-1054,Detecting Opinions Using Deep Syntactic Analysis,2011,15,22,1,1,10313,caroline brun,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"In this paper, we present an opinion detection system built on top of a robust syntactic pars-er. The goal of this system is to extract opi-nions associated with products but also with characteristics of these products, i.e. to per-form feature-based opinion extraction. To car-ry out this task, and following a rget corpus tastudy, the robust syntactic parser is enriched by associa ting polarities to pertinent lexical elements and by developing generic rules to extract relations of opinions t ogether with their polarity, i.e. positive or negative. These rela-tions are used to feed an opinion representa-tion model. A first evaluation shows very en-couraging results, but numerous perspectives and developments remain to be inve stigated."
2011.jeptalnrecital-court.46,Un syst{\\`e}me de d{\\'e}tection d{'}opinions fond{\\'e} sur l{'}analyse syntaxique profonde (An opinion detection system based on deep syntactic analysis),2011,-1,-1,1,1,10313,caroline brun,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous pr{\'e}sentons un syst{\`e}me de d{\'e}tection d{'}opinions construit {\`a} partir des sorties d{'}un analyseur syntaxique robuste produisant des analyses profondes. L{'}objectif de ce syst{\`e}me est l{'}extraction d{'}opinions associ{\'e}es {\`a} des produits (les concepts principaux) ainsi qu{'}aux concepts qui leurs sont associ{\'e}s (en anglais Â«features-based opinion extractionÂ»). Suite {\`a} une {\'e}tude d{'}un corpus cible, notre analyseur syntaxique est enrichi par l{'}ajout de polarit{\'e} aux {\'e}l{\'e}ments pertinents du lexique et par le d{\'e}veloppement de r{\`e}gles g{\'e}n{\'e}riques et sp{\'e}cialis{\'e}es permettant l{'}extraction de relations s{\'e}mantiques d{'}opinions, qui visent {\`a} alimenter un mod{\`e}le de repr{\'e}sentation des opinions. Une premi{\`e}re {\'e}valuation montre des r{\'e}sultats tr{\`e}s encourageants, mais de nombreuses perspectives restent {\`a} explorer."
2010.jeptalnrecital-court.20,Un syst{\\`e}me de d{\\'e}tection d{'}entit{\\'e}s nomm{\\'e}es adapt{\\'e} pour la campagne d{'}{\\'e}valuation {ESTER} 2,2010,-1,-1,1,1,10313,caroline brun,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article nous relatons notre participation {\`a} la campagne d{'}{\'e}valuation ESTER 2 (Evaluation des Syst{\`e}mes de Transcription Enrichie d{'}Emissions Radiophoniques). Apr{\`e}s avoir d{\'e}crit les objectifs de cette campagne ainsi que ses sp{\'e}cificit{\'e}s et difficult{\'e}s, nous pr{\'e}sentons notre syst{\`e}me d{'}extraction d{'}entit{\'e}s nomm{\'e}es en nous focalisant sur les adaptations r{\'e}alis{\'e}es dans le cadre de cette campagne. Nous d{\'e}crivons ensuite les r{\'e}sultats obtenus lors de la comp{\'e}tition, ainsi que des r{\'e}sultats originaux obtenus par la suite. Nous concluons sur les le{\c{c}}ons tir{\'e}es de cette exp{\'e}rience."
2009.jeptalnrecital-long.26,Une exp{\\'e}rience de fusion pour l{'}annotation d{'}entit{\\'e}s nomm{\\'e}es,2009,-1,-1,1,1,10313,caroline brun,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous pr{\'e}sentons une exp{\'e}rience de fusion d{'}annotations d{'}entit{\'e}s nomm{\'e}es provenant de diff{\'e}rents annotateurs. Ce travail a {\'e}t{\'e} r{\'e}alis{\'e} dans le cadre du projet Infom@gic, projet visant {\`a} l{'}int{\'e}gration et {\`a} la validation d{'}applications op{\'e}rationnelles autour de l{'}ing{\'e}nierie des connaissances et de l{'}analyse de l{'}information, et soutenu par le p{\^o}le de comp{\'e}titivit{\'e} Cap Digital Â« Image, MultiM{\'e}dia et Vie Num{\'e}rique Â». Nous d{\'e}crivons tout d{'}abord les quatre annotateurs d{'}entit{\'e}s nomm{\'e}es {\`a} l{'}origine de cette exp{\'e}rience. Chacun d{'}entre eux fournit des annotations d{'}entit{\'e}s conformes {\`a} une norme d{\'e}velopp{\'e}e dans le cadre du projet Infom@gic. L{'}algorithme de fusion des annotations est ensuite pr{\'e}sent{\'e} ; il permet de g{\'e}rer la compatibilit{\'e} entre annotations et de mettre en {\'e}vidence les conflits, et ainsi de fournir des informations plus fiables. Nous concluons en pr{\'e}sentant et interpr{\'e}tant les r{\'e}sultats de la fusion, obtenus sur un corpus de r{\'e}f{\'e}rence annot{\'e} manuellement."
2008.jeptalnrecital-long.25,V{\\'e}rification s{\\'e}mantique pour l{'}annotation d{'}entit{\\'e}s nomm{\\'e}es,2008,-1,-1,1,1,10313,caroline brun,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous proposons une m{\'e}thode visant {\`a} corriger et {\`a} associer dynamiquement de nouveaux types s{\'e}mantiques dans le cadre de syst{\`e}mes de d{\'e}tection automatique d{'}entit{\'e}s nomm{\'e}es (EN). Apr{\`e}s la d{\'e}tection des entit{\'e}s nomm{\'e}es et aussi de mani{\`e}re plus g{\'e}n{\'e}rale des noms propres dans les textes, une v{\'e}rification de compatibilit{\'e} de types s{\'e}mantiques est effectu{\'e}e non seulement pour confirmer ou corriger les r{\'e}sultats obtenus par le syst{\`e}me de d{\'e}tection d{'}EN, mais aussi pour associer de nouveaux types non couverts par le syst{\`e}me de d{\'e}tection d{'}EN. Cette v{\'e}rification est effectu{\'e}e en utilisant l{'}information syntaxique associ{\'e}e aux EN par un syst{\`e}me d{'}analyse syntaxique robuste et en confrontant ces r{\'e}sultats avec la ressource s{\'e}mantique WordNet. Les r{\'e}sultats du syst{\`e}me de d{\'e}tection d{'}EN sont alors consid{\'e}rablement enrichis, ainsi que les {\'e}tiquettes s{\'e}mantiques associ{\'e}es aux EN, ce qui est particuli{\`e}rement utile pour l{'}adaptation de syst{\`e}mes de d{\'e}tection d{'}EN {\`a} de nouveaux domaines."
2008.jeptalnrecital-long.27,R{\\'e}solution de M{\\'e}tonymie des Entit{\\'e}s Nomm{\\'e}es : proposition d{'}une m{\\'e}thode hybride,2008,-1,-1,1,1,10313,caroline brun,Actes de la 15{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous d{\'e}crivons la m{\'e}thode que nous avons d{\'e}velopp{\'e}e pour la r{\'e}solution de m{\'e}tonymie des entit{\'e}s nomm{\'e}es dans le cadre de la comp{\'e}tition SemEval 2007. Afin de r{\'e}soudre les m{\'e}tonymies sur les noms de lieux et noms d{'}organisation, tel que requis pour cette t{\^a}che, nous avons mis au point un syst{\`e}me hybride bas{\'e} sur l{'}utilisation d{'}un analyseur syntaxique robuste combin{\'e} avec une m{\'e}thode d{'}analyse distributionnelle. Nous d{\'e}crivons cette m{\'e}thode ainsi que les r{\'e}sultats obtenus par le syst{\`e}me dans le cadre de la comp{\'e}tition SemEval 2007."
S07-1109,{XRCE}-{M}: A Hybrid System for Named Entity Metonymy Resolution,2007,11,11,1,1,10313,caroline brun,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes our participation to the Metonymy resolution at SemEval 2007 (task #8). In order to perform named entity metonymy resolution, we developed a hybrid system based on a robust parser that extracts deep syntactic relations combined with a non-supervised distributional approach, also relying on the relations extracted by the parser."
2004.jeptalnrecital-long.15,Extraction d{'}information en domaine restreint pour la g{\\'e}n{\\'e}ration multilingue de r{\\'e}sum{\\'e}s cibl{\\'e}s,2004,-1,-1,1,1,10313,caroline brun,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article nous pr{\'e}sentons une application de g{\'e}n{\'e}ration de r{\'e}sum{\'e}s multilingues cibl{\'e}s {\`a} partir de textes d{'}un domaine restreint. Ces r{\'e}sum{\'e}s sont dits cibl{\'e}s car ils sont produits d{'}apr{\`e}s les sp{\'e}cifications d{'}un utilisateur qui doit d{\'e}cider a priori du type de l{'}information qu{'}il souhaite voir appara{\^\i}tre dans le r{\'e}sum{\'e} final. Pour mener {\`a} bien cette t{\^a}che, nous effectuons dans un premier temps l{'}extraction de l{'}information sp{\'e}cifi{\'e}e par l{'}utilisateur. Cette information constitue l{'}entr{\'e}e d{'}un syst{\`e}me de g{\'e}n{\'e}ration multilingue qui produira des r{\'e}sum{\'e}s normalis{\'e}s en trois langues (anglais, fran{\c{c}}ais et espagnol) {\`a} partir d{'}un texte en anglais."
W03-1606,Normalization and Paraphrasing Using Symbolic Methods,2003,6,34,1,1,10313,caroline brun,Proceedings of the Second International Workshop on Paraphrasing,0,We describe an ongoing work in information extraction which is seen as a text normalization task. The normalized representation can be used to detect paraphrases in texts. Normalization and paraphrase detection tasks are built on top of a robust analyzer for English and are exclusively achieved using symbolic methods. Both grammar development rules and information extraction rules are expressed within the same formalism and are developed in an integrated way. The experiment we describe in the paper is evaluated and presents encouraging results.
E03-2003,Controlled Authoring of Biological Experiment Reports,2003,7,2,1,1,10313,caroline brun,Demonstrations,0,"We give a demonstration of an application of XRCE's controlled text authoring system MDA to biological experiment reports. This work is the result of a collaboration between XRCE's Document Content Models team, CNRS's Institut de Biologie Structurale, and Protein'eXpert, a company specialized in biotechnology based in Grenoble. We start with a brief presentation of the partners involved and their respective goals. We then give some technical background on the MDA system. Some novel features of the application are discussed, in particular how MDA can be used for integrating the formalization of an experimental protocol with its associated textual documentation."
2003.jeptalnrecital-poster.14,{MDA}-{XML} : une exp{\\'e}rience de r{\\'e}daction contr{\\^o}l{\\'e}e multilingue bas{\\'e}e sur {XML},2003,-1,-1,2,0,14084,guy lapalme,Actes de la 10{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Nous d{\'e}crivons dans cet article l{'}implantation d{'}un syst{\`e}me de r{\'e}daction contr{\^o}l{\'e}e multilingue dans un environnement XML. Avec ce syst{\`e}me, un auteur r{\'e}dige interactivement un texte se conformant {\`a} des r{\`e}gles de bonne formation aux niveaux du contenu s{\'e}mantique et de la r{\'e}alisation linguistique d{\'e}crites par un sch{\'e}ma XML. Nous discutons les avantages de cette approche ainsi que les difficult{\'e}s rencontr{\'e}es lors du d{\'e}veloppement de ce syst{\`e}me. Nous concluons avec un exemple d{'}application {\`a} une classe de documents pharmaceutiques."
W00-1404,Document structure and multilingual authoring,2000,12,27,1,1,10313,caroline brun,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,"The use of XML-based authoring tools is swiftly becoming a standard in the world of technical documentation. An XML document is a mixture of structure (the tags) and surface (text between the tags). The structure reflects the choices made by the author during the top-down stepwise refinement of the document under control of a DTD grammar. These choices are typically choices of meaning which are independent of the language in which the document is rendered, and can be seen as a kind of interlingua for the class of documents which is modeled by the DTD. Based on this remark, we advocate a radicalization of XML authoring, where the semantic content of the document is accounted for exclusively in terms of choice structures, and where appropriate rendering/realization mechanisms are responsible for producing the surface, possibly in several languages simultaneously. In this view, XML authoring has strong connections to natural language generation and text authoring. We describe the IG (Interaction Grammar) formalism, an extension of DTD's which permits powerful linguistic manipulations, and show its application to the production of multilingual versions of a certain class of pharmaceutical documents."
C00-1020,A Client/Server Architecture for Word Sense Disambiguation,2000,16,12,1,1,10313,caroline brun,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,This paper presents a robust client/server implementation of a word sense disambiguator for English. This system associates a word with its meaning in a given context using dictionaries as tagged corpora in order to extract semantic disambiguation rules. Semantic rules are used as input of a semantic application program which encodes a linguistic strategy in order to select the best disambiguation rule for the word to be disambiguated. The semantic disambiguation rule application program is part of the client/server architecture enabling the processing of large corpora.
P98-1030,Terminology Finite-state Preprocessing for Computational {LFG},1998,4,14,1,1,10313,caroline brun,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"This paper presents a technique to deal with multiword nominal terminology in a computational Lexical Functional Grammar. This method treats multiword terms as single tokens by modifying the preprocessing stage of the grammar (tokenization and morphological analysis), which consists of a cascade of two-level finite-state automata (transducers). We present here how we build the transducers to take terminology into account. We tested the method by parsing a small corpus with the without this treatment of multiword terms. The number of parses and parsing time decrease without affecting the relevance of the results. Moreover, the method improves the perspicuity of the analyses."
C98-1030,Terminology Finite-State Preprocessing for Computational {LFG},1998,4,14,1,1,10313,caroline brun,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"This paper presents a technique to deal with multiword nominal terminology in a computational Lexical Functional Grammar. This method treats multiword terms as single tokens by modifying the preprocessing stage of the grammar (tokenization and morphological analysis), which consists of a cascade of two-level finite-state automata (transducers). We present here how we build the transducers to take terminology into account. We tested the method by parsing a small corpus with the without this treatment of multiword terms. The number of parses and parsing time decrease without affecting the relevance of the results. Moreover, the method improves the perspicuity of the analyses."
