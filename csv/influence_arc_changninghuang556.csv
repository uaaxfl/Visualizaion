A97-1018,C92-1019,0,0.257355,"Missing"
A97-1018,C92-4199,0,0.27213,"Missing"
A97-1018,W93-0305,0,0.0701545,"Missing"
A97-1018,P94-1010,0,0.305441,"Missing"
A97-1018,J96-3004,0,\N,Missing
C02-1010,P00-1050,1,0.887476,"Missing"
C02-1010,C00-2131,0,0.0314432,"Missing"
C02-1010,C92-2101,0,\N,Missing
C02-1010,W00-0726,0,\N,Missing
C02-1010,P93-1004,0,\N,Missing
C02-1010,C96-1078,0,\N,Missing
C02-1010,P00-1015,1,\N,Missing
C02-1010,J97-3002,0,\N,Missing
C02-1010,P98-2221,0,\N,Missing
C02-1010,C98-2216,0,\N,Missing
C02-1012,W98-1120,0,\N,Missing
C02-1012,M98-1004,0,\N,Missing
C02-1012,M98-1012,0,\N,Missing
C02-1012,M98-1014,0,\N,Missing
C02-1012,M98-1021,0,\N,Missing
C02-1012,J92-4003,0,\N,Missing
C02-1012,M98-1017,0,\N,Missing
C10-1079,W05-0622,0,0.0163437,"n the next section, we review related work. In Section 3 we detail key components of our approach. In Section 4, we setup experiments and evaluate the effectiveness of our method. Finally, Section 5 concludes and presents the future work. 2 Related Work Our related work falls into two categories: SRL on news and domain adaption. As for SRL on news, most researchers used the pipelined approach, i.e., dividing the task into several phases such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue and Palmer, 2004; Koomen et al., 2005; Cohn and Blunsom, 2005; Punyakanok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single"
C10-1079,W05-0625,0,0.0276125,"ganized as follows: In the next section, we review related work. In Section 3 we detail key components of our approach. In Section 4, we setup experiments and evaluate the effectiveness of our method. Finally, Section 5 concludes and presents the future work. 2 Related Work Our related work falls into two categories: SRL on news and domain adaption. As for SRL on news, most researchers used the pipelined approach, i.e., dividing the task into several phases such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue and Palmer, 2004; Koomen et al., 2005; Cohn and Blunsom, 2005; Punyakanok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsi"
C10-1079,P09-5003,0,0.0223964,"Missing"
C10-1079,W08-2101,0,0.0134703,"ova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo, 2006; Merlo and Musillo, 2008), or by using Markov Logic Networks (MLN, Richardson and Domingos, 2005) as the learning framework (Riedel and Meza-Ruiz, 2008; Meza-Ruiz and Riedel, 2009). All the above approaches focus on sentences from news articles or other formal documents, and depend on human annotated corpus for training. To our knowledge, little study has been carried out on SRL for news tweets. As for domain adaption, some researchers regarded the out-of-GRPDLQ GDWD DV SULRU NQRZOHGJH´DQGestimated the model parameters by maximizing the posterior under this prior distribution, and successfully applied their app"
C10-1079,N09-1018,0,0.0696354,"their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo, 2006; Merlo and Musillo, 2008), or by using Markov Logic Networks (MLN, Richardson and Domingos, 2005) as the learning framework (Riedel and Meza-Ruiz, 2008; Meza-Ruiz and Riedel, 2009). All the above approaches focus on sentences from news articles or other formal documents, and depend on human annotated corpus for training. To our knowledge, little study has been carried out on SRL for news tweets. As for domain adaption, some researchers regarded the out-of-GRPDLQ GDWD DV SULRU NQRZOHGJH´DQGestimated the model parameters by maximizing the posterior under this prior distribution, and successfully applied their approach to language modeling (Bacchiani and Roark, 2003) and parsing (Roark and Bacchiani, 2003). Daumé III and Marcu (2006) presented a QRYHO IUDPHZRUN E"
C10-1079,N06-2026,0,0.0220547,"anok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo, 2006; Merlo and Musillo, 2008), or by using Markov Logic Networks (MLN, Richardson and Domingos, 2005) as the learning framework (Riedel and Meza-Ruiz, 2008; Meza-Ruiz and Riedel, 2009). All the above approaches focus on sentences from news articles or other formal documents, and depend on human annotated corpus for training. To our knowledge, little study has been carried out on SRL for news tweets. As for domain adaption, some researchers regarded the out-of-GRPDLQ GDWD DV SULRU NQRZOHGJH´DQGestimated the model parameters by maximizing the posterior under this prior distribution, and succ"
C10-1079,J08-2005,0,0.0221116,"eview related work. In Section 3 we detail key components of our approach. In Section 4, we setup experiments and evaluate the effectiveness of our method. Finally, Section 5 concludes and presents the future work. 2 Related Work Our related work falls into two categories: SRL on news and domain adaption. As for SRL on news, most researchers used the pipelined approach, i.e., dividing the task into several phases such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue and Palmer, 2004; Koomen et al., 2005; Cohn and Blunsom, 2005; Punyakanok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo"
C10-1079,W08-2125,0,0.0121536,"beled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo, 2006; Merlo and Musillo, 2008), or by using Markov Logic Networks (MLN, Richardson and Domingos, 2005) as the learning framework (Riedel and Meza-Ruiz, 2008; Meza-Ruiz and Riedel, 2009). All the above approaches focus on sentences from news articles or other formal documents, and depend on human annotated corpus for training. To our knowledge, little study has been carried out on SRL for news tweets. As for domain adaption, some researchers regarded the out-of-GRPDLQ GDWD DV SULRU NQRZOHGJH´DQGestimated the model parameters by maximizing the posterior under this prior distribution, and successfully applied their approach to language modeling (Bacchiani and Roark, 2003) and parsing (Roark and Bacchiani, 2003). Daumé III and Marcu (2006) pre"
C10-1079,N03-1027,0,0.0162277,"005) as the learning framework (Riedel and Meza-Ruiz, 2008; Meza-Ruiz and Riedel, 2009). All the above approaches focus on sentences from news articles or other formal documents, and depend on human annotated corpus for training. To our knowledge, little study has been carried out on SRL for news tweets. As for domain adaption, some researchers regarded the out-of-GRPDLQ GDWD DV SULRU NQRZOHGJH´DQGestimated the model parameters by maximizing the posterior under this prior distribution, and successfully applied their approach to language modeling (Bacchiani and Roark, 2003) and parsing (Roark and Bacchiani, 2003). Daumé III and Marcu (2006) presented a QRYHO IUDPHZRUN E GHILQLQJ D JHQHUDO GoPDLQ´EHWZHHQWKHWUXOLQ-GRPDLQ´DQGWUXO out-of-GRPDLQ´ Unlike existing domain adaption approaches, our method is about adapting SRL system on news domain to the news tweets domain, two domains that differ in writing style but are linked through content similarity. 700 3 Our Method Our method of SRL for news tweets is to train a domain specific SRL on automatically annotated training data as briefed in Section 1. In this section we present details of the five crucial components of our method, i.e.,"
C10-1079,P03-1002,0,0.0814673,"Missing"
C10-1079,W08-2121,0,0.0354669,"Missing"
C10-1079,P05-1073,0,0.0154372,"ction 3 we detail key components of our approach. In Section 4, we setup experiments and evaluate the effectiveness of our method. Finally, Section 5 concludes and presents the future work. 2 Related Work Our related work falls into two categories: SRL on news and domain adaption. As for SRL on news, most researchers used the pipelined approach, i.e., dividing the task into several phases such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue and Palmer, 2004; Koomen et al., 2005; Cohn and Blunsom, 2005; Punyakanok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo, 2006; Merlo and Musill"
C10-1079,J08-2002,0,0.0173197,"mponents of our approach. In Section 4, we setup experiments and evaluate the effectiveness of our method. Finally, Section 5 concludes and presents the future work. 2 Related Work Our related work falls into two categories: SRL on news and domain adaption. As for SRL on news, most researchers used the pipelined approach, i.e., dividing the task into several phases such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue and Palmer, 2004; Koomen et al., 2005; Cohn and Blunsom, 2005; Punyakanok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008). Exceptions to the pipelined approach exist. Màrquez et al. (2005) sequentially labeled the words according to their positions relative to an argument (i.e., inside, outside or at the beginning of it). Carreras et al. (2004) and Surdeanu et al. (2007) jointly labeled all the predicates. Vickrey and Koller(2008) simplified the input sentence by hand-written and machine learnt rules before conducting SRL. Some other approaches simultaneously resolved all the sub-tasks by integrating syntactic parsing and SRL into a single model (Musillo and Merlo, 2006; Merlo and Musillo, 2008), or by using Mar"
C10-1079,W08-2140,0,0.0220689,"Missing"
C10-1079,W04-2415,0,\N,Missing
C10-1079,W05-0628,0,\N,Missing
C10-1079,W04-3212,0,\N,Missing
C10-1079,P00-1056,0,\N,Missing
C10-1079,W06-2303,0,\N,Missing
C94-2153,2002.tmi-tutorials.1,0,0.0520831,"Missing"
C94-2153,1993.tmi-1.17,0,0.0256132,"Missing"
C94-2153,1983.tc-1.13,0,0.0639107,"Missing"
C94-2153,1993.tmi-1.28,0,0.0429899,"Missing"
C94-2153,J92-4001,0,0.0381426,"Missing"
C94-2153,W93-0312,1,0.773869,"Missing"
C94-2153,1993.tmi-1.25,0,0.0915548,"Missing"
C94-2153,1993.tmi-1.5,0,\N,Missing
C94-2200,W93-0312,1,0.747213,"se 1 (p.275). and under ~__ as an example in Sense 1 (p. 151), t~x~. Hence .,~ A01 '~t~_A()I. By checking through all example words and phrases in the way they arc cross-referrt:d, all words that art: t:rossreferred as examples in the dictionary are automatically tagged with appropriate sense numbers. This process pr¢xluced the bulk of MTD entries which form the core of the reasoning system in the atttomatic sense tagging of running Chmest: text (Tong, ct al., 1993). At Step 2 the antomatic tagging o f sense numbers to each word in the definition text proceeds in the ~ m e way as described in Tong, et al. (1993). E f f o r t s are now being made to blend in human judgement to the making e l a m(ne accurate version of MTD-XIANTONG. 2.3. M T D - D U O G O N G N E N G 1232 MTI)-I)UOGONGNHNG is the MTD version of The Mult!funclional I)icli(marv o/' Modern Chittexe Words (lSeng & Zhou, 19019). f)UOGONGN[~NG is the shoitt:ned ltanm: itn tht: oHgimtl Chmt:sc dictionaD. It c,antains ab,.;,it 7,000 most f,-equenfiy used ,:,.,rds ip, everyday Chinese MTD I)).JOGONGNIEN(] ix p r o d n c e d by manually tagging word sense numbers to each 'word in the definition text of evmy sense cnhy undm t:Vel 3 h(.:ad word of"
C94-2200,C92-2070,0,\N,Missing
C98-1001,A88-1019,0,0.0617133,"ral analysis of Chinese baseNPs and a MDL-based algorithm for quasidependency-strength acquisition. The experiments show that the proposed model is more suitable for Chinese baseNP analysis and the proposed MDLbased algorithm is superior to the traditional MLbased algorithm. The paper also discusses the problem of incorporating the linguistic knowledge into the above statistical model. 1. Introduction The concept of baseNP is initially put forward by Church. In English, baseNP is defined as &apos;simple non-recursive noun phrases&apos;, which means that there is no sub-noun-phrases contained in a baseNP[1]. But the definition can not meet the needs in Chinese information retrieval. The noun phrases such as &quot; n ~ ( n a t u r a l ) ~ ( l a n g u a g e ) ~ - ( p r o c e s s ) &quot; , &quot;~-[E~](Asian) _~[l(finance) :f~ })L(crisis)&quot; and &quot; i ~ ( p o l i t i c a l ) ~fJlJ(system) ~(reformation) ~ ( p r o c e s s ) &quot; are critical for information retrieval, but they are not nonrecursive noun phrases. In Chinese, the attribute of noun phrases can be classified into three types, that is restrictive attributes, distinctive attributes and descriptive attributes, among which the restrictive attributes have aggluti"
C98-1001,P94-1052,0,0.0605986,"&quot; y (where y is called the head) or y ~ x (where x is called the head); Otherwise, we say that they have no quasi 2. The quasi-dependency model dependency relation, formulated as x - ~ y and Y -~ x. [Assumption 1 ] In a Chinese baseNP, if two words x and y can constituent dependency relation, then the head is always the post-positon word y, There are two kinds of structural analysis models for Eng!ish noun phrase, that is adjacency model and dependency model. The research of Lauer shows that the dependency model is superior to the adjacency model for structural analysis of English noun phrase[2]. However, there is no model for structural analysis of Chinese baseNP till now. According to the dependency grammar, two constituents can be bound together they are determined to be dependent. The determination of y z y that isx-*y. According to the Definition 1, there is no preposition phrase, verb phrase, locality phrase or (l~l)-structure in a baseNP, so assumption-I is reasonable. On the basis of assumption-l, we put forward the quasi-dependency model for structural analysis of Chinese baseNPs. There are the following 3 kinds of quasidependency-pattern for a tri-word-composed baseNP xyz."
C98-1001,A97-1046,0,0.0222955,"the problem can be described as learning a quasi-dependency-strength set G (abbreviated as model) from the training set. x y z X d wEx X Y In summary, we can compute the belief in which the structure of np~ is S/ using the correspondence between the quasi-dependencypattern and the baseNP structure. The acquisition of quasi-dependency-strength between words is the critical problem. Where, G= {dso. I dsij :ds( w i --->wj ), Vwi , wj e W} x x x Y $44 = W((Xy)Z) S45 = W ( X ( y Z ) ) Zhai Chengxiang puts forward an unsupervised algorithm for acquiring quasi-dependency-strength from noun phrase set[3]. The algorithm is derived from the EM algorithm. Because the algorithm is based on the maximum likelihood (ML) principle, it usually leads to overfitness between the data and the model[4]. For example, given a simple baseNP set N P = { i ~ / p o l i t i c s ~k~]tJ/system ~ / r e f o r m , ~;zff/economics ~k~[~lJ/system ~ / r e f o r m , ~ ( ~ /politics ~ ~[]lJ/system ~ @/revolute , ~ /economics/g~:~IJ/system ~ / r e v o l u t e } , there are sixteen possible models for the training set, among them G4, G7, Gl0 and Gl3 have the best fitness to NP, that is Num(NPIG)=6. However, in the linguistic"
C98-1095,H93-1036,0,\N,Missing
C98-1095,C92-2070,0,\N,Missing
C98-1095,P93-1034,0,\N,Missing
I05-2040,W98-1119,0,0.072442,"tion answering, and machine translation. EDT is an extension of the task of coreference resolution in that in EDT we not only resolve the coreference between mentions but also detect the entities. Each of those entities may have one or more mentions. In the ACE project, there are five types of entities defined in EDT: person (PER), geography political Entity (GPE), organization (ORG), location (LOC), and facility (FAC). Many traditional coreference techniques can be extended to EDT for entity tracking. Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents. Recent research (Soon et al., 2001; Yang et al., 2003; Ng and Cardie, 2002; Ittycherah et al., 2003; Luo et al., 2004) focuses on the use of statistical machine learning methods and tries to resolve references among all kinds of noun phases, including name, nominal and pronoun phrase. One common approach applied by them is to first train a binary statistical model to measure how likely a pair of This work is done while the first author is visiting Microsoft Research Asia. 232 words. However MS"
I05-2040,N01-1008,0,0.201653,"Missing"
I05-2040,N03-2014,0,0.0413118,"Missing"
I05-2040,W04-0705,0,0.0517128,"Missing"
I05-2040,P04-1018,0,0.0896313,"s may have one or more mentions. In the ACE project, there are five types of entities defined in EDT: person (PER), geography political Entity (GPE), organization (ORG), location (LOC), and facility (FAC). Many traditional coreference techniques can be extended to EDT for entity tracking. Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents. Recent research (Soon et al., 2001; Yang et al., 2003; Ng and Cardie, 2002; Ittycherah et al., 2003; Luo et al., 2004) focuses on the use of statistical machine learning methods and tries to resolve references among all kinds of noun phases, including name, nominal and pronoun phrase. One common approach applied by them is to first train a binary statistical model to measure how likely a pair of This work is done while the first author is visiting Microsoft Research Asia. 232 words. However MSRSeg can’t well match the standard of ACE EDT evaluation for either types or boundaries. The difference of the standard of named entity between MSRSeg and ACE cause more than half of the errors for NAME mention detection"
I05-2040,P98-2143,0,0.0235618,"nd machine translation. EDT is an extension of the task of coreference resolution in that in EDT we not only resolve the coreference between mentions but also detect the entities. Each of those entities may have one or more mentions. In the ACE project, there are five types of entities defined in EDT: person (PER), geography political Entity (GPE), organization (ORG), location (LOC), and facility (FAC). Many traditional coreference techniques can be extended to EDT for entity tracking. Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents. Recent research (Soon et al., 2001; Yang et al., 2003; Ng and Cardie, 2002; Ittycherah et al., 2003; Luo et al., 2004) focuses on the use of statistical machine learning methods and tries to resolve references among all kinds of noun phases, including name, nominal and pronoun phrase. One common approach applied by them is to first train a binary statistical model to measure how likely a pair of This work is done while the first author is visiting Microsoft Research Asia. 232 words. However MSRSeg can’t well"
I05-2040,J01-4004,0,0.487285,"the coreference between mentions but also detect the entities. Each of those entities may have one or more mentions. In the ACE project, there are five types of entities defined in EDT: person (PER), geography political Entity (GPE), organization (ORG), location (LOC), and facility (FAC). Many traditional coreference techniques can be extended to EDT for entity tracking. Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents. Recent research (Soon et al., 2001; Yang et al., 2003; Ng and Cardie, 2002; Ittycherah et al., 2003; Luo et al., 2004) focuses on the use of statistical machine learning methods and tries to resolve references among all kinds of noun phases, including name, nominal and pronoun phrase. One common approach applied by them is to first train a binary statistical model to measure how likely a pair of This work is done while the first author is visiting Microsoft Research Asia. 232 words. However MSRSeg can’t well match the standard of ACE EDT evaluation for either types or boundaries. The difference of the standard of named entity"
I05-2040,J95-4004,0,0.112318,"ns is an essential problem for EDT/coreference, there has been relatively less previous research. Ng and Cardie (2002) shows that improving the recall of noun phrase identification can improve the performance of a coreference system. Florian et al. (2004) formulate the mention detection problem as a character-based classification problem. They assign for each character in the text a label, indicating whether it is the start of a specific mention, inside a specific mention, or outside of any mention. In this paper, we propose a unified EDT model based on the Transformation Based Learning (TBL, Brill, 1995) framework for Chinese. The model consists of two sub models: a mention detection model and a coreference model. The first sub-model is used to adapt existing Chinese word segmentation and Named Entity (NE) recognition system to a specific EDT standard. TBL is a widely used machine learning method, but it is the first time it is applied to coreference resolution. In addition, a feedback technique is proposed to further improve the performance of the system. The rest of the paper is organized as follows. In section 2, we propose the unified TBL Chinese EDT model framework. We describe the four"
I05-2040,M95-1005,0,0.472854,"Missing"
I05-2040,N04-1001,0,0.148554,"of allowable templates for rules, and an objective function for learning. mentions corefer; and then followed by a greedy procedure to group the mentions into entities. Mention detection is to find all the named entity, noun or noun phrase, pronoun or pronoun phrase. Therefore, it needs Named Entity Recognition, but not only. Though the detection of entity mentions is an essential problem for EDT/coreference, there has been relatively less previous research. Ng and Cardie (2002) shows that improving the recall of noun phrase identification can improve the performance of a coreference system. Florian et al. (2004) formulate the mention detection problem as a character-based classification problem. They assign for each character in the text a label, indicating whether it is the start of a specific mention, inside a specific mention, or outside of any mention. In this paper, we propose a unified EDT model based on the Transformation Based Learning (TBL, Brill, 1995) framework for Chinese. The model consists of two sub models: a mention detection model and a coreference model. The first sub-model is used to adapt existing Chinese word segmentation and Named Entity (NE) recognition system to a specific EDT"
I05-2040,P03-1023,0,0.098023,"ween mentions but also detect the entities. Each of those entities may have one or more mentions. In the ACE project, there are five types of entities defined in EDT: person (PER), geography political Entity (GPE), organization (ORG), location (LOC), and facility (FAC). Many traditional coreference techniques can be extended to EDT for entity tracking. Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents. Recent research (Soon et al., 2001; Yang et al., 2003; Ng and Cardie, 2002; Ittycherah et al., 2003; Luo et al., 2004) focuses on the use of statistical machine learning methods and tries to resolve references among all kinds of noun phases, including name, nominal and pronoun phrase. One common approach applied by them is to first train a binary statistical model to measure how likely a pair of This work is done while the first author is visiting Microsoft Research Asia. 232 words. However MSRSeg can’t well match the standard of ACE EDT evaluation for either types or boundaries. The difference of the standard of named entity between MSRSeg and"
I05-2040,P04-1059,1,\N,Missing
I05-2040,C98-2138,0,\N,Missing
I05-2040,W03-1701,1,\N,Missing
I05-3001,W03-1721,0,0.061811,"raining material for participants and they serve as a gold standard for evaluating the performance of participant systems. This paper presents a semi-automatic method to detect segmentation errors in a manually annotated Chinese corpus in order to improve its quality further. Especially a segmentation error rate of a gold standard corpus could be obtained with our approach. As we know a particular Chinese character string occurring more than once in a corpus may be assigned different segmentations. Those differences are considered as segmentation inconsistencies by some researchers (Wu, 2003; Chen, 2003). Segmentation consistency is also considered as one of the quality criteria of an annotated Chinese corpus (Sun, 1999). But in order to provide a more clearer description of those segmentation differences we define a new This paper proposes a semi-automatic method to detect segmentation errors in a manually annotated Chinese corpus in order to improve its quality further. A particular Chinese character string occurring more than once in a corpus may be assigned different segmentations during a segmentation process. Based on these differences our approach outputs the segmentation error candida"
I05-3001,W03-1727,0,0.0265932,"provide training material for participants and they serve as a gold standard for evaluating the performance of participant systems. This paper presents a semi-automatic method to detect segmentation errors in a manually annotated Chinese corpus in order to improve its quality further. Especially a segmentation error rate of a gold standard corpus could be obtained with our approach. As we know a particular Chinese character string occurring more than once in a corpus may be assigned different segmentations. Those differences are considered as segmentation inconsistencies by some researchers (Wu, 2003; Chen, 2003). Segmentation consistency is also considered as one of the quality criteria of an annotated Chinese corpus (Sun, 1999). But in order to provide a more clearer description of those segmentation differences we define a new This paper proposes a semi-automatic method to detect segmentation errors in a manually annotated Chinese corpus in order to improve its quality further. A particular Chinese character string occurring more than once in a corpus may be assigned different segmentations during a segmentation process. Based on these differences our approach outputs the segmentation"
I05-3001,P03-1035,1,0.825212,"ntation inconsistency S3. A character string inconsistently between a test data and its training In the close test of Bakeoff1, participants could only use training material from the training data for the particular corpus being testing on. No other material was allowed (Sproat and Emerson, 2003). As we know that the test data should be consistent with the training data based on a general definition of Chinese words. That is if we collect all words seen in the training data and store them into a lexicon, then each word in a test set is either a lexicon word or an OOV (out of vocabulary) word (Gao et al., 2003). In another word, if a character string has been treated as one word, i.e. a lexicon word, in the training data, the same occurrence should be taken in the data. This situation could be divided into the following two cases further: S3.1 A word identified in a training data has been segmented into multiple words in corresponding test data; S3.2 A word identified in a test data has been segmented into multiple words in corresponding training data. Chen (2003) describes inconsistency problem found in cases S1, S2 and S3.1 of PK corpora. For example, he gives the amount of unique text fragments t"
I05-3001,E03-1068,0,0.0259954,"e. Thus a segmentation variation (type) consists of more than one variation instances in corpora C. And a variation instance may include one or more than one tokens. Definition 4: If a variation instance is an incorrect segmentation, it is called an error instance (EI). The definitions of segmentation variation, variation instance and error instance (EI) clearly distinguish those inconsistent components, so we can count the number of segmentation errors (in tokens) exactly. The term variation is also used to express other annotation inconsistency in a corpus by other researchers. For example, Dickinson and Meurers (2003) used variation to describe POS (Part-of-Speech) inconsistency in an annotated corpus. Example 1: Segmentation variations (Bakeoff1 PK corpus): Word &quot;ㄝৠ[deng3-tong2]&quot; is segmented as &quot;ㄝৠ&quot; (equal) and &quot;ㄝৠ&quot; (et al. with). Word &quot;咘䞥[huang2-jin1-zhou1]&quot; is segmented as &quot;咘䞥&quot; (golden week) and &quot; 咘䞥&quot; (gold week). Word &quot;[⋕⥝⏙ބbing1-qing1-yu4-jie2]&quot; is segmented as &quot;( &quot;⋕⥝⏙ބpure and noble) and &quot;( &quot;⋕⥝⏙ބice clear jade clean). In example 1, Words like “ㄝৠ”, “咘䞥  ” and “  ” ⋕ ⥝ ⏙ ބare segmentation variation types. Segmentations “ㄝৠ” and “ ㄝ  ৠ ” are two variation instances of segmentation va"
I05-3001,W03-1719,0,\N,Missing
I05-3001,W03-1726,0,\N,Missing
I08-4009,I05-3017,0,0.301743,"alance the performance on IV and out-ofvocabulary (OOV) words by combining these two methods according to this belief. In this paper, we provide a more detailed evaluation metric of IV and OOV words than Bakeoff to analyze CT method and combination method, which is a typical way to seek such balance. Our evaluation metric shows that CT outperforms dictionary-based (or so called word-based in general) segmentation on both IV and OOV words within Bakeoff 1 Introduction Chinese Word Segmentation (CWS) has been witnessed a prominent progress in the last three Bakeoffs (Sproat and Emerson, 2003), (Emerson, 2005), (Levow, 2006). One of the reasons for this progress is that Bakeoff provides standard corpora and objective metric, which makes the result of each system comparable. Through those evaluations researchers can recognize the advantage and disadvantage of their methods and improve their systems accordingly. However, in the evaluation metric of Bakeoff, only the overall F measure, precision, recall, IV (invocabulary) recall and OOV (out-of-vocabulary) recall are included and such a metric is not sufficient to give a completely measure on the performance, especially when the performance on IV and"
I08-4009,W06-0115,0,0.0526585,"mance on IV and out-ofvocabulary (OOV) words by combining these two methods according to this belief. In this paper, we provide a more detailed evaluation metric of IV and OOV words than Bakeoff to analyze CT method and combination method, which is a typical way to seek such balance. Our evaluation metric shows that CT outperforms dictionary-based (or so called word-based in general) segmentation on both IV and OOV words within Bakeoff 1 Introduction Chinese Word Segmentation (CWS) has been witnessed a prominent progress in the last three Bakeoffs (Sproat and Emerson, 2003), (Emerson, 2005), (Levow, 2006). One of the reasons for this progress is that Bakeoff provides standard corpora and objective metric, which makes the result of each system comparable. Through those evaluations researchers can recognize the advantage and disadvantage of their methods and improve their systems accordingly. However, in the evaluation metric of Bakeoff, only the overall F measure, precision, recall, IV (invocabulary) recall and OOV (out-of-vocabulary) recall are included and such a metric is not sufficient to give a completely measure on the performance, especially when the performance on IV and OOV word segmen"
I08-4009,I05-3025,0,0.136476,"d such a metric is not sufficient to give a completely measure on the performance, especially when the performance on IV and OOV word segmentation need to be evaluated. An important issue is that segmentation based on which, word or character, can yield the better performance on IV words. We give a detailed explanation about this issue as following. Since CWS was firstly treated as a characterbased tagging task (we call it “CT” for short hereafter) in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Relatively to dictionary-based * The work is done when the first author is working in MSRA as an intern. 61 Sixth SIGHAN Workshop on Chinese Language Processing segmentation (we call it “DS” for short hereafter), CT method can achieve a higher accuracy on OOV word recognition and a better performance of segmentation in whole. Thus, CT has drawn more and more attention and became the dominant method in the Bakeoff 2005 and 2006. Although CT has shown its merits in word segmentation task, some researchers still hold the belief that on IV words DS can perform better than CT"
I08-4009,C04-1081,0,0.218383,"(out-of-vocabulary) recall are included and such a metric is not sufficient to give a completely measure on the performance, especially when the performance on IV and OOV word segmentation need to be evaluated. An important issue is that segmentation based on which, word or character, can yield the better performance on IV words. We give a detailed explanation about this issue as following. Since CWS was firstly treated as a characterbased tagging task (we call it “CT” for short hereafter) in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Relatively to dictionary-based * The work is done when the first author is working in MSRA as an intern. 61 Sixth SIGHAN Workshop on Chinese Language Processing segmentation (we call it “DS” for short hereafter), CT method can achieve a higher accuracy on OOV word recognition and a better performance of segmentation in whole. Thus, CT has drawn more and more attention and became the dominant method in the Bakeoff 2005 and 2006. Although CT has shown its merits in word segmentation task, some researchers still hold the belief that"
I08-4009,W03-1719,0,0.0864695,"Many efforts were paid to balance the performance on IV and out-ofvocabulary (OOV) words by combining these two methods according to this belief. In this paper, we provide a more detailed evaluation metric of IV and OOV words than Bakeoff to analyze CT method and combination method, which is a typical way to seek such balance. Our evaluation metric shows that CT outperforms dictionary-based (or so called word-based in general) segmentation on both IV and OOV words within Bakeoff 1 Introduction Chinese Word Segmentation (CWS) has been witnessed a prominent progress in the last three Bakeoffs (Sproat and Emerson, 2003), (Emerson, 2005), (Levow, 2006). One of the reasons for this progress is that Bakeoff provides standard corpora and objective metric, which makes the result of each system comparable. Through those evaluations researchers can recognize the advantage and disadvantage of their methods and improve their systems accordingly. However, in the evaluation metric of Bakeoff, only the overall F measure, precision, recall, IV (invocabulary) recall and OOV (out-of-vocabulary) recall are included and such a metric is not sufficient to give a completely measure on the performance, especially when the perfo"
I08-4009,W02-1815,0,0.285464,"n metric of Bakeoff, only the overall F measure, precision, recall, IV (invocabulary) recall and OOV (out-of-vocabulary) recall are included and such a metric is not sufficient to give a completely measure on the performance, especially when the performance on IV and OOV word segmentation need to be evaluated. An important issue is that segmentation based on which, word or character, can yield the better performance on IV words. We give a detailed explanation about this issue as following. Since CWS was firstly treated as a characterbased tagging task (we call it “CT” for short hereafter) in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Relatively to dictionary-based * The work is done when the first author is working in MSRA as an intern. 61 Sixth SIGHAN Workshop on Chinese Language Processing segmentation (we call it “DS” for short hereafter), CT method can achieve a higher accuracy on OOV word recognition and a better performance of segmentation in whole. Thus, CT has drawn more and more attention and became the dominant method in the Bakeoff 2005 and 2006. Although"
I08-4009,N06-2049,0,0.143627,"Missing"
I08-4009,P06-2123,0,0.0318735,"Missing"
I08-4009,P07-1106,0,0.0534477,"orpora (AS, MSRA and PKU) this pure CT method gets the best result. Even on IV word, this pure CT approach outperforms Zhang‟s CT method and produces comparable results with combination with EIV tags, which shows that pure CT method can perform well on IV words too. Moreover, this character-based tagging approach is more clear and simple than the confidence measure method. Although character-based tagging became mainstream approach in the last two Bakeoffs, it does not mean that word information is valueless in Chinese word segmentation. A word-based perceptron algorithm is proposed recently (Zhang and Clark, 2007), which views Chinese word segmentation task from a new angle instead of character-based tagging and gets comparable results with the best results of Bakeoff. Discussion and Related Works Although the method such as confidence measure can be helpful at some circumstance, our experiment shows that pure character-based tagging (pure CT) can work well with reasonable features and tag set. In (Zhao et al., 2006), an enhanced CRF tag set is proposed to distinguish different positions in the multi-character words when the word length is less than 6. In this method, feature templates are almost the s"
I08-4009,Y06-1012,1,0.910019,"Missing"
I08-4009,I05-3027,0,\N,Missing
I08-4009,W03-1726,0,\N,Missing
I08-4015,C04-1081,0,0.038038,"m of character-based tagging. To further improve the performance of our segmenter, we employ a word-based approach to increase the in-vocabulary (IV) word recall and a post-processing to increase the out-of-vocabulary (OOV) word recall. We participate in the word segmentation closed test on all five corpora and our system achieved four second best and one the fifth in all the five corpora. 1 2 Introduction Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Thus, as a powerful sequence tagging model, CRF became the dominant method in the Bakeoff 2006 (Levow, 2006). In this paper, we improve basic segmenter under the CRF work frame in two aspects, namely IV and OOV identification respectively. We use the result from word-based segmentation to revise the CRF output so that we gain a higher IV word recall. For the OOV part a post-processing rule is proposed to find those OOV words which are wrongly segmented into several fractions. Our 98 Our Word Segmentation System In this section, w"
I08-4015,I05-3027,0,0.117845,"Missing"
I08-4015,I08-4009,1,0.569446,"kept as the final result. Sixth SIGHAN Workshop on Chinese Language Processing The restriction that WT should not be “S” is reasonable because word-based segmentation is incapable to recognize the OOV word and always segments OOV word into single characters. Besides CRF model is better at dealing with OOV word than our word-based segmentation. When WT is “S” it is possible that current word is an OOV word and segmented into single character wrongly by the word-based segmenter, so the CT of the character should be kept under such situation. For more detail about this analysis please refer to (Wang et al., 2008). 2.3 Post-processing rule The rules we described in last subsection is helpful to improve the IV word recall and now we introduce our post-processing rule to improve the OOV recall. Our post-processing rule is designed to deal with one typical type of OOV errors, namely an OOV word wrongly segmented into several parts. In practice many OOV errors belong to such type. The rule is quite simple. When we read a sentence from the result we get by the last step, we also kept the last N sentences in memory, in our system we set N equals to 20. We do this because adjacent sentences are always relevan"
I08-4015,W02-1815,0,0.0312684,"ing Bakeoff. Base on Conditional Random Field (CRF) model, a basic segmenter is designed as a problem of character-based tagging. To further improve the performance of our segmenter, we employ a word-based approach to increase the in-vocabulary (IV) word recall and a post-processing to increase the out-of-vocabulary (OOV) word recall. We participate in the word segmentation closed test on all five corpora and our system achieved four second best and one the fifth in all the five corpora. 1 2 Introduction Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Thus, as a powerful sequence tagging model, CRF became the dominant method in the Bakeoff 2006 (Levow, 2006). In this paper, we improve basic segmenter under the CRF work frame in two aspects, namely IV and OOV identification respectively. We use the result from word-based segmentation to revise the CRF output so that we gain a higher IV word recall. For the OOV part a post-processing rule is proposed to find those OOV words which are w"
I08-4015,W06-0115,0,0.0658766,"sing to increase the out-of-vocabulary (OOV) word recall. We participate in the word segmentation closed test on all five corpora and our system achieved four second best and one the fifth in all the five corpora. 1 2 Introduction Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Thus, as a powerful sequence tagging model, CRF became the dominant method in the Bakeoff 2006 (Levow, 2006). In this paper, we improve basic segmenter under the CRF work frame in two aspects, namely IV and OOV identification respectively. We use the result from word-based segmentation to revise the CRF output so that we gain a higher IV word recall. For the OOV part a post-processing rule is proposed to find those OOV words which are wrongly segmented into several fractions. Our 98 Our Word Segmentation System In this section, we describe our system in more detail. Our system includes three modules: a basic CRF tagger, a word-base segmenter to improve the IV recall and a post-processing rule to imp"
I08-4015,I05-3025,0,0.123213,"prove the performance of our segmenter, we employ a word-based approach to increase the in-vocabulary (IV) word recall and a post-processing to increase the out-of-vocabulary (OOV) word recall. We participate in the word segmentation closed test on all five corpora and our system achieved four second best and one the fifth in all the five corpora. 1 2 Introduction Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al., 2004), (Tseng et al., 2005), (Low et al., 2005), (Zhao et al., 2006). Thus, as a powerful sequence tagging model, CRF became the dominant method in the Bakeoff 2006 (Levow, 2006). In this paper, we improve basic segmenter under the CRF work frame in two aspects, namely IV and OOV identification respectively. We use the result from word-based segmentation to revise the CRF output so that we gain a higher IV word recall. For the OOV part a post-processing rule is proposed to find those OOV words which are wrongly segmented into several fractions. Our 98 Our Word Segmentation System In this section, we describe our system in more detail. Our"
I08-4015,Y06-1012,1,0.911063,"Missing"
I08-4015,W04-1122,0,0.0286115,"quite simple. When we read a sentence from the result we get by the last step, we also kept the last N sentences in memory, in our system we set N equals to 20. We do this because adjacent sentences are always relevant and some named entity likely occurs repeatedly in these sentences. Then, we scan these sentences to find all n-grams (n from 2 to 7) and count their occurrence. If certain n-gram appears more than a threshold and this n-gram never appears in training corpus, the n-gram will be selected as a word candidate. Then, we filter these word candidates according to the context entropy (Luo and Song, 2004). Assume w is a word candidate appears n times in the current sentence and last N sentences and   {a0 , a1 ,..., al } is the set of left side characters of w . Left Context Entropy (LCE) can be defined as: LCE ( w)  1 n C (ai , w) log  n ai C (ai , w) Here, C (ai , w) is the count of concurrence of ai and w . For the Right Context Entropy, the definition is the same except change left into right. Now, we define Context Entropy (CE) of a word candidate w as min( LCE (w), RCE (w)) . The word candidates with CE larger than a predefined 100 threshold will be bind as a whole word in test corp"
I08-4015,N06-2049,0,\N,Missing
J05-4005,J96-1002,0,0.0113923,"Missing"
J05-4005,J95-4004,0,0.0136868,"ecall rates (Wu 2003). Therefore, we do not assume that an application-independent universal word segmentation standard exists. We argue instead for the existence of multiple segmentation standards, each for a specific application. It is undesirable to develop a set of application-specific segmenters. A better solution would be to develop a generic segmenter with customizable output that is able to provide alternative segmentation units according to the specification that is either predefined or implied in the application data. To achieve this, we present a transformation-based learning (TBL; Brill 1995) method, to be described in Section 6. We implement the pragmatic approach to Chinese word segmentation in an adaptive Chinese word segmenter called MSRSeg. It consists of two components: (1) a generic segmenter that is based on the linear mixture model framework of word breaking and unknown word detection and that can adapt to domain-specific vocabularies, and (2) a set of output adaptors for adapting the output of (1) to different application-specific standards. Evaluation on five test sets with different standards shows that the adaptive system achieves state-of-the-art performance on all t"
J05-4005,O97-4005,0,0.0121829,"mance of these methods thus depends to a large degree upon the coverage of the dictionary, which unfortunately may never be complete because new words appear constantly. Therefore, in addition to the dictionary, many systems also contain special components for unknown word identification. 533 Computational Linguistics Volume 31, Number 4 In particular, statistical methods have been widely applied because they use a probabilistic or cost-based scoring mechanism rather than a dictionary to segment the text. These methods have three drawbacks. First, some of these methods (e.g., Lin et al. 1993; Chang and Su 1997) identify OOV (out-of-vocabulary) words without identifying their types. For instance, one might identify a string as a unit but fail to identify that it is a person name. Second, many current statistical methods do not incorporate linguistic knowledge effectively into segmentation. For example, Teahan et al. (2000) and Dai et al. (1999) do not use any linguistic knowledge. Thus, the identified OOV words are likely to be linguistically implausible, and consequently, additional manual checking is needed for some subsequent tasks such as parsing. Third, in many current segmenters, OOV identifica"
J05-4005,W03-1721,0,0.0815062,"ir types. For instance, one might identify a string as a unit but fail to identify that it is a person name. Second, many current statistical methods do not incorporate linguistic knowledge effectively into segmentation. For example, Teahan et al. (2000) and Dai et al. (1999) do not use any linguistic knowledge. Thus, the identified OOV words are likely to be linguistically implausible, and consequently, additional manual checking is needed for some subsequent tasks such as parsing. Third, in many current segmenters, OOV identification is considered a separate process from segmentation (e.g., Chen 2003; Wu and Jiang 2000; Chen and Bai 1998). For instance, Chen (2003) assumes that OOV words are usually two or more characters long and are often segmented into single characters. He then uses different components to detect OOV words of different types in a cascaded manner after the basic word segmentation. We believe that the identification of OOV words should not be treated as a problem separate from word segmentation. We propose a unified approach that solves both problems simultaneously. A previous work along this line is Sproat et al. (1996), which is based on weighted finite-state transduc"
J05-4005,O98-3002,0,0.0319127,"ght identify a string as a unit but fail to identify that it is a person name. Second, many current statistical methods do not incorporate linguistic knowledge effectively into segmentation. For example, Teahan et al. (2000) and Dai et al. (1999) do not use any linguistic knowledge. Thus, the identified OOV words are likely to be linguistically implausible, and consequently, additional manual checking is needed for some subsequent tasks such as parsing. Third, in many current segmenters, OOV identification is considered a separate process from segmentation (e.g., Chen 2003; Wu and Jiang 2000; Chen and Bai 1998). For instance, Chen (2003) assumes that OOV words are usually two or more characters long and are often segmented into single characters. He then uses different components to detect OOV words of different types in a cascaded manner after the basic word segmentation. We believe that the identification of OOV words should not be treated as a problem separate from word segmentation. We propose a unified approach that solves both problems simultaneously. A previous work along this line is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs). Our approach is similarly m"
J05-4005,W02-1001,0,0.00419524,"d feature value f (s, wR )), and decreases the parameter values whose models were “overestimated” (i.e., f (s, w) is larger than f (s, wR )). Empirically, the sequence of these updates, when iterated over all training samples, provides a reasonable approximation to descending the gradient with respect to the original loss function of Equation (5). Although this method cannot guarantee a globally optimal solution, it is chosen for our modeling because of its efficiency and because it achieved the best results in our experiments. The algorithm is similar to the perceptron algorithm described in Collins (2002). The key difference is that, instead of using the delta rule of Equation (8) (as shown in line 5 of Figure 4), Collins (2002) updates parameters using the rule: λdt+1 ← λtd + fd (wRi ) − fd (wi ). Our pilot study shows that our algorithm achieves slightly better results. 4.3 Discussions on Robustness The training methods described in Section 4.2 aim at minimizing errors in a training set. But test sets can be different. The robustness issue concerns how well the minimal error rate in the training set preserves in the test set. According to Dudewicz and Mishra (1988), the MSE function in gener"
J05-4005,P00-1073,1,0.796307,"hose words whose probability of appearing in a new document is lower than general lexical words. Let Pi (k) be the probability of word wi that occurs k times in a document. In our experiments, we assume that P(NW |wi ) can be approximated by the probability of wi occurring less than K times in a new document: P(NW |wi ) ≈ K1  Pi (k), (14) k=0 where the constant K (7 in our experiments) is dependent on the size of the document: The larger the document, the larger the value. Pi (k) can be estimated using several term ¨ distribution models (Chapter 15.3 in Manning and Schutze [1999]). Following Gao and Lee (2000), we use K-Mixture (Katz 1996) which estimates Pi (k) as Pi (k) = (1 − a)δk, 0 + a ( β )k , β+1 β+1 (15) where δk,0 =1 if k=0; 0, otherwise. α and β are parameters that can be fit using the observed mean λ and the observed inverse document frequency IDF as follows: λ= cf , IDF = log N , N df β = λ × 2IDF − 1 = cf − df , and a = λ , β df (16) where cf is the total number of occurrence of word wi in training data, df is the number of documents in training data in which wi occurs, and N is the total number of documents. In our implementation, the training data contain approximately 40,000 documen"
J05-4005,O01-2002,1,0.812473,"Missing"
J05-4005,P03-1035,1,0.48854,"Missing"
J05-4005,P04-1059,1,0.834246,"tions. This inspires the development of an adaptive Chinese word segmenter. However, most of the previous segmenters have been developed according to a standard that assumes a single correct segmentation. The only adaptive system, to the best of our knowledge, is the customizable segmenter described in Wu (2003), in which the display of the segmentation output can be customized by users.3 The adaptation method we will describe in Section 6 can be viewed as an improved version in that the adaptation rules (or transformations) are acquired automatically from application data via the TBL method (Gao et al. 2004). Though the use of TBL for Chinese word segmentation is not new (see Palmer [1997]; Hockenmaier and Brew [1998]), none of the previous work is aimed at standards adaptation. 2.4 Evaluation The performance of Chinese word segmenters is generally reported in terms of precision and recall. However, a comparison across systems could be very difficult for two reasons. First, the “correct” segmentation is not clearly defined. It is common that for a given sentence there are multiple plausible word segmentations. As shown in Sproat et al. (1996), the rate of agreement between two human judges is les"
J05-4005,H05-1027,1,0.678464,"ss function. We will present in turn the loss function and the optimization algorithm. 4.2.1 Loss Function. Assume that we can measure the number of segmentation errors in w by comparing it with a reference segmentation wR using an error function Er(wR , w) (i.e., editing distance, in our case). The training criterion that directly minimizes the segmentation errors over the training data is λ ∗ = arg min λ  Er(wRi , w(si , λ )), (4) i=1...M where w(si , λ ) is the segmentation determined by Equation (3), where it is denoted as w∗ . Equation (4) is referred to as the minimum sample risk (MSR; Gao et al. 2005) criterion hereafter. Notice that without knowing the “true” distribution of the data, the best λ can be chosen approximately based on training samples. This is known as the principle of empirical risk minimization (ERM; Vapnik 1998): If the segmenter were trained using exactly the MSR criterion, it would converge to a Bayes risk performance (minimal error rate) as the training size goes to infinity. However, Er(.) is a piecewise constant function of the model parameter λ , and thus a poor candidate for optimization by any simple gradient-type numerical search. For example, the gradient cannot"
J05-4005,O97-4003,0,0.051105,"Approach Figure 2 Taxonomy of morphologically derived words (MDWs) in MSRSeg. 3.2 MSR Standard The taxonomy employed here has been specified in detail in the MSR standard. There are two general guidelines for the development of the standard: 1. The standard should be applicable to a wide variety of NLP tasks, of which some representative examples are Chinese text input, IR, TTS, ASR, and MT. 2. The standard should be compatible with existing standards, of which representative examples are the Chinese NE standards in ET/ER-99, the Mainland standard (GB/T), Taiwan’s ROCLING standard (CNS14366; Huang et al. 1997), and the UPenn Chinese Treebank (Xia 1999), as much as possible.4 We are seeking a standard that is “linguistically felicitous, computationally feasible, and [ensures] data uniformity” (Huang et al. 1997; Sproat and Shih 2002). The MSR standard consists of a set of specific rules that aims at unambiguously determining the word segmentation of a Chinese sentence, given a reference lexicon. The development of the standard is an iterative procedure, interacting with the development of a gold test set (which we will describe in the next section). We begin with an initial set of 4 MET is a Chinese"
J05-4005,W03-1701,1,0.693218,"hods use metrics that are based on statistical features such as mutual information, term frequency, and their variants. They require a reasonably large training corpus. The new words detected are mostly proper nouns and other relatively frequent words. Unfortunately, new words, under our definition of the term, may not be detected.  534  ^x Gao et al. Chinese Word Segmentation: A Pragmatic Approach Fewer methods have been proposed for an on-line approach, and that is the focus of this article. Some recent advances in on-line NWI explore the use of machine learning approaches. For example, Li et al. (2003) define NWI as a binary classification problem and use support vector machines (SVM) to combine various linguistically motivated features to determine whether a Chinese character sequence is a word. Our method is an extension of that of Li et al. in that NWI is not a stand-alone process in our system but an integral part of word segmentation. We shall show experimentally the benefit of the integration in Section 5.5. 2.3 Standards Adaptation As described earlier, while Chinese words are supposed to be well-defined, unambiguous, and static linguistic entities, we are more concerned with segment"
J05-4005,O93-1004,0,0.0610786,"1994). The performance of these methods thus depends to a large degree upon the coverage of the dictionary, which unfortunately may never be complete because new words appear constantly. Therefore, in addition to the dictionary, many systems also contain special components for unknown word identification. 533 Computational Linguistics Volume 31, Number 4 In particular, statistical methods have been widely applied because they use a probabilistic or cost-based scoring mechanism rather than a dictionary to segment the text. These methods have three drawbacks. First, some of these methods (e.g., Lin et al. 1993; Chang and Su 1997) identify OOV (out-of-vocabulary) words without identifying their types. For instance, one might identify a string as a unit but fail to identify that it is a person name. Second, many current statistical methods do not incorporate linguistic knowledge effectively into segmentation. For example, Teahan et al. (2000) and Dai et al. (1999) do not use any linguistic knowledge. Thus, the identified OOV words are likely to be linguistically implausible, and consequently, additional manual checking is needed for some subsequent tasks such as parsing. Third, in many current segmen"
J05-4005,P03-1021,0,0.00297496,"t the source–channel models are the rationale behind our system, e.g., the decoding process described in Section 5.6 follows the framework. Linear models are just another representation based on the optimization algorithm of class model weights. 4.2 Linear Models The framework of linear models is derived from linear discriminant functions widely used for pattern classification (Duda, Hart, and Stork 2001) and has been recently introduced into NLP tasks by Collins and Duffy (2001). It is also related to (log-)linear models described in Berger, Della Pietra, and Della Pietra (1996), Xue (2003); Och (2003), and Peng, Feng, and McCallum (2004). We use the following notation in the rest of the article. r r 546 Training data are a set of example input/output pairs. In Chinese word segmentation, we have training samples {si , wRi }, for i = 1 . . . M, where each si is an input Chinese character sequence and each wRi is the reference segmentation (i.e., word class sequence) of si . We assume a set of D + 1 features fd (s, w), for d = 0 . . . D. The features are arbitrary functions that map (s, w) to real values. Using vector notation, we have f(s, w) ∈ D+1 , where f(s, w) = {f0 (s, w), f1 (s, w), ."
J05-4005,P97-1041,0,0.0213808,"Missing"
J05-4005,C04-1081,0,0.204751,"still informative. 568 Gao et al. Chinese Word Segmentation: A Pragmatic Approach Table 22 Cross-system comparison results. # OAS Segmenters LN PN ON errors P R F P R F P R F 63 49 20 7 .935 .854 .767 .876 .442 .720 .736 .864 .600 .782 .752 .870 .907 .945 .780 .830 .744 .781 .787 .897 .818 .856 .784 .862 .642 .713 .817 .799 .469 .131 .216 .617 .600 .222 .342 .696 MSWS LCWS PBWS MSRSeg Table 23 Comparisons against other segmenters: In Column 1, SXX indicates participating sites in the 1st SIGHAN International Chinese Word Segmentation Bakeoff, and CRFs indicates the word segmenter reported in (Peng et al. 2004). In Columns 2 to 5, entries contain the F-measure of each segmenter on different open runs, with the best performance in bold. Column Site-Avg is the average F-measure over the data sets on which a segmenter reported results of open runs, where a bolded entry indicates the segmenter outperforms MSRSeg. Column Our-Avg is the average F-measure of MSRSeg over the same data sets, where a bolded entry indicates that MSRSeg outperforms the other segmenter. ASo S01 S02 S03 S04 S05 S06 S07 S08 S09 S10 S11 S12 CRFs MSRSeg ASc .872 CTBo CTBc .881 .912 .829 .881 .874 .942 .945 HKo HKc PKo PKc Site-Avg O"
J05-4005,W03-1719,0,0.120733,"into the first three: descriptive, expository, and narrative. Practical writing is just an umbrella term for practical writing such as notes, letter, e-mails, and marriage announcements. 541 Computational Linguistics Volume 31, Number 4 Figure 3 Fragments of the MSR gold test set. Therefore, we evaluate MSRSeg using five corpora, each corresponding to a different standard, and consistent train–test splits, as shown in Table 4. MSR is described in previous sections, and the other four are standards used in SIGHAN’s First International Chinese Word Segmentation Bakeoff (or Bakeoff for brevity) (Sproat and Emerson 2003). In the Bakeoff corpora, OOV is defined as the set of words in the test corpus not occurring in the training corpus. In experiments, we always consider the following adaptation paradigm. Suppose we have a general predefined standard according to which we create a large amount of training data. We then develop a generic word segmenter. Whenever we deploy the segmenter for any application, we customize the output of the segmenter according to an application-specific standard that can be partially acquired from a given small amount of application data (called adaptation data). The MSR standard d"
J05-4005,J96-3004,0,0.39825,"on is considered a separate process from segmentation (e.g., Chen 2003; Wu and Jiang 2000; Chen and Bai 1998). For instance, Chen (2003) assumes that OOV words are usually two or more characters long and are often segmented into single characters. He then uses different components to detect OOV words of different types in a cascaded manner after the basic word segmentation. We believe that the identification of OOV words should not be treated as a problem separate from word segmentation. We propose a unified approach that solves both problems simultaneously. A previous work along this line is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs). Our approach is similarly motivated but is based on a different mechanism: linear mixture models. As we shall see, the models provide a more flexible framework for incorporating various kinds of lexical and statistical information. Many types of OOV words that are not covered in Sproat’s system can be dealt with in our system. The linear models we used are originally derived from linear discriminant functions widely used for pattern classification (Duda, Hart, and Stork 2001) and have been recently introduced into NLP tasks by Colli"
J05-4005,C02-1012,1,0.213291,"Missing"
J05-4005,O03-5001,1,0.841659,"Missing"
J05-4005,W01-0512,0,0.00770431,"Missing"
J05-4005,W00-1207,1,0.539293,"or instance, one might identify a string as a unit but fail to identify that it is a person name. Second, many current statistical methods do not incorporate linguistic knowledge effectively into segmentation. For example, Teahan et al. (2000) and Dai et al. (1999) do not use any linguistic knowledge. Thus, the identified OOV words are likely to be linguistically implausible, and consequently, additional manual checking is needed for some subsequent tasks such as parsing. Third, in many current segmenters, OOV identification is considered a separate process from segmentation (e.g., Chen 2003; Wu and Jiang 2000; Chen and Bai 1998). For instance, Chen (2003) assumes that OOV words are usually two or more characters long and are often segmented into single characters. He then uses different components to detect OOV words of different types in a cascaded manner after the basic word segmentation. We believe that the identification of OOV words should not be treated as a problem separate from word segmentation. We propose a unified approach that solves both problems simultaneously. A previous work along this line is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs). Our app"
J05-4005,O03-4001,1,0.946382,"ion. Word breaking refers to the process of segmenting known words that are predefined in a lexicon. Word segmentation refers to the process of both lexicon word segmentation and unknown word detection. 2 New words in this article refer to out-of-vocabulary words that are neither recognized as named entities or factoids nor derived by morphological rules. These words are mostly domain-specific and/or time-sensitive (see Section 5.5 for details). 532 Gao et al. Chinese Word Segmentation: A Pragmatic Approach formation retrieval (IR) systems prefer shorter “words” to obtain higher recall rates (Wu 2003). Therefore, we do not assume that an application-independent universal word segmentation standard exists. We argue instead for the existence of multiple segmentation standards, each for a specific application. It is undesirable to develop a set of application-specific segmenters. A better solution would be to develop a generic segmenter with customizable output that is able to provide alternative segmentation units according to the specification that is either predefined or implied in the application data. To achieve this, we present a transformation-based learning (TBL; Brill 1995) method, t"
J05-4005,O03-4002,0,0.770183,"ear mixture models. As we shall see, the models provide a more flexible framework for incorporating various kinds of lexical and statistical information. Many types of OOV words that are not covered in Sproat’s system can be dealt with in our system. The linear models we used are originally derived from linear discriminant functions widely used for pattern classification (Duda, Hart, and Stork 2001) and have been recently introduced into NLP tasks by Collins and Duffy (2001). Other frameworks of Chinese word segmentation, which are similar to the linear models, include maximum entropy models (Xue 2003) and conditional random fields (Peng, Feng, and McCallum 2004). They also use a unified approach to word breaking and OOV identification. 2.2 More on New Word Identification In this article, we use the term “new words” to refer to OOV words other than named entities, factoids, and morphologically derived words. “New words” are mostly domain‘cellular’) and time-sensitive political, social, or cultural specific terms (e.g., ‘Three Links’; ‘SARS’). There have been two general approaches terms (e.g., to NWI. The first is to acquire new words from large corpora off-line and put them into a dictiona"
J05-4005,W03-1718,1,\N,Missing
J05-4005,P98-2206,0,\N,Missing
J05-4005,C98-2201,0,\N,Missing
J05-4005,J00-3004,0,\N,Missing
J05-4005,W03-1726,0,\N,Missing
O01-2001,C96-2098,0,0.0606194,"Missing"
O01-2001,A94-1006,0,0.0478751,"Missing"
O01-2001,J94-4003,0,0.476138,"Missing"
O01-2001,P95-1032,0,0.0641052,"Missing"
O01-2001,P98-1069,0,0.0613736,"Missing"
O01-2001,J96-1001,0,\N,Missing
O01-2001,1994.amta-1.26,0,\N,Missing
O01-2001,C96-1040,0,\N,Missing
O01-2001,W97-0119,0,\N,Missing
O01-2001,J94-1002,0,\N,Missing
O01-2001,J93-2004,0,\N,Missing
O01-2001,W96-0208,0,\N,Missing
O01-2001,C90-2036,0,\N,Missing
O01-2001,J93-2003,0,\N,Missing
O01-2001,1995.tmi-1.28,0,\N,Missing
O01-2001,C94-2119,0,\N,Missing
O01-2001,C98-1066,0,\N,Missing
O01-2001,W00-1211,0,\N,Missing
O01-2001,C92-2101,0,\N,Missing
O01-2001,A88-1019,0,\N,Missing
O01-2001,C94-1079,0,\N,Missing
O01-2001,C00-2131,0,\N,Missing
O01-2001,W00-1212,1,\N,Missing
O01-2001,P98-2212,0,\N,Missing
O01-2001,C98-2207,0,\N,Missing
O01-2001,J90-2002,0,\N,Missing
O01-2001,P95-1026,0,\N,Missing
O01-2001,P95-1033,0,\N,Missing
O01-2001,P93-1001,0,\N,Missing
O01-2001,P91-1022,0,\N,Missing
O01-2001,W99-0617,0,\N,Missing
O01-2001,J92-4003,0,\N,Missing
O01-2001,P91-1037,0,\N,Missing
O01-2001,J97-2004,0,\N,Missing
O01-2001,J97-3002,0,\N,Missing
O01-2001,P00-1050,0,\N,Missing
O01-2001,P98-2127,0,\N,Missing
O01-2001,C98-2122,0,\N,Missing
O01-2001,P98-2139,0,\N,Missing
O01-2001,C98-2134,0,\N,Missing
O01-2001,W95-0106,0,\N,Missing
O01-2001,P93-1024,0,\N,Missing
O01-2004,P91-1022,0,0.082527,"Missing"
O01-2004,P93-1001,0,0.0434082,"Missing"
O01-2004,C94-2119,0,0.0380266,"Missing"
O01-2004,W09-4205,0,0.062288,"Missing"
O01-2004,C92-2101,0,0.061944,"Missing"
O01-2004,C00-1075,0,0.0265163,"Missing"
O01-2004,J93-2004,0,0.0354613,"Missing"
O01-2004,P98-2139,0,0.0592392,"Missing"
O01-2004,1997.tmi-1.13,0,0.107408,"Missing"
O01-2004,C96-1040,0,0.0598061,"Missing"
O01-2004,P98-2212,0,0.0382456,"Missing"
O01-2004,1993.tmi-1.25,0,0.14908,"Missing"
O01-2004,C00-2131,0,0.0446209,"Missing"
O01-2004,P95-1033,0,0.55593,"Missing"
O01-2004,J97-3002,0,0.330471,"Missing"
O01-2004,W00-1211,1,0.841686,"Missing"
O01-2004,W97-0119,0,\N,Missing
O01-2004,J93-2003,0,\N,Missing
O01-2004,1995.tmi-1.28,0,\N,Missing
O01-2004,J97-2004,0,\N,Missing
O01-2004,P00-1050,0,\N,Missing
O01-2004,W95-0106,0,\N,Missing
O05-2004,C02-1054,0,0.0567029,"Missing"
O05-2004,P00-1033,1,0.895818,"Missing"
O05-2004,J93-2004,0,0.027591,"Missing"
O05-2004,xia-etal-2000-developing,0,0.0905444,"Missing"
O05-2004,W04-1107,1,\N,Missing
O05-2004,P01-1005,0,\N,Missing
O06-3002,W00-1201,0,0.0600264,"Missing"
O06-3002,P02-1055,0,0.0427147,"Missing"
O06-3002,P80-1024,0,0.683241,"Missing"
O06-3002,W04-1107,1,0.822826,"Missing"
O06-3002,W01-0706,0,0.0366842,"Missing"
O06-3002,W00-0726,0,0.0816367,"Missing"
O06-3002,W00-0730,0,0.453634,"Missing"
O06-3002,P01-1043,0,0.0456828,"Missing"
O06-3002,W00-0729,0,0.0603513,"Missing"
O06-3002,J93-2004,0,0.0278933,"Missing"
O06-3002,W03-1025,0,0.0251577,"Missing"
O06-3002,W00-0731,0,0.060197,"Missing"
O06-3002,P03-1063,0,0.0411775,"Missing"
O06-3002,W95-0107,0,0.0593771,"Missing"
O06-3002,W96-0213,0,0.288989,"Missing"
O06-3002,xia-etal-2000-developing,0,0.0581492,"Missing"
O06-3002,P00-1015,1,0.895631,"Missing"
O06-3002,J96-1002,0,\N,Missing
P00-1015,J93-2004,0,0.0517215,"Missing"
P00-1015,A88-1019,0,\N,Missing
P00-1015,P99-1009,0,\N,Missing
P00-1015,P98-1034,0,\N,Missing
P00-1015,C98-1034,0,\N,Missing
P00-1015,P98-1010,0,\N,Missing
P00-1015,C98-1010,0,\N,Missing
P00-1032,J96-1003,0,\N,Missing
P00-1033,J90-4003,0,\N,Missing
P00-1033,C92-4211,1,\N,Missing
P00-1033,C86-1046,0,\N,Missing
P00-1033,C94-2153,1,\N,Missing
P00-1033,H94-1020,0,\N,Missing
P00-1067,P93-1002,0,0.0604293,"Missing"
P00-1067,P91-1022,0,0.0208785,"Missing"
P00-1067,W93-0301,0,0.0648142,"Missing"
P00-1067,J93-2003,0,0.00789834,"Missing"
P00-1067,P93-1001,0,\N,Missing
P03-1035,O93-1004,0,0.434107,"ianfeng Li, Wenfeng Yang and Xiaodan Zhu for their help with evaluating our system. a large degree upon the coverage of the dictionary, which unfortunately may never be complete because new words appear constantly. Therefore, in addition to the dictionary, many systems also contain special components for unknown word identification. In particular, statistical methods have been widely applied because they utilize a probabilistic or cost-based scoring mechanism, instead of the dictionary, to segment the text. These methods however, suffer from three drawbacks. First, some of these methods (e.g. Lin et al., 1993) identify unknown words without identifying their types. For instance, one would identify a string as a unit, but not identify whether it is a person name. This is not always sufficient. Second, the probabilistic models used in these methods (e.g. Teahan et al., 2000) are trained on a segmented corpus which is not always available. Third, the identified unknown words are likely to be linguistically implausible (e.g. Dai et al., 1999), and additional manual checking is needed for some subsequent tasks such as parsing. We believe that the identification of unknown words should not be defined as"
P03-1035,J96-3004,0,0.676541,"me. This is not always sufficient. Second, the probabilistic models used in these methods (e.g. Teahan et al., 2000) are trained on a segmented corpus which is not always available. Third, the identified unknown words are likely to be linguistically implausible (e.g. Dai et al., 1999), and additional manual checking is needed for some subsequent tasks such as parsing. We believe that the identification of unknown words should not be defined as a separate problem from word segmentation. These two problems are better solved simultaneously in a unified approach. One example of such approaches is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs). Our approach is motivated by the same inspiration, but is based on a different mechanism: the improved source-channel models. As we shall see, these models provide a more flexible framework to incorporate various kinds of lexical and statistical information. Some types of unknown words that are not discussed in Sproat’s system are dealt with in our system. 3 processed in different ways in our system. For example, the plausible word segmentation for the sentence in Figure 1(a) is as shown. Figure 1(b) is the output of our system, whe"
P03-1035,J00-3004,0,0.0796475,"tems also contain special components for unknown word identification. In particular, statistical methods have been widely applied because they utilize a probabilistic or cost-based scoring mechanism, instead of the dictionary, to segment the text. These methods however, suffer from three drawbacks. First, some of these methods (e.g. Lin et al., 1993) identify unknown words without identifying their types. For instance, one would identify a string as a unit, but not identify whether it is a person name. This is not always sufficient. Second, the probabilistic models used in these methods (e.g. Teahan et al., 2000) are trained on a segmented corpus which is not always available. Third, the identified unknown words are likely to be linguistically implausible (e.g. Dai et al., 1999), and additional manual checking is needed for some subsequent tasks such as parsing. We believe that the identification of unknown words should not be defined as a separate problem from word segmentation. These two problems are better solved simultaneously in a unified approach. One example of such approaches is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs). Our approach is motivated by the s"
P03-1035,C02-1012,1,\N,Missing
P04-1059,J95-4004,0,0.0498692,"ment in this field shows that, problem is handled in this framework. We explore in addition to ambiguity resolution and unknown several features and describe how to create training word detection, the usefulness of a Chinese word data by sampling. We evaluate the performance of segmenter also depends crucially on its ability to our segmentation system using an annotated test set, adapt to different domains of texts and different where new words are simulated by sampling. We segmentation standards. then describe a transformation-based learning (TBL, The need of adaptation involves two research Brill, 1995) method that is used to adapt our system issues that we will address in this paper. The first is to different segmentation standards. We compare new word detection. Different domains/applications the adaptive system to other state-of-the-art systems may have different vocabularies which contain new using four test sets in the SIGHAN’s First Internawords/terms that are not available in a general tional Chinese Word Segmentation Bakeoff, each of dictionary. In this paper, new words refer to OOV which is constructed according to a different segwords other than named entities, factoids and mor- me"
P04-1059,P00-1073,1,0.894198,"ose words whose probability to appear in a new document is lower than general lexical words. Let Pi(k) be the probability of word wi that occurs k times in a document. In our experiments, we assume that P(NW|wi) can be approximated by the probability of wi occurring less than K times in a new document: K −1 P ( NW |wi ) ≈ ∑ Pi (k ) , (5) k =0 where the constant K is dependent on the size of the document: The larger the document, the larger the value. Pi(k) can be estimated using several term distribution models (see Chapter 15.3 in Manning and Schütze, 1999). Following the empirical study in (Gao and Lee, 2000), we use K-Mixture (Katz, 1996) which estimate Pi(k) as α β k ( ) , (6) β +1 β +1 where δk,0=1 if k=0, 0 otherwise. α and β are parameters that can be fit using the observed mean λ Pi (k ) = (1 − α )δ k , 0 + and the observed inverse document frequency IDF as follow: cf N λ = , IDF = log , N df λ cf − df , and α = , β = λ × 2 IDF − 1 = df β where cf is the total number of occurrence of word wi in training data, df is the number of documents in training data that wi occurs in, and N is the total number of documents. In our implementation, the training data contain approximately 40 thousand docu"
P04-1059,P03-1035,1,0.63764,"subsets of the AS training set of different sizes, and observed the same trend. However, even with a much smaller adaptation data set (e.g. 250K), we still outperform the best bakeoff results. 6 Related Work Many methods of Chinese word segmentation have been proposed (See Wu and Tseng, 1993; Sproat and Shih, 2001 for reviews). However, it is difficult to compare systems due to the fact that there is no widely accepted standard. There has been less work on dealing with NWI and standard adaptation. All feature functions in Figure 1, except the NW function, are derived from models presented in (Gao et al., 2003). The linear models are similar to what was presented in Collins and Duffy (2001). An alternative to linear models is the log-linear models suggested by Och (2003). See Collins (2002) for a comparison of these approaches. The features for NWI were studied in Wu & Jiang (2000) and Li et al. (2004). The use of sampling was proposed in Della Pietra et al. (1997) and Rosenfeld et al. (2001). There is also a related work on this line in Japanese (Uchimoto et al., 2001). A detailed discussion on differences among the four Bakeoff standards is presented in Wu (2003), which also proposes an adaptive s"
P04-1059,P03-1021,0,0.0866914,"fferent ways (e.g. name entity models are n-gram models trained on 2 corpora whereas factoid models use derivation rules and have binary values). The dynamic value ranges of different class models can be so different that it is improper to combine all models through simple multiplication as Equation (1). In this study we use linear models. The method is derived from linear discriminant functions widely used for pattern classification (Duda et al., 2001), and has been recently introduced into NLP tasks by Collins and Duffy (2001). It is also related to loglinear models for machine translation (Och, 2003). In this framework, we have a set of M+1 feature functions fi(S,W), i = 0,…,M. They are derived from the context model (i.e. f0(W)) and M class models, each for one word class, as shown in Figure 1: For probabilistic models such as the context model or person name model, the feature functions are defined as the negative logarithm of the corresponding probabilistic models. For each feature function, there is a model parameter λi. The best word segmentation W* is determined by the decision rule as M W * = arg max Score(λ0M , S ,W ) = arg max ∑ λi f i ( S ,W ) (2) W W i =0 Below we describe how"
P04-1059,P97-1041,0,0.593397,"Missing"
P04-1059,W03-1719,0,0.346254,"Missing"
P04-1059,W01-0512,0,0.170452,"(e.g. 蜂窝式 ‘cellular’) four test sets. It demonstrates the possibility of and time-sensitive political, social or cultural terms having a single adaptive Chinese word segmenter (e.g. 三通‘Three Links’, 非典 ‘SARS’). that is capable of supporting multiple user applicaThe second issue concerns the customizable tions. display of word segmentation. Different Chinese Abstract 1 This work was done while Hongqiao Li, Xinsong Xia and Haowei Qin were visiting Microsoft Research (MSR) Asia. We thank Xiaodan Zhu for his early contribution, and the three reviewers, one of whom alerted us the related work of (Uchimoto et al., 2001). Word Class2 Model Feature Functions, f(S,W) Context Model Word class based trigram, P(W). -log(P(W)) Lexical Word (LW) Morphological Word (MW) Named Entity (NE) ----Character/word bigram, P(S|NE). 1 if S forms a word lexicon entry, 0 otherwise. 1 if S forms a morph lexicon entry, 0 otherwise. -log(P(S|NE)) Factoid (FT) New Word (NW) ----- 1 if S can be parsed using a factoid grammar, 0 otherwise Score of SVM classifier Figure 1: Context model, word classes, and class models, and feature functions. 2 Chinese Word Segmentation with Linear Models Let S be a Chinese sentence which is a character"
P04-1059,W00-1207,1,0.900394,"res are chosen due to their effectiveness and availability for on-line detection. They are Independent Word Probability (IWP), Anti-Word Pair (AWP), and Word Formation Analogy (WFA). Below we describe each feature in turn. In Section 3.2, we shall describe the way the training data (new word list) for the classifier is created by sampling. IWP is a real valued feature. Most Chinese characters can be used either as independent words or component parts of multi-character words, or both. The IWP of a single character is the likelihood for this character to appear as an independent word in texts (Wu and Jiang, 2000): IWP ( x ) = C ( x, W ) . C( x) (4) where C(x, W) is the number of occurrences of the character x as an independent word in training data, and C(x) is the total number of x in training data. We assume that the IWP of a character string is the product of the IWPs of the component characters. Intuitively, the lower the IWP value, the more likely the character string forms a new word. In our implementation, the training data is word-segmented. AWP is a binary feature derived from IWP. For example, the value of AWP of an NW_11 candidate ab is defined as: AWP(ab)=1 if IWP(a)>θ or IWP(b) >θ, 0 othe"
P04-1059,O03-4001,1,0.882954,"ong@founder.com & Shanghai Jiaotong university, Shanghai. haoweiqin@sjtu.edu.cn NLP-enabled applications may have different requirements that call for different granularities of word segmentation. For example, speech recogniThis paper presents a Chinese word segmentation system which can adapt to different tion systems prefer “longer words” to achieve domains and standards. We first present a stahigher accuracy whereas information retrieval tistical framework where domain-specific systems prefer “shorter words” to obtain higher words are identified in a unified approach to recall rates, etc. (Wu, 2003). Given a word segword segmentation based on linear models. mentation specification (or standard) and/or some We explore several features and describe how application data used as training data, a segmenter to create training data by sampling. We then with customizable display should be able to provide describe a transformation-based learning alternative segmentation units according to the method used to adapt our system to different specification which is either pre-defined or implied word segmentation standards. Evaluation of in the data. the proposed system on five test sets with difIn this"
P04-1059,W03-1726,0,\N,Missing
P04-1059,W01-1802,0,\N,Missing
P98-1001,A88-1019,0,0.0642798,"ral analysis of Chinese baseNPs and a MDL-based algorithm for quasidependency-strength acquisition. The experiments show that the proposed model is more suitable for Chinese baseNP analysis and the proposed MDLbased algorithm is superior to the traditional MLbased algorithm. The paper also discusses the problem of incorporating the linguistic knowledge into the above statistical model. 1. Introduction The concept of baseNP is initially put forward by Church. In English, baseNP is defined as 'simple non-recursive noun phrases', which means that there is no sub-noun-phrases contained in a baseNP[1]. B~t the definition can not meet the needs in Chinese information retrieval. The noun phrases such as &quot;1~ ~(natural) ~-~(language) ~ ( p r o c e s s ) &quot; , &quot;~-IF~b~l(Asian) ~;-'~!]~(finance) ~f~ ~(crisis)&quot; and &quot; i ~ ( p o l i t i c a l ) /¢~k$1J(system) ~(reformation) ~.~(process)&quot; are critical for information retrieval, but they are not nonrecursive noun phrases. In Chinese, the attribute of noun phrases can be classified into three types, that is restrictive attributes, distinctive attributes and descriptive attributes, among which the restrictive attributes have agglutinative relation with"
P98-1001,P94-1052,0,0.0638463,"ion phrase, verb phrase, locality phrase or (l~)-structure in a baseNP, so assumption-1 is reasonable. On the basis of assumption-l, we put forward the quasi-dependency model for structural analysis of Chinese baseNPs. There are the following 3 kinds of quasidependency-pattern for a tri-word-composed baseNP xyz. 2. The quasi-dependency model There are two kinds of structural analysis models for Eng!ish noun phrase, that is adjacency model and dependency model. The research of Lauer shows that the dependency model is superior to the adjacency model for structural analysis of English noun phrase[2]. However, there is no model for structural analysis of Chinese baseNP till now. According to the dependency grammar, two constituents can be bound together they are determined to be dependent. The determination of y z y X J ,/ Y s3, =(x y) z x v z x J x y ,/ X x J ,/ y g J 4 J I I s==x O' z) /reform&quot;, there are quasi-dependency-relations&quot; ~ Where, pattern s3t means x ~ y , y - &quot; z andx ~ z, which corresponds to structure (x y) z; pattern s3~ means x-&quot;z, y ~ z and x ~ y , which corresponds to the structure x (y z); However, the quasidependency-strength must be used to determine the correspondi"
P98-1001,A97-1046,0,0.0225505,". Similarly, a four-word-composed baseNP has the following five possible structures. ~_a dep( wi --~ w.i , nPt ) dep(w i ~ wj,npk)is Z ds(u ~ v) + (u---~v)aD(np i ,s I ) npt ~ NP where quasi(u..-~v)eD(np~ ,s j ) dependency-strength of w ~ w j is defined as: dsCwi --~ w~) = the y J x z x Y y z x J X x 4 Y y z X s43 ; ( ~ ) ) z $44 = W((Xy)Z) $45 = W(X(yT)) Zhai Chengxiang puts forward an unsupervised In summary, we can compute the belief in algorithm for acquiring quasi-dependency-strength which the structure of npi is sj using the correspondence between the quasi-dependencyfrom noun phrase set[3]. The algorithm is derived pattern and the baseNP structure. The acquisition from the EM algorithm. Because the algorithm is based on the maximum likelihood (ML) principle, of quasi-dependency-strength between words is the critical problem. it usually leads to overfitness between the data and the model[4]. For example, given a simple baseNP 3. The acquisition of quasiset N P = { i ~ / p o l i t i c s ~k~lJ/system ~ / r e f o r m , dependency-strength between words _t~:/economics ~k~lJ/system ~i~/reform, i ~ /politics ~ f~lJ/system ~ ~/revolute , ~ If we have a large scale baseNP annotated corp"
P98-1098,H93-1036,0,\N,Missing
P98-1098,C92-2070,0,\N,Missing
P98-1098,P93-1034,0,\N,Missing
sun-etal-2000-hua,P98-2206,1,\N,Missing
sun-etal-2000-hua,C98-2201,1,\N,Missing
sun-etal-2000-hua,hu-yu-2000-multi,0,\N,Missing
sun-etal-2000-hua,A97-1018,1,\N,Missing
W02-2224,P96-1025,0,0.037987,"Missing"
W02-2224,C96-1058,0,0.0396255,"Missing"
W02-2224,C86-1046,0,0.233812,"Missing"
W02-2224,P00-1033,1,0.857182,"ement C intervenes between them (in linear order of string), then C depends directly on A or on B or some other intervening element. These conditions say, in effect, that conforming dependency structures are representable by trees without crossing branches. Of courses, as in other grammar formalisms that pre-suppose a context-free syntactic structure back-bone, additional linguistic constraints can be incorporated in the formalism by means of various mechanisms, e.g. feature unification. 2.2. Dependency Structures without Phrasal Nodes In the dependency grammar formalism (Lai and Huang, 1998; Lai and Huang, 2000) discussed in this paper, dependency structures are trees consisting entirely of lexical nodes. For example, the dependency tree for (1a), taken from Abeill´e (1993), is (1b): (1) a. Jean dort beaucoup Jean sleeps much ‘Jean sleeps a lot.’ b. dort | -------------------------- |subj adjunct | | | Jean beaucoup When a coarser degree of granularity is warranted by the situation, the actual lexical items in the tree nodes can be replaced by their syntactic categories. c 2002 Tom B.Y. Lai. Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks (TAG+6), pp."
W03-1701,P98-1029,0,0.0380793,"Missing"
W03-1701,A00-2009,0,0.0296688,"Missing"
W03-1701,C98-1029,0,\N,Missing
W03-1718,J96-1002,0,0.00689166,"ork to integrate various features from different knowledge sources. Each feature is typically represented as a binary constraint f. All features are then combined using a log-linear model shown in Eq. 5. Pλ ( y |x ) = 1 exp( Z λ ( x) λ i f i ( x , y )) i (5) where i is a weight of the feature fi , and Z(x) is a normalization factor. Weights ( ) are estimated using the maximum entropy principle: to satisfy constraints on observed data and assume a uniform distribution (with the maximum entropy) on unseen data. The training algorithm we used is the improved iterative scaling (IIS) described in (Berger et al, 1996)3. The context features include six characters: three on the left of the SCNE, and three on the right. Given the context features, the ME classifier would estimate the probability of the candidate being a SCNE. In our example, we treat candidates with the probability larger than 0.5 as SCNEs. To get the precision-recall curve, we can vary the probability threshold from 0.1 to 0.9. 4.2 Vector Space Model VSM is another model we used to detect SCNE. Similar to ME, we use six surrounding characters as the features, as shown in Figure 2. Figure 2. Context window In this approach, we apply the stan"
W03-1718,P03-1035,1,0.899904,"Missing"
W03-1718,C02-1054,0,0.0644216,"Missing"
W03-1718,C02-1012,1,0.900718,"Missing"
W03-1718,M98-1018,0,\N,Missing
W03-1718,P02-1060,0,\N,Missing
W03-1718,M98-1017,0,\N,Missing
W03-1718,P02-1062,0,\N,Missing
W04-1107,W00-0726,0,0.393223,"Missing"
W04-1107,P00-1015,1,0.803515,"ons. For example, one inputs a POS pattern: ‘a_n_n’, and an expected annotation result: ‘B-NP_I-NP_E-NP 3 ’, the tool will list all the consistent and inconsistent sentences in the annotated text respectively. Based on the output one can revise those inconsistent results one by one, and finally the consistency of the chunked text will be improved step by step. 5 i =1 Chunking Model After annotating the corpus, we could use various learning algorithms to build the chunking model. In this paper, HMM is selected because not only its training speed is fast, but also it has comparable performance (Xun and Huang, 2000). Automatic chunking with HMM should conduct the following two steps. 1) Identify boundaries of each chunk. It is to assign each word a chunk mark, named M, which contains 5 classes: B, I, E, S (a single word chunk) and O (outside all chunks). 2) Tag the chunk type, named X, which contains 11 types defined in Section 3. So each word will be tagged with two tags: M and X (the words excluding from any chunk only have M). So the result after chunking is a sequence of triples (t, m, x), where t, m, x represent POS tag, chunk mark and chunk type respectively. All the triples of a chunk are combined"
W04-1107,P02-1055,0,0.41431,"Missing"
W04-1107,W00-0730,0,0.220739,"Missing"
W04-1107,W01-0706,0,0.35348,"Missing"
W04-1107,P03-1063,0,0.271011,"Missing"
W04-1107,brants-2000-inter,0,0.0743744,"Missing"
W04-1107,C02-1145,0,0.139467,"Missing"
W04-1107,P01-1043,0,\N,Missing
W06-0127,W03-1728,0,\N,Missing
W06-0127,W03-1719,0,\N,Missing
W06-0127,C04-1081,0,\N,Missing
W06-0127,P03-1035,1,\N,Missing
W06-0127,J05-4005,1,\N,Missing
W06-0127,O03-4002,0,\N,Missing
W06-0127,I05-3027,0,\N,Missing
W06-0127,I05-3017,0,\N,Missing
W06-0127,I05-3025,0,\N,Missing
W06-0127,W03-1726,0,\N,Missing
W97-0321,P96-1006,0,0.0754483,"s definitions with those of the words in the clusters. 1. Introduction Word sense disambiguation has long been one of the major concerns in natural language processing area (e.g., Bruce et al., 1994; Choueka et al., 1985; Gale et al., 1993; McRoy, 1992; Yarowsky 1992, 1994, 1995), whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus. Undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, e.g., machine translation and information retrieving (Allen, 1995; Ng and Lee, 1996; Resnik, 1995), etc. Previous strategies for word sense disambiguation mainly fall into two categories: statistics-based method and exemplar-based method. Statistics-based method often requires large-scale corpora (e.g., Hirst, 1987; Luk, 1995), sense-tagging or not, monolingual or aligned bilingual, as training data to specify significant clues for each word sense. The method generally suffers from the problem of data sparseness. Moreover, huge corpora, especially sense-tagged or aligned ones, are not generally available in all domains for all languages. Exemplar-based method makes use of ty"
W97-0321,W95-0105,0,0.0219613,"those of the words in the clusters. 1. Introduction Word sense disambiguation has long been one of the major concerns in natural language processing area (e.g., Bruce et al., 1994; Choueka et al., 1985; Gale et al., 1993; McRoy, 1992; Yarowsky 1992, 1994, 1995), whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus. Undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, e.g., machine translation and information retrieving (Allen, 1995; Ng and Lee, 1996; Resnik, 1995), etc. Previous strategies for word sense disambiguation mainly fall into two categories: statistics-based method and exemplar-based method. Statistics-based method often requires large-scale corpora (e.g., Hirst, 1987; Luk, 1995), sense-tagging or not, monolingual or aligned bilingual, as training data to specify significant clues for each word sense. The method generally suffers from the problem of data sparseness. Moreover, huge corpora, especially sense-tagged or aligned ones, are not generally available in all domains for all languages. Exemplar-based method makes use of typical contexts"
W97-0321,P93-1034,0,0.0813666,"Missing"
W97-0321,C92-2070,0,0.0296879,"algorithm to find the nodes (sense clusters) corresponding with sets of similar senses in the dendrogram. Given a word in a particular context&apos; the context would activate some clusters in the dendrogram, based on its similarity with the contexts of the words in the clusters, then the correct sense of the word could be determined by comparing its definitions with those of the words in the clusters. 1. Introduction Word sense disambiguation has long been one of the major concerns in natural language processing area (e.g., Bruce et al., 1994; Choueka et al., 1985; Gale et al., 1993; McRoy, 1992; Yarowsky 1992, 1994, 1995), whose aim is to identify the correct sense of a word in a particular context, among all of its senses defined in a dictionary or a thesaurus. Undoubtedly, effective disambiguation techniques are of great use in many natural language processing tasks, e.g., machine translation and information retrieving (Allen, 1995; Ng and Lee, 1996; Resnik, 1995), etc. Previous strategies for word sense disambiguation mainly fall into two categories: statistics-based method and exemplar-based method. Statistics-based method often requires large-scale corpora (e.g., Hirst, 1987; Luk, 1995), sens"
W97-0321,P94-1013,0,0.0123697,"r each word sense. The method generally suffers from the problem of data sparseness. Moreover, huge corpora, especially sense-tagged or aligned ones, are not generally available in all domains for all languages. Exemplar-based method makes use of typical contexts (exemplars) of a word sense, e.g., verbnoun collocations or adjective-noun collocations, and identifies the correct sense of a word in a particular context by comparing the context with the exemplars (Ng and Lee, 1996). Recently, some kinds of learning techniques have been applied to cumulatively acquire exemplars form large corpora (Yarowsky, 1994, 1995). But ideal resources from which to learn exemplars are not generally available for any languages. Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated (Ng and Lee, 1996). *The work is supportedby National ScienceFoundationof China. 187 both semantic space based on the contexts o f the monoapproaches is that neighboring words provide strong sense words, and structure the senses in the space as A common assumption held by and consistent clues for the correct sense o f a target a den"
W97-0321,P95-1026,0,0.0373827,"Missing"
W97-0321,P92-1032,0,\N,Missing
W97-0321,P95-1025,0,\N,Missing
W97-1004,P89-1010,0,0.140052,"similar ones, while in bound compositions, words cannot be replaced freely(Benson 1990). Free compositions are predictable, i.e., their reasonableness can be determined according to the syntactic and semantic properties of the words in them. While bound compositions are not predictable, i.e., their reasonableness cannot be derived from the syntactic and semantic properties of the words in them(Smadja 1993). Now with the availability of large-scale corpus, automatic acquisition of word compositions, especially word collocations from them have been extensively studied(e.g., Choueka et al. 1988; Church and Hanks 1989; Smadja 1993). The key of their methods is to make use of some statistical means, e.g., frequencies or mutual information, to quantify the compositional strength between words. These methods are more appropriate for retrieving bound compositions, while less appropriate for retrieving free ones. This is because in free compositions, words are related with each other in a more loose way, which may result in the invalidity of mutual information and other statistical means in distinguishing reasonable compositions from unreasonable ones. In this paper, we start from a different point to explore t"
W97-1004,W89-0240,0,0.0606214,"Missing"
W97-1004,P93-1024,0,0.0526087,"ned with another one to form a meaningful phrase, the words similar to t h e m in meaning can also be combined with each other. But it has been shown t h a t the similarity between words in meaning doesn&apos;t correspond to the similarity in compositional ability(Zhu 1982). So adopting semantic classes to construct compositional frames will result in considerable redundancy. An alternative to semantic class is word cluster based on distributional environment (Brown et al., 1992), which in general refers to the surrounding words distributed around certain word (e.g., Hatzivassiloglou et al., 1993; Pereira et al., 1993), or the classes of them(Bensch et al., 1995), or more complex statistical means (Dagan et al., 1993). According to the properties of the clusters in compositional frames, the clusters should be based on the environment, which, however, is narrowed in the given compositions. Because the given compositions are listed by hand, it is impossible to make use of statistical means to form the environment, the remaining choices are surrounding words or classes of them. Pereira et a1.(1993) put forward a method to cluster nouns in V-N compositions, taking the verbs which can combine with a noun as its"
W97-1004,J93-1007,0,0.053469,"Missing"
W97-1004,J90-1003,0,\N,Missing
W97-1004,H89-2012,0,\N,Missing
W97-1004,P95-1026,0,\N,Missing
W97-1004,P93-1023,0,\N,Missing
W98-0512,C86-1046,0,0.610096,"he mathematical properties of Dependency Grammar (Tesniere (1959)) are studied by Gaifman (1965) and Hays (1964). Following their footsteps, Robinson (1970) formulates four axioms to govern the weU-formedness of dependency structures: (a) One and only one element is independent; 102 These are effectively the requirements of singleheadedness and projectivity. While there are some schools of DG that do not follow Robinson&apos;s axioms in their entirety (e.g. Hudson (1984, 1990), Melcuk (1988)), many computational linguists working on DG-based parsing have based their work on these assumptions (e.g. Hellwig (1986), Covington (1990)). DG parsing of Chinese have used statistical corpus-based algorithms (Huang et al. (1992), Yuan and Huang. (1992)), rule-based I I I they may or may not take word order into consideration; but they all observe Robinson&apos;s axioms in their entirety. They also label depedency relations with grammatical functions like subject and object. Generalizing over DG-based parsing of Chinese, Lai and Huang (1994) note that, taking linear word-order into consideration, this approach to DG can be emulated by a model having a context-free constituent component that is constrained by a gramm"
W98-0512,C92-4211,1,0.531322,"grammatical problems like control. On the other hand, dependency rules, emulated by PATR phrasestructure rules, are kept to a minimum and deals with subeategorization and adjoining with a l-IPSG-like mechanism. The emulation model, however, remains an emulation. The Chinese parsing experiments from which the generalization has been made do not all use (context-free) phrase structure rules (e.g. X: subcat.right = [] to rules in Fig. 11 As shown in Fig. 12, a lexical entry has two subcategorization lists, one for complements on its left and one for complements on its right, an inspiration from Yuan and Huang (1992). The elements in a subcategorization list is arranged so that the one that occurs closest to the head word is at the head. The rules in Fig. 13 are presented in a form that is easily understood by readers. The pop operation, which is procedural in nature (hence the braces), hands over to the caller the head elements of a the subcategorization list, removing it from the list at the same time. It is actually implemented in a PATR-compatible manner. This scheme works for Chinese and English, in which unmoved non-subject complements follow the verb. Adjustments are required for moved complements."
W98-0512,C94-2153,1,0.435878,"noted that the rules, in the spirit of Robinson&apos;s axioms, try not to meddle with word order as far as possible. In this respect, PATR is inelegant in that it has to have two symmetrical adjunct rules in Fig. !I and two symmetrical complement rules in Fig. 13. This inelegance seems to be inherent in the PSG nature of PATR. 4 Nature of the Emulation Model An examination of the real nature of our emulation model is in order. As a computational emulation of a DG conforming to Robinson&apos;s four axioms and using grammatical functions to label 107 I I I I I I I I I I I I I I I I I Yuan et al. (1992); Zhou and Huang (1994)). PATR rules are useful only in so far as they can produce structures that can be transformed to dependency structures. Acquisition and Syntacu&apos;c Parsing). Journal of Chinese InformationProcessing, 6/3, pp. I-6. Hudson R. (1984) Word Grammar. Blackw¢ll, Oxford, 267p. Hudson R. (1990) English Word Grammar. Blackwell, Oxford,445p. Conclusion We have thus been committed in our efforts to emulate a Robinson-style Dependency Grammar with a lexically oriented Context-Free Grammar constrained by grammatical function annotations. Besides providing a formalism for valid and illuminating linguistic ana"
Y06-1001,J96-3004,0,0.124816,"ining corpus. 1 Introduction Chinese text is written without natural delimiters, so word segmentation is an essential first step in Chinese language processing. In this aspect, Chinese is quite different from English in which sentences of words delimited by white spaces. Though it seems very simple, Chinese word segmentation (CWS) is not a trivial problem. Actually, it has been active area of research in computational linguistics for almost 20 years and has drawn more and more attention in the Chinese language processing community. To accomplish such a task, various technologies are developed [1][2]. In the early work of Chinese word segmentation, word-based method once played the dominant role, in which maximum matching algorithm is the most typical method. Here, the term, word, means those known words are shown in known lexicon or training corpus (also are called in-vocabulary(IV) words.). Explicit known word information was still important learning object even after statistical methods were introduced in CWS [1]. To give a comprehensive comparison of Chinese segmentation on common test corpora, three International Chinese Word Segmentation Bakeoffs were held in 2003, 2005, and 2006"
Y06-1001,J05-4005,1,0.835086,"ng corpus. 1 Introduction Chinese text is written without natural delimiters, so word segmentation is an essential first step in Chinese language processing. In this aspect, Chinese is quite different from English in which sentences of words delimited by white spaces. Though it seems very simple, Chinese word segmentation (CWS) is not a trivial problem. Actually, it has been active area of research in computational linguistics for almost 20 years and has drawn more and more attention in the Chinese language processing community. To accomplish such a task, various technologies are developed [1][2]. In the early work of Chinese word segmentation, word-based method once played the dominant role, in which maximum matching algorithm is the most typical method. Here, the term, word, means those known words are shown in known lexicon or training corpus (also are called in-vocabulary(IV) words.). Explicit known word information was still important learning object even after statistical methods were introduced in CWS [1]. To give a comprehensive comparison of Chinese segmentation on common test corpora, three International Chinese Word Segmentation Bakeoffs were held in 2003, 2005, and 20061 ,"
Y06-1001,I05-3017,0,0.0509021,"ethod once played the dominant role, in which maximum matching algorithm is the most typical method. Here, the term, word, means those known words are shown in known lexicon or training corpus (also are called in-vocabulary(IV) words.). Explicit known word information was still important learning object even after statistical methods were introduced in CWS [1]. To give a comprehensive comparison of Chinese segmentation on common test corpora, three International Chinese Word Segmentation Bakeoffs were held in 2003, 2005, and 20061 , and there were 12, 23 and 23 participants, respectively [3], [4], [5]. Four segmentation corpora were presented in each Bakeoff. Thus, twelve corpora are available from Bakeoff 2003, 2005, and 2006. A summary of these corpora is shown in Table 1. In all of proposed methods, character-based tagging method [6], instead of traditional word-based one, quickly rose in Bakeoff-2005 as a remarkable one with state-ofthe-art performance. Especially, two participants, Ng and Tseng, gave the best results 1 In 2006, the name of the third Bakeoff has been changed into International Chinese Language Processing Bakeoff for the reason that named entity recognition task wa"
Y06-1001,W06-0115,0,0.0259048,"once played the dominant role, in which maximum matching algorithm is the most typical method. Here, the term, word, means those known words are shown in known lexicon or training corpus (also are called in-vocabulary(IV) words.). Explicit known word information was still important learning object even after statistical methods were introduced in CWS [1]. To give a comprehensive comparison of Chinese segmentation on common test corpora, three International Chinese Word Segmentation Bakeoffs were held in 2003, 2005, and 20061 , and there were 12, 23 and 23 participants, respectively [3], [4], [5]. Four segmentation corpora were presented in each Bakeoff. Thus, twelve corpora are available from Bakeoff 2003, 2005, and 2006. A summary of these corpora is shown in Table 1. In all of proposed methods, character-based tagging method [6], instead of traditional word-based one, quickly rose in Bakeoff-2005 as a remarkable one with state-ofthe-art performance. Especially, two participants, Ng and Tseng, gave the best results 1 In 2006, the name of the third Bakeoff has been changed into International Chinese Language Processing Bakeoff for the reason that named entity recognition task was add"
Y06-1001,O03-4002,0,0.519694,"known word information was still important learning object even after statistical methods were introduced in CWS [1]. To give a comprehensive comparison of Chinese segmentation on common test corpora, three International Chinese Word Segmentation Bakeoffs were held in 2003, 2005, and 20061 , and there were 12, 23 and 23 participants, respectively [3], [4], [5]. Four segmentation corpora were presented in each Bakeoff. Thus, twelve corpora are available from Bakeoff 2003, 2005, and 2006. A summary of these corpora is shown in Table 1. In all of proposed methods, character-based tagging method [6], instead of traditional word-based one, quickly rose in Bakeoff-2005 as a remarkable one with state-ofthe-art performance. Especially, two participants, Ng and Tseng, gave the best results 1 In 2006, the name of the third Bakeoff has been changed into International Chinese Language Processing Bakeoff for the reason that named entity recognition task was added 1 in almost all tracks [7], [8]. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. Researchers turned to character-based method from traditional word-based method onl"
Y06-1001,I05-3027,0,0.219659,"e presented in each Bakeoff. Thus, twelve corpora are available from Bakeoff 2003, 2005, and 2006. A summary of these corpora is shown in Table 1. In all of proposed methods, character-based tagging method [6], instead of traditional word-based one, quickly rose in Bakeoff-2005 as a remarkable one with state-ofthe-art performance. Especially, two participants, Ng and Tseng, gave the best results 1 In 2006, the name of the third Bakeoff has been changed into International Chinese Language Processing Bakeoff for the reason that named entity recognition task was added 1 in almost all tracks [7], [8]. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. Researchers turned to character-based method from traditional word-based method only with four years. The success of Bakeoffs not only gave some public consistent segmentation standards, but also proposed a corpus-based segmentation standard representation, instead of the representation of known word lexicon and segmentation manual before. Thus Chinese word segmentation becomes more like corpus-based machine learning procedure in this sense. With the supply of common segme"
Y06-1001,O05-4005,0,0.0761006,"the representation of known word lexicon and segmentation manual before. Thus Chinese word segmentation becomes more like corpus-based machine learning procedure in this sense. With the supply of common segmentation standards of Bakeoffs, the comparison problem on word-based method and character-based method are still remained. Though most effective Chinese word segmentation techniques are turned to pure characterbased methods, some researchers are still insisting that character-based method alone can not be superior to the method that combines both word information and character information [9] [10][11]. In this paper, we will briefly explore the linguistic background of such turnaround in Chinese word segmentation and give an empirical comparison of these methods. Table 1. Corpora statistics of Bakeoff 2003, 2005 and 2006 Provider Corpus words words Academia AS2003 Big5 5.8M 12K 0.022 Sinica AS2005 Big5 5.45M 122K 0.043 AS2006 Big5 5.45M 91K 0.042 CityU2003 Big5 240K 35K 0.071 City University CityU2005 Big5 1.46M 41K 0.074 CityU2006 Big5 1.64M 220K 0.040 Hong Kong Encoding #Training #Test OOV rate University of CTB2003 GB 250K 40K 0.181 Pennsylvania CTB2006 GB 508K 154K 0.088 Micro"
Y06-1001,W02-1815,0,0.0266408,"iews the track of character-based method. We discuss the linguistic background of characterbased features (especially for unigram feature) in Section 3. We evaluate unigram feature through CWS performance comparison in Section 4. In Section 5, the experimental 2 results between word-based method and character-based method are demonstrated. We summarize our contribution in Section 6. 2 The Track of Character-based Method Character-based tagging method is a classification technique for Chinese characters according to their positions occurring in Chinese words. This method was first conducted in [12], two classifiers were combined to perform Chinese word segmentation. First, a maximum entropy model was used to segment the text, and then an error driven transformation model was used to correct the word boundaries. This method was continuously improved in [6] and [13], where a unified maximum entropy model was used to perform character-based tagging task. As mentioned above, two top participants, Tseng and Low, won the most outstanding success in Bakeoff-2005 with the similar character-based tagging method, though the former used conditional random field model while the latter still used ma"
Y06-1001,W03-1728,0,0.0194171,"between word-based method and character-based method are demonstrated. We summarize our contribution in Section 6. 2 The Track of Character-based Method Character-based tagging method is a classification technique for Chinese characters according to their positions occurring in Chinese words. This method was first conducted in [12], two classifiers were combined to perform Chinese word segmentation. First, a maximum entropy model was used to segment the text, and then an error driven transformation model was used to correct the word boundaries. This method was continuously improved in [6] and [13], where a unified maximum entropy model was used to perform character-based tagging task. As mentioned above, two top participants, Tseng and Low, won the most outstanding success in Bakeoff-2005 with the similar character-based tagging method, though the former used conditional random field model while the latter still used maximum entropy model. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. There are five participants ranked the first in one track at least [14][15][16][17][18], in which two participants used condition"
Y06-1001,W06-0127,1,0.899024,"ndaries. This method was continuously improved in [6] and [13], where a unified maximum entropy model was used to perform character-based tagging task. As mentioned above, two top participants, Tseng and Low, won the most outstanding success in Bakeoff-2005 with the similar character-based tagging method, though the former used conditional random field model while the latter still used maximum entropy model. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. There are five participants ranked the first in one track at least [14][15][16][17][18], in which two participants used conditional random field, and the other three used maximum entropy as learning model. Especially, four participants directly or indirectly used the technique in [7]. 3 Features of Character Classification for CWS CWS is the primary processing in Chinese language processing. Thus it is difficult or even impossible to use derivative features like other Chinese language processing tasks. The basic features that we can use are characters themselves. We perform a position frequency statistics of Chinese characters in MSRA2005 training corpus. All cha"
Y06-1001,W06-0121,0,0.0208805,"ies. This method was continuously improved in [6] and [13], where a unified maximum entropy model was used to perform character-based tagging task. As mentioned above, two top participants, Tseng and Low, won the most outstanding success in Bakeoff-2005 with the similar character-based tagging method, though the former used conditional random field model while the latter still used maximum entropy model. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. There are five participants ranked the first in one track at least [14][15][16][17][18], in which two participants used conditional random field, and the other three used maximum entropy as learning model. Especially, four participants directly or indirectly used the technique in [7]. 3 Features of Character Classification for CWS CWS is the primary processing in Chinese language processing. Thus it is difficult or even impossible to use derivative features like other Chinese language processing tasks. The basic features that we can use are characters themselves. We perform a position frequency statistics of Chinese characters in MSRA2005 training corpus. All charact"
Y06-1001,W06-0133,0,0.0197151,"This method was continuously improved in [6] and [13], where a unified maximum entropy model was used to perform character-based tagging task. As mentioned above, two top participants, Tseng and Low, won the most outstanding success in Bakeoff-2005 with the similar character-based tagging method, though the former used conditional random field model while the latter still used maximum entropy model. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. There are five participants ranked the first in one track at least [14][15][16][17][18], in which two participants used conditional random field, and the other three used maximum entropy as learning model. Especially, four participants directly or indirectly used the technique in [7]. 3 Features of Character Classification for CWS CWS is the primary processing in Chinese language processing. Thus it is difficult or even impossible to use derivative features like other Chinese language processing tasks. The basic features that we can use are characters themselves. We perform a position frequency statistics of Chinese characters in MSRA2005 training corpus. All characters"
Y06-1001,W06-0117,0,0.0163219,"thod was continuously improved in [6] and [13], where a unified maximum entropy model was used to perform character-based tagging task. As mentioned above, two top participants, Tseng and Low, won the most outstanding success in Bakeoff-2005 with the similar character-based tagging method, though the former used conditional random field model while the latter still used maximum entropy model. In Bakeoff-2006, all participants whose system performance ranked first in a track at least used character-based method. There are five participants ranked the first in one track at least [14][15][16][17][18], in which two participants used conditional random field, and the other three used maximum entropy as learning model. Especially, four participants directly or indirectly used the technique in [7]. 3 Features of Character Classification for CWS CWS is the primary processing in Chinese language processing. Thus it is difficult or even impossible to use derivative features like other Chinese language processing tasks. The basic features that we can use are characters themselves. We perform a position frequency statistics of Chinese characters in MSRA2005 training corpus. All characters appearin"
Y06-1001,C04-1081,0,0.0744673,"omparisons of CRF method and semi-CRF method in corpora of Bakeoff-2003 Tagging method CityU2003 PKU2003 CTB2003 CRF learning in Liang’s method 0.937 0.941 0.879 Semi-CRF learning in Liang’s method 0.936 0.936 0.868 Character-based method 0.947 0.956 0.872 9 5.4 Comparison with the Best Existing Work Comparisons between our results and best existing results in three Bakeoffs are shown in Table 9-11. There are two types of existing results for Bakeoff-2003 and 2005. One is the best F scores of Bakeoff 2003, 2005 for each corpus in closed test tracks. The other are the results of Peng and Tseng [19] [8]. As for Bakeoff-2006, our results is slightly lower than those in [14], because more feature templates were used in [14] than that in Table 4. Table 9. Comparisons of best existing results and our results in the corpora of Bakeoff 2003 Participant AS2003 CTB2003 CityU2003 PKU2003 Peng 0.956 0.849 0.928 0.941 Tseng 0.970 0.863 0.947 0.953 Best results of Bakeoff 0.961 0.881 0.940 0.951 0.872 0.947 0.956 Ours 0.973 Table 10. Comparisons of best existing results and our results in the corpora of Bakeoff 2005 Participant Tseng AS2005 CityU2005 PKU2005 MSRA2005 0.947 0.943 0.950 0.964 Best res"
Y06-1001,W06-1655,0,0.0347181,"ional features in semi-CRF that are intuitively very useful. Also, it has been shown that an order-M seimi-CRF is strictly more powerful than an order-M CRF. However, the use of a semi-Markov CRF for Chinese word segmentation did not find significant gains over the standard CRF in Liang’s previous work [21]. The comparison with our method in three corpora of Bakeoff-2003 is shown in Table 8. Liang used two learning model, standard CRF and semi-CRF in the same features, the results did not support the superiority of semi-CRF, too. A hybrid Markov/Semi-Markov CRF learning method was proposed in [22]. The traditional semi-CRF method was effectively improved since Liang’s work, and the Fmeasure of MSRA2005 corpus has been 0.9684, which is much better than the best results in Bakeoff-2005. However, we see that it is not better than character-based tagging method, which is 0.974 as seen in Table 7. Table 8. Comparisons of CRF method and semi-CRF method in corpora of Bakeoff-2003 Tagging method CityU2003 PKU2003 CTB2003 CRF learning in Liang’s method 0.937 0.941 0.879 Semi-CRF learning in Liang’s method 0.936 0.936 0.868 Character-based method 0.947 0.956 0.872 9 5.4 Comparison with the Best"
Y06-1001,W03-1719,0,\N,Missing
Y06-1001,N06-2049,0,\N,Missing
Y06-1001,P06-2123,0,\N,Missing
Y06-1001,W06-0120,0,\N,Missing
Y06-1001,I05-3025,0,\N,Missing
Y06-1001,W03-1726,0,\N,Missing
Y06-1012,J05-4005,1,0.608158,"Missing"
Y06-1012,O03-4002,0,0.572227,"d to used for the particular corpus. No other data is allowed. In this study, we will limit our comparison in closed test because additional linguistical resource often varies from system to system. The remainder of the paper is organized as follows. The next section is a simple introduction to conditional random field. Feature templates and tag sets are given in Section 3. In Section 4, our experimental results are demonstrated. We summarize our contribution in Section 5. 2 Conditional Random Field Maximum entropy tagger was used in early character-based tagging for Chinese word segmentation [2], [3], while we choose linear-chain CRF as our learning model in this study. It can combine rich feature representation and probabilistic finite state model, too. In addition, it can avoid so-called ‘label-bias’ problem in some degree. Actually, such model was also proved to be very effective in many existing works [8]. Conditional random field (CRF) is a statistical sequence modeling framework first introduced into language processing in [9]. Work by Peng et al. first used this framework for Chinese word segmentation by treating it as a binary decision task, such that each Chinese character i"
Y06-1012,W03-1728,0,0.0145844,"used for the particular corpus. No other data is allowed. In this study, we will limit our comparison in closed test because additional linguistical resource often varies from system to system. The remainder of the paper is organized as follows. The next section is a simple introduction to conditional random field. Feature templates and tag sets are given in Section 3. In Section 4, our experimental results are demonstrated. We summarize our contribution in Section 5. 2 Conditional Random Field Maximum entropy tagger was used in early character-based tagging for Chinese word segmentation [2], [3], while we choose linear-chain CRF as our learning model in this study. It can combine rich feature representation and probabilistic finite state model, too. In addition, it can avoid so-called ‘label-bias’ problem in some degree. Actually, such model was also proved to be very effective in many existing works [8]. Conditional random field (CRF) is a statistical sequence modeling framework first introduced into language processing in [9]. Work by Peng et al. first used this framework for Chinese word segmentation by treating it as a binary decision task, such that each Chinese character is lab"
Y06-1012,I05-3017,0,0.435599,"Missing"
Y06-1012,I05-3027,0,0.49937,"Missing"
Y06-1012,C04-1081,0,0.45997,". Feature templates and tag sets are given in Section 3. In Section 4, our experimental results are demonstrated. We summarize our contribution in Section 5. 2 Conditional Random Field Maximum entropy tagger was used in early character-based tagging for Chinese word segmentation [2], [3], while we choose linear-chain CRF as our learning model in this study. It can combine rich feature representation and probabilistic finite state model, too. In addition, it can avoid so-called ‘label-bias’ problem in some degree. Actually, such model was also proved to be very effective in many existing works [8]. Conditional random field (CRF) is a statistical sequence modeling framework first introduced into language processing in [9]. Work by Peng et al. first used this framework for Chinese word segmentation by treating it as a binary decision task, such that each Chinese character is labeled either as the beginning of a word or not. The probability assigned to a label sequence for a particular sequence of characters by a CRF is given by the equation below: pλ (Y |W ) = XX 1 exp( λk fk (yt−1 , yt , W, t)) Z(W ) t∈T (1) k where Y = {yi } is the label sequence for the sentence, W is the sequence of"
Y06-1012,W06-0127,1,0.341064,"03 and 2005 for each corpus under closed test. The other is the results of Tseng et al.. All of our results are performed under TMPT-01 (or TMPT-044 ) and 6-tag set. 3 4 The Third SIGHAN Chinese Language Processing Bakeoff has been held, the results will be presented at the 5th SIGHAN Workshop, to be held at ACL-COLING 2006 in Sydney, Australia, July 22-23, 2006. We also participate this Bakeoff, and our system with the techniques presented in this paper won four highest and two third highest F measures in six Chinese word segmentation tracks. Our results on Bakeoff-2006 appear in SIGHAN-2006 [11]. Note that TMPT-04 is a feature template set only including n-gram ones. Researchers in CWS did not make an agree on what P and T−1 T0 T1 are feature templates for closed test or not. Thus the results under TMPT-04 are demonstrated, too. We will see that our system gets stateof-the-art performance in either of feature template set. 91 Table 6. Comparisons of best existing results and our results in the corpora of Bakeoff-2003 and 2005 Participant AS2003 CTB2003 CityU2003 PKU2003 AS2005 CityU2005 PKU2005 MSRA2005 Peng 0.956 0.849 0.928 0.941 Tseng 0.970 0.863 0.947 0.953 0.947 0.943 0.950 0.96"
Y06-1012,W03-1719,0,\N,Missing
Y06-1012,W03-1726,0,\N,Missing
Y06-1012,I05-3025,0,\N,Missing
Y09-2035,P03-1035,1,0.778156,"indow, they are counted as co′ ′ occurrence ??? = ??(?? , ?? ), where ??? is the initial weight of the edge ?? → ?? , and ??(?? , ?? ) is the co-occurrence times of ?? and ?? . The transition matrix ? = [??? ]?×? is given by ′ ??? = ??? / ? ∑ ′ ??? . (2) ?=1 3 Phrase Generation Chinese is different from English because there is no explicit separator between words in a sentence. Segmentation converts a sequence of continuous Chinese characters into a sequence of 734 delimited words. It is a necessary step for most Chinese information processing systems including keyphrase extraction. S-MSRSeg (Gao et al., 2003) is used as our segmentation tool1 . One crucial step to generate phrases from words is to determine the phrase boundary. In TextRank, only single words take part in the PageRank iteration. After a small number of candidate keywords have been extracted, the sequences of adjacent keywords are merged into keyphrases. One disadvantage of this method is that not all parts of the keyphrase can always be extracted correctly as keywords. Any loss of the adjacent keywords will cause the failure of keyphrase generation. In this section, we introduce three statistical criteria to generate phrases before"
Y09-2035,I08-4017,0,0.0143965,"l criteria to generate phrases before the PageRank iteration. A straightforward criterion is frequency. For an article ?, a word sequence ?1 ..?? should be a phrase if { ? ??(?1 ..?? , ?) ≥ ? ??? ?? , (3) ?? ∈ / ??, ? = 1, 2, ..., ? where ? ??(?1 ..?? , ?) is the frequency of ?1 ..?? in article ?, ? ??? ?? is the threshold, ?? is the stop word collection. We call this criterion “local frequency” because the frequency is based on the article from which we extract keyphrases. The advantage of this criterion is robust and efficient, especially for domain specific articles. Boundary entropy (BE) (Zhao and Kit, 2008) measures the boundary by entropy. ∑ ??(?1 ..?? ) = − ?(?∣?1 ..?? ) log ?(?∣?1 ..?? ), (4) ?∈? where ? is a Chinese character, ?(?∣?1 ..?? ) is the probability of ?1 ..?? adjacent to ?. As ? can be right or left to ?1 ..?? , two types of BE named ??? and ??? can be defined. Feng et al. (2004) and Zhao and Kit (2008) used Access Variety (AV) to measure the boundary of Chinese words as ?? (?1 ..?? ) = log ???? (?1 ..?? ), (5) where ???? (?1 ..?? ) is the number of the distinct Chinese characters which adjacent to ?1 ..?? . Also, we can define left access variety (??? ) and right access variety ("
Y09-2035,W04-3252,0,\N,Missing
Y09-2035,J04-1004,0,\N,Missing
Y15-1001,J00-4006,0,\N,Missing
Y15-1001,I08-4010,0,\N,Missing
Y99-1017,J90-4003,0,0.0690424,"or dependency relations holding between governor-dependent pairs of words in a sentence. Using different algorithms for the parsing process, they differ in whether syntactic categories are considered in lieu of the actual words and in whether and how word order is taken into consideration, but they all observe the requirements of singleheadedness and projectivity. They also label dependency relations with functional labels like subject and object as is done in practically all schools of Dependency Grammar. Unification [22] has been used in Dependency Grammar implementation and theory (e.g. [8][2][18]). The authors have distinguished between a single-headed and projective dependency (constituent) structure and a much less constrained functional structure.[14][15][16][17] Dependency rules [7] are annotated with functional annotation,[1] and a unification-based parser [22][5] has been adapted to produce dependency and functional structures for Chinese (and English) sentences. They have discussed how syntactic phenomena like control are dealt with. They make a distinction between obligatory complements prescribed for by the syntactic properties of the governing verb and optional adjuncts"
Y99-1017,C86-1046,0,0.105617,"d for dependency relations holding between governor-dependent pairs of words in a sentence. Using different algorithms for the parsing process, they differ in whether syntactic categories are considered in lieu of the actual words and in whether and how word order is taken into consideration, but they all observe the requirements of singleheadedness and projectivity. They also label dependency relations with functional labels like subject and object as is done in practically all schools of Dependency Grammar. Unification [22] has been used in Dependency Grammar implementation and theory (e.g. [8][2][18]). The authors have distinguished between a single-headed and projective dependency (constituent) structure and a much less constrained functional structure.[14][15][16][17] Dependency rules [7] are annotated with functional annotation,[1] and a unification-based parser [22][5] has been adapted to produce dependency and functional structures for Chinese (and English) sentences. They have discussed how syntactic phenomena like control are dealt with. They make a distinction between obligatory complements prescribed for by the syntactic properties of the governing verb and optional adjunc"
Y99-1017,W98-0512,1,0.596066,"tegories are considered in lieu of the actual words and in whether and how word order is taken into consideration, but they all observe the requirements of singleheadedness and projectivity. They also label dependency relations with functional labels like subject and object as is done in practically all schools of Dependency Grammar. Unification [22] has been used in Dependency Grammar implementation and theory (e.g. [8][2][18]). The authors have distinguished between a single-headed and projective dependency (constituent) structure and a much less constrained functional structure.[14][15][16][17] Dependency rules [7] are annotated with functional annotation,[1] and a unification-based parser [22][5] has been adapted to produce dependency and functional structures for Chinese (and English) sentences. They have discussed how syntactic phenomena like control are dealt with. They make a distinction between obligatory complements prescribed for by the syntactic properties of the governing verb and optional adjuncts that are taken care of by non-lexical rules in the syntax of the language. A pair of subcategorization lists residing in the lexical entry of the governing verb are used to take"
Y99-1017,J96-1005,0,0.0286496,"Missing"
Y99-1017,C92-4211,1,0.876028,"ists residing in the governing verb have been used to capture these properties. However when one tries to extend the model to languages with relatively free word order like Japanese, for which the assumptions mentioned above are not valid, straight-forward list-manipulations on subcategorization lists will not be adequate. This paper discusses how additional subcategorization handling mechanisms can be introduced to deal with verbal complements scrambling and intervening adjuncts, while retaining the mechanisms to capture default word order. 1. INTRODUCTION Computational linguists in China [9][26][27] have been studying and experimenting with Chinese sentence parsing based on the tradition of Gaifman, Hays and Robinson [4][7][21] in the development of Dependency Grammar,[25] which is different from other traditions of the grammar formalism [10][24][19][6] in that single-headedness and projectivity are required for dependency relations holding between governor-dependent pairs of words in a sentence. Using different algorithms for the parsing process, they differ in whether syntactic categories are considered in lieu of the actual words and in whether and how word order is taken into con"
Y99-1017,C94-2153,1,0.897071,"residing in the governing verb have been used to capture these properties. However when one tries to extend the model to languages with relatively free word order like Japanese, for which the assumptions mentioned above are not valid, straight-forward list-manipulations on subcategorization lists will not be adequate. This paper discusses how additional subcategorization handling mechanisms can be introduced to deal with verbal complements scrambling and intervening adjuncts, while retaining the mechanisms to capture default word order. 1. INTRODUCTION Computational linguists in China [9][26][27] have been studying and experimenting with Chinese sentence parsing based on the tradition of Gaifman, Hays and Robinson [4][7][21] in the development of Dependency Grammar,[25] which is different from other traditions of the grammar formalism [10][24][19][6] in that single-headedness and projectivity are required for dependency relations holding between governor-dependent pairs of words in a sentence. Using different algorithms for the parsing process, they differ in whether syntactic categories are considered in lieu of the actual words and in whether and how word order is taken into conside"
