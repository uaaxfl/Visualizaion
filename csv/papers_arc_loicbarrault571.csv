2021.emnlp-main.51,Active Learning by Acquiring Contrastive Examples,2021,-1,-1,3,0,8739,katerina margatina,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Common acquisition functions for active learning use either uncertainty or diversity sampling, aiming to select difficult and diverse data points from the pool of unlabeled data, respectively. In this work, leveraging the best of both worlds, we propose an acquisition function that opts for selecting contrastive examples, i.e. data points that are similar in the model feature space and yet the model outputs maximally different predictive likelihoods. We compare our approach, CAL (Contrastive Active Learning), with a diverse set of acquisition functions in four natural language understanding tasks and seven datasets. Our experiments show that CAL performs consistently better or equal than the best performing baseline across all tasks, on both in-domain and out-of-domain data. We also conduct an extensive ablation study of our method and we further analyze all actively acquired datasets showing that CAL achieves a better trade-off between uncertainty and diversity compared to other strategies."
2021.acl-short.60,In Factuality: Efficient Integration of Relevant Facts for Visual Question Answering,2021,-1,-1,4,0,11534,peter vickers,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Visual Question Answering (VQA) methods aim at leveraging visual input to answer questions that may require complex reasoning over entities. Current models are trained on labelled data that may be insufficient to learn complex knowledge representations. In this paper, we propose a new method to enhance the reasoning capabilities of a multi-modal pretrained model (Vision+Language BERT) by integrating facts extracted from an external knowledge base. Evaluation on the KVQA dataset benchmark demonstrates that our method outperforms competitive baselines by 19{\%}, achieving new state-of-the-art results. We also perform an extensive analysis highlighting the limitations of our best performing model through an ablation study."
2020.wmt-1.1,Findings of the 2020 Conference on Machine Translation ({WMT}20),2020,-1,-1,1,1,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages."
2020.wmt-1.2,Findings of the First Shared Task on Lifelong Learning Machine Translation,2020,-1,-1,1,1,8740,loic barrault,Proceedings of the Fifth Conference on Machine Translation,0,"A lifelong learning system can adapt to new data without forgetting previously acquired knowledge. In this paper, we introduce the first benchmark for lifelong learning machine translation. For this purpose, we provide training, lifelong and test data sets for two language pairs: English-German and English-French. Additionally, we report the results of our baseline systems, which we make available to the public. The goal of this shared task is to encourage research on the emerging topic of lifelong learning machine translation."
2020.lrec-1.226,Evaluation of Lifelong Learning Systems,2020,0,0,4,0,17067,yevhenii prokopalo,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Current intelligent systems need the expensive support of machine learning experts to sustain their performance level when used on a daily basis. To reduce this cost, i.e. remaining free from any machine learning expert, it is reasonable to implement lifelong (or continuous) learning intelligent systems that will continuously adapt their model when facing changing execution conditions. In this work, the systems are allowed to refer to human domain experts who can provide the system with relevant knowledge about the task. Nowadays, the fast growth of lifelong learning systems development rises the question of their evaluation. In this article we propose a generic evaluation methodology for the specific case of lifelong learning systems. Two steps will be considered. First, the evaluation of human-assisted learning (including active and/or interactive learning) outside the context of lifelong learning. Second, the system evaluation across time, with propositions of how a lifelong learning intelligent system should be evaluated when including human assisted learning or not."
2020.jeptalnrecital-taln.20,Traduction automatique pour la normalisation du fran{\\c{c}}ais du {XVII}e si{\\`e}cle (),2020,-1,-1,2,0,18581,simon gabay,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,
2020.jeptalnrecital-jep.58,{\\'E}valuation de syst{\\`e}mes apprenant tout au long de la vie (Evaluation of lifelong learning systems ),2020,-1,-1,4,0,17067,yevhenii prokopalo,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"Aujourd{'}hui les syst{\`e}mes intelligents obtiennent d{'}excellentes performances dans de nombreux domaines lorsqu{'}ils sont entra{\^\i}n{\'e}s par des experts en apprentissage automatique. Lorsque ces syst{\`e}mes sont mis en production, leurs performances se d{\'e}gradent au cours du temps du fait de l{'}{\'e}volution de leur environnement r{\'e}el. Une adaptation de leur mod{\`e}le par des experts en apprentissage automatique est possible mais tr{\`e}s co{\^u}teuse alors que les soci{\'e}t{\'e}s utilisant ces syst{\`e}mes disposent d{'}experts du domaine qui pourraient accompagner ces syst{\`e}mes dans un apprentissage tout au long de la vie. Dans cet article nous proposons un cadre d{'}{\'e}valuation g{\'e}n{\'e}rique pour des syst{\`e}mes apprenant tout au long de la vie (SATLV). Nous proposons d{'}{\'e}valuer l{'}apprentissage assist{\'e} par l{'}humain (actif ou interactif) et l{'}apprentissage au cours du temps."
2020.emnlp-main.184,Simultaneous Machine Translation with Visual Context,2020,-1,-1,5,1,10667,ozan caglayan,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Simultaneous machine translation (SiMT) aims to translate a continuous input text stream into another language with the lowest latency and highest quality possible. The translation thus has to start with an incomplete source text, which is read progressively, creating the need for anticipation. In this paper, we seek to understand whether the addition of visual information can compensate for the missing source context. To this end, we analyse the impact of different multimodal approaches and visual features on state-of-the-art SiMT frameworks. Our results show that visual context is helpful and that visually-grounded models based on explicit object region information are much better than commonly used global features, reaching up to 3 BLEU points improvement under low latency scenarios. Our qualitative analysis illustrates cases where only the multimodal systems are able to translate correctly from English into gender-marked languages, as well as deal with differences in word order, such as adjective-noun placement between English and French."
W19-5301,Findings of the 2019 Conference on Machine Translation ({WMT}19),2019,0,50,1,1,8740,loic barrault,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,"This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation."
W19-5307,{LIUM}{'}s Contributions to the {WMT}2019 News Translation Task: Data and Systems for {G}erman-{F}rench Language Pairs,2019,-1,-1,4,0.637033,13777,fethi bougares,"Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",0,This paper describes the neural machine translation (NMT) systems of the LIUM Laboratory developed for the FrenchâGerman news translation task of the Fourth Conference onMachine Translation (WMT 2019). The chosen language pair is included for the first time in the WMT news translation task. We de-scribe how the training and the evaluation data was created. We also present our participation in the FrenchâGerman translation directions using self-attentional Transformer networks with small and big architectures.
N19-1422,Probing the Need for Visual Context in Multimodal Machine Translation,2019,31,2,4,1,10667,ozan caglayan,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Current work on multimodal machine translation (MMT) has suggested that the visual modality is either unnecessary or only marginally beneficial. We posit that this is a consequence of the very simple, short and repetitive sentences used in the only available dataset for the task (Multi30K), rendering the source text sufficient as context. In the general case, however, we believe that it is possible to combine visual and textual information in order to ground translations. In this paper we probe the contribution of the visual modality to state-of-the-art MMT models by conducting a systematic analysis where we partially deprive the models from source-side textual context. Our results show that under limited textual context, models are capable of leveraging the visual input to generate better translations. This contradicts the current belief that MMT models disregard the visual modality because of either the quality of the image features or the way they are integrated into the model."
2019.jeptalnrecital-court.13,{\\'E}tude de l{'}apprentissage par transfert de syst{\\`e}mes de traduction automatique neuronaux (Study on transfer learning in neural machine translation ),2019,-1,-1,3,0,23859,adrien bardet,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"L{'}apprentissage par transfert est une solution au probl{\`e}me de l{'}apprentissage de syst{\`e}mes de traduction automatique neuronaux pour des paires de langues peu dot{\'e}es. Dans cet article, nous proposons une analyse de cette m{\'e}thode. Nous souhaitons {\'e}valuer l{'}impact de la quantit{\'e} de donn{\'e}es et celui de la proximit{\'e} des langues impliqu{\'e}es pour obtenir le meilleur transfert possible. Nous prenons en compte ces deux param{\`e}tres non seulement pour une t{\^a}che de traduction {``}classique{''} mais {\'e}galement lorsque les corpus de donn{\'e}es font d{\'e}faut. Enfin, il s{'}agit de proposer une approche o{\`u} volume de donn{\'e}es et proximit{\'e} des langues sont combin{\'e}es afin de ne plus avoir {\`a} trancher entre ces deux {\'e}l{\'e}ments."
W18-6402,Findings of the Third Shared Task on Multimodal Machine Translation,2018,0,22,1,1,8740,loic barrault,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We present the results from the third shared task on multimodal machine translation. In this task a source sentence in English is supplemented by an image and participating systems are required to generate a translation for such a sentence into German, French or Czech. The image can be used in addition to (or instead of) the source sentence. This year the task was extended with a third target language (Czech) and a new test set. In addition, a variant of this task was introduced with its own test set where the source sentence is given in multiple languages: English, French and German, and participating systems are required to generate a translation in Czech. Seven teams submitted 45 different systems to the two variants of the task. Compared to last year, the performance of the multimodal submissions improved, but text-only systems remain competitive."
W18-6438,{LIUM}-{CVC} Submissions for {WMT}18 Multimodal Translation Task,2018,16,0,4,1,10667,ozan caglayan,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,This paper describes the multimodal Neural Machine Translation systems developed by LIUM and CVC for WMT18 Shared Task on Multimodal Translation. This year we propose several modifications to our previous multimodal attention architecture in order to better integrate convolutional features and refine them using encoder-side information. Our final constrained submissions ranked first for EnglishâFrench and second for EnglishâGerman language pairs among the constrained submissions according to the automatic evaluation metric METEOR.
P18-1198,What you can cram into a single {\\$}{\\&}!{\\#}* vector: Probing sentence embeddings for linguistic properties,2018,41,71,4,0.857143,2456,alexis conneau,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. {``}Downstream{''} tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods."
W17-4703,Word Representations in Factored Neural Machine Translation,2017,0,4,3,0,23863,franck burlot,Proceedings of the Second Conference on Machine Translation,0,"Translation into a morphologically rich languagen  requires a large output vocabulary to model variousn  morphological phenomena, which is a challenge forn  neural machine translation architectures. To address this issue,n  the present paper investigates the impact of havingn  two output factors with a system able to generaten  separately two distinct representations of the targetn  words. Within this framework, we investigaten  several word representations that correspond ton  different distributions of morpho-syntactic informationn  across both factors. We report experiments for translationn  from English into two morphologically rich languages,n  Czech and Latvian, and show the importance of explicitlyn  modeling target morphology."
W17-4718,Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description,2017,41,12,3,0,2490,desmond elliott,Proceedings of the Second Conference on Machine Translation,0,"We present the results from the second shared task on multimodal machine translation and multilingual image description. Nine teams submitted 19 systems to two tasks. The multimodal translation task, in which the source sentence is supplemented by an image, was extended with a new language (French) and two new test sets. The multilingual image description task was changed such that at test time, only the image is given. Compared to last year, multimodal systems improved, but text-only systems remain competitive."
W17-4726,{LIUM} Machine Translation Systems for {WMT}17 News Translation Task,2017,14,0,6,0,4977,mercedes garciamartinez,Proceedings of the Second Conference on Machine Translation,0,"This paper describes LIUM submissions to WMT17 News Translation Task for English-German, English-Turkish, English-Czech and English-Latvian language pairs. We train BPE-based attentive Neural Machine Translation systems with and without factored outputs using the open source nmtpy framework. Competitive scores were obtained by ensembling various systems and exploiting the availability of target monolingual corpora for back-translation. The impact of back-translation quantity and quality is also analyzed for English-Turkish where our post-deadline submission surpassed the best entry by 1.6 BLEU."
W17-4746,{LIUM}-{CVC} Submissions for {WMT}17 Multimodal Translation Task,2017,17,3,6,1,10667,ozan caglayan,Proceedings of the Second Conference on Machine Translation,0,This paper describes the monomodal and multimodal Neural Machine Translation systems developed by LIUM and CVC for WMT17 Shared Task on Multimodal Translation. We mainly explored two multimodal architectures where either global visual features or convolutional feature maps are integrated in order to benefit from visual context. Our final systems ranked first for both En-De and En-Fr language pairs according to the automatic evaluation metrics METEOR and BLEU.
E17-1104,Very Deep Convolutional Networks for Text Classification,2017,12,185,3,0.857143,2456,alexis conneau,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"The dominant approach for many NLP tasks are recurrent neural networks, in particular LSTMs, and convolutional neural networks. However, these architectures are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in computer vision. We present a new architecture (VDCNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with the depth: using up to 29 convolutional layers, we report improvements over the state-of-the-art on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to text processing."
D17-1070,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data,2017,36,271,4,0.857143,2456,alexis conneau,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."
W16-2358,Does Multimodality Help Human and Machine for Translation and Image Captioning?,2016,26,14,7,1,10667,ozan caglayan,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the systems developed by LIUM and CVC for the WMT16 Multimodal Machine Translation challenge. We explored various comparative methods, namely phrase-based systems and attentional recurrent neural networks models trained using monomodal or multimodaln data. We also performed a human evaluation in order to estimate the usefulness of multimodal data for human machine translation and image description generation. Our systems obtained the best results for both tasks according to the automatic evaluation metrics BLEU and METEOR."
W16-2392,{SHEF}-{LIUM}-{NN}: Sentence level Quality Estimation with Neural Network Features,2016,0,4,3,0.474213,695,kashif shah,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,None
W15-4006,Incremental Adaptation Strategies for Neural Network Language Models,2015,32,6,4,0,36730,alex tersarkisov,Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality,0,"It is today acknowledged that neural network language models outperform backoff language models in applications like speech recognition or statistical machine translation. However, training these models on large amounts of data can take several days. We present efficient techniques to adapt a neural network language model to new data. Instead of training a completely new model or relying on mixture approaches, we propose two new methods: continued training on resampled data or insertion of adaptation layers. We present experimental results in an CAT environment where the post-edits of professional translators are used to improve an SMT system. Both methods are very fast and achieve significant improvements without over-fitting the small adaptation data."
N15-1103,Continuous Adaptation to User Feedback for Statistical Machine Translation,2015,11,0,4,0,3257,frederic blain,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper gives a detailed experiment feedback of different approaches to adapt a statistical machine translation system towards a targeted translation project, using only small amounts of parallel in-domain data. The experiments were performed by professional translators under realistic conditions of work using a computer assisted translation tool. We analyze the influence of these adaptations on the translator productivity and on the overall post-editing effort. We show that significant improvements can be obtained by using the presented adaptation techniques."
2015.iwslt-papers.5,Improving continuous space language models auxiliary features,2015,27,2,3,1,31616,walid aransa,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,None
2015.iwslt-evaluation.7,The {LIUM} {ASR} and {SLT} systems for {IWSLT} 2015,2015,14,0,2,0,38016,mercedes martinez,Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the Automatic Speech Recognition and Spoken Language Translation systems developed by the LIUM for the IWSLT 2015 evaluation campaign. We participated in two of the proposed tasks, namely the Automatic Speech Recognition task (ASR) in German and the English to French Spoken Language Translation task (SLT). We present the approaches and specificities found in our systems, as well as our results from the evaluation campaign."
W14-1002,Using Hypothesis Selection Based Features for Confusion Network {MT} System Combination,2014,9,2,2,0,862,sahar ghannay,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"This paper describes the development operated into MANY, an open source system combination software based on confusion networks developed at LIUM. The hypotheses from Chinese-English MT systems were combined with a new version of the software. MANY has been updated in order to use word confidence score and to boostn-grams occurring in input hypotheses. In this paper we propose either to use an adapted language model or adding some additional features in the decoder to boost certain n-grams probabilities. Experimental results show that the updates yielded significant improvements in terms of BLEU score."
C14-2028,The {M}ate{C}at Tool,2014,7,36,13,0,3526,marcello federico,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"We present a new web-based CAT tool providing translators with a professional work environment, integrating translation memories, terminology bases, concordancers, and machine translation. The tool is completely developed as open source software and has been already successfully deployed for business, research and education. The MateCat Tool represents today probably the best available open source platform for investigating, integrating, and evaluating under realistic conditions the impact of new machine translation technology on human post-editing."
2014.iwslt-evaluation.14,{LIUM} {E}nglish-to-{F}rench spoken language translation system and the Vecsys/{LIUM} automatic speech recognition system for {I}talian language for {IWSLT} 2014,2014,11,1,2,0.666667,17019,anthony rousseau,Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the Spoken Language Translation system developed by the LIUM for the IWSLT 2014 evaluation campaign. We participated in two of the proposed tasks: (i) the Automatic Speech Recognition task (ASR) in two languages, Italian with the Vecsys company, and English alone, (ii) the English to French Spoken Language Translation task (SLT). We present the approaches and specificities found in our systems, as well as the results from the evaluation campaign."
I13-1033,Multimodal Comparable Corpora as Resources for Extracting Parallel Data: Parallel Phrases Extraction,2013,29,4,2,0.740741,5094,haithem afli,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Discovering parallel data in comparable corpora is a promising approach for overcoming the lack of parallel texts in statistical machine translation and other NLP applications. In this paper we propose an alternative to comparable corpora of texts as resources for extracting parallel data: a multimodal comparable corpus of audio and texts. We present a novel method to detect parallel phrases from such corpora based on splitting comparable sentences into fragments, called phrases. The audio is transcribed by an automatic speech recognition system, split into fragments and translated with a baseline statistical machine translation system. We then use information retrieval in a large text corpus in the target language, split also into fragments, and extract parallel phrases. We compared our method with parallel sentences extraction techniques. We evaluate the quality of the extracted data on an English to French translation task and show significant improvements over a state-ofthe-art baseline."
2013.mtsummit-wptp.13,Issues in incremental adaptation of statistical {MT} from human post-edits,2013,19,7,5,0.114055,10592,mauro cettolo,Proceedings of the 2nd Workshop on Post-editing Technology and Practice,0,"This work investigates a crucial aspect for the integration of MT technology into a CAT environment, that is the ability of MT systems to adapt from the user feedback. In particular, we consider the scenario of an MT system tuned for a specific translation project that after each day of work adapts from the post-edited translations created by the user. We apply and compare different state-of-the-art adaptation methods on post-edited translations generated by two professionals during two days of work with a CAT tool embedding MT suggestions. Both translators worked at the same legal document from English into Italian and German, respectively. Although exactly the same amount of translations was available each day for each language , the application of the same adaptation methods resulted in quite different outcomes. This suggests that adaptation strategies should not be applied blindly, but rather taking into account language specific issues, such as data sparsity."
W12-3147,{LIUM}{'}s {SMT} Machine Translation Systems for {WMT} 2012,2012,14,1,5,0.714286,5281,christophe servan,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the development of French--English and English--French statistical machine translation systems for the 2012 WMT shared task evaluation. We developed phrase-based systems based on the Moses decoder, trained on the provided data only. Additionally, new features this year included improved language and translation model adaptation using the cross-entropy score for the corpus selection."
F12-2039,Traduction automatique {\\`a} partir de corpus comparables: extraction de phrases parall{\\`e}les {\\`a} partir de donn{\\'e}es comparables multimodales (Automatic Translation from Comparable corpora : extracting parallel sentences from multimodal comparable corpora) [in {F}rench],2012,0,0,2,0.740741,5094,haithem afli,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
2012.iwslt-papers.6,Semi-supervised transliteration mining from parallel and comparable corpora,2012,16,3,3,1,31616,walid aransa,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,Transliteration is the process of writing a word (mainly proper noun) from one language in the alphabet of another language. This process requires mapping the pronunciation of the word from the source language to the closest possible pronunciation in the target language. In this paper we introduce a new semi-supervised transliteration mining method for parallel and comparable corpora. The method is mainly based on a new suggested Three Levels of Similarity (TLS) scores to extract the transliteration pairs. The first level calculates the similarity of of all vowel letters and consonants letters. The second level calculates the similarity of long vowels and vowel letters at beginning and end position of the words and consonants letters. The third level calculates the similarity consonants letters only. We applied our method on Arabic-English parallel and comparable corpora. We evaluated the extracted transliteration pairs using a statistical based transliteration system. This system is built using letters instead or words as tokens. The transliteration system achieves an accuracy of 0.50 and a mean F-score 0.8958 when trained on transliteration pairs extracted from a parallel corpus. The accuracy is 0.30 and the mean F-score 0.84 when we used instead a comparable corpus to automatically extract the transliteration pairs. This shows that the proposed semi-supervised transliteration mining algorithm is effective and can be applied to other language pairs. We also evaluated two segmentation techniques and reported the impact on the transliteration performance.
2012.amta-papers.21,A General Framework to Weight Heterogeneous Parallel Data for Model Adaptation in Statistical {MT},2012,23,6,2,1,695,kashif shah,Proceedings of the 10th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"The standard procedure to train the translation model of a phrase-based SMT system is to concatenate all available parallel data, to perform word alignment, to extract phrase pairs and to calculate translation probabilities by simple relative frequency. However, parallel data is quite inhomogeneous in many practical applications with respect to several factors like data source, alignment quality, appropriateness to the task, etc. We propose a general framework to take into account these factors during the calculation of the phrase-table, e.g. by better distributing the probability mass of the individual phrase pairs. No additional feature functions are needed. We report results on two well-known tasks: the IWSLT{'}11 and WMT{'}11 evaluations, in both conditions translating from English to French. We give detailed results for different functions to weight the bitexts. Our best systems improve a strong baseline by up to one BLEU point without any impact on the computational complexity during training or decoding."
W11-2115,{MANY} improvements for {WMT}{'}11,2011,-1,-1,1,1,8740,loic barrault,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,None
W11-2158,{LIUM}{'}s {SMT} Machine Translation Systems for {WMT} 2011,2011,16,19,3,0.432659,5770,holger schwenk,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the development of French--English and English--French statistical machine translation systems for the 2011 WMT shared task evaluation. Our main systems were standard phrase-based statistical systems based on the Moses decoder, trained on the provided data only, but we also performed initial experiments with hierarchical systems. Additional, new features this year include improved translation model adaptation using monolingual data, a continuous space language model and the treatment of unknown words."
I11-1148,Parametric Weighting of Parallel Data for Statistical Machine Translation,2011,8,3,2,1,695,kashif shah,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"During the last years there is increasing interest in methods that perform some kind of weighting of heterogeneous parallel training data when building a statistical machine translation system. It was for instance observed that training data that is close to the period of the test data is more valuable than older data (Hardt and Elming, 2010; Levenberg et al., 2010). In this paper we obtain such a weighting by resampling alignments using weights that decrease with the temporal distance of bitexts to the test set. By these means, we can use all the available bitexts and still put an emphasis on the most recent one. The main idea of our approach is to use a parametric form or meta-weights for the weighting of the different parts of the bitexts. This ensures that our approach has only few parameters to optimize. We report experimental results on the Europarl corpus, translating from French to English and further verified it on the official WMTxe2x80x9911 task, translating from English to French. Our method achieves improvements of about 0.6 points BLEU on the test set with respect to a system trained on data without any weighting."
W10-1739,{MANY}: Open Source {MT} System Combination at {WMT}{'}10,2010,-1,-1,1,1,8740,loic barrault,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,None
W10-1759,Translation Model Adaptation by Resampling,2010,16,13,2,1,695,kashif shah,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"The translation model of statistical machine translation systems is trained on parallel data coming from various sources and domains. These corpora are usually concatenated, word alignments are calculated and phrases are extracted. This means that the corpora are not weighted according to their importance to the domain of the translation task. This is in contrast to the training of the language model for which well known techniques are used to weight the various sources of texts. On a smaller granularity, the automatic calculated word alignments differ in quality. This is usually not considered when extracting phrases either.n n In this paper we propose a method to automatically weight the different corpora and alignments. This is achieved with a resampling technique. We report experimental results for a small (IWSLT) and large (NIST) Arabic/English translation tasks. In both cases, significant improvements in the BLEU score were observed."
2010.iwslt-evaluation.14,{LIUM}{'}s statistical machine translation system for {IWSLT} 2010,2010,8,0,2,0.666667,17019,anthony rousseau,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the two systems developed by the LIUM laboratory for the 2010 IWSLT evaluation campaign. We participated to the new English to French TALK task. We developed two systems, one for each evaluation condition, both being statistical phrase-based systems using the the Moses toolkit. Several approaches were investigated."
W09-0423,{SMT} and {SPE} Machine Translation Systems for {WMT}{`}09,2009,14,19,3,0,5770,holger schwenk,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,This paper describes the development of several machine translation systems for the 2009 WMT shared task evaluation. We only consider the translation between French and English. We describe a statistical system based on the Moses decoder and a statistical post-editing system using SYSTRAN's rule-based system. We also investigated techniques to automatically extract additional bilingual texts from comparable corpora.
2009.iwslt-evaluation.10,{LIUM}{'}s statistical machine translation system for {IWSLT} 2009,2009,12,1,2,0,5770,holger schwenk,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the systems developed by the LIUM laboratory for the 2009 IWSLT evaluation. We participated in the Arabic and Chinese to English BTEC tasks. We developed three different systems: a statistical phrase-based system using the Moses toolkit, an Statistical Post-Editing system and a hierarchical phrase-based system based on Joshua. A continuous space language model was deployed to improve the modeling of the target language. These systems are combined by a confusion network based approach."
