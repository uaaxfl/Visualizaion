2020.lrec-1.577,Controllable Sentence Simplification,2020,-1,-1,2,1,17824,louis martin,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Text simplification aims at making a text easier to read and understand by simplifying grammar and structure while keeping the underlying information identical. It is often considered an all-purpose generic task where the same simplification is suitable for all; however multiple audiences can benefit from simplified text in different ways. We adapt a discrete parametrization mechanism that provides explicit control on simplification systems based on Sequence-to-Sequence models. As a result, users can condition the simplifications returned by a model on attributes such as length, amount of paraphrasing, lexical complexity and syntactic complexity. We also show that carefully chosen values of these attributes allow out-of-the-box Sequence-to-Sequence models to outperform their standard counterparts on simplification benchmarks. Our model, which we call ACCESS (as shorthand for AudienCe-CEntric Sentence Simplification), establishes the state of the art at 41.87 SARI on the WikiLarge test set, a +1.42 improvement over the best previously reported score."
2020.jeptalnrecital-taln.5,Les mod{\\`e}les de langue contextuels Camembert pour le fran{\\c{c}}ais : impact de la taille et de l{'}h{\\'e}t{\\'e}rog{\\'e}n{\\'e}it{\\'e} des donn{\\'e}es d{'}entrainement ({C} {AMEM} {BERT} Contextual Language Models for {F}rench: Impact of Training Data Size and Heterogeneity ),2020,-1,-1,6,1,17824,louis martin,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Les mod{\`e}les de langue neuronaux contextuels sont d{\'e}sormais omnipr{\'e}sents en traitement automatique des langues. Jusqu{'}{\`a} r{\'e}cemment, la plupart des mod{\`e}les disponibles ont {\'e}t{\'e} entra{\^\i}n{\'e}s soit sur des donn{\'e}es en anglais, soit sur la concat{\'e}nation de donn{\'e}es dans plusieurs langues. L{'}utilisation pratique de ces mod{\`e}les {---} dans toutes les langues sauf l{'}anglais {---} {\'e}tait donc limit{\'e}e. La sortie r{\'e}cente de plusieurs mod{\`e}les monolingues fond{\'e}s sur BERT (Devlin et al., 2019), notamment pour le fran{\c{c}}ais, a d{\'e}montr{\'e} l{'}int{\'e}r{\^e}t de ces mod{\`e}les en am{\'e}liorant l{'}{\'e}tat de l{'}art pour toutes les t{\^a}ches {\'e}valu{\'e}es. Dans cet article, {\`a} partir d{'}exp{\'e}riences men{\'e}es sur CamemBERT (Martin et al., 2019), nous montrons que l{'}utilisation de donn{\'e}es {\`a} haute variabilit{\'e} est pr{\'e}f{\'e}rable {\`a} des donn{\'e}es plus uniformes. De fa{\c{c}}on plus surprenante, nous montrons que l{'}utilisation d{'}un ensemble relativement petit de donn{\'e}es issues du web (4Go) donne des r{\'e}sultats aussi bons que ceux obtenus {\`a} partir d{'}ensembles de donn{\'e}es plus grands de deux ordres de grandeurs (138Go)."
2020.cmlc-1.3,{F}rench Contextualized Word-Embeddings with a sip of {C}a{B}e{R}net: a New {F}rench Balanced Reference Corpus,2020,-1,-1,4,0,21816,murielle popafabre,Proceedings of the 8th Workshop on Challenges in the Management of Large Corpora,0,"This paper investigates the impact of different types and size of training corpora on language models. By asking the fundamental question of quality versus quantity, we compare four French corpora by pre-training four different ELMos and evaluating them on dependency parsing, POS-tagging and Named Entities Recognition downstream tasks. We present and asses the relevance of a new balanced French corpus, CaBeRnet, that features a representative range of language usage, including a balanced variety of genres (oral transcriptions, newspapers, popular magazines, technical reports, fiction, academic texts), in oral and written styles. We hypothesize that a linguistically representative corpus will allow the language models to be more efficient, and therefore yield better evaluation scores on different evaluation sets and tasks. This paper offers three main contributions: (1) two newly built corpora: (a) CaBeRnet, a French Balanced Reference Corpus and (b) CBT-fr a domain-specific corpus having both oral and written style in youth literature, (2) five versions of ELMo pre-trained on differently built corpora, and (3) a whole array of computational results on downstream tasks that deepen our understanding of the effects of corpus balance and register in NLP evaluation."
2020.acl-main.645,{C}amem{BERT}: a Tasty {F}rench Language Model,2020,-1,-1,6,1,17824,louis martin,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models {--}in all languages except English{--} very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks."
W19-7816,Challenges of language change and variation: towards an extended treebank of Medieval {F}rench,2019,-1,-1,3,0,23441,mathilde regnault,"Proceedings of the 18th International Workshop on Treebanks and Linguistic Theories (TLT, SyntaxFest 2019)",0,None
S19-2211,{INRIA} at {S}em{E}val-2019 Task 9: Suggestion Mining Using {SVM} with Handcrafted Features,2019,0,1,2,0,442,ilia markov,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"We present the INRIA approach to the suggestion mining task at SemEval 2019. The task consists of two subtasks: suggestion mining under single-domain (Subtask A) and cross-domain (Subtask B) settings. We used the Support Vector Machines algorithm trained on handcrafted features, function words, sentiment features, digits, and verbs for Subtask A, and handcrafted features for Subtask B. Our best run archived a F1-score of 51.18{\%} on Subtask A, and ranked in the top ten of the submissions for Subtask B with 73.30{\%} F1-score."
W18-7005,Reference-less Quality Estimation of Text Simplification Systems,2018,0,6,4,1,17824,louis martin,Proceedings of the 1st Workshop on Automatic Text Adaptation ({ATA}),0,"The evaluation of text simplification (TS) systems remains an open challenge. As the task has common points with machine translation (MT), TS is often evaluated using MT metrics such as BLEU. However, such metrics require high quality reference data, which is rarely available for TS. TS has the advantage over MT of being a monolingual task, which allows for direct comparisons to be made between the simplified text and its original version. In this paper, we compare multiple approaches to reference-less quality estimation of sentence-level text simplification systems, based on the dataset used for the QATS 2016 shared task. We distinguish three different dimensions: gram-maticality, meaning preservation and simplicity. We show that n-gram-based MT metrics such as BLEU and METEOR correlate the most with human judgment of grammaticality and meaning preservation, whereas simplicity is best evaluated by basic length-based metrics."
L18-1064,{ANCOR}-{AS}: Enriching the {ANCOR} Corpus with Syntactic Annotations,2018,0,0,3,1,5600,loic grobol,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This paper presents ANCOR-AS, an enriched version of the ANCOR corpus. This version adds syntactic annotations in addition to the existing coreference and speech transcription ones. This corpus is also released in a new TEI-compliant XML format."
L18-1718,Cheating a Parser to Death: Data-driven Cross-Treebank Annotation Transfer,2018,0,0,2,0,167,djame seddah,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"We present an efficient and accurate method for transferring annotations between two different treebanks of the same language. This method led to the creation of a new instance of the French Treebank (Abeille et al., 2003), which follows the Universal Dependency annotation scheme and which was proposed to the participants of the CoNLL 2017 Universal Dependency parsing shared task (Zeman et al., 2017). Strong results from an evaluation on our gold standard (94.75% of LAS, 99.40% UAS on the test set) demonstrate the quality of this new annotated data set and validate our approach."
K18-2023,{ELM}o{L}ex: Connecting {ELM}o and Lexicon Features for Dependency Parsing,2018,0,1,5,0,12015,ganesh jawahar,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"In this paper, we present the details of the neural dependency parser and the neural tagger submitted by our team {`}ParisNLP{'} to the CoNLL 2018 Shared Task on parsing from raw text to Universal Dependencies. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively: we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations; we utilize disambiguated, embedded, morphosyntactic features from lexicons (Sagot, 2018), which complements the existing feature set. Henceforth, we call our system {`}ELMoLex{'}. In addition to incorporating character embeddings, ELMoLex benefits from pre-trained word vectors, ELMo and morphosyntactic features (whenever available) to correctly handle rare or unknown words which are prevalent in languages with complex morphology. ELMoLex ranked 11th by Labeled Attachment Score metric (70.64{\%}), Morphology-aware LAS metric (55.74{\%}) and ranked 9th by Bilexical dependency metric (60.70{\%})."
K17-3026,The {P}aris{NLP} entry at the {C}on{LL} {UD} Shared Task 2017: A Tale of a {\\#}{P}arsing{T}ragedy,2017,4,0,1,1,17825,eric clergerie,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task. In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers. All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected. Unfortunately, a glitch in the shared task{'}s Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models. Because of this {\#}ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th."
2017.jeptalnrecital-court.25,Apports des analyses syntaxiques pour la d{\\'e}tection automatique de mentions dans un corpus de fran{\\c{c}}ais oral (Experiences in using deep and shallow parsing to detect entity mentions in oral {F}rench),2017,-1,-1,3,1,5600,loic grobol,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"Cet article pr{\'e}sente trois exp{\'e}riences de d{\'e}tection de mentions dans un corpus de fran{\c{c}}ais oral : ANCOR. Ces exp{\'e}riences utilisent des outils pr{\'e}existants d{'}analyse syntaxique du fran{\c{c}}ais et des m{\'e}thodes issues de travaux sur la cor{\'e}f{\'e}rence, les anaphores et la d{\'e}tection d{'}entit{\'e}s nomm{\'e}es. Bien que ces outils ne soient pas optimis{\'e}s pour le traitement de l{'}oral, la qualit{\'e} de la d{\'e}tection des mentions que nous obtenons est comparable {\`a} l{'}{\'e}tat de l{'}art des syst{\`e}mes con{\c{c}}us pour l{'}{\'e}crit dans d{'}autres langues. Nous concluons en proposant des perspectives pour l{'}am{\'e}lioration des r{\'e}sultats que nous obtenons et la construction d{'}un syst{\`e}me end-to-end pour lequel nos exp{\'e}riences peuvent servir de base de travail."
L16-1566,Accurate Deep Syntactic Parsing of Graphs: The Case of {F}rench,2016,0,0,2,1,30903,corentin ribeyre,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Parsing predicate-argument structures in a deep syntax framework requires graphs to be predicted. Argument structures represent a higher level of abstraction than the syntactic ones and are thus more difficult to predict even for highly accurate parsing models on surfacic syntax. In this paper we investigate deep syntax parsing, using a French data set (Ribeyre et al., 2014a). We demonstrate that the use of topologically different types of syntactic features, such as dependencies, tree fragments, spines or syntactic paths, brings a much needed context to the parser. Our higher-order parsing model, gaining thus up to 4 points, establishes the state of the art for parsing French deep syntactic structures."
N15-1007,Because Syntax Does Matter: Improving Predicate-Argument Structures Parsing with Syntactic Features,2015,44,2,2,1,30903,corentin ribeyre,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Parsing full-fledged predicate-argument structures in a deep syntax framework requires graphs to be predicted. Using the DeepBank (Flickinger et al., 2012) and the Predicate-Argument Structure treebank (Miyao and Tsujii, 2005) as a test field, we show how transition-based parsers, extended to handle connected graphs, benefit from the use of topologically different syntactic features such as dependencies, tree fragments, spines or syntactic paths, bringing a much needed context to the parsing models, improving notably over long distance dependencies and elided coordinate structures. By confirming this positive impact on an accurate 2nd-order graph-based parser (Martins and Almeida, 2014), we establish a new state-of-the-art on these data sets."
S14-2012,{A}lpage: Transition-based Semantic Graph Parsing with Syntactic Features,2014,24,4,2,1,30903,corentin ribeyre,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper describes the systems deployed by the ALPAGE team to participate to the SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing. We developed two transition-based dependency parsers with extended sets of actions to handle non-planar acyclic graphs. For the open track, we worked over two orthogonal axes xe2x80x90 lexical and syntactic xe2x80x90 in order to provide our models with lexical and syntactic features such as word clusters, lemmas and tree fragments of different types."
candito-etal-2014-deep,Deep Syntax Annotation of the Sequoia {F}rench Treebank,2014,27,7,7,0,16504,marie candito,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We define a deep syntactic representation scheme for French, which abstracts away from surface syntactic variation and diathesis alternations, and describe the annotation of deep syntactic representations on top of the surface dependency trees of the Sequoia corpus. The resulting deep-annotated corpus, named deep-sequoia, is freely available, and hopefully useful for corpus linguistics studies and for training deep analyzers to prepare semantic analysis."
morardo-villemonte-de-la-clergerie-2014-towards,Towards an environment for the production and the validation of lexical semantic resources,2014,14,0,2,0,39675,mikael morardo,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present the components of a processing chain for the creation, visualization, and validation of lexical resources (formed of terms and relations between terms). The core of the chain is a component for building lexical networks relying on Harris{'} distributional hypothesis applied on the syntactic dependencies produced by the French parser FRMG on large corpora. Another important aspect concerns the use of an online interface for the visualization and collaborative validation of the resulting resources."
F14-1007,Playing with parsers (Jouer avec des analyseurs syntaxiques) [in {F}rench],2014,-1,-1,1,1,17825,eric clergerie,Proceedings of TALN 2014 (Volume 1: Long Papers),0,None
W13-5706,Improving a symbolic parser through partially supervised learning,2013,9,2,1,1,17825,eric clergerie,Proceedings of the 13th International Conference on Parsing Technologies ({IWPT} 2013),0,"Recently, several statistical parsers have been trained and evaluated on the dependency version of the French TreeBank (FTB). However, older symbolic parsers still exist, including FRMG, a wide coverage TAG parser. It is interesting to compare these different parsers, based on very different approaches, and explore the possibilities of hybridization. In particular, we explore the use of partially supervised learning techniques to improve the performances of FRMG to the levels reached by the statistical parsers."
W13-4906,Exploring beam-based shift-reduce dependency parsing with {D}y{AL}og: Results from the {SPMRL} 2013 shared task,2013,23,7,1,1,17825,eric clergerie,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"The SPMRL 2013 shared task was the op- portunity to develop and test, with promising results, a simple beam-based shift-reduce de- pendency parser on top of the tabular logic programming system DYALOG. The parser was also extended to handle ambiguous word lattices, with almost no loss w.r.t. disam- biguated input, thanks to specific training, use of oracle segmentation, and large beams. We believe that this result is an interesting new one for shift-reduce parsing."
W13-4917,Overview of the {SPMRL} 2013 Shared Task: A Cross-Framework Evaluation of Parsing Morphologically Rich Languages,2013,110,38,23,0.165615,167,djame seddah,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"This paper reports on the first shared task on statistical parsing of morphologically rich languages (MRLs). The task features data sets from nine languages, each available both in constituency and dependency annotation. We report on the preparation of the data sets, on the proposed parsing scenarios, and on the evaluation metrics for parsing MRLs given different representation types. We present and analyze parsing results obtained by the task participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios."
W12-4625,A linguistically-motivated 2-stage Tree to Graph Transformation,2012,-1,-1,3,1,30903,corentin ribeyre,Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+11),0,None
tolone-etal-2012-evaluating,Evaluating and improving syntactic lexica by plugging them within a parser,2012,17,1,3,0,43065,elsa tolone,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We present some evaluation results for four French syntactic lexica, obtained through their conversion to the Alexina format used by the Lefff lexicon, and their integration within the large-coverage TAG-based FRMG parser. The evaluations are run on two test corpora, annotated with two distinct annotation formats, namely EASy/Passage chunks and relations and CoNLL dependencies. The information provided by the evaluation results provide valuable feedback about the four lexica. Moreover, when coupled with error mining techniques, they allow us to identify how these lexica might be improved."
gabor-etal-2012-boosting,Boosting the Coverage of a Semantic Lexicon by Automatically Extracted Event Nominalizations,2012,18,0,4,0,22563,kata gabor,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this article, we present a distributional analysis method for extracting nominalization relations from monolingual corpora. The acquisition method makes use of distributional and morphological information to select nominalization candidates. We explain how the learning is performed on a dependency annotated corpus and describe the nominalization results. Furthermore, we show how these results served to enrich an existing lexical resource, the WOLF (Wordnet Libre du Franc{\^A}{\c{}}ais). We present the techniques that we developed in order to integrate the new information into WOLF, based on both its structure and content. Finally, we evaluate the validity of the automatically obtained information and the correctness of its integration into the semantic resource. The method proved to be useful for boosting the coverage of WOLF and presents the advantage of filling verbal synsets, which are particularly difficult to handle due to the high level of verbal polysemy."
W10-4414,Building factorized {TAG}s with meta-grammars,2010,-1,-1,1,1,17825,eric clergerie,Proceedings of the 10th International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+10),0,None
paroubek-etal-2010-second,The Second Evaluation Campaign of {PASSAGE} on Parsing of {F}rench,2010,-1,-1,3,0,5615,patrick paroubek,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,None
vilnat-etal-2010-passage,{PASSAGE} Syntactic Representation: a Minimal Common Ground for Evaluation,2010,14,9,3,0.626908,15243,anne vilnat,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The current PASSAGE syntactic representation is the result of 9 years of constant evolution with the aim of providing a common ground for evaluating parsers of French whatever their type and supporting theory. In this paper we present the latest developments concerning the formalism and show first through a review of basic linguistic phenomena that it is a plausible minimal common ground for representing French syntax in the context of generic black box quantitative objective evaluation. For the phenomena reviewed, which include: the notion of syntactic head, apposition, control and coordination, we explain how PASSAGE representation relates to other syntactic representation schemes for French and English, slightly extending the annotation to address English when needed. Second, we describe the XML format chosen for PASSAGE and show that it is compliant with the latest propositions in terms of linguistic annotation standard. We conclude discussing the influence that corpus-based evaluation has on the characteristics of syntactic representation when willing to assess the performance of any kind of parser."
2010.jeptalnrecital-long.10,Convertir des d{\\'e}rivations {TAG} en d{\\'e}pendances,2010,-1,-1,1,1,17825,eric clergerie,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les structures de d{\'e}pendances syntaxiques sont importantes et bien adapt{\'e}es comme point de d{\'e}part de diverses applications. Dans le cadre de l{'}analyseur TAG FRMG, nous pr{\'e}sentons les d{\'e}tails d{'}un processus de conversion de for{\^e}ts partag{\'e}es de d{\'e}rivations en for{\^e}ts partag{\'e}es de d{\'e}pendances. Des {\'e}l{\'e}ments d{'}information sont fournis sur un algorithme de d{\'e}sambiguisation sur ces for{\^e}ts de d{\'e}pendances."
2010.jeptalnrecital-court.33,Exploitation de r{\\'e}sultats d{'}analyse syntaxique pour extraction semi-supervis{\\'e}e des chemins de relations,2010,-1,-1,2,0,44955,yayoi nakamuradelloye,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Le pr{\'e}sent article d{\'e}crit un travail en cours sur l{'}acquisition des patrons de relations entre entit{\'e}s nomm{\'e}es {\`a} partir de r{\'e}sultats d{'}analyse syntaxique. Sans aucun patron pr{\'e}d{\'e}fini, notre m{\'e}thode fournit des chemins syntaxiques susceptibles de repr{\'e}senter une relation donn{\'e}e {\`a} partir de quelques exemples de couples d{'}entit{\'e}s nomm{\'e}es entretenant la relation en question."
R09-1058,Towards Efficient Production of Linguistic Resources: the {V}ictoria Project,2009,9,2,5,1,3003,lionel nicolas,Proceedings of the International Conference {RANLP}-2009,0,"In order to produce efficient Natural Language Pro- cessing (NLP) tools, reliable linguistic resources are a preliminary requirement. When available for a given language, the resources are generally far below the ex- pectations in terms of quality, coverage or usability. This paper presents a project whose ambition is to en- hance the production capacities of linguistic resources through the creation and intensive use of intercon- nected acquisition and correction tools, inter-lingual transfer processes and a collaborative online develop- ment framework."
2009.jeptalnrecital-long.23,Trouver et confondre les coupables : un processus sophistiqu{\\'e} de correction de lexique,2009,0,1,5,1,3003,lionel nicolas,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"La couverture d{'}un analyseur syntaxique d{\'e}pend avant tout de la grammaire et du lexique sur lequel il repose. Le d{\'e}veloppement d{'}un lexique complet et pr{\'e}cis est une t{\^a}che ardue et de longue haleine, surtout lorsque le lexique atteint un certain niveau de qualit{\'e} et de couverture. Dans cet article, nous pr{\'e}sentons un processus capable de d{\'e}tecter automatiquement les entr{\'e}es manquantes ou incompl{\`e}tes d{'}un lexique, et de sugg{\'e}rer des corrections pour ces entr{\'e}es. La d{\'e}tection se r{\'e}alise au moyen de deux techniques reposant soit sur un mod{\`e}le statistique, soit sur les informations fournies par un {\'e}tiqueteur syntaxique. Les hypoth{\`e}ses de corrections pour les entr{\'e}es lexicales d{\'e}tect{\'e}es sont g{\'e}n{\'e}r{\'e}es en {\'e}tudiant les modifications qui permettent d{'}am{\'e}liorer le taux d{'}analyse des phrases dans lesquelles ces entr{\'e}es apparaissent. Le processus global met en oeuvre plusieurs techniques utilisant divers outils tels que des {\'e}tiqueteurs et des analyseurs syntaxiques ou des classifieurs d{'}entropie. Son application au Lefff , un lexique morphologique et syntaxique {\`a} large couverture du fran{\c{c}}ais, nous a d{\'e}j{\`a} permis de r{\'e}aliser des am{\'e}liorations notables."
W08-1306,Large Scale Production of Syntactic Annotations to Move Forward,2008,19,1,6,0.626908,15243,anne vilnat,Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,0,"This article presents the methodology of the PASSAGE project, aiming at syntactically annotating large corpora by composing annotations. It introduces the annotation format and the syntactic annotation specifications. It describes an important component of the methodolgy, namely an WEB-based evaluation service, deployed in the context of the first PASSAGE parser evaluation campaign."
villemonte-de-la-clergerie-etal-2008-passage,{PASSAGE}: from {F}rench Parser Evaluation to Large Sized Treebank,2008,11,23,1,1,17825,eric clergerie,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper we present the PASSAGE project which aims at building automatically a French Treebank of large size by combining the output of several parsers, using the EASY annotation scheme. We present also the results of the of the first evaluation campaign of the project and the preliminary results we have obtained with our ROVER procedure for combining parsers automatically."
C08-1080,Computer Aided Correction and Extension of a Syntactic Wide-Coverage Lexicon,2008,9,10,5,1,3003,lionel nicolas,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"The effectiveness of parsers based on manually created resources, namely a grammar and a lexicon, rely mostly on the quality of these resources. Thus, increasing the parser coverage and precision usually implies improving these two resources. Their manual improvement is a time consuming and complex task: identifying which resource is the true culprit for a given mistake is not always obvious, as well as finding the mistake and correcting it.n n Some techniques, like van Noord (2004) or Sagot and Villemonte de La Clergerie (2006), bring a convenient way to automatically identify forms having potentially erroneous entries in a lexicon. We have integrated and extended such techniques in a wider process which, thanks to the grammar ability to tell how these forms could be used as part of correct parses, is able to propose lexical corrections for the identified entries.n n We present in this paper an implementation of this process and discuss the main results we have obtained on a syntactic wide-coverage French lexicon."
2007.jeptalnrecital-long.29,Confondre le coupable : corrections d{'}un lexique sugg{\\'e}r{\\'e}es par une grammaire,2007,-1,-1,3,1,3003,lionel nicolas,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Le succ{\`e}s de l{'}analyse syntaxique d{'}une phrase d{\'e}pend de la qualit{\'e} de la grammaire sous-jacente mais aussi de celle du lexique utilis{\'e}. Une premi{\`e}re {\'e}tape dans l{'}am{\'e}lioration des lexiques consiste {\`a} identifier les entr{\'e}es lexicales potentiellement erron{\'e}es, par exemple en utilisant des techniques de fouilles d{'}erreurs sur corpus (Sagot {\&} Villemonte de La Clergerie, 2006). Nous explorons ici l{'}{\'e}tape suivante : la suggestion de corrections pour les entr{\'e}es identifi{\'e}es. Cet objectif est atteint au travers de r{\'e}analyses des phrases rejet{\'e}es {\`a} l{'}{\'e}tape pr{\'e}c{\'e}dente, apr{\`e}s modification des informations port{\'e}es par les entr{\'e}es suspect{\'e}es. Un calcul statistique sur les nouveaux r{\'e}sultats permet ensuite de mettre en valeur les corrections les plus pertinentes."
P06-1042,Error Mining in Parsing Results,2006,5,30,2,0.777778,250,benoit sagot,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We introduce an error mining technique for automatically detecting errors in resources that are used in parsing systems. We applied this technique on parsing results produced on several million words by two distinct parsing systems, which share the syntactic lexicon and the pre-parsing processing chain. We were thus able to identify missing and erroneous information in these resources."
sagot-etal-2006-lefff,"The Lefff 2 syntactic lexicon for {F}rench: architecture, acquisition, use",2006,6,74,3,0.777778,250,benoit sagot,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper, we introduce a new lexical resource for French which is freely available as the second version of the Lefff (Lexique des formes fl{\'e}chies du fran{\c{c}}ais - Lexicon of French inflected forms). It is a wide-coverage morphosyntactic and syntactic lexicon, whose architecture relies on properties inheritance, which makes it more compact and more easily maintainable and allows to describe lexical entries independantly from the formalisms it is used for. For these two reasons, we define it as a meta-lexicon. We describe its architecture, several automatic or semi-automatic approaches we use to acquire, correct and/or enrich such a lexicon, as well as the way it is used both with an LFG parser and with a TAG parser based on a meta-grammar, so as to build two large-coverage parsers for French. The web site of the Lefff is http://www.lefff.net/."
2006.jeptalnrecital-long.26,Trouver le coupable : Fouille d{'}erreurs sur des sorties d{'}analyseurs syntaxiques,2006,-1,-1,2,0.777778,250,benoit sagot,Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Nous pr{\'e}sentons une m{\'e}thode de fouille d{'}erreurs pour d{\'e}tecter automatiquement des erreurs dans les ressources utilis{\'e}es par les syst{\`e}mes d{'}analyse syntaxique. Nous avons mis en oeuvre cette m{\'e}thode sur le r{\'e}sultat de l{'}analyse de plusieurs millions de mots par deux syst{\`e}mes d{'}analyse diff{\'e}rents qui ont toutefois en commun le lexique syntaxique et la cha{\^\i}ne de traitement pr{\'e}-syntaxique. Nous avons pu identifier ainsi des inexactitudes et des incompl{\'e}tudes dans les ressources utilis{\'e}es. En particulier, la comparaison des r{\'e}sultats obtenus sur les sorties des deux analyseurs sur un m{\^e}me corpus nous a permis d{'}isoler les probl{\`e}mes issus des ressources partag{\'e}es de ceux issus des grammaires."
W05-1522,From metagrammars to factorized {TAG}/{TIG} parsers,2005,1,30,1,1,17825,eric clergerie,Proceedings of the Ninth International Workshop on Parsing Technology,0,This document shows how the factorized syntactic descriptions provided by Meta-Grammars coupled with factorization operators may be used to derive compact large coverage tree adjoining grammars.
2005.jeptalnrecital-long.1,Comment obtenir plus des M{\\'e}ta-Grammaires,2005,-1,-1,2,0,51248,franccois thomasset,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente un environnement de d{\'e}veloppement pour les m{\'e}ta-grammaires (MG), utilis{\'e} pour concevoir rapidement une grammaire d{'}arbres adjoints (TAG) du fran{\c{c}}ais {\`a} large couverture et n{\'e}anmoins tr{\`e}s compacte, gr{\^a}ce {\`a} des factorisations d{'}arbres. Exploitant les fonctionnalit{\'e}s fournies par le syst{\`e}me DYALOG, cette grammaire a permis de construire un analyseur syntaxique hybride TAG/TIG utilis{\'e} dans le cadre de la campagne d{'}{\'e}valuation syntaxique EASY."
2005.jeptalnrecital-long.11,Cha{\\^\\i}nes de traitement syntaxique,2005,-1,-1,4,0.384615,46836,pierre boullier,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article expose l{'}ensemble des outils que nous avons mis en oeuvre pour la campagne EASy d{'}{\'e}valuation d{'}analyse syntaxique. Nous commen{\c{c}}ons par un aper{\c{c}}u du lexique morphologique et syntaxique utilis{\'e}. Puis nous d{\'e}crivons bri{\`e}vement les propri{\'e}t{\'e}s de notre cha{\^\i}ne de traitement pr{\'e}-syntaxique qui permet de g{\'e}rer des corpus tout-venant. Nous pr{\'e}sentons alors les deux syst{\`e}mes d{'}analyse que nous avons utilis{\'e}s, un analyseur TAG issu d{'}une m{\'e}ta-grammaire et un analyseur LFG. Nous comparons ces deux syst{\`e}mes en indiquant leurs points communs, comme l{'}utilisation intensive du partage de calcul et des repr{\'e}sentations compactes de l{'}information, mais {\'e}galement leurs diff{\'e}rences, au niveau des formalismes, des grammaires et des analyseurs. Nous d{\'e}crivons ensuite le processus de post-traitement, qui nous a permis d{'}extraire de nos analyses les informations demand{\'e}es par la campagne EASy. Nous terminons par une {\'e}valuation quantitative de nos architectures."
lee-etal-2004-towards,Towards an International Standard on Feature Structure Representation,2004,22,18,4,0,18931,kiyong lee,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,This paper describes the preliminary results of a joint initiative of the TEI (Text Encoding Initiative) Consortium and the ISO Committee TC 37SC 4 (language Resource management) to provide a standard for the representation and interchange of feature structures.
W03-0804,International Standard for a Linguistic Annotation Framework,2003,7,89,3,0,16303,nancy ide,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Software Engineering and Architecture of Language Technology Systems ({SEALTS}),0,"This paper describes the outline of a linguistic annotation framework under development by ISO TC37 SC WG1-1. This international standard will provide an architecture for the creation, annotation, and manipulation of linguistic resources and processing software. The outline described here results from a meeting of approximately 20 experts in the field, who determined the principles and fundamental structure of the framework. The goal is to provide maximum flexibility for encoders and annotators, while at the same time enabling interchange and re-use of annotated linguistic resources."
W02-2228,Parsing {MCS} languages with Thread Automata,2002,0,8,1,1,17825,eric clergerie,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,None
C02-1028,Parsing Mildly Context-Sensitive Languages with Thread Automata,2002,4,26,1,1,17825,eric clergerie,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We introduce simple but powerful automata called Thread Automata, to describe a wide range of parsing strategies for Mildly Context-Sensitive languages. Thread Automata are completed by a Dynamic Programming interpretation ensuring that tabular parsing may be performed with polynomial worst-case complexity."
2002.jeptalnrecital-long.6,Construire des analyseurs avec {D}y{AL}og,2002,0,5,1,1,17825,eric clergerie,Actes de la 9{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article survole les fonctionnalit{\'e}s offertes par le syst{\`e}me DyALog pour construire des analyseurs syntaxiques tabulaires. Offrant la richesse d{'}un environnement de programmation en logique, DyALog facilite l{'}{\'e}criture de grammaires, couvre plusieurs formalismes et permet le param{\'e}trage de strat{\'e}gies d{'}analyse."
W01-1509,Tools and resources for {T}ree {A}djoining {G}rammars,2001,8,2,5,0,40010,franccois barthelemy,Proceedings of the {ACL} 2001 Workshop on Sharing Tools and Resources,0,"This paper presents a workbench for Tree Adjoining Grammars that we are currently developing. This workbench includes several tools and resources based on the markup language XML, used as a convenient language to format and exchange linguistic resources."
P01-1007,Guided Parsing of Range Concatenation Languages,2001,9,18,4,0,40010,franccois barthelemy,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"The theoretical study of the range concatenation grammar [RCG] formalism has revealed many attractive properties which may be used in NLP. In particular, range concatenation languages [RCL] can be parsed in polynomial time and many classical grammatical formalisms can be translated into equivalent RCGs without increasing their worst-case parsing time complexity. For example, after translation into an equivalent RCG, any tree adjoining grammar can be parsed in O(n6) time. In this paper, we study a parsing technique whose purpose is to improve the practical efficiency of RCL parsers. The non-deterministic parsing choices of the main parser for a language L are directed by a guide which uses the shared derivation forest output by a prior RCL parser for a suitable superset of L. The results of a practical evaluation of this method on a wide coverage English grammar are given."
N01-1022,Refining Tabular Parsers for {TAG}s,2001,4,8,1,1,17825,eric clergerie,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper investigates several refinements of a generic tabular parser for Tree Adjoining Grammars. The resulting parser is simpler and more efficient in practice, even though the worst case complexity is not optimal."
2001.jeptalnrecital-long.4,Atelier {ATOLL} pour les grammaires d{'}arbres adjoints,2001,-1,-1,5,0,40010,franccois barthelemy,Actes de la 8{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,Cet article pr{\'e}sente l{'}environnement de travail que nous d{\'e}veloppons au sein de l{'}{\'e}quipe ATOLL pour les grammaires d{'}arbres adjoints. Cet environnement comprend plusieurs outils et ressources fond{\'e}s sur l{'}emploi du langage de balisage XML. Ce langage facilite la mise en forme et l{'}{\'e}change de ressources linguistiques.
W00-2002,A redefinition of Embedded Push-Down Automata,2000,-1,-1,2,1,31545,miguel alonso,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,None
W00-2003,Practical aspects in compiling tabular {TAG} parsers,2000,4,2,3,1,31545,miguel alonso,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,This paper describes the extension of the system DyALog to compile tabular parsers from Feature Tree Adjoining Grammars. The compilation process uses intermediary 2-stack automata to encode various parsing strategies and a dynamic programming interpretation to break automata derivations into tabulable fragments.
2000.iwpt-1.6,New Tabular Algorithms for Parsing,2000,-1,-1,4,1,31545,miguel alonso,Proceedings of the Sixth International Workshop on Parsing Technologies,0,"We develop a set of new tabular parsing algorithms for Linear Indexed Grammars, including bottom-up algorithms and Earley-like algorithms with and without the valid prefix property, creating a continuum in which one algorithm can in turn be derived from another. The output of these algorithms is a shared forest in the form of a context-free grammar that encodes all possible derivations for a given input string."
E99-1020,Tabular Algorithms for {TAG} Parsing,1999,13,33,3,1,31545,miguel alonso,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We describe several tabular algorithms for Tree Adjoining Grammar parsing, creating a continuum from simple pure bottom-up algorithms to complex predictive algorithms and showing what transformations must be applied to each one in order to obtain the next one in the continuum."
W98-0111,A tabular interpretation of bottom-up automata for {TAG},1998,9,7,1,1,17825,eric clergerie,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,We present a tabular interpretation for a class of 2xe2x80x93Stack Automata that may be used to describe bottom-up parsing strategies for TAGs. The results are also useful for tabulating other existing bottomup automata models for this kind of languages.
P98-2217,A tabular interpretation of a class of 2-Stack Automata,1998,8,13,1,1,17825,eric clergerie,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"The paper presents a tabular interpretation for a kind of 2-Stack Automata. These automata may be used to describe various parsing strategies, ranging from purely top-down to purely bottom-up, for LIGs and TAGs. The tabular interpretation ensures, for all strategies, a time complexity in O(n6) and space complexity in O(n5) where n is the length of the input string."
C98-2212,A tabular interpretation of a class of 2-Stack Automata,1998,8,13,1,1,17825,eric clergerie,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"The paper presents a tabular interpretation for a kind of 2-Stack Automata. These automata may be used to describe various parsing strategies, ranging from purely top-down to purely bottom-up, for LIGs and TAGs. The tabular interpretation ensures, for all strategies, a time complexity in O(n6) and space complexity in O(n5) where n is the length of the input string."
