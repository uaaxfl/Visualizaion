2020.acl-main.676,E17-1088,0,0.0229966,"the input dataset exhibits a high degree of recursion. 6 Low-resource language modeling Both of the previous sections investigated conditional models. The fragments extracted and reused by GECA were essentially synchronous lexicon entries, in line with example (4). We originally motivated GECA with monolingual problems in which we simply wish to improve model judgments about well-formedness, so we conclude with a set of language modeling experiments. We use Wikipedia dumps2 in five languages (Kinyarwanda, Lao, Pashto, Tok Pisin, and a subset of English Wikipedia) as well as the Na dataset of Adams et al. (2017). These languages exhibit the performance of GECA across a range of morpholog7562 2 https://dumps.wikimedia.org/ ENG KIN LAO NA PUS TOK # train tokens 2M 62K 10K 28K 2M 30K 5-MKN + GECA 369 365† 241 239† 315 313† 45.4 45.4 574 570† 44.3 44.1 Table 4: Perplexities on low-resource language modeling in English (ENG), Kinyarwanda (KIN), Lao, Na, Pashto (PUS) and Tok Pisin (TOK). Even with a Kneser–Ney smoothed 5-gram model (5-MKN) rather than a high-capacity neural model, applying GECA leads to small improvements in perplexity. † Significant improvement over 5-gram MKN baseline (paired binomial te"
2020.acl-main.676,W18-5407,0,0.0211912,"P walk right RTURN WALK Figure 2: Example SCAN data. Each example consists of a synthetic natural language command (left) paired with a discrete action sequence (right). 7559 seq2seq + GECA jump / SCAN jump / NACS right / SCAN right / NACS 0.00 ± 0.00 0.87 ± 0.02 0.00 ± 0.00 0.67 ± 0.01 0.00 ± 0.00 0.82 ± 0.04 0.00 ± 0.00 0.82 ± 0.03 Table 1: Sequence match accuracies on SCAN datasets, in which the learner must generalize to new compositional uses of a single lexical item (“jump”) or multi-word modifier (“around right”) when mapping instructions to action sequences (SCAN) or vice-versa (NACS, Bastings et al., 2018). While the sequence-to-sequence model is unable to make any correct generalizations at all, applying GECA enables it to succeed most of the time. Scores are averaged over 10 random seeds; the standard deviation across seeds is shown. All improvements are significant (paired binomial test, p  0.001). ple of the effect of this augmentation procedure, the original jump split has 12620 training examples; GECA generates an additional 395 using 395 distinct templates and 6 distinct fragments. With the original and augmented datasets, we train a one-layer LSTM encoder–decoder model with an embeddin"
2020.acl-main.676,P16-1139,0,0.0322021,"ical structure can be learned given enough data. But the precise point at which this transition occurs is not well characterized, and it is evidently beyond the scale available in many real-world problems. How can we improve the behavior of highquality black-box models in these settings? There are many sophisticated tools available for improving the function approximators or loss functions themselves—structured regularization of parameters (Oh et al., 2017), posterior regularization (Ganchev et al., 2010; Hu et al., 2018), explicit stacks (Grefenstette et al., 2015) and composition operators (Bowman et al., 2016; Russin et al., 2019). These existing proposals tend to be taskand architecture-specific. But to the extent that the generalization problem can be addressed by increasing the scale of the training data, it is natural to ask whether we can address the problem by increasing this scale artificially—in other words, via data augmentation. Data augmentation techniques, which generate auxiliary training data by performing structured transformation or combination of training examples, are widely used in computer vision (Krizhevsky et al., 2012; Zhang et al., 2017; Summers and Dinneen, 2019). Within N"
2020.acl-main.676,J92-4003,0,0.480672,"nce of syntactic categories, and the expressibility of well-formedness rules in terms of these abstract categories, is one of the foundational principles of generative approaches to syntax (Chomsky, 1965). The observation that context provides a strong signal about a sentence fragment’s category is in turn the foundation of distributional techniques for the study of language (Firth, 1957). Combining the two gives the outlines of the above procedure. This combination has a productive history in natural language processing: when fragments are single words, it yields class-based language models (Brown et al., 1992); when fragments are contiguous spans it yields unsupervised parsers (Clark, 2000; Klein and Manning, 2002). The present data augmentation scenario is distinguished mainly by the fact that we are unconcerned with producing a complete generative model of data, or with recovering the latent structure implied by the presence of nested syntactic categories. We can still synthesize high-precision examples of well-formed sequences by identifying individual substitutions that are likely to be correct without understanding how they fit into the grammar as a whole. Indeed, if we are not concerned with"
2020.acl-main.676,P98-1035,0,0.540668,"Missing"
2020.acl-main.676,P05-1033,0,0.285459,"Missing"
2020.acl-main.676,W00-0717,0,0.0782885,"r+pV12vBHIps=&quot;>AAAB7nicbVBNSwMxEJ2tX7V+VT16CRbBU9kVQY9FLx4r2A9ol5JNs21oNglJVixLf4QXD4p49fd489+YbfegrQ8GHu/NMDMvUpwZ6/vfXmltfWNzq7xd2dnd2z+oHh61jUw1oS0iudTdCBvKmaAtyyynXaUpTiJOO9HkNvc7j1QbJsWDnSoaJngkWMwItk7q9LFSWj4NqjW/7s+BVklQkBoUaA6qX/2hJGlChSUcG9MLfGXDDGvLCKezSj81VGEywSPac1TghJowm587Q2dOGaJYalfCorn6eyLDiTHTJHKdCbZjs+zl4n9eL7XxdZgxoVJLBVksilOOrET572jINCWWTx3BRDN3KyJjrDGxLqGKCyFYfnmVtC/qgV8P7i9rjZsijjKcwCmcQwBX0IA7aEILCEzgGV7hzVPei/fufSxaS14xcwx/4H3+AJNij7Y=&lt;/latexit> &lt;latexit ⇡ (2) a. The wug daxed. b. * The sang daxed. This generalization amounts to an inference about syntactic categories (Clark, 2000). Because cat and wug are interchangeable in (1a) and (1b), they are also likely interchangeable elsewhere; cat and sang are not similarly interchangeable. Human learners make judgments like (2) about novel lexical items She puts the wug down in Tempe. Pat puts cats down. (b) (d) Figure 1: Visualization of the proposed approach: two discontinuous sentence fragments (a–b, underlined) which appear in similar environments (a–b, highlighted) are identified. Additional sentences in which the first fragment appears (c) are used to synthesize new examples (d) by substituting in the second fragment. 7"
2020.acl-main.676,N16-1024,0,0.0829611,"Missing"
2020.acl-main.676,P18-1033,0,0.0529193,"ns about compositionality, generalization, and data augmentation. For the reasons discussed in Section 3, we expect qualitatively different behavior from this approach on real language data without the controlled vocabulary of SCAN. We study four versions of the G EO Q UERY dataset (Zelle, 1995), which consists of 880 English questions about United States geography, paired with meaning representations in the form of either logical expressions or SQL queries. The standard train–test split for this dataset ensures that no natural language question is repeated between the train and test sets. As Finegan-Dollak et al. (2018) note, this provides only a limited test of generalization, as many test examples feature a logical form that overlaps with the training data; they introduce a more challenging query split to ensure that neither questions nor logical forms are repeated (even after anonymizing named entities). We extract fragments with at most 2 gaps and at most 12 tokens. On the SQL query split, the original training set contains 695 examples. GECA generates an additional 1055 using 839 distinct templates and 379 distinct fragments. For the question split we use the baseline model of Jia and Liang (2016); for"
2020.acl-main.676,N13-1092,0,0.0862928,"Missing"
2020.acl-main.676,W11-2123,0,0.293571,"on the true support beyond providing useful general inductive bias. Implementation Naïve implementation of the boxed operation takes O(t3 f 3 ) time (where t is the number of distinct templates in the dataset and f the number of distinct fragments). This can be improved to O(f t2 e) (where e is the number of templates that map to the same environment) by building appropriate data structures (Algorithm 1). Space requirements might still be considerable (comparable to those used by n-gram language models), and strategies from the language modeling literature can be used to reduce memory usage (Heafield, 2011). This algorithm is agnostic with respect to the choice of fragmentation and environment functions; task-specific choices are described in more detail for each experiment below. 4 Diagnostic experiments We begin with a set of experiments on synthetic data designed to precisely test whether GECA provides the kind of generalization it was designed for. Here we use the SCAN dataset (Lake and Baroni, 2018), which consists of simple English commands paired with sequences of discrete actions (Figure 2). We focus specifically on the add primitive (jump) and add template (around right) conditions, whi"
2020.acl-main.676,P17-1089,0,0.0762356,"Missing"
2020.acl-main.676,N18-1170,0,0.0270681,"in this paper relies on exact string matching to identify common context; future work might take advantage of learned representations of spans and their environments (Mikolov et al., 2013; Peters et al., 2018). Further improvements are likely obtainable by constraining the extracted fragments to respect constituent boundaries when syntactic information is available. The experiments presented here focus on rewriting sentences using evidence within a dataset to encourage generalization to new outputs. An alternative line of work on paraphrase-based data augmentation (Ganitkevitch et al., 2013; Iyyer et al., 2018) uses external, text-only resources to encourage robust interpretation of new inputs corresponding to known outputs. The two lines of work could be combined, e.g. by using GECA-identified fragments to indicate productive locations for sub-sentential paraphrasing. More generally, the present results underline the extent to which current models fail to learn simple, context-independent notions of reuse, but also how easy it is to make progress towards addressing this problem without fundamental changes in model architecture. Reproducibility Code for all experiments in this paper may be found at"
2020.acl-main.676,P16-1002,0,0.466417,"ciation for Computational Linguistics, pages 7556–7566 c July 5 - 10, 2020. 2020 Association for Computational Linguistics GECA is crude: as a linguistic principle, it is both limited and imprecise. As discussed in Sections 3 and 4, it captures a narrow slice of the many phenomena studied under the heading of “compositionality”, while also making a number of incorrect predictions about real language data. Nevertheless, GECA appears to be quite effective across a range of learning problems. In semantic parsing, it gives improvements comparable to the task-specific data augmentation approach of Jia and Liang (2016) on logical expressions, better performance than that approach on a different split of the data designed to test generalization more rigorously, and corresponding improvements on a version of the dataset with a different meaning representation language. Outside of semantic parsing, it solves two representative problems from the SCAN dataset of Lake and Baroni (2018) that are synthetic but precise in the notion of compositionality they test. Finally, it helps with some (unconditional) low-resource language modeling problems in a typologically diverse set of six languages. 2 Background Recent ye"
2020.acl-main.676,N18-1202,0,0.0144473,"r of scots-irish traders lived among the choctaw and married high-status women . 7563 parsing and language modeling. While the approach is surprisingly effective in its current form, we view these results primarily as an invitation to consider more carefully the role played by representations of sentence fragments in larger questions about compositionality in blackbox sequence models. The procedure detailed in this paper relies on exact string matching to identify common context; future work might take advantage of learned representations of spans and their environments (Mikolov et al., 2013; Peters et al., 2018). Further improvements are likely obtainable by constraining the extracted fragments to respect constituent boundaries when syntactic information is available. The experiments presented here focus on rewriting sentences using evidence within a dataset to encourage generalization to new outputs. An alternative line of work on paraphrase-based data augmentation (Ganitkevitch et al., 2013; Iyyer et al., 2018) uses external, text-only resources to encourage robust interpretation of new inputs corresponding to known outputs. The two lines of work could be combined, e.g. by using GECA-identified fra"
2020.acl-main.676,P02-1017,0,0.0697128,"t categories, is one of the foundational principles of generative approaches to syntax (Chomsky, 1965). The observation that context provides a strong signal about a sentence fragment’s category is in turn the foundation of distributional techniques for the study of language (Firth, 1957). Combining the two gives the outlines of the above procedure. This combination has a productive history in natural language processing: when fragments are single words, it yields class-based language models (Brown et al., 1992); when fragments are contiguous spans it yields unsupervised parsers (Clark, 2000; Klein and Manning, 2002). The present data augmentation scenario is distinguished mainly by the fact that we are unconcerned with producing a complete generative model of data, or with recovering the latent structure implied by the presence of nested syntactic categories. We can still synthesize high-precision examples of well-formed sequences by identifying individual substitutions that are likely to be correct without understanding how they fit into the grammar as a whole. Indeed, if we are not concerned with recovering linguistically plausible analyses, we need not limit ourselves to words or contiguous sentence a"
2020.acl-main.676,D19-1670,0,0.0353466,"at the generalization problem can be addressed by increasing the scale of the training data, it is natural to ask whether we can address the problem by increasing this scale artificially—in other words, via data augmentation. Data augmentation techniques, which generate auxiliary training data by performing structured transformation or combination of training examples, are widely used in computer vision (Krizhevsky et al., 2012; Zhang et al., 2017; Summers and Dinneen, 2019). Within NLP, several data augmentation approaches have been proposed for text classification (e.g. Ratner et al., 2017; Wei and Zhou, 2019); these approaches give improvements even when combined with large-scale pretraining (Hu et al., 2019). Jia and Liang (2016) study data augmentation and compositionality in specific setting of learning language-to-logical-form mappings, beginning from the principle that data is compositional if it is generated by an explicit grammar that relates strings to logical forms. This view of compositionality as determined by synchronicity between form and meaning is essentially Montagovian and well-suited to problems in formal semantics (Montague, 1973); however, it requires access to structured meani"
2020.emnlp-main.703,D16-1125,1,0.840058,"space effectively restricts understanding to small grammars (Paul et al., 2018; Walter et al., 2013) or controlled dialog responses (Thomason et al., 2020). These efforts to translate language instructions to actions build towards using language for end-to-end, continuous control (WS4). Collaborative games have long served as a testbed for studying language (Werner and Dyer, 1991) and emergent communication (Schlangen, 2019a; Lazaridou et al., 2018; Chaabouni et al., 2020). Suhr et al. (2019a) introduced an environment for evaluating language understanding in the service of a shared goal, and Andreas and Klein (2016) use a visual paradigm for studying pragmatics. Such efforts help us examine how inductive biases and environmental pressures build towards socialization (WS5), even if full social context is still too difficult and expensive to be practical. Most of this research provides resources such as data, code, simulators and methodology for evaluating the multimodal content of linguistic representations (Schlangen, 2019b; Silberer and Lapata, 2014; Bruni et al., 2012). Moving forward, we encourage a broad re-examination of how NLP frames the relationship between meaning and context (Bender and Koller,"
2020.emnlp-main.703,2020.acl-main.463,0,0.195512,"s and Klein (2016) use a visual paradigm for studying pragmatics. Such efforts help us examine how inductive biases and environmental pressures build towards socialization (WS5), even if full social context is still too difficult and expensive to be practical. Most of this research provides resources such as data, code, simulators and methodology for evaluating the multimodal content of linguistic representations (Schlangen, 2019b; Silberer and Lapata, 2014; Bruni et al., 2012). Moving forward, we encourage a broad re-examination of how NLP frames the relationship between meaning and context (Bender and Koller, 2020) and how pretraining obfuscates our ability to measure generalization (Linzen, 2020). 7 Conclusions Our World Scopes are steep steps. WS5 implies a persistent agent experiencing time and a personalized set of experiences. confined to IID datasets that lack the structure in time from which humans draw correlations about long-range causal dependencies. What happens if a machine is allowed to participate consistently? This is difficult to test under current evaluation paradigms for generalization. Yet, this is the structure of generalization in human development: drawing analogies to episodic mem"
2020.emnlp-main.703,J92-4003,0,0.0781903,"Missing"
2020.emnlp-main.703,P12-1015,0,0.0358063,"., 2020). Suhr et al. (2019a) introduced an environment for evaluating language understanding in the service of a shared goal, and Andreas and Klein (2016) use a visual paradigm for studying pragmatics. Such efforts help us examine how inductive biases and environmental pressures build towards socialization (WS5), even if full social context is still too difficult and expensive to be practical. Most of this research provides resources such as data, code, simulators and methodology for evaluating the multimodal content of linguistic representations (Schlangen, 2019b; Silberer and Lapata, 2014; Bruni et al., 2012). Moving forward, we encourage a broad re-examination of how NLP frames the relationship between meaning and context (Bender and Koller, 2020) and how pretraining obfuscates our ability to measure generalization (Linzen, 2020). 7 Conclusions Our World Scopes are steep steps. WS5 implies a persistent agent experiencing time and a personalized set of experiences. confined to IID datasets that lack the structure in time from which humans draw correlations about long-range causal dependencies. What happens if a machine is allowed to participate consistently? This is difficult to test under current"
2020.emnlp-main.703,2020.acl-main.407,0,0.0170751,"ng (She et al., 2014) in the real world face challenging, continuous perception and control (Tellex et al., 2020). Consequently, research in this space effectively restricts understanding to small grammars (Paul et al., 2018; Walter et al., 2013) or controlled dialog responses (Thomason et al., 2020). These efforts to translate language instructions to actions build towards using language for end-to-end, continuous control (WS4). Collaborative games have long served as a testbed for studying language (Werner and Dyer, 1991) and emergent communication (Schlangen, 2019a; Lazaridou et al., 2018; Chaabouni et al., 2020). Suhr et al. (2019a) introduced an environment for evaluating language understanding in the service of a shared goal, and Andreas and Klein (2016) use a visual paradigm for studying pragmatics. Such efforts help us examine how inductive biases and environmental pressures build towards socialization (WS5), even if full social context is still too difficult and expensive to be practical. Most of this research provides resources such as data, code, simulators and methodology for evaluating the multimodal content of linguistic representations (Schlangen, 2019b; Silberer and Lapata, 2014; Bruni et"
2020.emnlp-main.703,P14-1113,0,0.0214947,"Missing"
2020.emnlp-main.703,W17-2810,0,0.0700925,"Missing"
2020.emnlp-main.703,J93-2004,0,0.0733849,"al These World Scopes go beyond text to consider the contextual foundations of language: grounding, embodiment, and social interaction. We describe a brief history and ongoing progression of how contextual information can factor into representations and tasks. We conclude with a discussion of how 8718 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 8718–8735, c November 16–20, 2020. 2020 Association for Computational Linguistics 1 WS1: Corpora and Representations The story of data-driven language research begins with the corpus. The Penn Treebank (Marcus et al., 1993) is the canonical example of a clean subset of naturally generated language, processed and annotated for the purpose of studying representations. Such corpora and the model representations built from them exemplify WS1. Community energy was initially directed at finding formal linguistic structure, such as recovering syntax trees. Recent success on downstream tasks has not required such explicitly annotated signal, leaning instead on unstructured fuzzy representations. These representations span from dense word vectors (Mikolov et al., 2013) to contextualized pretrained representations (Peters"
2020.emnlp-main.703,E12-1076,0,0.0176926,"r new research into more challenging world modeling. Mottaghi et al. (2016) predicts the effects of forces on objects in images. Bakhtin et al. (2019) extends this physical reasoning to complex puzzles of cause and effect. Sun et al. (2019b,a) models scripts and actions, and alternative unsupervised training regimes (Bachman et al., 2019) open up research towards automatic concept formation. Advances in computer vision have enabled building semantic representations rich enough to interact with natural language. In the last decade of work descendant from image captioning (Farhadi et al., 2010; Mitchell et al., 2012), a myriad of tasks on visual question answering (Antol et al., 2015; Das et al., 2018; Yagcioglu et al., 2018), natural language and visual reasoning (Suhr et al., 2019b), visual commonsense (Zellers et al., 2019a), 8721 2 3 Or the 1,600 classes of Anderson et al. (2017). Torchvision/Detectron2 include dozens of trained models. and multilingual captioning/translation via video (Wang et al., 2019b) have emerged. These combined text and vision benchmarks are rich enough to train large-scale, multimodal transformers (Li et al., 2019a; Lu et al., 2019; Zhou et al., 2019) without language pretrain"
2020.emnlp-main.703,1985.tmi-1.17,0,0.223965,"achs et al., 1981; O’Grady, 2005; Vigliocco et al., 2014). Perception includes auditory, tactile, and visual input. Even restricted to purely linguistic signals, sarcasm, stress, and meaning can be implied through prosody. Further, tactile senses lend meaning, both physical (Sinapov et al., 2014; Thomason et al., 2016) and abstract, to concepts like heavy and soft. Visual perception is a rich signal for modeling a vastness of experiences in the world that cannot be documented by text alone (Harnad, 1990). For example, frames and scripts (Schank and Abelson, 1977; Charniak, 1977; Dejong, 1981; Mooney and Dejong, 1985) require understanding often unstated sets of pre- and post-conditions about the world. To borrow from Charniak (1977), how should we learn the meaning, method, and implications of painting? A web crawl of knowledge Eugene Charniak (A Framed PAINTING: The Representation of a Common Sense Knowledge Fragment 1977) from an exponential number of possible how-to, text-only guides and manuals (Bisk et al., 2020) is misdirected without some fundamental referents to which to ground symbols. Models must be able to watch and recognize objects, people, and activities to understand the language describing"
2020.emnlp-main.703,N18-1202,0,0.171411,"1993) is the canonical example of a clean subset of naturally generated language, processed and annotated for the purpose of studying representations. Such corpora and the model representations built from them exemplify WS1. Community energy was initially directed at finding formal linguistic structure, such as recovering syntax trees. Recent success on downstream tasks has not required such explicitly annotated signal, leaning instead on unstructured fuzzy representations. These representations span from dense word vectors (Mikolov et al., 2013) to contextualized pretrained representations (Peters et al., 2018; Devlin et al., 2019). Word representations have a long history predating the recent success of deep learning methods. Outside of NLP, philosophy (Austin, 1975) and linguistics (Lakoff, 1973; Coleman and Kay, 1981) recognized that meaning is flexible yet structured. Early experiments on neural networks trained with sequences of words (Elman, 1990; Bengio et al., 2003) suggested that vector representations could capture both syntax and semantics. Subsequent experiments with larger models, documents, and corpora have demonstrated that representations learned from text capture a great deal of in"
2020.emnlp-main.703,D18-1261,0,0.0266104,"perimentation with language starkly contrasts with the disembodied chat bots that are the focus of the current dialogue community (Roller et al., 2020; Adiwardana et al., 2020; Zhou et al., 2020; Chen et al., 2018; Serban et al., 2017), which often do not learn from individual experiences and whose environments are not persistent enough to learn the effects of actions. Theory of Mind When attempting to get what we want, we confront people who have their own desires and identities. The ability to consider the feelings and knowledge of others is now commonly referred to as the “Theory of Mind” (Nematzadeh et al., 2018). This paradigm has also been described under the “Speaker-Listener” model (Stephens et al., 2010), and a rich theory to describe this computationally is being actively developed under the Rational Speech Act Model (Frank and Goodman, 2012; Bergen et al., 2016). A series of challenges that attempt to address this fundamental aspect of communication have been introduced (Nematzadeh et al., 2018; Sap et al., 2019). These works are a great start towards deeper understanding, but static datasets can be problematic due to the risk of embedding spurious patterns and bias (de Vries et al., 2020; Le e"
2020.emnlp-main.703,P19-1506,0,0.0297579,"s rethinking existing tasks and investigating where their semantics can be expanded and grounded. This idea is not new (Chen and Mooney, 2008; Feng and Lapata, 2010; Bruni et al., 2014; Lazaridou et al., 2016) and has accelerated in the last few years. Elliott et al. (2016) reframes machine translation with visual observations, a trend extended into videos (Wang et al., 2019b). Regneri et al. (2013) introduce a foundational dataset aligning text descriptions and semantic annotations of actions with videos. Vision can even inform core tasks like syntax (Shi et al., 2019) and language modeling (Ororbia et al., 2019). Careful design is key, as visually augmented tasks can fail to require sensory perception (Thomason et al., 2019a). Language-guided, embodied agents invoke many of the challenges of WS4. Language-based navigation (Anderson et al., 2018) and task completion (Shridhar et al., 2020) in simulation environments ground language to actions, but even complex simulation action spaces can be discretized and enumerated. By contrast, language-guided robots that perform task completion (Tellex et al., 2014) and learning (She et al., 2014) in the real world face challenging, continuous perception and cont"
2020.emnlp-main.703,P16-1144,1,0.890919,"Missing"
2020.emnlp-main.703,N15-1082,0,0.0556621,"Missing"
2020.emnlp-main.703,D14-1162,0,0.0857475,"s in deep models. Traditionally, transfer learning relied on our understanding of model classes, such as English grammar. Domain adaptation simply required sufficient data to capture lexical variation, by assuming most higherlevel structure would remain the same. Unsupervised representations today capture deep associations across multiple domains, and can be used successfully transfer knowledge into surprisingly diverse contexts (Brown et al., 2020). These representations require scale in terms of both data and parameters. Concretely, Mikolov et al. (2013) trained on 1.6 billion tokens, while Pennington et al. (2014) scaled up to 840 billion tokens from Common Crawl. Recent approaches 1 A parallel discussion would focus on the hardware required to enable advances to higher World Scopes. Playstations (Pinto et al., 2009) and then GPUs (Krizhevsky et al., 2012) made many WS2 advances possible. Perception, interaction, and robotics leverage other new hardware. have made progress by substantially increasing the number of model parameters to better consume these vast quantities of data. Where Peters et al. (2018) introduced ELMo with ∼108 parameters, Transformer models (Vaswani et al., 2017) have continued to"
2020.emnlp-main.703,P18-2124,0,0.0547463,"Missing"
2020.emnlp-main.703,P19-1534,0,0.0307256,"rate language that does something to the world. Passive creation and evaluation of generated language separates generated utterances from their effects on other people, and while the latter is a rich learning signal it is inherently difficult to annotate. In order to learn the effects language has on the world, an agent must participate in linguistic activity, such as negotiation (Yang et al., 2019a; He et al., 2018; Lewis et al., 2017), collaboration (Chai et al., 2017), visual disambiguation (Anderson et al., 2018; Lazaridou et al., 2017; Liu and Chai, 2015), or providing emotional support (Rashkin et al., 2019). These activities require inferring mental states and social outcomes—a key area of interest in itself (Zadeh et al., 2019). What “lame” means in terms of discriminative information is always at question: it can be defined as “undesirable,” but what it tells one about the processes operating in the environment requires social context to determine (Bloom, 2002). It is the toddler’s social experimentation with “You’re so lame!” that gives the word weight and definite intent (Ornaghi et al., 2011). In other words, the discriminative signal for the most foundational part of a word’s meaning can o"
2020.emnlp-main.703,Q13-1003,0,0.0607394,"fool!” can be hurtful, while for others it may seem playful. Social knowledge is requisite for realistic understanding of sentiment in situated human contexts. 8725 Relevant recent work The move from WS2 to WS3 requires rethinking existing tasks and investigating where their semantics can be expanded and grounded. This idea is not new (Chen and Mooney, 2008; Feng and Lapata, 2010; Bruni et al., 2014; Lazaridou et al., 2016) and has accelerated in the last few years. Elliott et al. (2016) reframes machine translation with visual observations, a trend extended into videos (Wang et al., 2019b). Regneri et al. (2013) introduce a foundational dataset aligning text descriptions and semantic annotations of actions with videos. Vision can even inform core tasks like syntax (Shi et al., 2019) and language modeling (Ororbia et al., 2019). Careful design is key, as visually augmented tasks can fail to require sensory perception (Thomason et al., 2019a). Language-guided, embodied agents invoke many of the challenges of WS4. Language-based navigation (Anderson et al., 2018) and task completion (Shridhar et al., 2020) in simulation environments ground language to actions, but even complex simulation action spaces c"
2020.emnlp-main.703,P19-1180,0,0.0412109,"ent work The move from WS2 to WS3 requires rethinking existing tasks and investigating where their semantics can be expanded and grounded. This idea is not new (Chen and Mooney, 2008; Feng and Lapata, 2010; Bruni et al., 2014; Lazaridou et al., 2016) and has accelerated in the last few years. Elliott et al. (2016) reframes machine translation with visual observations, a trend extended into videos (Wang et al., 2019b). Regneri et al. (2013) introduce a foundational dataset aligning text descriptions and semantic annotations of actions with videos. Vision can even inform core tasks like syntax (Shi et al., 2019) and language modeling (Ororbia et al., 2019). Careful design is key, as visually augmented tasks can fail to require sensory perception (Thomason et al., 2019a). Language-guided, embodied agents invoke many of the challenges of WS4. Language-based navigation (Anderson et al., 2018) and task completion (Shridhar et al., 2020) in simulation environments ground language to actions, but even complex simulation action spaces can be discretized and enumerated. By contrast, language-guided robots that perform task completion (Tellex et al., 2014) and learning (She et al., 2014) in the real world fac"
2020.emnlp-main.703,D19-1454,0,0.0599647,"Missing"
2020.emnlp-main.703,P14-1068,1,0.867068,"al., 2018; Chaabouni et al., 2020). Suhr et al. (2019a) introduced an environment for evaluating language understanding in the service of a shared goal, and Andreas and Klein (2016) use a visual paradigm for studying pragmatics. Such efforts help us examine how inductive biases and environmental pressures build towards socialization (WS5), even if full social context is still too difficult and expensive to be practical. Most of this research provides resources such as data, code, simulators and methodology for evaluating the multimodal content of linguistic representations (Schlangen, 2019b; Silberer and Lapata, 2014; Bruni et al., 2012). Moving forward, we encourage a broad re-examination of how NLP frames the relationship between meaning and context (Bender and Koller, 2020) and how pretraining obfuscates our ability to measure generalization (Linzen, 2020). 7 Conclusions Our World Scopes are steep steps. WS5 implies a persistent agent experiencing time and a personalized set of experiences. confined to IID datasets that lack the structure in time from which humans draw correlations about long-range causal dependencies. What happens if a machine is allowed to participate consistently? This is difficult"
2020.emnlp-main.703,D19-1592,0,0.0554394,"Missing"
2020.emnlp-main.703,P18-1238,0,0.112804,"Missing"
2020.emnlp-main.703,W14-4313,1,0.780432,"re tasks like syntax (Shi et al., 2019) and language modeling (Ororbia et al., 2019). Careful design is key, as visually augmented tasks can fail to require sensory perception (Thomason et al., 2019a). Language-guided, embodied agents invoke many of the challenges of WS4. Language-based navigation (Anderson et al., 2018) and task completion (Shridhar et al., 2020) in simulation environments ground language to actions, but even complex simulation action spaces can be discretized and enumerated. By contrast, language-guided robots that perform task completion (Tellex et al., 2014) and learning (She et al., 2014) in the real world face challenging, continuous perception and control (Tellex et al., 2020). Consequently, research in this space effectively restricts understanding to small grammars (Paul et al., 2018; Walter et al., 2013) or controlled dialog responses (Thomason et al., 2020). These efforts to translate language instructions to actions build towards using language for end-to-end, continuous control (WS4). Collaborative games have long served as a testbed for studying language (Werner and Dyer, 1991) and emergent communication (Schlangen, 2019a; Lazaridou et al., 2018; Chaabouni et al., 202"
2020.emnlp-main.703,J08-1008,0,0.0602314,"time and a personalized set of experiences. confined to IID datasets that lack the structure in time from which humans draw correlations about long-range causal dependencies. What happens if a machine is allowed to participate consistently? This is difficult to test under current evaluation paradigms for generalization. Yet, this is the structure of generalization in human development: drawing analogies to episodic memories and gathering new data through non-independent experiments. As with many who have analyzed the history of NLP, its trends (Church, 2007), its maturation toward a science (Steedman, 2008), and its major challenges (Hirschberg and Manning, 2015; McClelland et al., 2019), we hope to provide momentum for a direction many are already heading. We call for and embrace the incremental, but purposeful, contextualization of language in human experience. With all that we have learned about what words can tell us and what they keep implicit, now is the time to ask: What tasks, representations, and inductive-biases will fill the gaps? Computer vision and speech recognition are mature enough for investigation of broader linguistic contexts (WS3). The robotics industry is rapidly developing"
2020.emnlp-main.703,D19-1218,0,0.0512018,"Missing"
2020.emnlp-main.703,P19-1644,0,0.137634,"easoning to complex puzzles of cause and effect. Sun et al. (2019b,a) models scripts and actions, and alternative unsupervised training regimes (Bachman et al., 2019) open up research towards automatic concept formation. Advances in computer vision have enabled building semantic representations rich enough to interact with natural language. In the last decade of work descendant from image captioning (Farhadi et al., 2010; Mitchell et al., 2012), a myriad of tasks on visual question answering (Antol et al., 2015; Das et al., 2018; Yagcioglu et al., 2018), natural language and visual reasoning (Suhr et al., 2019b), visual commonsense (Zellers et al., 2019a), 8721 2 3 Or the 1,600 classes of Anderson et al. (2017). Torchvision/Detectron2 include dozens of trained models. and multilingual captioning/translation via video (Wang et al., 2019b) have emerged. These combined text and vision benchmarks are rich enough to train large-scale, multimodal transformers (Li et al., 2019a; Lu et al., 2019; Zhou et al., 2019) without language pretraining (e.g. via conceptual captions (Sharma et al., 2018)) or further broadened to include audio (Tsai et al., 2019). Vision can also help ground speech signals (Srinivasa"
2020.emnlp-main.703,P06-1124,0,0.0482713,"ardware. have made progress by substantially increasing the number of model parameters to better consume these vast quantities of data. Where Peters et al. (2018) introduced ELMo with ∼108 parameters, Transformer models (Vaswani et al., 2017) have continued to scale by orders of magnitude between papers (Devlin et al., 2019; Radford et al., 2019; Zellers et al., 2019b) to ∼1011 (Brown et al., 2020). Current models are the next (impressive) step in language modeling which started with Good (1953), the weights of Kneser and Ney (1995); Chen and Goodman (1996), and the power-law distributions of Teh (2006). Modern approaches to learning dense representations allow us to better estimate these distributions from massive corpora. However, modeling lexical co-occurrence, no matter the scale, is still modeling the written world. Models constructed this way blindly search for symbolic co-occurences void of meaning. How can models yield both “impressive results” and “diminishing returns”? Language modeling— the modern workhorse of neural NLP systems—is a canonical example. Recent pretraining literature has produced results that few could have predicted, crowding leaderboards with “super-human"" accurac"
2020.emnlp-main.703,P19-1452,0,0.0131052,"e, in the limit, to everything humanity has ever written.1 We are no longer constrained to a single author or source, and the temptation for NLP is to believe everything that needs knowing can be learned from the written world. But, a large and noisy text corpus is still a text corpus. This move towards using large scale raw data has led to substantial advances in performance on existing and novel community benchmarks (Devlin et al., 2019; Brown et al., 2020). Scale in data and modeling has demonstrated that a single representation can discover both rich syntax and semantics without our help (Tenney et al., 2019). This change is perhaps best seen in transfer learning enabled by representations in deep models. Traditionally, transfer learning relied on our understanding of model classes, such as English grammar. Domain adaptation simply required sufficient data to capture lexical variation, by assuming most higherlevel structure would remain the same. Unsupervised representations today capture deep associations across multiple domains, and can be used successfully transfer knowledge into surprisingly diverse contexts (Brown et al., 2020). These representations require scale in terms of both data and pa"
2020.emnlp-main.703,N19-1197,1,0.927858,"the basis of action-oriented categories (Thelen and Smith, 1996) as children learn how to manipulate their perception by manipulating their environment. Language grounding enables an agent to connect words to these actionoriented categories for communication (Smith and Gasser, 2005), but requires action to fully discover such connections. Embodiment—situated action taking—is therefore a natural next broader context. An embodied agent, whether in a virtual world, such as a 2D Maze (MacMahon et al., 2006), a grid world (Chevalier-Boisvert et al., 2019), a simulated house (Anderson et al., 2018; Thomason et al., 2019b; Shridhar et al., 2020), or the real world (Tellex et al., 2011; Matuszek, 2018; Thomason et al., 2020; Tellex et al., 2020) must translate from language to action. Control and action taking open several new dimensions to understanding and actively learning about the world. Queries can be resolved via dialog-based exploration with a human interlocutor (Liu and Chai, 2015), even as new object properties, like texture and weight (Thomason et al., 2017), or feedback, like muscle activations (Moro and Kennington, 2018), become available. We see the need for embodied language with complex meaning"
2020.emnlp-main.703,P19-1656,0,0.0233734,"u et al., 2018), natural language and visual reasoning (Suhr et al., 2019b), visual commonsense (Zellers et al., 2019a), 8721 2 3 Or the 1,600 classes of Anderson et al. (2017). Torchvision/Detectron2 include dozens of trained models. and multilingual captioning/translation via video (Wang et al., 2019b) have emerged. These combined text and vision benchmarks are rich enough to train large-scale, multimodal transformers (Li et al., 2019a; Lu et al., 2019; Zhou et al., 2019) without language pretraining (e.g. via conceptual captions (Sharma et al., 2018)) or further broadened to include audio (Tsai et al., 2019). Vision can also help ground speech signals (Srinivasan et al., 2020; Harwath et al., 2019) to facilitate discovery of linguistic concepts (Harwath et al., 2020). At the same time, NLP resources contributed to the success of these vision backbones. Hierarchical semantic representations emerge from ImageNet classification pretraining partially due to class hypernyms owed to that dataset’s WordNet origins. For example, the person class sub-divides into many professions and hobbies, like firefighter, gymnast, and doctor. To differentiate such sibling classes, learned vectors can also encode lowe"
2020.emnlp-main.703,P10-1040,1,0.164233,"the recent success of deep learning methods. Outside of NLP, philosophy (Austin, 1975) and linguistics (Lakoff, 1973; Coleman and Kay, 1981) recognized that meaning is flexible yet structured. Early experiments on neural networks trained with sequences of words (Elman, 1990; Bengio et al., 2003) suggested that vector representations could capture both syntax and semantics. Subsequent experiments with larger models, documents, and corpora have demonstrated that representations learned from text capture a great deal of information about meaning in and out of context (Collobert and Weston, 2008; Turian et al., 2010; Mikolov et al., 2013; McCann et al., 2017). The intuition of such embedding representations, that context lends meaning, has long been acknowledged (Firth, 1957; Turney and Pantel, 2010). Earlier on, discrete, hierarchical representations, such as agglomerative clustering guided by mutual information (Brown et al., 1992), were constructed with some innate interpretability. A word’s position in such a hierarchy captures semantic and syntactic distinctions. When the Baum–Welch algorithm (Welch, 2003) is applied to unsupervised Hidden Markov Models, it assigns a class distribution to every word"
2020.emnlp-main.703,2020.cl-1.2,0,0.0416453,"Missing"
2020.emnlp-main.703,N19-1364,0,0.123027,"chniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication. Improvements in hardware and data collection have galvanized progress in NLP across many benchmark tasks. Impressive performance has been achieved in language modeling (Radford et al., 2019; Zellers et al., 2019b; Keskar et al., 2019) and span-selection question answering (Devlin et al., 2019; Yang et al., 2019b; Lan et al., 2020) through massive data and massive models. With models exceeding human performance on such tasks, now is an excellent time to reflect on a key question: Where is NLP going? In this paper, we consider how the data and world a language learner is exposed to define and constrains the scope of that learner’s semantics. Meaning does not arise from the statistical distribution of words, but from their use by people to communicate. Many of the assumptions and understandings on which communication relies lie outside of text. We must consider what is missing from models trained solel"
2020.emnlp-main.703,N10-1125,1,\N,Missing
2020.emnlp-main.703,D12-1110,0,\N,Missing
2020.emnlp-main.703,D08-1094,0,\N,Missing
2020.emnlp-main.703,P15-1135,1,\N,Missing
2020.emnlp-main.703,D16-1230,0,\N,Missing
2020.emnlp-main.703,P18-2103,0,\N,Missing
2020.emnlp-main.703,W18-5446,0,\N,Missing
2020.emnlp-main.703,P19-1388,0,\N,Missing
2020.emnlp-main.703,D17-1259,0,\N,Missing
2020.emnlp-main.703,D18-1256,0,\N,Missing
2020.emnlp-main.703,N19-1423,0,\N,Missing
2020.emnlp-main.703,D19-1598,0,\N,Missing
2020.tacl-1.36,P96-1009,0,0.132698,"uces the same result, or an alternative interpretation that is also contextually appropriate. Count 8 Related work 3 The view of dialogue as an interactive process of shared plan synthesis dates back to Grosz and Sidner’s earliest work on discourse structure (1986; 1988). That work represents the state of a dialogue as a predicate recognizing whether a desired piece of information has been communicated or change in world state effected. Goals can be refined via questions and corrections from both users and agents. The only systems to attempt full versions of this shared-plans framework (e.g., Allen et al., 1996; Rich et al., 2001) required inputs that could be parsed under a predefined grammar. Subsequent research on dialogue understanding has largely focused on two simpler subtasks: Contextual semantic parsing approaches focus on complex language understanding without reasoning about underspecified goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2"
2020.tacl-1.36,D18-1547,0,0.165132,"65 1,052 3,315 Dataflow inline .729 .696 .665 .606 .642 .533 .574 .465 .697 .631 .565 .474 Dataflow inline refer inline both TRADE Table 2: SMCalFlow results. Agent action accuracy is significantly higher than a baseline without metacomputation, especially on turns that involve a reference (Ref. Turns) or revision (Rev. Turns) to earlier turns in the dialogue (p &lt; 10−6 , McNemar’s test). Joint Goal Dialogue Prefix .467 .447 .467 .454 .220 .202 .205 .168 3.07 2.97 2.90 2.73 Table 3: MultiWOZ 2.1 test set results. TRADE (Wu et al., 2019) results are from the public implementation. “Joint Goal” (Budzianowski et al., 2018) is average dialogue state exact-match, “Dialogue” is average dialogue-level exact-match, and “Prefix” is the average number of turns before an incorrect prediction. Within each column, the best result is boldfaced, along with all results that are not significantly worse (p &lt; 0.05, paired permutation test). Moreover, all of “Dataflow,” “inline refer,” and “inline both” have higher dialogue accuracy than TRADE (p &lt; 0.005). els that train on inlined metacomputation. These experiments make it possible to evaluate the importance of explicit dataflow manipulation compared to a standard contextual s"
2020.tacl-1.36,D19-1459,0,0.0502204,"bling side-byside comparisons and experiments with alternative representations. We provide full conversion scripts for MultiWOZ. 567 9 teractive dialogues. It is assumed that any user intent can be represented with a flat structure consisting of a categorical dialogue act and a mapping between a fixed set of slots and string-valued fillers. Existing fine-grained dialogue act schemes (Stolcke et al., 2000) can distinguish among a range of communicative intents not modeled by our approach, and slot-filling representations have historically been easier to predict (Zue et al., 1994) and annotate (Byrne et al., 2019). But while recent variants support interaction between related slots (Budzianowski et al., 2018) and fixed-depth hierarchies of slots (Gupta et al., 2018), modern slot-filling approaches remain limited in their support for semantic compositionality. By contrast, our approach supports user requests corresponding to general compositional programs. Conclusions We have presented a representational framework for task-oriented dialogue modeling based on dataflow graphs, in which dialogue agents predict a sequence of compositional updates to a graphical state representation. This approach makes it p"
2020.tacl-1.36,P17-1167,0,0.0181575,"bout underspecified goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2014) describe a semantic parsing representation targeted at more general dialogue problems. Most existing methods interpret context-dependent user questions (What is the next flight to Atlanta? When does it land?) by learning to copy subtrees (Zettlemoyer and Collins, 2009; Iyyer et al., 2017; Suhr et al., 2018) or tokens (Zhang et al., 2019) from previously-generated queries. In contrast, our approach reifies reuse with explicit graph operators. Slot-filling approaches (Pieraccini et al., 1992) model simpler utterances in the context of full, inTable 4: Manual classification of 100 model errors on the SMCalFlow dataset. The largest categories are underprediction (omitting steps from agent programs), entity linking (errors in extraction of entities from user utterances, fencing (classifying a user request as outof-scope), and ambiguity (user utterances with multiple possible inter"
2020.tacl-1.36,P17-4012,0,0.0122901,"propriate type constraint, provided that the reference resolution heuristic would retrieve the correct string from earlier in the dataflow. This covers references like the same day. Otherwise, our re-annotation retains the literal string value. Data statistics are shown in Table 1. To the best of our knowledge, SMCalFlow is the largest annotated task-oriented dialogue dataset to date. Compared to MultiWOZ, it features a larger user vocabulary, a more complex space of statemanipulation primitives, and a long tail of agent programs built from numerous function calls and deep composition. 7 NMT (Klein et al., 2017) pointer-generator network (See et al., 2017), a sequence-to-sequence model that can copy tokens from the source sequence while decoding. Our goal is to demonstrate that dataflow-based representations benefit standard neural model architectures. Dataflowspecific modeling might improve on this baseline, and we leave this as a challenge for future work. For each user turn i, we linearize the target program into a sequence of tokens zi . This must be predicted from the dialogue context— namely the concatenated source sequence xi−c zi−c · · · xi−1 zi−1 xi (for SMCalFlow) or xi−c yi−c · · · xi−1 yi"
2020.tacl-1.36,J94-4002,0,0.175555,"tate representations. While a complete description of dataflow-based language generation is beyond the scope of this paper, we briefly describe the components of the generation system relevant to the understanding system presented here. 3 Reference resolution In a dialogue, entities that have been introduced once may be referred to again. In dataflow dialogues, the entities available for reference are given by the nodes in the dataflow graph. Entities are salient to conversation participants to different degrees, and their relative salience determines the ways in which they may be referenced (Lappin and Leass, 1994). For example, it generally refers to the most salient non-human entity, while more specific expressions like the Friday meeting are needed to refer to accessible but less salient entities. Not all references to entities are overt: if the agent says “You have a meeting tomorrow” and the user responds “What time?”, the agent must predict the implicit reference to a salient event. 559 Dataflow pointers We have seen that refer is used to find referents for referring expressions. In general, these referents may be existing dataflow nodes or new subgraphs for newly mentioned entities. We now give m"
2020.tacl-1.36,J86-3001,0,0.780827,"Missing"
2020.tacl-1.36,W18-6322,0,0.0167485,"ser utterances with multiple possible interpretations). See §7 for discussion. Error analysis Beyond the quantitative results shown in Tables 2–3, we manually analyzed 100 SMCalFlow turns where our model mispredicted. Table 4 breaks down the errors by type. Three categories involve straightforward parsing errors. In underprediction errors, the model fails to predict some computation (e.g., a search constraint or property extractor) specified in the user request. This behavior is not specific to our system: under-length predictions are also welldocumented in neural machine translation systems (Murray and Chiang, 2018). In entity linking errors, the model correctly identifies the presence of an entity mention in the input utterance, but uses it incorrectly in the input plan. Sometimes the entity that appears in the plan is hallucinated, appearing nowhere in the utterance; sometimes the entity is cast to a wrong type (e.g., locations interpreted as event names) used in the wrong field or extracted with wrong boundaries. In fencing errors, the model interprets an out-of-scope user utterance as an interpretable command, or vice-versa versions of the full dataset, and inlined and non-inlined versions of our mod"
2020.tacl-1.36,D18-1300,0,0.0282209,"It is assumed that any user intent can be represented with a flat structure consisting of a categorical dialogue act and a mapping between a fixed set of slots and string-valued fillers. Existing fine-grained dialogue act schemes (Stolcke et al., 2000) can distinguish among a range of communicative intents not modeled by our approach, and slot-filling representations have historically been easier to predict (Zue et al., 1994) and annotate (Byrne et al., 2019). But while recent variants support interaction between related slots (Budzianowski et al., 2018) and fixed-depth hierarchies of slots (Gupta et al., 2018), modern slot-filling approaches remain limited in their support for semantic compositionality. By contrast, our approach supports user requests corresponding to general compositional programs. Conclusions We have presented a representational framework for task-oriented dialogue modeling based on dataflow graphs, in which dialogue agents predict a sequence of compositional updates to a graphical state representation. This approach makes it possible to represent and learn from complex, natural dialogues. Future work might focus on improving prediction by introducing learned implementations of r"
2020.tacl-1.36,H90-1021,0,0.582952,"ted or change in world state effected. Goals can be refined via questions and corrections from both users and agents. The only systems to attempt full versions of this shared-plans framework (e.g., Allen et al., 1996; Rich et al., 2001) required inputs that could be parsed under a predefined grammar. Subsequent research on dialogue understanding has largely focused on two simpler subtasks: Contextual semantic parsing approaches focus on complex language understanding without reasoning about underspecified goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2014) describe a semantic parsing representation targeted at more general dialogue problems. Most existing methods interpret context-dependent user questions (What is the next flight to Atlanta? When does it land?) by learning to copy subtrees (Zettlemoyer and Collins, 2009; Iyyer et al., 2017; Suhr et al., 2018) or tokens (Zhang et al., 2019) from previously-generated queries. In contrast, our approach"
2020.tacl-1.36,D14-1162,0,0.0839852,"with a separator token that indicates the speaker (user or agent). Our formulation of context for MultiWOZ is standard (e.g., Wu et al., 2019). We take the source and target vocabularies to consist of all words that occur in (respectively) the source and target sequences in training data, as just defined. The model is trained using the Adam optimizer (Kingma and Ba, 2015) with the maximum likelihood objective. We use 0.001 as the learning rate. Training ends when there have been two different epochs that increased the development loss. We use Glove800B-300d (cased) and Glove6B300d (uncased) (Pennington et al., 2014) to initialize the vocabulary embeddings for the SMCalFlow and MultiWoZ experiments, respectively. The context window size c, hidden layer size d, number of hidden layers l, and dropout rates r are selected based on the agent action accuracy (for SMCalFlow) or dialogue-level exact match (for MultiWoZ) on the development set from {2, 4, 10}, {256, 300, 320, 384}, {1, 2, 3}, {0.3, 0.5, 0.7} respectively. Approximate 1-best decoding uses a beam of size 5. Quantitative evaluation Table 2 shows results for the SMCalFlow dataset. We report program accuracy: specifically, exact-match accuracy of the"
2020.tacl-1.36,P17-1062,0,0.0717515,"Missing"
2020.tacl-1.36,P19-1078,0,0.0158945,"work. For each user turn i, we linearize the target program into a sequence of tokens zi . This must be predicted from the dialogue context— namely the concatenated source sequence xi−c zi−c · · · xi−1 zi−1 xi (for SMCalFlow) or xi−c yi−c · · · xi−1 yi−1 xi (for MultiWOZ 2.1). Here c is a context window size, xj is the user utterance at user turn j, yj is the agent’s naturallanguage response, and zj is the linearized agent program. Each sequence xj , yj , or zj begins with a separator token that indicates the speaker (user or agent). Our formulation of context for MultiWOZ is standard (e.g., Wu et al., 2019). We take the source and target vocabularies to consist of all words that occur in (respectively) the source and target sequences in training data, as just defined. The model is trained using the Adam optimizer (Kingma and Ba, 2015) with the maximum likelihood objective. We use 0.001 as the learning rate. Training ends when there have been two different epochs that increased the development loss. We use Glove800B-300d (cased) and Glove6B300d (uncased) (Pennington et al., 2014) to initialize the vocabulary embeddings for the SMCalFlow and MultiWoZ experiments, respectively. The context window s"
2020.tacl-1.36,P17-1099,0,0.0599554,"Missing"
2020.tacl-1.36,J00-3003,0,0.766051,"Missing"
2020.tacl-1.36,N18-1203,0,0.0172756,"goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2014) describe a semantic parsing representation targeted at more general dialogue problems. Most existing methods interpret context-dependent user questions (What is the next flight to Atlanta? When does it land?) by learning to copy subtrees (Zettlemoyer and Collins, 2009; Iyyer et al., 2017; Suhr et al., 2018) or tokens (Zhang et al., 2019) from previously-generated queries. In contrast, our approach reifies reuse with explicit graph operators. Slot-filling approaches (Pieraccini et al., 1992) model simpler utterances in the context of full, inTable 4: Manual classification of 100 model errors on the SMCalFlow dataset. The largest categories are underprediction (omitting steps from agent programs), entity linking (errors in extraction of entities from user utterances, fencing (classifying a user request as outof-scope), and ambiguity (user utterances with multiple possible interpretations). See §7"
2020.tacl-1.36,P19-1443,0,0.056047,"state effected. Goals can be refined via questions and corrections from both users and agents. The only systems to attempt full versions of this shared-plans framework (e.g., Allen et al., 1996; Rich et al., 2001) required inputs that could be parsed under a predefined grammar. Subsequent research on dialogue understanding has largely focused on two simpler subtasks: Contextual semantic parsing approaches focus on complex language understanding without reasoning about underspecified goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2014) describe a semantic parsing representation targeted at more general dialogue problems. Most existing methods interpret context-dependent user questions (What is the next flight to Atlanta? When does it land?) by learning to copy subtrees (Zettlemoyer and Collins, 2009; Iyyer et al., 2017; Suhr et al., 2018) or tokens (Zhang et al., 2019) from previously-generated queries. In contrast, our approach reifies reuse wi"
2020.tacl-1.36,Q14-1042,0,0.0241672,", Allen et al., 1996; Rich et al., 2001) required inputs that could be parsed under a predefined grammar. Subsequent research on dialogue understanding has largely focused on two simpler subtasks: Contextual semantic parsing approaches focus on complex language understanding without reasoning about underspecified goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2014) describe a semantic parsing representation targeted at more general dialogue problems. Most existing methods interpret context-dependent user questions (What is the next flight to Atlanta? When does it land?) by learning to copy subtrees (Zettlemoyer and Collins, 2009; Iyyer et al., 2017; Suhr et al., 2018) or tokens (Zhang et al., 2019) from previously-generated queries. In contrast, our approach reifies reuse with explicit graph operators. Slot-filling approaches (Pieraccini et al., 1992) model simpler utterances in the context of full, inTable 4: Manual classification of 100 model errors o"
2020.tacl-1.36,E17-1042,0,0.105146,"Missing"
2020.tacl-1.36,P09-1110,0,0.038465,"derstanding without reasoning about underspecified goals or agent initiative. Here the prototypical problem is iterated question answering (Hemphill et al., 1990; Yu et al., 2019b), in which the user asks a sequence of questions corresponding to database queries, and results of query execution are presented as structured result sets. Vlachos and Clark (2014) describe a semantic parsing representation targeted at more general dialogue problems. Most existing methods interpret context-dependent user questions (What is the next flight to Atlanta? When does it land?) by learning to copy subtrees (Zettlemoyer and Collins, 2009; Iyyer et al., 2017; Suhr et al., 2018) or tokens (Zhang et al., 2019) from previously-generated queries. In contrast, our approach reifies reuse with explicit graph operators. Slot-filling approaches (Pieraccini et al., 1992) model simpler utterances in the context of full, inTable 4: Manual classification of 100 model errors on the SMCalFlow dataset. The largest categories are underprediction (omitting steps from agent programs), entity linking (errors in extraction of entities from user utterances, fencing (classifying a user request as outof-scope), and ambiguity (user utterances with mul"
2020.tacl-1.36,W16-3601,0,0.0677409,"Missing"
2020.tacl-1.36,H94-1037,0,0.573739,"odel’s test set predictions, enabling side-byside comparisons and experiments with alternative representations. We provide full conversion scripts for MultiWOZ. 567 9 teractive dialogues. It is assumed that any user intent can be represented with a flat structure consisting of a categorical dialogue act and a mapping between a fixed set of slots and string-valued fillers. Existing fine-grained dialogue act schemes (Stolcke et al., 2000) can distinguish among a range of communicative intents not modeled by our approach, and slot-filling representations have historically been easier to predict (Zue et al., 1994) and annotate (Byrne et al., 2019). But while recent variants support interaction between related slots (Budzianowski et al., 2018) and fixed-depth hierarchies of slots (Gupta et al., 2018), modern slot-filling approaches remain limited in their support for semantic compositionality. By contrast, our approach supports user requests corresponding to general compositional programs. Conclusions We have presented a representational framework for task-oriented dialogue modeling based on dataflow graphs, in which dialogue agents predict a sequence of compositional updates to a graphical state repres"
2021.acl-long.143,2021.naacl-main.422,0,0.0175504,"ion states logically, and decode information states via the truth values that they assign to logical propositions (φi,j in Fig. 2).3 2 3 See also Yalcin (2014) for an introductory survey. In existing work, one of the main applications of dynamic LMs and other semantic phenomena In addition to work on interpretability, a great deal of past research uses language modeling as a pretraining scheme for more conventional (supervised) semantics tasks in NLP. LM pretraining is useful for semantic parsing (Einolghozati et al., 2019), instruction following (Hill et al., 2020), and even image retrieval (Ilharco et al., 2021). Here, our primary objective is not good performance on downstream tasks, but rather understanding of representations themselves. LM pretraining has also been found to be useful for tasks like factoid question answering (Petroni et al., 2019; Roberts et al., 2020). Our experiments do not explore the extent to which LMs encode static background knowledge, but instead the extent to which they can build representations of novel situations described by novel text. 3 Approach Overview We train probing models to test whether NLMs represent the information states specified by the input text. We spec"
2021.acl-long.143,D19-1445,0,0.0194606,"s encode? This paper’s investigation of state representations builds on a large body of past work aimed at understanding how other linguistic phenomena are represented in large-scale language models. NLM representations have been found to encode syntactic categories, dependency relations, and coreference information (Tenney et al., 2019; Hewitt and Manning, 2019; Clark et al., 2019). Within the realm of semantics, existing work has identified representations of word meaning (e.g., finegrained word senses; Wiedemann et al. 2019) and predicate–argument structures like frames and semantic roles (Kovaleva et al., 2019). In all these studies, the main experimental paradigm is probing (Shi et al., 2016; Belinkov and Glass, 2019): given a fixed source of representations (e.g. the BERT language model; Devlin et al. 2019) and a linguistic label of interest (e.g. semantic role), a low-capacity “probe” (e.g a linear classifier) is trained to predict the label from the representations (e.g. to predict semantic roles from BERT embeddings). A phenomenon is judged to be encoded by a model if the probe’s accuracy cannot be explained by its accuracy when trained on control tasks (Hewitt and Liang, 2019) or baseline mode"
2021.acl-long.143,2020.acl-main.703,0,0.12449,"or. (c2) …drop an apple on the ground. (c3) …remove an apple from the chest. you (b′) door locked Figure 1: Neural language models trained on text alone (a–c) produce semantic representations that encode properties and relations of entities mentioned in a discourse (a0 ). Representations are updated when the discourse describes changes to entities’ state (b0 ). Introduction Neural language models (NLMs), which place probability distributions over sequences of words, produce contextual word and sentence embeddings that are useful for a variety of language processing tasks (Peters et al., 2018; Lewis et al., 2020). This usefulness is partially explained by the fact that NLM representations encode lexical relations (Mikolov et al., 2013) and syntactic structure (Tenney et al., 2019). But the extent to which NLM training also induces representations of meaning remains a topic of ongoing debate (Bender and Koller, 2020; Wu et al., 2021). In this paper, we show that NLMs represent meaning in a specific sense: in simple semantic domains, they build representations of situations and entities that encode logical descriptions of each entity’s dynamic state. 1 You see an open chest. The only thing in the chest"
2021.acl-long.143,P16-1138,0,0.024176,"representation of each proposition. We denote this: NL(has-v-c(b)) = “the b beaker has v c” . (3) Preliminaries Model In all experiments, the encoder E comes from a BART (Lewis et al., 2020) or T5 (Raffel et al., 2020) model. Except where noted, BART is pretrained on OpenWebText, BookCorpus, CCNews, and Stories (Lewis et al., 2020), T5 is pretrained on C4 (Raffel et al., 2020), and both are fine-tuned on the TextWorld or Alchemy datasets described below. Weights of E are frozen during probe training. Data: Alchemy Alchemy, the first dataset used in our experiments, is derived from the SCONE (Long et al., 2016) semantic parsing tasks. We preserve the train / development split from the original dataset (3657 train / 245 development). Every example in the dataset consists of a humangenerated sequence of instructions to drain, pour, or mix a beaker full of colored liquid. Each instruction is annotated with the ground-truth state that results from following that instruction (Figure 3). We turn Alchemy into a language modeling dataset by prepending a declaration of the initial state (the initial contents of each beaker) to the actions. The initial state declaration always follows a fixed form (“the first"
2021.acl-long.143,N13-1090,0,0.0144234,"models trained on text alone (a–c) produce semantic representations that encode properties and relations of entities mentioned in a discourse (a0 ). Representations are updated when the discourse describes changes to entities’ state (b0 ). Introduction Neural language models (NLMs), which place probability distributions over sequences of words, produce contextual word and sentence embeddings that are useful for a variety of language processing tasks (Peters et al., 2018; Lewis et al., 2020). This usefulness is partially explained by the fact that NLM representations encode lexical relations (Mikolov et al., 2013) and syntactic structure (Tenney et al., 2019). But the extent to which NLM training also induces representations of meaning remains a topic of ongoing debate (Bender and Koller, 2020; Wu et al., 2021). In this paper, we show that NLMs represent meaning in a specific sense: in simple semantic domains, they build representations of situations and entities that encode logical descriptions of each entity’s dynamic state. 1 You see an open chest. The only thing in the chest is an old key. There is a locked wooden door leading east. Code and data are available at https://github.com/ belindal/state-"
2021.acl-long.143,N18-1202,0,0.0259715,"key to unlock the door. (c2) …drop an apple on the ground. (c3) …remove an apple from the chest. you (b′) door locked Figure 1: Neural language models trained on text alone (a–c) produce semantic representations that encode properties and relations of entities mentioned in a discourse (a0 ). Representations are updated when the discourse describes changes to entities’ state (b0 ). Introduction Neural language models (NLMs), which place probability distributions over sequences of words, produce contextual word and sentence embeddings that are useful for a variety of language processing tasks (Peters et al., 2018; Lewis et al., 2020). This usefulness is partially explained by the fact that NLM representations encode lexical relations (Mikolov et al., 2013) and syntactic structure (Tenney et al., 2019). But the extent to which NLM training also induces representations of meaning remains a topic of ongoing debate (Bender and Koller, 2020; Wu et al., 2021). In this paper, we show that NLMs represent meaning in a specific sense: in simple semantic domains, they build representations of situations and entities that encode logical descriptions of each entity’s dynamic state. 1 You see an open chest. The onl"
2021.acl-long.143,2020.emnlp-main.437,0,0.0388146,"Missing"
2021.acl-long.284,P16-1154,0,0.0345369,"proposed value v is a constant, we embed it by applying the utterance encoder on a string rendering of the value. The set of constants is automatically extracted from the training data (see Appendix B). Copies. Copies are string values that correspond to substrings of the user utterance (e.g., person names). String values can only enter the program through copying, as they are not in the set of constants (i.e., they cannot be “hallucinated” by the model; see Pasupat and Liang, 2015; Nie et al., 2019). One might try to construct an approach based on a standard token-based copy mechanism (e.g., Gu et al., 2016). However, this would allow copying non-contiguous spans and would also require marginalizing over identical tokens as opposed to spans, resulting in more ambiguity. Instead, we propose a mechanism that enables the decoder to copy contiguous spans directly from the utterance. Its goal is to produce a score for each of the U (U + 1)/2 possible utterance spans. Na¨ıvely, this would result in a computational cost that is quadratic in the utterance length U , and so we instead chose a simple scoring model that avoids it. Similar to Stern et al. (2017) and Kuribayashi et al. (2019), we assume that"
2021.acl-long.284,P17-1097,0,0.0537063,"Missing"
2021.acl-long.284,P16-1002,0,0.0525653,"Missing"
2021.acl-long.284,C12-1083,1,0.706699,"Missing"
2021.acl-long.284,P17-4012,0,0.015823,"2 87.1 86.2 87.0 87.1 86.7 86.9 80.2 75.0 86.9 87.1 88.3 86.5 88.1 88.3 87.4 88.2 80.6 76.5 87.4 88.3 (b) Ablation study. Table 2: Validation set exact match accuracy across varying amounts of training data (each subset is sampled uniformly at random). The best results in each case are shown in bold red and are underlined. In order to further understand the performance characteristics of our model and quantify the impact of each modeling contribution, we also compare to a variety of other models and ablated versions of our model. We implemented the following baselines: – Seq2Seq: The OpenNMT (Klein et al., 2017) implementation of a pointer-generator network (See et al., 2017) that predicts linearized plans represented as S-expressions and is able to copy tokens from the utterance while decoding. This model is very similar to the model used by Semantic Machines et al. (2020) and represents the current state-of-the-art for SMC AL F LOW.8 – Seq2Tree: The same as Seq2Seq, except that it generates invocations in a top-down, pre-order program traversal. Each invocation is embedded as a unique item in the output vocabulary. Note that SMC ALFLOW contains re-entrant programs represented with LISP-style let bi"
2021.acl-long.284,D17-1160,1,0.835119,"s sminfo@microsoft.com Abstract the output (Suhr et al., 2018). While this approach can capture arbitrary dependencies between inputs and outputs, it comes at the cost of sample- and computational inefficiency. We propose a new “value-agnostic” approach to contextual semantic parsing driven by type-based representations of the dialogue history and functionbased representations of the generated programs. Types and functions have long served as a foundation for formal reasoning about programs, but their use in neural semantic parsing has been limited, e.g., to constraining the hypothesis space (Krishnamurthy et al., 2017), guiding data augmentation (Jia and Liang, 2016), and coarsening in coarse-to-fine models (Dong and Lapata, 2018). We show that representing conversation histories and partial programs via the types and functions they contain enables fast, accurate, and sample-efficient contextual semantic parsing. We propose a neural encoder– decoder contextual semantic parsing model which, in contrast to prior work: Conversational semantic parsers map user utterances to executable programs given dialogue histories composed of previous utterances, programs, and system responses. Existing parsers typically co"
2021.acl-long.284,P19-1464,0,0.0282221,"sed copy mechanism (e.g., Gu et al., 2016). However, this would allow copying non-contiguous spans and would also require marginalizing over identical tokens as opposed to spans, resulting in more ambiguity. Instead, we propose a mechanism that enables the decoder to copy contiguous spans directly from the utterance. Its goal is to produce a score for each of the U (U + 1)/2 possible utterance spans. Na¨ıvely, this would result in a computational cost that is quadratic in the utterance length U , and so we instead chose a simple scoring model that avoids it. Similar to Stern et al. (2017) and Kuribayashi et al. (2019), we assume that the score for a span factorizes, and define the embedding of each span value as the concatenation of the contextual embeddings of the first and last tokens of the span, v˜ = [hkuttstart ; hkuttend ]. To compute the copy scores we also concatenate hi,a dec with itself in Equation 8. Entities. Entities are treated the same way as copies, except that instead of scoring all spans of the input, we only score spans proposed by the external entity proposers discussed in §2.1. Specifically, the proposers provide the model with a list of candidate entities that are each described by an"
2021.acl-long.284,P14-1135,0,0.0237253,"urs include SMBOP (Rubin and Berant, 2020) and BUSTLE (Odena et al., 2020). Context-Dependent Semantic Parsing. Prior work on conversational semantic parsing mainly focuses on the decoder, with few efforts on incorporating the dialogue history information in the encoder. Recent work on context-dependent semantic parsing (e.g., Suhr et al., 2018; Yu et al., 2019) conditions on explicit representations of user utterances and programs with a neural encoder. While this results in highly expressive models, it also increases the risk of overfitting. Contrary to this, Zettlemoyer and Collins (2009), Lee et al. (2014) and Semantic Machines et al. (2020) do not use context to resolve references at all. They instead predict context-independent logical forms that are resolved in a separate step. Our approach occupies a middle ground: when combined with local program representations, types, even without any value information, provide enough information to resolve context-dependent meanings that cannot be derived from isolated sentences. The specific mechanism we use to do this “infuses” contextual type information into input sentence representations, in a manner reminiscent of attention flow models from the QA"
2021.acl-long.284,D16-1262,0,0.0663869,"Missing"
2021.acl-long.284,P17-1099,0,0.0104458,"88.3 87.4 88.2 80.6 76.5 87.4 88.3 (b) Ablation study. Table 2: Validation set exact match accuracy across varying amounts of training data (each subset is sampled uniformly at random). The best results in each case are shown in bold red and are underlined. In order to further understand the performance characteristics of our model and quantify the impact of each modeling contribution, we also compare to a variety of other models and ablated versions of our model. We implemented the following baselines: – Seq2Seq: The OpenNMT (Klein et al., 2017) implementation of a pointer-generator network (See et al., 2017) that predicts linearized plans represented as S-expressions and is able to copy tokens from the utterance while decoding. This model is very similar to the model used by Semantic Machines et al. (2020) and represents the current state-of-the-art for SMC AL F LOW.8 – Seq2Tree: The same as Seq2Seq, except that it generates invocations in a top-down, pre-order program traversal. Each invocation is embedded as a unique item in the output vocabulary. Note that SMC ALFLOW contains re-entrant programs represented with LISP-style let bindings. Both the Seq2Tree and Seq2Seq are unaware of the special"
2021.acl-long.284,2020.acl-main.703,0,0.0165634,"Unlike Seq2Seq and Seq2Tree, this model can only produce well-formed and well-typed programs. It also makes use of the same entity proposers (§2.1) similar to our model, and it can atomically copy spans of up to 15 tokens by treating them as additional proposed entities. Furthermore, it uses the linear history encoder that is described in the next paragraph. Like our model, re-entrancies are represented as references to previous outputs in the predicted sequence. Table 3: Validation set exact match accuracy for singleturn semantic parsing datasets. Note that Aghajanyan et al. (2020) use BART (Lewis et al., 2020), a large pretrained encoder. The best results for each dataset are shown in bold red and are underlined. mechanism with a linear function over a multihot embedding of the history types. The results, shown in Table 2b, indicate that all of our features play a role in improving accuracy. Perhaps most importantly though, the “value dependence” ablation shows that our function-based program representations are indeed important, and the “previous turn” ablation shows that our typebased program representations are also important. Furthermore, the impact of both these modeling decisions grows larger"
2021.acl-long.284,D16-1183,0,0.0136943,"ork in neural semantic parsing and also context-dependent semantic parsing. Neural Semantic Parsing. While there was a brief period of interest in using unstructured sequence models for semantic parsing (e.g., Andreas 3673 et al., 2013; Dong and Lapata, 2016), most research on semantic parsing has used tree- or graph-shaped decoders that exploit program structure. Most such approaches use this structure as a constraint while decoding, filling in function arguments one-at-atime, in either a top-down fashion (e.g., Dong and Lapata, 2016; Krishnamurthy et al., 2017) or a bottom-up fashion (e.g., Misra and Artzi, 2016; Cheng et al., 2018). Both directions can suffer from exposure bias and search errors during decoding: in top-down when there’s no way to realize an argument of a given type in the current context, and in bottom-up when there are no functions in the programming language that combine the predicted arguments. To this end, there has been some work on global search with guarantees for neural semantic parsers (e.g., Lee et al., 2016) but it is expensive and makes certain strong assumptions. In contrast to this prior work, we use program structure not just as a decoder constraint but as a source of"
2021.acl-long.284,P19-1256,0,0.0121943,"lues that are always proposed, so the decoder always has the option of generating them. If the source s for the proposed value v is a constant, we embed it by applying the utterance encoder on a string rendering of the value. The set of constants is automatically extracted from the training data (see Appendix B). Copies. Copies are string values that correspond to substrings of the user utterance (e.g., person names). String values can only enter the program through copying, as they are not in the set of constants (i.e., they cannot be “hallucinated” by the model; see Pasupat and Liang, 2015; Nie et al., 2019). One might try to construct an approach based on a standard token-based copy mechanism (e.g., Gu et al., 2016). However, this would allow copying non-contiguous spans and would also require marginalizing over identical tokens as opposed to spans, resulting in more ambiguity. Instead, we propose a mechanism that enables the decoder to copy contiguous spans directly from the utterance. Its goal is to produce a score for each of the U (U + 1)/2 possible utterance spans. Na¨ıvely, this would result in a computational cost that is quadratic in the utterance length U , and so we instead chose a sim"
2021.acl-long.284,K17-1026,0,0.0600814,"Missing"
2021.acl-long.284,N18-1203,0,0.034024,"Missing"
2021.acl-long.284,D14-1135,0,0.0604812,"Missing"
2021.acl-long.284,D18-2002,0,0.0252359,"Missing"
2021.acl-long.284,P19-1443,0,0.104352,"ate that simple representations are key to effective generalization in conversational semantic parsing. 1 1. uses a compact yet informative representation of discourse context in the encoder that considers only the types of salient entities that were predicted by the model in previous turns or that appeared in the execution results of the predicted programs, and Introduction Conversational semantic parsers, which translate natural language utterances into executable programs while incorporating conversational context, play an increasingly central role in systems for interactive data analysis (Yu et al., 2019), instruction following (Guu et al., 2017), and task-oriented dialogue (Zettlemoyer and Collins, 2009). An example of this task is shown in Figure 1. Typical models are based on an autoregressive sequence prediction approach, in which a detailed representation of the dialogue history is concatenated to the input sequence, and predictors condition on this sequence and all previously generated components of 2. conditions the decoder state on the sequence of function invocations so far, without conditioning on any concrete values passed as arguments to the functions. Our model substantially impro"
2021.acl-long.284,D07-1071,0,0.257344,"Missing"
2021.acl-long.284,P09-1110,0,0.310471,"ure 2: Illustration of the revise meta-computation operator (§2.1) used in our program representations. This operator can remove the need to copy program fragments from the dialogue history. 2.1 Preliminaries Our approach assumes that programs have type annotations on all values and function calls, similar to the setting of Krishnamurthy et al. (2017).1 Furthermore, we assume that program prediction is local in that it does not require program fragments to be copied from the dialogue history (but may still depend on history in other ways). Several formalisms, including the typed references of Zettlemoyer and Collins (2009) and the meta-computation operators of Semantic Machines et al. (2020), make it possible to produce local program annotations even for dialogues like the one depicted in Figure 2, which reuse past computations. We transformed the datasets in our experiments to use such metacomputation operators (see Appendix C). We also optionally make use of entity proposers, similar to Krishnamurthy et al. (2017), which annotate spans from the current utterance with typed values. For example, the span “one” in “Change it to one” might be annotated with the value 1 of type Number. These values are scored by t"
2021.acl-long.284,P19-1009,0,0.0467415,"Missing"
2021.acl-long.284,N15-1162,0,0.054247,"Missing"
2021.acl-long.382,2020.acl-main.676,1,0.85231,"l., 2020; Kim and Linzen, 2020). What they share is a common expectation that learners should associate specific production or transformation rules with specific input tokens (or phrases), and generalize to use of these tokens in new contexts. Recent years have seen tremendous amount of modeling work aimed at encouraging these generalizations in neural models, primarily by equipping them with symbolic scaffolding in the form of program synthesis engines (Nye et al., 2020), stack machines (Grefenstette et al., 2015; Liu et al., 2020), or symbolic data transformation rules (Gordon et al., 2019; Andreas, 2020). A parallel line of work has investigated the role of continuous representations in systematic generalization, proposing improved methods for pretraining (Furrer et al., 2020) and procedures for removing irrelevant contextual information from word representations (Arthur et al., 2016; Russin et al., 2019; Thrush, 2020). The latter two approaches proceed from similar intuition to ours, aiming to disentangle word meanings from syntax in encoder representations via alternative attention mechanisms and adversarial training. Our approach instead focuses on providing an explicit lexicon to the deco"
2021.acl-long.382,D16-1162,0,0.0196375,"ount of modeling work aimed at encouraging these generalizations in neural models, primarily by equipping them with symbolic scaffolding in the form of program synthesis engines (Nye et al., 2020), stack machines (Grefenstette et al., 2015; Liu et al., 2020), or symbolic data transformation rules (Gordon et al., 2019; Andreas, 2020). A parallel line of work has investigated the role of continuous representations in systematic generalization, proposing improved methods for pretraining (Furrer et al., 2020) and procedures for removing irrelevant contextual information from word representations (Arthur et al., 2016; Russin et al., 2019; Thrush, 2020). The latter two approaches proceed from similar intuition to ours, aiming to disentangle word meanings from syntax in encoder representations via alternative attention mechanisms and adversarial training. Our approach instead focuses on providing an explicit lexicon to the decoder; as discussed below, this appears to be considerably more effective. Copying and lexicon learning In neural encoder–decoder models, the clearest example of benefits from special treatment of word-level production rules is the copy mechanism. A great deal of past work has found tha"
2021.acl-long.382,J93-2003,0,0.182678,"the decoder. These mechanisms are described in detail in Section 3, and are widely used in models for language generation, summarization and semantic parsing. Our work generalizes these models to structural operations on the input that replace copying with general context-independent token-level translation. As will be discussed, the core of our approach is a (non-contextual) lexicon that maps individual input tokens to individual output tokens. Learning lexicons like this is of interest in a number of communities in NLP and language science more broadly. A pair of representative approaches (Brown et al., 1993; Frank et al., 2007) will be discussed in detail below; other work on lexicon learning for semantics and translation includes Liang et al. (2009); Goldwater (2007); Haghighi et al. (2008) among numerous others. Finally, and closest to the modeling contribution in this work, several previous papers have proposed alternative generalized copy mechanisms for tasks other than semantic lexicon learning. Concurrent work by Prabhu and Kann (2020) introduces a similar approach for grapheme-to-phoneme translation (with a fixed functional lexicon rather than a trainable parameter matrix), and Nguyen and"
2021.acl-long.382,N13-1073,0,0.101298,"Missing"
2021.acl-long.382,2020.emnlp-main.731,0,0.335878,"cifically, we augment decoder output layers with a lexical translation mechanism which generalizes neural copy mechanisms (e.g. See et al., 2017) and enables models to generate token-level translations purely attentionally. While the lexical translation mechanism is quite general, we focus here on its ability to improve few-shot learning in sequence-to-sequence models. On a suite of challenging tests of few-shot semantic parsing and instruction following, our model exhibits strong generalization, achieving the highest reported results for neural sequence models on datasets as diverse as COGS (Kim and Linzen 2020, with 24155 training examples) and Colors (Lake et al. 2019, with 14). Our approach also generalizes to real-world tests of few-shot learning, improving BLEU scores (Papineni et al., 2002) by 1.2 on a low-resource English–Chinese machine translation task (2.2 on test sentences requiring one-shot word learning). In an additional set of experiments, we explore effective procedures for initializing the lexical translation mechanism using lexicon learning algorithms derived from information theory, statistical machine translation, and Bayesian cognitive modeling. We find that both mutual-informat"
2021.acl-long.382,N03-1017,0,0.143133,"network. As with other neural network parameters, however, our experiments will show that the initialization of the parameter L significantly impacts downstream model performance, and specifically benefits from initialization with a set of input–output mappings learned with an offline lexicon learning step. Indeed, while not widely used in neural sequence models (though c.f. Section 2), lexicon-based initialization was a standard feature of many complex non-neural sequence transduction models, including semantic parsers (Kwiatkowski et al., 2011) and phrase-based machine translation systems (Koehn et al., 2003). But an important distinction between our approach and these others is the fact that we can handle outputs that are not (transparently) compositional. Not every fragment of an input will correspond to a fragment of an output: for example, thrice in SCAN has no corresponding output token and instead describes a structural transformation. Moreover, the lexicon is not the only way to generate: complex mappings can also be learned by pwrite without going through the lexicon at all. Thus, while most existing work on lexicon learning aims for complete coverage of all word meanings, the model descri"
2021.acl-long.70,J08-1001,0,0.0807753,"l anything about usable information: indeed, patterns of attention do not necessarily correlate with model predictions (Jain and Wallace, 2019). Other related work Our finding that finegrained ordering information contributes little usable information is consistent with Rae et al. (2019)’s finding that long-range contexts could be informatively summarized in fixed-sized vectors; our finding that most usable information is carried by nouns is consistent with earlier findings about both specialized neural architectures (Henaff et al., 2016) and discourse representations in feature-based models (Barzilay and Lapata, 2008). Our approach also shares similar motivations to information-theoretic work on probing (Voita and Titov, 2020; Pimentel et al., 2020), which uses related tools to interpret linguistic structure in LM representations rather than characterizing their effect on LM predictions. Several recent papers have explored the effect of training-time and test-time ablations in models for other data analysis tasks: Pham et al. (2020) find that shuffling experiments have a limited effect on the accuracy of models for natural language inference, while Perez et al. (2021) describe several experiments aimed at"
2021.acl-long.70,J92-1002,0,0.525842,"ta and training details For all experiments, our LM uses the GPT-2 model architecture (Radford et al., 2019) in the implementation of Wolf et al. (2020) with default hyperparameters. All models are trained from scratch on the WikiText-103 dataset (Merity et al., 2016), an English language modeling benchmark. Aside from ablations, no preprocessing is applied. A special separator token is inserted between ablated and unablated context. The training set contains 103,221,021 words, while the evaluation set contains 217,646 words. A note on evaluation As in past work on evaluating language models (Brown et al., 1992), our evaluation of relative predictive information ultimately bottoms out in a conditional entropy (logperplexity). Recent work has shown that other metrics, such as diversity of outputs, are important for evaluating the quality of LMs as models for language generation (Hashimoto et al., 2019; Caccia et al., 2020). Generation also depends on a number of other factors, such as choice of decoding procedure (Caglayan et al., 2020). Here, we focus on LMs as predictive models, measuring their ability to place an accurate distribution over future words and sentences, rather than their ability to ge"
2021.acl-long.70,2020.coling-main.210,0,0.0241066,"context. The training set contains 103,221,021 words, while the evaluation set contains 217,646 words. A note on evaluation As in past work on evaluating language models (Brown et al., 1992), our evaluation of relative predictive information ultimately bottoms out in a conditional entropy (logperplexity). Recent work has shown that other metrics, such as diversity of outputs, are important for evaluating the quality of LMs as models for language generation (Hashimoto et al., 2019; Caccia et al., 2020). Generation also depends on a number of other factors, such as choice of decoding procedure (Caglayan et al., 2020). Here, we focus on LMs as predictive models, measuring their ability to place an accurate distribution over future words and sentences, rather than their ability to generate useful or coherent text (see Appendix C). We want to emphasize that these results below apply to language models specifically, and not transformers applied to NLP tasks in general—the same analysis might give very different conclusions if applied to, e.g., question answering or summarization. 3 context. We first train a no information model to minimize L(θ, 0 ∼ 512) and a full information model to minimize L(θ, 512 ∼ 1024"
2021.conll-1.7,N18-1202,0,0.286414,"? x1 f(x0, x1) ? x0 The cat [MASK] on the mat everything else verbs Nullspace Proj. (d) dog causal? sat or correlative? Figure 1: By training rank-constrained probing models on linguistic analysis tasks, we find that linguistically meaningful categories are (a) encoded in lowdimensional representation spaces; (b) organized hierarchically, but (c) not aligned with individual neurons. An additional set of experiments (d) uses these findings to identify linear operators that predictably affect outputs of a masked language model. Best viewed in color. Introduction Contextual word representations (Peters et al., 2018) encode general linguistic features (e.g. semantic class; Belinkov and Glass, 2019) and sentence-specific relations (e.g. syntactic role; Tenney et al., 2019a). Used as input features, pretrained representations enable efficient training of models for a variety of NLP tasks (Peters et al., 2019). An enormous body of recent work in NLP has attempted to enumerate what features are encoded by pretrained word representations (e.g. Shi et al., 2016; Tenney et al., 2019b; Belinkov and Glass, 2019), and more recent approaches have studied how accessible this information is, characterizing the tradeof"
2021.conll-1.7,P19-1452,0,0.450128,"probing models on linguistic analysis tasks, we find that linguistically meaningful categories are (a) encoded in lowdimensional representation spaces; (b) organized hierarchically, but (c) not aligned with individual neurons. An additional set of experiments (d) uses these findings to identify linear operators that predictably affect outputs of a masked language model. Best viewed in color. Introduction Contextual word representations (Peters et al., 2018) encode general linguistic features (e.g. semantic class; Belinkov and Glass, 2019) and sentence-specific relations (e.g. syntactic role; Tenney et al., 2019a). Used as input features, pretrained representations enable efficient training of models for a variety of NLP tasks (Peters et al., 2019). An enormous body of recent work in NLP has attempted to enumerate what features are encoded by pretrained word representations (e.g. Shi et al., 2016; Tenney et al., 2019b; Belinkov and Glass, 2019), and more recent approaches have studied how accessible this information is, characterizing the tradeoff between generic notions of model complexity and accuracy needed to recover word features from learned representations (Voita and Titov, 2020; Pimentel et a"
2021.conll-1.7,W19-4302,0,0.0230257,"tation spaces; (b) organized hierarchically, but (c) not aligned with individual neurons. An additional set of experiments (d) uses these findings to identify linear operators that predictably affect outputs of a masked language model. Best viewed in color. Introduction Contextual word representations (Peters et al., 2018) encode general linguistic features (e.g. semantic class; Belinkov and Glass, 2019) and sentence-specific relations (e.g. syntactic role; Tenney et al., 2019a). Used as input features, pretrained representations enable efficient training of models for a variety of NLP tasks (Peters et al., 2019). An enormous body of recent work in NLP has attempted to enumerate what features are encoded by pretrained word representations (e.g. Shi et al., 2016; Tenney et al., 2019b; Belinkov and Glass, 2019), and more recent approaches have studied how accessible this information is, characterizing the tradeoff between generic notions of model complexity and accuracy needed to recover word features from learned representations (Voita and Titov, 2020; Pimentel et al., 2020a). But the manner in which these features are encoded in representations remains poorly understood. In this paper, we investigate"
2021.conll-1.7,2020.emnlp-main.254,0,0.546205,"et al., 2019a). Used as input features, pretrained representations enable efficient training of models for a variety of NLP tasks (Peters et al., 2019). An enormous body of recent work in NLP has attempted to enumerate what features are encoded by pretrained word representations (e.g. Shi et al., 2016; Tenney et al., 2019b; Belinkov and Glass, 2019), and more recent approaches have studied how accessible this information is, characterizing the tradeoff between generic notions of model complexity and accuracy needed to recover word features from learned representations (Voita and Titov, 2020; Pimentel et al., 2020a). But the manner in which these features are encoded in representations remains poorly understood. In this paper, we investigate the shape and structure of learned representation spaces (Figure 1). We build on previous studies that have identified specific linear subspaces responsible for gender bias in word embeddings (Bolukbasi et al., 2016) and word sense disambiguation (Coenen et al., 2019). We show that these linear subspaces are the rule, not the exception: a variety of other lexical and syntactic phenomena are encoded in low-dimensional linear subspaces, and these subspaces exhibit re"
2021.conll-1.7,2020.emnlp-main.232,0,0.0349734,"information further: in time, as a function of training dynamics (Saphra and Lopez, 2019), and in space, e.g. as a function of individual hidden units (Bau* et al., 2019; Dalvi et al., 2019). See Belinkov and Glass (2019) for a detailed survey. Our work falls into the latter category: we aim to identify global, linear structure in representation spaces. Some previous work has identified surprising non-linear geometry in word embeddings (Mimno and Thompson, 2017), but other work suggests that simple linear subspaces encode meaningful attributes like gender information (Bolukbasi et al., 2016; Vargas and Cotterell, 2020; Ravfogel et al., 2020) and word sense information (Coenen 3 Method Consider a corpus of words W = (w1 , . . . , wn ) with D-dimensional word representations (r1 , . . . , rn ) written as a matrix R ∈ RD×n . A probing task on W is defined by a mapping f (W ) from words to discrete labels (part of speech tags, head–dependent relations, semantic roles, etc.) We say the representations encode the task if there exists a probe g(R) that predicts f (W ) according to a score S(g(R), f (W )), which we choose to be held-out accuracy. There are other choices for S, e.g. selectivity (Hewitt and Liang, 2"
2021.conll-1.7,2020.acl-main.420,0,0.110035,"et al., 2019a). Used as input features, pretrained representations enable efficient training of models for a variety of NLP tasks (Peters et al., 2019). An enormous body of recent work in NLP has attempted to enumerate what features are encoded by pretrained word representations (e.g. Shi et al., 2016; Tenney et al., 2019b; Belinkov and Glass, 2019), and more recent approaches have studied how accessible this information is, characterizing the tradeoff between generic notions of model complexity and accuracy needed to recover word features from learned representations (Voita and Titov, 2020; Pimentel et al., 2020a). But the manner in which these features are encoded in representations remains poorly understood. In this paper, we investigate the shape and structure of learned representation spaces (Figure 1). We build on previous studies that have identified specific linear subspaces responsible for gender bias in word embeddings (Bolukbasi et al., 2016) and word sense disambiguation (Coenen et al., 2019). We show that these linear subspaces are the rule, not the exception: a variety of other lexical and syntactic phenomena are encoded in low-dimensional linear subspaces, and these subspaces exhibit re"
2021.conll-1.7,D19-1448,0,0.0178698,"and verbs (Section 6). 2 et al., 2019; Ethayarajh, 2019). We extend this account to a variety of other linguistic features, identify relations among feature subspaces themselves, and show that these subspaces are causally linked to model behavior. More recent work has focused on addressing shortcomings of the probing paradigm itself. Hewitt and Liang (2019) design non-linguistic control tasks to benchmark how selective probes are for linguistic information, and show that high probe accuracy is sometimes attributable to task simplicity rather than explicit representation of linguistic content. Voita et al. (2019), Voita and Titov (2020) and Pimentel et al. (2020b) describe an informationtheoretic approach to probing. Voita and Titov (2020) in particular argue that measurements of probe quality based on description length characterize encodings more precisely than raw selectivity measurements, showing that part-of-speech tags and dependency edges can be extracted with a smaller code length than controls. Ravichander et al. (2021) and Elazar et al. (2021) further question the use of probe accuracy, finding that language models encode linguistic information even when it is not causally linked to task per"
2021.conll-1.7,2020.emnlp-main.14,0,0.29682,"syntactic role; Tenney et al., 2019a). Used as input features, pretrained representations enable efficient training of models for a variety of NLP tasks (Peters et al., 2019). An enormous body of recent work in NLP has attempted to enumerate what features are encoded by pretrained word representations (e.g. Shi et al., 2016; Tenney et al., 2019b; Belinkov and Glass, 2019), and more recent approaches have studied how accessible this information is, characterizing the tradeoff between generic notions of model complexity and accuracy needed to recover word features from learned representations (Voita and Titov, 2020; Pimentel et al., 2020a). But the manner in which these features are encoded in representations remains poorly understood. In this paper, we investigate the shape and structure of learned representation spaces (Figure 1). We build on previous studies that have identified specific linear subspaces responsible for gender bias in word embeddings (Bolukbasi et al., 2016) and word sense disambiguation (Coenen et al., 2019). We show that these linear subspaces are the rule, not the exception: a variety of other lexical and syntactic phenomena are encoded in low-dimensional linear subspaces, and the"
2021.conll-1.7,2020.acl-main.647,0,0.101532,"e, as a function of training dynamics (Saphra and Lopez, 2019), and in space, e.g. as a function of individual hidden units (Bau* et al., 2019; Dalvi et al., 2019). See Belinkov and Glass (2019) for a detailed survey. Our work falls into the latter category: we aim to identify global, linear structure in representation spaces. Some previous work has identified surprising non-linear geometry in word embeddings (Mimno and Thompson, 2017), but other work suggests that simple linear subspaces encode meaningful attributes like gender information (Bolukbasi et al., 2016; Vargas and Cotterell, 2020; Ravfogel et al., 2020) and word sense information (Coenen 3 Method Consider a corpus of words W = (w1 , . . . , wn ) with D-dimensional word representations (r1 , . . . , rn ) written as a matrix R ∈ RD×n . A probing task on W is defined by a mapping f (W ) from words to discrete labels (part of speech tags, head–dependent relations, semantic roles, etc.) We say the representations encode the task if there exists a probe g(R) that predicts f (W ) according to a score S(g(R), f (W )), which we choose to be held-out accuracy. There are other choices for S, e.g. selectivity (Hewitt and Liang, 2019) and MDL (Voita and"
2021.conll-1.7,2020.emnlp-demos.6,0,0.0623669,"Missing"
2021.emnlp-main.448,2020.emnlp-main.615,0,0.0264733,"a local-only and global-only predictor (bottom). or n-gram statistics (Miller and Selfridge, 1950). But improved predictive power comes at the cost of increased model complexity and a loss of transparency. While it is possible to characterize (and even control) how finite-state models will behave in previously unseen contexts, generalization in neural LMs is not nearly as well understood. Consider the following sentence prefixes: Neural language models (LMs) play a key role in language processing systems for tasks as diverse as machine translation, dialogue, and automated speech recognition (Baziotis et al., 2020; Sordoni et al., 2015; Mikolov et al., 2010). These LMs, which model distributions over words in context via recurrent, convolutional, or attentional neural (a) The pandemic won’t end children can. . . networks, have been found to consistently outper(b) Let him easter. . . form finite-state approaches to language modeling (c) After we ate the pizza, the pizza ate. . . based on hidden Markov models (Kuhn et al., 1994) 5513 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5513–5526 c November 7–11, 2021. 2021 Association for Computational Linguistics"
2021.emnlp-main.448,P98-1035,0,0.55689,"rolled, and understood theoretically. 2 Background Generalization in count-based LMs Before the widespread use of neural approaches in NLP, statistical approaches to language modeling were typically defined by explicit independence assumptions governing their generalization in contexts never observed in the training data. For example, ngram models (Miller and Selfridge, 1950; Shannon, 1951) ignore global sentence structure in favor of a local context of at most n words. By contrast, latent-variable language models based on finitestate machines (Kuhn et al., 1994) (or more expressive automata; Chelba and Jelinek 1998, Pauls and Klein 2012) explicitly incorporate information from the long-range context by conditioning next-word prediction on abstract global states constrained by global sentence structure. In models of both kinds, behavior in contexts unlike any seen at training time is be explicitly specified via backoff and smoothing schemes aimed at providing robust estimates of the frequency of rare events (Good, 1953; Katz, 1987; Kneser and Ney, 1995). Like past work on backoff and smoothing, our work in this paper attempts to provide a general mechanism for both prediction and control in more complex,"
2021.naacl-main.225,P13-2009,1,0.790848,"the aligned utterance tokens in Tzs (e.g., Block 1, Fig. 1a). In the second variant (lines 8-9), we find internally contiguous utterance spans (subsequences) in Tzs and align them to z s . For instance, the sub-program (?x1 art_directed M1) in Block 2 of Fig. 1b aligns to two utterance spans: M1 ’s and art director. While this case does not have an exact analog in MT, it is reminiscent of the model of Chiang (2005) which extracts translation rules with discontinuous phrase segments, and could be useful in capturing long-range alignments of utterance subsequences to sub-programs as in Block 2 (Andreas et al., 2013). Span-level alignments for a sub-program are then generated by pairing its program spans zp:q (spans with consecutive program tokens) with all its aligned utterance spans (lines 11-12). Finally, we generate alignments for sketch spans in z by pairing them with any utterance tokens that have not yet been aligned to a sub-program (lines 13-14). Algo. 1 leverages the explicit hierarchical structures of programs to generate alignments between sub-programs and utterance spans. Such an idea of using structural information for alignment extraction has deep roots in statistical syntax-based MT, which"
2021.naacl-main.225,D16-1162,1,0.824538,"n data transformations and model architectures, the de1 Introduction sign of loss functions to encourage compositional Semantic parsers translate natural language ut- generalization has been under-explored. This paterances (e.g., Schedule a meeting with Jean) per investigates attention supervision losses that encourage attention matrices in neural sequence into executable programs (e.g., CreateEvent( attendees=Jean)), and play a crucial role in ap- models to resemble the output of word alignment algorithms (Liu et al. (2016); Mi et al. (2016); plications such as question answering systems and Arthur et al. (2016); Lyu and Titov (2018), inter conversational agents (Liang, 2016; Gupta et al., alia) as a source of inductive bias for composi2018; Wen et al., 2017). As in many language understanding problems, a central challenge in se- tional tasks. Previous work has found that aligning program tokens (e.g., FindManager in Fig. 1) mantic parsing is compositional generalization (Finegan-Dollak et al., 2018; Keysers et al., 2020). to natural language tokens (manager) improves Consider a personal digital assistant for which de- model performance (Misra et al., 2018; Rabinovich et al., 2017; Goldman et al., 20"
2021.naacl-main.225,J93-2003,0,0.157172,"Missing"
2021.naacl-main.225,P05-1033,0,0.318552,"aset (§3). In the first case (lines 5-6), similar to bilingual phrase extraction in machine translation (MT; Och, 2002), we create a single consecutive utterance span um:n via the outer bound of the aligned utterance tokens in Tzs (e.g., Block 1, Fig. 1a). In the second variant (lines 8-9), we find internally contiguous utterance spans (subsequences) in Tzs and align them to z s . For instance, the sub-program (?x1 art_directed M1) in Block 2 of Fig. 1b aligns to two utterance spans: M1 ’s and art director. While this case does not have an exact analog in MT, it is reminiscent of the model of Chiang (2005) which extracts translation rules with discontinuous phrase segments, and could be useful in capturing long-range alignments of utterance subsequences to sub-programs as in Block 2 (Andreas et al., 2013). Span-level alignments for a sub-program are then generated by pairing its program spans zp:q (spans with consecutive program tokens) with all its aligned utterance spans (lines 11-12). Finally, we generate alignments for sketch spans in z by pairing them with any utterance tokens that have not yet been aligned to a sub-program (lines 13-14). Algo. 1 leverages the explicit hierarchical structu"
2021.naacl-main.225,P16-1004,0,0.0455513,"zation in semantic parsers. Our approach builds on existing losses that encourage attention maps in neural sequence-to-sequence models to imitate the output of classical word alignment algorithms. Where past work has used word-level alignments, we focus on spans; borrowing ideas from phrase-based machine translation, we align subtrees in semantic parses to spans of input sentences, and encourage neural attention mechanisms to mimic these alignments. This method improves the performance of transformers, RNNs, and structured decoders on three benchmarks of compositional generalization. parsers (Dong and Lapata, 2016; Yin and Neubig, 2017), tend to perform poorly at out-of-distribution generalization of this kind (Lake and Baroni, 2018; Furrer et al., 2020; Suhr et al., 2020). Methods have been proposed to bridge the generalization gap using meta-learning (Lake, 2019; Wang et al., 2020) or specialized model architectures (Russin et al., 2019; Li et al., 2019; Liu et al., 2020; Chen et al., 2020). These have registered impressive performance on small synthetic benchmark datasets, but it has proven difficult to effectively combine them with large-scale pre-training (Lewis et al., 2020; Raffel et al., 2020)"
2021.naacl-main.225,P18-1068,0,0.0166598,"pervised Attention Neural Semantic Parsers A semantic parser maps a natural language (NL) utterance u to an executable program z. In this paper, we consider neural parsers using token-based attentive decoders, in which z is predicted as a sequence of consecu|z| tive tokens {zj=1 } by attending to tokens in u = |u| {ui=1 }. Examples include sequence-to-sequence models based on recurrent networks (Dong and Lapata, 2016; Jia and Liang, 2016) or transformers (Vaswani et al., 2017; Raffel et al., 2020), as well as structured parsing methods that predict a program following its syntactic structure (Dong and Lapata (2018), see §3 for more details). Bangkok 1st is aligned to the j-th target (program) token zj . A|u|×|z |can be inferred using latent variable models (Brown et al., 1993; Och and Ney, 2003; Dyer et al., 2013). During training, when the decoder predicts a target token zj , supervised attention encourages the target-to-source attention distribution patt (ui |zj ) to match the prior alignment distribua tion pprior (ui |zj ) = P i,j , which is normalized k ak,j by the number of source tokens aligned to zj . We use a squared error loss (Liu et al., 2016): Lsup_att = |z ||u| 2 1 XX patt (ui |zj )−pprior"
2021.naacl-main.225,N13-1073,0,0.0448885,"s, in which z is predicted as a sequence of consecu|z| tive tokens {zj=1 } by attending to tokens in u = |u| {ui=1 }. Examples include sequence-to-sequence models based on recurrent networks (Dong and Lapata, 2016; Jia and Liang, 2016) or transformers (Vaswani et al., 2017; Raffel et al., 2020), as well as structured parsing methods that predict a program following its syntactic structure (Dong and Lapata (2018), see §3 for more details). Bangkok 1st is aligned to the j-th target (program) token zj . A|u|×|z |can be inferred using latent variable models (Brown et al., 1993; Och and Ney, 2003; Dyer et al., 2013). During training, when the decoder predicts a target token zj , supervised attention encourages the target-to-source attention distribution patt (ui |zj ) to match the prior alignment distribua tion pprior (ui |zj ) = P i,j , which is normalized k ak,j by the number of source tokens aligned to zj . We use a squared error loss (Liu et al., 2016): Lsup_att = |z ||u| 2 1 XX patt (ui |zj )−pprior (ui |zj ) . (1) |z |j=1 i=1 Previous work has also used a cross entropy loss (Rabinovich et al., 2017; Oren et al., 2020). Sub-program-to-Span Alignment We present a simple heuristic algorithm to extrac"
2021.naacl-main.225,P18-1033,0,0.0116855,"., CreateEvent( attendees=Jean)), and play a crucial role in ap- models to resemble the output of word alignment algorithms (Liu et al. (2016); Mi et al. (2016); plications such as question answering systems and Arthur et al. (2016); Lyu and Titov (2018), inter conversational agents (Liang, 2016; Gupta et al., alia) as a source of inductive bias for composi2018; Wen et al., 2017). As in many language understanding problems, a central challenge in se- tional tasks. Previous work has found that aligning program tokens (e.g., FindManager in Fig. 1) mantic parsing is compositional generalization (Finegan-Dollak et al., 2018; Keysers et al., 2020). to natural language tokens (manager) improves Consider a personal digital assistant for which de- model performance (Misra et al., 2018; Rabinovich et al., 2017; Goldman et al., 2018; Richardson et al., velopers have assembled separate collections of 2018; Herzig and Berant, 2020; Oren et al., 2020). annotated utterances for user requests involving their calendars (e.g., Schedule a meeting with Jean) However, the token-level alignments derived from and their contact books (e.g., Who is Jean’s man- off-the-shelf aligners are often noisy, and the correspondence between n"
2021.naacl-main.225,N04-1035,0,0.271193,"cutive program tokens) with all its aligned utterance spans (lines 11-12). Finally, we generate alignments for sketch spans in z by pairing them with any utterance tokens that have not yet been aligned to a sub-program (lines 13-14). Algo. 1 leverages the explicit hierarchical structures of programs to generate alignments between sub-programs and utterance spans. Such an idea of using structural information for alignment extraction has deep roots in statistical syntax-based MT, which leverages the syntactic structure of sentences to generate alignments between parse trees and NL constituents (Galley et al., 2004; Chiang, 2005; Liu et al., 2006). Our approach is also broadly related to lexicon induction models in semantic parsers based on probabilistic CCG grammars (Kwiatkowski et al., 2011) or other formalisms (Jones et al., 2012), which learn mapping rules between logical form templates and utterance tokens. 3 Experiments We evaluate span-level supervised attention on three benchmarks of compositional generalization. SMC AL F LOW Compositional Skills (SMC AL F LOW-CS) is a new dataset created in this study based on the task-oriented dialogue corpus SMC AL F LOW (Semantic Machines et al., 2020), feat"
2021.naacl-main.225,P18-1168,0,0.0119956,"thur et al. (2016); Lyu and Titov (2018), inter conversational agents (Liang, 2016; Gupta et al., alia) as a source of inductive bias for composi2018; Wen et al., 2017). As in many language understanding problems, a central challenge in se- tional tasks. Previous work has found that aligning program tokens (e.g., FindManager in Fig. 1) mantic parsing is compositional generalization (Finegan-Dollak et al., 2018; Keysers et al., 2020). to natural language tokens (manager) improves Consider a personal digital assistant for which de- model performance (Misra et al., 2018; Rabinovich et al., 2017; Goldman et al., 2018; Richardson et al., velopers have assembled separate collections of 2018; Herzig and Berant, 2020; Oren et al., 2020). annotated utterances for user requests involving their calendars (e.g., Schedule a meeting with Jean) However, the token-level alignments derived from and their contact books (e.g., Who is Jean’s man- off-the-shelf aligners are often noisy, and the correspondence between natural language and program ager?). An effective model should learn from this data how to additionally handle requests like Sched- tokens is not always a many-to-one map of the kind returned by standard alig"
2021.naacl-main.225,D18-1300,0,0.0646605,"Missing"
2021.naacl-main.225,P16-1002,0,0.0163993,"tently improves over token-level objectives, achieving strong results on three semantic parsing datasets featuring diverse formalisms and tests of generalization. 2 Span-level Supervised Attention Neural Semantic Parsers A semantic parser maps a natural language (NL) utterance u to an executable program z. In this paper, we consider neural parsers using token-based attentive decoders, in which z is predicted as a sequence of consecu|z| tive tokens {zj=1 } by attending to tokens in u = |u| {ui=1 }. Examples include sequence-to-sequence models based on recurrent networks (Dong and Lapata, 2016; Jia and Liang, 2016) or transformers (Vaswani et al., 2017; Raffel et al., 2020), as well as structured parsing methods that predict a program following its syntactic structure (Dong and Lapata (2018), see §3 for more details). Bangkok 1st is aligned to the j-th target (program) token zj . A|u|×|z |can be inferred using latent variable models (Brown et al., 1993; Och and Ney, 2003; Dyer et al., 2013). During training, when the decoder predicts a target token zj , supervised attention encourages the target-to-source attention distribution patt (ui |zj ) to match the prior alignment distribua tion pprior (ui |zj )"
2021.naacl-main.225,P12-1051,0,0.0348018,"es 13-14). Algo. 1 leverages the explicit hierarchical structures of programs to generate alignments between sub-programs and utterance spans. Such an idea of using structural information for alignment extraction has deep roots in statistical syntax-based MT, which leverages the syntactic structure of sentences to generate alignments between parse trees and NL constituents (Galley et al., 2004; Chiang, 2005; Liu et al., 2006). Our approach is also broadly related to lexicon induction models in semantic parsers based on probabilistic CCG grammars (Kwiatkowski et al., 2011) or other formalisms (Jones et al., 2012), which learn mapping rules between logical form templates and utterance tokens. 3 Experiments We evaluate span-level supervised attention on three benchmarks of compositional generalization. SMC AL F LOW Compositional Skills (SMC AL F LOW-CS) is a new dataset created in this study based on the task-oriented dialogue corpus SMC AL F LOW (Semantic Machines et al., 2020), featuring real-world human-generated utterances about calendar management. Like the motivating story in §1, we create training data for skills S involving event creation (e.g., Schedule a meeting with Adam) and organization str"
2021.naacl-main.225,D11-1140,0,0.0454445,"have not yet been aligned to a sub-program (lines 13-14). Algo. 1 leverages the explicit hierarchical structures of programs to generate alignments between sub-programs and utterance spans. Such an idea of using structural information for alignment extraction has deep roots in statistical syntax-based MT, which leverages the syntactic structure of sentences to generate alignments between parse trees and NL constituents (Galley et al., 2004; Chiang, 2005; Liu et al., 2006). Our approach is also broadly related to lexicon induction models in semantic parsers based on probabilistic CCG grammars (Kwiatkowski et al., 2011) or other formalisms (Jones et al., 2012), which learn mapping rules between logical form templates and utterance tokens. 3 Experiments We evaluate span-level supervised attention on three benchmarks of compositional generalization. SMC AL F LOW Compositional Skills (SMC AL F LOW-CS) is a new dataset created in this study based on the task-oriented dialogue corpus SMC AL F LOW (Semantic Machines et al., 2020), featuring real-world human-generated utterances about calendar management. Like the motivating story in §1, we create training data for skills S involving event creation (e.g., Schedule"
2021.naacl-main.225,2020.acl-main.703,0,0.0287333,"alization. parsers (Dong and Lapata, 2016; Yin and Neubig, 2017), tend to perform poorly at out-of-distribution generalization of this kind (Lake and Baroni, 2018; Furrer et al., 2020; Suhr et al., 2020). Methods have been proposed to bridge the generalization gap using meta-learning (Lake, 2019; Wang et al., 2020) or specialized model architectures (Russin et al., 2019; Li et al., 2019; Liu et al., 2020; Chen et al., 2020). These have registered impressive performance on small synthetic benchmark datasets, but it has proven difficult to effectively combine them with large-scale pre-training (Lewis et al., 2020; Raffel et al., 2020) and natural data (Furrer et al., 2020). In contrast to this extensive literature on data transformations and model architectures, the de1 Introduction sign of loss functions to encourage compositional Semantic parsers translate natural language ut- generalization has been under-explored. This paterances (e.g., Schedule a meeting with Jean) per investigates attention supervision losses that encourage attention matrices in neural sequence into executable programs (e.g., CreateEvent( attendees=Jean)), and play a crucial role in ap- models to resemble the output of word alig"
2021.naacl-main.225,D19-1438,0,0.0280134,"s to spans of input sentences, and encourage neural attention mechanisms to mimic these alignments. This method improves the performance of transformers, RNNs, and structured decoders on three benchmarks of compositional generalization. parsers (Dong and Lapata, 2016; Yin and Neubig, 2017), tend to perform poorly at out-of-distribution generalization of this kind (Lake and Baroni, 2018; Furrer et al., 2020; Suhr et al., 2020). Methods have been proposed to bridge the generalization gap using meta-learning (Lake, 2019; Wang et al., 2020) or specialized model architectures (Russin et al., 2019; Li et al., 2019; Liu et al., 2020; Chen et al., 2020). These have registered impressive performance on small synthetic benchmark datasets, but it has proven difficult to effectively combine them with large-scale pre-training (Lewis et al., 2020; Raffel et al., 2020) and natural data (Furrer et al., 2020). In contrast to this extensive literature on data transformations and model architectures, the de1 Introduction sign of loss functions to encourage compositional Semantic parsers translate natural language ut- generalization has been under-explored. This paterances (e.g., Schedule a meeting with Jean) per in"
2021.naacl-main.225,C16-1291,0,0.0540971,"020) and natural data (Furrer et al., 2020). In contrast to this extensive literature on data transformations and model architectures, the de1 Introduction sign of loss functions to encourage compositional Semantic parsers translate natural language ut- generalization has been under-explored. This paterances (e.g., Schedule a meeting with Jean) per investigates attention supervision losses that encourage attention matrices in neural sequence into executable programs (e.g., CreateEvent( attendees=Jean)), and play a crucial role in ap- models to resemble the output of word alignment algorithms (Liu et al. (2016); Mi et al. (2016); plications such as question answering systems and Arthur et al. (2016); Lyu and Titov (2018), inter conversational agents (Liang, 2016; Gupta et al., alia) as a source of inductive bias for composi2018; Wen et al., 2017). As in many language understanding problems, a central challenge in se- tional tasks. Previous work has found that aligning program tokens (e.g., FindManager in Fig. 1) mantic parsing is compositional generalization (Finegan-Dollak et al., 2018; Keysers et al., 2020). to natural language tokens (manager) improves Consider a personal digital assistant for wh"
2021.naacl-main.225,P06-1077,0,0.12014,"aligned utterance spans (lines 11-12). Finally, we generate alignments for sketch spans in z by pairing them with any utterance tokens that have not yet been aligned to a sub-program (lines 13-14). Algo. 1 leverages the explicit hierarchical structures of programs to generate alignments between sub-programs and utterance spans. Such an idea of using structural information for alignment extraction has deep roots in statistical syntax-based MT, which leverages the syntactic structure of sentences to generate alignments between parse trees and NL constituents (Galley et al., 2004; Chiang, 2005; Liu et al., 2006). Our approach is also broadly related to lexicon induction models in semantic parsers based on probabilistic CCG grammars (Kwiatkowski et al., 2011) or other formalisms (Jones et al., 2012), which learn mapping rules between logical form templates and utterance tokens. 3 Experiments We evaluate span-level supervised attention on three benchmarks of compositional generalization. SMC AL F LOW Compositional Skills (SMC AL F LOW-CS) is a new dataset created in this study based on the task-oriented dialogue corpus SMC AL F LOW (Semantic Machines et al., 2020), featuring real-world human-generated"
2021.naacl-main.225,D15-1166,0,0.0715009,"Missing"
2021.naacl-main.225,P18-1037,0,0.0192076,"and model architectures, the de1 Introduction sign of loss functions to encourage compositional Semantic parsers translate natural language ut- generalization has been under-explored. This paterances (e.g., Schedule a meeting with Jean) per investigates attention supervision losses that encourage attention matrices in neural sequence into executable programs (e.g., CreateEvent( attendees=Jean)), and play a crucial role in ap- models to resemble the output of word alignment algorithms (Liu et al. (2016); Mi et al. (2016); plications such as question answering systems and Arthur et al. (2016); Lyu and Titov (2018), inter conversational agents (Liang, 2016; Gupta et al., alia) as a source of inductive bias for composi2018; Wen et al., 2017). As in many language understanding problems, a central challenge in se- tional tasks. Previous work has found that aligning program tokens (e.g., FindManager in Fig. 1) mantic parsing is compositional generalization (Finegan-Dollak et al., 2018; Keysers et al., 2020). to natural language tokens (manager) improves Consider a personal digital assistant for which de- model performance (Misra et al., 2018; Rabinovich et al., 2017; Goldman et al., 2018; Richardson et al.,"
2021.naacl-main.225,E17-1042,0,0.0203363,"Missing"
2021.naacl-main.225,P17-1105,0,0.161585,"answering systems and Arthur et al. (2016); Lyu and Titov (2018), inter conversational agents (Liang, 2016; Gupta et al., alia) as a source of inductive bias for composi2018; Wen et al., 2017). As in many language understanding problems, a central challenge in se- tional tasks. Previous work has found that aligning program tokens (e.g., FindManager in Fig. 1) mantic parsing is compositional generalization (Finegan-Dollak et al., 2018; Keysers et al., 2020). to natural language tokens (manager) improves Consider a personal digital assistant for which de- model performance (Misra et al., 2018; Rabinovich et al., 2017; Goldman et al., 2018; Richardson et al., velopers have assembled separate collections of 2018; Herzig and Berant, 2020; Oren et al., 2020). annotated utterances for user requests involving their calendars (e.g., Schedule a meeting with Jean) However, the token-level alignments derived from and their contact books (e.g., Who is Jean’s man- off-the-shelf aligners are often noisy, and the correspondence between natural language and program ager?). An effective model should learn from this data how to additionally handle requests like Sched- tokens is not always a many-to-one map of the kind ret"
2021.naacl-main.225,P17-1041,1,0.835763,"ers. Our approach builds on existing losses that encourage attention maps in neural sequence-to-sequence models to imitate the output of classical word alignment algorithms. Where past work has used word-level alignments, we focus on spans; borrowing ideas from phrase-based machine translation, we align subtrees in semantic parses to spans of input sentences, and encourage neural attention mechanisms to mimic these alignments. This method improves the performance of transformers, RNNs, and structured decoders on three benchmarks of compositional generalization. parsers (Dong and Lapata, 2016; Yin and Neubig, 2017), tend to perform poorly at out-of-distribution generalization of this kind (Lake and Baroni, 2018; Furrer et al., 2020; Suhr et al., 2020). Methods have been proposed to bridge the generalization gap using meta-learning (Lake, 2019; Wang et al., 2020) or specialized model architectures (Russin et al., 2019; Li et al., 2019; Liu et al., 2020; Chen et al., 2020). These have registered impressive performance on small synthetic benchmark datasets, but it has proven difficult to effectively combine them with large-scale pre-training (Lewis et al., 2020; Raffel et al., 2020) and natural data (Furre"
2021.naacl-main.225,N18-1066,0,0.0326748,"Missing"
2021.naacl-main.225,P17-1099,0,0.107671,"Missing"
2021.naacl-main.421,N18-1197,1,0.764561,"al in the study of artificial and natufor training. As LLPs employ a human-specified ral intelligence is to understand how language can scaffold more general problem-solving skills (e.g. space of high-level commands, they must be initialized with human supervision, typically obtained by Spelke, 2017), and how these skills in turn shape pretraining the executor. On its own, this training language itself (e.g. Gibson et al., 2017). In NLP paradigm restricts the quality of the learned execuand machine learning, latent language policies tor policy to that exhibited in (possibly suboptimal) (LLPs; Andreas et al., 2018) provide a standard human supervision. For tasks like the real-time framework for studying these questions. An LLP strategy game depicted in Fig. 1, we would like consists of instructor and executor subpolicies: the instructor generates natural language messages (e.g. to study LLPs trained via reinforcement learning high-level commands or subgoals), and the execu- (RL), jointly learning from a downstream reward signal, and optimizing both instructors and executor maps these messages to sequences of low-level tors for task success rather than fidelity to human actions (Fig. 1). LLPs have been u"
2021.naacl-main.421,D17-1259,1,0.7956,"n difficult. Past over long horizons (e.g. in strategy games; Hu et al., work has identified two main challenges: primar2019). They promise an effective and interpretable ily, the LLP-specific problem of semantic drift, in interface between planning and control. which agents come to deploy messages in ways 5351 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5351–5366 June 6–11, 2021. ©2021 Association for Computational Linguistics inconsistent with their original (natural language) meanings (Lewis et al., 2017; Lee et al., 2019); secondarily, the general problem of sample inefficiency in RL algorithms (Kakade et al., 2003; Brunskill and Li, 2013). Model-free deep RL is particularly notorious for requiring enormous amounts of interaction with the environment (Munos et al., 2016; Mnih et al., 2013b). For LLPs to meet their promise as flexible, controllable, and understandable tools for deep learning, better approaches are needed to limit semantic drift and perhaps improve sample efficiency. While semantic change is a constant and welldocumented feature of human languages (McMahon and April, 1994), (h"
2021.naacl-main.421,D16-1127,0,0.0411102,"n. This is typically accomplished ticular multitask training scheme eliminates by pretraining executors via human demonstrations the set of initializations that undergo semantic or reinforcement learning; here we focus on the drift. ingredients of effective joint RL of instructors and • Section 4 evaluates the empirical effectiveness executors. of multitask learning in a real-time strategy Reinforcement learning has been widely used to game featuring rich language, complex com- improve supervised language generation policies, plex dynamics, and LLPs implemented with particularly for dialogue (Li et al., 2016; Lewis deep neural networks. Again, we show that et al., 2017), translation (Ranzato et al., 2015; Wu multitask training reduces semantic drift (and et al., 2016) and summarization (Stiennon et al., improves sample efficiency) of LLPs in multi- 2020). Here, we instead focus on models where ple game variants. language is a latent variable as part of a hierarchical Together, these results show that diverse shared policy for a non-linguistic task. 5352 Instructor I(m ∣ o) o1 Executor E(a ∣ m) m1 = push red a1 R o1 m2 = push blue a2 o2 o2 a2 a1 1 0 0 1 R′ o1 o2 a2 a1 0 1 1 0 Figure 2: A signaling"
andreas-etal-2012-annotating,W04-2319,0,\N,Missing
andreas-etal-2012-annotating,D08-1027,0,\N,Missing
andreas-etal-2012-annotating,N03-2012,0,\N,Missing
andreas-etal-2012-annotating,P04-1085,1,\N,Missing
andreas-etal-2012-annotating,W10-0701,0,\N,Missing
andreas-etal-2012-annotating,P11-2065,0,\N,Missing
andreas-etal-2012-annotating,N06-2014,0,\N,Missing
C12-1083,bohnet-wanner-2010-open,0,0.0225855,"ds for graphs in NLP. The standard model for graphshaped meaning representations in NLP are feature structures, which can be constructed from strings using unification grammars (Moore, 1989). However, while powerful in representation, unification grammars have unfavorable algorithmic properties, lack an intuitive probabilistic extension, and require hand-built rules. Other formal devices to accept and transduce feature structure graphs have rarely been discussed. Notable exceptions are Quernheim and Knight (2012) who discuss formal devices to accept and transduce feature structure graphs, and Bohnet and Wanner (2010) who present a toolkit for manually engineering graph-to-string transducer rules for natural language generation. We believe that we are the first to use hyperedge replacement grammars in the NLP literature and can only refer to the formal HRG survey by (Drewes et al., 1997). 1371 7 Conclusion We have introduced a new model for semantically-driven statistical machine translation using graph-structured meaning representations. Our approach is based on the class of weighted synchronous hyperedge replacement grammars, a rewriting formalism for graph-string pairs that intuitively extends context-f"
C12-1083,J90-2002,0,0.554639,"n Figure 3a using the canonical grammar in a, as created by the CANSEM algorithm. 1363 3 Learning Grammars from Annotated Data 3.1 Aligning Strings and Graphs A0 :an t :ca A1 na root:miss poss:anna Anna misses her cat. Figure 5: Edge-word alignment example. Like much of SMT, alignments lie at the center of our semantics-based approach. However, in our case the alignments are between edges of the graph and words of the string. Figure 5 illustrates such an alignment. By listing out edge labels in a linear order, the graph-to-string alignment problem reduces to ordinary token-to-token alignment (Brown et al., 1990). We experiment with two strategies: (1) IBM Model 4 (M4) as implemented in GIZA++ (Och and Ney, 2003), and (2) a novel aligner that relies on the relative structure of the MR graph and the natural language syntax. For M4, we traverse the graph in a fixed breadth first order to get a sequence of edge labels and feed this, along with the tokenized natural language string, to GIZA++. We then use the edge label order to map the aligned edge labels back to their respective edges. We also experiment with a novel variant of IBM alignment Model 2 (Brown et al., 1990) that we call the dependency depth"
C12-1083,P10-1146,0,0.0168125,"Missing"
C12-1083,P05-1066,0,0.0698714,"Missing"
C12-1083,D09-1076,1,0.470877,"Missing"
C12-1083,P09-2036,0,0.0190644,"meaning. Such systems often struggle to generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confronted with verbs that realize their arguments differently. A system using an inte"
C12-1083,W08-1111,0,0.0145247,"the parameters of statistical generation models is popular, but not much attention has been paid to the scenario where no handwritten rules exist or the mapping between semantic structure and output language is unknown in the training data (the scenario we assume in this paper). The WASP system (Wong and Mooney, 2006) can also be used as a generator. Lu and Ng (2011) automatically learn to generate English and Chinese from sentences paired with lambda calculus. Other examples are (Varges and Mellish, 2001) who learn a semantic grammar form a semantically annotated treebank automatically, and (DeVault et al., 2008) who infer a TAG for generation automatically from semantically annotated example sentences. Formal language approaches to probabilistic tree transformation are popular (e.g. in syntaxbased MT) and recently a formulation of such methods as tree transducers (Comon et al., 2007) has gained prominence in NLP (Knight and May, 2009; Graehl and Knight, 2004). In contrast, little work has been done on methods for graphs in NLP. The standard model for graphshaped meaning representations in NLP are feature structures, which can be constructed from strings using unification grammars (Moore, 1989). Howev"
C12-1083,P10-4002,0,0.0113576,"vation. While parsing arbitrary graphs with SHRGs is NP-complete, we use a polynomial time chart parsing algorithms (which are exponential in the maximum size of the graph fragments on the rule right hand side) for connected graphs (Drewes et al., 1997). In the case of the CANSEM algorithm, we use a parser specialized for the canonical HRG which can be parsed even more efficiently in O (nc ), with c the maximum number of rule right hand side nodes (worst case c = 3 for experiments in this paper). Finally, we rerank the natural language output by incorporating a language model (Heafield, 2011; Dyer et al., 2010). For the SYNSEM algorithm, this is integrated into the parsing algorithm via cube pruning (Chiang, 2007). In the CANSEM algorithm reranking is performed on an k-best list of generated natural language output using a standard n-gram language model. Hypothesis meaning representations might be similarly reranked using a ‘language model’ defined on MR graphs, but we leave this for future work. In our experiments, language model weights were selected empirically based on initial evaluations of the development set. 4.2 Parameter Estimation As with CFGs, there are two strategies for estimating the p"
C12-1083,P03-2041,0,0.00810631,"ere) is strictly harder than direct translation, as the test set contains numerous sentences annotated with identical meaning representations but different natural language realizations. We are optimistic about the potential for an extended version of the current system in which generation is conditioned on both semantics and source language. 6 Related Work We view our semantics-based approach to MT as a continuation of recent work in statistical MT (SMT) that abstracts away from the surface string level by capturing syntactic reorderings in translation (Yamada and Knight, 2001; Gildea, 2003; Eisner, 2003; Collins et al., 2005), or using larger syntactic fragments instead of phrases (Galley et al., 2004, 2006; Chiang, 2007). These systems combine the benefits of rule-based MT and SMT by defining their translation model using syntactic translation rules from the source syntax, into the target syntax, or both. Our syntax-driven approach to rule extraction is inspired by (Chiang, 2007, 2010), while the canonical grammar approach is based on (Galley et al., 2004, 2006). However, we induce synchronous graph grammars between surface form and meaning representation, instead of transfer rules between"
C12-1083,P06-1121,1,0.586811,"rom the meaning representation automatically to build a true statistical semanticsbased MT system. In the semantic parsing literature, there are other learning based approaches to analysis into meaning representations. Zettlemoyer and Collins (2005) use an automatically induced, semantically augmented CCG and a log-linear model to parse into lambda expressions, and Ge and Mooney (2005) integrate syntactic parsing with semantic parsing for recovering Prolog queries. Lu et al. (2008) learn a generative model over tree shaped meaning representation and natural language sentences. Wong and Mooney (2006)’s WASP system is similar to ours because it draws on techniques from SMT, using word alignment algorithms to learn synchronous CFGs which translate between syntax and semantics. In fact, Jones et al. (2012) recasts many semantic parsing approaches as tree transduction, which is closely related to synchronous grammar parsing (Shieber, 2004). To our knowledge we are the first to address semantic parsing into graph-based representations as a learning task using synchronous graph grammars. In generation, learning the parameters of statistical generation models is popular, but not much attention h"
C12-1083,N04-1035,1,0.938738,"phrases can be translated without reference to syntax or meaning. Such systems often struggle to generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confronted with verbs that r"
C12-1083,W05-0602,0,0.028053,"r good performance especially in narrow domains, rule-based MT was the predominant paradigm in deployed MT systems. In contrast, while our system adopts a semantic transfer based paradigm, we learn weighted transfer rules into and from the meaning representation automatically to build a true statistical semanticsbased MT system. In the semantic parsing literature, there are other learning based approaches to analysis into meaning representations. Zettlemoyer and Collins (2005) use an automatically induced, semantically augmented CCG and a log-linear model to parse into lambda expressions, and Ge and Mooney (2005) integrate syntactic parsing with semantic parsing for recovering Prolog queries. Lu et al. (2008) learn a generative model over tree shaped meaning representation and natural language sentences. Wong and Mooney (2006)’s WASP system is similar to ours because it draws on techniques from SMT, using word alignment algorithms to learn synchronous CFGs which translate between syntax and semantics. In fact, Jones et al. (2012) recasts many semantic parsing approaches as tree transduction, which is closely related to synchronous grammar parsing (Shieber, 2004). To our knowledge we are the first to a"
C12-1083,C10-1043,0,0.0196763,"generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confronted with verbs that realize their arguments differently. A system using an intermediate meaning representation ne"
C12-1083,P03-1011,0,0.0129076,"s formulated here) is strictly harder than direct translation, as the test set contains numerous sentences annotated with identical meaning representations but different natural language realizations. We are optimistic about the potential for an extended version of the current system in which generation is conditioned on both semantics and source language. 6 Related Work We view our semantics-based approach to MT as a continuation of recent work in statistical MT (SMT) that abstracts away from the surface string level by capturing syntactic reorderings in translation (Yamada and Knight, 2001; Gildea, 2003; Eisner, 2003; Collins et al., 2005), or using larger syntactic fragments instead of phrases (Galley et al., 2004, 2006; Chiang, 2007). These systems combine the benefits of rule-based MT and SMT by defining their translation model using syntactic translation rules from the source syntax, into the target syntax, or both. Our syntax-driven approach to rule extraction is inspired by (Chiang, 2007, 2010), while the canonical grammar approach is based on (Galley et al., 2004, 2006). However, we induce synchronous graph grammars between surface form and meaning representation, instead of transfer"
C12-1083,N04-1014,1,0.352589,". Lu and Ng (2011) automatically learn to generate English and Chinese from sentences paired with lambda calculus. Other examples are (Varges and Mellish, 2001) who learn a semantic grammar form a semantically annotated treebank automatically, and (DeVault et al., 2008) who infer a TAG for generation automatically from semantically annotated example sentences. Formal language approaches to probabilistic tree transformation are popular (e.g. in syntaxbased MT) and recently a formulation of such methods as tree transducers (Comon et al., 2007) has gained prominence in NLP (Knight and May, 2009; Graehl and Knight, 2004). In contrast, little work has been done on methods for graphs in NLP. The standard model for graphshaped meaning representations in NLP are feature structures, which can be constructed from strings using unification grammars (Moore, 1989). However, while powerful in representation, unification grammars have unfavorable algorithmic properties, lack an intuitive probabilistic extension, and require hand-built rules. Other formal devices to accept and transduce feature structure graphs have rarely been discussed. Notable exceptions are Quernheim and Knight (2012) who discuss formal devices to ac"
C12-1083,W09-1201,0,0.0247227,"Missing"
C12-1083,W11-2123,0,0.00521563,"lded by the derivation. While parsing arbitrary graphs with SHRGs is NP-complete, we use a polynomial time chart parsing algorithms (which are exponential in the maximum size of the graph fragments on the rule right hand side) for connected graphs (Drewes et al., 1997). In the case of the CANSEM algorithm, we use a parser specialized for the canonical HRG which can be parsed even more efficiently in O (nc ), with c the maximum number of rule right hand side nodes (worst case c = 3 for experiments in this paper). Finally, we rerank the natural language output by incorporating a language model (Heafield, 2011; Dyer et al., 2010). For the SYNSEM algorithm, this is integrated into the parsing algorithm via cube pruning (Chiang, 2007). In the CANSEM algorithm reranking is performed on an k-best list of generated natural language output using a standard n-gram language model. Hypothesis meaning representations might be similarly reranked using a ‘language model’ defined on MR graphs, but we leave this for future work. In our experiments, language model weights were selected empirically based on initial evaluations of the development set. 4.2 Parameter Estimation As with CFGs, there are two strategies"
C12-1083,N06-2015,0,0.0111525,"r cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confronted with verbs that realize their arguments differently. A system using an intermediate meaning representation need not suffer from this problem. Instead of learning many bilingual translation rules over all possible realizations of this pattern, it can rely on monolingual realizations to preserve meaning in translation. Due to the recent emergence of large, multilingual, semantically annotated resources such as OntoNotes (Hovy et al., 2006), we believe the time is ripe for data-driven, semantics-based machine translation. In this paper we present a pilot statistical, semantic machine translation system which treats MT as a two-step process of analysis into meaning in the source language, and decoding from meaning in the target language. Our system assumes that meaning representations are directed acyclic graphs; beyond that, it is completely agnostic with respect to the details of the formalism, including the inventory of node and edge labels used. Figure 1 illustrates a pipeline via one possible graph as semantic pivot. The pro"
C12-1083,P12-1051,1,0.155831,"meaning representations. Zettlemoyer and Collins (2005) use an automatically induced, semantically augmented CCG and a log-linear model to parse into lambda expressions, and Ge and Mooney (2005) integrate syntactic parsing with semantic parsing for recovering Prolog queries. Lu et al. (2008) learn a generative model over tree shaped meaning representation and natural language sentences. Wong and Mooney (2006)’s WASP system is similar to ours because it draws on techniques from SMT, using word alignment algorithms to learn synchronous CFGs which translate between syntax and semantics. In fact, Jones et al. (2012) recasts many semantic parsing approaches as tree transduction, which is closely related to synchronous grammar parsing (Shieber, 2004). To our knowledge we are the first to address semantic parsing into graph-based representations as a learning task using synchronous graph grammars. In generation, learning the parameters of statistical generation models is popular, but not much attention has been paid to the scenario where no handwritten rules exist or the mapping between semantic structure and output language is unknown in the training data (the scenario we assume in this paper). The WASP sy"
C12-1083,P07-2045,0,0.00320073,"NSEM Sample sentence Reference give me cities with the largest population what is the population of washington what are in washington what city has the largest population how many people live in washington how many rivers in washington (b) SYNSEM Figure 8: Sample translation output. source language are analyzed into a language-independent meaning representation, and that meaning representation is then used to generate a semantically equivalent sentence in the target language. The scores reported for SYNSEM are especially heartening in light of the fact that a standard phrase-based SMT system (Koehn et al., 2007), trained and tuned on the same corpus, achieves a BLEU score of 45.13 for ZH–EN translation. Note that the semantic translation task (at least as formulated here) is strictly harder than direct translation, as the test set contains numerous sentences annotated with identical meaning representations but different natural language realizations. We are optimistic about the potential for an extended version of the current system in which generation is conditioned on both semantics and source language. 6 Related Work We view our semantics-based approach to MT as a continuation of recent work in st"
C12-1083,D10-1119,0,0.029886,"‘Which rivers cross Ohio?’), is produced by only looking at the query expression itself (GQN). The second (GQE), shown in Figure 6b is a transformation of GQN to more closely match the English syntax using the gold alignments. Note that this reshaped graph better fits the assumptions of the SYNSEM algorithm and should, in theory, produce better SHRGs for English. It is less clear whether an English biased intermediate representation would perform better for translation, as it could conceivably hurt translation to and from other languages. We use the standard 600 train/280 test sentence split (Kwiatkowski et al., 2010), and run 10 1367 DD M4 Prec. Rec. f1 74.8 54.6 46.9 53.7 57.7 54.1 Table 1: Evaluation of English alignment, vs. gold alignments fold cross-validation on the training data during development. We also use the standard list of named entities paired with the corresponding edges to create some fallback rules for handling previously unseen named entities. 5.2 Alignment Table 1 shows results for the alignment algorithms described in Section 3.1 on English and the GQN MR. We report precision, recall and f1 -measure on alignment pairs. The DEPDEP algorithm (DD) performs somewhat better than IBM Model"
C12-1083,1989.mtsummit-1.15,0,0.582692,"t al., 2004, 2006). However, we induce synchronous graph grammars between surface form and meaning representation, instead of transfer rules between source and target form. As with other translation work using synchronous tree grammars, such as synchronous TSG (Chiang, 2010) and synchronous TAG (DeNeefe and 1370 Knight, 2009), our SHRGs can also be applied in both directions. However, none of these SMT approaches use an intermediate semantic representation. A lot of research has been done in the early days of MT on translation systems using such representations (Uchida, 1987; Nirenburg, 1989; Landsbergen, 1989). These systems usually required hand-crafted rules and large knowledge bases and do not learn translation models from data automatically. Until recently, because of their good performance especially in narrow domains, rule-based MT was the predominant paradigm in deployed MT systems. In contrast, while our system adopts a semantic transfer based paradigm, we learn weighted transfer rules into and from the meaning representation automatically to build a true statistical semanticsbased MT system. In the semantic parsing literature, there are other learning based approaches to analysis into mean"
C12-1083,P03-1056,0,0.0174368,"io))) to a MR graph: (a) language-neutral, (b) English-biased and (c) an illustration of how (b) matches the English dependency analysis. Our experiments use the GEOQUERY data set (Tang and Mooney, 2001), originally a parallel corpus of 880 English questions about US geography paired with Prolog style database queries and later translated into Chinese (Lu and Ng, 2011). For English there are gold Penn Treebankstyle syntax annotations as well as gold alignments pairing every word with the best predicate in the query. For Chinese, we make use of automatic parses provided by the Stanford Parser (Levy and Manning, 2003). The database queries—expressions in an unambiguous formal language—serve as a rough encoding of sentence meaning, which we use as our meaning representation in the machine translation pipeline. Though they do not, strictly speaking, encode a linguistic notion of semantics, a statistical MT system can still learn meaningful associations with this languageindependent representation. (For instance the German ‘Gib mir die Bevölkerung von Kalifornien!’ [‘Give me the population of California!’] would match the the same Prolog query as English ‘How many people live in California?’.) For input to ou"
C12-1083,D08-1082,0,0.0175623,"d MT systems. In contrast, while our system adopts a semantic transfer based paradigm, we learn weighted transfer rules into and from the meaning representation automatically to build a true statistical semanticsbased MT system. In the semantic parsing literature, there are other learning based approaches to analysis into meaning representations. Zettlemoyer and Collins (2005) use an automatically induced, semantically augmented CCG and a log-linear model to parse into lambda expressions, and Ge and Mooney (2005) integrate syntactic parsing with semantic parsing for recovering Prolog queries. Lu et al. (2008) learn a generative model over tree shaped meaning representation and natural language sentences. Wong and Mooney (2006)’s WASP system is similar to ours because it draws on techniques from SMT, using word alignment algorithms to learn synchronous CFGs which translate between syntax and semantics. In fact, Jones et al. (2012) recasts many semantic parsing approaches as tree transduction, which is closely related to synchronous grammar parsing (Shieber, 2004). To our knowledge we are the first to address semantic parsing into graph-based representations as a learning task using synchronous grap"
C12-1083,D11-1149,0,0.0621796,":a0/answer o t (c) r ive o o t :ohio a (b) x av :a 1/ oh i r x :t r /r a0 :traverse : v :ri :answer (a) r e which r :ohio t o rivers cross ohio root Two different ways of converting the GEOQUERY Prolog expression answer(A,(river(A),traverse(A,ohio))) to a MR graph: (a) language-neutral, (b) English-biased and (c) an illustration of how (b) matches the English dependency analysis. Our experiments use the GEOQUERY data set (Tang and Mooney, 2001), originally a parallel corpus of 880 English questions about US geography paired with Prolog style database queries and later translated into Chinese (Lu and Ng, 2011). For English there are gold Penn Treebankstyle syntax annotations as well as gold alignments pairing every word with the best predicate in the query. For Chinese, we make use of automatic parses provided by the Stanford Parser (Levy and Manning, 2003). The database queries—expressions in an unambiguous formal language—serve as a rough encoding of sentence meaning, which we use as our meaning representation in the machine translation pipeline. Though they do not, strictly speaking, encode a linguistic notion of semantics, a statistical MT system can still learn meaningful associations with thi"
C12-1083,P89-1005,0,0.684234,"Vault et al., 2008) who infer a TAG for generation automatically from semantically annotated example sentences. Formal language approaches to probabilistic tree transformation are popular (e.g. in syntaxbased MT) and recently a formulation of such methods as tree transducers (Comon et al., 2007) has gained prominence in NLP (Knight and May, 2009; Graehl and Knight, 2004). In contrast, little work has been done on methods for graphs in NLP. The standard model for graphshaped meaning representations in NLP are feature structures, which can be constructed from strings using unification grammars (Moore, 1989). However, while powerful in representation, unification grammars have unfavorable algorithmic properties, lack an intuitive probabilistic extension, and require hand-built rules. Other formal devices to accept and transduce feature structure graphs have rarely been discussed. Notable exceptions are Quernheim and Knight (2012) who discuss formal devices to accept and transduce feature structure graphs, and Bohnet and Wanner (2010) who present a toolkit for manually engineering graph-to-string transducer rules for natural language generation. We believe that we are the first to use hyperedge re"
C12-1083,J03-1002,0,0.0047739,"ars from Annotated Data 3.1 Aligning Strings and Graphs A0 :an t :ca A1 na root:miss poss:anna Anna misses her cat. Figure 5: Edge-word alignment example. Like much of SMT, alignments lie at the center of our semantics-based approach. However, in our case the alignments are between edges of the graph and words of the string. Figure 5 illustrates such an alignment. By listing out edge labels in a linear order, the graph-to-string alignment problem reduces to ordinary token-to-token alignment (Brown et al., 1990). We experiment with two strategies: (1) IBM Model 4 (M4) as implemented in GIZA++ (Och and Ney, 2003), and (2) a novel aligner that relies on the relative structure of the MR graph and the natural language syntax. For M4, we traverse the graph in a fixed breadth first order to get a sequence of edge labels and feed this, along with the tokenized natural language string, to GIZA++. We then use the edge label order to map the aligned edge labels back to their respective edges. We also experiment with a novel variant of IBM alignment Model 2 (Brown et al., 1990) that we call the dependency depth based aligner (DEPDEP, or DD for short) which uses depth within the graph and the dependency analysis"
C12-1083,oepen-lonning-2006-discriminant,0,0.012092,"respect to the details of the formalism, including the inventory of node and edge labels used. Figure 1 illustrates a pipeline via one possible graph as semantic pivot. The proposed framework is flexible enough to handle numerous existing meaning representations, including the programming language syntax of the GEOQUERY corpus (Wong and Mooney, 2006) (used for the experiments in this paper), the PropBank-style structures (Palmer et al., 2005) used for the CoNLL shared task on recognizing semantic dependencies (Hajiˇc et al., 2009), and the Elementary Dependency Structures of the LOGON corpus (Oepen and Lønning, 2006). 1 Google Translate, 08/31/2012 1360 Anna fehlt ihrem Kater patient instance MISS instance agent CAT owner ANNA instance Anna’s cat is missing her Figure 1: A string to meaning graph to string translation pipeline. Experimental results demonstrate that our system is capable of learning semantic abstractions, and more specifically, to both analyse text into these abstractions and decode them back into text in multiple languages. The need to manipulate graph structures adds an additional level of complexity to the standard MT task. While the problems of parsing and rule-extraction are well-stud"
C12-1083,J05-1004,0,0.0147987,"e, and decoding from meaning in the target language. Our system assumes that meaning representations are directed acyclic graphs; beyond that, it is completely agnostic with respect to the details of the formalism, including the inventory of node and edge labels used. Figure 1 illustrates a pipeline via one possible graph as semantic pivot. The proposed framework is flexible enough to handle numerous existing meaning representations, including the programming language syntax of the GEOQUERY corpus (Wong and Mooney, 2006) (used for the experiments in this paper), the PropBank-style structures (Palmer et al., 2005) used for the CoNLL shared task on recognizing semantic dependencies (Hajiˇc et al., 2009), and the Elementary Dependency Structures of the LOGON corpus (Oepen and Lønning, 2006). 1 Google Translate, 08/31/2012 1360 Anna fehlt ihrem Kater patient instance MISS instance agent CAT owner ANNA instance Anna’s cat is missing her Figure 1: A string to meaning graph to string translation pipeline. Experimental results demonstrate that our system is capable of learning semantic abstractions, and more specifically, to both analyse text into these abstractions and decode them back into text in multiple"
C12-1083,P02-1040,0,0.0925377,"lead to improved analysis, and in accordance with our expectations the syntactically-guided DD alignments appear to help SYNSEM but not CANSEM. CANSEM EN ZH SYNSEM M4 DD GOLD M4 DD GOLD 67.9 67.8 56.4 – 72.4 – 81.5 76.8 81.8 – 84.4 – Table 2: Evaluation of analysis ( f1 ), vs. gold MRs in development set CANSEM EN ZH SYNSEM M4 DD GOLD M4 DD GOLD 51.89 50.28 48.82 – 55.24 – 52.47 45.82 42.91 – 53.3 – Table 3: Evaluation of generation (BLEU), vs. gold strings in development set 1368 5.4 Generation: Graph to String We evaluate text generated from gold MR graphs using the well-known BLEU measure (Papineni et al., 2002). Table 3 shows results for English (EN) and Chinese (ZH), varying rule extraction and alignment model as before. As before, M4 alignments help CANSEM more than DD alignments; however, here the trend also carries through to SYNSEM. Also in contrast to the analysis results, the two systems perform comparably on their best English results, and CANSEM outperforms SYNSEM on Chinese. While not targeted directly at the generation task (and not comparable to the existing literature, which reports BLEU scores on the test set), these results are promising: They are close to state-of-the-art for generat"
C12-1083,W12-4209,1,0.812969,"nence in NLP (Knight and May, 2009; Graehl and Knight, 2004). In contrast, little work has been done on methods for graphs in NLP. The standard model for graphshaped meaning representations in NLP are feature structures, which can be constructed from strings using unification grammars (Moore, 1989). However, while powerful in representation, unification grammars have unfavorable algorithmic properties, lack an intuitive probabilistic extension, and require hand-built rules. Other formal devices to accept and transduce feature structure graphs have rarely been discussed. Notable exceptions are Quernheim and Knight (2012) who discuss formal devices to accept and transduce feature structure graphs, and Bohnet and Wanner (2010) who present a toolkit for manually engineering graph-to-string transducer rules for natural language generation. We believe that we are the first to use hyperedge replacement grammars in the NLP literature and can only refer to the formal HRG survey by (Drewes et al., 1997). 1371 7 Conclusion We have introduced a new model for semantically-driven statistical machine translation using graph-structured meaning representations. Our approach is based on the class of weighted synchronous hyper"
C12-1083,J10-4005,0,0.0155767,"often struggle to generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confronted with verbs that realize their arguments differently. A system using an intermediate meaning re"
C12-1083,W04-3312,0,0.0300877,"arse into lambda expressions, and Ge and Mooney (2005) integrate syntactic parsing with semantic parsing for recovering Prolog queries. Lu et al. (2008) learn a generative model over tree shaped meaning representation and natural language sentences. Wong and Mooney (2006)’s WASP system is similar to ours because it draws on techniques from SMT, using word alignment algorithms to learn synchronous CFGs which translate between syntax and semantics. In fact, Jones et al. (2012) recasts many semantic parsing approaches as tree transduction, which is closely related to synchronous grammar parsing (Shieber, 2004). To our knowledge we are the first to address semantic parsing into graph-based representations as a learning task using synchronous graph grammars. In generation, learning the parameters of statistical generation models is popular, but not much attention has been paid to the scenario where no handwritten rules exist or the mapping between semantic structure and output language is unknown in the training data (the scenario we assume in this paper). The WASP system (Wong and Mooney, 2006) can also be used as a generator. Lu and Ng (2011) automatically learn to generate English and Chinese from"
C12-1083,1987.mtsummit-1.10,0,0.917372,"approach is based on (Galley et al., 2004, 2006). However, we induce synchronous graph grammars between surface form and meaning representation, instead of transfer rules between source and target form. As with other translation work using synchronous tree grammars, such as synchronous TSG (Chiang, 2010) and synchronous TAG (DeNeefe and 1370 Knight, 2009), our SHRGs can also be applied in both directions. However, none of these SMT approaches use an intermediate semantic representation. A lot of research has been done in the early days of MT on translation systems using such representations (Uchida, 1987; Nirenburg, 1989; Landsbergen, 1989). These systems usually required hand-crafted rules and large knowledge bases and do not learn translation models from data automatically. Until recently, because of their good performance especially in narrow domains, rule-based MT was the predominant paradigm in deployed MT systems. In contrast, while our system adopts a semantic transfer based paradigm, we learn weighted transfer rules into and from the meaning representation automatically to build a true statistical semanticsbased MT system. In the semantic parsing literature, there are other learning b"
C12-1083,N01-1001,0,0.0266115,"ing into graph-based representations as a learning task using synchronous graph grammars. In generation, learning the parameters of statistical generation models is popular, but not much attention has been paid to the scenario where no handwritten rules exist or the mapping between semantic structure and output language is unknown in the training data (the scenario we assume in this paper). The WASP system (Wong and Mooney, 2006) can also be used as a generator. Lu and Ng (2011) automatically learn to generate English and Chinese from sentences paired with lambda calculus. Other examples are (Varges and Mellish, 2001) who learn a semantic grammar form a semantically annotated treebank automatically, and (DeVault et al., 2008) who infer a TAG for generation automatically from semantically annotated example sentences. Formal language approaches to probabilistic tree transformation are popular (e.g. in syntaxbased MT) and recently a formulation of such methods as tree transducers (Comon et al., 2007) has gained prominence in NLP (Knight and May, 2009; Graehl and Knight, 2004). In contrast, little work has been done on methods for graphs in NLP. The standard model for graphshaped meaning representations in NLP"
C12-1083,W06-3119,0,0.00997337,"rlying assumption that surface phrases can be translated without reference to syntax or meaning. Such systems often struggle to generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confron"
C12-1083,J82-2005,0,0.816934,"gen Struktur und mit einer sprachneutralen Struktur. Unsere Arbeit zeigt dass semantikbasierte maschinelle Übersetzung vielversprechend ist. ∗ The authors contributed equally to this work and are listed in randomized order. Proceedings of COLING 2012: Technical Papers, pages 1359–1376, COLING 2012, Mumbai, December 2012. 1359 1 Introduction In this paper, we introduce a model for semantic machine translation using a graph-structured meaning representation. While it has been claimed since the inception of machine translation that a semantic model is necessary to achieve human-like translation (Weaver, 1955; Bar-Hillel, 1960), most recent work in MT has instead focused on phrase-based approaches. Statistical phrase-based systems rely on large volumes of parallel training data to learn translation probabilities across two languages; while, given sufficient data, phrase-based systems can cope with some of the ambiguity problems identified by early MT researchers, they are limited by the underlying assumption that surface phrases can be translated without reference to syntax or meaning. Such systems often struggle to generate correct translations that involve non-local phenomena such as argument re"
C12-1083,N06-1056,0,0.249012,"tion system which treats MT as a two-step process of analysis into meaning in the source language, and decoding from meaning in the target language. Our system assumes that meaning representations are directed acyclic graphs; beyond that, it is completely agnostic with respect to the details of the formalism, including the inventory of node and edge labels used. Figure 1 illustrates a pipeline via one possible graph as semantic pivot. The proposed framework is flexible enough to handle numerous existing meaning representations, including the programming language syntax of the GEOQUERY corpus (Wong and Mooney, 2006) (used for the experiments in this paper), the PropBank-style structures (Palmer et al., 2005) used for the CoNLL shared task on recognizing semantic dependencies (Hajiˇc et al., 2009), and the Elementary Dependency Structures of the LOGON corpus (Oepen and Lønning, 2006). 1 Google Translate, 08/31/2012 1360 Anna fehlt ihrem Kater patient instance MISS instance agent CAT owner ANNA instance Anna’s cat is missing her Figure 1: A string to meaning graph to string translation pipeline. Experimental results demonstrate that our system is capable of learning semantic abstractions, and more specific"
C12-1083,P01-1067,1,0.340912,"y are limited by the underlying assumption that surface phrases can be translated without reference to syntax or meaning. Such systems often struggle to generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”)"
C12-1083,C08-1144,0,0.0186118,"reference to syntax or meaning. Such systems often struggle to generate correct translations that involve non-local phenomena such as argument reorderings across languages, deep embeddings, empty categories and anaphora. With the increasing availability of syntactically-annotated data in many languages, it has become possible to more directly integrate syntax into data-driven approaches. Such syntax-based SMT systems can automatically extract larger rules, and learn syntactic reorderings for translation (Yamada and Knight, 2001; Venugopal and Zollmann, 2006; Galley et al., 2004; Chiang, 2007; Zollmann et al., 2008; DeNero et al., 2009; Shen et al., 2010; Genzel, 2010). However, many problems remain unsolved. For illustration of a specific phenomenon difficult to capture without an intermediate meaning representation, consider the following translation example using a state-of-the-art German→English SMT system 1 : Source Anna fehlt ihrem Kater System output *Anna is missing her cat Reference Anna’s cat is missing her SMT systems are frequently unable to preserve basic meaning structures (e.g. “who does what to whom”) across languages when confronted with verbs that realize their arguments differently. A"
C12-1083,J08-3004,1,\N,Missing
C12-1083,P13-2131,1,\N,Missing
C12-1083,J07-2003,0,\N,Missing
D15-1138,W14-1607,1,0.909453,"ossible to behave correctly in environments containing novel strings or other features unseen during training. This aspect of the syntax–semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al., 2013), the relationship between text and the environment has ultimately been mediated by a discrete (and indeed finite) inventory of predicates. Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds. Formally, we assume access to a joining feature function φ : (2L × 2L ) → Rd . As with grounding graphs, our goal is to make the general framework as flexible as possible, and for individual experiments have chosen φ to emulate modeling decisions from previous work. 1168 4 Then we have2 Model As noted in the introduction, we approach instruction following as a sequence prediction problem. Thus we must place a distribution over sequences of acti"
D15-1138,Q13-1005,0,0.480505,"eld, with alignment potentials to relate instructions to actions and transition potentials to encode the environment model (Figure 3). Explicitly modeling sequenceto-sequence alignments between text and actions allows flexible reasoning about action sequences, enabling the agent to determine which actions are specified (perhaps redundantly) by text, and which actions must be performed automatically (in order to satisfy pragmatic constraints on interpretation). Treating instruction following as a sequence prediction problem, rather than a series of independent decisions (Branavan et al., 2009; Artzi and Zettlemoyer, 2013), makes it possible to use general-purpose planning machinery, greatly increasing inferential power. The fragment of semantics necessary to complete most instruction-following tasks is essentially predicate–argument structure, with limited influence from quantification and scoping. Thus the problem of sentence interpretation can reasonably be modeled as one of finding an alignment between language and the environment it describes. We allow this structure-to-structure alignment— an “overlay” of language onto the world—to be mediated by linguistic structure (in the form of dependency parses) and"
D15-1138,D14-1134,0,0.5413,"Missing"
D15-1138,P14-1133,0,0.0173303,"must eventually combine features provided by parse trees with features provided by the environment. Examples here might include simple conjunctions (word=yellow ∧ rgb=(0.5, 0.5, 0.0)) or more complicated computations like edit distance between landmark names and lexical items. Features of the latter kind make it possible to behave correctly in environments containing novel strings or other features unseen during training. This aspect of the syntax–semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al., 2013), the relationship between text and the environment has ultimately been mediated by a discrete (and indeed finite) inventory of predicates. Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds. Formally, we assume access to a joining feature function φ : (2L × 2L ) → Rd . As with grounding graphs, our goal is to make the gene"
D15-1138,P09-1010,0,0.187612,"d conditional random field, with alignment potentials to relate instructions to actions and transition potentials to encode the environment model (Figure 3). Explicitly modeling sequenceto-sequence alignments between text and actions allows flexible reasoning about action sequences, enabling the agent to determine which actions are specified (perhaps redundantly) by text, and which actions must be performed automatically (in order to satisfy pragmatic constraints on interpretation). Treating instruction following as a sequence prediction problem, rather than a series of independent decisions (Branavan et al., 2009; Artzi and Zettlemoyer, 2013), makes it possible to use general-purpose planning machinery, greatly increasing inferential power. The fragment of semantics necessary to complete most instruction-following tasks is essentially predicate–argument structure, with limited influence from quantification and scoping. Thus the problem of sentence interpretation can reasonably be modeled as one of finding an alignment between language and the environment it describes. We allow this structure-to-structure alignment— an “overlay” of language onto the world—to be mediated by linguistic structure (in the"
D15-1138,P11-1028,0,0.0526053,"o model compositionality in language or actions. Agents in this family have been evaluated on a variety of tasks, including map reading (Anderson et al., 1991) and gameplay (Branavan et al., 2009). Though both families address the same class of instruction-following problems, they have been applied to a totally disjoint set of tasks. It should be emphasized that there is nothing inherent to policy learning that prevents the use of compositional structure, and nothing inherent to general compositional models that prevents more complicated dependence on environment state. Indeed, previous work (Branavan et al., 2011; Narasimhan et al., 2015) uses aspects of both to solve a different class of gameplay problems. In some sense, our goal in this paper is simply to combine the strengths of semantic parsers and linear policy estimators for fully general instruction following. As we shall see, however, this requires changes to many aspects of representation, learning and inference. 3 Representations We wish to train a model capable of following commands in a simulated environment. We do so by presenting the model with a sequence of training pairs (x, y), where each x is a sequence of natural language instructio"
D15-1138,J93-2003,0,0.0744857,"(2) provides context-dependent interpretation of text by means of the structured scoring function ψ(x, y; θ), described in the next section. Formally, we associate with each instruction xi a sequence-to-sequence alignment variable ai ∈ 1 . . . n (recalling that n is the number of actions).  n X p(y,a|x; θ) ∝ exp ψ(n) + ψ(yj ) j=1 + m X n X 1[aj = i] ψ(xi , yj )  (1) i=1 j=1 We additionally place a monotonicity constraint on the alignment variables. This model is globally normalized, and for a fixed alignment is equivalent to a linear-chain CRF. In this sense it is analogous to IBM Model I (Brown et al., 1993), with the structured potentials ψ(xi , yj ) taking the place of lexical translation probabilities. While alignment models from machine translation have previously been used to align words to fragments of semantic parses (Wong and Mooney, 2006; Pourdamghani et al., 2014), we are unaware of such models being used to align entire instruction sequences to demonstrations. Action structure: aligning words to percepts Intuitively, this scoring function ψ(x, y) should capture how well a given utterance describes an action. If neither the utterances nor the actions had structure (i.e. both could be re"
D15-1138,P12-1045,0,0.0229318,"Missing"
D15-1138,C12-1083,1,0.357068,"Missing"
D15-1138,D12-1040,0,0.0864582,"Missing"
D15-1138,Q14-1042,0,0.00563031,"e family of approaches is based on learning a policy over primitive actions directly (Branavan et al., 2009; Vogel and Jurafsky, 2010).1 Policybased approaches instantiate a Markov decision process representing the action domain, and apply standard supervised or reinforcement-learning approaches to learn a function for greedily selecting among actions. In linear policy approximators, natural language instructions are incorporated directly into state observations, and reading order 1 This is distinct from semantic parsers in which greedy inference happens to have an interpretation as a policy (Vlachos and Clark, 2014). 1166 becomes part of the action selection process. Almost all existing policy-learning approaches make use of an unstructured parameterization, with a single (flat) feature vector representing all text and observations. Such approaches are thus restricted to problems that are simple enough (and have small enough action spaces) to be effectively characterized in this fashion. While there is a great deal of flexibility in the choice of feature function (which is free to inspect the current and future state of the environment, the whole instruction sequence, etc.), standard linear policy estima"
D15-1138,P10-1083,0,0.231116,"ic formal language for describing agent behavior. Thus it is extremely difficult to work with environments that cannot be modeled with a fixed inventory of predicates (e.g. those involving novel strings or arbitrary real quantities). Much of contemporary work in this family is evaluated on the maze navigation task introduced by MacMahon et al. (2006). Dukes (2013) also introduced a “blocks world” task for situated parsing of spatial robot commands. Linear policy estimators An alternative family of approaches is based on learning a policy over primitive actions directly (Branavan et al., 2009; Vogel and Jurafsky, 2010).1 Policybased approaches instantiate a Markov decision process representing the action domain, and apply standard supervised or reinforcement-learning approaches to learn a function for greedily selecting among actions. In linear policy approximators, natural language instructions are incorporated directly into state observations, and reading order 1 This is distinct from semantic parsers in which greedy inference happens to have an interpretation as a policy (Vlachos and Clark, 2014). 1166 becomes part of the action selection process. Almost all existing policy-learning approaches make use o"
D15-1138,P13-1022,0,0.0489834,"g in a variety of sophisticated approaches. Despite superficial similarity to the previous navigation task, the language and plans required for this task are quite different. The proportion of instructions to actions is much higher (so redundancy much lower), and the interpretation of language is highly compositional. As can be seen in Table 3, we outperform a number of systems purpose-built for this navigation task. We also outperform both variants of our system, most conspicuously the variant without grounding graphs. This highlights the importance of compositional structure. Recent work by Kim and Mooney (2013) and Artzi et al. (2014) has achieved better results; these systems make use of techniques and resources (respectively, discriminative reranking and a seed lexicon of handannotated logical forms) that are largely orthogonal to the ones used here, and might be applied to improve our own results as well. Puzzle solving The last task we consider is the Crossblock task studied by Branavan et al. (2009) (Figure 1c). Here, again, natural language is used to specify a sequence of actions, in this case the solution to a simple game. The environment is simple enough to be captured with a flat feature 4"
D15-1138,N06-1056,0,0.0330591,"ate the importance of our contributions in both compositional semantics and search over plans. We have released all code for this project at github.com/jacobandreas/instructions. 2 Related work Existing work on instruction following can be roughly divided into two families: semantic parsers and linear policy estimators. Semantic parsers Parser-based approaches (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013; Kim and Mooney, 2013) map from text into a formal language representing commands. These take familiar structured prediction models for semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2006), and train them with task-provided supervision. Instead of attempting to match the structure of a manually-annotated semantic parse, semantic parsers for instruction following are trained to maximize a reward signal provided by black-box execution of the predicted command in the environment. (It is possible to think of response-based learning for question answering (Liang et al., 2013) as a special case.) This approach uses a well-studied mechanism for compositional interpretation of language, but is subject to certain limitations. Because the environment is manipulated only through black-box"
D15-1138,D13-1161,0,0.0201035,"with features provided by the environment. Examples here might include simple conjunctions (word=yellow ∧ rgb=(0.5, 0.5, 0.0)) or more complicated computations like edit distance between landmark names and lexical items. Features of the latter kind make it possible to behave correctly in environments containing novel strings or other features unseen during training. This aspect of the syntax–semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al., 2013), the relationship between text and the environment has ultimately been mediated by a discrete (and indeed finite) inventory of predicates. Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds. Formally, we assume access to a joining feature function φ : (2L × 2L ) → Rd . As with grounding graphs, our goal is to make the general framework as flexible as possible, and for individual"
D15-1138,J13-2005,1,0.400173,"and Zettlemoyer, 2013; Kim and Mooney, 2013) map from text into a formal language representing commands. These take familiar structured prediction models for semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2006), and train them with task-provided supervision. Instead of attempting to match the structure of a manually-annotated semantic parse, semantic parsers for instruction following are trained to maximize a reward signal provided by black-box execution of the predicted command in the environment. (It is possible to think of response-based learning for question answering (Liang et al., 2013) as a special case.) This approach uses a well-studied mechanism for compositional interpretation of language, but is subject to certain limitations. Because the environment is manipulated only through black-box execution of the completed semantic parse, there is no way to incorporate current or future environment state into the scoring function. It is also in general necessary to hand-engineer a task-specific formal language for describing agent behavior. Thus it is extremely difficult to work with environments that cannot be modeled with a fixed inventory of predicates (e.g. those involving"
D15-1138,Q15-1008,0,0.0207009,"ly in environments containing novel strings or other features unseen during training. This aspect of the syntax–semantics interface has been troublesome for some logic-based approaches: while past work has used related machinery for selecting lexicon entries (Berant and Liang, 2014) or for rewriting logical forms (Kwiatkowski et al., 2013), the relationship between text and the environment has ultimately been mediated by a discrete (and indeed finite) inventory of predicates. Several recent papers have investigated simple grounded models with realvalued output spaces (Andreas and Klein, 2014; McMahan and Stone, 2015), but we are unaware of any fully compositional system in recent literature that can incorporate observations of these kinds. Formally, we assume access to a joining feature function φ : (2L × 2L ) → Rd . As with grounding graphs, our goal is to make the general framework as flexible as possible, and for individual experiments have chosen φ to emulate modeling decisions from previous work. 1168 4 Then we have2 Model As noted in the introduction, we approach instruction following as a sequence prediction problem. Thus we must place a distribution over sequences of actions conditioned on instruc"
D15-1138,D15-1001,0,0.0047215,"y in language or actions. Agents in this family have been evaluated on a variety of tasks, including map reading (Anderson et al., 1991) and gameplay (Branavan et al., 2009). Though both families address the same class of instruction-following problems, they have been applied to a totally disjoint set of tasks. It should be emphasized that there is nothing inherent to policy learning that prevents the use of compositional structure, and nothing inherent to general compositional models that prevents more complicated dependence on environment state. Indeed, previous work (Branavan et al., 2011; Narasimhan et al., 2015) uses aspects of both to solve a different class of gameplay problems. In some sense, our goal in this paper is simply to combine the strengths of semantic parsers and linear policy estimators for fully general instruction following. As we shall see, however, this requires changes to many aspects of representation, learning and inference. 3 Representations We wish to train a model capable of following commands in a simulated environment. We do so by presenting the model with a sequence of training pairs (x, y), where each x is a sequence of natural language instructions (x1 , x2 , . . . , xm )"
D15-1138,P15-1142,0,0.0182281,"ingle (structured) random variable. However, the two kinds of alignments are treated differently for purposes of inference, so it is useful to maintain a notational distinction. 1169 and that each lexical item is associated with a small set of functional forms. Here we simply allow all words to license all predicates, multiple words to specify the same predicate, and some edges to be skipped. We instead rely on a scoring function to impose soft versions of the hard constraints typically provided by a grammar. Related models have previously been used for question answering (Reddy et al., 2014; Pasupat and Liang, 2015). For the moment let us introduce variables b to denote these structure-to-structure alignments. (As will be seen in the following section, it is straightforward to marginalize over all choices of b. Thus the structure-to-structure alignments are never explicitly instantiated during inference, and do not appear in the final form of ψ(x, y).) For a fixed alignment, we define ψ(x, y, b) according to a recurrence relation. Let xi be the ith word of the sentence, and let y j be the jth node in the action graph (under some topological ordering). Let c(i) and c(j) give the indices of the dependents"
D15-1138,D14-1048,0,0.0349502,"al or simulated environment, in response to a sequence of natural language commands. Examples include giving navigational directions to robots and providing hints to automated game-playing agents. Plans specified with natural language exhibit compositionality both at the level of individual actions and at the overall sequence level. This paper describes a framework for learning to follow instructions by leveraging structure at both levels. Our primary contribution is a new, alignmentbased approach to grounded compositional semantics. Building on related logical approaches (Reddy et al., 2014; Pourdamghani et al., 2014), we recast instruction following as a pair of nested, structured alignment problems. Given instructions and a candidate plan, the model infers a sequenceto-sequence alignment between sentences and atomic actions. Within each sentence–action pair, the model infers a structure-to-structure alignment between the syntax of the sentence and a graphbased representation of the action. At a high level, our agent is a block-structured, graph-valued conditional random field, with alignment potentials to relate instructions to actions and transition potentials to encode the environment model (Figure 3)."
D15-1138,Q14-1030,0,0.0921343,"e of actions in a real or simulated environment, in response to a sequence of natural language commands. Examples include giving navigational directions to robots and providing hints to automated game-playing agents. Plans specified with natural language exhibit compositionality both at the level of individual actions and at the overall sequence level. This paper describes a framework for learning to follow instructions by leveraging structure at both levels. Our primary contribution is a new, alignmentbased approach to grounded compositional semantics. Building on related logical approaches (Reddy et al., 2014; Pourdamghani et al., 2014), we recast instruction following as a pair of nested, structured alignment problems. Given instructions and a candidate plan, the model infers a sequenceto-sequence alignment between sentences and atomic actions. Within each sentence–action pair, the model infers a structure-to-structure alignment between the syntax of the sentence and a graphbased representation of the action. At a high level, our agent is a block-structured, graph-valued conditional random field, with alignment potentials to relate instructions to actions and transition potentials to encode the e"
D15-1138,P11-1060,1,\N,Missing
D16-1125,W09-3704,0,0.0144615,"014). In order for the players to win, S’s description d must be pragmatic: it must be informative, fluent, concise, and must ultimately encode an understanding of L’s behavior. In Figure 1, for example, the owl is wearing a hat and the owl is sitting in the tree are both accurate descriptions of the target image, but only the second allows a human listener to succeed with high probability. RG is the focus of many papers in the computational pragmatics literature: it provides a concrete generation task while eliciting a broad range of pragmatic behaviors, including conversational implicature (Benotti and Traum, 2009) and context dependence (Smith et al., 2013). Existing computational models of pragmatics can be divided into two broad lines of work, which we term the direct and derived approaches. Direct models (see Section 2 for examples) are based on a representation of S. They learn pragmatic behavior by example. Beginning with datasets annotated for the specific task they are trying to 1173 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1173–1182, c Austin, Texas, November 1-5, 2016. 2016 Association for Computational Linguistics solve (e.g. examples of hu"
D16-1125,D13-1197,0,0.0530538,"Missing"
D16-1125,W07-2307,0,0.0344898,"Missing"
D16-1125,D10-1040,1,0.785838,"(2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks. Given a set of blocks to describe, their model directly learns a maximumentropy distribution over the set of logical expressions whose denotation is the target set. Other research, focused on referring expression generation from a computer vision perspective, includes that of Mao et al. (2015) and Kazemzadeh et al. (2014). Derived pragmatics Derived approaches, sometimes referred to as “rational speech acts” models, include those of Smith et al. (2013), Vogel et al. (2013), Golland et al. (2010), and Monroe and Potts (2015). These couple template-driven language generation with probabilistic or game-theoretic reasoning frameworks to produce contextually appropriate language: intelligent listeners reason about the behavior of reflexive speakers, and even higher-order speakers reason about these listeners. Experiments (Frank et al., 2009) show that derived approaches explain human behavior well, but both computational and representational issues restrict their application to simple reference games. They require domainspecific engineering, controlled world representations, and pragmatic"
D16-1125,D14-1086,0,0.0586745,", and between computational efficiency and expressive power.1 2 Related Work Direct pragmatics As an example of the direct approach mentioned in the introduction, FitzGerald et al. (2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks. Given a set of blocks to describe, their model directly learns a maximumentropy distribution over the set of logical expressions whose denotation is the target set. Other research, focused on referring expression generation from a computer vision perspective, includes that of Mao et al. (2015) and Kazemzadeh et al. (2014). Derived pragmatics Derived approaches, sometimes referred to as “rational speech acts” models, include those of Smith et al. (2013), Vogel et al. (2013), Golland et al. (2010), and Monroe and Potts (2015). These couple template-driven language generation with probabilistic or game-theoretic reasoning frameworks to produce contextually appropriate language: intelligent listeners reason about the behavior of reflexive speakers, and even higher-order speakers reason about these listeners. Experiments (Frank et al., 2009) show that derived approaches explain human behavior well, but both computa"
D16-1125,N15-1174,0,0.0195886,"Missing"
D16-1125,P05-1044,0,0.0212148,"owing optimization problem: max W X j log pL0 (1|dj , rj , r0 ) (5) Here r0 is a random distractor chosen uniformly from the training set. For each training example (ri , di ), this objective attempts to maximize the probability that the model chooses ri as the referent of di over a random distractor. This contrastive objective ensures that our approach is applicable even when there is not a naturally-occurring source of target–distractor pairs, as previous work (Golland et al., 2010; Monroe and Potts, 2015) has required. Note that this can also be viewed as a version of the loss described by Smith and Eisner (2005), where it approximates a likelihood objective that encourages L0 to prefer ri to every other possible referent simultaneously. Literal speaker As in the figure, the literal speaker is obtained by composing a referent encoder with a describer, as follows: e = Er (f (r)) pS0 (d|r) = Dd (d|e) As with the listener, the literal speaker should be understood as producing a distribution over strings. It is trained by maximizing the conditional likelihood of captions in the training data: X max log pS0 (di |ri ) (6) W i These base models are intended to be the minimal learned equivalents of the hand-e"
D16-1125,Q14-1017,0,0.0181275,"ding instruction following (Anderson et al., 1991) and discourse analysis (Jurafsky et al., 1997). 1 Models, human annotations, and code to generate all tables and figures in this paper can be found at http://github. com/jacobandreas/pragma. Representing language and the world In addition to the pragmatics literature, the approach proposed in this paper relies extensively on recently developed tools for multimodal processing of language and unstructured representations like images. These includes both image retrieval models, which select an image from a collection given a textual description (Socher et al., 2014), and neural conditional language models, which take a content representation and emit a string (Donahue et al., 2015). ref features FC desc desc Sum ReLU FC Softmax choice referent sentence (c) choice ranker R wordn Approach FC ReLU FC Softmax wordn+1 referent Our goal is to produce a model that can play the role of the speaker S in RG. Specifically, given a target referent (e.g. scene or object) r and a distractor r0 , the model must produce a description d that uniquely identifies r. For training, we have access to a set of non-contrastively captioned referents {(ri , di )}: each training d"
D16-1125,N13-1127,0,0.233778,"on, FitzGerald et al. (2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks. Given a set of blocks to describe, their model directly learns a maximumentropy distribution over the set of logical expressions whose denotation is the target set. Other research, focused on referring expression generation from a computer vision perspective, includes that of Mao et al. (2015) and Kazemzadeh et al. (2014). Derived pragmatics Derived approaches, sometimes referred to as “rational speech acts” models, include those of Smith et al. (2013), Vogel et al. (2013), Golland et al. (2010), and Monroe and Potts (2015). These couple template-driven language generation with probabilistic or game-theoretic reasoning frameworks to produce contextually appropriate language: intelligent listeners reason about the behavior of reflexive speakers, and even higher-order speakers reason about these listeners. Experiments (Frank et al., 2009) show that derived approaches explain human behavior well, but both computational and representational issues restrict their application to simple reference games. They require domainspecific engineering, controlled world represe"
D17-1311,D13-1197,0,0.0477602,"Missing"
D17-1311,W14-1618,0,0.0389403,"lable at http://github. com/jacobandreas/rnn-syn. One of the distinguishing features of natural language is compositionality: the existence of operations like negation and coordination that can be applied to utterances with predictable effects on meaning. RNN models trained for natural language processing tasks have been found to learn representations that encode some of this compositional structure—for example, sentence representations for machine translation encode explicit features for certain syntactic phenomena (Shi et al., 2016) and represent some semantic relationships translationally (Levy et al., 2014). It is thus natural to ask whether these “language-like” structures also arise spontaneously in models trained directly from an environment signal. Rather than using language as a form of supervision, we propose to use it as a probe—exploiting post-hoc statistical correspondences between natural language descriptions and neural encodings to discover regular structure in representation space. To do this, we need to find (vector, string) pairs with matching semantics, which requires first aligning unpaired examples of human–human 2893 Proceedings of the 2017 Conference on Empirical Methods in N"
D17-1311,D16-1159,0,0.020168,"2017), even without natural language training data. 1 Code and data are available at http://github. com/jacobandreas/rnn-syn. One of the distinguishing features of natural language is compositionality: the existence of operations like negation and coordination that can be applied to utterances with predictable effects on meaning. RNN models trained for natural language processing tasks have been found to learn representations that encode some of this compositional structure—for example, sentence representations for machine translation encode explicit features for certain syntactic phenomena (Shi et al., 2016) and represent some semantic relationships translationally (Levy et al., 2014). It is thus natural to ask whether these “language-like” structures also arise spontaneously in models trained directly from an environment signal. Rather than using language as a form of supervision, we propose to use it as a probe—exploiting post-hoc statistical correspondences between natural language descriptions and neural encodings to discover regular structure in representation space. To do this, we need to find (vector, string) pairs with matching semantics, which requires first aligning unpaired examples of"
D17-1311,P17-1022,1,0.76693,"ze classification accuracy on randomly-generated scenes and target sets of the same form as in the G EN X dataset. 3 Approach We are not concerned with the RNN model’s raw performance on this task (it achieves nearly perfect accuracy). Instead, our goal is to explore what kinds of messages the model computes in order to achieve this accuracy—and specifically whether these messages contain high-level semantics and low-level structure similar to the referring expressions produced by humans. But how do we judge semantic equivalence between natural language and vector representations? Here, as in Andreas et al. (2017), we adopt an approach inspired by formal semantics, and represent the meaning of messages via their truth conditions (Figure 1). For every problem instance W in the dataset, we have access to one or more human messages e(W ) as well as the RNN encoding f (W ). The truth-conditional account of meaning suggests that we should judge e and f to be equivalent if they designate the same set of of objects in the world (Davidson, 1967). But it is not enough to compare their predictions solely in the context where they were generated—testing if JeKW = Jf KW — because any pair of models that achieve pe"
D17-1311,D14-1067,0,0.0246126,"ior essentially random.) Conversely, if there is a first-class notion of negation, we should be able to select an arbitrary representation vector f with an associated referring expression e, apply some transformation N to f , and be able to predict a priori how the decoder model will interpret the representation N f —i.e. in correspondence with ¬e. Here we make the strong assumption that the negation operation is not only predictable but linear. Previous work has found that linear operators are powerful enough to capture many hierarchical and relational structures (Paccanaro and Hinton, 2002; Bordes et al., 2014). Using examples (f, f 0 ) collected from the training set as described above, we compute P the least-squares ˆ estimate N = arg minN ||N f − f 0 ||22 . To evaluate, we collect example representations from the test set that are equivalent to known logical forms, and measure how frequently model behaviors rep(N f ) agree with the logical predictions x.red(x) x.red(x) x.blue(x) 2 x.red(x) 1 (b) blue(x) x.blue(x) yellow(x) 0 1 x.red(x) yellow(x) 2 3 x.yellow(x) 4 3 2 1 0 1 2 3 4 Figure 3: Principal components of structured message transformations discovered by our experiments. (a) Negation: black"
D17-1311,W14-4012,0,0.100823,"Missing"
N15-1027,P14-1129,0,0.0587568,"ving model quality. 1 Introduction This paper investigates the theoretical properties of log-linear models trained to make their unnormalized scores approximately sum to one. Recent years have seen a resurgence of interest in log-linear approaches to language modeling. This includes both conventional log-linear models (Rosenfeld, 1994; Biadsy et al., 2014) and neural networks with a log-linear output layer (Bengio et al., 2006). On a variety of tasks, these LMs have produced substantial gains over conventional generative models based on counting n-grams. Successes include machine translation (Devlin et al., 2014) and speech recognition (Graves et al., 2013). However, log-linear LMs come at a significant cost for computational efficiency. In order to output a well-formed probability distribution over words, such models must typically calculate a normalizing constant whose computational cost grows linearly in the size of the vocabulary. Fortunately, many applications of LMs remain well-behaved even if LM scores do not actually correspond to probability distributions. For example, if a machine translation decoder uses output from a pre-trained LM as a feature inside a larger model, it suffices to have al"
N15-1027,D13-1140,0,0.0241032,"main well-behaved even if LM scores do not actually correspond to probability distributions. For example, if a machine translation decoder uses output from a pre-trained LM as a feature inside a larger model, it suffices to have all output scores on approximately the same scale, even if these do not sum to one for every LM context. There has thus been considerable research interest around training procedures capable of ensuring that unnormalized outputs for every context are “close” to a probability distribution. We are aware of at least two such techniques: noisecontrastive estimation (NCE) (Vaswani et al., 2013; Gutmann and Hyv¨arinen, 2010) and explicit penalization of the log-normalizer (Devlin et al., 2014). Both approaches have advantages and disadvantages. NCE allows fast training by dispensing with the need to ever compute a normalizer. Explicit penalization requires full normalizers to be computed during training but parameterizes the relative importance of the likelihood and the “sum-to-one” constraint, allowing system designers to tune the objective for optimal performance. While both NCE and explicit penalization are observed to work in practice, their theoretical properties have not been"
N16-1181,P13-2009,1,0.563292,"okup[Georgia])) In this paper, we present a model for learning to select such structures from a set of automatically generated candidates. We call this model a dynamic neural module network. 2 But note that unlike formal semantics, the behavior of the primitive functions here is itself unknown. 3 Related work There is an extensive literature on database question answering, in which strings are mapped to logical forms, then evaluated by a black-box execution model to produce answers. Supervision may be provided either by annotated logical forms (Wong and Mooney, 2007; Kwiatkowski et al., 2010; Andreas et al., 2013) or from (world, question, answer) triples alone (Liang et al., 2011; Pasupat and Liang, 2015). In general the set of primitive functions from which these logical forms can be assembled is fixed, but one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a differentiable execution model w"
N16-1181,P14-1133,0,0.0158203,"le in each layout is a describe or exists module, the fully- instantiated network corresponds to a distribution over labels P conditioned on layouts. To train, we maximize (w,y,z) log pz (y|w; θe ) directly. This can be understood as a parameter-tying scheme, where the decisions about which parameters to tie are governed by the observed layouts z. 4.2 Assembling networks Next we describe the layout model p(z|x; θ` ). We first use a fixed syntactic parse to generate a small set of candidate layouts, analogously to the way a semantic grammar generates candidate semantic parses in previous work (Berant and Liang, 2014). A semantic parse differs from a syntactic parse in two primary ways. First, lexical items must be 1549 mapped onto a (possibly smaller) set of semantic primitives. Second, these semantic primitives must be combined into a structure that closely, but not exactly, parallels the structure provided by syntax. For example, state and province might need to be identified with the same field in a database schema, while all states have a capital might need to be identified with the correct (in situ) quantifier scope. While we cannot avoid the structure selection problem, continuous representations si"
N16-1181,D14-1067,0,0.00959861,"al features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a differentiable execution model with continuous evaluation results. Neural models for question answering are also a subject of current interest. These include approaches that model the task directly as a multiclass classification problem (Iyyer et al., 2014), models that attempt to embed questions and answers in a shared vector space (Bordes et al., 2014) and attentional models that select words from documents sources (Hermann et al., 2015). Such approaches generally require that answers can be retrieved directly based on surface linguistic features, without requiring intermediate computation. A more structured approach described by Yin et al. (2015) learns a query execution model for database tables without any natural language component. Previous efforts toward unifying formal logic and representation learning include those of Grefenstette (2013) and Krishnamurthy and Mitchell (2013). The visually-grounded component of this work relies on re"
N16-1181,W08-1301,0,0.0131897,"Missing"
N16-1181,S13-1001,0,0.0241993,"yer et al., 2014), models that attempt to embed questions and answers in a shared vector space (Bordes et al., 2014) and attentional models that select words from documents sources (Hermann et al., 2015). Such approaches generally require that answers can be retrieved directly based on surface linguistic features, without requiring intermediate computation. A more structured approach described by Yin et al. (2015) learns a query execution model for database tables without any natural language component. Previous efforts toward unifying formal logic and representation learning include those of Grefenstette (2013) and Krishnamurthy and Mitchell (2013). The visually-grounded component of this work relies on recent advances in convolutional networks for computer vision (Simonyan and Zisserman, 2014), and in particular the fact that late convolutional layers in networks trained for image recognition contain rich features useful for other downstream vision tasks, while preserving spatial information. These features have been used for both image captioning (Xu et al., 2015) and visual question answering (Yang et al., 2015). 1547 Most previous approaches to visual question answering either apply a recurrent"
N16-1181,D14-1070,0,0.0537942,"Missing"
N16-1181,Q13-1016,0,0.0265387,"ature on database question answering, in which strings are mapped to logical forms, then evaluated by a black-box execution model to produce answers. Supervision may be provided either by annotated logical forms (Wong and Mooney, 2007; Kwiatkowski et al., 2010; Andreas et al., 2013) or from (world, question, answer) triples alone (Liang et al., 2011; Pasupat and Liang, 2015). In general the set of primitive functions from which these logical forms can be assembled is fixed, but one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a differentiable execution model with continuous evaluation results. Neural models for question answering are also a subject of current interest. These include approaches that model the task directly as a multiclass classification problem (Iyyer et al., 2014), models that attempt to embed questions and answers in a shared vector space (Bordes et al., 2014) and attentional models"
N16-1181,W13-3201,0,0.0138184,"s that attempt to embed questions and answers in a shared vector space (Bordes et al., 2014) and attentional models that select words from documents sources (Hermann et al., 2015). Such approaches generally require that answers can be retrieved directly based on surface linguistic features, without requiring intermediate computation. A more structured approach described by Yin et al. (2015) learns a query execution model for database tables without any natural language component. Previous efforts toward unifying formal logic and representation learning include those of Grefenstette (2013) and Krishnamurthy and Mitchell (2013). The visually-grounded component of this work relies on recent advances in convolutional networks for computer vision (Simonyan and Zisserman, 2014), and in particular the fact that late convolutional layers in networks trained for image recognition contain rich features useful for other downstream vision tasks, while preserving spatial information. These features have been used for both image captioning (Xu et al., 2015) and visual question answering (Yang et al., 2015). 1547 Most previous approaches to visual question answering either apply a recurrent model to deep representations of both"
N16-1181,D10-1119,0,0.00620017,"find[city] (relate[in] lookup[Georgia])) In this paper, we present a model for learning to select such structures from a set of automatically generated candidates. We call this model a dynamic neural module network. 2 But note that unlike formal semantics, the behavior of the primitive functions here is itself unknown. 3 Related work There is an extensive literature on database question answering, in which strings are mapped to logical forms, then evaluated by a black-box execution model to produce answers. Supervision may be provided either by annotated logical forms (Wong and Mooney, 2007; Kwiatkowski et al., 2010; Andreas et al., 2013) or from (world, question, answer) triples alone (Liang et al., 2011; Pasupat and Liang, 2015). In general the set of primitive functions from which these logical forms can be assembled is fixed, but one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a different"
N16-1181,D13-1161,0,0.00883107,"mapped to logical forms, then evaluated by a black-box execution model to produce answers. Supervision may be provided either by annotated logical forms (Wong and Mooney, 2007; Kwiatkowski et al., 2010; Andreas et al., 2013) or from (world, question, answer) triples alone (Liang et al., 2011; Pasupat and Liang, 2015). In general the set of primitive functions from which these logical forms can be assembled is fixed, but one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a differentiable execution model with continuous evaluation results. Neural models for question answering are also a subject of current interest. These include approaches that model the task directly as a multiclass classification problem (Iyyer et al., 2014), models that attempt to embed questions and answers in a shared vector space (Bordes et al., 2014) and attentional models that select words from documents sources (Hermann et"
N16-1181,P11-1060,1,0.843642,"e 2: Simple neural module networks, corresponding to the questions What color is the bird? and Are there any states? (a) A neural find module for computing an attention over pixels. (b) The same operation applied to a knowledge base. (c) Using an attention produced by a lower module to identify the color of the region of the image attended to. (d) Performing quantification by evaluating an attention directly. works are required. Thus our goal is to automatically induce variable-free, tree-structured computation descriptors. We can use a familiar functional notation from formal semantics (e.g. Liang et al., 2011) to represent these computations.2 We write the two examples in Figure 2 as (describe[color] find[bird]) and (exists find[state]) respectively. These are network layouts: they specify a structure for arranging modules (and their lexical parameters) into a complete network. Andreas et al. (2016) use hand-written rules to deterministically transform dependency trees into layouts, and are restricted to producing simple structures like the above for non-synthetic data. For full generality, we will need to solve harder problems, like transforming What cities are in Georgia? (Figure 1) into (and fin"
N16-1181,P15-1142,0,0.0531041,"om a set of automatically generated candidates. We call this model a dynamic neural module network. 2 But note that unlike formal semantics, the behavior of the primitive functions here is itself unknown. 3 Related work There is an extensive literature on database question answering, in which strings are mapped to logical forms, then evaluated by a black-box execution model to produce answers. Supervision may be provided either by annotated logical forms (Wong and Mooney, 2007; Kwiatkowski et al., 2010; Andreas et al., 2013) or from (world, question, answer) triples alone (Liang et al., 2011; Pasupat and Liang, 2015). In general the set of primitive functions from which these logical forms can be assembled is fixed, but one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a differentiable execution model with continuous evaluation results. Neural models for question answering are also a subject of"
N16-1181,P13-1045,0,0.00900756,"015). All of these models assume that a fixed computation can be performed on the image and question to compute the answer, rather than adapting the structure of the computation to the question. As noted, Andreas et al. (2016) previously considered a simple generalization of these attentional approaches in which small variations in the network structure per-question were permitted, with the structure chosen by (deterministic) syntactic processing of questions. Other approaches in this general family include the “universal parser” sketched by Bottou (2014), and the recursive neural networks of Socher et al. (2013), which use a fixed tree structure to perform further linguistic analysis without any external world representation. We are unaware of previous work that succeeds in simultaneously learning both the parameters for and structures of instance-specific neural networks. 4 Model Recall that our goal is to map from questions and world representations to answers. This process involves the following variables: 1. 2. 3. 4. 5. w a world representation x a question y an answer z a network layout θ a collection of model parameters Our model is built around two distributions: a layout model p(z|x; θ` ) whi"
N16-1181,P07-1121,0,0.0105895,"a? (Figure 1) into (and find[city] (relate[in] lookup[Georgia])) In this paper, we present a model for learning to select such structures from a set of automatically generated candidates. We call this model a dynamic neural module network. 2 But note that unlike formal semantics, the behavior of the primitive functions here is itself unknown. 3 Related work There is an extensive literature on database question answering, in which strings are mapped to logical forms, then evaluated by a black-box execution model to produce answers. Supervision may be provided either by annotated logical forms (Wong and Mooney, 2007; Kwiatkowski et al., 2010; Andreas et al., 2013) or from (world, question, answer) triples alone (Liang et al., 2011; Pasupat and Liang, 2015). In general the set of primitive functions from which these logical forms can be assembled is fixed, but one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features (Krishnamurthy and Kollar, 2013) or the underlying schema (Kwiatkowski et al., 2013). The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primari"
N16-1181,S13-1002,0,\N,Missing
N16-1181,Q13-1015,0,\N,Missing
N18-1177,D10-1040,1,0.644454,"ch in this paper builds upon long lines of work in pragmatic modeling, instruction following, and instruction generation. 1 Source code is available at http://github.com/ dpfried/pragmatic-instructions 1952 Pragmatics Our approach to pragmatics (Grice, 1975) belongs to a general category of rational speech acts models (Frank and Goodman, 2012), in which the interaction between speakers and listeners is modeled as a probabilistic process with Bayesian actors (Goodman and Stuhlm¨uller, 2013). Alternative formulations (e.g. with bestresponse rather than probabilistic dynamics) are also possible (Golland et al., 2010). Inference in these models is challenging even when the space of listener actions is extremely simple (Smith et al., 2013), and one of our goals in the present work is to show how this inference problem can be solved even in much richer action spaces than previously considered in computational pragmatics. This family of pragmatic models captures a number of important linguistic phenomena, especially those involving conversational implicature (Monroe and Potts, 2015); we note that many other topics studied under the broad heading of “pragmatics,” including presupposition and indexicality, requ"
N18-1177,P17-1097,0,0.0921474,"ar inference procedure for a competitive negotiation task. The language learning model of Wang et al. (2016) also features a structured output space and uses pragmatics to improve online predictions for a semantic parsing model. Our approach in this paper performs both generation and interpretation, and investigates both structured and unstructured output representations. Instruction following Work on instruction following tasks includes models that parse commands into structured representations processed by a rich execution model (Tellex et al., 2011; Chen, 2012; Artzi and Zettlemoyer, 2013; Guu et al., 2017), and models that map directly from instructions to a policy over primitive actions (Branavan et al., 2009), possibly mediated by an intermediate alignment or attention variable (Andreas and Klein, 2015; Mei et al., 2016). We use a model similar to Mei et al. (2016) as our base listener in this paper, evaluating on the SAIL navigation task (MacMahon et al., 2006) as they did, as well as the SCONE context-dependent execution domains (Long et al., 2016). Instruction generation Previous work has also investigated the instruction generation task, in particular for navigational directions. The GIVE"
N18-1177,D14-1086,0,0.0299081,"of pragmatic models captures a number of important linguistic phenomena, especially those involving conversational implicature (Monroe and Potts, 2015); we note that many other topics studied under the broad heading of “pragmatics,” including presupposition and indexicality, require different machinery. Williams et al. (2015) use pragmatic reasoning with weighted inference rules to resolve ambiguity and generate clarification requests in a humanrobot dialog task. Other recent work on pragmatic models focuses on the referring expression generation or “contrastive captioning” task introduced by Kazemzadeh et al. (2014). In this family are approaches that model the listener at training time (Mao et al., 2016), at evaluation time (Andreas and Klein, 2016; Monroe et al., 2017; Vedantam et al., 2017; Su et al., 2017) or both (Yu et al., 2017b; Luo and Shakhnarovich, 2017). Other conditional sequence rescoring models that are structurally similar but motivated by concerns other than pragmatics include Li et al. (2016) and Yu et al. (2017a). Lewis et al. (2017) perform a similar inference procedure for a competitive negotiation task. The language learning model of Wang et al. (2016) also features a structured out"
N18-1177,W10-4233,0,0.0192443,"instructions to a policy over primitive actions (Branavan et al., 2009), possibly mediated by an intermediate alignment or attention variable (Andreas and Klein, 2015; Mei et al., 2016). We use a model similar to Mei et al. (2016) as our base listener in this paper, evaluating on the SAIL navigation task (MacMahon et al., 2006) as they did, as well as the SCONE context-dependent execution domains (Long et al., 2016). Instruction generation Previous work has also investigated the instruction generation task, in particular for navigational directions. The GIVE shared tasks (Byron et al., 2009; Koller et al., 2010; Striegnitz et al., 2011) have produced a large number of interactive direction-giving systems, both rule-based and learned. The work most immediately related to the generation task in this paper is that of Daniele et al. (2017), which also focuses on the SAIL dataset but requires substantial additional structured annotation for training, while both our base and pragmatic speaker models learn directly from strings and action sequences. Older work has studied the properties of effective human strategies for generating navigational directions (Anderson et al., 1991). Instructions of this kind c"
N18-1177,P02-1040,0,0.114507,"Missing"
N18-1177,D17-1259,0,0.0158321,"obot dialog task. Other recent work on pragmatic models focuses on the referring expression generation or “contrastive captioning” task introduced by Kazemzadeh et al. (2014). In this family are approaches that model the listener at training time (Mao et al., 2016), at evaluation time (Andreas and Klein, 2016; Monroe et al., 2017; Vedantam et al., 2017; Su et al., 2017) or both (Yu et al., 2017b; Luo and Shakhnarovich, 2017). Other conditional sequence rescoring models that are structurally similar but motivated by concerns other than pragmatics include Li et al. (2016) and Yu et al. (2017a). Lewis et al. (2017) perform a similar inference procedure for a competitive negotiation task. The language learning model of Wang et al. (2016) also features a structured output space and uses pragmatics to improve online predictions for a semantic parsing model. Our approach in this paper performs both generation and interpretation, and investigates both structured and unstructured output representations. Instruction following Work on instruction following tasks includes models that parse commands into structured representations processed by a rich execution model (Tellex et al., 2011; Chen, 2012; Artzi and Zet"
N18-1177,N16-1014,0,0.00569052,"erate clarification requests in a humanrobot dialog task. Other recent work on pragmatic models focuses on the referring expression generation or “contrastive captioning” task introduced by Kazemzadeh et al. (2014). In this family are approaches that model the listener at training time (Mao et al., 2016), at evaluation time (Andreas and Klein, 2016; Monroe et al., 2017; Vedantam et al., 2017; Su et al., 2017) or both (Yu et al., 2017b; Luo and Shakhnarovich, 2017). Other conditional sequence rescoring models that are structurally similar but motivated by concerns other than pragmatics include Li et al. (2016) and Yu et al. (2017a). Lewis et al. (2017) perform a similar inference procedure for a competitive negotiation task. The language learning model of Wang et al. (2016) also features a structured output space and uses pragmatics to improve online predictions for a semantic parsing model. Our approach in this paper performs both generation and interpretation, and investigates both structured and unstructured output representations. Instruction following Work on instruction following tasks includes models that parse commands into structured representations processed by a rich execution model (Tel"
N18-1177,P16-1138,0,0.0339462,"and must generate a sequence of direction sentences d1 , . . . dK describing the actions. The agent succeeds if a human listener is able to correctly follow those directions to the intended final state. We evaluate models for both tasks in four domains. The first domain is the SAIL corpus of virtual environments and navigational directions (MacMahon et al., 2006; Chen and Mooney, 2011), where an agent navigates through a twodimensional grid of hallways with patterned walls and floors and a discrete set of objects (Figure 1 shows a portion of one of these hallways). In the three SCONE domains (Long et al., 2016), the world contains a number of objects with various properties, such as colored beakers which an agent can combine, drain, and mix. Instructions describe how these objects should be manipulated. These domains were designed to elicit instructions with a variety of context-dependent language phenomena, including ellipsis and coreference (Long et al., 2016) which we might expect a model of pragmatics to help resolve (Potts, 2011). 3 Related Work The approach in this paper builds upon long lines of work in pragmatic modeling, instruction following, and instruction generation. 1 Source code is av"
N18-1177,W11-2845,0,0.0242438,"licy over primitive actions (Branavan et al., 2009), possibly mediated by an intermediate alignment or attention variable (Andreas and Klein, 2015; Mei et al., 2016). We use a model similar to Mei et al. (2016) as our base listener in this paper, evaluating on the SAIL navigation task (MacMahon et al., 2006) as they did, as well as the SCONE context-dependent execution domains (Long et al., 2016). Instruction generation Previous work has also investigated the instruction generation task, in particular for navigational directions. The GIVE shared tasks (Byron et al., 2009; Koller et al., 2010; Striegnitz et al., 2011) have produced a large number of interactive direction-giving systems, both rule-based and learned. The work most immediately related to the generation task in this paper is that of Daniele et al. (2017), which also focuses on the SAIL dataset but requires substantial additional structured annotation for training, while both our base and pragmatic speaker models learn directly from strings and action sequences. Older work has studied the properties of effective human strategies for generating navigational directions (Anderson et al., 1991). Instructions of this kind can be used to extract temp"
N18-1177,P16-1224,0,0.129739,"ning” task introduced by Kazemzadeh et al. (2014). In this family are approaches that model the listener at training time (Mao et al., 2016), at evaluation time (Andreas and Klein, 2016; Monroe et al., 2017; Vedantam et al., 2017; Su et al., 2017) or both (Yu et al., 2017b; Luo and Shakhnarovich, 2017). Other conditional sequence rescoring models that are structurally similar but motivated by concerns other than pragmatics include Li et al. (2016) and Yu et al. (2017a). Lewis et al. (2017) perform a similar inference procedure for a competitive negotiation task. The language learning model of Wang et al. (2016) also features a structured output space and uses pragmatics to improve online predictions for a semantic parsing model. Our approach in this paper performs both generation and interpretation, and investigates both structured and unstructured output representations. Instruction following Work on instruction following tasks includes models that parse commands into structured representations processed by a rich execution model (Tellex et al., 2011; Chen, 2012; Artzi and Zettlemoyer, 2013; Guu et al., 2017), and models that map directly from instructions to a policy over primitive actions (Branav"
N18-1197,D11-1140,0,0.0642625,"Missing"
N18-1197,P17-1015,0,0.0345304,"interesting and meaningful behaviors. 7 Other Related Work This is the first approach we are aware of to frame a general learning problem as optimization over a space of natural language strings. However, many closely related ideas have been explored in the literature. String-valued latent variables are widely used in language processing tasks ranging from morphological analysis (Dreyer and Eisner, 2009) to sentence compression (Miao and Blunsom, 2016). Natural language annotations have been used in conjunction with training examples to guide the discovery of logical descriptions of concepts (Ling et al., 2017; Srivastava et al., 2017), and used as an auxiliary loss for training (Frome et al., 2013), analogously to the Meta+Joint baseline in this paper. Structured language-like annotations have been used to improve learning of generalizable structured policies (Oh et al., 2017; Andreas et al., 2017; Denil et al., 2017). Finally, natural language instructions available at concept-learning time (rather than language-learning time) have been used to provide side information to reinforcement learners about high-level strategy (Branavan et al., 2011), environments (Narasimhan et al., 2017) and explorati"
N18-1197,D16-1031,0,0.0198,"that the model has used the structure provided by language to learn a better representation space for policies— one that facilitates sampling from a distribution over interesting and meaningful behaviors. 7 Other Related Work This is the first approach we are aware of to frame a general learning problem as optimization over a space of natural language strings. However, many closely related ideas have been explored in the literature. String-valued latent variables are widely used in language processing tasks ranging from morphological analysis (Dreyer and Eisner, 2009) to sentence compression (Miao and Blunsom, 2016). Natural language annotations have been used in conjunction with training examples to guide the discovery of logical descriptions of concepts (Ling et al., 2017; Srivastava et al., 2017), and used as an auxiliary loss for training (Frome et al., 2013), analogously to the Meta+Joint baseline in this paper. Structured language-like annotations have been used to improve learning of generalizable structured policies (Oh et al., 2017; Andreas et al., 2017; Denil et al., 2017). Finally, natural language instructions available at concept-learning time (rather than language-learning time) have been u"
N18-1197,Q14-1017,0,0.0494754,"guage provides a strong prior about the kinds of abstractions that are useful for natural learning problems. Concretely, we replace the pretraining phase above with a language-learning phase. We assume that at language-learning time we have access to natural-language descriptions w(`i) (Figure 2a, bottom). We use these w as parameters, in place of the task-specific parameters θ—that is, we learn a language interpretation model f (x; η, w) that uses shared parameters η to turn a description w into a function from inputs to outputs. For the example in Figure 2, f might be an image rating model (Socher et al., 2014) that outputs a scalar judgment y of how well an image x matches a caption w. Because these natural language parameters are observed at language-learning time, we need only learn the real-valued shared parameters η used for their interpretation (e.g. the weights of a neural network that implements the image rating model): arg min η ∈ Ra In this work, we are interested in developing a learning method that enjoys the benefits of both approaches. In particular, we seek an intermediate language of task representations that, like in program synthesis, is both expressive and compact, but like in mul"
N18-1197,D17-1161,0,0.0873683,"ningful behaviors. 7 Other Related Work This is the first approach we are aware of to frame a general learning problem as optimization over a space of natural language strings. However, many closely related ideas have been explored in the literature. String-valued latent variables are widely used in language processing tasks ranging from morphological analysis (Dreyer and Eisner, 2009) to sentence compression (Miao and Blunsom, 2016). Natural language annotations have been used in conjunction with training examples to guide the discovery of logical descriptions of concepts (Ling et al., 2017; Srivastava et al., 2017), and used as an auxiliary loss for training (Frome et al., 2013), analogously to the Meta+Joint baseline in this paper. Structured language-like annotations have been used to improve learning of generalizable structured policies (Oh et al., 2017; Andreas et al., 2017; Denil et al., 2017). Finally, natural language instructions available at concept-learning time (rather than language-learning time) have been used to provide side information to reinforcement learners about high-level strategy (Branavan et al., 2011), environments (Narasimhan et al., 2017) and exploration (Harrison et al., 2017)"
N18-1197,P17-2034,0,0.0430825,"d these techniques to reinforcement learning. 4 Few-shot Classification We begin by investigating whether natural language can be used to support high-dimensional few-shot classification. Our focus is on visual reasoning tasks like the one shown in Figure 3. In these problems, the learner is presented with four images, all positive examples of some visual concept like a blue shape near a yellow triangle, and must decide whether a fifth, held-out image matches the same concept. These kinds of reasoning problems have been well-studied in visual question answering settings (Johnson et al., 2017; Suhr et al., 2017). Our version of the problem, where the input and output feature no text data, but an explanation must be inferred, is similar to the visual reasoning problems proposed by Raven (1936) and Bongard (1968). To apply the recipe in Section 2, we need to specify an implementation of the interpretation model f and the proposal model q. We begin by computing representations of input images x. We start with a pre-trained 16-layer VGGNet (Simonyan and Zisserman, 2014). Because spatial information is important for these tasks, we extract a feature representation from the final convolutional layer of the"
N19-1410,N18-1150,0,0.0150674,"q. 1 (with weights tuned on the development data). Both of our pragmatic systems improve over the strong baseline S0 system on all five metrics, with the largest improvements (2.1 BLEU, 0.2 NIST, 0.8 METEOR , 1.5 ROUGE - L , and 0.1 CIDE r) from the S1R model. This S1R model outperforms the previous best results obtained by any system in the E2E challenge on BLEU, NIST, and CIDEr, with comparable performance on METEOR and ROUGE - L. Table 2: Test results for the non-anonymized CNN/Daily Mail summarization task. We compare to extractive baselines, and the best previous abstractive results of † Celikyilmaz et al. (2018), ‡ Paulus et al. (2018) and  Chen and Bansal (2018). We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models. 4.2 Abstractive Summarization We evaluate on the CNN/Daily Mail summarization dataset (Hermann et al., 2015; Nallapati et al., 2016), using See et al.’s (2017) non-anonymized preprocessing. As in previous work (Chen and Bansal, 2018), we evaluate using ROUGE and ME TEOR . Table 2 compares our pragmatic systems to the base S0 model (with scores taken from Chen and Bansal (2018); we obtained comparable performance in our reprodu"
N19-1410,D10-1040,1,0.556817,"atic system (S1R ) Fitzbillies is a family friendly coffee shop that serves cheap English food in the riverside area. It has a customer rating of 5 out of 5. Figure 1: Example outputs of our systems on the E2E generation task. While a base sequence-to-sequence model (S0 , Sec. 2) fails to describe all attributes in the input meaning representation, both of our pragmatic systems (S1R , Sec. 3.1 and S1D , Sec. 3.2) and the human-written reference do. Introduction Computational approaches to pragmatics cast language generation and interpretation as gametheoretic or Bayesian inference procedures (Golland et al., 2010; Frank and Goodman, 2012). While such approaches are capable of modeling a variety of pragmatic phenomena, their main application in natural language processing has been to improve the informativeness of generated text in grounded language learning problems (Monroe et al., 2018). In this paper, we show that pragmatic reasoning can be similarly used to improve performance in more traditional language generation tasks like generation from structured meaning representations (Figure 1) and summarization. Our work builds on a line of learned Rational Speech Acts (RSA) models (Monroe and Potts, 201"
N19-1410,P18-1063,0,0.14831,"(Puzikov and Gurevych, 2018) that achieves comparable performance to the best published results in Duˇsek et al. (2018). Abstractive Summarization Our second task is multi-sentence document summarization. There is a vast amount of past work on summarization (Nenkova and McKeown, 2011); recent neural models have used large datasets (e.g., Hermann et al. (2015)) to train models in both the extractive (Cheng and Lapata, 2016; Nallapati et al., 2017) and abstractive (Rush et al., 2015; See et al., 2017) settings. Among these works, we build on the recent abstractive neural summarization system of Chen and Bansal (2018). First, this system uses a sentence-level extractive model RNN - EXT to identify a sequence of salient sentences i(1) , . . . i(P ) in each source document. Second, the system uses an abstractive model ABS to rewrite each i(p) into an output o(p) , which are then concatenated to produce the final summary. We rely on the fixed RNN EXT model to extract sentences as inputs in our pragmatic procedure, using ABS as our S0 model and applying pragmatics to the i(p) → o(p) abstractive step. 3 Pragmatic Models To produce informative outputs, we consider pragmatic methods that extend the base speaker m"
N19-1410,P16-1046,0,0.0272664,"rant with the specified attributes. We apply pragmatics to encourage output strings from which the input MR can be identified. For our S0 model, we use a publicly-released neural generation system (Puzikov and Gurevych, 2018) that achieves comparable performance to the best published results in Duˇsek et al. (2018). Abstractive Summarization Our second task is multi-sentence document summarization. There is a vast amount of past work on summarization (Nenkova and McKeown, 2011); recent neural models have used large datasets (e.g., Hermann et al. (2015)) to train models in both the extractive (Cheng and Lapata, 2016; Nallapati et al., 2017) and abstractive (Rush et al., 2015; See et al., 2017) settings. Among these works, we build on the recent abstractive neural summarization system of Chen and Bansal (2018). First, this system uses a sentence-level extractive model RNN - EXT to identify a sequence of salient sentences i(1) , . . . i(P ) in each source document. Second, the system uses an abstractive model ABS to rewrite each i(p) into an output o(p) , which are then concatenated to produce the final summary. We rely on the fixed RNN EXT model to extract sentences as inputs in our pragmatic procedure, u"
N19-1410,D14-1179,0,0.0145181,"Missing"
N19-1410,N18-2070,0,0.0519457,"fine LR (i |o) as the joint probability of predicting all input MR attributes in i from o. Summarization To construct LR for summarization, we train an ABS model (of the type we use for S0 , Chen and Bansal (2018)) but in reverse, i.e., taking as input a sentence in the summary and producing a sentence in the source document. We train LR on the same heuristically-extracted and aligned source document sentences used to train S0 (Chen and Bansal, 2018). 3.2 Distractor-Based Pragmatics Pragmatic approaches in this category (Frank and Goodman, 2012; Andreas and Klein, 2016; Vedantam et al., 2017; Cohn-Gordon et al., 2018) derive pragmatic behavior by producing outputs that distinguish the input i from an alternate distractor input (or inputs). We construct a distractor eı for a given input i in a task-dependent way.1 We follow the approach of Cohn-Gordon et al. (2018), outlined briefly here. The base speakers we build on produce outputs incrementally, where the probability of ot , the word output at time t, is conditioned on the input and the previously generated words: S0 (ot |i, o<t ). Since the output is generated incrementally and there is no separate 1 In tasks such as contrastive captioning or referring"
N19-1410,P16-2008,0,0.164084,"Missing"
N19-1410,N18-1014,0,0.0624822,".83 2.23 2.27• Extractive S0 S0 ×2 S1R S1D 66.52 65.93 68.60 67.76 8.55 8.31 8.73 8.72 44.45 43.52 45.25 44.59 69.34 69.58 70.82 69.41 2.23 2.12 2.37 2.27 R-2 R-L METEOR 40.34 38.93 17.70 18.23 36.57 35.90 22.21 24.66 Best Previous 41.69† 19.47† 39.08‡ 21.00 S0 S0 ×2 S1R S1D 40.88 40.76 41.23 41.39 17.80 17.88 18.07 18.30 38.54 38.46 38.76 38.78 20.38 19.88 20.57 21.70 Lead-3 Inputs Abstractive Table 1: Test results for the E2E generation task, in comparison to the T-Gen baseline (Duˇsek and Jurˇc´ıcˇ ek, 2016) and the best results from the E2E challenge, reported by Duˇsek et al. (2018): † Juraska et al. (2018), ‡ Puzikov and Gurevych (2018),  Zhang et al. (2018), and • Gong (2018). We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models. 4.1 R-1 Meaning Representations We evaluate on the E2E task of generation from meaning representations containing restaurant attributes (Novikova et al., 2017). We report the task’s five automatic metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Lavie and Agarwal, 2007), ROUGE - L (Lin, 2004) and CIDEr (Vedantam et al., 2015). Table 1 compares the performance of our base S0 and pragma"
N19-1410,W07-0734,0,0.0472317,"seline (Duˇsek and Jurˇc´ıcˇ ek, 2016) and the best results from the E2E challenge, reported by Duˇsek et al. (2018): † Juraska et al. (2018), ‡ Puzikov and Gurevych (2018),  Zhang et al. (2018), and • Gong (2018). We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models. 4.1 R-1 Meaning Representations We evaluate on the E2E task of generation from meaning representations containing restaurant attributes (Novikova et al., 2017). We report the task’s five automatic metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Lavie and Agarwal, 2007), ROUGE - L (Lin, 2004) and CIDEr (Vedantam et al., 2015). Table 1 compares the performance of our base S0 and pragmatic models to the baseline T-Gen system (Duˇsek and Jurˇc´ıcˇ ek, 2016) and the best previous result from the 20 primary systems evaluated in the E2E challenge (Duˇsek et al., 2018). The systems obtaining these results encompass a range of approaches: a template system (Puzikov and Gurevych, 2018), a neural model (Zhang et al., 2018), models trained with reinforcement learning (Gong, 2018), and systems using ensembling and reranking (Juraska et al., 2018). To ensure that the ben"
N19-1410,W04-1013,0,0.01764,") and the best results from the E2E challenge, reported by Duˇsek et al. (2018): † Juraska et al. (2018), ‡ Puzikov and Gurevych (2018),  Zhang et al. (2018), and • Gong (2018). We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models. 4.1 R-1 Meaning Representations We evaluate on the E2E task of generation from meaning representations containing restaurant attributes (Novikova et al., 2017). We report the task’s five automatic metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Lavie and Agarwal, 2007), ROUGE - L (Lin, 2004) and CIDEr (Vedantam et al., 2015). Table 1 compares the performance of our base S0 and pragmatic models to the baseline T-Gen system (Duˇsek and Jurˇc´ıcˇ ek, 2016) and the best previous result from the 20 primary systems evaluated in the E2E challenge (Duˇsek et al., 2018). The systems obtaining these results encompass a range of approaches: a template system (Puzikov and Gurevych, 2018), a neural model (Zhang et al., 2018), models trained with reinforcement learning (Gong, 2018), and systems using ensembling and reranking (Juraska et al., 2018). To ensure that the benefit of the reconstruct"
N19-1410,N18-1196,0,0.0780322,"fails to describe all attributes in the input meaning representation, both of our pragmatic systems (S1R , Sec. 3.1 and S1D , Sec. 3.2) and the human-written reference do. Introduction Computational approaches to pragmatics cast language generation and interpretation as gametheoretic or Bayesian inference procedures (Golland et al., 2010; Frank and Goodman, 2012). While such approaches are capable of modeling a variety of pragmatic phenomena, their main application in natural language processing has been to improve the informativeness of generated text in grounded language learning problems (Monroe et al., 2018). In this paper, we show that pragmatic reasoning can be similarly used to improve performance in more traditional language generation tasks like generation from structured meaning representations (Figure 1) and summarization. Our work builds on a line of learned Rational Speech Acts (RSA) models (Monroe and Potts, 2015; Andreas and Klein, 2016), in which generated strings are selected to optimize the behavior of an embedded listener model. The canonical presentation of the RSA framework (Frank and Goodman, 2012) is grounded in reference resolution: models of speakers attempt to describe refer"
N19-1410,K16-1028,0,0.0199832,"t results obtained by any system in the E2E challenge on BLEU, NIST, and CIDEr, with comparable performance on METEOR and ROUGE - L. Table 2: Test results for the non-anonymized CNN/Daily Mail summarization task. We compare to extractive baselines, and the best previous abstractive results of † Celikyilmaz et al. (2018), ‡ Paulus et al. (2018) and  Chen and Bansal (2018). We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models. 4.2 Abstractive Summarization We evaluate on the CNN/Daily Mail summarization dataset (Hermann et al., 2015; Nallapati et al., 2016), using See et al.’s (2017) non-anonymized preprocessing. As in previous work (Chen and Bansal, 2018), we evaluate using ROUGE and ME TEOR . Table 2 compares our pragmatic systems to the base S0 model (with scores taken from Chen and Bansal (2018); we obtained comparable performance in our reproduction3 ), an ensemble of two of these base models, and the best previous abstractive summarization result for each metric on this dataset (Celikyilmaz et al., 2018; Paulus et al., 2018; Chen and Bansal, 2018). We also report two extractive baselines: Lead-3, which uses the first three sentences of the"
N19-1410,P17-1099,0,0.228617,"from which the input MR can be identified. For our S0 model, we use a publicly-released neural generation system (Puzikov and Gurevych, 2018) that achieves comparable performance to the best published results in Duˇsek et al. (2018). Abstractive Summarization Our second task is multi-sentence document summarization. There is a vast amount of past work on summarization (Nenkova and McKeown, 2011); recent neural models have used large datasets (e.g., Hermann et al. (2015)) to train models in both the extractive (Cheng and Lapata, 2016; Nallapati et al., 2017) and abstractive (Rush et al., 2015; See et al., 2017) settings. Among these works, we build on the recent abstractive neural summarization system of Chen and Bansal (2018). First, this system uses a sentence-level extractive model RNN - EXT to identify a sequence of salient sentences i(1) , . . . i(P ) in each source document. Second, the system uses an abstractive model ABS to rewrite each i(p) into an output o(p) , which are then concatenated to produce the final summary. We rely on the fixed RNN EXT model to extract sentences as inputs in our pragmatic procedure, using ABS as our S0 model and applying pragmatics to the i(p) → o(p) abstractive"
N19-1410,W17-5525,0,0.123139,"Missing"
N19-1410,P15-1158,0,0.0634905,"Missing"
N19-1410,P02-1040,0,0.103698,"or the E2E generation task, in comparison to the T-Gen baseline (Duˇsek and Jurˇc´ıcˇ ek, 2016) and the best results from the E2E challenge, reported by Duˇsek et al. (2018): † Juraska et al. (2018), ‡ Puzikov and Gurevych (2018),  Zhang et al. (2018), and • Gong (2018). We bold our highest performing model on each metric, as well as previous work if it outperforms all of our models. 4.1 R-1 Meaning Representations We evaluate on the E2E task of generation from meaning representations containing restaurant attributes (Novikova et al., 2017). We report the task’s five automatic metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), METEOR (Lavie and Agarwal, 2007), ROUGE - L (Lin, 2004) and CIDEr (Vedantam et al., 2015). Table 1 compares the performance of our base S0 and pragmatic models to the baseline T-Gen system (Duˇsek and Jurˇc´ıcˇ ek, 2016) and the best previous result from the 20 primary systems evaluated in the E2E challenge (Duˇsek et al., 2018). The systems obtaining these results encompass a range of approaches: a template system (Puzikov and Gurevych, 2018), a neural model (Zhang et al., 2018), models trained with reinforcement learning (Gong, 2018), and systems using ensembling a"
N19-1410,W18-6557,0,0.302195,". For these S0 models we use systems from past work that are strong, but may still be underinformative relative to human reference outputs (e.g., Figure 1). Meaning Representations Our first task is generation from structured meaning representations (MRs) containing attribute-value pairs (Novikova et al., 2017). An example is shown in Figure 1, where systems must generate a description of the restaurant with the specified attributes. We apply pragmatics to encourage output strings from which the input MR can be identified. For our S0 model, we use a publicly-released neural generation system (Puzikov and Gurevych, 2018) that achieves comparable performance to the best published results in Duˇsek et al. (2018). Abstractive Summarization Our second task is multi-sentence document summarization. There is a vast amount of past work on summarization (Nenkova and McKeown, 2011); recent neural models have used large datasets (e.g., Hermann et al. (2015)) to train models in both the extractive (Cheng and Lapata, 2016; Nallapati et al., 2017) and abstractive (Rush et al., 2015; See et al., 2017) settings. Among these works, we build on the recent abstractive neural summarization system of Chen and Bansal (2018). Firs"
N19-1410,D15-1044,0,0.0475982,"age output strings from which the input MR can be identified. For our S0 model, we use a publicly-released neural generation system (Puzikov and Gurevych, 2018) that achieves comparable performance to the best published results in Duˇsek et al. (2018). Abstractive Summarization Our second task is multi-sentence document summarization. There is a vast amount of past work on summarization (Nenkova and McKeown, 2011); recent neural models have used large datasets (e.g., Hermann et al. (2015)) to train models in both the extractive (Cheng and Lapata, 2016; Nallapati et al., 2017) and abstractive (Rush et al., 2015; See et al., 2017) settings. Among these works, we build on the recent abstractive neural summarization system of Chen and Bansal (2018). First, this system uses a sentence-level extractive model RNN - EXT to identify a sequence of salient sentences i(1) , . . . i(P ) in each source document. Second, the system uses an abstractive model ABS to rewrite each i(p) into an output o(p) , which are then concatenated to produce the final summary. We rely on the fixed RNN EXT model to extract sentences as inputs in our pragmatic procedure, using ABS as our S0 model and applying pragmatics to the i(p)"
P13-1091,C12-1083,1,0.377003,"on of contextfree grammars, and some important implementation details, resulting in an algorithm that is practical for natural-language applications. The algorithm is part of Bolinas, a new software toolkit for HRG processing. 1 Introduction Hyperedge replacement grammar (HRG) is a context-free rewriting formalism for generating graphs (Drewes et al., 1997), and its synchronous counterpart can be used for transforming graphs to/from other graphs or trees. As such, it has great potential for applications in natural language understanding and generation, and semantics-based machine translation (Jones et al., 2012). Figure 1 shows some examples of graphs for naturallanguage semantics. A polynomial-time recognition algorithm for HRGs was described by Lautemann (1990), building on the work of Rozenberg and Welzl (1986) on boundary node label controlled grammars, and others have presented polynomial-time algorithms as well (Mazanek and Minas, 2008; Moot, 2008). Although Lautemann’s algorithm is correct and tractable, its presentation is prefaced with the remark: “As we are only interested in distinguishing polynomial time from non-polynomial time, the analysis will be rather crude, and implementation detai"
P13-1091,W08-2309,0,0.0254182,"7), and its synchronous counterpart can be used for transforming graphs to/from other graphs or trees. As such, it has great potential for applications in natural language understanding and generation, and semantics-based machine translation (Jones et al., 2012). Figure 1 shows some examples of graphs for naturallanguage semantics. A polynomial-time recognition algorithm for HRGs was described by Lautemann (1990), building on the work of Rozenberg and Welzl (1986) on boundary node label controlled grammars, and others have presented polynomial-time algorithms as well (Mazanek and Minas, 2008; Moot, 2008). Although Lautemann’s algorithm is correct and tractable, its presentation is prefaced with the remark: “As we are only interested in distinguishing polynomial time from non-polynomial time, the analysis will be rather crude, and implementation details will be explicated as little as possible.” Indeed, the key step of the algorithm, which matches a rule against the input graph, is described at a very high level, so that it is not obvious (for a non-expert in graph algorithms) how to implement it. More importantly, this step as described leads to a time complexity that is polynomial, but poten"
P13-1091,J11-1008,0,\N,Missing
P13-2009,J93-2003,0,0.0286326,"ecoding: given any sequence of decorated MRL tokens, we can always reconstruct the corresponding tree structure (if one exists). Arity labeling additionally allows functions with variable numbers of arguments (e.g. cityid, which in some training examples is unary) to align with different natural language strings depending on context. LINEARIZE state border texa state1 next to1 state1 stateid1 texas0 ⇓ ALIGN state border texa state1 next to1 state1 stateid1 texas0 Alignment Following the linearization of the MRs, we find alignments between the MR tokens and the NL tokens using the IBM Model 4 (Brown et al., 1993). Once the alignment algorithm is run in both directions (NL to MRL, MRL to NL), we symmetrize the resulting alignments to obtain a consensus many-to-many alignment (Och and Ney, 2000; Koehn et al., 2005). ⇓ EXTRACT ( PHRASE ) h state , state1 i h state border , state1 border1 i h texa , state1 stateid1 texas0 i .. . ⇓ EXTRACT ( HIER ) [X] → hstate , state1 i Rule extraction From the many-to-many alignment we need to extract a translation rule table, consisting of corresponding phrases in NL and MRL. We consider a phrase-based translation model (Koehn et al., 2003) and a hierarchical translati"
P13-2009,P11-1149,0,0.0308621,"he use of machine translation methods as an informative baseline in semantic parsing evaluations, and suggest that research in semantic parsing could benefit from advances in machine translation. 1 Stephen Clark Computer Laboratory University of Cambridge sc609@cam.ac.uk Introduction Semantic parsing (SP) is the problem of transforming a natural language (NL) utterance into a machine-interpretable meaning representation (MR). It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it, e.g. rule-based (Popescu et al., 2003), supervised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al., 2011). At least superficially, SP is simply a machine translation (MT) task: we transform an NL utterance in one language into a statement of another (un-natural) meaning representation language (MRL). Indeed, successful semantic parsers often resemble MT systems in several important respects, including the use of word alignment models as a starting point for rule extraction (Wong and Mooney, 2006; Kwiatkowski et al., 2010) and the use of automata such as tree transducers (Jones et al., 2012) to encode the relationship between NL and MRL. 2 MT-based semantic"
P13-2009,P12-1051,0,0.666025,"opescu et al., 2003), supervised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al., 2011). At least superficially, SP is simply a machine translation (MT) task: we transform an NL utterance in one language into a statement of another (un-natural) meaning representation language (MRL). Indeed, successful semantic parsers often resemble MT systems in several important respects, including the use of word alignment models as a starting point for rule extraction (Wong and Mooney, 2006; Kwiatkowski et al., 2010) and the use of automata such as tree transducers (Jones et al., 2012) to encode the relationship between NL and MRL. 2 MT-based semantic parsing The input is a corpus of NL utterances paired with MRs. In order to learn a semantic parser using MT we linearize the MRs, learn alignments between the MRL and the NL, extract translation rules, and learn a language model for the MRL. We also specify a decoding procedure that will return structured MRs for an utterance during prediction. 47 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 47–52, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguist"
P13-2009,N03-1017,0,0.0364768,"okens using the IBM Model 4 (Brown et al., 1993). Once the alignment algorithm is run in both directions (NL to MRL, MRL to NL), we symmetrize the resulting alignments to obtain a consensus many-to-many alignment (Och and Ney, 2000; Koehn et al., 2005). ⇓ EXTRACT ( PHRASE ) h state , state1 i h state border , state1 border1 i h texa , state1 stateid1 texas0 i .. . ⇓ EXTRACT ( HIER ) [X] → hstate , state1 i Rule extraction From the many-to-many alignment we need to extract a translation rule table, consisting of corresponding phrases in NL and MRL. We consider a phrase-based translation model (Koehn et al., 2003) and a hierarchical translation model (Chiang, 2005). Rules for the phrase-based model consist of pairs of aligned source and target sequences, while hierarchical rules are SCFG productions containing at most two instances of a single nonterminal symbol. Note that both extraction algorithms can learn rules which a traditional tree-transducer-based approach cannot—for example the right hand side [X] → hstate [X] texa , state1 [X] state1 stateid1 texas0 i .. . Figure 1: Illustration of preprocessing and rule extraction. Linearization We assume that the MRL is variable-free (that is, the meaning"
P13-2009,2005.iwslt-1.8,0,0.0119875,"ents (e.g. cityid, which in some training examples is unary) to align with different natural language strings depending on context. LINEARIZE state border texa state1 next to1 state1 stateid1 texas0 ⇓ ALIGN state border texa state1 next to1 state1 stateid1 texas0 Alignment Following the linearization of the MRs, we find alignments between the MR tokens and the NL tokens using the IBM Model 4 (Brown et al., 1993). Once the alignment algorithm is run in both directions (NL to MRL, MRL to NL), we symmetrize the resulting alignments to obtain a consensus many-to-many alignment (Och and Ney, 2000; Koehn et al., 2005). ⇓ EXTRACT ( PHRASE ) h state , state1 i h state border , state1 border1 i h texa , state1 stateid1 texas0 i .. . ⇓ EXTRACT ( HIER ) [X] → hstate , state1 i Rule extraction From the many-to-many alignment we need to extract a translation rule table, consisting of corresponding phrases in NL and MRL. We consider a phrase-based translation model (Koehn et al., 2003) and a hierarchical translation model (Chiang, 2005). Rules for the phrase-based model consist of pairs of aligned source and target sequences, while hierarchical rules are SCFG productions containing at most two instances of a singl"
P13-2009,P07-2045,0,0.00547291,"tely discard malformed MRs; for the experiments in this paper we simply filter the regular n-best list until we find a well-formed MR. This filtering can be done with time linear in the length of the example by exploiting the argument label numbers introduced during linearization. Finally, we insert the brackets according to the tree structure specified by the argument number labels. 3 Implementation In all experiments, we use the IBM Model 4 implementation from the GIZA++ toolkit (Och and Ney, 2000) for alignment, and the phrase-based and hierarchical models implemented in the Moses toolkit (Koehn et al., 2007) for rule extraction. The best symmetrization algorithm, translation and language model weights for each language are selected using cross-validation on the development set. In the case of English and German, we also found that stemming (Bird et al., 2009; Porter, 1980) was hepful in reducing data sparsity. 4 Results We first compare the results for the two translation rule extraction models, phrase-based and hierarchical (“MT-phrase” and “MT-hier” respectively in Table 1). We find that the hierarchical model performs better in all languages apart from Greek, indicating that the long-range reo"
P13-2009,D10-1119,0,0.0752731,"wide variety of methods have been proposed to tackle it, e.g. rule-based (Popescu et al., 2003), supervised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al., 2011). At least superficially, SP is simply a machine translation (MT) task: we transform an NL utterance in one language into a statement of another (un-natural) meaning representation language (MRL). Indeed, successful semantic parsers often resemble MT systems in several important respects, including the use of word alignment models as a starting point for rule extraction (Wong and Mooney, 2006; Kwiatkowski et al., 2010) and the use of automata such as tree transducers (Jones et al., 2012) to encode the relationship between NL and MRL. 2 MT-based semantic parsing The input is a corpus of NL utterances paired with MRs. In order to learn a semantic parser using MT we linearize the MRs, learn alignments between the MRL and the NL, extract translation rules, and learn a language model for the MRL. We also specify a decoding procedure that will return structured MRs for an utterance during prediction. 47 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 47–52, c Sofia,"
P13-2009,P11-1060,0,0.0670688,"formative baseline in semantic parsing evaluations, and suggest that research in semantic parsing could benefit from advances in machine translation. 1 Stephen Clark Computer Laboratory University of Cambridge sc609@cam.ac.uk Introduction Semantic parsing (SP) is the problem of transforming a natural language (NL) utterance into a machine-interpretable meaning representation (MR). It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it, e.g. rule-based (Popescu et al., 2003), supervised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al., 2011). At least superficially, SP is simply a machine translation (MT) task: we transform an NL utterance in one language into a statement of another (un-natural) meaning representation language (MRL). Indeed, successful semantic parsers often resemble MT systems in several important respects, including the use of word alignment models as a starting point for rule extraction (Wong and Mooney, 2006; Kwiatkowski et al., 2010) and the use of automata such as tree transducers (Jones et al., 2012) to encode the relationship between NL and MRL. 2 MT-based semantic parsing The input is a corpus of NL utte"
P13-2009,D11-1149,0,0.0250669,"scribes a generative model over derivations of MRL trees. The remaining system discussed in this paper, UBL (Kwiatkowski et al., 2010), leverages the fact that the MRL does not simply encode trees, but rather λ-calculus expressions. It employs resolution procedures specific to the λ-calculus such as splitting and unification in order to generate rule templates. Like other systems described, it uses GIZA alignments for initialization. Other work which generalizes from variable-free meaning representations to λ-calculus expressions includes the natural language generation procedure described by Lu and Ng (2011). UBL , like an MT system (and unlike most of the other systems discussed in this section), extracts rules at multiple levels of granularity by means of this splitting and unification procedure. hybridtree similarly benefits from the introduction of We also compare the MT-based semantic parsers to several recently published ones: WASP (Wong and Mooney, 2006), which like the hierarchical model described here learns a SCFG to translate between NL and MRL; tsVB (Jones et al., 2012), which uses variational Bayesian inference to learn weights for a tree transducer; UBL (Kwiatkowski et al., 2010), w"
P13-2009,D08-1082,0,0.0842745,"ctic MT to extract rules. tsVB also uses a piece of standard MT machinery, specifically tree transducers, which have been profitably employed for syntax-based machine translation (Maletti, 2010). In that work, however, the usual MT parameter-estimation technique of simply counting the number of rule occurrences does not improve scores, and the authors instead resort to a variational inference procedure to acquire rule weights. The present work is also the first we are aware of which uses phrasebased rather than tree-based machine translation techniques to learn a semantic parser. hybrid-tree (Lu et al., 2008) similarly describes a generative model over derivations of MRL trees. The remaining system discussed in this paper, UBL (Kwiatkowski et al., 2010), leverages the fact that the MRL does not simply encode trees, but rather λ-calculus expressions. It employs resolution procedures specific to the λ-calculus such as splitting and unification in order to generate rule templates. Like other systems described, it uses GIZA alignments for initialization. Other work which generalizes from variable-free meaning representations to λ-calculus expressions includes the natural language generation procedure"
P13-2009,P00-1056,0,0.0603827,"le numbers of arguments (e.g. cityid, which in some training examples is unary) to align with different natural language strings depending on context. LINEARIZE state border texa state1 next to1 state1 stateid1 texas0 ⇓ ALIGN state border texa state1 next to1 state1 stateid1 texas0 Alignment Following the linearization of the MRs, we find alignments between the MR tokens and the NL tokens using the IBM Model 4 (Brown et al., 1993). Once the alignment algorithm is run in both directions (NL to MRL, MRL to NL), we symmetrize the resulting alignments to obtain a consensus many-to-many alignment (Och and Ney, 2000; Koehn et al., 2005). ⇓ EXTRACT ( PHRASE ) h state , state1 i h state border , state1 border1 i h texa , state1 stateid1 texas0 i .. . ⇓ EXTRACT ( HIER ) [X] → hstate , state1 i Rule extraction From the many-to-many alignment we need to extract a translation rule table, consisting of corresponding phrases in NL and MRL. We consider a phrase-based translation model (Koehn et al., 2003) and a hierarchical translation model (Chiang, 2005). Rules for the phrase-based model consist of pairs of aligned source and target sequences, while hierarchical rules are SCFG productions containing at most two"
P13-2009,N06-1056,0,0.940236,"l-studied in NLP, and a wide variety of methods have been proposed to tackle it, e.g. rule-based (Popescu et al., 2003), supervised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al., 2011). At least superficially, SP is simply a machine translation (MT) task: we transform an NL utterance in one language into a statement of another (un-natural) meaning representation language (MRL). Indeed, successful semantic parsers often resemble MT systems in several important respects, including the use of word alignment models as a starting point for rule extraction (Wong and Mooney, 2006; Kwiatkowski et al., 2010) and the use of automata such as tree transducers (Jones et al., 2012) to encode the relationship between NL and MRL. 2 MT-based semantic parsing The input is a corpus of NL utterances paired with MRs. In order to learn a semantic parser using MT we linearize the MRs, learn alignments between the MRL and the NL, extract translation rules, and learn a language model for the MRL. We also specify a decoding procedure that will return structured MRs for an utterance during prediction. 47 Proceedings of the 51st Annual Meeting of the Association for Computational Linguist"
P13-2009,P05-1033,0,\N,Missing
P14-2133,N07-1051,1,0.646584,"artof-speech tagging (Sch¨utze, 1995), and chunking 822 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 822–827, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics which shows embeddings for a variety of English determiners, projected onto their first two principal components. We can see that the quantifiers each and every cluster together, as do few and most. These are precisely the kinds of distinctions between determiners that state-splitting in the Berkeley parser has shown to be useful (Petrov and Klein, 2007), and existing work (Mikolov et al., 2013b) has observed that such regular embedding structure extends to many other parts of speech. But we don’t know how prevalent or important such “syntactic axes” are in practice. Thus we have two questions: Are such groupings (learned on large data sets but from less syntactically rich models) better than the ones the parser finds on its own? How much data is needed to learn them without word embeddings? We consider three general hypotheses about how embeddings might interact with a parser: 0.8 few most 0.6 0.4 0.2 that the 0 a each this every −0.2 −0.4 0"
P14-2133,W13-3211,1,0.825458,"Missing"
P14-2133,E95-1020,0,0.213589,"Missing"
P14-2133,P14-2131,0,0.206208,"embeddings encode about syntax? Jacob Andreas and Dan Klein Computer Science Division University of California, Berkeley {jda,klein}@cs.berkeley.edu Abstract (Turian et al., 2010) have been shown to benefit from the inclusion of word embeddings as features. In the other direction, access to a syntactic parse has been shown to be useful for constructing word embeddings for phrases compositionally (Hermann and Blunsom, 2013; Andreas and Ghahramani, 2013). Dependency parsers have seen gains from distributional statistics in the form of discrete word clusters (Koo et al., 2008), and recent work (Bansal et al., 2014) suggests that similar gains can be derived from embeddings like the ones used in this paper. It has been less clear how (and indeed whether) word embeddings in and of themselves are useful for constituency parsing. There certainly exist competitive parsers that internally represent lexical items as real-valued vectors, such as the neural network-based parser of Henderson (2004), and even parsers which use pre-trained word embeddings to represent the lexicon, such as Socher et al. (2013). In these parsers, however, use of word vectors is a structural choice, rather than an added feature, and i"
P14-2133,P13-1045,0,0.020897,"s from distributional statistics in the form of discrete word clusters (Koo et al., 2008), and recent work (Bansal et al., 2014) suggests that similar gains can be derived from embeddings like the ones used in this paper. It has been less clear how (and indeed whether) word embeddings in and of themselves are useful for constituency parsing. There certainly exist competitive parsers that internally represent lexical items as real-valued vectors, such as the neural network-based parser of Henderson (2004), and even parsers which use pre-trained word embeddings to represent the lexicon, such as Socher et al. (2013). In these parsers, however, use of word vectors is a structural choice, rather than an added feature, and it is difficult to disentangle whether vector-space lexicons are actually more powerful than their discrete analogs—perhaps the performance of neural network parsers comes entirely from the model’s extra-lexical syntactic structure. In order to isolate the contribution from word embeddings, it is useful to demonstrate improvement over a parser that already achieves state-of-the-art performance without vector representations. The fundamental question we want to explore is whether embedding"
P14-2133,P10-1040,0,0.329117,"Missing"
P14-2133,W04-3234,0,0.0358537,"tations of lexical items as points in a real vector space—have a long history in natural language processing, going back at least as far as work on latent semantic analysis (LSA) for information retrieval (Deerwester et al., 1990). While word embeddings can be constructed directly from surface distributional statistics, as in LSA, more sophisticated tools for unsupervised extraction of word representations have recently gained popularity (Collobert et al., 2011; Mikolov et al., 2013a). Semi-supervised and unsupervised models for a variety of core NLP tasks, including named-entity recognition (Freitag, 2004), partof-speech tagging (Sch¨utze, 1995), and chunking 822 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 822–827, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics which shows embeddings for a variety of English determiners, projected onto their first two principal components. We can see that the quantifiers each and every cluster together, as do few and most. These are precisely the kinds of distinctions between determiners that state-splitting in the Berkeley parser has shown to be usefu"
P14-2133,P04-1013,0,0.185961,"ompositionally (Hermann and Blunsom, 2013; Andreas and Ghahramani, 2013). Dependency parsers have seen gains from distributional statistics in the form of discrete word clusters (Koo et al., 2008), and recent work (Bansal et al., 2014) suggests that similar gains can be derived from embeddings like the ones used in this paper. It has been less clear how (and indeed whether) word embeddings in and of themselves are useful for constituency parsing. There certainly exist competitive parsers that internally represent lexical items as real-valued vectors, such as the neural network-based parser of Henderson (2004), and even parsers which use pre-trained word embeddings to represent the lexicon, such as Socher et al. (2013). In these parsers, however, use of word vectors is a structural choice, rather than an added feature, and it is difficult to disentangle whether vector-space lexicons are actually more powerful than their discrete analogs—perhaps the performance of neural network parsers comes entirely from the model’s extra-lexical syntactic structure. In order to isolate the contribution from word embeddings, it is useful to demonstrate improvement over a parser that already achieves state-of-the-a"
P14-2133,P13-1088,0,0.0220342,"Missing"
P14-2133,I11-1025,0,0.0686956,"f its weight with a small number of close neighbors, and almost none with words farther away. To exploit this, we pre-compute the k-nearest-neighbor graph of points in the embedding space, and take the sum in Equation 1 only over this set of nearest neighbors. Empirically, taking k = 20 gives adequate performance, and increasing it does not seem to alter the behavior of the parser. As in the OOV model, we also need to worry about how to handle words for which we have no For the experiments in this paper, we will use the Berkeley parser (Petrov and Klein, 2007) and the related Maryland parser (Huang and Harper, 2011). The Berkeley parser induces a latent, statesplit PCFG in which each symbol V of the (observed) X-bar grammar is refined into a set of more specific symbols {V1 , V2 , . . .} which capture more detailed grammatical behavior. This allows the parser to distinguish between words which share the same tag but exhibit very different syntactic behavior—for example, between articles and demonstrative pronouns. The Maryland parser builds on the state-splitting parser, replacing its basic word emission model with a featurerich, log-linear representation of the lexicon. The choice of this parser family"
P14-2133,P08-1068,0,0.345207,"Missing"
P14-2133,N13-1090,0,0.152431,"a variety of ways in which word embeddings might augment a constituency parser with a discrete state space. Word embeddings—representations of lexical items as points in a real vector space—have a long history in natural language processing, going back at least as far as work on latent semantic analysis (LSA) for information retrieval (Deerwester et al., 1990). While word embeddings can be constructed directly from surface distributional statistics, as in LSA, more sophisticated tools for unsupervised extraction of word representations have recently gained popularity (Collobert et al., 2011; Mikolov et al., 2013a). Semi-supervised and unsupervised models for a variety of core NLP tasks, including named-entity recognition (Freitag, 2004), partof-speech tagging (Sch¨utze, 1995), and chunking 822 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 822–827, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics which shows embeddings for a variety of English determiners, projected onto their first two principal components. We can see that the quantifiers each and every cluster together, as do few and most. Thes"
P17-1022,D16-1125,1,0.839691,"nd even communication using natural language messages (Vogel et al., 2013b). All of these approaches employ structured communication schemes with manually engineered messaging protocols; these are, in some sense, automatically interpretable, but at the cost of introducing considerable complexity into both training and inference. Our evaluation in this paper investigates communication strategies that arise in a number of different games, including reference games and an extended-horizon driving game. Communication strategies for reference games were previously explored by Vogel et al. (2013a), Andreas and Klein (2016) and Kazemzadeh et al. (2014), and reference games specifically featuring end-to-end communication protocols by Yu et al. (2016). On the control side, a long line of work considers nonverbal communication strategies in multiagent policies (Dragan and Srinivasa, 2013). Another group of related approaches focuses on the development of more general machinery for interpreting deep models in which messages have no explicit semantics. This includes both visualization techniques (Zeiler and Fergus, 2014; Strobelt et al., 2016), and approaches focused on generating explanations in the form of natural"
P17-1022,W14-4012,0,0.0172249,"Missing"
P17-1022,D14-1086,0,0.0208833,"atural language messages (Vogel et al., 2013b). All of these approaches employ structured communication schemes with manually engineered messaging protocols; these are, in some sense, automatically interpretable, but at the cost of introducing considerable complexity into both training and inference. Our evaluation in this paper investigates communication strategies that arise in a number of different games, including reference games and an extended-horizon driving game. Communication strategies for reference games were previously explored by Vogel et al. (2013a), Andreas and Klein (2016) and Kazemzadeh et al. (2014), and reference games specifically featuring end-to-end communication protocols by Yu et al. (2016). On the control side, a long line of work considers nonverbal communication strategies in multiagent policies (Dragan and Srinivasa, 2013). Another group of related approaches focuses on the development of more general machinery for interpreting deep models in which messages have no explicit semantics. This includes both visualization techniques (Zeiler and Fergus, 2014; Strobelt et al., 2016), and approaches focused on generating explanations in the form of natural language (Hendricks et al., 2"
P17-1022,Q15-1008,0,0.0145022,"ation. Our evaluation considers two kinds of tasks: reference games and navigation games. In a reference game (e.g. Figure 6a), both players observe a pair of candidate referents. A speaker is assigned a target referent; it must communicate this target to a listener, who then performs a choice action corresponding to its belief about the true target. In this paper we consider two variants on the reference game: a simple color-naming task, and a more complex task involving natural images of birds. For examples of human communication strategies for these tasks, we obtain the XKCD color dataset (McMahan and Stone, 2015; Monroe et al., 2016) and the Caltech Birds dataset (Welinder et al., 2010) with accom(b) (a) (c) Figure 6: Tasks used to evaluate the translation model. (a–b) Reference games: both players observe a pair of reference candidates (colors or images); Player a is assigned a target (marked with a star), which player b must guess based on a message from a. (c) Driving game: each car attempts to navigate to its goal (marked with a star). The cars cannot see each other, and must communicate to avoid a collision. panying natural language descriptions (Reed et al., 2016). We use standard train / valid"
P17-1022,D16-1243,0,0.0113975,"siders two kinds of tasks: reference games and navigation games. In a reference game (e.g. Figure 6a), both players observe a pair of candidate referents. A speaker is assigned a target referent; it must communicate this target to a listener, who then performs a choice action corresponding to its belief about the true target. In this paper we consider two variants on the reference game: a simple color-naming task, and a more complex task involving natural images of birds. For examples of human communication strategies for these tasks, we obtain the XKCD color dataset (McMahan and Stone, 2015; Monroe et al., 2016) and the Caltech Birds dataset (Welinder et al., 2010) with accom(b) (a) (c) Figure 6: Tasks used to evaluate the translation model. (a–b) Reference games: both players observe a pair of reference candidates (colors or images); Player a is assigned a target (marked with a star), which player b must guess based on a message from a. (c) Driving game: each car attempts to navigate to its goal (marked with a star). The cars cannot see each other, and must communicate to avoid a collision. panying natural language descriptions (Reed et al., 2016). We use standard train / validation / test splits fo"
P17-1022,P16-1003,0,0.0231119,"sage whose meaning is most similar. The key question is then what form this grounded meaning representation should take. The existing literature suggests two broad approaches: Semantic representation The meaning of a message za is given by its denotations: that is, by the set of world states of which za may be felicitously predicated, given the existing context available to a listener. In probabilistic terms, this says that the meaning of a message za is represented by the distribution p(xa |za , xb ) it induces over speaker states. Examples of this approach include Guerin and Pitt (2001) and Pasupat and Liang (2016). These two approaches can give rise to rather different behaviors. Consider the following example: square few hexagon circle many many The top language (in blue) has a unique name for every kind of shape, while the bottom language (in red) only distinguishes between shapes with few sides and shapes with many sides. Now imagine a simple reference game with the following form: player a is covertly assigned one of these three shapes as a reference target, and communicates that reference to b; b must then pull a lever labeled large or small depending on the size of the target shape. Blue language"
P17-1022,N16-3020,0,0.00784252,"pose to understand neuralese messages by translating them. In this work, we present a simple technique for inducing a dictionary that maps between neuralese message vectors and short natural language strings, given only examples of DCP agents interacting with other agents, and humans interacting with other humans. Natural language already provides a rich set of tools for describing beliefs, observations, and plans—our thesis is that these tools provide a useful complement to the visualization and ablation techniques used in previous work on understanding complex models (Strobelt et al., 2016; Ribeiro et al., 2016). While structurally quite similar to the task of machine translation between pairs of human languages, interpretation of neuralese poses a number of novel challenges. First, there is no natural source of parallel data: there are no bilingual “speakers” of both neuralese and natural language. Second, there may not be a direct correspondence between the strategy employed by humans and DCP agents: even if it were constrained to communicate using natural language, an automated agent might choose to produce a different message from humans in a given state. We tackle both of these challenges by app"
P17-1022,N13-1127,0,0.176177,"tions to learned messages; however, this approach relies on supervised cluster labels and is targeted specifically towards referring expression games. Here we attempt to develop an approach that can handle general multiagent interactions without assuming a prior discrete structure in space of observations. 233 The literature on learning decentralized multiagent policies in general is considerably larger (Bernstein et al., 2002; Dibangoye et al., 2016). This includes work focused on communication in multiagent settings (Roth et al., 2005) and even communication using natural language messages (Vogel et al., 2013b). All of these approaches employ structured communication schemes with manually engineered messaging protocols; these are, in some sense, automatically interpretable, but at the cost of introducing considerable complexity into both training and inference. Our evaluation in this paper investigates communication strategies that arise in a number of different games, including reference games and an extended-horizon driving game. Communication strategies for reference games were previously explored by Vogel et al. (2013a), Andreas and Klein (2016) and Kazemzadeh et al. (2014), and reference game"
P17-1022,P13-2014,0,0.0998908,"tions to learned messages; however, this approach relies on supervised cluster labels and is targeted specifically towards referring expression games. Here we attempt to develop an approach that can handle general multiagent interactions without assuming a prior discrete structure in space of observations. 233 The literature on learning decentralized multiagent policies in general is considerably larger (Bernstein et al., 2002; Dibangoye et al., 2016). This includes work focused on communication in multiagent settings (Roth et al., 2005) and even communication using natural language messages (Vogel et al., 2013b). All of these approaches employ structured communication schemes with manually engineered messaging protocols; these are, in some sense, automatically interpretable, but at the cost of introducing considerable complexity into both training and inference. Our evaluation in this paper investigates communication strategies that arise in a number of different games, including reference games and an extended-horizon driving game. Communication strategies for reference games were previously explored by Vogel et al. (2013a), Andreas and Klein (2016) and Kazemzadeh et al. (2014), and reference game"
P17-1076,Q13-1033,0,0.0155865,", and which easily accommodates both sparse log-linear scoring models (Hall et al., 2014) and deep neural potentials (Henderson, 2004; Ballesteros et al., 2016). The best-performing constituency parsers in the last two years have largely been transition-based rather than global; examples include the models of Dyer et al. (2016), Cross and Huang (2016) and Liu and Zhang (2016). The present work takes many of the insights developed in these models (e.g. the recurrent representation of spans (Kiperwasser and Goldberg, 2016), and the use of a dynamic oracle and exploration policy during training (Goldberg and Nivre, 2013)) and extends these insights to span-oriented models, which support a wider range of decoding procedures. Our approach differs from other recent chart-based neural models (e.g. Durrett and Klein (2015)) in the use of a recurrent input representation, structured loss function, and comparatively simple parameterization of the scoring function. In addition to the globally optimal decoding procedures for which these models were designed, and in contrast to the left-to-right decoder typically employed by transition-based models, our model admits an additional greedy top-to-bottom inference procedur"
P17-1076,P08-1109,0,0.319203,"versity of California, Berkeley {mitchell,jda,klein}@cs.berkeley.edu Abstract outputs. However, transition-based models do not admit fast dynamic programs and require careful feature engineering to support exact search-based inference (Thang et al., 2015). Moreover, models with recurrent state require complex training procedures to benefit from anything other than greedy decoding (Wiseman and Rush, 2016). An alternative line of work focuses on chart parsers, which use log-linear or neural scoring potentials to parameterize a tree-structured dynamic program for maximization or marginalization (Finkel et al., 2008; Durrett and Klein, 2015). These models enjoy a number of appealing formal properties, including support for exact inference and structured loss functions. However, previous chart-based approaches have required considerable scaffolding beyond a simple well-formedness potential, e.g. pre-specification of a complete context-free grammar for generating output structures and initial pruning of the output space with a weaker model (Hall et al., 2014). Additionally, we are unaware of any recent chartbased models that achieve results competitive with the best transition-based models. In this work, w"
P17-1076,P04-1013,0,0.0224012,"in the input space, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely related to ours but targeted at dependency formalisms, and which easily accommodates both sparse log-linear scoring models (Hall et al., 2014) and deep neural potentials (Henderson, 2004; Ballesteros et al., 2016). The best-performing constituency parsers in the last two years have largely been transition-based rather than global; examples include the models of Dyer et al. (2016), Cross and Huang (2016) and Liu and Zhang (2016). The present work takes many of the insights developed in these models (e.g. the recurrent representation of spans (Kiperwasser and Goldberg, 2016), and the use of a dynamic oracle and exploration policy during training (Goldberg and Nivre, 2013)) and extends these insights to span-oriented models, which support a wider range of decoding procedures. Ou"
P17-1076,D16-1211,0,0.0254732,"ce, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely related to ours but targeted at dependency formalisms, and which easily accommodates both sparse log-linear scoring models (Hall et al., 2014) and deep neural potentials (Henderson, 2004; Ballesteros et al., 2016). The best-performing constituency parsers in the last two years have largely been transition-based rather than global; examples include the models of Dyer et al. (2016), Cross and Huang (2016) and Liu and Zhang (2016). The present work takes many of the insights developed in these models (e.g. the recurrent representation of spans (Kiperwasser and Goldberg, 2016), and the use of a dynamic oracle and exploration policy during training (Goldberg and Nivre, 2013)) and extends these insights to span-oriented models, which support a wider range of decoding procedures. Our approach differs from oth"
P17-1076,Q16-1023,0,0.0168907,"e long-distance dependencies and lexical phenomena (Collins, 2003; Klein and Manning, 2003; Petrov and Klein, 2007). By contrast, the approach we have described here continues a recent line of work on direct modeling of correlations in the input space, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely related to ours but targeted at dependency formalisms, and which easily accommodates both sparse log-linear scoring models (Hall et al., 2014) and deep neural potentials (Henderson, 2004; Ballesteros et al., 2016). The best-performing constituency parsers in the last two years have largely been transition-based rather than global; examples include the models of Dyer et al. (2016), Cross and Huang (2016) and Liu and Zhang (2016). The present work takes many of the insights developed in these models (e.g. the recurrent representation of spans (Kiperwasser and Goldbe"
P17-1076,W14-6110,0,0.0412147,"Missing"
P17-1076,P03-1054,1,0.0790107,", 824 Final Parsing Results on Penn Treebank Parser LR LP F1 Durrett and Klein (2015) – – 91.1 Vinyals et al. (2015) – – 88.3 Dyer et al. (2016) – – 89.8 Cross and Huang (2016) 90.5 92.1 91.3 Liu and Zhang (2016) 91.3 92.1 91.7 Best Chart Parser 90.63 92.98 91.79 Best Top-Down Parser 90.35 93.23 91.77 7 Related Work Many early successful approaches to constituency parsing focused on rich modeling of correlations in the output space, typically by engineering proabilistic context-free grammars with state spaces enriched to capture long-distance dependencies and lexical phenomena (Collins, 2003; Klein and Manning, 2003; Petrov and Klein, 2007). By contrast, the approach we have described here continues a recent line of work on direct modeling of correlations in the input space, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely related to ours but targeted"
P17-1076,D14-1082,0,0.248614,"paper presents a minimal but surprisingly effective span-based neural model for constituency parsing. Recent years have seen a great deal of interest in parsing architectures that make use of recurrent neural network (RNN) representations of input sentences (Vinyals et al., 2015). Despite evidence that linear RNN decoders are implicitly able to respect some nontrivial well-formedness constraints on structured outputs (Graves, 2013), researchers have consistently found that the best performance is achieved by systems that explicitly require the decoder to generate well-formed tree structures (Chen and Manning, 2014). There are two general approaches to ensuring this structural consistency. The most common is to encode the output as a sequence of operations within a transition system which constructs trees incrementally. This transforms the parsing problem back into a sequence-to-sequence problem, while making it easy to force the decoder to take only actions guaranteed to produce well-formed 818 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 818–827 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org"
P17-1076,J03-4003,0,0.0304987,"vident, however, 824 Final Parsing Results on Penn Treebank Parser LR LP F1 Durrett and Klein (2015) – – 91.1 Vinyals et al. (2015) – – 88.3 Dyer et al. (2016) – – 89.8 Cross and Huang (2016) 90.5 92.1 91.3 Liu and Zhang (2016) 91.3 92.1 91.7 Best Chart Parser 90.63 92.98 91.79 Best Top-Down Parser 90.35 93.23 91.77 7 Related Work Many early successful approaches to constituency parsing focused on rich modeling of correlations in the output space, typically by engineering proabilistic context-free grammars with state spaces enriched to capture long-distance dependencies and lexical phenomena (Collins, 2003; Klein and Manning, 2003; Petrov and Klein, 2007). By contrast, the approach we have described here continues a recent line of work on direct modeling of correlations in the input space, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely rela"
P17-1076,J93-2004,0,0.0615263,"Missing"
P17-1076,D16-1001,0,0.171489,"mple chart-based neural parser based on independent scoring of labels and spans, and show how this model can be adapted to support a greedy topdown decoding procedure. Our goal is to preserve the basic algorithmic properties of span-oriented (rather than transition-oriented) parse representations, while exploring the extent to which neural representational machinery can replace the additional structure required by existing chart parsers. On the Penn Treebank, our approach outperforms a number of recent models for chart-based and transition-based parsing—including the state-ofthe-art models of Cross and Huang (2016) and Liu and Zhang (2016)—achieving an F1 score of 91.79. We additionally obtain a strong F1 score of 82.23 on the French Treebank. In this work, we present a minimal neural model for constituency parsing based on independent scoring of labels and spans. We show that this model is not only compatible with classical dynamic programming techniques, but also admits a novel greedy top-down inference algorithm based on recursive partitioning of the input. We demonstrate empirically that both prediction schemes are competitive with recent work, and when combined with basic extensions to the scoring"
P17-1076,D16-1137,0,0.022034,"Missing"
P17-1076,N07-1051,1,0.404147,"ts on Penn Treebank Parser LR LP F1 Durrett and Klein (2015) – – 91.1 Vinyals et al. (2015) – – 88.3 Dyer et al. (2016) – – 89.8 Cross and Huang (2016) 90.5 92.1 91.3 Liu and Zhang (2016) 91.3 92.1 91.7 Best Chart Parser 90.63 92.98 91.79 Best Top-Down Parser 90.35 93.23 91.77 7 Related Work Many early successful approaches to constituency parsing focused on rich modeling of correlations in the output space, typically by engineering proabilistic context-free grammars with state spaces enriched to capture long-distance dependencies and lexical phenomena (Collins, 2003; Klein and Manning, 2003; Petrov and Klein, 2007). By contrast, the approach we have described here continues a recent line of work on direct modeling of correlations in the input space, by using rich feature representations to parameterize local potentials that interact with a comparatively unconstrained structured decoder. As noted in the introduction, this class of feature-based tree scoring functions can be implemented with either a linear transition system (Chen and Manning, 2014) or a global decoder (Finkel et al., 2008). Kiperwasser and Goldberg (2016) describe an approach closely related to ours but targeted at dependency formalisms,"
P17-1076,W14-6111,0,0.0196274,"Missing"
P17-1076,P15-1148,0,0.0946059,"Missing"
P17-1076,N03-1033,1,0.16234,"Missing"
P17-1076,P16-1218,0,0.124071,"recurrent neural networks as a starting point, since they have previously been shown to capture contextual information suitable for use in a variety of natural language applications (Bahdanau et al., 2014; Wang et al., 2015) In particular, we run a bidirectional LSTM over the input to obtain context-sensitive forward and backward encodings for each position i, denoted by fi and bi , respectively. Our representation of the span (i, j) is then the concatenatation the vector differences fj − fi and bi − bj . This corresponds to a bidirectional version of the LSTMMinus features first proposed by Wang and Chang (2016). On top of this base, our label and span scoring functions are implemented as one-layer feedforward networks, taking as input the concatenated span difference and producing as output either a vector of label scores or a single span score. More formally, letting sij denote the vector representation of span (i, j), we define 3 Chart Parsing Our basic model is compatible with traditional chart-based dynamic programming. Representing a constituency tree T by its labeled spans, T := {(`t , (it , jt )) : t = 1, . . . , |T |}, we define the score of a tree to be the sum of its constituent label and"
rosenthal-etal-2010-towards,W04-2705,0,\N,Missing
rosenthal-etal-2010-towards,W97-1016,0,\N,Missing
rosenthal-etal-2010-towards,A00-2018,0,\N,Missing
rosenthal-etal-2010-towards,W97-0109,0,\N,Missing
rosenthal-etal-2010-towards,J93-2004,0,\N,Missing
rosenthal-etal-2010-towards,D08-1027,0,\N,Missing
rosenthal-etal-2010-towards,H94-1048,0,\N,Missing
rosenthal-etal-2010-towards,J07-4002,0,\N,Missing
rosenthal-etal-2010-towards,J03-4003,0,\N,Missing
rosenthal-etal-2010-towards,N09-4006,0,\N,Missing
rosenthal-etal-2010-towards,W00-0726,0,\N,Missing
rosenthal-etal-2010-towards,P08-1037,0,\N,Missing
rosenthal-etal-2010-towards,J95-4004,0,\N,Missing
rosenthal-etal-2010-towards,P98-2234,0,\N,Missing
rosenthal-etal-2010-towards,C98-2229,0,\N,Missing
rosenthal-etal-2010-towards,J05-1004,0,\N,Missing
W10-0702,D09-1021,0,0.0133432,"ety of tasks such as information extraction (Hong and Davison, 2009), social networking (Gruhl et al., 2004), and sentiment analysis (Leshed and Kaye, 2006), we are not aware of any previous efforts to gather syntactic data (such as PP attach14 ments) in the genre. Syntactic methods such as POS tagging, parsing and structural disambiguation are commonly used when analyzing well-structured text. Including the use of syntactic information has yielded improvements in accuracy in speech recognition (Chelba and Jelenik, 1998; Collins et al., 2005) and machine translation (DeNeefe and Knight, 2009; Carreras and Collins, 2009). We anticipate that datasets such as ours could be useful for such tasks as well. Amazon’s Mechanical Turk (MTurk) has become very popular for manual annotation tasks and has been shown to perform equally well over labeling tasks such as affect recognition, word similarity, recognizing textual entailment, event temporal ordering and word sense disambiguation, when compared to annotations from experts (Snow et al., 2008). While these tasks were small in scale and intended to demonstrate the viability of annotation via MTurk, it has also proved effective in large-scale tasks including the colle"
W10-0702,P05-1063,0,0.0131239,"text, such as discussion forums and emails, have been studied for a variety of tasks such as information extraction (Hong and Davison, 2009), social networking (Gruhl et al., 2004), and sentiment analysis (Leshed and Kaye, 2006), we are not aware of any previous efforts to gather syntactic data (such as PP attach14 ments) in the genre. Syntactic methods such as POS tagging, parsing and structural disambiguation are commonly used when analyzing well-structured text. Including the use of syntactic information has yielded improvements in accuracy in speech recognition (Chelba and Jelenik, 1998; Collins et al., 2005) and machine translation (DeNeefe and Knight, 2009; Carreras and Collins, 2009). We anticipate that datasets such as ours could be useful for such tasks as well. Amazon’s Mechanical Turk (MTurk) has become very popular for manual annotation tasks and has been shown to perform equally well over labeling tasks such as affect recognition, word similarity, recognizing textual entailment, event temporal ordering and word sense disambiguation, when compared to annotations from experts (Snow et al., 2008). While these tasks were small in scale and intended to demonstrate the viability of annotation v"
W10-0702,D09-1076,0,0.0172095,"ve been studied for a variety of tasks such as information extraction (Hong and Davison, 2009), social networking (Gruhl et al., 2004), and sentiment analysis (Leshed and Kaye, 2006), we are not aware of any previous efforts to gather syntactic data (such as PP attach14 ments) in the genre. Syntactic methods such as POS tagging, parsing and structural disambiguation are commonly used when analyzing well-structured text. Including the use of syntactic information has yielded improvements in accuracy in speech recognition (Chelba and Jelenik, 1998; Collins et al., 2005) and machine translation (DeNeefe and Knight, 2009; Carreras and Collins, 2009). We anticipate that datasets such as ours could be useful for such tasks as well. Amazon’s Mechanical Turk (MTurk) has become very popular for manual annotation tasks and has been shown to perform equally well over labeling tasks such as affect recognition, word similarity, recognizing textual entailment, event temporal ordering and word sense disambiguation, when compared to annotations from experts (Snow et al., 2008). While these tasks were small in scale and intended to demonstrate the viability of annotation via MTurk, it has also proved effective in large-sc"
W10-0702,H94-1048,0,0.0410564,"ntially applicable to any task which can be reliably decomposed into independent judgments that untrained annotators can tackle (e.g., quantifier scoping, conjunction scope). This work is intended as an initial step towards the development of efficient hybrid annotation tools that seamlessly incorporate aggregate human wisdom alongside effective algorithms. 2 Related Work Identifying PP attachments is an essential task for building syntactic parse trees. While this task has been studied using fully-automated systems, many of them rely on parse tree output for predicting potential attachments (Ratnaparkhi et al., 1994; Yeh and Vilain, 1998; Stetina and Nagao, 1997; Zavrel et al., 1997). However, systems that rely on good parses are unlikely to perform well on new genres such as blogs and machine translated texts for which parse tree training data is not readily available. Furthermore, the predominant dataset for evaluating PP attachment is the RRR dataset (Ratnaparkhi et al., 1994) which consists of PP attachment cases from the Wall Street Journal portion of the Penn Treebank. Instead of complete sentences, this dataset consists of sets of the form {V,N1 ,P,N2 } where {P,N2 } is the PP and {V,N1 } are the"
W10-0702,rosenthal-etal-2010-towards,1,0.814923,"disambiguation, when compared to annotations from experts (Snow et al., 2008). While these tasks were small in scale and intended to demonstrate the viability of annotation via MTurk, it has also proved effective in large-scale tasks including the collection of accurate speech transcriptions (Gruenstein et al., 2009). In this paper we explore a method for corpus building on a large scale in order to extend annotation into new domains and genres. We previously evaluated crowdsourced PP attachment annotation by using MTurk workers to reproduce PP attachments from the Wall Street Journal corpus (Rosenthal et al., 2010). The results demonstrated that MTurk workers are capable of identifying PP attachments in newswire text, but the approach used to generate attachment options is dependent on the existing gold-standard parse trees and cannot be used on corpora where parse trees are not available. In this paper, we build on the semiautomated annotation principle while avoiding the dependency on parsers, allowing us to apply this technique to the noisy and informal text found in blogs. 3 System Description Our system must both identify PPs and generate a list of potential attachments for each PP in this section."
W10-0702,D08-1027,0,0.313945,"Missing"
W10-0702,W97-0109,0,0.0275117,"ably decomposed into independent judgments that untrained annotators can tackle (e.g., quantifier scoping, conjunction scope). This work is intended as an initial step towards the development of efficient hybrid annotation tools that seamlessly incorporate aggregate human wisdom alongside effective algorithms. 2 Related Work Identifying PP attachments is an essential task for building syntactic parse trees. While this task has been studied using fully-automated systems, many of them rely on parse tree output for predicting potential attachments (Ratnaparkhi et al., 1994; Yeh and Vilain, 1998; Stetina and Nagao, 1997; Zavrel et al., 1997). However, systems that rely on good parses are unlikely to perform well on new genres such as blogs and machine translated texts for which parse tree training data is not readily available. Furthermore, the predominant dataset for evaluating PP attachment is the RRR dataset (Ratnaparkhi et al., 1994) which consists of PP attachment cases from the Wall Street Journal portion of the Penn Treebank. Instead of complete sentences, this dataset consists of sets of the form {V,N1 ,P,N2 } where {P,N2 } is the PP and {V,N1 } are the potential attachments. This simplification of t"
W10-0702,P98-2234,0,0.0383594,"task which can be reliably decomposed into independent judgments that untrained annotators can tackle (e.g., quantifier scoping, conjunction scope). This work is intended as an initial step towards the development of efficient hybrid annotation tools that seamlessly incorporate aggregate human wisdom alongside effective algorithms. 2 Related Work Identifying PP attachments is an essential task for building syntactic parse trees. While this task has been studied using fully-automated systems, many of them rely on parse tree output for predicting potential attachments (Ratnaparkhi et al., 1994; Yeh and Vilain, 1998; Stetina and Nagao, 1997; Zavrel et al., 1997). However, systems that rely on good parses are unlikely to perform well on new genres such as blogs and machine translated texts for which parse tree training data is not readily available. Furthermore, the predominant dataset for evaluating PP attachment is the RRR dataset (Ratnaparkhi et al., 1994) which consists of PP attachment cases from the Wall Street Journal portion of the Penn Treebank. Instead of complete sentences, this dataset consists of sets of the form {V,N1 ,P,N2 } where {P,N2 } is the PP and {V,N1 } are the potential attachments."
W10-0702,W97-1016,0,0.0176698,"pendent judgments that untrained annotators can tackle (e.g., quantifier scoping, conjunction scope). This work is intended as an initial step towards the development of efficient hybrid annotation tools that seamlessly incorporate aggregate human wisdom alongside effective algorithms. 2 Related Work Identifying PP attachments is an essential task for building syntactic parse trees. While this task has been studied using fully-automated systems, many of them rely on parse tree output for predicting potential attachments (Ratnaparkhi et al., 1994; Yeh and Vilain, 1998; Stetina and Nagao, 1997; Zavrel et al., 1997). However, systems that rely on good parses are unlikely to perform well on new genres such as blogs and machine translated texts for which parse tree training data is not readily available. Furthermore, the predominant dataset for evaluating PP attachment is the RRR dataset (Ratnaparkhi et al., 1994) which consists of PP attachment cases from the Wall Street Journal portion of the Penn Treebank. Instead of complete sentences, this dataset consists of sets of the form {V,N1 ,P,N2 } where {P,N2 } is the PP and {V,N1 } are the potential attachments. This simplification of the PP attachment task"
W10-0702,C98-2229,0,\N,Missing
W10-0702,D07-1112,0,\N,Missing
W11-2127,W05-0909,0,0.828278,"ses), and a corresponding improvement in the percentage of syntactically wellformed subjects under a manual evaluation. The rest of the paper is structured as follows. Section 2 gives a review of research on this topic. Section 3 motivates the approach discussed in Section 4. 227 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 227–236, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics Section 5 presents the results of a set of machine translation experiments using the automatic metrics BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), and a manual-evaluation of subject integrity. Section 6 discusses our conclusions and future plans. 2 Related Work The general approach pursued in this paper—that of using pre-ordering to improve translation output– has been explored by many researchers. Most work has focused on automatically learning reordering rules (Xia and McCord, 2004; Habash, 2007b; Elming, 2008; Elming and Habash, 2009; Dyer and Resnik, 2010). Xia and McCord (2004) describe an approach for translation from French to English, where context-free constituency reordering rules are acquired automatically using source and t"
W11-2127,W10-1735,0,0.313793,"es is still quite poor. Collins et al. (2005), for example, assume that the parse trees they use are correct. While the state-of-the-art in English parsing is fairly good (though far from perfect), this is not the case in other languages, where parsing shows substantial error rates. Moreover, when attempting to reorder so as to bring the source text more grammatically in line with the target language, a bad parse can be disastrous: moving parts of the sentence that shouldn’t be moved, and introducing more distortion error than it is able to correct. To address the problem of noisy parse data, Bisazza and Federico (2010) identify the subject using a chunker, then fuzzify it, creating a lattice in which the translation system has a choice of several different paths, corresponding to re-orderings of different subject spans. In investigating syntax-based reordering for Arabic specifically, Carpuat et al. (2010) show that a syntax-driven reordering of the training data only for the purpose of alignment improvement leads to a substantial improvement in translation quality, but do not report a corresponding improvement when reordering test data in a similar fashion. Interestingly, Bisazza and Federico (2010) report"
W11-2127,P10-2033,1,0.907361,"attempting to reorder so as to bring the source text more grammatically in line with the target language, a bad parse can be disastrous: moving parts of the sentence that shouldn’t be moved, and introducing more distortion error than it is able to correct. To address the problem of noisy parse data, Bisazza and Federico (2010) identify the subject using a chunker, then fuzzify it, creating a lattice in which the translation system has a choice of several different paths, corresponding to re-orderings of different subject spans. In investigating syntax-based reordering for Arabic specifically, Carpuat et al. (2010) show that a syntax-driven reordering of the training data only for the purpose of alignment improvement leads to a substantial improvement in translation quality, but do not report a corresponding improvement when reordering test data in a similar fashion. Interestingly, Bisazza and Federico (2010) report that fuzzy reordering the test data improves MT output, suggesting that fuzzification may be the mechanism necessary to render reordering on test data useful. To the best of our knowledge, nobody has yet used fuzzification to correct the identified subject span of complete Arabic dependency"
W11-2127,P11-2031,0,0.017868,"and left-attachment cases), it is guaranteed to appear as one path through the lattice. 5 5.1 Evaluation 5-gram language model with modified Kneser-Ney smoothing implemented using the SRILM toolkit (Stolcke, 2002). Feature weights were tuned with MERT (Och, 2003) to maximize BLEU on the NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on m"
W11-2127,P05-1066,0,0.388507,"Missing"
W11-2127,N10-1128,0,0.0734522,"Missing"
W11-2127,P08-1115,0,0.0186757,"nslations of up to 10 words are extracted in the Moses phrase table. The same baseline phrase table was used in all experiments. The system’s language model was trained both on the English portion of the training corpus and English Gigaword (Graff and Cieri, 2003). We used a 5 All data is available from the Linguistic Data Consortium: http://www.ldc.upenn.edu. 232 • SPAN A test set with fuzzification through optional reordering on matrix verbs and through fuzzification of the subject span according to the algorithm shown in Section 4.2. Each reordering corpus used Moses’ lattice input format (Dyer et al., 2008) (including the baselines, which had only one path). Results are presented in terms of the standard BLEU metric (Papineni et al., 2002), METEOR metric (Banerjee and Lavie, 2005) and a manual evaluation targeting subject span translation correctness. 5.2 Automatic Evaluation Results Table 2 presents the results for the experiments discussed above. Columns three and Four (Prec-1g and Prec-4g) indicate the corresponding 1-gram and 4-gram (sub-BLEU) precision scores, respectively. System BASE FORCE OPT SPAN BLEU Prec-1g Prec-4g METEOR 47.13 81.91 29.52 53.09 47.03 81.78 29.52 53.11 47.42 81.88 30."
W11-2127,W09-0809,1,0.888195,"Missing"
W11-2127,W08-0406,0,0.0449602,"Missing"
W11-2127,2009.mtsummit-caasl.4,0,0.174897,"eeebank (CATiB) (Habash and Roth, 2009). To answer this question, we examined more servation that even VS-ordered matrix verbs in Arabic are sometimes translated monotonically into English (as, for example, in passive constructions). An alternative explanation may be that since the training data itself is not re-ordered, it is plausible that some re-ordering may cause otherwise good possible matches in the phrase table to not match any more. 3.2 Parser Error The problem of finding correct subject span boundaries for reordering, however, is a particularly difficult one. Both Habash (2007b) and Green et al. (2009) have noted previously that even state-ofthe-art Arabic dependency parsers tend to perform poorly, and we would expect that incorrect boundaries would do more harm than good for translation. In order to determine how to “fix” these spans, it is first necessary to understand the kinds of errors that the parser makes. A set of predicted parses of the NIST MT05 data was compared to the gold parses of the same data set. There are three categories of error the parser can make in identifying subjects: labeling errors, attachment errors and span errors. In labeling errors, the parser either incorrect"
W11-2127,P05-1071,1,0.770901,"ERT (Och, 2003) to maximize BLEU on the NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M word"
W11-2127,P09-2056,1,0.914406,"Missing"
W11-2127,2007.mtsummit-papers.29,1,0.976961,"burgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics Section 5 presents the results of a set of machine translation experiments using the automatic metrics BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), and a manual-evaluation of subject integrity. Section 6 discusses our conclusions and future plans. 2 Related Work The general approach pursued in this paper—that of using pre-ordering to improve translation output– has been explored by many researchers. Most work has focused on automatically learning reordering rules (Xia and McCord, 2004; Habash, 2007b; Elming, 2008; Elming and Habash, 2009; Dyer and Resnik, 2010). Xia and McCord (2004) describe an approach for translation from French to English, where context-free constituency reordering rules are acquired automatically using source and target parses and word alignment. Elming (2008) and Elming and Habash (2009) use a large set of linguistic features to automatically learn reordering rules for English-Danish and English-Arabic; the rules are used to pre-order the input into a lattice of variant orders. Habash (2007b) learns syntactic reordering rules targeting Arabic-English word order di"
W11-2127,P07-2045,0,0.0216307,"04) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103)5 Sentences were reordered only for alignment, following the approach of Carpuat et al. (2010). Parses were obtained using a publicly available parser for Arabic (Marton et al., 2010). GIZA++ was used for word alignment (Och and Ney, 2003) and phrase translations of up to 10 words are extracted in the Moses phrase table. The same baseline phrase table was used in all experiments. The system’s language model was trained both on the English portion of the training corpus and English Gigaword"
W11-2127,W04-3250,0,0.204998,"Missing"
W11-2127,W10-1402,1,0.910449,"Missing"
W11-2127,J03-1002,0,0.00412204,"Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103)5 Sentences were reordered only for alignment, following the approach of Carpuat et al. (2010). Parses were obtained using a publicly available parser for Arabic (Marton et al., 2010). GIZA++ was used for word alignment (Och and Ney, 2003) and phrase translations of up to 10 words are extracted in the Moses phrase table. The same baseline phrase table was used in all experiments. The system’s language model was trained both on the English portion of the training corpus and English Gigaword (Graff and Cieri, 2003). We used a 5 All data is available from the Linguistic Data Consortium: http://www.ldc.upenn.edu. 232 • SPAN A test set with fuzzification through optional reordering on matrix verbs and through fuzzification of the subject span according to the algorithm shown in Section 4.2. Each reordering corpus used Moses’ lattice"
W11-2127,P03-1021,0,0.0247076,"ists of tuples, where each tuple defines a single reordering, and each list of tuples defines a set of spans that must be moved to the left of the matrix verb for one reordering. These re-orderings are then joined together to form the final lattice. If a single-constituent correction to the span exists (except in the aforementioned pathological and left-attachment cases), it is guaranteed to appear as one path through the lattice. 5 5.1 Evaluation 5-gram language model with modified Kneser-Ney smoothing implemented using the SRILM toolkit (Stolcke, 2002). Feature weights were tuned with MERT (Och, 2003) to maximize BLEU on the NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Ramb"
W11-2127,P02-1040,0,0.087095,"the maximum possible using gold parses), and a corresponding improvement in the percentage of syntactically wellformed subjects under a manual evaluation. The rest of the paper is structured as follows. Section 2 gives a review of research on this topic. Section 3 motivates the approach discussed in Section 4. 227 Proceedings of the 6th Workshop on Statistical Machine Translation, pages 227–236, c Edinburgh, Scotland, UK, July 30–31, 2011. 2011 Association for Computational Linguistics Section 5 presents the results of a set of machine translation experiments using the automatic metrics BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), and a manual-evaluation of subject integrity. Section 6 discusses our conclusions and future plans. 2 Related Work The general approach pursued in this paper—that of using pre-ordering to improve translation output– has been explored by many researchers. Most work has focused on automatically learning reordering rules (Xia and McCord, 2004; Habash, 2007b; Elming, 2008; Elming and Habash, 2009; Dyer and Resnik, 2010). Xia and McCord (2004) describe an approach for translation from French to English, where context-free constituency reordering rules are acq"
W11-2127,P08-2030,1,0.810201,"NIST MT06 corpus. MERT was done only for the baseline system; these same weights were used for all experiments to control for the effect of MERT instability. In the future, we plan to experiment with approachspecific optimization and to use recent published suggestions on controlling for optimizer instability (Clark et al., 2011). English data was tokenized using simple punctuation-based rules. Arabic data was segmented with to the Arabic Treebank tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological disambiguator and tokenizer (Habash and Rambow, 2005; Habash, 2007a; Roth et al., 2008). The Arabic text was also Alif/Ya normalized (Habash, 2010). MADAproduced Arabic lemmas were used for word alignment. We compare four settings with predicted parses (as opposed to the gold parse experiments discussed in Section 3): • BASE An un-reordered test set; • FORCE A test set which forced reordering on matrix verbs; • OPT A test set with fuzzification through optional reordering on matrix verbs; and Experimental Setup We used the open-source Moses PSMT toolkit (Koehn et al., 2007). Training data was a newswire (MSA-English) parallel text with 12M words on the Arabic side (LDC2007E103)5"
W11-2127,C04-1073,0,0.306764,"Missing"
W11-2127,C08-1027,0,\N,Missing
W11-2127,D08-1076,0,\N,Missing
W12-2105,andreas-etal-2012-annotating,1,0.874501,"fall into that category of conversational behavior and these Language Uses are used directly as features in a supervised machine learning model to predict whether or not a participant is an influencer. For example, Dialog Patterns contributes the Language Uses Initiative, Irrelevance, Incitation, Investment and Interjection. The Language Uses of the Persuasion and Agreement/Disagreement components are not described in detail in this paper, and instead are treated as black boxes (indicated by solid boxes in Figure 1). We have previously published work on some of these (Biran and Rambow, 2011; Andreas et al., 2012). The remainder of this section describes them briefly and provides the results of evaluations of their performance (in Table 2). The next section describes the features of the Dialog Patterns component. 41 Persuasion This component identifies three Language Uses: Attempt to Persuade, Claims and Argumentation. We define an attempt to persuade as a set of contributions made by a single participant which may be made anywhere within the thread, and which are all concerned with stating and supporting a single claim. The subject of the claim does not matter: an opinion may seem trivial, but the arg"
W13-3211,W02-0109,0,0.0757463,"act linear operations alone. We find a maximum-likelihood estimate for these parameters by minimizing L(Θ, x) = − N X M X 4.1.1 Setup details Noun vectors yi are estimated distributionally from a corpus of approximately 10 million tokens of English-language Wikipedia data (Wikimedia Foundation, 2013). A training set of adjectivenoun pairs are collected automatically from a collection of reference translations originally prepared for a machine translation task. For each foreign sentence we have four reference translations produced by different translators. We assign POS tags to each reference (Loper and Bird, 2002) then add to the training data any adjective that appears exactly once in multiple reference translations, with all the nouns that follow it (e.g. “great success”, “great victory”, “great accomplishment”). We then do the same for repeated nouns and the adjectives that precede them (e.g. “great success”, “huge success”, “tremendous success”). This approach is crude, and the data collected are noisy, featuring such “synonym pairs” as (“incomplete myths”, “incomplete autumns”) and (“similar training”, “province-level training”), as well as occasional pairs which are not adjectivenoun pairs at all"
W13-3211,D10-1115,0,0.344385,"oun pairs (ANs). We describe two different parameter estimation procedures for different kinds of training data. Relation to existing work The approach perhaps most closely related to the present work is the bottom-up account given by Coecke et al. (2010), which has already been discussed in some detail in the preceding section. A regression-based training procedure for a similar model is given by Grefenstette et al. (2013). Other work which takes as its starting point the decision to endow some (or all) lexical items with matrixlike operator semantics include that of Socher et al. (2012) and Baroni and Zamparelli (2010). Indeed, it is possible to think of the model in Baroni and Zamparelli’s paper as corresponding to a training procedure for a special case of this model, in which the positions of both nouns and noun-adjective vectors are fixed in advance, and in 4.1 Learning from matching pairs We begin by training the model on matching pairs. In this setting, we start with a collection N sets of up to M adjective-noun pairs (ai1 , ni1 ), (ai2 , ni2 ), . . . which mean the same thing. We fix the vector space representation yi of each noun ni distributionally, as described below, and find optimal settings for"
W13-3211,D12-1110,0,0.040009,"similarity of adjective-noun pairs (ANs). We describe two different parameter estimation procedures for different kinds of training data. Relation to existing work The approach perhaps most closely related to the present work is the bottom-up account given by Coecke et al. (2010), which has already been discussed in some detail in the preceding section. A regression-based training procedure for a similar model is given by Grefenstette et al. (2013). Other work which takes as its starting point the decision to endow some (or all) lexical items with matrixlike operator semantics include that of Socher et al. (2012) and Baroni and Zamparelli (2010). Indeed, it is possible to think of the model in Baroni and Zamparelli’s paper as corresponding to a training procedure for a special case of this model, in which the positions of both nouns and noun-adjective vectors are fixed in advance, and in 4.1 Learning from matching pairs We begin by training the model on matching pairs. In this setting, we start with a collection N sets of up to M adjective-noun pairs (ai1 , ni1 ), (ai2 , ni2 ), . . . which mean the same thing. We fix the vector space representation yi of each noun ni distributionally, as described bel"
W13-3211,W13-0112,0,0.0129839,"his model by measuring precisely that correlation. In the remainder of this section, we provide evidence of the usefulness of our approach by focusing on measurements of the similarity of adjective-noun pairs (ANs). We describe two different parameter estimation procedures for different kinds of training data. Relation to existing work The approach perhaps most closely related to the present work is the bottom-up account given by Coecke et al. (2010), which has already been discussed in some detail in the preceding section. A regression-based training procedure for a similar model is given by Grefenstette et al. (2013). Other work which takes as its starting point the decision to endow some (or all) lexical items with matrixlike operator semantics include that of Socher et al. (2012) and Baroni and Zamparelli (2010). Indeed, it is possible to think of the model in Baroni and Zamparelli’s paper as corresponding to a training procedure for a special case of this model, in which the positions of both nouns and noun-adjective vectors are fixed in advance, and in 4.1 Learning from matching pairs We begin by training the model on matching pairs. In this setting, we start with a collection N sets of up to M adject"
W13-3211,W11-0131,0,0.0534707,"Missing"
W13-3211,S12-1021,0,0.0177037,"learned in that paper correspond to the inverses of the E matrices used above. Also relevant here is the work of Mitchell and Lapata (2008) and Zanzotto et al. (2010), which provide several alternative procedures for composing distributional representations of words, and Wu et al. (2011), which describes a compositional vector space semantics with an integrated syntactic model. Our work differs from these approaches in requiring only positive examples for training, and in providing a mechanism for generation as well as parsing. Other generative work on vector space semantics includes that of Hermann et al. (2012), which models the distribution of nounnoun compounds. This work differs from the model that paper in attempting to generate complete natural language strings, rather than simply recover distributional representations. In training settings where we allow all positional vectors to be free parameters, it’s possible to view this work as a kind of linear relational embedding (Paccanaro and Hinton, 2002). It differs from that work, obviously, in that we are interested in modeling natural language syntax and semantics rather than arbitrary hierarchical models, and provide a mechanism for realization"
W13-3211,C10-1142,0,0.0999666,"Missing"
W13-3211,P02-1043,0,0.0579313,"e for splitting meanings and their associated categories. 2.3 Generation Our goal in this subsection is to describe a probabilistic generative process by which a vector in a semantic space is realized in natural language. Given a constituent of category X, and a corresponding vector x residing in some SX , we can either generate a lexical item of the appropriate type or probabilistically draw a CCG derivation rooted in X, then independently generate the leaves. For noun-adjective pairs, this can only be done in one way, namely as in (1) (for a detailed account of generative models for CCG see Hockenmaier and Steedman (2002)). We will assume that this CCG derivation tree is observed, and concern ourselves with filling in the appropriate vectors and lexical items. This is a strong independence assumption! It effectively says “the grammatical realization of a concept is independent of its meaning”. We will return to it in Section 6. The adjective-noun model has four groups of parameters: (1) a collection ΘN/N of weight vectors θa for adjectives a, (2) a collection ΘN of weight vectors θn for nouns n, (3) a collection EN/N of adjective matrices Ea for adjectives a, and finally (4) a noise parameter σ 2 . For compact"
W13-3211,P08-1028,0,\N,Missing
W13-3211,P06-4018,0,\N,Missing
W14-1607,J13-2005,1,0.795549,"k, we consider language that deIntroduction This paper introduces a probabilistic model for predicting grounded, real-valued trajectories from natural language text. A long tradition of research in compositional semantics has focused on discrete representations of meaning. The original focus of such work was on logical translation: mapping statements of natural language to a formal language like first-order logic (Zettlemoyer and Collins, 2005) or database queries (Zelle and Mooney, 1996). Subsequent work has integrated this logical translation with interpretation against a symbolic database (Liang et al., 2013). There has been a recent increase in interest in perceptual grounding, where lexical semantics anchor in perceptual variables (points, distances, etc.) derived from images or video. Bruni et al. (2014) describe a procedure for constructing word representations using text- and image-based dis58 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 58–67, c Baltimore, Maryland USA, June 26-27 2014. 2014 Association for Computational Linguistics scribes time-evolving trajectories, and unlike Yu and Siskind (2013), we allow these trajectories to have event substructur"
W14-1607,Q13-1005,0,0.0197985,"te complex. Head59 considerably less formal than the language found in the Wall Street Journal examples, involving disfluency, redundancy and occasionally errors. Nevertheless the underlying structure of this problem and the stock problem are fundamentally similar. In addition to Vogel and Jurafsky, Tellex et al. (2011) give a weakly-supervised model for mapping single sentences to commands, and Branavan et al. (2009) give an alternative reinforcementlearning approach for following long command sequences. An intermediate between this approach and ours is the work of Chen and Mooney (2011) and Artzi and Zettlemoyer (2013), which bootstrap a semantic parser to generate logical forms specifying the output path, rather than predicting the path directly. right round the white water [. . . ] but stay quite close ’cause you don’t otherwise you’re going to be in that stone creek Figure 3: Example map data: a portion of a map, and a single line from a dialog which describes navigation relative to the two visible landmarks. Between them, these tasks span a wide range of linguistic phenomena relevant to grounded semantics, and provide a demonstration of the usefulness and general applicability of our model. While develo"
W14-1607,N07-1051,1,0.547524,"ng model: approx. to V (stocks only) Cartesian prod. of ϕt (T ) with: ϕa (T, Ai , Ai−1 ) ■ I[Ai is aligned] ■ I[Ai−1 is aligned] ■ A1 − Ai−1 (if both aligned) Table 1: Features used for linear parameterization of the grounding model. simplify notation by writing Ti = ϕt (Ti ) and Vi = ϕv (Vi ). As the ultimate prediction task is to produce paths, and not their featurized representations, we will assume that it is also straightforward to compute ϕ−1 v , which projects path features back into the original grounding domain. All parse trees are predicted from input text using the Berkeley Parser (Petrov and Klein, 2007). Feature representations for both trees and paths are simple and largely domain-independent; they are explicitly enumerated in Table 1. The general framework presented here leaves one significant problem unaddressed: given a large state vector encoding properties of multiple objects, how do we resolve an utterance about a single object to the correct subset of indices in the vector? While none of the tasks considered in this paper require an argument resolution step of this kind, interpretation of noun phrases is one of the better-studied problems in compositional semantics (Zelle and Mooney"
W14-1607,P09-1010,0,0.36793,"rization—in this case just a single number describing the total value of the index—but as shown by the headline example in Figure 1, the language used to describe changes in the stock market can be quite complex. Head59 considerably less formal than the language found in the Wall Street Journal examples, involving disfluency, redundancy and occasionally errors. Nevertheless the underlying structure of this problem and the stock problem are fundamentally similar. In addition to Vogel and Jurafsky, Tellex et al. (2011) give a weakly-supervised model for mapping single sentences to commands, and Branavan et al. (2009) give an alternative reinforcementlearning approach for following long command sequences. An intermediate between this approach and ours is the work of Chen and Mooney (2011) and Artzi and Zettlemoyer (2013), which bootstrap a semantic parser to generate logical forms specifying the output path, rather than predicting the path directly. right round the white water [. . . ] but stay quite close ’cause you don’t otherwise you’re going to be in that stone creek Figure 3: Example map data: a portion of a map, and a single line from a dialog which describes navigation relative to the two visible la"
W14-1607,P10-1083,0,0.41456,"nstructing word representations using text- and image-based dis58 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 58–67, c Baltimore, Maryland USA, June 26-27 2014. 2014 Association for Computational Linguistics scribes time-evolving trajectories, and unlike Yu and Siskind (2013), we allow these trajectories to have event substructure, and model temporal ordering. Our class of models generalizes to a variety of different domains: a new color-picking task, a new financial news task, and a more challenging variant of the direction-following task established by Vogel and Jurafsky (2010). As an example of the kinds of phenomena we want to model, consider Figure 1, which shows the value of the Dow Jones Industrial Average over June 3rd and 4th 2008, along with a financial news headline from June 4th. There are several effects of interest here. One phenomenon we want to capture is that the lexical semantics of individual words must be combined: swoon roughly describes a drop while bruising indicates that the drop was severe. We isolate this lexical combination in Section 4, where we consider a limited model of color descriptions (Figure 2). A second phenomenon is that the descr"
W14-1607,P13-1006,0,0.173813,"slation with interpretation against a symbolic database (Liang et al., 2013). There has been a recent increase in interest in perceptual grounding, where lexical semantics anchor in perceptual variables (points, distances, etc.) derived from images or video. Bruni et al. (2014) describe a procedure for constructing word representations using text- and image-based dis58 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 58–67, c Baltimore, Maryland USA, June 26-27 2014. 2014 Association for Computational Linguistics scribes time-evolving trajectories, and unlike Yu and Siskind (2013), we allow these trajectories to have event substructure, and model temporal ordering. Our class of models generalizes to a variety of different domains: a new color-picking task, a new financial news task, and a more challenging variant of the direction-following task established by Vogel and Jurafsky (2010). As an example of the kinds of phenomena we want to model, consider Figure 1, which shows the value of the Dow Jones Industrial Average over June 3rd and 4th 2008, along with a financial news headline from June 4th. There are several effects of interest here. One phenomenon we want to cap"
W14-1607,D10-1040,1,0.900242,"Missing"
W14-1607,N09-1031,0,0.0135557,"ning or end of the trading day. Along with temporal structure, the problem requires a more sophisticated treatment of syntax than the colors case— now we have to identify which subspans of the sentence are associated with each event observed, and determine the correspondence between surface order and actual order in time. The learning of correspondences between text and time series has attracted more interest in natural language generation than in semantics (Yu et al., 2007). Research on natural language processing and stock data, meanwhile, has largely focused on prediction of future events (Kogan et al., 2009). 3 Preliminaries In the experiments that follow, each training example will consist of: – Natural language text, consisting of a constituency parse tree or trees. For a given example, we will denote the associated trees (T1 , T2 , . . .). These are also observed at test time, and used to predict new groundings. – A vector-valued, grounded observation, or a sequence of observations (a path), which we will denote V for a given example. We will further assume that each of these paths has been pre-segmented (discussed in detail in Section 5) into a sequence (V1 , V2 , . . .). These are only obser"
W14-1607,P11-1060,1,\N,Missing
W14-1607,Q13-1016,0,\N,Missing
