2021.sigmorphon-1.25,SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages,2021,-1,-1,43,0,1357,tiago pimentel,"Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"This year's iteration of the SIGMORPHON Shared Task on morphological reinflection focuses on typological diversity and cross-lingual variation of morphosyntactic features. In terms of the task, we enrich UniMorph with new data for 32 languages from 13 language families, with most of them being under-resourced: Kunwinjku, Classical Syriac, Arabic (Modern Standard, Egyptian, Gulf), Hebrew, Amharic, Aymara, Magahi, Braj, Kurdish (Central, Northern, Southern), Polish, Karelian, Livvi, Ludic, Veps, V{\~o}ro, Evenki, Xibe, Tuvan, Sakha, Turkish, Indonesian, Kodi, Seneca, Ash{\'a}ninka, Yanesha, Chukchi, Itelmen, Eibela. We evaluate six systems on the new data and conduct an extensive error analysis of the systems' predictions. Transformer-based models generally demonstrate superior performance on the majority of languages, achieving {\textgreater}90{\%} accuracy on 65{\%} of them. The languages on which systems yielded low accuracy are mainly under-resourced, with a limited amount of data. Most errors made by the systems are due to allomorphy, honorificity, and form variation. In addition, we observe that systems especially struggle to inflect multiword lemmas. The systems also produce misspelled forms or end up in repetitive loops (e.g., RNN-based models). Finally, we report a large drop in systems' performance on previously unseen lemmas."
2021.naacl-main.435,Do {RNN} States Encode Abstract Phonological Alternations?,2021,-1,-1,2,0,1308,miikka silfverberg,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Sequence-to-sequence models have delivered impressive results in word formation tasks such as morphological inflection, often learning to model subtle morphophonological details with limited training data. Despite the performance, the opacity of neural models makes it difficult to determine whether complex generalizations are learned, or whether a kind of separate rote memorization of each morphophonological process takes place. To investigate whether complex alternations are simply memorized or whether there is some level of generalization across related sound changes in a sequence-to-sequence model, we perform several experiments on Finnish consonant gradation{---}a complex set of sound changes triggered in some words by certain suffixes. We find that our models often{---}though not always{---}encode 17 different consonant gradation processes in a handful of dimensions in the RNN. We also show that by scaling the activations in these dimensions we can control whether consonant gradation occurs and the direction of the gradation."
2021.iwclul-1.1,Keyword spotting for audiovisual archival search in Uralic languages,2021,-1,-1,3,1,5841,nils hjortnaes,Proceedings of the Seventh International Workshop on Computational Linguistics of Uralic Languages,0,None
2021.emnlp-main.475,A Large-Scale Study of Machine Translation in {T}urkic Languages,2021,-1,-1,5,0,932,jamshidbek mirzakhalov,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Recent advances in neural machine translation (NMT) have pushed the quality of machine translation systems to the point where they are becoming widely adopted to build competitive systems. However, there is still a large number of languages that are yet to reap the benefits of NMT. In this paper, we provide the first large-scale case study of the practical application of MT in the Turkic language family in order to realize the gains of NMT for Turkic languages under high-resource to extremely low-resource scenarios. In addition to presenting an extensive analysis that identifies the bottlenecks towards building competitive systems to ameliorate data scarcity, our study has several key contributions, including, i) a large parallel corpus covering 22 Turkic languages consisting of common public datasets in combination with new datasets of approximately 1.4 million parallel sentences, ii) bilingual baselines for 26 language pairs, iii) novel high-quality test sets in three different translation domains and iv) human evaluation scores. All models, scripts, and data will be released to the public."
2021.computel-1.8,The Relevance of the Source Language in Transfer Learning for {ASR},2021,-1,-1,4,1,5841,nils hjortnaes,Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,None
2021.computel-1.10,Towards an Open Source Finite-State Morphological Analyzer for Zacatl{\\'a}n-Ahuacatl{\\'a}n-Tepetzintla {N}ahuatl,2021,-1,-1,2,0,11444,robert pugh,Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,None
2021.americasnlp-1.2,A corpus of K{'}iche{'} annotated for morphosyntactic structure,2021,-1,-1,1,1,1394,francis tyers,Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas,0,"This article describes a collection of sentences in K{'}iche{'} annotated for morphology and syntax. K{'}iche{'} is a language in the Mayan language family, spoken in Guatemala. The annotation is done according to the guidelines of the Universal Dependencies project. The corpus consists of a total of 1,433 sentences containing approximately 10,000 tokens and is released under a free/open-source licence. We present a comparison of parsing systems for K{'}iche{'} using this corpus and describe how it can be used for mining linguistic examples."
2021.americasnlp-1.3,Investigating variation in written forms of {N}ahuatl using character-based language models,2021,-1,-1,2,0,11444,robert pugh,Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas,0,"We describe experiments with character-based language modeling for written variants of Nahuatl. Using a standard LSTM model and publicly available Bible translations, we explore how character language models can be applied to the tasks of estimating mutual intelligibility, identifying genetic similarity, and distinguishing written variants. We demonstrate that these simple language models are able to capture similarities and differences that have been described in the linguistic literature."
2021.americasnlp-1.6,A survey of part-of-speech tagging approaches applied to K{'}iche{'},2021,-1,-1,1,1,1394,francis tyers,Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas,0,"We study the performance of several popular neural part-of-speech taggers from the Universal Dependencies ecosystem on Mayan languages using a small corpus of 1435 annotated K{'}iche{'} sentences consisting of approximately 10,000 tokens, with encouraging results: $F_1$ scores 93{\%}+ on lemmatisation, part-of-speech and morphological feature assignment. The high performance motivates a cross-language part-of-speech tagging study, where K{'}iche{'}-trained models are evaluated on two other Mayan languages, Kaqchikel and Uspanteko: performance on Kaqchikel is good, 63-85{\%}, and on Uspanteko modest, 60-71{\%}. Supporting experiments lead us to conclude the relative diversity of morphological features as a plausible explanation for the limiting factors in cross-language tagging performance, providing some direction for future sentence annotation and collection work to support these and other Mayan languages."
2021.americasnlp-1.9,A finite-state morphological analyser for {P}araguayan {G}uaran{\\'\\i},2021,-1,-1,2,0,12324,anastasia kuznetsova,Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas,0,"This article describes the development of morphological analyser for Paraguayan Guaran{\'\i}, agglutinative indigenous language spoken by nearly 6 million people in South America. The implementation of our analyser uses HFST (Helsiki Finite State Technology) and two-level transducer that covers morphotactics and phonological processes occurring in Guaran{\'\i}. We assess the efficacy of the approach on publicly available Wikipedia and Bible corpora and the naive coverage of analyser reaches 86{\%} on Wikipedia and 91{\%} on Bible corpora."
2021.americasnlp-1.14,Expanding {U}niversal {D}ependencies for Polysynthetic Languages: A Case of {S}t. {L}awrence {I}sland {Y}upik,2021,-1,-1,3,0,12330,hyunji park,Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas,0,"This paper describes the development of the first Universal Dependencies (UD) treebank for St. Lawrence Island Yupik, an endangered language spoken in the Bering Strait region. While the UD guidelines provided a general framework for our annotations, language-specific decisions were made necessary by the rich morphology of the polysynthetic language. Most notably, we annotated a corpus at the morpheme level as well as the word level. The morpheme level annotation was conducted using an existing morphological analyzer and manual disambiguation. By comparing the two resulting annotation schemes, we argue that morpheme-level annotation is essential for polysynthetic languages like St. Lawrence Island Yupik. Word-level annotation results in degenerate trees for some Yupik sentences and often fails to capture syntactic relations that can be manifested at the morpheme level. Dependency parsing experiments provide further support for morpheme-level annotation. Implications for UD annotation of other polysynthetic languages are discussed."
2020.udw-1.22,Dependency annotation of noun incorporation in polysynthetic languages,2020,-1,-1,1,1,1394,francis tyers,Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020),0,"This paper describes an approach to annotating noun incorporation in Universal Dependencies. It motivates the need to annotate this particular morphosyntactic phenomenon and justifies it with respect to frequency of the construction. A case study is presented in which the proposed annotation scheme is applied to Chukchi, a language that exhibits noun incorporation. We compare argument encoding in Chukchi, English and Russian and find that while in English and Russian discourse elements are primarily tracked through noun phrases and pronouns, in Chukchi they are tracked through agreement marking and incorporation, with a lesser role for noun phrases."
2020.udw-1.23,{U}niversal {D}ependency Treebank for {X}ibe,2020,-1,-1,4,0,8274,he zhou,Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020),0,"We present our work of constructing the first treebank for the Xibe language following the Universal Dependencies (UD) annotation scheme. Xibe is a low-resourced and severely endangered Tungusic language spoken by the Xibe minority living in the Xinjiang Uygur Autonomous Region of China. We collected 810 sentences so far, including 544 sentences from a grammar book on written Xibe and 266 sentences from Cabcal News. We annotated those sentences manually from scratch. In this paper, we report the procedure of building this treebank and analyze several important annotation issues of our treebank. Finally, we propose our plans for future work."
2020.sltu-1.47,Improving the Language Model for Low-Resource {ASR} with Online Text Corpora,2020,-1,-1,5,1,5841,nils hjortnaes,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),0,"In this paper, we expand on previous work on automatic speech recognition in a low-resource scenario typical of data collected by field linguists. We train DeepSpeech models on 35 hours of dialectal Komi speech recordings and correct the output using language models constructed from various sources. Previous experiments showed that transfer learning using DeepSpeech can improve the accuracy of a speech recognizer for Komi, though the error rate remained very high. In this paper we present further experiments with language models created using KenLM from text materials available online. These are constructed from two corpora, one containing literary texts, one for social media content, and another combining the two. We then trained the model using each language model to explore the impact of the language model data source on the speech recognition model. Our results show significant improvements of over 25{\%} in character error rate and nearly 20{\%} in word error rate. This offers important methodological insight into how ASR results can be improved under low-resource conditions: transfer learning can be used to compensate the lack of training data in the target language, and online texts are a very useful resource when developing language models in this context."
2020.sigmorphon-1.1,{SIGMORPHON} 2020 Shared Task 0: Typologically Diverse Morphological Inflection,2020,-1,-1,11,0,1282,ekaterina vylomova,"Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"A broad goal in natural language processing (NLP) is to develop a system that has the capacity to process any natural language. Most systems, however, are developed using data from just one language such as English. The SIGMORPHON 2020 shared task on morphological reinflection aims to investigate systems{'} ability to generalize across typologically distinct languages, many of which are low resource. Systems were developed using data from 45 languages and just 5 language families, fine-tuned with data from an additional 45 languages and 10 language families (13 in total), and evaluated on all 90 languages. A total of 22 systems (19 neural) from 10 teams were submitted to the task. All four winning systems were neural (two monolingual transformers and two massively multilingual RNN-based models with gated attention). Most teams demonstrate utility of data hallucination and augmentation, ensembles, and multilingual training for low-resource languages. Non-neural learners and manually designed grammars showed competitive and even superior performance on some languages (such as Ingrian, Tajik, Tagalog, Zarma, Lingala), especially with very limited data. Some language families (Afro-Asiatic, Niger-Congo, Turkic) were relatively easy for most systems and achieved over 90{\%} mean accuracy while others were more challenging."
2020.lrec-1.314,A Finite-State Morphological Analyser for {E}venki,2020,-1,-1,3,0,17285,anna zueva,Proceedings of the 12th Language Resources and Evaluation Conference,0,"It has been widely admitted that morphological analysis is an important step in automated text processing for morphologically rich languages. Evenki is a language with rich morphology, therefore a morphological analyser is highly desirable for processing Evenki texts and developing applications for Evenki. Although two morphological analysers for Evenki have already been developed, they are able to analyse less than a half of the available Evenki corpora. The aim of this paper is to create a new morphological analyser for Evenki. It is implemented using the Helsinki Finite-State Transducer toolkit (HFST). The lexc formalism is used to specify the morphotactic rules, which define the valid orderings of morphemes in a word. Morphophonological alternations and orthographic rules are described using the twol formalism. The lexicon is extracted from available machine-readable dictionaries. Since a part of the corpora belongs to texts in Evenki dialects, a version of the analyser with relaxed rules is developed for processing dialectal features. We evaluate the analyser on available Evenki corpora and estimate precision, recall and F-score. We obtain coverage scores of between 61{\%} and 87{\%} on the available Evenki corpora."
2020.lrec-1.474,An Unsupervised Method for Weighting Finite-state Morphological Analyzers,2020,-1,-1,2,0,15938,amr keleg,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Morphological analysis is one of the tasks that have been studied for years. Different techniques have been used to develop models for performing morphological analysis. Models based on finite state transducers have proved to be more suitable for languages with low available resources. In this paper, we have developed a method for weighting a morphological analyzer built using finite state transducers in order to disambiguate its results. The method is based on a word2vec model that is trained in a completely unsupervised way using raw untagged corpora and is able to capture the semantic meaning of the words. Most of the methods used for disambiguating the results of a morphological analyzer relied on having tagged corpora that need to manually built. Additionally, the method developed uses information about the token irrespective of its context unlike most of the other techniques that heavily rely on the word{'}s context to disambiguate its set of candidate analyses."
2020.lrec-1.497,{U}niversal {D}ependencies v2: An Evergrowing Multilingual Treebank Collection,2020,17,3,8,0,10682,joakim nivre,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. The annotation consists in a linguistically motivated word segmentation; a morphological layer comprising lemmas, universal part-of-speech tags, and standardized morphological features; and a syntactic layer focusing on syntactic relations between predicates, arguments and modifiers. In this paper, we describe version 2 of the universal guidelines (UD v2), discuss the major changes from UD v1 to UD v2, and give an overview of the currently available treebanks for 90 languages."
2020.lrec-1.520,Common Voice: A Massively-Multilingual Speech Corpus,2020,-1,-1,9,0,17697,rosana ardila,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The Common Voice corpus is a massively-multilingual collection of transcribed speech intended for speech technology research and development. Common Voice is designed for Automatic Speech Recognition purposes but can be useful in other domains (e.g. language identification). To achieve scale and sustainability, the Common Voice project employs crowdsourcing for both data collection and data validation. The most recent release includes 29 languages, and as of November 2019 there are a total of 38 languages collecting data. Over 50,000 individuals have participated so far, resulting in 2,500 hours of collected audio. To our knowledge this is the largest audio corpus in the public domain for speech recognition, both in terms of number of hours and number of languages. As an example use case for Common Voice, we present speech recognition experiments using Mozilla{'}s DeepSpeech Speech-to-Text toolkit. By applying transfer learning from a source English model, we find an average Character Error Rate improvement of 5.99 {\mbox{$\pm$}} 5.48 for twelve target languages (German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton, Tatar, Chuvash, and Kabyle). For most of these languages, these are the first ever published results on end-to-end Automatic Speech Recognition."
2020.iwclul-1.2,Effort-value payoff in lemmatisation for Uralic languages,2020,-1,-1,3,0,12322,nick howell,Proceedings of the Sixth International Workshop on Computational Linguistics of Uralic Languages,0,None
2020.iwclul-1.5,"Towards a Speech Recognizer for {K}omi, an Endangered and Low-Resource Uralic Language",2020,-1,-1,4,1,5841,nils hjortnaes,Proceedings of the Sixth International Workshop on Computational Linguistics of Uralic Languages,0,None
W19-6904,Development of a {U}niversal {D}ependencies treebank for {W}elsh,2019,-1,-1,2,0,8201,johannes heinecke,Proceedings of the Celtic Language Technology Workshop,0,None
W19-6805,Machine Translation for {C}rimean {T}atar to {T}urkish,2019,-1,-1,2,1,23561,memduh gokirmak,Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages,0,None
W19-6010,A biscriptual morphological transducer for {C}rimean {T}atar,2019,0,0,1,1,1394,francis tyers,Proceedings of the 3rd Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,"This paper describes a weighted finite-state morphological transducer for Crimean Tatar able to analyse and generate in both Latin and Cyrillic orthographies. This transducer was developed by a team including a community member and language expert, a field linguist who works with the community, a Turkologist with computational linguistics expertise, and an experienced computational linguist with Turkic expertise.n Dealing with two orthographic systems in the same transducer is challenging as they employ different strategies to deal with the spelling of loan words and encode the full range of the language's phonemes and their interaction. We develop the core transducer using the Latin orthography and then design a separate transliteration transducer to map the surface forms to Cyrillic. To help control the non-determinism in the orthographic mapping, we use weights to prioritise forms seen in the corpus. We perform an evaluation of all components of the system, finding an accuracy above 90% for morphological analysis and near 90% for orthographic conversion. This comprises the state of the art for Crimean Tatar morphological modelling, and, to our knowledge, is the first biscriptual single morphological transducer for any language."
W19-4022,A New Annotation Scheme for the {S}ejong Part-of-speech Tagged Corpus,2019,0,0,2,0,24158,jungyeul park,Proceedings of the 13th Linguistic Annotation Workshop,0,"In this paper we present a new annotation scheme for the Sejong part-of-speech tagged corpus based on Universal Dependencies style annotation. By using a new annotation scheme, we can produce Sejong-style morphological analysis and part-of-speech tagging results which have been the \textit{de facto} standard for Korean language processing. We also explore the possibility of doing named-entity recognition and semantic-role labelling for Korean using the new annotation scheme."
W19-1401,A Report on the Third {V}ar{D}ial Evaluation Campaign,2019,-1,-1,5,0,622,marcos zampieri,"Proceedings of the Sixth Workshop on {NLP} for Similar Languages, Varieties and Dialects",0,"In this paper, we present the findings of the Third VarDial Evaluation Campaign organized as part of the sixth edition of the workshop on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects (VarDial), co-located with NAACL 2019. This year, the campaign included five shared tasks, including one task re-run {--} German Dialect Identification (GDI) {--} and four new tasks {--} Cross-lingual Morphological Analysis (CMA), Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT), Moldavian vs. Romanian Cross-dialect Topic identification (MRC), and Cuneiform Language Identification (CLI). A total of 22 teams submitted runs across the five shared tasks. After the end of the competition, we received 14 system description papers, which are published in the VarDial workshop proceedings and referred to in this report."
W19-0301,Data-Driven Morphological Analysis for Uralic Languages,2019,0,1,2,0,1308,miikka silfverberg,Proceedings of the Fifth International Workshop on Computational Linguistics for Uralic Languages,0,None
R19-1101,Building a Morphological Analyser for {L}az,2019,0,0,2,0,9665,esra onal,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"This study is an attempt to contribute to documentation and revitalization efforts of endangered Laz language, a member of South Caucasian language family mainly spoken on northeastern coastline of Turkey. It constitutes the first steps to create a general computational model for word form recognition and production for Laz by building a rule-based morphological analyser using Helsinki Finite-State Toolkit (HFST). The evaluation results show that the analyser has a 64.9{\%} coverage over a corpus collected for this study with 111,365 tokens. We have also performed an error analysis on randomly selected 100 tokens from the corpus which are not covered by the analyser, and these results show that the errors mostly result from Turkish words in the corpus and missing stems in our lexicon."
W18-6017,Multi-source synthetic treebank creation for improved cross-lingual dependency parsing,2018,0,1,1,1,1394,francis tyers,Proceedings of the Second Workshop on Universal Dependencies ({UDW} 2018),0,"This paper describes a method of creating synthetic treebanks for cross-lingual dependency parsing using a combination of machine translation (including pivot translation), annotation projection and the spanning tree algorithm. Sentences are first automatically translated from a lesser-resourced language to a number of related highly-resourced languages, parsed and then the annotations are projected back to the lesser-resourced language, leading to multiple trees for each sentence from the lesser-resourced language. The final treebank is created by merging the possible trees into a graph and running the spanning tree algorithm to vote for the best tree for each sentence. We present experiments aimed at parsing Faroese using a combination of Danish, Swedish and Norwegian. In a similar experimental setup to the CoNLL 2018 shared task on dependency parsing we report state-of-the-art results on dependency parsing for Faroese using an off-the-shelf parser."
W18-5412,Can {LSTM} Learn to Capture Agreement? The Case of {B}asque,2018,0,7,3,0,4304,shauli ravfogel,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},0,"Sequential neural networks models are powerful tools in a variety of Natural Language Processing (NLP) tasks. The sequential nature of these models raises the questions: to what extent can these models implicitly learn hierarchical structures typical to human language, and what kind of grammatical phenomena can they acquire? We focus on the task of agreement prediction in Basque, as a case study for a task that requires implicit understanding of sentence structure and the acquisition of a complex but consistent morphological system. Analyzing experimental results from two syntactic prediction tasks {--} verb number prediction and suffix recovery {--} we find that sequential models perform worse on agreement prediction in Basque than one might expect on the basis of a previous agreement prediction work in English. Tentative findings based on diagnostic classifiers suggest the network makes use of local heuristics as a proxy for the hierarchical structure of the sentence. We propose the Basque agreement prediction task as challenging benchmark for models that attempt to learn regularities in human language."
W18-4804,A prototype finite-state morphological analyser for {C}hukchi,2018,-1,-1,2,0,28119,vasilisa andriyanets,Proceedings of the Workshop on Computational Modeling of Polysynthetic Languages,0,"In this article we describe the application of finite-state transducers to the morphological and phonological systems of Chukchi, a polysynthetic language spoken in the north of the Russian Federation. The language exhibits progressive and regressive vowel harmony, productive incorporation and extensive circumfixing. To implement the analyser we use the well-known Helsinki Finite-State Toolkit (HFST). The resulting model covers the majority of the morphological and phonological processes. A brief evaluation carried out on publically-available corpora shows that the coverage of the transducer is between and 53{\%} and 76{\%}. An error evaluation of 100 tokens randomly selected from the corpus, which were not covered by the analyser shows that most of the morphological processes are covered and that the majority of errors are caused by a limited stem lexicon."
W18-0210,Towards an open-source universal-dependency treebank for {E}rzya,2018,0,1,2,0,111,jack rueter,Proceedings of the Fourth International Workshop on Computational Linguistics of Uralic Languages,0,None
L18-1411,Finite-state morphological analysis for {G}agauz,2018,0,0,1,1,1394,francis tyers,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
2018.jeptalnrecital-court.1,A prototype dependency treebank for {B}reton,2018,-1,-1,1,1,1394,francis tyers,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"This paper describes the development of the first syntactically-annotated corpus of Breton. The corpus is part of the Universal Dependencies project. In the paper we describe how the corpus was prepared, some Breton-specific constructions that required special treatment, and in addition we give results for parsing Breton using a number of off-the-shelf data-driven parsers."
W17-7604,{UD} Annotatrix: An annotation tool for {U}niversal {D}ependencies,2017,0,1,1,1,1394,francis tyers,Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories,0,None
W17-7618,Towards a dependency-annotated treebank for {B}ambara,2017,-1,-1,2,0,31178,ekaterina aplonova,Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories,0,None
W17-6509,A Dependency Treebank for {K}urmanji {K}urdish,2017,0,1,2,1,23561,memduh gokirmak,Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017),0,None
W17-4006,Finite-State Morphological Analysis for {M}arathi,2017,0,1,2,0,2707,vinit ravishankar,Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing ({FSMNLP} 2017),0,None
W17-0607,Annotation schemes in {N}orth {S}{\\'a}mi dependency parsing,2017,0,0,1,1,1394,francis tyers,Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages,0,None
W17-0214,{N}orth-{S}{\\'a}mi to {F}innish rule-based machine translation system,2017,0,0,2,0,2235,tommi pirinen,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0215,Machine translation with North Saami as a pivot language,2017,0,0,7,0,27598,lene antonsen,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
K17-3001,{C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2017,28,32,11,0,5828,daniel zeman,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
E17-5001,{U}niversal {D}ependencies,2017,0,3,4,0,10682,joakim nivre,Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Tutorial Abstracts,0,"Universal Dependencies (UD) is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages. This tutorial gives an introduction to the UD framework and resources, from basic design principles to annotation guidelines and existing treebanks. We also discuss tools for developing and exploiting UD treebanks and survey applications of UD in NLP and linguistics."
L16-1407,A Finite-state Morphological Analyser for Tuvan,2016,0,0,1,1,1394,francis tyers,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"{\textasciitilde}This paper describes the development of free/open-source finite-state morphological transducers for Tuvan, a Turkic language spoken in and around the Tuvan Republic in Russia. The finite-state toolkit used for the work is the Helsinki Finite-State Toolkit (HFST), we use the lexc formalism for modelling the morphotactics and twol formalism for modelling morphophonological alternations. We present a novel description of the morphological combinatorics of pseudo-derivational morphemes in Tuvan. An evaluation is presented which shows that the transducer has a reasonable coverageâaround 93{\%}âon freely-available corpora of the languages, and high precisionâover 99{\%}âon a manually verified test set."
L16-1409,A Finite-State Morphological Analyser for {S}indhi,2016,0,4,2,0,34659,raveesh motlani,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Morphological analysis is a fundamental task in natural-language processing, which is used in other NLP applications such as part-of-speech tagging, syntactic parsing, information retrieval, machine translation, etc. In this paper, we present our work on the development of free/open-source finite-state morphological analyser for Sindhi. We have used Apertium{'}s lttoolbox as our finite-state toolkit to implement the transducer. The system is developed using a paradigm-based approach, wherein a paradigm defines all the word forms and their morphological features for a given stem (lemma). We have evaluated our system on the Sindhi Wikipedia corpus and achieved a reasonable coverage of 81{\%} and a precision of over 97{\%}."
C16-1325,{U}niversal {D}ependencies for {T}urkish,2016,9,5,3,0,17617,umut sulubacak,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"The Universal Dependencies (UD) project was conceived after the substantial recent interest in unifying annotation schemes across languages. With its own annotation principles and abstract inventory for parts of speech, morphosyntactic features and dependency relations, UD aims to facilitate multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. This paper presents the Turkish IMST-UD Treebank, the first Turkish treebank to be in a UD release. The IMST-UD Treebank was automatically converted from the IMST Treebank, which was also recently released. We describe this conversion procedure in detail, complete with mapping tables. We also present our evaluation of the parsing performances of both versions of the IMST Treebank. Our findings suggest that the UD framework is at least as viable for Turkish as the original annotation framework of the IMST Treebank."
2016.eamt-2.4,Apertium: a free/open source platform for machine translation and basic language technology,2016,-1,-1,2,0,5037,mikel forcada,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
W15-4918,Evaluating machine translation for assimilation via a gap-filling task,2015,10,2,3,0,36551,ekaterina ageeva,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-4919,Unsupervised training of maximum-entropy models for lexical selection in rule-based machine translation,2015,21,2,1,1,1394,francis tyers,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"This article presents a method of training maximum-entropy models to perform lexical selection in a rule-based machine translation system. The training method described is unsupervised; that is, it does not require any annotated corpus. The method uses source-language monolingual corpora, the machine translation (MT) system in which the models are integrated, and a statistical target-language model. Using the MT system, the sentences in the sourcelanguage corpus are translated in all possible ways according to the different translation equivalents in the bilingual dictionary of the system. These translations are then scored on the target-language model and the scores are normalised to provide fractional counts for training source-language maximum-entropy lexical-selection models. We show that these models can perform equally well, or better, than using the target-language model directly for lexical selection, at a substantially reduced computational cost."
W15-1822,Automatic word stress annotation of {R}ussian unrestricted text,2015,12,4,2,0,34083,robert reynolds,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"We evaluate the effectiveness of finitestate tools we developed for automatically annotating word stress in Russian unrestricted text. This task is relevant for computer-assisted language learning and text-to-speech. To our knowledge, this is the first study to empirically evaluate the results of this task. Given an adequate lexicon with specified stress, the primary obstacle for correct stress placement is disambiguating homographic wordforms. The baseline performance of this task is 90.07%, (known words only, no morphosyntactic disambiguation). Using a constraint grammar to disambiguate homographs, we achieve 93.21% accuracy with minimal errors. For applications with a higher threshold for errors, we achieved 96.15% accuracy by incorporating frequency- based guessing and a simple algorithm for guessing the stress position on unknown words. These results highlight the need for morphosyntactic disambiguation in the word stress placement task for Russian, and set a standard for future research on this task."
W15-1827,Automatic conversion of colloquial Finnishto standard {F}innish,2015,12,1,2,0,11502,inari listenmaa,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper presents a rule-based method for converting between colloquial Finnish and standard Finnish. The method relies upon a small number of orthographical rules combined with a large language model of standard Finnish for ranking the possible conversions. Aside from this contribution, the paper also presents an evaluation corpus consisting of aligned sentences in colloquial Finnish, orthographically-standardised colloquial Finnish and standard Finnish. The method we present outperforms the baseline of simply treating colloquial Finnish as standard Finnish, but is outperformed by a phrase-based MT system trained by the evaluation corpus. The paper also presents preliminary results which show promise for using normalisation in the machine translation task."
2015.eamt-1.19,Evaluating machine translation for assimilation via a gap-filling task,2015,10,2,2,0,36551,ekaterina ageeva,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
2015.eamt-1.20,Unsupervised training of maximum-entropy models for lexical selection i in rule-based machine translation,2015,21,2,1,1,1394,francis tyers,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"This article presents a method of training maximum-entropy models to perform lexical selection in a rule-based machine translation system. The training method described is unsupervised; that is, it does not require any annotated corpus. The method uses source-language monolingual corpora, the machine translation (MT) system in which the models are integrated, and a statistical target-language model. Using the MT system, the sentences in the sourcelanguage corpus are translated in all possible ways according to the different translation equivalents in the bilingual dictionary of the system. These translations are then scored on the target-language model and the scores are normalised to provide fractional counts for training source-language maximum-entropy lexical-selection models. We show that these models can perform equally well, or better, than using the target-language model directly for lexical selection, at a substantially reduced computational cost."
W14-4612,Subsegmental language detection in Celtic language text,2014,9,0,2,0,38386,akshay minocha,Proceedings of the First Celtic Language Technology Workshop,0,"This paper describes an experiment to perform language identification on a sub-sentence basis. The typical case of language identification is to detect the language of documents or sentences. However, it may be the case that a single sentence or segment contains more than one language. This is especially the case in texts where code switching occurs."
washington-etal-2014-finite,Finite-state morphological transducers for three Kypchak languages,2014,5,9,3,1,1386,jonathan washington,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper describes the development of free/open-source finite-state morphological transducers for three Turkic languagesâKazakh, Tatar, and Kumykârepresenting one language from each of the three sub-branches of the Kypchak branch of Turkic. The finite-state toolkit used for the work is the Helsinki Finite-State Toolkit (HFST). This paper describes how the development of a transducer for each subsequent closely-related language took less development time. An evaluation is presented which shows that the transducers all have a reasonable coverageâaround 90{\textbackslash}{\%}âon freely available corpora of the languages, and high precision over a manually verified test set."
C14-1073,Why Implementation Matters: Evaluation of an Open-source Constraint Grammar Parser,2014,14,1,2,0,33871,david nemeskey,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In recent years, the problem of finite-state constraint grammar (CG) parsing has received renewed attention. Several compilers have been proposed to convert CG rules to finite-state transducers. While these formalisms serve their purpose as proofs of the concept, the performance of the generated transducers lags behind other CG implementations and taggers. In this paper, we argue that the fault lies with using generic finite-state libraries, and not with the formalisms themselves. We present an open-source implementation that capitalises on the characteristics of CG rule application to improve execution time. On smaller grammars our implementation achieves performance comparable to the current open-source state of the art."
2013.mtsummit-papers.22,A Free/Open-source {K}azakh-{T}atar Machine Translation System,2013,-1,-1,3,0,39404,ilnar salimzyanov,Proceedings of Machine Translation Summit XIV: Papers,0,None
W12-5017,Rule-based Machine Translation between {I}ndonesian and {M}alaysian,2012,10,1,3,0,325,raymond susanto,Proceedings of the 3rd Workshop on South and Southeast {A}sian Natural Language Processing,0,"We describe the development of a bidirectional rule-based machine translation system between Indonesian and Malaysian (id-ms), two closely related Austronesian languages natively spoken by approximately 35 million people. The system is based on the re-use of free and publicly available resources, such as the Apertium machine translation platform and Wikipedia articles. We also present our approaches to overcome the data scarcity problems in both languages by exploiting the morphology similarities between the two."
cortes-etal-2012-free,Free/Open Source Shallow-Transfer Based Machine Translation for {S}panish and {A}ragonese,2012,8,4,3,0,42948,juan cortes,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This article describes the development of a bidirectional shallow-transfer based machine translation system for Spanish and Aragonese, based on the Apertium platform, reusing the resources provided by other translators built for the platform. The system, and the morphological analyser built for it, are both the first resources of their kind for Aragonese. The morphological analyser has coverage of over 80{\textbackslash}{\%}, and is being reused to create a spelling checker for Aragonese. The translator is bidirectional: the Word Error Rate for Spanish to Aragonese is 16.83{\%}, while Aragonese to Spanish is 11.61{\%}."
washington-etal-2012-finite,A finite-state morphological transducer for {K}yrgyz,2012,8,5,3,1,1386,jonathan washington,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper describes the development of a free/open-source finite-state morphological transducer for Kyrgyz. The transducer has been developed for morphological generation for use within a prototype Turkish{\^a}ÂÂKyrgyz machine translation system, but has also been extensively tested for analysis. The finite-state toolkit used for the work was the Helsinki Finite-State Toolkit (HFST). The paper describes some issues in Kyrgyz morphology, the development of the tool, some linguistic issues encountered and how they were dealt with, and which issues are left to resolve. An evaluation is presented which shows that the transducer has medium-level coverage, between 82{\%} and 87{\%} on two freely available corpora of Kyrgyz, and high precision and recall over a manually verified test set."
2012.freeopmt-1.6,A rule-based machine translation system from {S}erbo-{C}roatian to {M}acedonian,2012,-1,-1,2,0,43849,hrvoje peradin,Proceedings of the Third International Workshop on Free/Open-Source Rule-Based Machine Translation,0,"This paper describes the development of a one-way machine translation system from SerboCroatian to Macedonian on the Apertium platform. Details of resources and development methods are given, as well as an evaluation, and general directives for future work."
2012.eamt-1.54,Flexible finite-state lexical selection for rule-based machine translation,2012,21,13,1,1,1394,francis tyers,Proceedings of the 16th Annual conference of the European Association for Machine Translation,0,"In this paper we describe a module (rule formalism, rule compiler and rule processor) designed to provide flexible support for lexical selection in rule-based machine translation. The motivation and implementation for the system is outlined and an efficient algorithm to compute the best coverage of lexical-selection rules over an ambiguous input sentence is described. We provide a demonstration of the module by learning rules for it on a typical training corpus and evaluating against other possible lexicalselection strategies. The inclusion of the module, along with rules learnt from the parallel corpus provides a small, but consistent and statistically-significant improvement over either using the highest-scoring translation according to a target-language model or using the most frequent aligned translation in the parallel corpus which is also found in the systemxe2x80x99s bilingual dictionaries."
2011.freeopmt-1.12,An {I}talian to {C}atalan {RBMT} system reusing data from existing language pairs,2011,16,6,3,0,9426,antonio toral,Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation,0,This paper presents an ItalianâCatalan RBMT system automatically built by combining the linguistic data of the existing pairs Spanish{--}Catalan and Spanish{--}Italian. A lightweight manual postprocessing is carried out in order to fix inconsistencies in the automatically derived dictionaries and to add very frequent words that are missing according to a corpus analysis. The system is evaluated on the KDE4 corpus and outperforms Google Translate by approximately ten absolute points in terms of both TER and GTM.
2011.eamt-1.22,Rapid rule-based machine translation between {D}utch and {A}frikaans,2011,7,8,2,0,44994,pim otte,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"This paper describes the design, development and evaluation of a machine translation system between Dutch and Afrikaans developed over a period of around a month and a half. The system relies heavily on the re-use of existing publically available resources such as Wiktionary, Wikipedia and the Apertium machine translation platform. A method of translating compound words between the languages by means of left-to-right longest match lookup is also introduced and evaluated."
2011.eamt-1.30,Apertium-{I}ce{NLP}: A rule-based {I}celandic to {E}nglish machine translation system,2011,11,10,4,0,44998,martha brandt,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"We describe the development of a prototype of an open source rule-based Icelandic!English MT system, based on the Apertium MT framework and IceNLP, a natural language processing toolkit for Icelandic. Our system, Apertium-IceNLP, is the first system in which the whole morphological and tagging component of Apertium is replaced by modules from an external system. Evaluation shows that the word error rate and the positionindependent word error rate for our prototype is 50.6% and 40.8%, respectively. As expected, this is higher than the corresponding error rates in two publicly available MT systems that we used for comparison. Contrary to our expectations, the error rates of our prototype is also higher than the error rates of a comparable system based solely on Apertium modules. Based on error analysis, we conclude that better translation quality may be achieved by replacing only the tagging component of Apertium with the corresponding module in IceNLP, but leaving morphological analysis to Apertium."
2010.eamt-1.13,Rule-based {B}reton to {F}rench machine translation,2010,5,7,1,1,1394,francis tyers,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,"This paper describes a rule-based machine translation system from Breton to French intended for producing gisting translations. The paper presents a summary of the ongoing development of the system, along with an evaluation of two versions, and some reflection on the use of MT systems for lesser-resourced or minority languages."
2009.freeopmt-1.3,The Apertium machine translation platform: Five years on,2009,24,21,2,0,5037,mikel forcada,Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation,0,"This paper describes Apertium: a free/open-source machine translation platform (engine, toolbox and data), its history, its philosophy of design, its technology, the community of developers, the research and business based on it, and its prospects and challenges, now that it is five years old."
2009.freeopmt-1.4,Matxin: Moving towards language independence,2009,18,5,2,0,42031,aingeru mayor,Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation,0,This paper describes some of the issues found when adapting and extending the Matxin free-software machine translation system to other language pairs. It sketches out some of the characteristics of Matxin and offers some possible solutions to these issues.
2009.freeopmt-1.6,Shallow-transfer rule-based machine translation for {S}wedish to {D}anish,2009,7,8,1,1,1394,francis tyers,Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation,0,"This article describes the development of a shallow-transfer machine translation system from Swedish to Danish in the Apertium platform. It gives details of the resources used, the methods for constructing the system and an evaluation of the translation quality. The quality is found to be comparable with that of current commercial systems, despite the particularly low coverage of the lexicons."
2009.freeopmt-1.8,Development of a morphological analyser for {B}engali,2009,3,9,2,0,47598,abu faridee,Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation,0,"This article describes the development of an open-source morphological analyser for Bengali Language using ô°nitestate technology. First we discuss the challenges of creating a morphological analyser for a highly inô°ectional language like Bengali and then propose a solution to that using lttoolbox, an open-source ô°nite-state toolkit. We then evaluate the performance of our developed system and propose ways of improving it further."
2009.eamt-1.17,Developing Prototypes for Machine Translation between Two {S}ami Languages,2009,6,12,1,1,1394,francis tyers,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"This paper describes the development of two prototype systems for machine translation between North Sami and Lule Sami. Experiments were conducted in rule-based machine translation (RBMT), using the Apertium platform, and statistical machine translation (SMT) using the Mosesdecoder. The experiments show that both approaches have their advantages and disadvantages, and that they can both make use of pre-existing linguistic resources."
2009.eamt-1.29,Rule-Based Augmentation of Training Data in {B}reton-{F}rench Statistical Machine Translation,2009,-1,-1,1,1,1394,francis tyers,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,None
