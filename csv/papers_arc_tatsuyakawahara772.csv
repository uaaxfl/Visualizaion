2021.sigdial-1.20,Multi-Referenced Training for Dialogue Response Generation,2021,-1,-1,2,1,1480,tianyu zhao,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"In open-domain dialogue response generation, a dialogue context can be continued with diverse responses, and the dialogue models should capture such one-to-many relations. In this work, we first analyze the training objective of dialogue models from the view of Kullback-Leibler divergence (KLD) and show that the gap between the real world probability distribution and the single-referenced data{'}s probability distribution prevents the model from learning the one-to-many relations efficiently. Then we explore approaches to multi-referenced training in two aspects. Data-wise, we generate diverse pseudo references from a powerful pretrained model to build multi-referenced data that provides a better approximation of the real-world distribution. Model-wise, we propose to equip variational models with an expressive prior, named linear Gaussian model (LGM). Experimental results of automated evaluation and human evaluation show that the methods yield significant improvements over baselines."
2021.sigdial-1.27,{ERICA}: An Empathetic Android Companion for Covid-19 Quarantine,2021,-1,-1,5,0,1505,etsuko ishii,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Over the past year, research in various domains, including Natural Language Processing (NLP), has been accelerated to fight against the COVID-19 pandemic, yet such research has just started on dialogue systems. In this paper, we introduce an end-to-end dialogue system which aims to ease the isolation of people under self-quarantine. We conduct a control simulation experiment to assess the effects of the user interface: a web-based virtual agent, Nora vs. the android ERICA via a video call. The experimental results show that the android can offer a more valuable user experience by giving the impression of being more empathetic and engaging in the conversation due to its nonverbal information, such as facial expressions and body gestures."
2021.sigdial-1.28,A multi-party attentive listening robot which stimulates involvement from side participants,2021,-1,-1,5,1,1510,koji inoue,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We demonstrate the moderating abilities of a multi-party attentive listening robot system when multiple people are speaking in turns. Our conventional one-on-one attentive listening system generates listener responses such as backchannels, repeats, elaborating questions, and assessments. In this paper, additional robot responses that stimulate a listening user (side participant) to become more involved in the dialogue are proposed. The additional responses elicit assessments and questions from the side participant, making the dialogue more empathetic and lively."
2021.naacl-main.150,Source and Target Bidirectional Knowledge Distillation for End-to-end Speech Translation,2021,-1,-1,2,0,3713,hirofumi inaguma,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"A conventional approach to improving the performance of end-to-end speech translation (E2E-ST) models is to leverage the source transcription via pre-training and joint training with automatic speech recognition (ASR) and neural machine translation (NMT) tasks. However, since the input modalities are different, it is difficult to leverage source language text successfully. In this work, we focus on sequence-level knowledge distillation (SeqKD) from external text-based NMT models. To leverage the full potential of the source language information, we propose backward SeqKD, SeqKD from a target-to-source backward NMT model. To this end, we train a bilingual E2E-ST model to predict paraphrased transcriptions as an auxiliary task with a single decoder. The paraphrases are generated from the translations in bitext via back-translation. We further propose bidirectional SeqKD in which SeqKD from both forward and backward NMT models is combined. Experimental evaluations on both autoregressive and non-autoregressive models show that SeqKD in each direction consistently improves the translation performance, and the effectiveness is complementary regardless of the model capacity."
2020.sigdial-1.15,An Attentive Listening System with Android {ERICA}: Comparison of Autonomous and {WOZ} Interactions,2020,-1,-1,6,1,1510,koji inoue,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We describe an attentive listening system for the autonomous android robot ERICA. The proposed system generates several types of listener responses: backchannels, repeats, elaborating questions, assessments, generic sentimental responses, and generic responses. In this paper, we report a subjective experiment with 20 elderly people. First, we evaluated each system utterance excluding backchannels and generic responses, in an offline manner. It was found that most of the system utterances were linguistically appropriate, and they elicited positive reactions from the subjects. Furthermore, 58.2{\%} of the responses were acknowledged as being appropriate listener responses. We also compared the proposed system with a WOZ system where a human operator was operating the robot. From the subjective evaluation, the proposed system achieved comparable scores in basic skills of attentive listening such as encouragement to talk, focused on the talk, and actively listening. It was also found that there is still a gap between the system and the WOZ for more sophisticated skills such as dialogue understanding, showing interest, and empathy towards the user."
2020.lrec-1.319,Speech Corpus of {A}inu Folklore and End-to-end Speech Recognition for {A}inu Language,2020,33,1,5,0,17293,kohei matsuura,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Ainu is an unwritten language that has been spoken by Ainu people who are one of the ethnic groups in Japan. It is recognized as critically endangered by UNESCO and archiving and documentation of its language heritage is of paramount importance. Although a considerable amount of voice recordings of Ainu folklore has been produced and accumulated to save their culture, only a quite limited parts of them are transcribed so far. Thus, we started a project of automatic speech recognition (ASR) for the Ainu language in order to contribute to the development of annotated language archives. In this paper, we report speech corpus development and the structure and performance of end-to-end ASR for Ainu. We investigated four modeling units (phone, syllable, word piece, and word) and found that the syllable-based model performed best in terms of both word and phone recognition accuracy, which were about 60{\%} and over 85{\%} respectively in speaker-open condition. Furthermore, word and phone accuracy of 80{\%} and 90{\%} has been achieved in a speaker-closed setting. We also found out that a multilingual ASR training with additional speech corpora of English and Japanese further improves the speaker-open test accuracy."
2020.coling-main.359,Topic-relevant Response Generation using Optimal Transport for an Open-domain Dialog System,2020,-1,-1,3,0,21455,shuying zhang,Proceedings of the 28th International Conference on Computational Linguistics,0,"Conventional neural generative models tend to generate safe and generic responses which have little connection with previous utterances semantically and would disengage users in a dialog system. To generate relevant responses, we propose a method that employs two types of constraints - topical constraint and semantic constraint. Under the hypothesis that a response and its context have higher relevance when they share the same topics, the topical constraint encourages the topics of a response to match its context by conditioning response decoding on topic words{'} embeddings. The semantic constraint, which encourages a response to be semantically related to its context by regularizing the decoding objective function with semantic distance, is proposed. Optimal transport is applied to compute a weighted semantic distance between the representation of a response and the context. Generated responses are evaluated by automatic metrics, as well as human judgment, showing that the proposed method can generate more topic-relevant and content-rich responses than conventional models."
2020.acl-main.4,Designing Precise and Robust Dialogue Response Evaluators,2020,21,0,3,1,1480,tianyu zhao,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Automatic dialogue response evaluator has been proposed as an alternative to automated metrics and human evaluation. However, existing automatic evaluators achieve only moderate correlation with human judgement and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation ({\textgreater} 0.6) with human judgement and generalizes robustly to diverse responses and corpora. We open-source the code and data in https://github.com/ZHAOTING/dialog-processing."
W18-5021,A Unified Neural Architecture for Joint Dialog Act Segmentation and Recognition in Spoken Dialog System,2018,0,1,2,1,1480,tianyu zhao,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"In spoken dialog systems (SDSs), dialog act (DA) segmentation and recognition provide essential information for response generation. A majority of previous works assumed ground-truth segmentation of DA units, which is not available from automatic speech recognition (ASR) in SDS. We propose a unified architecture based on neural networks, which consists of a sequence tagger for segmentation and a classifier for recognition. The DA recognition model is based on hierarchical neural networks to incorporate the context of preceding sentences. We investigate sharing some layers of the two components so that they can be trained jointly and learn generalized features from both tasks. An evaluation on the Switchboard Dialog Act (SwDA) corpus shows that the jointly-trained models outperform independently-trained models, single-step models, and other reported results in DA segmentation, recognition, and joint tasks."
W17-5516,"Attentive listening system with backchanneling, response generation and flexible turn-taking",2017,0,8,6,1,1508,divesh lala,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"Attentive listening systems are designed to let people, especially senior people, keep talking to maintain communication ability and mental health. This paper addresses key components of an attentive listening system which encourages users to talk smoothly. First, we introduce continuous prediction of end-of-utterances and generation of backchannels, rather than generating backchannels after end-point detection of utterances. This improves subjective evaluations of backchannels. Second, we propose an effective statement response mechanism which detects focus words and responds in the form of a question or partial repeat. This can be applied to any statement. Moreover, a flexible turn-taking mechanism is designed which uses backchannels or fillers when the turn-switch is ambiguous. These techniques are integrated into a humanoid robot to conduct attentive listening. We test the feasibility of the system in a pilot experiment and show that it can produce coherent dialogues during conversation."
I17-1071,Joint Learning of Dialog Act Segmentation and Recognition in Spoken Dialog Using Neural Networks,2017,12,4,2,1,1480,tianyu zhao,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"Dialog act segmentation and recognition are basic natural language understanding tasks in spoken dialog systems. This paper investigates a unified architecture for these two tasks, which aims to improve the model{'}s performance on both of the tasks. Compared with past joint models, the proposed architecture can (1) incorporate contextual information in dialog act recognition, and (2) integrate models for tasks of different levels as a whole, i.e. dialog act segmentation on the word level and dialog act recognition on the segment level. Experimental results show that the joint training system outperforms the simple cascading system and the joint coding system on both dialog act segmentation and recognition tasks."
W16-4122,Automatic Speech Recognition Errors as a Predictor of {L}2 Listening Difficulties,2016,0,1,3,0,33626,maryam mirzaei,Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity ({CL}4{LC}),0,"This paper investigates the use of automatic speech recognition (ASR) errors as indicators of the second language (L2) learners{'} listening difficulties and in doing so strives to overcome the shortcomings of Partial and Synchronized Caption (PSC) system. PSC is a system that generates a partial caption including difficult words detected based on high speech rate, low frequency, and specificity. To improve the choice of words in this system, and explore a better method to detect speech challenges, ASR errors were investigated as a model of the L2 listener, hypothesizing that some of these errors are similar to those of language learners{'} when transcribing the videos. To investigate this hypothesis, ASR errors in transcription of several TED talks were analyzed and compared with PSC{'}s selected words. Both the overlapping and mismatching cases were analyzed to investigate possible improvement for the PSC system. Those ASR errors that were not detected by PSC as cases of learners{'} difficulties were further analyzed and classified into four categories: homophones, minimal pairs, breached boundaries and negatives. These errors were embedded into the baseline PSC to make the enhanced version and were evaluated in an experiment with L2 learners. The results indicated that the enhanced version, which encompasses the ASR errors addresses most of the L2 learners{'} difficulties and better assists them in comprehending challenging video segments as compared with the baseline."
W16-3625,"Talking with {ERICA}, an autonomous android",2016,4,14,5,1,1510,koji inoue,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
W14-4305,Information Navigation System Based on {POMDP} that Tracks User Focus,2014,21,7,2,1,1439,koichiro yoshino,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"We present a spoken dialogue system for navigating information (such as news articles), and which can engage in small talk. At the core is a partially observable Markov decision process (POMDP), which tracks userxe2x80x99s state and focus of attention. The input to the POMDP is provided by a spoken language understanding (SLU) component implemented with logistic regression (LR) and conditional random fields (CRFs). The POMDP selects one of six action classes; each action class is implemented with its own module."
2014.amta-researchers.18,{J}apanese-to-{E}nglish patent translation system based on domain-adapted word segmentation and post-ordering,2014,35,0,4,0,1440,katsuhito sudoh,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"This paper presents a Japanese-to-English statistical machine translation system specialized for patent translation. Patents are practically useful technical documents, but their translation needs different efforts from general-purpose translation. There are two important problems in the Japanese-to-English patent translation: long distance reordering and lexical translation of many domain-specific terms. We integrated novel lexical translation of domain-specific terms with a syntax-based post-ordering framework that divides the machine translation problem into lexical translation and reordering explicitly for efficient syntax-based translation. The proposed lexical translation consists of a domain-adapted word segmentation and an unknown word transliteration. Experimental results show our system achieves better translation accuracy in BLEU and TER compared to the baseline methods."
I13-1126,Predicate Argument Structure Analysis using Partially Annotated Corpora,2013,32,8,3,1,1439,koichiro yoshino,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We present a novel scheme of predicate argument structure analysis that can be trained from partially annotated corpora. In order to allow partial annotation, this semantic role labeler does not require worddependencyinformation. Theadvantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains."
W12-1601,Multi-modal {S}ensing and Analysis of Poster Conversations: Toward Smart Posterboard,2012,16,7,1,1,1481,tatsuya kawahara,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Conversations in poster sessions in academic events, referred to as poster conversations, pose interesting and challenging topics on multi-modal analysis of multi-party dialogue. This article gives an overview of our project on multi-modal sensing, analysis and understanding of poster conversations. We focus on the audience's feedback behaviors such as non-lexical backchannels (reactive tokens) and noddings as well as joint eye-gaze events by the presenter and the audience. We investigate whether we can predict when and who will ask what kind of questions, and also interest level of the audience. Based on these analyses, we design a smart posterboard which can sense human behaviors and annotate interactions and interest level during poster sessions."
P12-1018,Machine Translation without Words through Substring Alignment,2012,44,27,4,0.465116,834,graham neubig,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper, we demonstrate that accurate machine translation is possible without the concept of words, treating MT as a problem of transformation between character strings. We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character-based translation model, and using this in the phrase-based MT framework. We also propose a look-ahead parsing algorithm and substring-informed prior probabilities to achieve more effective and efficient alignment. In an evaluation, we demonstrate that character-based translation can achieve results that compare to word-based systems while effectively translating unknown and uncommon words over several language pairs."
akiba-etal-2012-designing,Designing an Evaluation Framework for Spoken Term Detection and Spoken Document Retrieval at the {NTCIR}-9 {S}poken{D}oc Task,2012,14,5,4,0.833333,43140,tomoyosi akiba,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We describe the evaluation framework for spoken document retrieval for the IR for the Spoken Documents Task, conducted in the ninth NTCIR Workshop. The two parts of this task were a spoken term detection (STD) subtask and an ad hoc spoken document retrieval subtask (SDR). Both subtasks target search terms, passages and documents included in academic and simulated lectures of the Corpus of Spontaneous Japanese. Seven teams participated in the STD subtask and five in the SDR subtask. The results obtained through the evaluation in the workshop are discussed."
C12-1183,Language Modeling for Spoken Dialogue System based on Filtering using Predicate-Argument Structures,2012,13,0,3,1,1439,koichiro yoshino,Proceedings of {COLING} 2012,0,"We present a novel scheme of language modeling for a spoken dialogue system by effectively filtering query sentences collected via a Web site of wisdom of crowds. Our goal is a speechbased information navigation system by retrieving from backend documents such as Web news. Then, we expect that users make queries that are relevant to the backend documents. The relevance measure can be defined with cross-entropy or perplexity by the language model generated from the documents in a conventional manner. In this article, we propose a novel criteria that considers semantic-level information. It is based on predicate-argument (P-A) pairs and their relevance to the documents (or topic) is defined by a naive Bayes score. Experimental evaluations demonstrate that the proposed relevance measure effectively selects relevant sentences used for a language model, resulting in significant reduction of the word error rate of speech recognition as well as the semantic-level error rate."
W11-2008,Spoken Dialogue System based on Information Extraction using Similarity of Predicate Argument Structures,2011,16,21,3,1,1439,koichiro yoshino,Proceedings of the {SIGDIAL} 2011 Conference,0,"We present a novel scheme of spoken dialogue systems which uses the up-to-date information on the web. The scheme is based on information extraction which is defined by the predicate-argument (P-A) structure and realized by semantic parsing. Based on the information structure, the dialogue system can perform question answering and also proactive information presentation. Feasibility of this scheme is demonstrated with experiments using a domain of baseball news. In order to automatically select useful domain-dependent P-A templates, statistical measures are introduced, resulting to a completely unsupervised learning of the information structure given a corpus. Similarity measures of P-A structures are also introduced to select relevant information. An experimental evaluation shows that the proposed system can make more relevant responses compared with the conventional bag-of-words scheme."
P11-1064,An Unsupervised Model for Joint Phrase Alignment and Extraction,2011,30,61,5,0.465116,834,graham neubig,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present an unsupervised model for joint phrase alignment and extraction using non-parametric Bayesian methods and inversion transduction grammars (ITGs). The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memorizes phrases generated not only by terminal, but also non-terminal symbols. This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase-based machine translation tasks directly from unaligned sentence pairs. Experiments on several language pairs demonstrate that the proposed model matches the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size."
akiba-etal-2008-test,Test Collections for Spoken Document Retrieval from Lecture Audio Data,2008,14,7,4,0.833333,43140,tomoyosi akiba,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The Spoken Document Processing Working Group, which is part of the special interest group of spoken language processing of the Information Processing Society of Japan, is developing a test collection for evaluation of spoken document retrieval systems. A prototype of the test collection consists of a set of textual queries, relevant segment lists, and transcriptions by an automatic speech recognition system, allowing retrieval from the Corpus of Spontaneous Japanese (CSJ). From about 100 initial queries, application of the criteria that a query should have more than five relevant segments that consist of about one minute speech segments yielded 39 queries. Targeting the test collection, an ad hoc retrieval experiment was also conducted to assess the baseline retrieval performance by applying a standard method for spoken document retrieval."
C08-2015,{B}ayes Risk-based Dialogue Management for Document Retrieval System with Speech Interface,2008,5,1,2,1,38434,teruhisa misu,Coling 2008: Companion volume: Posters,0,"We propose an efficient dialogue management for an information navigation system based on a document knowledge base with a spoken dialogue interface. In order to perform robustly for fragmental speech input and erroneous output of an automatic speech recognition (ASR), the system should selectively use N-best hypotheses of ASR and contextual information. The system also has several choices in generating responses or confirmations. In this work, we formulate the optimization of the choices based on a unified criterion: Bayes risk, which is defined based on reward for correct information presentation and penalty for redundant turns. We have evaluated this strategy with a spoken dialogue system which also has questionanswering capability. Effectiveness of the proposed framework was confirmed in the success rate of retrieval and the average number of turns."
P06-2042,Detection of Quotations and Inserted Clauses and Its Application to Dependency Structure Analysis in Spontaneous {J}apanese,2006,4,0,3,0,49924,ryoji hamabe,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Japanese dependency structure is usually represented by relationships between phrasal units called bunsetsus. One of the biggest problems with dependency structure analysis in spontaneous speech is that clause boundaries are ambiguous. This paper describes a method for detecting the boundaries of quotations and inserted clauses and that for improving the dependency accuracy by applying the detected boundaries to dependency structure analysis. The quotations and inserted clauses are determined by using an SVM-based text chunking method that considers information on morphemes, pauses, fillers, etc. The information on automatically analyzed dependency structure is also used to detect the beginning of the clauses. Our evaluation experiment using Corpus of Spontaneous Japanese (CSJ) showed that the automatically estimated boundaries of quotations and inserted clauses helped to improve the accuracy of dependency structure analysis."
uchimoto-etal-2006-dependency,Dependency-structure Annotation to Corpus of Spontaneous {J}apanese,2006,10,3,5,0.159541,30019,kiyotaka uchimoto,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In Japanese, syntactic structure of a sentence is generally represented by the relationship between phrasal units, or bunsetsus inJapanese, based on a dependency grammar. In the same way, thesyntactic structure of a sentence in a large, spontaneous, Japanese-speech corpus, the Corpus of Spontaneous Japanese (CSJ), isrepresented by dependency relationships between bunsetsus. This paper describes the criteria and definitions of dependency relationships between bunsetsus in the CSJ. The dependency structure of the CSJ is investigated, and the difference in the dependency structures ofwritten text and spontaneous speech is discussed in terms of thedependency accuracies obtained by using a corpus-based model. It is shown that the accuracy of automatic dependency-structure analysis canbe improved if characteristic phenomena of spontaneous speech such as self-corrections, basic utterance units in spontaneous speech, and bunsetsus that have no modifiee are detected and used for dependency-structure analysis."
H05-1126,Speech-based Information Retrieval System with Clarification Dialogue Strategy,2005,8,4,2,1,38434,teruhisa misu,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper addresses a dialogue strategy to clarify and constrain the queries for speech-driven document retrieval systems. In spoken dialogue interfaces, users often make utterances before the query is completely generated in their mind; thus input queries are often vague or fragmental. As a result, usually many items are matched. We propose an efficient dialogue framework, where the system dynamically selects an optimal question based on information gain (IG), which represents reduction of matched items. A set of possible questions is prepared using various knowledge sources. As a bottom-up knowledge source, we extract a list of words that can take a number of objects and potentially causes ambiguity, using a dependency structure analysis of the document texts. This is complemented by top-down knowledge sources of metadata and hand-crafted questions. An experimental evaluation showed that the method significantly improved the success rate of retrieval, and all categories of the prepared questions contributed to the improvement."
C04-1158,Efficient Confirmation Strategy for Large-scale Text Retrieval Systems with Spoken Dialogue Interface,2004,14,0,3,0.75,14947,kazunori komatani,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"Adequate confirmation for keywords is indispensable in spoken dialogue systems to eliminate misunderstandings caused by speech recognition errors. Spoken language also inherently includes out-of-domain phrases and redundant expressions such as disfluency, which do not contribute to task achievement. It is necessary to appropriately make confirmation for important portions. However, a set of keywords necessary to achieve the tasks cannot be predefined in retrieval for a largescale knowledge base unlike conventional database query tasks. In this paper, we describe two statistical measures for identifying portions to be confirmed. A relevance score represents the matching degree with the target knowledge base. A significance score detects portions that consequently affect the retrieval results. These measures are defined based on information that is automatically derived from the target knowledge base. An experimental evaluation shows that our method improved the success rate of retrieval by generating confirmation more efficiently than using a conventional confidence measure."
C04-1159,Dependency Structure Analysis and Sentence Boundary Detection in Spontaneous {J}apanese,2004,11,11,3,0,52399,kazuya shitaoka,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper describes a project to detect dependencies between Japanese phrasal units called bunsetsus, and sentence boundaries in a spontaneous speech corpus. In monologues, the biggest problem with dependency structure analysis is that sentence boundaries are ambiguous. In this paper, we propose two methods for improving the accuracy of sentence boundary detection in spontaneous Japanese speech: One is based on statistical machine translation using dependency information and the other is based on text chunking using SVM. An F-measure of 84.9 was achieved for the accuracy of sentence boundary detection by using the proposed methods. The accuracy of dependency structure analysis was also improved from 75.2% to 77.2% by using automatically detected sentence boundaries. The accuracy of dependency structure analysis and that of sentence boundary detection were also improved by interactively using both automatically detected dependency structures and sentence boundaries."
W03-2107,Flexible Spoken Dialogue System based on User Models and Dynamic Generation of {V}oice{XML} Scripts,2003,14,10,4,1,14947,kazunori komatani,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,"We realize a telephone-based collaborative natural language dialogue system. Since natural language involves very various expressions, a large number of VoiceXML scripts need to be prepared to handle all possible input patterns. We realize flexible dialogue management for various user utterances by generating VoiceXML scripts dynamically. Moreover, we address appropriate user modeling in order to generate cooperative responses to each user. Specifically, we set up three dimensions of user models: skill level to the system, knowledge level on the target domain and the degree of hastiness. The models are automatically derived by decision tree learning using real dialogue data collected by the system. Experimental evaluation shows that the cooperative responses adapted to individual users serve as good guidance for novice users without increasing the dialogue duration for skilled users."
P03-2027,Dialog Navigator : A Spoken Dialog {Q}-A System based on Large Text Knowledge Base,2003,7,7,5,0,41987,yoji kiyota,The Companion Volume to the Proceedings of 41st Annual Meeting of the Association for Computational Linguistics,0,"This paper describes a spoken dialog Q-A system as a substitution for call centers. The system is capable of making dialogs for both fixing speech recognition errors and for clarifying vague questions, based on only large text knowledge base. We introduce two measures to make dialogs for fixing recognition errors. An experimental evaluation shows the advantages of these measures."
P03-1033,Flexible Guidance Generation Using User Model in Spoken Dialogue Systems,2003,13,27,3,1,14947,kazunori komatani,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"We address appropriate user modeling in order to generate cooperative responses to each user in spoken dialogue systems. Unlike previous studies that focus on user's knowledge or typical kinds of users, the user model we propose is more comprehensive. Specifically, we set up three dimensions of user models: skill level to the system, knowledge level on the target domain and the degree of hastiness. Moreover, the models are automatically derived by decision tree learning using real dialogue data collected by the system. We obtained reasonable classification accuracy for all dimensions. Dialogue strategies based on the user modeling are implemented in Kyoto city bus information system that has been developed at our laboratory. Experimental evaluation shows that the cooperative responses adaptive to individual users serve as good guidance for novice users without increasing the dialogue duration for skilled users."
lee-etal-2002-continuous,Continuous Speech Recognition Consortium an Open Repository for {CSR} Tools and Models,2002,12,24,2,0,53569,akinobu lee,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"LREC2002: International Conference on Language Resources and Evaluation, May 29-31, 2002, Las Palmas, Canary Islands, Spain."
C02-1152,Efficient Dialogue Strategy to Find Users{'} Intended Items from Information Query Results,2002,16,8,2,1,14947,kazunori komatani,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"We address a dialogue framework that narrows down the user's query results obtained by an information retrieval system. The follow-up dialogue to constrain query results is significant especially with the speech interfaces such as telephones because a lot of query results cannot be presented to the user. The proposed dialogue framework generates guiding questions based on an information theoretic criterion to eliminate retrieved candidates by a spontaneous query without assuming a semantic slot structure. We first describe its concept on general information query tasks, and then deal with a query task on the appliance manual where structured task knowledge is available. A hierarchical confirmation strategy is proposed by making use of a tree structure of the manual, and then three cost functions for selecting optimal question nodes are compared. Experimental evaluation demonstrates that the proposed system helps users find their intended items more efficiently."
itou-etal-2000-ipa,{IPA} {J}apanese Dictation Free Software Project,2000,6,11,3,0,53570,katsunobu itou,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"LREC2000: the 2nd International Conference on Language Resources and Evaluation, May 31 - June 2, 2000, Athens, Greece."
C00-1068,Flexible Mixed-Initiative Dialogue Management using Concept-Level Confidence Measures of Speech Recognizer Output,2000,9,48,2,0,14947,kazunori komatani,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"We present a method to realize flexible mixed-initiative dialogue, in which the system can make effective confirmation and guidance using concept-level confidence measures (CMs) derived from speech recognizer output in order to handle speech recognition errors. We define two concept-level CMs, which are on content-words and on semantic-attributes, using 10-best outputs of the speech recognizer and parsing with phrase-level grammars. Content-word CM is useful for selecting plausible interpretations. Less confident interpretations are given to confirmation process. The strategy improved the interpretation accuracy by 11.5%. Moreover, the semantic-attribute CM is used to estimate user's intention and generates system-initiative guidances even when successful interpretation is not obtained."
