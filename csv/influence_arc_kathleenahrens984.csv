2020.figlang-1.16,W18-0911,0,0.0890963,"taphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from person to person. To tackle such problems, researchers resort to specific domain knowledge (Tsvetkov et al., 2014); lexicons (Mohler et al., 2013; Dodge et al., 2015); supervised methods (Klebanov et al., 2014, 2015, 2016) or using attention-based deep learning models to capture latent patterns (Igam1 http://www.vismet.org/metcor/ documentation/home.html 2 http"
2020.figlang-1.16,Y18-1025,0,0.0277047,"Missing"
2020.figlang-1.16,W14-2302,0,0.456477,"e to interpret/understand complex concepts. On the other hand, as a popular linguistic device, metaphors encode versatile ontological information, which usually involve e.g. domain transfer (Ahrens et al., 2003; Ahrens, 2010; Ahrens and Jiang, 2020), sentiment reverse (Steen et al., 2010) or modality shift (Winter, 2019) etc. Therefore, detecting the metaphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from"
2020.figlang-1.16,W15-1402,0,0.320626,"hors encode versatile ontological information, which usually involve e.g. domain transfer (Ahrens et al., 2003; Ahrens, 2010; Ahrens and Jiang, 2020), sentiment reverse (Steen et al., 2010) or modality shift (Winter, 2019) etc. Therefore, detecting the metaphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from person to person. To tackle such problems, researchers resort to specific domain knowledge (Tsvetkov"
2020.figlang-1.16,P16-2017,0,0.347753,"as a popular linguistic device, metaphors encode versatile ontological information, which usually involve e.g. domain transfer (Ahrens et al., 2003; Ahrens, 2010; Ahrens and Jiang, 2020), sentiment reverse (Steen et al., 2010) or modality shift (Winter, 2019) etc. Therefore, detecting the metaphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from person to person. To tackle such problems, researchers resort"
2020.figlang-1.16,W03-1405,1,0.806458,"and Johnson (1980) in Conceptual Metaphor Theory (CMT), metaphor is not only a property of the language but also a cognitive mechanism that describes our conceptual system. Thus metaphors are devices that transfer the property of one domain to another unrelated or different domain, as in ‘sweet voice’ (use taste to describe sound). Metaphors are prevalent in daily life and play a significant role for people to interpret/understand complex concepts. On the other hand, as a popular linguistic device, metaphors encode versatile ontological information, which usually involve e.g. domain transfer (Ahrens et al., 2003; Ahrens, 2010; Ahrens and Jiang, 2020), sentiment reverse (Steen et al., 2010) or modality shift (Winter, 2019) etc. Therefore, detecting the metaphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and syste"
2020.figlang-1.16,W18-0907,0,0.832024,"653/v1/P17 – EB (embodiment): 2 dimension of nodes representation, including embodiment rating and standard deviation; – EB-diff (embodiment differences): 2 × 5 dimension of node-neighbor pairs (five lexical neighboring words) information. berdiev and Shin, 2018). These methods show different strengths on detecting metaphors, yet each has its respective disadvantages, such as having generalization problems or lack association of their results with the intrinsic properties of metaphors. In addition, the reported performances of metaphor detection so far (around 0.6 F1 in the last shared task) (Leong et al., 2018) are still not promising. This calls for further endeavours in all aspects. In this work, we adopt supervised machine learning algorithms based on four categories of features, which include linguistic norms, ngram-word, -lemma and -pos collocations, word embeddings and cosine similarity between the target nodes and its neighboring words, as well as the strong baselines provided by the organizer of the shared task (Leong et al., 2018; Klebanov et al., 2014, 2015, 2016). Moreover, we use several statistical models and ensemble learning strategies during training and testing so as to test the cro"
2020.figlang-1.16,W13-0904,0,0.0615221,"et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from person to person. To tackle such problems, researchers resort to specific domain knowledge (Tsvetkov et al., 2014); lexicons (Mohler et al., 2013; Dodge et al., 2015); supervised methods (Klebanov et al., 2014, 2015, 2016) or using attention-based deep learning models to capture latent patterns (Igam1 http://www.vismet.org/metcor/ documentation/home.html 2 https://catalog.ldc.upenn.edu/ LDC2014T06 104 Proceedings of the Second Workshop on Figurative Language Processing, pages 104–109 c July 9, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 – EB (embodiment): 2 dimension of nodes representation, including embodiment rating and standard deviation; – EB-diff (embodiment differences): 2 × 5 dimension o"
2020.figlang-1.16,D14-1162,0,0.086523,"utilise distributional vector representation of word meaning to the nodes based on the distributional hypothesis (Firth, 1957; Lenci, 2018). Two pre-trained Word2Vec models (GoogleNews.300d and Internal-W2V.300d (pre-trained using the VUA and TOFEL corpora)) and the GloVe vectors are used. GoogleNews7 in this work is pre-trained using the continuous bag-of-words architecture for computing vector representations of words (Church, 2017). GloVe8 is an unsupervised learning algorithm for obtaining vector representations for words. We use the 300d vectors pre-trained on Wikipedia 2014+Gigaword 5 (Pennington et al., 2014). • B3: baseline 2 and unigrams, pos tag, topic, concreteness ratings between nodes and up and down words respectively (UL + WordNet + CCDB + U + P + T + CUp + CDown) 4 Three traditional classifiers are used for predicting the metaphoricity of the tokens, including Logistic Regression, Linear SVC and a Random Forest Classifier. The Machine Learning experiments are run through utilities in the SciKit-Learn Laboratory (SKLL) (Pedregosa et al., 2011). 9 For parameter tuning, we use grid search to find optimal parameters for the learners. Finally, we set up the following optimized parameters for t"
2020.figlang-1.16,W16-1103,0,0.126763,"verse (Steen et al., 2010) or modality shift (Winter, 2019) etc. Therefore, detecting the metaphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from person to person. To tackle such problems, researchers resort to specific domain knowledge (Tsvetkov et al., 2014); lexicons (Mohler et al., 2013; Dodge et al., 2015); supervised methods (Klebanov et al., 2014, 2015, 2016) or using attention-based deep learn"
2020.figlang-1.16,P14-1024,0,0.66723,"∗ Mingyu Wan1,3 , Kathleen Ahrens2 , Emmanuele Chersoni3 Menghan Jiang3 , Qi Su1 , Rong Xiang4 , Chu-Ren Huang3 1 School of Foreign Languages, Peking University Dept. of English, The Hong Kong Polytechnic University 3 Dept. of Chinese and Bilingual Studies, The Hong Kong Polytechnic University 4 Dept. of Computing, The Hong Kong Polytechnic University ∗ {wanmy , sukia}@pku.edu.cn, {emmanuelechersoni, xiangrong0302}@gmail.com {kathleen.ahrens, menghanengl.jiang, churen.huang}@polyu.edu.hk 2 Abstract processing applications, such as machine translation, dialogue systems and sentiment analysis (Tsvetkov et al., 2014). In this shared task, we aim to detect token-level metaphors from plain texts by focusing on content words (Verbs, Nouns, Adjectives and Adverbs) of two corpora: VUA1 and TOFEL2 . To better understand the intrinsic properties of metaphors and to provide an in-depth analysis to this phenomenon, we propose a linguisticallyenriched model to deal with this task with the use of modality exclusivity and embodiment norms (see details in Section 3). This paper reports a linguistically-enriched method of detecting token-level metaphors for the second shared task on Metaphor Detection. We participate i"
2020.figlang-1.16,W13-0905,0,0.36508,"nd complex concepts. On the other hand, as a popular linguistic device, metaphors encode versatile ontological information, which usually involve e.g. domain transfer (Ahrens et al., 2003; Ahrens, 2010; Ahrens and Jiang, 2020), sentiment reverse (Steen et al., 2010) or modality shift (Winter, 2019) etc. Therefore, detecting the metaphors in texts is essential for capturing the authentic meaning of the texts, which can benefit many natural language Related Work Many approaches have been proposed for automatic detection of metaphors, using features of lexical information (Klebanov et al., 2014; Wilks et al., 2013), semantic classes (Klebanov et al., 2016), concreteness (Klebanov et al., 2015), word associations (Xiao et al., 2016), constructions and frames (Hong, 2016) and systems such as traditional machine learning classifiers (Rai et al., 2016), deep neural networks (Do Dinh and Gurevych, 2016) and sequential models (Bizzoni and Ghanimifard, 2018). Despite many advances in the above work, metaphor detection remains a challenging task. The semantic and ontological differences between metaphorical and non-metaphorical expressions are often subtle and their perception may vary from person to person. To"
2020.paclic-1.12,Y96-1018,1,0.219074,"rise/organization/experimental unit/improvement” were focused by Government in 1997-2001. 3 The change of relationship between clause length and word length The sentence, as the maximal grammatical unit and minimal statement unit, is considered to be a basic linguistic unit in all languages. Chinese sentences are often defined in terms of characteristics of speech (Huang and Shi 2016; Lu 1993). Chao (1968) and Zhu (1982) defined a sentence as an utterance with pauses and intonation changes at its boundaries. A common approach for identifying sentences in syntactically annotated corpora (e.g., Chen et al., 1996; Chen et al., 2003; Huang and Chen, 2017 for Sinica TreeBank) is to mark all segments between punctuation marks that indicate utterance pauses as sentences. Such punctuation marks include commas, semicolons, colon, periods, exclamation marks, and question marks. Wang and Qin (2014) and Chen (1994) also adopted this operational definition and called such units sentence segments. Wang and Qin (2014) considered the lengths of sentence segments to be relevant to language use in Chinese. Sentences (as defined by Chen et al., 2003; Huang and Chen, 2017) and sentence segments (as defined by Chen, 19"
2020.paclic-1.12,W18-4503,0,0.0414161,") throughout their history. Previous studies about language change focused on sound and sound changes, word and word changes mostly. Lieberman et al. (2007) studied the regularization of English verbs over the last 1200 years and how the rate of regularization depends on the frequency of word usage. Lexicostatistics was used to calculate the evolutionary history of a set of related languages and varieties (Bakker et al. 2009, Barbancon et al. 2013). Baker (2011) focused on words that have changed their frequency and meaning in the study of change in British English over the twentieth century. Degaetano-Ortlieb and Teich (2018) have used relative entropy for detection and analysis of periods of diachronic linguistic change. Campos et al. (2020) set a corpus-driven methodology to quantify automatically diachronic language distance between chronological periods of several languages. The results showed that a diachronic language distance based on perplexity detects the linguistic evolution that had already been explained by the historians of the three languages. There is a long tradition of linguistic research on political discourse. Van Dijk’s (1997) definition of political discourse brings together studies focusing o"
chung-etal-2008-extracting,P94-1019,0,\N,Missing
chung-etal-2008-extracting,huang-etal-2004-sinica,1,\N,Missing
L18-1160,Y96-1018,0,0.278151,"e German government. However, these corpora have not been released and made available for public search or free use. Our project proposes the creation of a corpus entitled ‘The HKBU Corpus of Political Speeches’ which is a largescale political database with English and Chinese data and featured search functions; it is convenient for corpus-based research and also available for online free use. Two major design features of the HKBU Corpus of Political Speeches are as follows: 1. The minimal interface of the database website is designed for users to operate easily. Similar to Sinica Corpus 4.0 (Chen et al., 1996), the search functions of our database such as the keyword-incontext (KWIC) search and collocation search can retrieve the lexical frequency and collocation lists which facilitate a corpus-based approach to linguistic analyses. Our database is especially useful for metaphor analysts who are able to search keywords in the source domains and the target domains of a particular metaphor and extract all the data involving the keywords searched into Excel files for further analyses. In addition, the collocation search and left one sort or right one sort functions can contribute to the determination"
O03-1006,W03-1405,1,\N,Missing
O05-5012,W03-1405,1,0.882823,"Missing"
O05-5012,W03-1402,0,0.0406774,"Missing"
O05-5012,alonge-castelli-2002-way,0,0.0549808,"Missing"
O05-5012,alonge-lonneker-2004-metaphors,0,0.0250753,"Missing"
O05-5012,O03-1006,1,0.900504,"Missing"
O05-5012,Y03-1014,1,0.90297,"Missing"
O05-5012,huang-etal-2004-sinica,1,0.873342,"Missing"
O05-5012,W03-1403,0,0.0343296,"Missing"
O05-5012,J04-2002,0,0.0817759,"Missing"
O98-3004,C96-1055,0,0.0585671,"Missing"
O98-3004,J93-2005,0,0.323339,"Missing"
W19-5521,P94-1002,0,0.123522,"Missing"
W19-5521,J06-4003,0,0.118719,"Missing"
W19-5521,A00-2035,0,0.155106,"Missing"
W19-5521,J02-3002,0,0.103879,"Missing"
W19-5521,J97-2002,0,0.253654,"Missing"
W19-5521,C12-2096,0,0.148169,"Missing"
W19-5521,A97-1004,0,0.503091,"Missing"
W19-5521,H89-2048,0,0.0679758,"Missing"
Y00-1012,O98-3003,1,0.886369,"Missing"
Y00-1012,Y99-1005,1,0.782394,"Missing"
Y00-1012,Y96-1018,1,0.890113,"Missing"
Y00-1012,Y99-1004,1,0.873613,"Missing"
Y00-1012,J93-2005,0,0.09282,"Missing"
Y00-1012,O98-3004,1,0.921236,"Missing"
Y00-1012,O00-2004,1,\N,Missing
Y00-1012,O99-1005,1,\N,Missing
Y01-1002,O00-2002,1,\N,Missing
Y03-1014,O03-1006,1,0.355313,"Missing"
Y07-1012,Y96-1018,1,0.802211,"Missing"
Y07-1012,P89-1010,0,0.19873,"iginally designed for psychologists, but later was used extensively by computational linguists. Similarly, corpora such as British National Corpus (BNC), the Academia Sinica Corpus of Mandarin Chinese (Chen et al., 1996) and the Gigaword corpus were also designed for the use of target groups such as lexicographers, linguists, language teachers, language learners, etc. These corpora usually provide some forms of statistical analyses so that users will be able to summarize their research results quickly. For example, many corpora provide collocational measures such as Mutual Information values (Church and Hanks, 1989) so that collocated words can be sorted according to their frequency of co-occurrence. Sketch Engine (Kilgarriff and Tugwell, 2001) is a powerful resource which displays search summary in collocated patterns, as well as according to grammatical relations. However, like many other resources, Sketch Engine is unable to determine which of the results in the list are meaningful linguistically. Therefore, when provided with collocation lists, most linguists report the top “few,” based on their preferences. Some linguists report the top one or two and keep the rest in appendixes. In fact, the curren"
Y07-1015,O00-2001,1,0.879639,"Missing"
Y07-1015,O00-2003,1,0.728097,"ide based on SUMO. First, we collect our data from Sinica Corpus and check their senses from Chinese Wordnet. Next, we take these physical event senses of da3 into SUMO concept system (Huang et al. 2004) to find all possible concepts and distinguish them into different categories. Finally, we analyzed these concepts for semantic features which can help us to compare our analysis with the analysis in Gao’s study (2001). 2. Previous research Regarding verb studies, previous research has focused on VV compound verbs in Modern Chinese (Hong and Huang, 2004), or on near synonyms in Modern Chinese (Chief et al, 2000; Huang et al. 2000; Liu 2002; Tsai, 2002; Huang and Hong, 2005). Also, some scholars have worked on da3 polysemy analyses. Da3 is one if the most frequently used verbs, being ranked 16 in the list of most frequently used verbs in Chinese (Bei and Zhang, 1988). Specifically, Gao * Copyright 2007 by Hong, Jia-Fei, Chu-Ren Huang , Kathleen Ahrens 155 (2001) explored the semantic properties of da3 and its prototypical meaning and categorized its semantic representations to show the systematic patterning of its meaning extensions. 3. Motivation and Goals Language knowledge representation is a mani"
Y07-1015,Y04-1015,1,0.877639,"Missing"
Y07-1015,huang-etal-2004-sinica,1,0.861813,"Missing"
Y07-1015,O00-2002,1,\N,Missing
Y10-1045,O05-5005,0,0.0271875,"hes to present and refer the same target. In WordNet, the definition of a lexically ambiguous word is the ambiguity of an individual word or phrase that can be used (in different contexts) to express two or more different meanings. WordNet researchers also regard polysemy and lexical ambiguity as synonym. In the case of the ∗ Copyright 2010 by Jia-Fei Hong, Sue-Jin Ker, Chu-Ren Huang and Kathleen Ahrens 399 400 Poster Papers previously related lexical ambiguity, several studies have concentrated on the corpus-based and computational perspective included: Peng et al. (2007), Xue et al. (2006), Chen et al. (2005), Moldovan and Novischi (2004) …and so on and they took several different approaches: used the corpus-based approach, an adaptive system, divided the sense of lexically ambiguous word and found the possibility of the senses of a word. Although a suite of heuristical methods are presented for word sense disambiguation of Chinese Wordnet glosses, unfortunately we know of several researchers who use only manual analysis to find out the argumentative roles and predict their semantic features to determine their senses. Therefore, they can’t deal with more quantities of lexically ambiguous words at"
Y10-1045,U06-1008,0,0.021404,"Missing"
Y10-1045,W04-0804,0,0.0422421,"efer the same target. In WordNet, the definition of a lexically ambiguous word is the ambiguity of an individual word or phrase that can be used (in different contexts) to express two or more different meanings. WordNet researchers also regard polysemy and lexical ambiguity as synonym. In the case of the ∗ Copyright 2010 by Jia-Fei Hong, Sue-Jin Ker, Chu-Ren Huang and Kathleen Ahrens 399 400 Poster Papers previously related lexical ambiguity, several studies have concentrated on the corpus-based and computational perspective included: Peng et al. (2007), Xue et al. (2006), Chen et al. (2005), Moldovan and Novischi (2004) …and so on and they took several different approaches: used the corpus-based approach, an adaptive system, divided the sense of lexically ambiguous word and found the possibility of the senses of a word. Although a suite of heuristical methods are presented for word sense disambiguation of Chinese Wordnet glosses, unfortunately we know of several researchers who use only manual analysis to find out the argumentative roles and predict their semantic features to determine their senses. Therefore, they can’t deal with more quantities of lexically ambiguous words at the same time. We consulted Fu"
Y10-1045,C90-2067,0,0.185568,"Missing"
Y10-1045,Y04-1028,1,\N,Missing
Y10-1045,P06-2118,0,\N,Missing
Y10-1045,O05-2006,0,\N,Missing
Y96-1001,O96-1009,1,\N,Missing
