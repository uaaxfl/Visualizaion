2021.computel-1.12,Developing a Shared Task for Speech Processing on Endangered Languages,2021,-1,-1,1,1,11446,ginaanne levow,Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,None
2021.acl-tutorials.5,"Prosody: Models, Methods, and Applications",2021,-1,-1,2,0,1412,nigel ward,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Tutorial Abstracts,0,"Prosody is essential in human interaction, enabling people to show interest, establish rapport, efficiently convey nuances of attitude or intent, and so on. Some applications that exploit prosodic knowledge have recently shown superhuman performance, and in many respects our ability to effectively model prosody is rapidly advancing. This tutorial will overview the computational modeling of prosody, including recent advances and diverse actual and potential applications."
W18-1206,Discovering Phonesthemes with Sparse Regularization,2018,0,2,2,0,4927,nelson liu,Proceedings of the Second Workshop on Subword/Character {LE}vel Models,0,"We introduce a simple method for extracting non-arbitrary form-meaning representations from a collection of semantic vectors. We treat the problem as one of feature selection for a model trained to predict word vectors from subword features. We apply this model to the problem of automatically discovering phonesthemes, which are submorphemic sound clusters that appear in words with similar meaning. Many of our model-predicted phonesthemes overlap with those proposed in the linguistics literature, and we validate our approach with human judgments."
2018.gwc-1.35,Automatic Identification of Basic-Level Categories,2018,11,0,3,0,31052,chad mills,Proceedings of the 9th Global Wordnet Conference,0,"Basic-level categories have been shown to be both psychologically significant and useful in a wide range of practical applications. We build a rule-based system to identify basic-level categories in WordNet, achieving 77{\%} accuracy on a test set derived from prior psychological experiments. With additional annotations we found our system also has low precision, in part due to the existence of many categories that do not fit into the three classes (superordinate, basic-level, and subordinate) relied on in basic-level category research."
W17-0106,{STREAMLI}n{ED} Challenges: Aligning Research Interests with Shared Tasks,2017,12,1,1,1,11446,ginaanne levow,Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages,0,This paper describes the use of Shared Task Evaluation Campaigns by designing tasks that are compelling to speech and natural language processing researchers while addressing technical challenges in language documentation and exploiting growing archives of endangered language data.
W15-5115,Analysis of Dysarthric Speech using Distinctive Feature Recognition,2015,17,5,4,0,13490,ka wong,Proceedings of {SLPAT} 2015: 6th Workshop on Speech and Language Processing for Assistive Technologies,0,"Imprecise articulatory breakdown is one of the characteristics of dysarthric speech. This work attempts to develop a framework to automatically identify problematic articulatory patterns of dysarthric speakers in terms of distinctive features (DFs), which are effective for describing speech production. The identification of problematic articulatory patterns aims to assist speech therapists in developing intervention strategies. A multilayer perceptron (MLP) system is trained with nondysarthric speech data for DF recognition. Agreement rates between the recognized DF values and the canonical values based on phonetic transcriptions are computed. For nondysarthric speech, our system achieves an average agreement rate of 85.7%. The agreement rate of dysarthric speech declines, ranging between 1% to 3% in mild cases, 4% to 7% in moderate cases, and 7% to 12% in severe cases, when compared with non-dysarthric speech. We observe that the DF disagreement patterns are consistent with the analysis of a speech"
S15-2075,{CMILLS}: Adapting Semantic Role Labeling Features to Dependency Parsing,2015,9,0,2,0,31052,chad mills,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"We describe a system for semantic role labeling adapted to a dependency parsing framework. Verb arguments are predicted over nodes in a dependency parse tree instead of nodes in a phrase-structure parse tree. Our system participated in SemEval-2015 shared Task 15, Subtask 1: CPA parsing and achieved an Fscore of 0.516. We adapted features from prior semantic role labeling work to the dependency parsing paradigm, using a series of supervised classifiers to identify arguments of a verb and then assigning syntactic and semantic labels. We found that careful feature selection had a major impact on system performance. However, sparse training data still led rule-based systems like the baseline to be more effective than learning-based approaches."
W12-1811,Bridging Gaps for Spoken Dialog System Frameworks in Instructional Settings,2012,4,1,1,1,11446,ginaanne levow,{NAACL}-{HLT} Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data ({SDCTD} 2012),0,"Spoken dialog systems frameworks fill a crucial role in the spoken dialog systems community by providing resources to lower barriers to entry. However, different user groups have different requirements and expectations for such systems. Here, we consider the particular needs for spoken dialog systems toolkits within an instructional setting. We discuss the challenges for existing systems in meeting these needs and propose strategies to overcome them."
P11-2108,Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport,2011,17,2,2,0,44634,siwei wang,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Verbal feedback is an important information source in establishing interactional rapport. However, predicting verbal feedback across languages is challenging due to language-specific differences, inter-speaker variation, and the relative sparseness and optionality of verbal feedback. In this paper, we employ an approach combining classifier weighting and SMOTE algorithm oversampling to improve verbal feedback prediction in Arabic, English, and Spanish dyadic conversations. This approach improves the prediction of verbal feedback, up to 6-fold, while maintaining a high overall accuracy. Analyzing highly weighted features highlights widespread use of pitch, with more varied use of intensity and duration."
P09-2068,Investigating Pitch Accent Recognition in Non-native Speech,2009,13,5,1,1,11446,ginaanne levow,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"Acquisition of prosody, in addition to vocabulary and grammar, is essential for language learners. However, it has received less attention in instruction. To enable automatic identification and feedback on learners' prosodic errors, we investigate automatic pitch accent labeling for non-native speech. We demonstrate that an acoustic-based context model can achieve accuracies over 79% on binary pitch accent recognition when trained on within-group data. Furthermore, we demonstrate that good accuracies are achieved in cross-group training, where native and near-native training data result in no significant loss of accuracy on non-native test speech. These findings illustrate the potential for automatic feedback in computer-assisted prosody learning."
W08-0213,Studying Discourse and Dialogue with {SIDG}rid,2008,14,1,1,1,11446,ginaanne levow,Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics,0,Teaching Computational Linguistics is inherently multi-disciplinary and frequently poses challenges and provides opportunities in teaching to a student body with diverse educational backgrounds and goals. This paper describes the use of a computational environment (SIDGrid) that facilitates interdisciplinary instruction by providing support for students with little computational background as well as extending the scale of projects accessible to students with more advanced computational skills. The environment facilitates the use of hands-on exercises and is being applied to interdisciplinary instruction in Discourse and Dialogue.
I08-1029,Automatic Prosodic Labeling with Conditional Random Fields and Rich Acoustic Features,2008,20,22,1,1,11446,ginaanne levow,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"Many acoustic approaches to prosodic labeling in English have employed only local classifiers, although text-based classification has employed some sequential models. In this paper we employ linear chain and factorial conditional random fields (CRFs) in conjunction with rich, contextually-based prosodic features, to exploit sequential dependencies and to facilitate integration with lexical features. Integration of lexical and prosodic features improves pitch accent prediction over either feature set alone, and for lower accuracy feature sets, factorial CRF models can improve over linear chain based prediction of pitch accent."
N07-2029,Hybrid Document Indexing with Spectral Embedding,2007,7,1,2,1,49314,irina matveeva,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,Document representation has a large impact on the performance of document retrieval and clustering algorithms. We propose a hybrid document indexing scheme that combines the traditional bag-of-words representation with spectral embedding. This method accounts for the specifics of the document collection and also uses semantic similarity information based on a large scale statistical analysis. Clustering experiments showed improvements over the traditional tf-idf representation and over the spectral methods based solely on the document collection.
D07-1037,Topic Segmentation with Hybrid Document Indexing,2007,20,7,2,1,49314,irina matveeva,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,We present a domain-independent unsupervised topic segmentation approach based on hybrid document indexing. Lexical chains have been successfully employed to evaluate lexical cohesion of text segments and to predict topic boundaries. Our approach is based in the notion of semantic cohesion. It uses spectral embedding to estimate semantic association between content nouns over a span of multiple text segments. Our method significantly outperforms the baseline on the topic segmentation task and achieves performance comparable to state-of-the-art methods that incorporate domain specific information.
2007.sigdial-1.41,{SIDGRID}: A Framework for Distributed and Integrated Multimodal Annotation and Archiving and and Analysis,2007,-1,-1,1,1,11446,ginaanne levow,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,None
W06-3810,Graph-based Generalized Latent Semantic Analysis for Document Representation,2006,8,3,2,1,49314,irina matveeva,Proceedings of {T}ext{G}raphs: the First Workshop on Graph Based Methods for Natural Language Processing,0,"Document indexing and representation of term-document relations are very important for document clustering and retrieval. In this paper, we combine a graph-based dimensionality reduction method with a corpus-based association measure within the Generalized Latent Semantic Analysis framework. We evaluate the graph-based GLSA on the document clustering task."
W06-0115,The Third International {C}hinese Language Processing Bakeoff: Word Segmentation and Named Entity Recognition,2006,4,119,1,1,11446,ginaanne levow,Proceedings of the Fifth {SIGHAN} Workshop on {C}hinese Language Processing,0,The Third International Chinese Language Processing Bakeoff was held in Spring 2006 to assess the state of the art in two important tasks: word segmentation and named entity recognition. Twenty-nine groups submitted result sets in the two tasks across two tracks and a total of five corpora. We found strong results in both tasks as well as continuing challenges.
N06-1029,Unsupervised and Semi-supervised Learning of Tone and Pitch Accent,2006,19,27,1,1,11446,ginaanne levow,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"Recognition of tone and intonation is essential for speech recognition and language understanding. However, most approaches to this recognition task have relied upon extensive collections of manually tagged data obtained at substantial time and financial cost. In this paper, we explore two approaches to tone learning with substantially reductions in training data. We employ both unsupervised clustering and semi-supervised learning to recognize pitch accent in English and tones in Mandarin Chinese. In unsupervised Mandarin tone clustering experiments, we achieve 57-87% accuracy on materials ranging from broadcast news to clean lab speech. For English pitch accent in broadcast news materials, results reach 78%. In the semi-supervised framework, we achieve Mandarin tone recognition accuracies ranging from 70% for broadcast news speech to 94% for read speech, outperforming both Support Vector Machines (SVMs) trained on only the labeled data and the 25% most common class assignment level. These results indicate that the intrinsic structure of tone and pitch accent acoustics can be exploited to reduce the need for costly labeled training data for tone learning and recognition."
E06-2017,Computing Term Translation Probabilities with Generalized Latent Semantic Analysis,2006,12,2,2,1,49314,irina matveeva,Demonstrations,0,"Term translation probabilities proved an effective method of semantic smoothing in the language modelling approach to information retrieval tasks. In this paper, we use Generalized Latent Semantic Analysis to compute semantically motivated term and document vectors. The normalized cosine similarity between the term vectors is used as term translation probability in the language modelling framework. Our experiments demonstrate that GLSA-based term translation probabilities capture semantic relations between terms and improve performance on document classification."
I05-3010,Turn-taking in {M}andarin Dialogue: Interactions of Tone and Intonation,2005,11,13,1,1,11446,ginaanne levow,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,"Fluent dialogue requires that speakers successfully negotiate and signal turn-taking. While many cues to turn change have been proposed, especially in multi-modal frameworks, here we focus on the use of prosodic cues to these functions. In particular, we consider the use of prosodic cues in a tone language, Mandarin Chinese, where variations in pitch height and slope additionally serve to determine word meaning. Within a corpus of spontaneous Chinese dialogues, we find that turn-unit final syllables are significantly lower in average pitch and intensity than turnunit initial syllables in both smooth turn changes and segments ended by speaker overlap. Interruptions are characterized by significant prosodic differences from smooth turn initiations. Furthermore, we demonstrate that these contrasts correspond to an overall lowering across all tones in final position, which largely preserves the relative heights of the lexical tones. In classification tasks, we contrast the use of text and prosodic features. Finally, we demonstrate that, on balanced training and test sets, we can distinguish turnunit final words from other words at xe2x89x88 93% accuracy and interruptions from smooth turn unit initiations at 62% accuracy."
W04-2906,Assessing Prosodic and Text Features for Segmentation of {M}andarin Broadcast News,2004,15,8,1,1,11446,ginaanne levow,Proceedings of the Workshop on Interdisciplinary Approaches to Speech Indexing and Retrieval at {HLT}-{NAACL} 2004,0,"Automatic topic segmentation, separation of a discourse stream into its constituent stories or topics, is a necessary preprocessing step for applications such as information retrieval, anaphora resolution, and summarization. While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic segmentation of other languages using both text and acoustic information. In this paper, we focus on exploiting both textual and prosodic features for topic segmentation of Mandarin Chinese. As a tone language, Mandarin presents special challenges for applicability of intonation-based techniques, since the pitch contour is also used to establish lexical identity. However, intonational cues such as reduction in pitch and intensity at topic boundaries and increase in duration and pause still provide significant contrasts in Mandarin Chinese. We first build a decision tree classifier that based only on prosodic information achieves boundary classification accuracy of 89--95.8% on a large standard test set. We then contrast these results with a simple text similarity-based classification scheme. Finally we build a merged classifier, finding the best effectiveness for systems integrating text and prosodic cues."
W04-2318,Prosodic Cues to Discourse Segment Boundaries in Human-Computer Dialogue,2004,18,18,1,1,11446,ginaanne levow,Proceedings of the 5th {SIG}dial Workshop on Discourse and Dialogue at {HLT}-{NAACL} 2004,0,"Theories of discourse structure hypothesize a hierarchical structure of discourse segments, typically tree-structured. While substantial work has been done on identifying and automatically recognizing the textual and prosodic correlates of discourse structure in monologue, comparable cues for dialogue or multiparty conversation, and in particular humancomputer dialogue remain relatively less studied. In this paper, we explore prosodic cues to discourse segmentation in humancomputer dialogue. Using data drawn from 60 hours of interactions with a voice-only conversational spoken language system, we identify pitch and intensity features that signal segment boundaries. Specifically, based on 473 pairs of segment-final and segmentinitiating utterances, we find significant increases for segment-initial utterances in maximum pitch, average pitch, and average intensity, while segment-final utterances show significantly lower minimum pitch. These results suggest that even in the artificial environment of human-computer dialogue, prosodic cues robustly signal discourse segment structure, comparably to the contrastive uses of pitch and amplitude identified in natural monologues."
W04-1115,Combining Prosodic and Text Features for Segmentation of {M}andarin Broadcast News,2004,17,1,1,1,11446,ginaanne levow,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,None
N04-4035,Prosody-based Topic Segmentation for {M}andarin Broadcast News,2004,15,12,1,1,11446,ginaanne levow,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"Automatic topic segmentation, separation of a discourse stream into its constituent stories or topics, is a necessary preprocessing step for applications such as information retrieval, anaphora resolution, and summarization. While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic, acoustic feature-based segmentation of other languages. In this paper, we focus on prosody-based topic segmentation of Mandarin Chinese. As a tone language, Mandarin presents special challenges for applicability of intonation-based techniques, since the pitch contour is also used to establish lexical identity. We demonstrate that intonational cues such as reduction in pitch and intensity at topic boundaries and increase in duration and pause still provide significant contrasts in Mandarin Chinese. We also build a decision tree classifier that, based only on word and local context prosodic information without reference to term similarity, cue phrase, or sentence-level information, achieves boundary classification accuracy of 89--95.8% on a large standard test set."
W03-2124,Learning to Speak to a Spoken Language System: Vocabulary Convergence in Novice Users,2003,5,5,1,1,11446,ginaanne levow,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,None
W03-1110,Issues in Pre- and Post-translation Document Expansion: Untranslatable Cognates and Missegmented Words,2003,8,7,1,1,11446,ginaanne levow,Proceedings of the Sixth International Workshop on Information Retrieval with {A}sian Languages,0,"Query expansion by pseudo-relevance feedback is a well-established technique in both mono- and cross- lingual information retrieval, enriching and disambiguating the typically terse queries provided by searchers. Comparable document-side expansion is a relatively more recent development motivated by error-prone transcription and translation processes in spoken document and cross-language retrieval. In the cross-language case, one can perform expansion before translation, after translation, and at both points. We investigate the relative impact of pre- and post- translation document expansion for cross-language spoken document retrieval in Mandarin Chinese. We find that post-translation expansion yields a highly significant improvement in retrieval effectiveness, while improvements due to pre-translation expansion alone or in combination do not reach significance. We identify two key factors of segmentation and translation in Chinese orthography that limit the effectiveness of pre-translation expansion in the Chinese-English case, while post-translation expansion yields its full benefit."
H01-1050,{M}andarin-{E}nglish Information: Investigating Translingual Speech Retrieval,2001,20,17,4,0,36519,helen meng,Proceedings of the First International Conference on Human Language Technology Research,0,"This paper describes the Mandarin-English Information (MEI) project, where we investigated the problem of cross-language spoken document retrieval (CL-SDR), and developed one of the first English-Chinese CL-SDR systems. Our system accepts an entire English news story (text) as query, and retrieves relevant Chinese broadcast news stories (audio) from the document collection. Hence this is a cross-language and cross-media retrieval task. We applied a multi-scale approach to our problem, which unifies the use of phrases, words and subwords in retrieval. The English queries are translated into Chinese by means of a dictionary-based approach, where we have integrated phrase-based translation with word-by-word translation. Untranslatable named entities are transliterated by a novel subword translation technique. The multi-scale approach can be divided into three subtasks -- multi-scale query formulation, multi-scale audio indexing (by speech recognition) and multi-scale retrieval. Experimental results demonstrate that the use of phrase-based translation and subword translation gave performance gains, and multi-scale retrieval outperforms word-based retrieval."
H01-1060,Rapidly Retargetable Interactive Translingual Retrieval,2001,2,4,1,1,11446,ginaanne levow,Proceedings of the First International Conference on Human Language Technology Research,0,"This paper describes a system for rapidly retargetable interactive translingual retrieval. Basic functionality can be achieved for a new document language in a single day, and further improvements require only a relatively modest additional investment. We applied the techniques first to search Chinese collections using English queries, and have successfully added French, German, and Italian document collections. We achieve this capability through separation of language-dependent and language-independent components and through the application of asymmetric techniques that leverage an extensive English retrieval infrastructure."
dorr-etal-2000-chinese,{C}hinese-{E}nglish Semantic Resource Construction,2000,12,8,2,0,14512,bonnie dorr,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"Abstract : We describe an approach to large-scale construction of a semantic lexicon for Chinese verbs. We leverage off of three existing resources-- a classification of English verbs called EVCA (English Verbs Classes and Alternations), a Chinese conceptual database called HowNet, and a large-machine readable dictionary called Optilex. The resulting lexicon is used for determining appropriate word senses in applications such as machine translation and cross-language information retrieval."
dorr-etal-2000-building,Building a {C}hinese-{E}nglish mapping between verb concepts for multilingual applications,2000,19,8,2,0,14512,bonnie dorr,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper addresses the problem of building conceptual resources for multilingual applications. We describe new techniques for large-scale construction of a Chinese-English lexicon for verbs, using thematic-role information to create links between Chinese and English conceptual information. We then present an approach to compensating for gaps in the existing resources. The resulting lexicon is used for multilingual applications such as machine translation and cross-language information retrieval."
W99-0405,Modeling the language assessment process and result: Proposed architecture for automatic oral proficiency assessment,1999,23,6,1,1,11446,ginaanne levow,Computer Mediated Language Assessment and Evaluation in Natural Language Processing,0,"We outline challenges for modeling human language assessment in automatic systems, both in terms of the process and the reliability of the result. We propose an architecture for a system to evaluate learners of Spanish via the Computerized Oral Proficiency Instrument, to determine whether they have 'reached' or 'not reached' the Intermediate Low level of proficiency, according to the American Council on the Teaching of Foreign Languages (ACTFL) Speaking Proficiency Guidelines. Our system divides the acoustic and non-acoustic features, incorporating human process modeling where permitted by the technology and required by the domain. We suggest machine learning techniques applied to this type of system permit insight into yet unarticulated aspects of the human rating process."
P98-1122,Characterizing and Recognizing Spoken Corrections in Human-Computer Dialogue,1998,28,70,1,1,11446,ginaanne levow,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"Miscommunication in speech recognition systems is unavoidable, but a detailed characterization of user corrections will enable speech systems to identify when a correction is taking place and to more accurately recognize the content of correction utterances. In this paper we investigate the adaptations of users when they encounter recognition errors in interactions with a voice-in/voice-out spoken language system. In analyzing more than 300 pairs of original and repeat correction utterances, matched on speaker and lexical content, we found overall increases in both utterance and pause duration from original to correction. Interestingly, corrections of misrecognition erros (CME) exhibited significantly heightened pitch variability, while corrections of rejection errors (CRE) showed only a small but significant decrease in pitch minimum. CME's demonstrated much greater increases in measures of duration and pitch variability than CRE's. These contrasts allow the development of decision trees which distinguish CME's from CRE's and from original inputs at 70--75% accuracy based on duration, pitch, and amplitude features."
C98-1117,Characterizing and Recognizing Spoken Corrections in Human-Computer Dialogue,1998,28,70,1,1,11446,ginaanne levow,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"Miscommunication in speech recognition systems is unavoidable, but a detailed characterization of user corrections will enable speech systems to identify when a correction is taking place and to more accurately recognize the content of correction utterances. In this paper we investigate the adaptations of users when they encounter recognition errors in interactions with a voice-in/voice-out spoken language system. In analyzing more than 300 pairs of original and repeat correction utterances, matched on speaker and lexical content, we found overall increases in both utterance and pause duration from original to correction. Interestingly, corrections of misrecognition erros (CME) exhibited significantly heightened pitch variability, while corrections of rejection errors (CRE) showed only a small but significant decrease in pitch minimum. CME's demonstrated much greater increases in measures of duration and pitch variability than CRE's. These contrasts allow the development of decision trees which distinguish CME's from CRE's and from original inputs at 70--75% accuracy based on duration, pitch, and amplitude features."
