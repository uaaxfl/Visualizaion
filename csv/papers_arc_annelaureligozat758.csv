2021.sustainlp-1.2,Evaluating the carbon footprint of {NLP} methods: a survey and analysis of existing tools,2021,-1,-1,4,0,861,nesrine bannour,Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing,0,"Modern Natural Language Processing (NLP) makes intensive use of deep learning methods because of the accuracy they offer for a variety of applications. Due to the significant environmental impact of deep learning, cost-benefit analysis including carbon footprint as well as accuracy measures has been suggested to better document the use of NLP methods for research or deployment. In this paper, we review the tools that are available to measure energy use and CO2 emissions of NLP methods. We describe the scope of the measures provided and compare the use of six tools (carbon tracker, experiment impact tracker, green algorithms, ML CO2 impact, energy usage and cumulator) on named entity recognition experiments performed on different computational set-ups (local server vs. computing facility). Based on these findings, we propose actionable recommendations to accurately measure the environmental impact of NLP experiments."
2020.jeptalnrecital-taln.33,Simplification automatique de texte dans un contexte de faibles ressources (Automatic Text Simplification : Approaching the Problem in Low Resource Settings for {F}rench),2020,-1,-1,2,0,2848,sadaf rauf,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"La simplification de textes a {\'e}merg{\'e} comme un sous-domaine actif du traitement automatique des langues, du fait des probl{\`e}mes pratiques et th{\'e}oriques qu{'}elle permet d{'}aborder, ainsi que de ses nombreuses applications pratiques. Des corpus de simplification sont n{\'e}cessaires pour entrainer des syst{\`e}mes de simplification automatique ; ces ressources sont toutefois rares et n{'}existent que pour un petit nombre de langues. Nous montrons ici que dans un contexte o{\`u} les ressources pour la simplification sont rares, il reste n{\'e}anmoins possible de construire des syst{\`e}mes de simplification, en ayant recours {\`a} des corpus synth{\'e}tiques, par exemple obtenus par traduction automatique, et nous {\'e}valuons diverses mani{\`e}res de les constituer."
2019.jeptalnrecital-court.29,Transformation d{'}annotations en parties du discours et lemmes vers le format {U}niversal {D}ependencies : {\\'e}tude de cas pour l{'}alsacien et l{'}occitan (Converting {POS}-tag and Lemma Annotations into the {U}niversal {D}ependencies Format : A Case Study on {A}lsatian and {O}ccitan ),2019,-1,-1,4,0,14246,aleksandra miletic,Actes de la Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) PFIA 2019. Volume II : Articles courts,0,"Cet article pr{\'e}sente un retour d{'}exp{\'e}rience sur la transformation de corpus annot{\'e}s pour l{'}alsacien et l{'}occitan vers le format CONLL-U d{\'e}fini dans le projet Universal Dependencies. Il met en particulier l{'}accent sur divers points de vigilance {\`a} prendre en compte, concernant la tok{\'e}nisation et la d{\'e}finition des cat{\'e}gories pour l{'}annotation."
L18-1619,"Corpora with Part-of-Speech Annotations for Three Regional Languages of {F}rance: {A}lsatian, {O}ccitan and {P}icard",2018,0,1,2,0,27324,delphine bernhard,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This article describes the creation of corpora with part-of-speech annotations for three regional languages of France: Alsatian, Occitan and Picard. These manual annotations were performed in the context of the RESTAURE project, whose goal is to develop resources and tools for these under-resourced French regional languages. The article presents the tagsets used in the annotation process as well as the resulting annotated corpora."
2018.jeptalnrecital-long.6,{\\'E}tiquetage en parties du discours de langues peu dot{\\'e}es par sp{\\'e}cialisation des plongements lexicaux ({POS} tagging for low-resource languages by adapting word embeddings ),2018,-1,-1,2,0,15790,pierre magistry,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Cet article pr{\'e}sente une nouvelle m{\'e}thode d{'}{\'e}tiquetage en parties du discours adapt{\'e}e aux langues peu dot{\'e}es : la d{\'e}finition du contexte utilis{\'e} pour construire les plongements lexicaux est adapt{\'e}e {\`a} la t{\^a}che, et de nouveaux vecteurs sont cr{\'e}{\'e}s pour les mots inconnus. Les exp{\'e}riences men{\'e}es sur le picard, le malgache et l{'}alsacien montrent que cette m{\'e}thode am{\'e}liore l{'}{\'e}tat de l{'}art pour ces trois langues peu dot{\'e}es."
2017.jeptalnrecital-long.13,"Apprendre des repr{\\'e}sentations jointes de mots et d{'}entit{\\'e}s pour la d{\\'e}sambigu{\\\\\i}sation d{'}entit{\\'e}s (Combining Word and Entity Embeddings for Entity Linking)""",2017,-1,-1,5,0,2103,jose moreno,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 - Articles longs,0,"La d{\'e}sambigu{\""\i}sation d{'}entit{\'e}s (ou liaison d{'}entit{\'e}s), qui consiste {\`a} relier des mentions d{'}entit{\'e}s d{'}un texte {\`a} des entit{\'e}s d{'}une base de connaissance, est un probl{\`e}me qui se pose, entre autre, pour le peuplement automatique de bases de connaissances {\`a} partir de textes. Une difficult{\'e} de cette t{\^a}che est la r{\'e}solution d{'}ambigu{\""\i}t{\'e}s car les syst{\`e}mes ont {\`a} choisir parmi un nombre important de candidats. Cet article propose une nouvelle approche fond{\'e}e sur l{'}apprentissage joint de repr{\'e}sentations distribu{\'e}es des mots et des entit{\'e}s dans le m{\^e}me espace, ce qui permet d{'}{\'e}tablir un mod{\`e}le robuste pour la comparaison entre le contexte local de la mention d{'}entit{\'e} et les entit{\'e}s candidates."
L16-1035,Evaluating Lexical Simplification and Vocabulary Knowledge for Learners of {F}rench: Possibilities of Using the {FLEL}ex Resource,2016,0,1,3,0,16943,anais tack,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This study examines two possibilities of using the FLELex graded lexicon for the automated assessment of text complexity in French as a foreign language learning. From the lexical frequency distributions described in FLELex, we derive a single level of difficulty for each word in a parallel corpus of original and simplified texts. We then use this data to automatically address the lexical complexity of texts in two ways. On the one hand, we evaluate the degree of lexical simplification in manually simplified texts with respect to their original version. Our results show a significant simplification effect, both in the case of French narratives simplified for non-native readers and in the case of simplified Wikipedia texts. On the other hand, we define a predictive model which identifies the number of words in a text that are expected to be known at a particular learning level. We assess the accuracy with which these predictions are able to capture actual word knowledge as reported by Dutch-speaking learners of French. Our study shows that although the predictions seem relatively accurate in general (87.4{\%} to 92.3{\%}), they do not yet seem to cover the learners{'} lack of knowledge very well."
L16-1366,Transfer-Based Learning-to-Rank Assessment of Medical Term Technicality,2016,0,3,3,1,35102,dhouha bouamor,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"While measuring the readability of texts has been a long-standing research topic, assessing the technicality of terms has only been addressed more recently and mostly for the English language. In this paper, we train a learning-to-rank model to determine a specialization degree for each term found in a given list. Since no training data for this task exist for French, we train our system with non-lexical features on English data, namely, the Consumer Health Vocabulary, then apply it to French. The features include the likelihood ratio of the term based on specialized and lay language models, and tests for containing morphologically complex words. The evaluation of this approach is conducted on 134 terms from the UMLS Metathesaurus and 868 terms from the Eugloss thesaurus. The Normalized Discounted Cumulative Gain obtained by our system is over 0.8 on both test sets. Besides, thanks to the learning-to-rank approach, adding morphological features to the language model features improves the results on the Eugloss thesaurus."
L16-1433,Purely Corpus-based Automatic Conversation Authoring,2016,0,6,3,0,18755,guillaume duplessis,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents an automatic corpus-based process to author an open-domain conversational strategy usable both in chatterbot systems and as a fallback strategy for out-of-domain human utterances. Our approach is implemented on a corpus of television drama subtitles. This system is used as a chatterbot system to collect a corpus of 41 open-domain textual dialogues with 27 human participants. The general capabilities of the system are studied through objective measures and subjective self-reports in terms of understandability, repetition and coherence of the system responses selected in reaction to human utterances. Subjective evaluations of the collected dialogues are presented with respect to amusement, engagement and enjoyability. The main factors influencing those dimensions in our chatterbot experiment are discussed."
C16-1094,Are Cohesive Features Relevant for Text Readability Evaluation?,2016,27,5,5,0,15684,amalia todirascu,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"This paper investigates the effectiveness of 65 cohesion-based variables that are commonly used in the literature as predictive features to assess text readability. We evaluate the efficiency of these variables across narrative and informative texts intended for an audience of L2 French learners. In our experiments, we use a French corpus that has been both manually and automatically annotated as regards to co-reference and anaphoric chains. The efficiency of the 65 variables for readability is analyzed through a correlational analysis and some modelling experiments."
2016.jeptalnrecital-long.17,Mod{\\`e}les adaptatifs pour pr{\\'e}dire automatiquement la comp{\\'e}tence lexicale d{'}un apprenant de fran{\\c{c}}ais langue {\\'e}trang{\\`e}re (Adaptive models for automatically predicting the lexical competence of {F}rench as a foreign language learners),2016,-1,-1,3,0,16943,anais tack,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"Cette {\'e}tude examine l{'}utilisation de m{\'e}thodes d{'}apprentissage incr{\'e}mental supervis{\'e} afin de pr{\'e}dire la comp{\'e}tence lexicale d{'}apprenants de fran{\c{c}}ais langue {\'e}trang{\`e}re (FLE). Les apprenants cibl{\'e}s sont des n{\'e}erlandophones ayant un niveau A2/B1 selon le Cadre europ{\'e}en commun de r{\'e}f{\'e}rence pour les langues (CECR). {\`A} l{'}instar des travaux r{\'e}cents portant sur la pr{\'e}diction de la ma{\^\i}trise lexicale {\`a} l{'}aide d{'}indices de complexit{\'e}, nous {\'e}laborons deux types de mod{\`e}les qui s{'}adaptent en fonction d{'}un retour d{'}exp{\'e}rience, r{\'e}v{\'e}lant les connaissances de l{'}apprenant. En particulier, nous d{\'e}finissons (i) un mod{\`e}le qui pr{\'e}dit la comp{\'e}tence lexicale de tous les apprenants du m{\^e}me niveau de ma{\^\i}trise et (ii) un mod{\`e}le qui pr{\'e}dit la comp{\'e}tence lexicale d{'}un apprenant individuel. Les mod{\`e}les obtenus sont ensuite {\'e}valu{\'e}s par rapport {\`a} un mod{\`e}le de r{\'e}f{\'e}rence d{\'e}terminant la comp{\'e}tence lexicale {\`a} partir d{'}un lexique sp{\'e}cialis{\'e} pour le FLE et s{'}av{\`e}rent gagner significativement en exactitude (9{\%}-17{\%})."
2016.jeptalnrecital-demo.18,Un syst{\\`e}me automatique de s{\\'e}lection de r{\\'e}ponse en domaine ouvert int{\\'e}grable {\\`a} un syst{\\`e}me de dialogue social (An automatic open-domain response selection system integrable to a social dialogue system),2016,-1,-1,4,0,36101,franck charras,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 5 : D{\\'e}monstrations,0,Cette d{\'e}monstration pr{\'e}sente un syst{\`e}me de dialogue en domaine ouvert qui utilise une base d{'}exemples de dialogue automatiquement constitu{\'e}e depuis un corpus de sous-titres afin de g{\'e}rer un dialogue social de type Â« chatbot Â».
W15-4660,Description of the {P}atient{G}enesys Dialogue System,2015,9,2,4,1,31973,leonardo llanos,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper describes the work-in-progress prototype of a dialog system that simulates a virtual patient (VP) consultation. We report some challenges and difficulties that are found during its development, especially in managing the interaction and the vocabulary from the medical domain."
2015.jeptalnrecital-long.11,Estimation de l{'}homog{\\'e}n{\\'e}it{\\'e} s{\\'e}mantique pour les Questionnaires {\\`a} Choix Multiples,2015,-1,-1,2,0,37952,vanminh pho,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"L{'}homog{\'e}n{\'e}it{\'e} s{\'e}mantique stipule que des termes sont s{\'e}mantiquement proches mais non similaires. Cette notion est au c{\oe}ur de travaux relatifs {\`a} la g{\'e}n{\'e}ration automatique de questionnaires {\`a} choix multiples, et particuli{\`e}rement {\`a} la s{\'e}lection automatique de distracteurs. Dans cet article, nous pr{\'e}sentons une m{\'e}thode d{'}estimation de l{'}homog{\'e}n{\'e}it{\'e} s{\'e}mantique dans un cadre de validation automatique de distracteurs. Cette m{\'e}thode est fond{\'e}e sur une combinaison de plusieurs crit{\`e}res de voisinage et de similarit{\'e} s{\'e}mantique entre termes, par apprentissage automatique. Nous montrerons que notre m{\'e}thode permet d{'}obtenir une meilleure estimation de l{'}homog{\'e}n{\'e}it{\'e} s{\'e}mantique que les m{\'e}thodes propos{\'e}es dans l{'}{\'e}tat de l{'}art."
2015.jeptalnrecital-demonstration.8,Un patient virtuel dialogant,2015,-1,-1,4,0,37967,leonardo campillos,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,Le d{\'e}monstrateur que nous d{\'e}crivons ici est un prototype de syst{\`e}me de dialogue dont l{'}objectif est de simuler un patient. Nous d{\'e}crivons son fonctionnement g{\'e}n{\'e}ral en insistant sur les aspects concernant la langue et surtout le rapport entre langue m{\'e}dicale de sp{\'e}cialit{\'e} et langue g{\'e}n{\'e}rale.
W14-1206,Syntactic Sentence Simplification for {F}rench,2014,30,10,3,1,38767,laetitia brouwers,Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations ({PITR}),0,This paper presents a method for the syntactic simplification of French texts. Syntactic simplification aims at making texts easier to understand by simplifying complex syntactic structures that hinder reading. Our approach is based on the study of two parallel corpora (encyclopaedia articles and tales). It aims to identify the linguistic phenomena involved in the manual simplification of French texts and organise them within a typology. We then propose a syntactic simplification system that relies on this typology to generate simplified sentences. The module starts by generating all possible variants before selecting the best subset. The evaluation shows that about 80% of the simplified sentences produced by our system are accurate.
garcia-fernandez-etal-2014-construction,Construction and Annotation of a {F}rench Folkstale Corpus,2014,22,0,2,0,39320,anne garciafernandez,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present the digitization and annotation of a tales corpus - which is to our knowledge the only French tales corpus available and classified according to the Aarne{\&}Thompson classification - composed of historical texts (with old French parts). We first studied whether the pre-processing tools, namely OCR and PoS-tagging, have good enough accuracies to allow automatic analysis. We also manually annotated this corpus according to several types of information which could prove useful for future work: character references, episodes, and motifs. The contributions are the creation of an corpus of French tales from classical anthropology material, which will be made available to the community; the evaluation of OCR and NLP tools on this corpus; and the annotation with anthropological information."
deleger-etal-2014-annotation,Annotation of specialized corpora using a comprehensive entity and relation scheme,2014,15,8,2,0.714286,17098,louise deleger,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Annotated corpora are essential resources for many applications in Natural Language Processing. They provide insight on the linguistic and semantic characteristics of the genre and domain covered, and can be used for the training and evaluation of automatic tools. In the biomedical domain, annotated corpora of English texts have become available for several genres and subfields. However, very few similar resources are available for languages other than English. In this paper we present an effort to produce a high-quality corpus of clinical documents in French, annotated with a comprehensive scheme of entities and relations. We present the annotation scheme as well as the results of a pilot annotation study covering 35 clinical documents in a variety of subfields and genres. We show that high inter-annotator agreement can be achieved using a complex annotation scheme."
pho-etal-2014-multiple,Multiple Choice Question Corpus Analysis for Distractor Characterization,2014,13,6,3,0,37952,vanminh pho,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present a study of MCQ aiming to define criteria in order to automatically select distractors. We are aiming to show that distractor editing follows rules like syntactic and semantic homogeneity according to associated answer, and the possibility to automatically identify this homogeneity. Manual analysis shows that homogeneity rule is respected to edit distractors and automatic analysis shows the possibility to reproduce these criteria. These ones can be used in future works to automatically select distractors, with the combination of other criteria."
P13-2076,Question Classification Transfer,2013,8,2,1,1,864,annelaure ligozat,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Question answering systems have been developed for many languages, but most resources were created for English, which can be a problem when developing a system in another language such as French. In particular, for question classification, no labeled question corpus is available for French, so this paper studies the possibility to use existing English corpora and transfer a classification by translating the question and their labels. By translating the training corpus, we obtain results close to a monolingual setting."
F13-1036,Studying frequency-based approaches to process lexical simplification (Approches {\\`a} base de fr{\\'e}quences pour la simplification lexicale) [in {F}rench],2013,0,0,1,1,864,annelaure ligozat,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
S12-1068,"{ANNLOR}: A Na{\\\\\i}ve Notation-system for Lexical Outputs Ranking""",2012,3,7,1,1,864,annelaure ligozat,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper presents the systems we developed while participating in the first task (English Lexical Simplification) of SemEval 2012. Our first system relies on n-grams frequencies computed from the Simple English Wikipedia version, ranking each substitution term by decreasing frequency of use. We experimented with several other systems, based on term frequencies, or taking into account the context in which each substitution term occurs. On the evaluation corpus, we achieved a 0.465 score with the first system."
F12-2001,Simplification de phrases pour l{'}extraction de relations (Sentence Simplification for Relation Extraction) [in {F}rench],2012,0,0,2,1,5690,annelyse minard,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
F12-2016,Simplification syntaxique de phrases pour le fran{\\c{c}}ais (Syntactic Simplification for {F}rench Sentences) [in {F}rench],2012,0,0,3,1,38767,laetitia brouwers,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
R11-1086,Multi-class {SVM} for Relation Extraction from Clinical Reports,2011,11,12,2,1,5690,annelyse minard,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"Information extraction in specialized texts raises different problems related to the kind of searched information. In this paper, we are interested in relation identification between some concepts in medical reports, task that was evaluated in the i2b2 2010 challenge. As relations are expressed in natural language with a great variety of forms, we proceeded to sentence analysis by extracting features that enable all together to identify a relation and we modeled this task as a multi-class classification based on an SVM, each type of relation representing a class. We will present the selection of the features used by our system and an error analysis. This approach allowed us to obtain an F-measure of 0.70, classifying the system among the best systems."
2011.jeptalnrecital-long.27,Apport de la syntaxe pour l{'}extraction de relations en domaine m{\\'e}dical (Contribution of syntax for relation extraction in the medical domain),2011,-1,-1,2,1,5690,annelyse minard,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous nous int{\'e}ressons {\`a} l{'}identification de relations entre entit{\'e}s en domaine de sp{\'e}cialit{\'e}, et {\'e}tudions l{'}apport d{'}informations syntaxiques. Nous nous pla{\c{c}}ons dans le domaine m{\'e}dical, et analysons des relations entre concepts dans des comptes-rendus m{\'e}dicaux, t{\^a}che {\'e}valu{\'e}e dans la campagne i2b2 en 2010. Les relations {\'e}tant exprim{\'e}es par des formulations tr{\`e}s vari{\'e}es en langue, nous avons proc{\'e}d{\'e} {\`a} l{'}analyse des phrases en extrayant des traits qui concourent {\`a} la reconnaissance de la pr{\'e}sence d{'}une relation et nous avons consid{\'e}r{\'e} l{'}identification des relations comme une t{\^a}che de classification multi-classes, chaque cat{\'e}gorie de relation {\'e}tant consid{\'e}r{\'e}e comme une classe. Notre syst{\`e}me de r{\'e}f{\'e}rence est celui qui a particip{\'e} {\`a} la campagne i2b2, dont la F-mesure est d{'}environ 0,70. Nous avons {\'e}valu{\'e} l{'}apport de la syntaxe pour cette t{\^a}che, tout d{'}abord en ajoutant des attributs syntaxiques {\`a} notre classifieur, puis en utilisant un apprentissage fond{\'e} sur la structure syntaxique des phrases (apprentissage {\`a} base de tree kernels) ; cette derni{\`e}re m{\'e}thode am{\'e}liore les r{\'e}sultats de la classification de 3{\%}."
2011.jeptalnrecital-long.31,Analyse automatique de la modalit{\\'e} et du niveau de certitude : application au domaine m{\\'e}dical (Automatic analysis of modality and level of certainty: application to the medical domain),2011,-1,-1,2,0.482035,27324,delphine bernhard,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"De nombreux ph{\'e}nom{\`e}nes linguistiques visent {\`a} exprimer le doute ou l{'}incertitude de l{'}{\'e}nonciateur, ainsi que la subjectivit{\'e} potentielle du point de vue. La prise en compte de ces informations sur le niveau de certitude est primordiale pour de nombreuses applications du traitement automatique des langues, en particulier l{'}extraction d{'}information dans le domaine m{\'e}dical. Dans cet article, nous pr{\'e}sentons deux syst{\`e}mes qui analysent automatiquement les niveaux de certitude associ{\'e}s {\`a} des probl{\`e}mes m{\'e}dicaux mentionn{\'e}s dans des compte-rendus cliniques en anglais. Le premier syst{\`e}me proc{\`e}de par apprentissage supervis{\'e} et obtient une f-mesure de 0,93. Le second syst{\`e}me utilise des r{\`e}gles d{\'e}crivant des d{\'e}clencheurs linguistiques sp{\'e}cifiques et obtient une f-mesure de 0,90."
2011.jeptalnrecital-demonstration.12,Extraction d{'}informations m{\\'e}dicales au {LIMSI} (Medical information extraction at {LIMSI}),2011,-1,-1,4,0,5675,cyril grouin,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,
2011.jeptalnrecital-court.7,S{\\'e}lection de r{\\'e}ponses {\\`a} des questions dans un corpus Web par validation (Selection of answers to questions in a web corpus by validation),2011,-1,-1,4,0,42529,arnaud grappy,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,Les syst{\`e}mes de questions r{\'e}ponses recherchent la r{\'e}ponse {\`a} une question pos{\'e}e en langue naturelle dans un ensemble de documents. Les collectionsWeb diff{\`e}rent des articles de journaux de par leurs structures et leur style. Pour tenir compte de ces sp{\'e}cificit{\'e}s nous avons d{\'e}velopp{\'e} un syst{\`e}me fond{\'e} sur une approche robuste de validation o{\`u} des r{\'e}ponses candidates sont extraites {\`a} partir de courts passages textuels puis ordonn{\'e}es par apprentissage. Les r{\'e}sultats montrent une am{\'e}lioration du MRR (Mean Reciprocal Rank) de 48{\%} par rapport {\`a} la baseline.
ayari-etal-2010-fine,Fine-grained Linguistic Evaluation of Question Answering Systems,2010,14,1,3,0,39919,sarra ayari,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Question answering systems are complex systems using natural language processing. Some evaluation campaigns are organized to evaluate such systems in order to propose a classification of systems based on final results (number of correct answers). Nevertheless, teams need to evaluate more precisely the results obtained by their systems if they want to do a diagnostic evaluation. There are no tools or methods to do these evaluations systematically. We present REVISE, a tool for glass box evaluation based on diagnostic of question answering system results."
W09-4504,Corpus Study of Kidney-related Experimental Data in Scientific Papers,2009,8,4,2,0.539042,2112,brigitte grau,Proceedings of the Workshop on Biomedical Information Extraction,0,"The Quantitative Kidney DataBase (QKDB) is a relational database that was created in order to centralize kidney-related experimental results. Each result is characterized by different attributes and the scientific paper from which it was extracted. Currently, this database is populated by hand by experts of the domain. We present a corpus study of some papers that have already been analyzed in order to exhibit the specificities and difficulties of the extraction process; then we propose a first solution to extract automatically the desired knowledge from papers."
2007.jeptalnrecital-poster.17,Syst{\\`e}mes de questions-r{\\'e}ponses : vers la validation automatique des r{\\'e}ponses,2007,-1,-1,1,1,864,annelaure ligozat,Actes de la 14{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Les syst{\`e}mes de questions-r{\'e}ponses (SQR) ont pour but de trouver une information pr{\'e}cise extraite d{'}une grande collection de documents comme le Web. Afin de pouvoir comparer les diff{\'e}rentes strat{\'e}gies possibles pour trouver une telle information, il est important d{'}{\'e}valuer ces syst{\`e}mes. L{'}objectif d{'}une t{\^a}che de validation de r{\'e}ponses est d{'}estimer si une r{\'e}ponse donn{\'e}e par un SQR est correcte ou non, en fonction du passage de texte donn{\'e} comme justification. En 2006, nous avons particip{\'e} {\`a} une t{\^a}che de validation de r{\'e}ponses, et dans cet article nous pr{\'e}sentons la strat{\'e}gie que nous avons utilis{\'e}e. Celle-ci est fond{\'e}e sur notre propre syst{\`e}me de questions-r{\'e}ponses. Le principe est de comparer nos r{\'e}ponses avec les r{\'e}ponses {\`a} valider. Nous pr{\'e}sentons les r{\'e}sultats obtenus et montrons les extensions possibles. {\`A} partir de quelques exemples, nous soulignons les difficult{\'e}s que pose cette t{\^a}che."
W06-1904,Evaluation and Improvement of Cross-Lingual Question {A}nswering{S}trategies,2006,18,9,1,1,864,annelaure ligozat,Proceedings of the Workshop on Multilingual Question Answering - {MLQA} {`}06,0,"This article presents a bilingual question answering system, which is able to process questions and documents both in French and in English. Two cross-lingual strategies are described and evaluated. First, we study the contribution of biterms translation, and the influence of the completion of the translation dictionaries. Then, we propose a strategy for transferring the question analysis from one language to the other, and we study its influence on the performance of our system."
grau-etal-2006-frasques,{FRASQUES}: A Question Answering system in the {EQ}ue{R} evaluation campaign,2006,3,8,2,0.539042,2112,brigitte grau,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Question-answering (QA) systems aim at providing either a small passage or just the answer to a question in natural language. We have developed several QA systems that work on both English and French. This way, we are able to provide answers to questions given in both languages by searching documents in both languages also. In this article, we present our French monolingual system FRASQUES which participated in the EQueR evaluation campaign of QA systems for French in 2004. First, the QA architecture common to our systems is shown. Then, for every step of the QA process, we consider which steps are language-independent, and for those that are language-dependent, the tools or processes that need to be adapted to switch for one language to another. Finally, our results at EQueR are given and commented; an error analysis is conducted, and the kind of knowledge needed to answer a question is studied."
2006.jeptalnrecital-long.20,L{'}extraction des r{\\'e}ponses dans un syst{\\`e}me de question-r{\\'e}ponse,2006,-1,-1,1,1,864,annelaure ligozat,Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les syst{\`e}mes de question-r{\'e}ponse sont la plupart du temps compos{\'e}s de trois grands modules : l{'}analyse de la question, la s{\'e}lection des documents et l{'}extraction de la r{\'e}ponse. Dans cet article, nous nous int{\'e}ressons au troisi{\`e}me module, plus particuli{\`e}rement dans le cas plus d{\'e}licat o{\`u} la r{\'e}ponse attendue n{'}est pas du type entit{\'e}e nomm{\'e}e. Nous d{\'e}crivons comment l{'}analyseur Cass est employ{\'e} pour marquer la r{\'e}ponse dans les phrases candidates et nous {\'e}valuons les r{\'e}sultats de cette approche. Au pr{\'e}alable, nous d{\'e}crivons et {\'e}valuons le module d{\'e}di{\'e} {\`a} l{'}analyse de la question, car les informations qui en sont issues sont n{\'e}cessaires {\`a} notre {\'e}tape finale d{'}extraction."
2004.jeptalnrecital-recital.1,Syst{\\`e}me de Question R{\\'e}ponse : apport de l{'}analyse syntaxique lors de l{'}extraction de la r{\\'e}ponse,2004,-1,-1,1,1,864,annelaure ligozat,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. REncontres jeunes Chercheurs en Informatique pour le Traitement Automatique des Langues,0,"Dans cet article, nous pr{\'e}sentons le syst{\`e}me de Question R{\'e}ponse QALC, et nous nous int{\'e}ressons tout particuli{\`e}rement {\`a} l{'}extraction de la r{\'e}ponse. Un appariement question-r{\'e}ponse fond{\'e} sur les relations syntaxiques a {\'e}t{\'e} d{\'e}velopp{\'e}, afin d{'}am{\'e}liorer les performances du syst{\`e}me. Un projet de g{\'e}n{\'e}ration de r{\'e}ponses {\`a} partir de plusieurs documents est {\'e}galement discut{\'e}."
