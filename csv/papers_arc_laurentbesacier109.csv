2021.jeptalnrecital-taln.12,Contribution d{'}informations syntaxiques aux capacit{\\'e}s de g{\\'e}n{\\'e}ralisation compositionelle des mod{\\`e}les seq2seq convolutifs (Assessing the Contribution of Syntactic Information for Compositional Generalization of seq2seq Convolutional Networks),2021,-1,-1,5,0,5606,diana popa,Actes de la 28e Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\\'e}rence principale,0,"Les mod{\`e}les neuronaux de type seq2seq manifestent d{'}{\'e}tonnantes capacit{\'e}s de pr{\'e}diction quand ils sont entra{\^\i}n{\'e}s sur des donn{\'e}es de taille suffisante. Cependant, ils {\'e}chouent {\`a} g{\'e}n{\'e}raliser de mani{\`e}re satisfaisante quand la t{\^a}che implique d{'}apprendre et de r{\'e}utiliser des r{\`e}gles syst{\'e}matiques de composition et non d{'}apprendre simplement par imitation des exemples d{'}entra{\^\i}nement. Le jeu de donn{\'e}es SCAN, constitu{\'e} d{'}un ensemble de commandes en langage naturel associ{\'e}es {\`a} des s{\'e}quences d{'}action, a {\'e}t{\'e} sp{\'e}cifiquement con{\c{c}}u pour {\'e}valuer les capacit{\'e}s des r{\'e}seaux de neurones {\`a} apprendre ce type de g{\'e}n{\'e}ralisation compositionnelle. Dans cet article, nous nous proposons d{'}{\'e}tudier la contribution d{'}informations syntaxiques sur les capacit{\'e}s de g{\'e}n{\'e}ralisation compositionnelle des r{\'e}seaux de neurones seq2seq convolutifs."
2021.gebnlp-1.10,Investigating the Impact of Gender Representation in {ASR} Training Data: a Case Study on Librispeech,2021,-1,-1,3,1,6299,mahault garnerin,Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing,0,"In this paper we question the impact of gender representation in training data on the performance of an end-to-end ASR system. We create an experiment based on the Librispeech corpus and build 3 different training corpora varying only the proportion of data produced by each gender category. We observe that if our system is overall robust to the gender balance or imbalance in training data, it is nonetheless dependant of the adequacy between the individuals present in the training and testing sets."
2021.findings-acl.250,Do Multilingual Neural Machine Translation Models Contain Language Pair Specific Attention Heads?,2021,-1,-1,2,0,8114,zae kim,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.533,Multilingual Unsupervised Neural Machine Translation with Denoising Adapters,2021,-1,-1,3,0,3854,ahmet ustun,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"We consider the problem of multilingual unsupervised machine translation, translating to and from languages that only have monolingual data by using auxiliary parallel language pairs. For this problem the standard procedure so far to leverage the monolingual data is {\_}back-translation{\_}, which is computationally costly and hard to tune. In this paper we propose instead to use {\_}denoising adapters{\_}, adapter layers with a denoising objective, on top of pre-trained mBART-50. In addition to the modularity and flexibility of such an approach we show that the resulting translations are on-par with back-translating as measured by BLEU, and furthermore it allows adding unseen languages incrementally."
2021.conll-1.42,Controlling Prosody in End-to-End {TTS}: A Case Study on Contrastive Focus Generation,2021,-1,-1,4,0,11396,siddique latif,Proceedings of the 25th Conference on Computational Natural Language Learning,0,"While End-2-End Text-to-Speech (TTS) has made significant progresses over the past few years, these systems still lack intuitive user controls over prosody. For instance, generating speech with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge. In this paper, we investigate whether we can control prosody directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor. We build and share a specific dataset for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately. Such a milestone is important to allow, for example, smart speakers to be programmatically controlled in terms of output prosody."
2021.computel-1.7,User-friendly Automatic Transcription of Low-resource Languages: Plugging {ESPnet} into Elpis,2021,-1,-1,10,0,11431,oliver adams,Proceedings of the 4th Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers),0,None
2021.codi-main.16,Visualizing {C}rossâ{L}ingual Discourse Relations in Multilingual {TED} Corpora,2021,-1,-1,5,0,8114,zae kim,Proceedings of the 2nd Workshop on Computational Approaches to Discourse,0,"This paper presents an interactive data dashboard that provides users with an overview of the preservation of discourse relations among 28 language pairs. We display a graph network depicting the cross-lingual discourse relations between a pair of languages for multilingual TED talks and provide a search function to look for sentences with specific keywords or relation types, facilitating ease of analysis on the cross-lingual discourse relations."
2021.acl-short.103,Lightweight Adapter Tuning for Multilingual Speech Translation,2021,-1,-1,6,1,5778,hang le,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Adapter modules were recently introduced as an efficient alternative to fine-tuning in NLP. Adapter tuning consists in freezing pre-trained parameters of a model and injecting lightweight modules between layers, resulting in the addition of only a small number of task-specific trainable parameters. While adapter tuning was investigated for multilingual neural machine translation, this paper proposes a comprehensive analysis of adapters for multilingual speech translation (ST). Starting from different pre-trained models (a multilingual ST trained on parallel data or a multilingual BART (mBART) trained on non parallel multilingual data), we show that adapters can be used to: (a) efficiently specialize ST to specific language pairs with a low extra cost in terms of parameters, and (b) transfer from an automatic speech recognition (ASR) task and an mBART pre-trained model to a multilingual ST task. Experiments show that adapter tuning offer competitive results to full fine-tuning, while being much more parameter-efficient."
2020.sltu-1.11,Investigating Language Impact in Bilingual Approaches for Computational Language Documentation,2020,30,0,3,0,14692,marcely boito,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),0,"For endangered languages, data collection campaigns have to accommodate the challenge that many of them are from oral tradition, and producing transcriptions is costly. Therefore, it is fundamental to translate them into a widely spoken language to ensure interpretability of the recordings. In this paper we investigate how the choice of translation language affects the posterior documentation work and potential automatic approaches which will work on top of the produced bilingual corpus. For answering this question, we use the MaSS multilingual speech corpus (Boito et al., 2020) for creating 56 bilingual pairs that we apply to the task of low-resource unsupervised word segmentation and alignment. Our results highlight that the choice of language for translation influences the word segmentation performance, and that different lexicons are learned by using different aligned translations. Lastly, this paper proposes a hybrid approach for bilingual word segmentation, combining boundary clues extracted from a non-parametric Bayesian model (Goldwater et al., 2009a) with the attentional word segmentation neural model from Godard et al. (2018). Our results suggest that incorporating these clues into the neural models{'} input representation increases their translation and alignment quality, specially for challenging language pairs."
2020.lrec-1.302,{F}lau{BERT}: Unsupervised Language Model Pre-training for {F}rench,2020,-1,-1,9,1,5778,hang le,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified evaluation protocol for the downstream tasks, called FLUE (French Language Understanding Evaluation), are shared to the research community for further reproducible experiments in French NLP."
2020.lrec-1.799,{M}a{SS}: A Large and Clean Multilingual Corpus of Sentence-aligned Spoken Utterances Extracted from the {B}ible,2020,-1,-1,5,0,14692,marcely boito,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The CMU Wilderness Multilingual Speech Dataset (Black, 2019) is a newly published multilingual speech dataset based on recorded readings of the New Testament. It provides data to build Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) models for potentially 700 languages. However, the fact that the source content (the Bible) is the same for all the languages is not exploited to date.Therefore, this article proposes to add multilingual links between speech segments in different languages, and shares a large and clean dataset of 8,130 parallel spoken utterances across 8 languages (56 language pairs). We name this corpus MaSS (Multilingual corpus of Sentence-aligned Spoken utterances). The covered languages (Basque, English, Finnish, French, Hungarian, Romanian, Russian and Spanish) allow researches on speech-to-speech alignment as well as on translation for typologically different language pairs. The quality of the final corpus is attested by human evaluation performed on a corpus subset (100 utterances, 8 language pairs). Lastly, we showcase the usefulness of the final product on a bilingual speech retrieval task."
2020.lrec-1.813,Gender Representation in Open Source Speech Resources,2020,0,0,3,1,6299,mahault garnerin,Proceedings of the 12th Language Resources and Evaluation Conference,0,"With the rise of artificial intelligence (AI) and the growing use of deep-learning architectures, the question of ethics, transparency and fairness of AI systems has become a central concern within the research community. We address transparency and fairness in spoken language systems by proposing a study about gender representation in speech resources available through the Open Speech and Language Resource platform. We show that finding gender information in open source corpora is not straightforward and that gender balance depends on other corpus characteristics (elicited/non elicited speech, low/high resource language, speech task targeted). The paper ends with recommendations about metadata and gender information for researchers in order to assure better transparency of the speech systems built using such corpora."
2020.jeptalnrecital-taln.26,{F}lau{BERT} : des mod{\\`e}les de langue contextualis{\\'e}s pr{\\'e}-entra{\\^\\i}n{\\'e}s pour le fran{\\c{c}}ais ({F}lau{BERT} : Unsupervised Language Model Pre-training for {F}rench),2020,-1,-1,9,1,5778,hang le,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Les mod{\`e}les de langue pr{\'e}-entra{\^\i}n{\'e}s sont d{\'e}sormais indispensables pour obtenir des r{\'e}sultats {\`a} l{'}{\'e}tat-de-l{'}art dans de nombreuses t{\^a}ches du TALN. Tirant avantage de l{'}{\'e}norme quantit{\'e} de textes bruts disponibles, ils permettent d{'}extraire des repr{\'e}sentations continues des mots, contextualis{\'e}es au niveau de la phrase. L{'}efficacit{\'e} de ces repr{\'e}sentations pour r{\'e}soudre plusieurs t{\^a}ches de TALN a {\'e}t{\'e} d{\'e}montr{\'e}e r{\'e}cemment pour l{'}anglais. Dans cet article, nous pr{\'e}sentons et partageons FlauBERT, un ensemble de mod{\`e}les appris sur un corpus fran{\c{c}}ais h{\'e}t{\'e}rog{\`e}ne et de taille importante. Des mod{\`e}les de complexit{\'e} diff{\'e}rente sont entra{\^\i}n{\'e}s {\`a} l{'}aide du nouveau supercalculateur Jean Zay du CNRS. Nous {\'e}valuons nos mod{\`e}les de langue sur diverses t{\^a}ches en fran{\c{c}}ais (classification de textes, paraphrase, inf{\'e}rence en langage naturel, analyse syntaxique, d{\'e}sambigu{\""\i}sation automatique) et montrons qu{'}ils surpassent souvent les autres approches sur le r{\'e}f{\'e}rentiel d{'}{\'e}valuation FLUE {\'e}galement pr{\'e}sent{\'e} ici."
2020.jeptalnrecital-jep.28,"Repr{\\'e}sentation du genre dans des donn{\\'e}es open source de parole (Gender representation in open source speech resources 1 With the rise of artificial intelligence ({AI}) and the growing use of deep-learning architectures, the question of ethics and transparency in {AI} systems has become a central concern within the research community)",2020,-1,-1,3,1,6299,mahault garnerin,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"Avec l{'}essor de l{'}intelligence artificielle (IA) et l{'}utilisation croissante des architectures d{'}apprentissage profond, la question de l{'}{\'e}thique et de la transparence des syst{\`e}mes d{'}IA est devenue une pr{\'e}occupation centrale au sein de la communaut{\'e} de recherche. Dans cet article, nous proposons une {\'e}tude sur la repr{\'e}sentation du genre dans les ressources de parole disponibles sur la plateforme Open Speech and Language Resource. Un tout premier r{\'e}sultat est la difficult{\'e} d{'}acc{\`e}s aux informations sur le genre des locuteurs. Ensuite, nous montrons que l{'}{\'e}quilibre entre les cat{\'e}gories de genre d{\'e}pend de diverses caract{\'e}ristiques des corpus (discours {\'e}licit{\'e} ou non, t{\^a}che adress{\'e}e). En nous appuyant sur des travaux ant{\'e}rieurs, nous reprenons quelques principes concernant les m{\'e}tadonn{\'e}es dans l{'}optique d{'}assurer une meilleure transparence des syst{\`e}mes de parole construits {\`a} l{'}aide de ces corpus."
2020.jeptalnrecital-eternal.1,Pratiques d{'}{\\'e}valuation en {ASR} et biais de performance (Evaluation methodology in {ASR} and performance bias),2020,-1,-1,3,1,6299,mahault garnerin,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). 2e atelier {\\'E}thique et TRaitemeNt Automatique des Langues (ETeRNAL)",0,"Nous proposons une r{\'e}flexion sur les pratiques d{'}{\'e}valuation des syst{\`e}mes de reconnaissance automatique de la parole (ASR). Apr{\`e}s avoir d{\'e}fini la notion de discrimination d{'}un point de vue l{\'e}gal et la notion d{'}{\'e}quit{\'e} dans les syst{\`e}mes d{'}intelligence artificielle, nous nous int{\'e}ressons aux pratiques actuelles lors des grandes campagnes d{'}{\'e}valuation. Nous observons que la variabilit{\'e} de la parole et plus particuli{\`e}rement celle de l{'}individu n{'}est pas prise en compte dans les protocoles d{'}{\'e}valuation actuels rendant impossible l{'}{\'e}tude de biais potentiels dans les syst{\`e}mes."
2020.iwslt-1.2,{ON}-{TRAC} Consortium for End-to-End and Simultaneous Speech Translation Challenge Tasks at {IWSLT} 2020,2020,28,0,8,1,5712,maha elbayad,Proceedings of the 17th International Conference on Spoken Language Translation,0,"This paper describes the ON-TRAC Consortium translation systems developed for two challenge tracks featured in the Evaluation Campaign of IWSLT 2020, offline speech translation and simultaneous speech translation. ON-TRAC Consortium is composed of researchers from three French academic laboratories: LIA (Avignon Universit{\'e}), LIG (Universit{\'e} Grenoble Alpes), and LIUM (Le Mans Universit{\'e}). Attention-based encoder-decoder models, trained end-to-end, were used for our submissions to the offline speech translation track. Our contributions focused on data augmentation and ensembling of multiple models. In the simultaneous speech translation track, we build on Transformer-based wait-k models for the text-to-text subtask. For speech-to-text simultaneous translation, we attach a wait-k MT system to a hybrid ASR system. We propose an algorithm to control the latency of the ASR+MT cascade and achieve a good latency-quality trade-off on both subtasks."
2020.emnlp-main.361,Monolingual Adapters for Zero-Shot Neural Machine Translation,2020,-1,-1,4,0,13885,jerin philip,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"We propose a novel adapter layer formalism for adapting multilingual models. They are more parameter-efficient than existing adapter layers while obtaining as good or better performance. The layers are specific to one language (as opposed to bilingual adapters) allowing to compose them and generalize to unseen language-pairs. In this zero-shot setting, they obtain a median improvement of +2.77 BLEU points over a strong 20-language multilingual Transformer baseline trained on TED talks."
2020.conll-1.22,Catplayinginthesnow: Impact of Prior Segmentation on a Model of Visually Grounded Speech,2020,-1,-1,2,1,5607,william havard,Proceedings of the 24th Conference on Computational Natural Language Learning,0,"The language acquisition literature shows that children do not build their lexicon by segmenting the spoken input into phonemes and then building up words from them, but rather adopt a top-down approach and start by segmenting word-like units and then break them down into smaller units. This suggests that the ideal way of learning a language is by starting from full semantic units. In this paper, we investigate if this is also the case for a neural model of Visually Grounded Speech trained on a speech-image retrieval task. We evaluated how well such a network is able to learn a reliable speech-to-image mapping when provided with phone, syllable, or word boundary information. We present a simple way to introduce such information into an RNN-based model and investigate which type of boundary is the most efficient. We also explore at which level of the network{'}s architecture such information should be introduced so as to maximise its performances. Finally, we show that using multiple boundary types at once in a hierarchical structure, by which low-level segments are used to recompose high-level segments, is beneficial and yields better results than using low-level or high-level segments in isolation."
2020.coling-main.303,Enabling Interactive Transcription in an Indigenous Community,2020,-1,-1,3,0,18204,eric ferrand,Proceedings of the 28th International Conference on Computational Linguistics,0,"We propose a novel transcription workflow which combines spoken term detection and human-in-the-loop, together with a pilot experiment. This work is grounded in an almost zero-resource scenario where only a few terms have so far been identified, involving two endangered languages. We show that in the early stages of transcription, when the available data is insufficient to train a robust ASR system, it is possible to take advantage of the transcription of a small number of isolated words in order to bootstrap the transcription of a speech collection."
2020.coling-main.314,Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation,2020,-1,-1,6,1,5778,hang le,Proceedings of the 28th International Conference on Computational Linguistics,0,"We introduce dual-decoder Transformer, a new model architecture that jointly performs automatic speech recognition (ASR) and multilingual speech translation (ST). Our models are based on the original Transformer architecture (Vaswani et al., 2017) but consist of two decoders, each responsible for one task (ASR or ST). Our major contribution lies in how these decoders interact with each other: one decoder can attend to different information sources from the other via a dual-attention mechanism. We propose two variants of these architectures corresponding to two different levels of dependencies between the decoders, called the parallel and cross dual-decoder Transformers, respectively. Extensive experiments on the MuST-C dataset show that our models outperform the previously-reported highest translation performance in the multilingual settings, and outperform as well bilingual one-to-one results. Furthermore, our parallel models demonstrate no trade-off between ASR and ST compared to the vanilla multi-task architecture. Our code and pre-trained models are available at https://github.com/formiel/speech-translation."
2020.coling-main.443,Online Versus Offline {NMT} Quality: An In-depth Analysis on {E}nglish-{G}erman and {G}erman-{E}nglish,2020,-1,-1,6,1,5712,maha elbayad,Proceedings of the 28th International Conference on Computational Linguistics,0,"We conduct in this work an evaluation study comparing offline and online neural machine translation architectures. Two sequence-to-sequence models: convolutional Pervasive Attention (Elbayad et al. 2018) and attention-based Transformer (Vaswani et al. 2017) are considered. We investigate, for both architectures, the impact of online decoding constraints on the translation quality through a carefully designed human evaluation on English-German and German-English language pairs, the latter being particularly sensitive to latency constraints. The evaluation results allow us to identify the strengths and shortcomings of each model when we shift to the online setup."
K19-1032,"Word Recognition, Competition, and Activation in a Model of Visually Grounded Speech",2019,26,0,3,1,5607,william havard,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"In this paper, we study how word-like units are represented and activated in a recurrent neural model of visually grounded speech. The model used in our experiments is trained to project an image and its spoken description in a common representation space. We show that a recurrent model trained on spoken sentences implicitly segments its input into word-like units and reliably maps them to their correct visual referents. We introduce a methodology originating from linguistics to analyse the representation learned by neural networks {--} the gating paradigm {--} and show that the correct representation of a word is only activated if the network has access to first phoneme of the target word, suggesting that the network does not rely on a global acoustic pattern. Furthermore, we find out that not all speech frames (MFCC vectors in our case) play an equal role in the final encoded representation of a given word, but that some frames have a crucial effect on it. Finally we suggest that word representation could be activated through a process of lexical competition."
D19-5631,Naver Labs {E}urope{'}s Systems for the Document-Level Generation and Translation Task at {WNGT} 2019,2019,18,0,4,0,6710,fahimeh saleh,Proceedings of the 3rd Workshop on Neural Generation and Translation,0,"Recently, neural models led to significant improvements in both machine translation (MT) and natural language generation tasks (NLG). However, generation of long descriptive summaries conditioned on structured data remains an open challenge. Likewise, MT that goes beyond sentence-level context is still an open issue (e.g., document-level MT or MT with metadata). To address these challenges, we propose to leverage data from both tasks and do transfer learning between MT, NLG, and MT with source-side metadata (MT+NLG). First, we train document-based MT systems with large amounts of parallel data. Then, we adapt these models to pure NLG and MT+NLG tasks by fine-tuning with smaller amounts of domain-specific data. This end-to-end NLG approach, without data selection and planning, outperforms the previous state of the art on the Rotowire NLG task. We participated to the {``}Document Generation and Translation{''} task at WNGT 2019, and ranked first in all tracks."
2019.nsurl-1.9,"Motivations, challenges, and perspectives for the development of an Automatic Speech Recognition System for the under-resourced {N}giemboon Language",2019,-1,-1,2,0,27284,patrice yemmene,Proceedings of The First International Workshop on NLP Solutions for Under Resourced Languages (NSURL 2019) co-located with ICNLSP 2019 - Short Papers,0,None
W18-5804,{A}daptor {G}rammars for the Linguist: Word Segmentation Experiments for Very Low-Resource Languages,2018,0,1,2,0,27865,pierre godard,"Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"Computational Language Documentation attempts to make the most recent research in speech and language technologies available to linguists working on language preservation and documentation. In this paper, we pursue two main goals along these lines. The first is to improve upon a strong baseline for the unsupervised word discovery task on two very low-resource Bantu languages, taking advantage of the expertise of linguists on these particular languages. The second consists in exploring the Adaptor Grammar framework as a decision and prediction tool for linguists studying a new language. We experiment 162 grammar configurations for each language and show that using Adaptor Grammars for word segmentation enables us to test hypotheses about a language. Specializing a generic grammar with language specific knowledge leads to great improvements for the word discovery task, ultimately achieving a leap of about 30{\%} token F-score from the results of a strong baseline."
W18-5402,Analyzing Learned Representations of a Deep {ASR} Performance Prediction Model,2018,0,2,2,1,27951,zied elloumi,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},0,"This paper addresses a relatively new task: prediction of ASR performance on unseen broadcast programs. In a previous paper, we presented an ASR performance prediction system using CNNs that encode both text (ASR transcript) and speech, in order to predict word error rate. This work is dedicated to the analysis of speech signal embeddings and text embeddings learnt by the CNN while training our prediction model. We try to better understand which information is captured by the deep model and its relation with different conditioning factors. It is shown that hidden layers convey a clear signal about speech style, accent and broadcast type. We then try to leverage these 3 types of information at training time through multi-task learning. Our experiments show that this allows to train slightly more efficient ASR performance prediction systems that - in addition - simultaneously tag the analyzed utterances according to their speech style, accent and broadcast program origin."
U18-1007,Exploring Textual and Speech information in Dialogue Act Classification with Speaker Domain Adaptation,2018,10,0,4,0,3742,xuanli he,Proceedings of the Australasian Language Technology Association Workshop 2018,0,"In spite of the recent success of Dialogue Act (DA) classification, the majority of prior works focus on text-based classification with oracle transcriptions, i.e. human transcriptions, instead of Automatic Speech Recognition (ASR){'}s transcriptions. In spoken dialog systems, however, the agent would only have access to noisy ASR transcriptions, which may further suffer performance degradation due to domain shift. In this paper, we explore the effectiveness of using both acoustic and textual signals, either oracle or ASR transcriptions, and investigate speaker domain adaptation for DA classification. Our multimodal model proves to be superior to the unimodal models, particularly when the oracle transcriptions are not available. We also propose an effective method for speaker domain adaptation, which achieves competitive results."
P18-1195,Token-level and sequence-level loss smoothing for {RNN} language models,2018,43,2,2,1,5712,maha elbayad,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Despite the effectiveness of recurrent neural network language models, their maximum likelihood estimation suffers from two limitations. It treats all sentences that do not match the ground truth as equally poor, ignoring the structure of the output space. Second, it suffers from {'}exposure bias{'}: during training tokens are predicted given ground-truth sequences, while at test time prediction is conditioned on generated output sequences. To overcome these limitations we build upon the recent reward augmented maximum likelihood approach that encourages the model to predict sentences that are close to the ground truth according to a given performance metric. We extend this approach to token-level loss smoothing, and propose improvements to the sequence-level smoothing approach. Our experiments on two different tasks, image captioning and machine translation, show that token-level and sequence-level loss smoothing are complementary, and significantly improve results."
L18-1001,Augmenting Librispeech with {F}rench Translations: A Multimodal Corpus for Direct Speech Translation Evaluation,2018,10,11,2,0,29500,ali kocabiyikoglu,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Recent works in spoken language translation (SLT) have attempted to build end-to-end speech-to-text translation without using source language transcription during learning or decoding. However, while large quantities of parallel texts (such as Europarl, OpenSubtitles) are available for training machine translation systems, there are no large (100h) and open source parallel corpora that include speech in a source language aligned to text in a target language. This paper tries to fill this gap by augmenting an existing (monolingual) corpus: LibriSpeech. This corpus, used for automatic speech recognition, is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned. After gathering French e-books corresponding to the English audio-books from LibriSpeech, we align speech segments at the sentence level with their respective translations and obtain 236h of usable parallel data. This paper presents the details of the processing as well as a manual evaluation conducted on a small subset of the corpus. This evaluation shows that the automatic alignments scores are reasonably correlated with the human judgments of the bilingual alignment quality. We believe that this corpus (which is made available online) is useful for replicable experiments in direct speech translation or more general spoken language translation experiments."
L18-1531,A Very Low Resource Language Speech Corpus for Computational Language Documentation Experiments,2018,0,4,5,0,27865,pierre godard,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Most speech and language technologies are trained with massive amounts of speech and text information. However, most of the world languages do not have such resources and some even lack a stable orthography. Building systems under these almost zero resource conditions is not only promising for speech technology but also for computational language documentation. The goal of computational language documentation is to help field linguists to (semi-)automatically analyze and annotate audio recordings of endangered, unwritten languages. Example tasks are automatic phoneme discovery or lexicon discovery from the speech signal. This paper presents a speech corpus collected during a realistic language documentation process. It is made up of 5k speech utterances in Mboshi (Bantu C25) aligned to French text translations. Speech transcriptions are also made available: they correspond to a non-standard graphemic form close to the language phonology. We detail how the data was collected, cleaned and processed and we illustrate its use through a zero-resource task: spoken term discovery. The dataset is made available to the community for reproducible computational language documentation experiments and their evaluation."
L18-1674,"Parallel Corpora in {M}boshi ({B}antu {C}25, {C}ongo-{B}razzaville)",2018,0,3,5,0,27867,annie rialland,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This article presents multimodal and parallel data collections in Mboshi, as part of the French-German BULB project. It aims at supporting documentation and providing digital resources for less resourced languages with the help of speech and language-based technology. The data collection specifications thus have to meet both field linguists' and computer scientists' requirements, which are large corpora for the latter and linguistically dense data for the former. Beyond speech, the collection comprises pictures and videos documenting social practices, agriculture, wildlife and plants. Visual supports aimed at encouraging people to comment on objects which are meaningful in their daily lives. Speech recordings are composed of the original speech in Mboshi, a respoken version and a translated version to French. These three speech streams remain time-aligned thanks to LIG-AIKUMA, which adds new features to a previous AIKUMA application. The speech corpus includes read material (5k sentences, Bible), verb conjugations and a large part of spontaneous speech (conversations, picture descriptions) resulting in over 50 hours of Mboshi speech, of which 20 hours are already respoken and orally translated to French. These parallel oral data are intended for linguistic documentation (tonology, phonology...) and automatic processing (corpus annotation, alignment between Mboshi speech and French translations)."
K18-1010,Pervasive Attention: 2{D} Convolutional Neural Networks for Sequence-to-Sequence Prediction,2018,0,7,2,1,5712,maha elbayad,Proceedings of the 22nd Conference on Computational Natural Language Learning,0,"Current state-of-the-art machine translation systems are based on encoder-decoder architectures, that first encode the input sequence, and then generate an output sequence based on the input encoding. Both are interfaced with an attention mechanism that recombines a fixed encoding of the source tokens based on the decoder state. We propose an alternative approach which instead relies on a single 2D convolutional neural network across both sequences. Each layer of our network re-codes source tokens on the basis of the output sequence produced so far. Attention-like properties are therefore pervasive throughout the network. Our model yields excellent results, outperforming state-of-the-art encoder-decoder systems, while being conceptually simpler and having fewer parameters."
W17-4772,{LIG}-{CRIS}t{AL} Submission for the {WMT} 2017 Automatic Post-Editing Task,2017,0,5,2,1,9749,alexandre berard,Proceedings of the Second Conference on Machine Translation,0,None
W17-4608,{A}mharic-{E}nglish Speech Translation in Tourism Domain,2017,0,0,2,0,13995,michael melese,Proceedings of the Workshop on Speech-Centric Natural Language Processing,0,"This paper describes speech translation from Amharic-to-English, particularly Automatic Speech Recognition (ASR) with post-editing feature and Amharic-English Statistical Machine Translation (SMT). ASR experiment is conducted using morpheme language model (LM) and phoneme acoustic model(AM). Likewise,SMT conducted using word and morpheme as unit. Morpheme based translation shows a 6.29 BLEU score at a 76.4{\%} of recognition accuracy while word based translation shows a 12.83 BLEU score using 77.4{\%} word recognition accuracy. Further, after post-edit on Amharic ASR using corpus based n-gram, the word recognition accuracy increased by 1.42{\%}. Since post-edit approach reduces error propagation, the word based translation accuracy improved by 0.25 (1.95{\%}) BLEU score. We are now working towards further improving propagated errors through different algorithms at each unit of speech translation cascading component."
W17-2502,Deep Investigation of Cross-Language Plagiarism Detection Methods,2017,12,1,2,1,31904,jeremy ferrero,Proceedings of the 10th Workshop on Building and Using Comparable Corpora,0,"This paper is a deep investigation of cross-language plagiarism detection methods on a new recently introduced open dataset, which contains parallel and comparable collections of documents with multiple characteristics (different genres, languages and sizes of texts). We investigate cross-language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages."
S17-2012,{C}ompi{LIG} at {S}em{E}val-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity,2017,8,6,2,1,31904,jeremy ferrero,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"We present our submitted systems for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of Spanish-English sentences, each system must estimate their semantic similarity by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these methods in unsupervised and supervised way. Our best run ranked 1st on track 4a with a correlation of 83.02{\%} with human annotations."
E17-2066,Using Word Embedding for Cross-Language Plagiarism Detection,2017,15,8,2,1,31904,jeremy ferrero,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,This paper proposes to use distributed representation of words (word embeddings) in cross-language textual similarity detection. The main contributions of this paper are the following: (a) we introduce new cross-language similarity detection methods based on distributed representation of words; (b) we combine the different methods proposed to verify their complementarity and finally obtain an overall F1 score of 89.15{\%} for English-French similarity detection at chunk level (88.5{\%} at sentence level) on a very challenging corpus.
2017.jeptalnrecital-long.5,Traitement des Mots Hors Vocabulaire pour la Traduction Automatique de Document {OCR}is{\\'e}s en Arabe (This article presents a new system that automatically translates images of arabic documents),2017,-1,-1,3,0,33219,kamel bouzidi,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 - Articles longs,0,"Cet article pr{\'e}sente un syst{\`e}me original de traduction de documents num{\'e}ris{\'e}s en arabe. Deux modules sont cascad{\'e}s : un syst{\`e}me de reconnaissance optique de caract{\`e}res (OCR) en arabe et un syst{\`e}me de traduction automatique (TA) arabe-fran{\c{c}}ais. Le couplage OCR-TA a {\'e}t{\'e} peu abord{\'e} dans la litt{\'e}rature et l{'}originalit{\'e} de cette {\'e}tude consiste {\`a} proposer un couplage {\'e}troit entre OCR et TA ainsi qu{'}un traitement sp{\'e}cifique des mots hors vocabulaire (MHV) engendr{\'e}s par les erreurs d{'}OCRisation. Le couplage OCR-TA par treillis et notre traitement des MHV par remplacement selon une mesure composite qui prend en compte forme de surface et contexte du mot, permettent une am{\'e}lioration significative des performances de traduction. Les exp{\'e}rimentations sont r{\'e}alis{\'e}s sur un corpus de journaux num{\'e}ris{\'e}s en arabe et permettent d{'}obtenir des am{\'e}liorations en score BLEU de 3,73 et 5,5 sur les corpus de d{\'e}veloppement et de test respectivement."
L16-1226,"The {CAMOMILE} Collaborative Annotation Platform for Multi-modal, Multi-lingual and Multi-media Documents",2016,0,7,8,0,34774,johann poignant,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we describe the organization and the implementation of the CAMOMILE collaborative annotation framework for multimodal, multimedia, multilingual (3M) data. Given the versatile nature of the analysis which can be performed on 3M data, the structure of the server was kept intentionally simple in order to preserve its genericity, relying on standard Web technologies. Layers of annotations, defined as data associated to a media fragment from the corpus, are stored in a database and can be managed through standard interfaces with authentication. Interfaces tailored specifically to the needed task can then be developed in an agile way, relying on simple but reliable services for the management of the centralized annotations. We then present our implementation of an active learning scenario for person annotation in video, relying on the CAMOMILE server; during a dry run experiment, the manual annotation of 716 speech segments was thus propagated to 3504 labeled tracks. The code of the CAMOMILE framework is distributed in open source."
L16-1611,Collecting Resources in Sub-{S}aharan {A}frican Languages for Automatic Speech Recognition: a Case Study of {W}olof,2016,13,31,2,0,30278,elodie gauthier,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This article presents the data collected and ASR systems developped for 4 sub-saharan african languages (Swahili, Hausa, Amharic and Wolof). To illustrate our methodology, the focus is made on Wolof (a very under-resourced language) for which we designed the first ASR system ever built in this language. All data and scripts are available online on our github repository."
L16-1657,"A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language Textual Similarity Detection",2016,0,5,3,1,31904,jeremy ferrero,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper we describe our effort to create a dataset for the evaluation of cross-language textual similarity detection. We present preexisting corpora and their limits and we explain the various gathered resources to overcome these limits and build our enriched dataset. The proposed dataset is multilingual, includes cross-language alignment for different granularities (from chunk to document), is based on both parallel and comparable corpora and contains human and machine translated texts. Moreover, it includes texts written by multiple types of authors (from average to professionals). With the obtained dataset, we conduct a systematic and rigorous evaluation of several state-of-the-art cross-language textual similarity detection methods. The evaluation results are reviewed and discussed. Finally, dataset and scripts are made publicly available on GitHub: http://github.com/FerreroJeremy/Cross-Language-Dataset."
L16-1662,{M}ulti{V}ec: a Multilingual and Multilevel Representation Learning Toolkit for {NLP},2016,13,20,4,1,9749,alexandre berard,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present MultiVec, a new toolkit for computing continuous representations for text at different granularity levels (word-level or sequences of words). MultiVec includes word2vec{'}s features, paragraph vector (batch and online) and bivec for bilingual distributed representations. MultiVec also includes different distance measures between words and sequences of words. The toolkit is written in C++ and is aimed at being fast (in the same order of magnitude as word2vec), easy to use, and easy to extend. It has been evaluated on several NLP tasks: the analogical reasoning task, sentiment analysis, and crosslingual document classification."
C16-1044,Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks,2016,40,2,3,1,35701,othman zennaki,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"This work focuses on the development of linguistic analysis tools for resource-poor languages. We use a parallel corpus to produce a multilingual word representation based only on sentence level alignment. This representation is combined with the annotated source side (resource-rich language) of the parallel corpus to train text analysis tools for resource-poor languages. Our approach is based on Recurrent Neural Networks (RNN) and has the following advantages: (a) it does not use word alignment information, (b) it does not assume any knowledge about foreign languages, which makes it applicable to a wide range of resource-poor languages, (c) it provides truly multilingual taggers. In a previous study, we proposed a method based on Simple RNN to automatically induce a Part-Of-Speech (POS) tagger. In this paper, we propose an improvement of our neural model. We investigate the Bidirectional RNN and the inclusion of external information (for instance low level information from Part-Of-Speech tags) in the RNN to train a more complex tagger (for instance, a multilingual super sense tagger). We demonstrate the validity and genericity of our method by using parallel corpora (obtained by manual or automatic translation). Our experiments are conducted to induce cross-lingual POS and super sense taggers."
C16-1110,{W}ord2{V}ec vs {DB}nary: Augmenting {METEOR} using Vector Representations or Lexical Resources?,2016,25,3,5,0.87726,5281,christophe servan,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"This paper presents an approach combining lexico-semantic resources and distributed representations of words applied to the evaluation in machine translation (MT). This study is made through the enrichment of a well-known MT evaluation metric: METEOR. METEOR enables an approximate match (synonymy or morphological similarity) between an automatic and a reference translation. Our experiments are made in the framework of the Metrics task of WMT 2014. We show that distributed representations are a good alternative to lexico-semanticresources for MT evaluation and they can even bring interesting additional information. The augmented versions of METEOR, using vector representations, are made available on our Github page."
2016.jeptalnrecital-long.21,Projection Interlingue d{'}{\\'E}tiquettes pour l{'}Annotation S{\\'e}mantique Non Supervis{\\'e}e (Cross-lingual Annotation Projection for Unsupervised Semantic Tagging),2016,-1,-1,3,1,35701,othman zennaki,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"Nos travaux portent sur la construction rapide d{'}outils d{'}analyse linguistique pour des langues peu dot{\'e}es en ressources. Dans une pr{\'e}c{\'e}dente contribution, nous avons propos{\'e} une m{\'e}thode pour la construction automatique d{'}un analyseur morpho-syntaxique via une projection interlingue d{'}annotations linguistiques {\`a} partir de corpus parall{\`e}les (m{\'e}thode fond{\'e}e sur les r{\'e}seaux de neurones r{\'e}currents). Nous pr{\'e}sentons, dans cet article, une am{\'e}lioration de notre mod{\`e}le neuronal, avec la prise en compte d{'}informations linguistiques externes pour un annotateur plus complexe. En particulier, nous proposons d{'}int{\'e}grer des annotations morpho-syntaxiques dans notre architecture neuronale pour l{'}apprentissage non supervis{\'e} d{'}annotateurs s{\'e}mantiques multilingues {\`a} gros grain (annotation en SuperSenses). Nous montrons la validit{\'e} de notre m{\'e}thode et sa g{\'e}n{\'e}ricit{\'e} sur l{'}italien et le fran{\c{c}}ais et {\'e}tudions aussi l{'}impact de la qualit{\'e} du corpus parall{\`e}le sur notre approche (g{\'e}n{\'e}r{\'e} par traduction manuelle ou automatique). Nos exp{\'e}riences portent sur la projection d{'}annotations de l{'}anglais vers le fran{\c{c}}ais et l{'}italien."
2016.jeptalnrecital-long.23,{W}ord2{V}ec vs {DB}nary ou comment (r{\\'e})concilier repr{\\'e}sentations distribu{\\'e}es et r{\\'e}seaux lexico-s{\\'e}mantiques ? Le cas de l{'}{\\'e}valuation en traduction automatique ({W}ord2{V}ec vs {DB}nary or how to bring back together vector representations and lexical resources ? A case study for machine translation evaluation),2016,-1,-1,4,0.87726,5281,christophe servan,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,Cet article pr{\'e}sente une approche associant r{\'e}seaux lexico-s{\'e}mantiques et repr{\'e}sentations distribu{\'e}es de mots appliqu{\'e}e {\`a} l{'}{\'e}valuation de la traduction automatique. Cette {\'e}tude est faite {\`a} travers l{'}enrichissement d{'}une m{\'e}trique bien connue pour {\'e}valuer la traduction automatique (TA) : METEOR. METEOR permet un appariement approch{\'e} (similarit{\'e} morphologique ou synonymie) entre une sortie de syst{\`e}me automatique et une traduction de r{\'e}f{\'e}rence. Nos exp{\'e}rimentations s{'}appuient sur la t{\^a}che Metrics de la campagne d{'}{\'e}valuation WMT 2014 et montrent que les repr{\'e}sentations distribu{\'e}es restent moins performantes que les ressources lexico-s{\'e}mantiques pour l{'}{\'e}valuation en TA mais peuvent n{\'e}ammoins apporter un compl{\'e}ment d{'}information int{\'e}ressant {\`a} ces derni{\`e}res.
Y15-1016,Unsupervised and Lightly Supervised Part-of-Speech Tagging Using Recurrent Neural Networks,2015,32,10,3,1,35701,othman zennaki,"Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation",0,"In this paper, we propose a novel approach to induce automatically a Part-Of-Speech (POS) tagger for resource-poor languages (languages that have no labeled training data). This approach is based on cross-language projection of linguistic annotations from parallel corpora without the use of word alignment information. Our approach does not assume any knowledge about foreign languages, making it applicable to a wide range of resource-poor languages. We use Recurrent Neural Networks (RNNs) as multilingual analysis tool. Our approach combined with a basic cross-lingual projection method (using word alignment information) achieves comparable results to the state-of-the-art. We also use our approach in a weakly supervised context, and it shows an excellent potential for very low-resource settings (less than 1k training utterances)."
W15-0713,Automated Translation of a Literary Work: A Pilot Study,2015,14,2,1,1,5610,laurent besacier,Proceedings of the Fourth Workshop on Computational Linguistics for Literature,0,"Current machine translation (MT) techniques are continuously improving. In specific areas , post-editing (PE) can enable the production of high-quality translations relatively quickly. But is it feasible to translate a literary work (fiction, short story, etc) using such an MTPE pipeline? This paper offers an initial response to this question. An essay by the American writer Richard Powers, currently not available in French, is automatically translated and post-edited and then revised by non-professional translators. In addition to presenting experimental evaluation results of the MTPE pipeline (MT system used, automatic evaluation), we also discuss the quality of the translation output from the perspective of a panel of readers (who read the translated short story in French, and answered a survey afterwards). Finally, some remarks of the official French translator of R. Powers, requested on this occasion, are given at the end of this article."
2015.mtsummit-papers.7,{METEOR} for multiple target languages using {DB}nary,2015,0,4,4,1,27951,zied elloumi,Proceedings of Machine Translation Summit XV: Papers,0,"This paper proposes an extension of METEOR, a well-known MT evaluation metric, for multiple target languages using an in-house lexical resource called DBnary (an extraction from Wiktionary provided to the community as a Multilingual Lexical Linked Open Data). Today, the use of the synonymy module of METEOR is only exploited when English is the target language (use of WordNet). A synonymy module using DBnary would allow its use for the 21 languages (covered up to now) as target languages. The code of this new instance of METEOR, adapted to several target languages, is provided to the community via a github repository. We also show that our DBnary augmented METEOR increases the correlation with human judgements on the WMT 2013 and 2014 metrics dataset for English-to-(French, Russian, German, Spanish) language pairs."
2015.jeptalnrecital-long.21,Utilisation de mesures de confiance pour am{\\'e}liorer le d{\\'e}codage en traduction de parole,2015,-1,-1,1,1,5610,laurent besacier,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les mesures de confiance au niveau mot (Word Confidence Estimation - WCE) pour la traduction auto- matique (TA) ou pour la reconnaissance automatique de la parole (RAP) attribuent un score de confiance {\`a} chaque mot dans une hypoth{\`e}se de transcription ou de traduction. Dans le pass{\'e}, l{'}estimation de ces mesures a le plus souvent {\'e}t{\'e} trait{\'e}e s{\'e}par{\'e}ment dans des contextes RAP ou TA. Nous proposons ici une estimation conjointe de la confiance associ{\'e}e {\`a} un mot dans une hypoth{\`e}se de traduction automatique de la parole (TAP). Cette estimation fait appel {\`a} des param{\`e}tres issus aussi bien des syst{\`e}mes de transcription de la parole (RAP) que des syst{\`e}mes de traduction automatique (TA). En plus de la construction de ces estimateurs de confiance robustes pour la TAP, nous utilisons les informations de confiance pour re-d{\'e}coder nos graphes d{'}hypoth{\`e}ses de traduction. Les exp{\'e}rimentations r{\'e}alis{\'e}es montrent que l{'}utilisation de ces mesures de confiance au cours d{'}une seconde passe de d{\'e}codage permettent d{'}obtenir une am{\'e}lioration significative des performances de traduction ({\'e}valu{\'e}es avec la m{\'e}trique BLEU - gains de deux points par rapport {\`a} notre syst{\`e}me de traduc- tion de parole de r{\'e}f{\'e}rence). Ces exp{\'e}riences sont faites pour une t{\^a}che de TAP (fran{\c{c}}ais-anglais) pour laquelle un corpus a {\'e}t{\'e} sp{\'e}cialement con{\c{c}}u (ce corpus, mis {\`a} la disposition de la communaut{\'e} TALN, est aussi d{\'e}crit en d{\'e}tail dans l{'}article)."
2015.jeptalnrecital-court.32,Utilisation des r{\\'e}seaux de neurones r{\\'e}currents pour la projection interlingue d{'}{\\'e}tiquettes morpho-syntaxiques {\\`a} partir d{'}un corpus parall{\\`e}le,2015,-1,-1,3,1,35701,othman zennaki,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"La construction d{'}outils d{'}analyse linguistique pour les langues faiblement dot{\'e}es est limit{\'e}e, entre autres, par le manque de corpus annot{\'e}s. Dans cet article, nous proposons une m{\'e}thode pour construire automatiquement des outils d{'}analyse via une projection interlingue d{'}annotations linguistiques en utilisant des corpus parall{\`e}les. Notre approche n{'}utilise pas d{'}autres sources d{'}information, ce qui la rend applicable {\`a} un large {\'e}ventail de langues peu dot{\'e}es. Nous proposons d{'}utiliser les r{\'e}seaux de neurones r{\'e}currents pour projeter les annotations d{'}une langue {\`a} une autre (sans utiliser d{'}information d{'}alignement des mots). Dans un premier temps, nous explorons la t{\^a}che d{'}annotation morpho-syntaxique. Notre m{\'e}thode combin{\'e}e avec une m{\'e}thode de projection d{'}annotation basique (utilisant l{'}alignement mot {\`a} mot), donne des r{\'e}sultats comparables {\`a} ceux de l{'}{\'e}tat de l{'}art sur une t{\^a}che similaire."
2015.iwslt-papers.11,An open-source toolkit for word-level confidence estimation in machine translation,2015,33,5,5,0.87726,5281,christophe servan,Proceedings of the 12th International Workshop on Spoken Language Translation: Papers,0,"Recently, a growing need of Confidence Estimation (CE) for Statistical Machine Translation (SMT) systems in Computer Aided Translation (CAT), was observed. However, most of the CE toolkits are optimized for a single target language (mainly English) and, as far as we know, none of them are dedicated to this specific task and freely available. This paper presents an open-source toolkit for predicting the quality of words of a SMT output, whose novel contributions are (i) support for various target languages, (ii) handle a number of features of different types (system-based, lexical , syntactic and semantic). In addition, the toolkit also integrates a wide variety of Natural Language Processing or Machine Learning tools to pre-process data, extract features and estimate confidence at word-level. Features for Word-level Confidence Estimation (WCE) can be easily added / removed using a configuration file. We validate the toolkit by experimenting in the WCE evaluation framework of WMT shared task with two language pairs: French-English and English-Spanish. The toolkit is made available to the research community with ready-made scripts to launch full experiments on these language pairs, while achieving state-of-the-art and reproducible performances."
W14-3342,{LIG} System for Word Level {QE} task at {WMT}14,2014,9,20,2,1,37407,ngocquang luong,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper describes our Word-level QE system for WMT 2014 shared task on Spanish-English pair. Compared to WMT 2013, this year's task is different due to the lack of SMT setting information and additional resources. We report how we overcome this challenge to retain most of the important features which performed well last year in our system. Novel features related to the availability of multiple systems output (new point of this year) are also proposed and experimented along with baseline set. The system is optimized by several ways: tuning the classification threshold, combining with WMT 2013 data, and refining using Feature Selection strategy on our development set, before dealing with the test set for submission."
W14-0301,Word Confidence Estimation for {SMT} N-best List Re-ranking,2014,21,5,2,1,37407,ngocquang luong,Proceedings of the {EACL} 2014 Workshop on Humans and Computer-assisted Translation,0,"This paper proposes to use Word Confidence Estimation (WCE) information to improve MT outputs via N-best list reranking. From the confidence label assigned for each word in the MT hypothesis, we add six scores to the baseline loglinear model in order to re-rank the N-best list. Firstly, the correlation between the WCE-based sentence-level scores and the conventional evaluation scores (BLEU, TER, TERp-A) is investigated. Then, the N-best list re-ranking is evaluated over different WCE system performance levels: from our real and efficient WCE system (ranked 1st during last WMT 2013 Quality Estimation Task) to an oracle WCE (which simulates an interactive scenario where a user simply validates words of a MT hypothesis and the new output will be automatically re-generated). The results suggest that our real WCE system slightly (but significantly) improves the baseline while the oracle one extremely boosts it; and better WCE leads to better MT quality."
F14-2001,Machine translation for litterature: a pilot study (Traduction automatis{\\'e}e d{'}une oeuvre litt{\\'e}raire: une {\\'e}tude pilote) [in {F}rench],2014,-1,-1,1,1,5610,laurent besacier,Proceedings of TALN 2014 (Volume 2: Short Papers),0,None
2014.eamt-1.23,An efficient two-pass decoder for {SMT} using word confidence estimation,2014,0,3,2,1,37407,ngocquang luong,Proceedings of the 17th Annual conference of the European Association for Machine Translation,0,"During decoding, the Statistical Machine Translation (SMT) decoder travels over all complete paths on the Search Graph (SG), seeks those with cheapest costs and back-tracks to read off the best translations. Although these winners beat the rest in model scores, there is no certain guarantee that they have the highest quality with respect to the human references. This paper exploits Word Confidence Estimation (WCE) scores in the second pass of decoding to enhance the Machine Translation (MT) quality. By using the confidence score of each word in the N-best list to update the cost of SG hypotheses containing it, we hope to  reinforce  or  weaken  them relied on word quality. After the update, new best translations are re-determined using updated costs. In the experiments on our real WCE scores and ideal (oracle) ones, the latter significantly boosts one-pass de-coder by 7.87 BLEU points, meanwhile the former yields an improvement of 1.49 points for the same metric."
2014.amta-researchers.23,Data selection for compact adapted {SMT} models,2014,17,7,2,0,27123,shachar mirkin,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas: MT Researchers Track,0,"Data selection is a common technique for adapting statistical translation models for a specific domain, which has been shown to both improve translation quality and to reduce model size. Selection relies on some in-domain data, of the same domain of the texts expected to be translated. Selecting the sentence-pairs that are most similar to the in-domain data from a pool of parallel texts has been shown to be effective; yet, this approach holds the risk of resulting in a limited coverage, when necessary n-grams that do appear in the pool are less similar to in-domain data that is available in advance. Some methods select additional data based on the actual text that needs to be translated. While useful, this is not always a practical scenario. In this work we describe an extensive exploration of data selection techniques over Arabic to French datasets, and propose methods to address both similarity and coverage considerations while maintaining a limited model size."
W13-4701,Fast Bootstrapping of Grapheme to Phoneme System for Under-resourced Languages - Application to the {I}ban Language,2013,6,4,2,0,40623,sarah juan,Proceedings of the 4th Workshop on South and Southeast {A}sian Natural Language Processing,0,"This paper deals with the fast bootstrapping of Grapheme-to-Phoneme (G2P) conversion system, which is a key module for both automatic speech recognition (ASR), and text-to-speech synthesis (TTS). The idea is to exploit language contact between a local dominant language (Malay) and a very under-resourced language (Iban - spoken in Sarawak and in several parts of the Borneo Island) for which no resource nor knowledge is really available. More precisely, a pre-existing Malay G2P is used to produce phoneme sequences of Iban words. The phonemes are then manually post-edited (corrected) by an Iban native. This resource, which has been produced in a semi-supervised fashion, is later used to train the first G2P system for Iban language. As a by-product of this methodology, the analysis of the xe2x80x9cpronunciation distancexe2x80x9d between Malay and Iban enlighten the phonological and orthographic relations between these two languages. The experiments conducted show that a rather efficient Iban G2P system can be obtained after only two hours of post-edition (correction) of the output of Malay G2P applied to Iban words."
W13-4706,{U}rdu {H}indi Machine Transliteration using {SMT},2013,32,3,3,1,40630,abbas malik,Proceedings of the 4th Workshop on South and Southeast {A}sian Natural Language Processing,0,"Transliteration is a process of transcribing a word of the source language into the target language such that when the native speaker of the target language pronounces it, it sounds as the native pronunciation of the source word. Statistical techniques have brought significant advances and have made real progress in various fields of Natural Language Processing (NLP). In this paper, we have analysed the application of Statistical Machine Translation (SMT) for solving the problem of Urdu Hindi transliteration using a parallel lexicon. We have designed total 24 Statistical Transliteration (ST) systems by combining different types of alignments, translation models and target language models. We have performed total 576 experiments and have reported significant results. From Hindixe2x80x93toxe2x80x93Urdu transliteration, we have achieved the maximum word-level accuracy of 71.5%. From Urduxe2x80x93toxe2x80x93Hindi transliteration, the maximum word-level accuracy is 77.8% when the input Urdu text contains all necessary diacritical marks and 77% when the input Urdu text does not contain all necessary diacritical marks. At character-level, transliteration accuracy is more than 90% in both directions."
W13-2248,{LIG} System for {WMT}13 {QE} Task: Investigating the Usefulness of Features in Word Confidence Estimation for {MT},2013,10,15,3,1,37407,ngocquang luong,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"This paper presents the LIGxe2x80x99s systems submitted for Task 2 of WMT13 Quality Estimation campaign. This is a word confidence estimation (WCE) task where each participant was asked to label each word in a translated text as a binary ( Keep/Change) or multi-class (Keep/Substitute/Delete) category. We integrate a number of features of various types (system-based, lexical, syntactic and semantic) into the conventional feature set, for our baseline classifier training. After the experiments with all features, we deploy a xe2x80x9cFeature Selectionxe2x80x9d strategy to keep only the best performing ones. Then, a method that combines multiple xe2x80x9cweakxe2x80x9d classifiers to build a strong xe2x80x9ccompositexe2x80x9d classifier by taking advantage of their complementarity is presented and experimented. We then select the best systems for submission and present the official results obtained."
F13-2004,Driven Decoding for machine translation (Vers un d{\\'e}codage guid{\\'e} pour la traduction automatique) [in {F}rench],2013,0,0,2,0.745614,5784,benjamin lecouteux,Proceedings of TALN 2013 (Volume 2: Short Papers),0,None
F13-1007,Discriminative statistical approaches for multilingual speech understanding (Approches statistiques discriminantes pour l{'}interpr{\\'e}tation s{\\'e}mantique multilingue de la parole) [in {F}rench],2013,0,0,3,1,27633,bassam jabaian,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
2013.mtsummit-wmwumttt.8,How hard is it to automatically translate phrasal verbs from {E}nglish to {F}rench?,2013,19,4,2,0,41878,carlos ramish,Proceedings of the Workshop on Multi-word Units in Machine Translation and Translation Technologies,0,"The translation of English phrasal verbs (PVs) into French is a challenge, specially when the verb occurs apart from the particle. Our goal is to quantify how well current SMT paradigms can translate split PVs into French. We compare two inhouse SMT systems, phrase-based and hierarchical, in translating a test set of PVs. Our analysis is based on a carefully designed evaluation protocol for assessing translation quality of a specific linguistic phenomenon. We find out that (a) current SMT technology can only translate 27% of PVs correctly, (b) in spite of their simplistic model, phrase-based systems outperform hierarchical systems and (c) when both systems translate the PV similarly, translation quality improves."
W12-1305,Analyse des performances de mod{\\`e}les de langage sub-lexicale pour des langues peu-dot{\\'e}es {\\`a} morphologie riche (Performance analysis of sub-word language modeling for under-resourced languages with rich morphology: case study on {S}wahili and {A}mharic) [in {F}rench],2012,-1,-1,3,0,42466,hadrien gelas,"{JEP}-{TALN}-{RECITAL} 2012, Workshop {TALA}f 2012: Traitement Automatique des Langues Africaines ({TALA}f 2012: {A}frican Language Processing)",0,None
potet-etal-2012-collection,Collection of a Large Database of {F}rench-{E}nglish {SMT} Output Corrections,2012,2,34,3,1,43044,marion potet,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Corpus-based approaches to machine translation (MT) rely on the availability of parallel corpora. To produce user-acceptable translation outputs, such systems need high quality data to be efficiency trained, optimized and evaluated. However, building high quality dataset is a relatively expensive task. In this paper, we describe the data collection and analysis of a large database of 10.881 SMT translation output hypotheses manually corrected. These post-editions were collected using Amazon's Mechanical Turk, following some ethical guidelines. A complete analysis of the collected data pointed out a high quality of the corrections with more than 87 {\%} of the collected post-editions that improve hypotheses and more than 94 {\%} of the crowdsourced post-editions which are at least of professional quality. We also post-edited 1,500 gold-standard reference translations (of bilingual parallel corpora generated by professional) and noticed that 72 {\%} of these translations needed to be corrected during post-edition. We computed a proximity measure between the differents kind of translations and pointed out that reference translations are as far from the hypotheses than from the corrected hypotheses (i.e. the post-editions). In light of these last findings, we discuss the adequation of text-based generated reference translations to train setence-to-sentence based SMT systems."
lefevre-etal-2012-leveraging,Leveraging study of robustness and portability of spoken language understanding systems across languages and domains: the {PORTMEDIA} corpora,2012,20,9,3,1,27634,fabrice lefevre,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The PORTMEDIA project is intended to develop new corpora for the evaluation of spoken language understanding systems. The newly collected data are in the field of human-machine dialogue systems for tourist information in French in line with the MEDIA corpus. Transcriptions and semantic annotations, obtained by low-cost procedures, are provided to allow a thorough evaluation of the systems' capabilities in terms of robustness and portability across languages and domains. A new test set with some adaptation data is prepared for each case: in Italian as an example of a new language, for ticket reservation as an example of a new domain. Finally the work is complemented by the proposition of a new high level semantic annotation scheme well-suited to dialogue data."
F12-1080,D{\\'e}veloppement de ressources en swahili pour un syt{\\`e}me de reconnaisance automatique de la parole (Developments of {S}wahili resources for an automatic speech recognition system) [in {F}rench],2012,-1,-1,2,0,42466,hadrien gelas,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
F12-1098,Robustesse et portabilit{\\'e}s multilingue et multi-domaines des syst{\\`e}mes de compr{\\'e}hension de la parole : les corpus du projet {P}ort{M}edia (Robustness and portability of spoken language understanding systems among languages and domains : the {PORTMEDIA} project) [in {F}rench],2012,0,1,3,1,27634,fabrice lefevre,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 1: JEP",0,None
2012.iwslt-papers.19,Towards a better understanding of statistical post-editing,2012,18,3,2,1,43044,marion potet,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"We describe several experiments to better understand the usefulness of statistical post-edition (SPE) to improve phrase-based statistical MT (PBMT) systems raw outputs. Whatever the size of the training corpus, we show that SPE systems trained on general domain data offers no breakthrough to our baseline general domain PBMT system. However, using manually post-edited system outputs to train the SPE led to a slight improvement in the translations quality compared with the use of professional reference translations. We also show that SPE is far more effective for domain adaptation, mainly because it recovers a lot of specific terms unknown to our general PBMT system. Finally, we compare two domain adaptation techniques, post-editing a general domain PBMT system vs building a new domain-adapted PBMT system with two different techniques, and show that the latter outperforms the first one. Yet, when the PBMT is a {``}black box{''}, SPE trained with post-edited system outputs remains an interesting option for domain adaptation."
2012.iwslt-evaluation.13,The {LIG} {E}nglish to {F}rench machine translation system for {IWSLT} 2012,2012,15,5,1,1,5610,laurent besacier,Proceedings of the 9th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper presents the LIG participation to the E-F MT task of IWSLT 2012. The primary system proposed made a large improvement (more than 3 point of BLEU on tst2010 set) compared to our last year participation. Part of this improvment was due to the use of an extraction from the Gigaword corpus. We also propose a preliminary adaptation of the driven decoding concept for machine translation. This method allows an efficient combination of machine translation systems, by rescoring the log-linear model at the N-best list level according to auxiliary systems: the basis technique is essentially guiding the search using one or previous system outputs. The results show that the approach allows a significant improvement in BLEU score using Google translate to guide our own SMT system. We also try to use a confidence measure as an additional log-linear feature but we could not get any improvment with this technique."
W11-2154,The {LIGA} ({LIG}/{LIA}) Machine Translation System for {WMT} 2011,2011,7,2,5,1,43044,marion potet,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the system submitted by the Laboratory of Informatics of Grenoble (LIG) for the fifth Workshop on Statistical Machine Translation. We participated to the news shared translation task for the French-English language pair. We investigated differents techniques to simply deal with Out-Of-Vocabulary words in a statistical phrase-based machine translation system and analyze their impact on translation quality. The final submission is a combination between a standard phrase-based system using the Moses decoder, with appropriate setups and pre-processing, and a lemmatized system to deal with Out-Of-Vocabulary conjugated verbs."
2011.jeptalnrecital-long.7,Comparaison et combinaison d{'}approches pour la portabilit{\\'e} vers une nouvelle langue d{'}un syst{\\`e}me de compr{\\'e}hension de l{'}oral (Comparison and combination of approaches for the portability to a new language of an oral comprehension system),2011,-1,-1,2,1,27633,bassam jabaian,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous proposons plusieurs approches pour la portabilit{\'e} du module de compr{\'e}hension de la parole (SLU) d{'}un syst{\`e}me de dialogue d{'}une langue vers une autre. On montre que l{'}utilisation des traductions automatiques statistiques (SMT) aide {\`a} r{\'e}duire le temps et le cout de la portabilit{\'e} d{'}un tel syst{\`e}me d{'}une langue source vers une langue cible. Pour la tache d{'}{\'e}tiquetage s{\'e}mantique on propose d{'}utiliser soit les champs al{\'e}atoires conditionnels (CRF), soit l{'}approche {\`a} base de s{\'e}quences (PH-SMT). Les r{\'e}sultats exp{\'e}rimentaux montrent l{'}efficacit{\'e} des m{\'e}thodes propos{\'e}es pour une portabilit{\'e} rapide du SLU vers une nouvelle langue. On propose aussi deux m{\'e}thodes pour accro{\^\i}tre la robustesse du SLU aux erreurs de traduction. Enfin on montre que la combinaison de ces approches r{\'e}duit les erreurs du syst{\`e}me. Ces travaux sont motiv{\'e}s par la disponibilit{\'e} du corpus MEDIA fran{\c{c}}ais et de la traduction manuelle vers l{'}italien d{'}une sous partie de ce corpus."
2011.iwslt-evaluation.8,{LIG} {E}nglish-{F}rench spoken language translation system for {IWSLT} 2011,2011,8,1,2,0.745614,5784,benjamin lecouteux,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the system developed by the LIG laboratory for the 2011 IWSLT evaluation. We participated to the English-French MT and SLT tasks. The development of a reference translation system (MT task), as well as an ASR output translation system (SLT task) are presented. We focus this year on the SLT task and on the use of multiple 1-best ASR outputs to improve overall translation quality. The main experiment presented here compares the performance of a SLT system where multiple ASR 1-best are combined before translation (source combination), with a SLT system where multiple ASR 1-best are translated, the system combination being conducted afterwards on the target side (target combination). The experimental results show that the second approach (target combination) overpasses the first one, when the performance is measured with BLEU."
2011.eamt-1.24,Oracle-based Training for Phrase-based Statistical Machine Translation,2011,19,4,4,1,43044,marion potet,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"A Statistical Machine Translation (SMT) system generates an n-best list of candidate translations for each sentence. A model error occurs if the most probable translation (1-best) generated by the SMT decoder is not the most accurate as measured by its similarity to the human reference translation(s) (an oracle). In this paper we investigate the parametric differences between the 1-best and the oracle translation and attempt to try and close this gap by proposing two rescoring strategies to push the oracle up the n-best list. We observe modest improvements in METEOR scores over the baseline SMT system trained on Frenchxe2x80x93 English Europarl corpora. We present a detailed analysis of the oracle rankings to determine the source of model errors, which in turn has the potential to improve overall system performance."
W10-3601,Boosting N-gram Coverage for Unsegmented Languages Using Multiple Text Segmentation Approach,2010,5,1,2,1,13993,solomon abate,Proceedings of the 1st Workshop on South and Southeast {A}sian Natural Language Processing,0,"Automatic word segmentation errors, for languages having a writing system without word boundaries, negatively affect the performance of language models. As a solution, the use of multiple, instead of unique, segmentation has recently been proposed. This approach boosts N-gram counts and generates new N-grams. However, it also produces bad N-grams that affect the language models' performance. In this paper, we study more deeply the contribution of our multiple segmentation approach and experiment on an efficient solution to minimize the effect of adding bad N-grams."
W10-1723,The {LIG} Machine Translation System for {WMT} 2010,2010,9,16,2,1,43044,marion potet,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the system submitted by the Laboratory of Informatics of Grenoble (LIG) for the fifth Workshop on Statistical Machine Translation. We participated to the news shared translation task for the French-English language pair. We investigated differents techniques to simply deal with Out-Of-Vocabulary words in a statistical phrase-based machine translation system and analyze their impact on translation quality. The final submission is a combination between a standard phrase-based system using the Moses decoder, with appropriate setups and pre-processing, and a lemmatized system to deal with Out-Of-Vocabulary conjugated verbs."
belgacem-etal-2010-automatic,Automatic Identification of {A}rabic Dialects,2010,2,7,3,0,46261,mohamed belgacem,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this work, automatic recognition of Arabic dialects is proposed. An acoustic survey of the proportion of vocalic intervals and the standard deviation of consonantal intervals in nine dialects (Tunisia, Morocco, Algeria, Egypt, Syria, Lebanon, Yemen, GolfÂs Countries and Iraq) is performed using the platform Alize and Gaussian Mixture Models (GMM). The results show the complexity of the automatic identification of Arabic dialects since. No clear border can be found between the dialects, but a gradual transition between them. They can even vary slightly from one city to another. The existence of this gradual change is easy to understand: it corresponds to a human and social reality, to the contact, friendships forged and affinity in the environment more or less immediate of the individual. This document also raises questions about the classes or macro classes of Arabic dialects noticed from the confusion matrix and the design of the hierarchical tree obtained."
2010.jeptalnrecital-long.28,Apprentissage non supervis{\\'e} pour la traduction automatique : application {\\`a} un couple de langues peu dot{\\'e},2010,-1,-1,2,0,46580,thi diep,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente une m{\'e}thode non-supervis{\'e}e pour extraire des paires de phrases parall{\`e}les {\`a} partir d{'}un corpus comparable. Un syst{\`e}me de traduction automatique est utilis{\'e} pour exploiter le corpus comparable et d{\'e}tecter les paires de phrases parall{\`e}les. Un processus it{\'e}ratif est ex{\'e}cut{\'e} non seulement pour augmenter le nombre de paires de phrases parall{\`e}les extraites, mais aussi pour am{\'e}liorer la qualit{\'e} globale du syst{\`e}me de traduction. Une comparaison avec une m{\'e}thode semi-supervis{\'e}e est pr{\'e}sent{\'e}e {\'e}galement. Les exp{\'e}riences montrent que la m{\'e}thode non-supervis{\'e}e peut {\^e}tre r{\'e}ellement appliqu{\'e}e dans le cas o{\`u} on manque de donn{\'e}es parall{\`e}les. Bien que les exp{\'e}riences pr{\'e}liminaires soient men{\'e}es sur la traduction fran{\c{c}}ais-anglais, cette m{\'e}thode non-supervis{\'e}e est {\'e}galement appliqu{\'e}e avec succ{\`e}s {\`a} un couple de langues peu dot{\'e} : vietnamien-fran{\c{c}}ais."
2010.jeptalnrecital-court.7,Weak Translation Problems {--} a case study of Scriptural Translation,2010,4,0,4,0,45925,muhammad malik,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"General purpose, high quality and fully automatic MT is believed to be impossible. We are interested in scriptural translation problems, which are weak sub-problems of the general problem of translation. We introduce the characteristics of the weak problems of translation and of the scriptural translation problems, describe different computational approaches (finite-state, statistical and hybrid) to solve these problems, and report our results on several combinations of Indo-Pak languages and writing systems."
2010.iwslt-papers.4,Improved {V}ietnamese-{F}rench parallel corpus mining using {E}nglish language,2010,0,1,2,0,7932,thi do,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,None
2010.iwslt-evaluation.12,{LIG} statistical machine translation systems for {IWSLT} 2010,2010,0,1,1,1,5610,laurent besacier,Proceedings of the 7th International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2010.eamt-1.6,A fully unsupervised approach for mining parallel data from comparable corpora,2010,13,13,2,0,7932,thi do,Proceedings of the 14th Annual conference of the European Association for Machine Translation,0,None
W09-3536,A Hybrid Model for {U}rdu {H}indi Transliteration,2009,11,20,2,1,40630,abbas malik,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"We report in this paper a novel hybrid approach for Urdu to Hindi transliteration that combines finite-state machine (FSM) based techniques with statistical word language model based approach. The output from the FSM is filtered with the word language model to produce the correct Hindi output. The main problem handled is the case of omission of diacritical marks from the input Urdu text. Our system produces the correct Hindi output even when the crucial information in the form of diacritic marks is absent. The approach improves the accuracy of the transducer-only approach from 50.7% to 79.1%. The results reported show that performance can be improved using a word language model to disambiguate the output produced by the transducer-only approach, especially when diacritic marks are not present in the Urdu input."
W09-0430,Mining a Comparable Text Corpus for a {V}ietnamese-{F}rench Statistical Machine Translation System,2009,19,16,4,0,47112,thingocdiep do,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"This paper presents our first attempt at constructing a Vietnamese-French statistical machine translation system. Since Vietnamese is an under-resourced language, we concentrate on building a large Vietnamese-French parallel corpus. A document alignment method based on publication date, special words and sentence alignment result is proposed. The paper also presents an application of the obtained parallel corpus to the construction of a Vietnamese-French statistical machine translation system, where the use of different units for Vietnamese (syllables, words, or their combinations) is discussed."
2009.jeptalnrecital-long.9,Exploitation d{'}un corpus bilingue pour la cr{\\'e}ation d{'}un syst{\\`e}me de traduction probabiliste Vietnamien - Fran{\\c{c}}ais,2009,-1,-1,4,0,47112,thingocdiep do,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente nos premiers travaux en vue de la construction d{'}un syst{\`e}me de traduction probabiliste pour le couple de langue vietnamien-fran{\c{c}}ais. La langue vietnamienne {\'e}tant consid{\'e}r{\'e}e comme une langue peu dot{\'e}e, une des difficult{\'e}s r{\'e}side dans la constitution des corpus parall{\`e}les, indispensable {\`a} l{'}apprentissage des mod{\`e}les. Nous nous concentrons sur la constitution d{'}un grand corpus parall{\`e}le vietnamien-fran{\c{c}}ais. La m{\'e}thode d{'}identification automatique des paires de documents parall{\`e}les fond{\'e}e sur la date de publication, les mots sp{\'e}ciaux et les scores d{'}alignements des phrases est appliqu{\'e}e. Cet article pr{\'e}sente {\'e}galement la construction d{'}un premier syst{\`e}me de traduction automatique probabiliste vietnamienfran{\c{c}}ais et fran{\c{c}}ais-vietnamien {\`a} partir de ce corpus et discute l{'}opportunit{\'e} d{'}utiliser des unit{\'e}s lexicales ou sous-lexicales pour le vietnamien (syllabes, mots, ou leurs combinaisons). Les performances du syst{\`e}me sont encourageantes et se comparent avantageusement {\`a} celles du syst{\`e}me de Google."
2009.jeptalnrecital-court.37,Segmentation multiple d{'}un flux de donn{\\'e}es textuelles pour la mod{\\'e}lisation statistique du langage,2009,-1,-1,2,1,45224,sopheap seng,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"Dans cet article, nous traitons du probl{\`e}me de la mod{\'e}lisation statistique du langage pour les langues peu dot{\'e}es et sans segmentation entre les mots. Tandis que le manque de donn{\'e}es textuelles a un impact sur la performance des mod{\`e}les, les erreurs introduites par la segmentation automatique peuvent rendre ces donn{\'e}es encore moins exploitables. Pour exploiter au mieux les donn{\'e}es textuelles, nous proposons une m{\'e}thode qui effectue des segmentations multiples sur le corpus d{'}apprentissage au lieu d{'}une segmentation unique. Cette m{\'e}thode bas{\'e}e sur les automates d{'}{\'e}tat finis permet de retrouver les n-grammes non trouv{\'e}s par la segmentation unique et de g{\'e}n{\'e}rer des nouveaux n-grammes pour l{'}apprentissage de mod{\`e}le du langage. L{'}application de cette approche pour l{'}apprentissage des mod{\`e}les de langage pour les syst{\`e}mes de reconnaissance automatique de la parole en langue khm{\`e}re et vietnamienne s{'}est montr{\'e}e plus performante que la m{\'e}thode par segmentation unique, {\`a} base de r{\`e}gles."
2009.iwslt-evaluation.9,{LIG} approach for {IWSLT}09,2009,-1,-1,2,0.20587,13777,fethi bougares,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"This paper describes the LIG experiments in the context of IWSLT09 evaluation (Arabic to English Statistical Machine Translation task). Arabic is a morphologically rich language, and recent experimentations in our laboratory have shown that the performance of Arabic to English SMT systems varies greatly according to the Arabic morphological segmenters applied. Based on this observation, we propose to use simultaneously multiple segmentations for machine translation of Arabic. The core idea is to keep the ambiguity of the Arabic segmentation in the system input (using confusion networks or lattices). Then, we hope that the best segmentation will be chosen during MT decoding. The mathematics of this multiple segmentation approach are given. Practical implementations in the case of verbatim text translation as well as speech translation (outside of the scope of IWSLT09 this year) are proposed. Experiments conducted in the framework of IWSLT evaluation campaign show the potential of the multiple segmentation approach. The last part of this paper explains in detail the different systems submitted by LIG at IWSLT09 and the results obtained."
seng-etal-2008-first,First Broadcast News Transcription System for {K}hmer Language,2008,13,2,3,1,45224,sopheap seng,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper we present an overview on the development of a large vocabulary continuous speech recognition (LVCSR) system for Khmer, the official language of Cambodia, spoken by more than 15 million people. As an under-resourced language, develop a LVCSR system for Khmer is a challenging task. We describe our methodologies for quick language data collection and processing for language modeling and acoustic modeling. For language modeling, we investigate the use of word and sub-word as basic modeling unit in order to see the potential of sub-word units in the case of unsegmented language like Khmer. Grapheme-based acoustic modeling is used to quickly build our Khmer language acoustic model. Furthermore, the approaches and tools used for the development of our system are documented and made publicly available on the web. We hope this will contribute to accelerate the development of LVCSR system for a new language, especially for under-resource languages of developing countries where resources and expertise are limited."
2007.iwslt-1.20,The {LIG} {A}rabic/{E}nglish speech translation system at {IWSLT}07,2007,0,8,1,1,5610,laurent besacier,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper is a description of the system presented by the LIG laboratory to the IWSLT07 speech translation evaluation. The LIG participated, for the first time this year, in the Arabic to English speech translation task. For translation, we used a conventional statistical phrase-based system developed using the moses open source decoder. Our baseline MT system is described and we discuss particularly the use of an additional bilingual dictionary which seems useful when few training data is available. The main contribution of this paper concerns the proposal of a lattice decomposition algorithm that allows transforming a word lattice into a sub word lattice compatible with our MT model that uses word segmentation on the Arabic part. The lattice is then transformed into a confusion network which can be directly decoded into moses. The results show that this method outperforms the conventional 1-best translation which consists in translating only the most probable ASR hypothesis. The best BLEU score, from ASR output obtained on IWSLT06 evaluation data is 0.2253. The results confirm the interest of full CN decoding for speech translation, compared to traditional ASR 1-best approach. Our primary system was ranked 7/14 for IWSLT07 AE ASR task with a BLEU score of 0.3804."
W06-3711,{IBM} {MASTOR} SYSTEM: Multilingual Automatic Speech-to-Speech Translator,2006,13,38,10,0,47817,yuqing gao,Proceedings of the First International Workshop on Medical Speech Translation,0,"In this paper, we describe the IBM MASTOR, a speech-to-speech translation system that can translate spontaneous free-form speech in real-time on both laptop and hand-held PDAs. Challenges include speech recognition and machine translation in adverse environments, lack of training data and linguistic resources for under-studied languages, and the need to rapidly develop capabilities for new languages. Another challenge is designing algorithms and building models in a scalable manner to perform well even on memory and CPU deficient hand-held computers. We describe our approaches, experience, and success in building working free-form S2S systems that can handle two language pairs (including a low-resource language)."
tan-besacier-2006-french,A {F}rench Non-Native Corpus for Automatic Speech Recognition,2006,12,6,2,0,50104,tienping tan,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Automatic speech recognition (ASR) technology has achieved a level of maturity, where it is already practical to be used by novice users. However, most non-native speakers are still not comfortable with services including ASR systems, because of the accuracy on non-native speakers. This paper describes our approach in constructing a non-native corpus particularly in French for testing and adapting non-native speaker for automatic speech recognition. Finally, we also propose in this paper a method for detecting pronunciation variants and possible pronunciation mistakes by non-native speakers."
le-etal-2004-spoken,Spoken and Written Language Resources for {V}ietnamese,2004,5,33,4,0,44974,vietbac le,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents an overview of our activities for spoken and written language resources for Vietnamese implemented at CLIPSIMAG Laboratory and International Research Center MICA. A new methodology for fast text corpora acquisition for minority languages which has been applied to Vietnamese is proposed. The first results of a process of building a large Vietnamese speech database (VNSpeechCorpus) and a phonetic dictionary, which is used for automatic alignment process, are also presented."
2004.jeptalnrecital-poster.5,Traduction de dialogue: r{\\'e}sultats du projet {NESPOLE}! et pistes pour le domaine,2004,-1,-1,2,0,30965,herve blanchon,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans cet article, nous d{\'e}taillons les r{\'e}sultats de la seconde {\'e}valuation du projet europ{\'e}en NESPOLE! auquel nous avons pris part pour le fran{\c{c}}ais. Dans ce projet, ainsi que dans ceux qui l{'}ont pr{\'e}c{\'e}d{\'e}, des techniques d{'}{\'e}valuation subjectives {---} r{\'e}alis{\'e}es par des {\'e}valuateurs humains {---} ont {\'e}t{\'e} mises en oeuvre. Nous pr{\'e}sentons aussi les nouvelles techniques objectives {---} automatiques {---} propos{\'e}es en traduction de l{'}{\'e}crit et mises en oeuvre dans le projet C-STAR III. Nous conclurons en proposant quelques id{\'e}es et perspectives pour le domaine."
2004.jeptalnrecital-poster.24,Mod{\\`e}le de langage s{\\'e}mantique pour la reconnaissance automatique de parole dans un contexte de traduction,2004,-1,-1,2,0,52467,quang vuminh,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Le travail pr{\'e}sent{\'e} dans cet article a {\'e}t{\'e} r{\'e}alis{\'e} dans le cadre d{'}un projet global de traduction automatique de la parole. L{'}approche de traduction est fond{\'e}e sur un langage pivot ou Interchange Format (IF), qui repr{\'e}sente le sens de la phrase ind{\'e}pendamment de la langue. Nous proposons une m{\'e}thode qui int{\`e}gre des informations s{\'e}mantiques dans le mod{\`e}le statistique de langage du syst{\`e}me de Reconnaissance Automatique de Parole. Le principe consiste a utiliser certaines classes d{\'e}finies dans l{'}IF comme des classes s{\'e}mantiques dans le mod{\`e}le de langage. Ceci permet au syst{\`e}me de reconnaissance de la parole d{'}analyser partiellement en IF les tours de parole. Les exp{\'e}rimentations realis{\'e}es montrent qu{'}avec cette approche, le syst{\`e}me de reconnaissance peut analyser directement en IF une partie des donn{\'e}es de dialogues de notre application, sans faire appel au syst{\`e}me de traduction (35{\%} des mots ; 58{\%} des tours de parole), tout en maintenant le m{\^e}me niveau de performance du syst{\`e}me global."
2004.iwslt-papers.1,"Spoken dialogue translation systems evaluation: results, new trends, problems and proposals",2004,23,7,3,0,30965,herve blanchon,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,"It is important to evaluate Spoken Dialogue Translation Systems, but as we show by analyzing evaluation methods in the Verbmobil, C-STAR II, and the Nespole! projects, the current state of the art is not fully satisfactory. Subjective methods are too costly, and objective methods, although cheaper, donxe2x80x99t give good indications about usability. We propose some ideas to improve that situation."
