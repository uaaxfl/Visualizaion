2021.socialnlp-1.13,Room to Grow: Understanding Personal Characteristics Behind Self Improvement Using Social Media,2021,-1,-1,5,0,1120,meixing dong,Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media,0,"Many people aim for change, but not everyone succeeds. While there are a number of social psychology theories that propose motivation-related characteristics of those who persist with change, few computational studies have explored the motivational stage of personal change. In this paper, we investigate a new dataset consisting of the writings of people who manifest intention to change, some of whom persist while others do not. Using a variety of linguistic analysis techniques, we first examine the writing patterns that distinguish the two groups of people. Persistent people tend to reference more topics related to long-term self-improvement and use a more complicated writing style. Drawing on these consistent differences, we build a classifier that can reliably identify the people more likely to persist, based on their language. Our experiments provide new insights into the motivation-related behavior of people who persist with their intention to change."
2021.sigdial-1.33,{CIDER}: Commonsense Inference for Dialogue Explanation and Reasoning,2021,-1,-1,5,1,1532,deepanway ghosal,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Commonsense inference to understand and explain human language is a fundamental research problem in natural language processing. Explaining human conversations poses a great challenge as it requires contextual understanding, planning, inference, and several aspects of reasoning including causal, temporal, and commonsense reasoning. In this work, we introduce CIDER {--} a manually curated dataset that contains dyadic dialogue explanations in the form of implicit and explicit knowledge triplets inferred using contextual commonsense inference. Extracting such rich explanations from conversations can be conducive to improving several downstream applications. The annotated triplets are categorized by the type of commonsense knowledge present (e.g., causal, conditional, temporal). We set up three different tasks conditioned on the annotated dataset: Dialogue-level Natural Language Inference, Span Extraction, and Multi-choice Span Selection. Baseline results obtained with transformer-based models reveal that the tasks are difficult, paving the way for promising future research. The dataset and the baseline implementations are publicly available at https://github.com/declare-lab/CIDER."
2021.nlp4if-1.7,Extractive and Abstractive Explanations for Fact-Checking and Evaluation of News,2021,-1,-1,4,1,2880,ashkan kazemi,"Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda",0,"In this paper, we explore the construction of natural language explanations for news claims, with the goal of assisting fact-checking and news evaluation applications. We experiment with two methods: (1) an extractive method based on Biased TextRank {--} a resource-effective unsupervised graph-based algorithm for content extraction; and (2) an abstractive method based on the GPT-2 language model. We perform comparative evaluations on two misinformation datasets in the political and health news domains, and find that the extractive method shows the most promise."
2021.naacl-main.216,{MUSER}: {MU}ltimodal Stress detection using Emotion Recognition as an Auxiliary Task,2021,-1,-1,5,0,3905,yiqun yao,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"The capability to automatically detect human stress can benefit artificial intelligent agents involved in affective computing and human-computer interaction. Stress and emotion are both human affective states, and stress has proven to have important implications on the regulation and expression of emotion. Although a series of methods have been established for multimodal stress detection, limited steps have been taken to explore the underlying inter-dependence between stress and emotion. In this work, we investigate the value of emotion recognition as an auxiliary task to improve stress detection. We propose MUSER {--} a transformer-based model architecture and a novel multi-task learning algorithm with speed-based dynamic sampling strategy. Evaluation on the Multimodal Stressed Emotion (MuSE) dataset shows that our model is effective for stress detection with both internal and external auxiliary tasks, and achieves state-of-the-art results."
2021.findings-emnlp.27,Mining the Cause of Political Decision-Making from Social Media: A Case Study of {COVID}-19 Policies across the {US} States,2021,-1,-1,5,0,6447,zhijing jin,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Mining the causes of political decision-making is an active research area in the field of political science. In the past, most studies have focused on long-term policies that are collected over several decades of time, and have primarily relied on surveys as the main source of predictors. However, the recent COVID-19 pandemic has given rise to a new political phenomenon, where political decision-making consists of frequent short-term decisions, all on the same controlled topic{---}the pandemic. In this paper, we focus on the question of how public opinion influences policy decisions, while controlling for confounders such as COVID-19 case increases or unemployment rates. Using a dataset consisting of Twitter data from the 50 US states, we classify the sentiments toward governors of each state, and conduct controlled studies and comparisons. Based on the compiled samples of sentiments, policies, and confounders, we conduct causal inference to discover trends in political decision-making across different states."
2021.findings-emnlp.360,"Micromodels for Efficient, Explainable, and Reusable Systems: A Case Study on Mental Health",2021,-1,-1,4,0,7302,andrew lee,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Many statistical models have high accuracy on test benchmarks, but are not explainable, struggle in low-resource scenarios, cannot be reused for multiple tasks, and cannot easily integrate domain expertise. These factors limit their use, particularly in settings such as mental health, where it is difficult to annotate datasets and model outputs have significant impact. We introduce a micromodel architecture to address these challenges. Our approach allows researchers to build interpretable representations that embed domain knowledge and provide explanations throughout the model{'}s decision process. We demonstrate the idea on multiple mental health tasks: depression classification, PTSD classification, and suicidal risk assessment. Our systems consistently produce strong results, even in low-resource scenarios, and are more interpretable than alternative methods."
2021.findings-acl.124,"Exploring the Role of Context in Utterance-level Emotion, Act and Intent Classification in Conversations: An Empirical Study",2021,-1,-1,3,1,1532,deepanway ghosal,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.273,How Good Is {NLP}? A Sober Look at {NLP} Tasks through the Lens of Social Impact,2021,-1,-1,5,0,6447,zhijing jin,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.392,Exploring Self-Identified Counseling Expertise in Online Support Forums,2021,-1,-1,7,0,8413,allison lahnala,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.392,{W}hy{A}ct: Identifying Action Reasons in Lifestyle Vlogs,2021,-1,-1,5,0,9523,oana ignat,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"We aim to automatically identify human action reasons in online videos. We focus on the widespread genre of lifestyle vlogs, in which people perform actions while verbally describing them. We introduce and make publicly available the WhyAct dataset, consisting of 1,077 visual actions manually annotated with their reasons. We describe a multimodal model that leverages visual and textual information to automatically infer the reasons corresponding to an action presented in the video."
2021.emnlp-main.476,Analyzing the Surprising Variability in Word Embedding Stability Across Languages,2021,-1,-1,3,0,9669,laura burdick,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Word embeddings are powerful representations that form the foundation of many natural language processing architectures, both in English and in other languages. To gain further insight into word embeddings, we explore their stability (e.g., overlap between the nearest neighbors of a word in different embedding spaces) in diverse languages. We discuss linguistic properties that are related to stability, drawing out insights about correlations with affixing, language gender systems, and other features. This has implications for embedding use, particularly in research that uses them to study language trends."
2021.emnlp-main.515,Hitting your {MARQ}: Multimodal {AR}gument Quality Assessment in Long Debate Video,2021,-1,-1,6,0,9725,md hasan,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"The combination of gestures, intonations, and textual content plays a key role in argument delivery. However, the current literature mostly considers textual content while assessing the quality of an argument, and it is limited to datasets containing short sequences (18-48 words). In this paper, we study argument quality assessment in a multimodal context, and experiment on DBATES, a publicly available dataset of long debate videos. First, we propose a set of interpretable debate centric features such as clarity, content variation, body movement cues, and pauses, inspired by theories of argumentation quality. Second, we design the Multimodal ARgument Quality assessor (MARQ) {--} a hierarchical neural network model that summarizes the multimodal signals on long sequences and enriches the multimodal embedding with debate centric features. Our proposed MARQ model achieves an accuracy of 81.91{\%} on the argument quality prediction task and outperforms established baseline models with an error rate reduction of 22.7{\%}. Through ablation studies, we demonstrate the importance of multimodal cues in modeling argument quality."
2021.emnlp-main.683,{ST}a{CK}: Sentence Ordering with Temporal Commonsense Knowledge,2021,-1,-1,3,1,1532,deepanway ghosal,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Sentence order prediction is the task of finding the correct order of sentences in a randomly ordered document. Correctly ordering the sentences requires an understanding of coherence with respect to the chronological sequence of events described in the text. Document-level contextual understanding and commonsense knowledge centered around these events are often essential in uncovering this coherence and predicting the exact chronological order. In this paper, we introduce STaCK {---} a framework based on graph neural networks and temporal commonsense knowledge to model global information and predict the relative order of sentences. Our graph network accumulates temporal evidence using knowledge of {`}past{'} and {`}future{'} and formulates sentence ordering as a constrained edge classification problem. We report results on five different datasets, and empirically show that the proposed method is naturally suitable for order prediction. The implementation of this work is available at: https://github.com/declare-lab/sentence-ordering."
2021.clpsych-1.18,Evaluating Automatic Speech Recognition Quality and Its Impact on Counselor Utterance Coding,2021,-1,-1,3,0,11646,do min,Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access,0,"Automatic speech recognition (ASR) is a crucial step in many natural language processing (NLP) applications, as often available data consists mainly of raw speech. Since the result of the ASR step is considered as a meaningful, informative input to later steps in the NLP pipeline, it is important to understand the behavior and failure mode of this step. In this work, we analyze the quality of ASR in the psychotherapy domain, using motivational interviewing conversations between therapists and clients. We conduct domain agnostic and domain-relevant evaluations using standard evaluation metrics and also identify domain-relevant keywords in the ASR output. Moreover, we empirically study the effect of mixing ASR and manual data during the training of a downstream NLP model, and also demonstrate how additional local context can help alleviate the error introduced by noisy ASR transcripts."
2020.sigdial-1.2,Counseling-Style Reflection Generation Using Generative Pretrained Transformers with Augmented Context,2020,-1,-1,3,0,1534,siqi shen,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"We introduce a counseling dialogue system that seeks to assist counselors while they are learning and refining their counseling skills. The system generates counselors{'}reflections {--} i.e., responses that reflect back on what the client has said given the dialogue history. Our method builds upon the new generative pretrained transformer architecture and enhances it with context augmentation techniques inspired by traditional strategies used during counselor training. Through a set of comparative experiments, we show that the system that incorporates these strategies performs better in the reflection generation task than a system that is just fine-tuned with counseling conversations. To confirm our findings, we present a human evaluation study that shows that our system generates naturally-looking reflections that are also stylistically and grammatically correct."
2020.nlpcovid19-2.6,Expressive Interviewing: A Conversational System for Coping with {COVID}-19,2020,-1,-1,9,1,8415,charles welch,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"The ongoing COVID-19 pandemic has raised concerns for many regarding personal and public health implications, financial security and economic stability. Alongside many other unprecedented challenges, there are increasing concerns over social isolation and mental health. We introduce Expressive Interviewing {--} an interview-style conversational system that draws on ideas from motivational interviewing and expressive writing. Expressive Interviewing seeks to encourage users to express their thoughts and feelings through writing by asking them questions about how COVID-19 has impacted their lives. We present relevant aspects of the system{'}s design and implementation as well as quantitative and qualitative analyses of user interactions with the system. In addition, we conduct a comparative evaluation with a general purpose dialogue system for mental health that shows our system potential in helping users to cope with COVID-19 issues."
2020.nlpcovid19-2.8,Quantifying the Effects of {COVID}-19 on Mental Health Support Forums,2020,-1,-1,5,0,16234,laura biester,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"The COVID-19 pandemic, like many of the disease outbreaks that have preceded it, is likely to have a profound effect on mental health. Understanding its impact can inform strategies for mitigating negative consequences. In this work, we seek to better understand the effects of COVID-19 on mental health by examining discussions within mental health support communities on Reddit. First, we quantify the rate at which COVID-19 is discussed in each community, or subreddit, in order to understand levels of pandemic-related discussion. Next, we examine the volume of activity in order to determine whether the number of people discussing mental health has risen. Finally, we analyze how COVID-19 has influenced language use and topics of discussion within each subreddit."
2020.lrec-1.187,{M}u{SE}: a Multimodal Dataset of Stressed Emotion,2020,-1,-1,5,0,16995,mimansa jaiswal,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Endowing automated agents with the ability to provide support, entertainment and interaction with human beings requires sensing of the users{'} affective state. These affective states are impacted by a combination of emotion inducers, current psychological state, and various conversational factors. Although emotion classification in both singular and dyadic settings is an established area, the effects of these additional factors on the production and perception of emotion is understudied. This paper presents a new dataset, Multimodal Stressed Emotion (MuSE), to study the multimodal interplay between the presence of stress and expressions of affect. We describe the data collection protocol, the possible areas of use, and the annotations for the emotional content of the recordings. The paper also presents several baselines to measure the performance of multimodal features for emotion and stress classification."
2020.lrec-1.536,{L}ife{QA}: A Real-life Dataset for Video Question Answering,2020,-1,-1,7,1,9524,santiago castro,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We introduce LifeQA, a benchmark dataset for video question answering that focuses on day-to-day real-life situations. Current video question answering datasets consist of movies and TV shows. However, it is well-known that these visual domains are not representative of our day-to-day lives. Movies and TV shows, for example, benefit from professional camera movements, clean editing, crisp audio recordings, and scripted dialog between professional actors. While these domains provide a large amount of data for training models, their properties make them unsuitable for testing real-life question answering systems. Our dataset, by contrast, consists of video clips that represent only real-life scenarios. We collect 275 such video clips and over 2.3k multiple-choice questions. In this paper, we analyze the challenging but realistic aspects of LifeQA, and we apply several state-of-the-art video question answering models to provide benchmarks for future research. The full dataset is publicly available at https://lit.eecs.umich.edu/lifeqa/."
2020.lrec-1.771,Small Town or Metropolis? Analyzing the Relationship between Population Size and Language,2020,-1,-1,3,0,18136,amy rechkemmer,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The variance in language used by different cultures has been a topic of study for researchers in linguistics and psychology, but often times, language is compared across multiple countries in order to show a difference in culture. As a geographically large country that is diverse in population in terms of the background and experiences of its citizens, the U.S. also contains cultural differences within its own borders. Using a set of over 2 million posts from distinct Twitter users around the country dating back as far as 2014, we ask the following question: is there a difference in how Americans express themselves online depending on whether they reside in an urban or rural area? We categorize Twitter users as either urban or rural and identify ideas and language that are more commonly expressed in tweets written by one population over the other. We take this further by analyzing how the language from specific cities of the U.S. compares to the language of other cities and by training predictive models to predict whether a user is from an urban or rural area. We publicly release the tweet and user IDs that can be used to reconstruct the dataset for future studies in this direction."
2020.lrec-1.772,Inferring Social Media Users{'} Mental Health Status from Multimodal Information,2020,-1,-1,3,0,18137,zhentao xu,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Worldwide, an increasing number of people are suffering from mental health disorders such as depression and anxiety. In the United States alone, one in every four adults suffers from a mental health condition, which makes mental health a pressing concern. In this paper, we explore the use of multimodal cues present in social media posts to predict users{'} mental health status. Specifically, we focus on identifying social media activity that either indicates a mental health condition or its onset. We collect posts from Flickr and apply a multimodal approach that consists of jointly analyzing language, visual, and metadata cues and their relation to mental health. We conduct several classification experiments aiming to discriminate between (1) healthy users and users affected by a mental health illness; and (2) healthy users and users prone to mental illness. Our experimental results indicate that using multiple modalities can improve the performance of this classification task as compared to the use of one modality at a time, and can provide important cues into a user{'}s mental status."
2020.findings-emnlp.224,{COSMIC}: {CO}mmon{S}ense knowledge for e{M}otion Identification in Conversations,2020,-1,-1,4,1,1532,deepanway ghosal,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"In this paper, we address the task of utterance level emotion recognition in conversations using commonsense knowledge. We propose COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation. Current state-of-theart methods often encounter difficulties in context propagation, emotion shift detection, and differentiating between related emotion classes. By learning distinct commonsense representations, COSMIC addresses these challenges and achieves new state-of-the-art results for emotion recognition on four different benchmark conversational datasets. Our code is available at https://github.com/declare-lab/conv-emotion."
2020.emnlp-main.334,Compositional Demographic Word Embeddings,2020,-1,-1,4,1,8415,charles welch,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve language model performance and other language processing tasks, they can only be computed for people with a large amount of longitudinal data, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for English: language modeling and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them."
2020.emnlp-main.696,Improving Low Compute Language Modeling with In-Domain Embedding Initialisation,2020,-1,-1,2,1,8415,charles welch,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Many NLP applications, such as biomedical data and technical support, have 10-100 million tokens of in-domain data and limited computational resources for learning from it. How should we train a language model in this scenario? Most language modeling research considers either a small dataset with a closed vocabulary (like the standard 1 million token Penn Treebank), or the whole web with byte-pair encoding. We show that for our target setting in English, initialising and freezing input embeddings using in-domain data can improve language model performance by providing a useful representation of rare words, and this pattern holds across several different domains. In the process, we show that the standard convention of tying input and output embeddings does not improve perplexity when initializing with embeddings trained on in-domain data."
2020.emnlp-main.721,{MIME}: {MIM}icking Emotions for Empathetic Response Generation,2020,-1,-1,7,1,1535,navonil majumder,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Current approaches to empathetic response generation view the set of emotions expressed in the input text as a flat structure, where all the emotions are treated uniformly. We argue that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content. We show that the consideration of these polarity-based emotion clusters and emotional mimicry results in improved empathy and contextual relevance of the response as compared to the state-of-the-art. Also, we introduce stochasticity into the emotion mixture that yields emotionally more varied empathetic responses than the previous work. We demonstrate the importance of these factors to empathetic response generation using both automatic- and human-based evaluations. The implementation of MIME is publicly available at https://github.com/declare-lab/MIME."
2020.coling-main.144,Biased {T}ext{R}ank: Unsupervised Graph-Based Content Extraction,2020,-1,-1,3,1,2880,ashkan kazemi,Proceedings of the 28th International Conference on Computational Linguistics,0,"We introduce Biased TextRank, a graph-based content extraction method inspired by the popular TextRank algorithm that ranks text spans according to their importance for language processing tasks and according to their relevance to an input {``}focus.{''} Biased TextRank enables focused content extraction for text by modifying the random restarts in the execution of TextRank. The random restart probabilities are assigned based on the relevance of the graph nodes to the focus of the task. We present two applications of Biased TextRank: focused summarization and explanation extraction, and show that our algorithm leads to improved performance on two different datasets by significant ROUGE-N score margins. Much like its predecessor, Biased TextRank is unsupervised, easy to implement and orders of magnitude faster and lighter than current state-of-the-art Natural Language Processing methods for similar tasks."
2020.coling-main.253,"{``}Judge me by my size (noun), do you?{''} {Y}oda{L}ib: A Demographic-Aware Humor Generation Framework",2020,-1,-1,4,1,8420,aparna garimella,Proceedings of the 28th International Conference on Computational Linguistics,0,"The subjective nature of humor makes computerized humor generation a challenging task. We propose an automatic humor generation framework for filling the blanks in Mad LibsÂ® stories, while accounting for the demographic backgrounds of the desired audience. We collect a dataset consisting of such stories, which are filled in and judged by carefully selected workers on Amazon Mechanical Turk. We build upon the BERT platform to predict location-biased word fillings in incomplete sentences, and we fine-tune BERT to classify location-specific humor in a sentence. We leverage these components to produce YodaLib, a fully-automated Mad Libs style humor generation framework, which selects and ranks appropriate candidate words and sentences in order to generate a coherent and funny story tailored to certain demographics. Our experimental results indicate that YodaLib outperforms a previous semi-automated approach proposed for this task, while also surpassing human annotators in both qualitative and quantitative analyses."
2020.coling-main.604,Exploring the Value of Personalized Word Embeddings,2020,-1,-1,4,1,8415,charles welch,Proceedings of the 28th International Conference on Computational Linguistics,0,"In this paper, we introduce personalized word embeddings, and examine their value for language modeling. We compare the performance of our proposed prediction model when using personalized versus generic word representations, and study how these representations can be leveraged for improved performance. We provide insight into what types of words can be more accurately predicted when building personalized models. Our results show that a subset of words belonging to specific psycholinguistic categories tend to vary more in their representations across users and that combining generic and personalized word embeddings yields the best performance, with a 4.7{\%} relative reduction in perplexity. Additionally, we show that a language model using personalized word embeddings can be effectively used for authorship attribution."
2020.acl-main.292,{K}in{GDOM}: {K}nowledge-{G}uided {DOM}ain {A}daptation for {S}entiment {A}nalysis,2020,63,0,5,1,1532,deepanway ghosal,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Cross-domain sentiment analysis has received significant attention in recent years, prompted by the need to combat the domain gap between different applications that make use of sentiment analysis. In this paper, we take a novel perspective on this task by exploring the role of external commonsense knowledge. We introduce a new framework, KinGDOM, which utilizes the ConceptNet knowledge graph to enrich the semantics of a document by providing both domain-specific and domain-general background concepts. These concepts are learned by training a graph convolutional autoencoder that leverages inter-domain concepts in a domain-invariant manner. Conditioning a popular domain-adversarial baseline method with these learned concepts helps improve its performance over state-of-the-art approaches, demonstrating the efficacy of our proposed framework."
2020.aacl-main.44,Building Location Embeddings from Physical Trajectories and Textual Representations,2020,-1,-1,3,0,16234,laura biester,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"Word embedding methods have become the de-facto way to represent words, having been successfully applied to a wide array of natural language processing tasks. In this paper, we explore the hypothesis that embedding methods can also be effectively used to represent spatial locations. Using a new dataset consisting of the location trajectories of 729 students over a seven month period and text data related to those locations, we implement several strategies to create location embeddings, which we then use to create embeddings of the sequences of locations a student has visited. To identify the surface level properties captured in the representations, we propose a number of probing tasks such as the presence of a specific location in a sequence or the type of activities that take place at a location. We then leverage the representations we generated and employ them in more complex downstream tasks ranging from predicting a student{'}s area of study to a student{'}s depression level, showing the effectiveness of these location embeddings."
S19-1005,Multi-Label Transfer Learning for Multi-Relational Semantic Similarity,2019,0,0,3,0,1073,li zhang,Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019),0,"Multi-relational semantic similarity datasets define the semantic relations between two short texts in multiple ways, e.g., similarity, relatedness, and so on. Yet, all the systems to date designed to capture such relations target one relation at a time. We propose a multi-label transfer learning approach based on LSTM to make predictions for several relations simultaneously and aggregate the losses to update the parameters. This multi-label regression approach jointly learns the information provided by the multiple relations, rather than treating them as separate tasks. Not only does this approach outperform the single-task approach and the traditional multi-task learning approach, but it also achieves state-of-the-art performance on all but one relation of the Human Activity Phrase dataset."
P19-1050,{MELD}: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations,2019,0,15,6,0.8,1536,soujanya poria,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Emotion recognition in conversations is a challenging task that has recently gained popularity due to its potential applications. Until now, however, a large-scale multimodal multi-party emotional conversational database containing more than two speakers per dialogue was missing. Thus, we propose the Multimodal EmotionLines Dataset (MELD), an extension and enhancement of EmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual and textual modalities. We propose several strong multimodal baselines and show the importance of contextual and multimodal information for emotion recognition in conversations. The full dataset is available for use at http://affective-meld.github.io."
P19-1088,What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations,2019,0,2,4,1,2882,veronica perezrosas,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"The quality of a counseling intervention relies highly on the active collaboration between clients and counselors. In this paper, we explore several linguistic aspects of the collaboration process occurring during counseling conversations. Specifically, we address the differences between high-quality and low-quality counseling. Our approach examines participants{'} turn-by-turn interaction, their linguistic alignment, the sentiment expressed by speakers during the conversation, as well as the different topics being discussed. Our results suggest important language differences in low- and high-quality counseling, which we further use to derive linguistic features able to capture the differences between the two groups. These features are then used to build automatic classifiers that can predict counseling quality with accuracies of up to 88{\%}."
P19-1245,Predicting Human Activities from User-Generated Content,2019,0,0,2,1,1646,steven wilson,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"The activities we do are linked to our interests, personality, political preferences, and decisions we make about the future. In this paper, we explore the task of predicting human activities from user-generated content. We collect a dataset containing instances of social media users writing about a range of everyday activities. We then use a state-of-the-art sentence embedding framework tailored to recognize the semantics of human activities and perform an automatic clustering of these activities. We train a neural network model to make predictions about which clusters contain activities that were performed by a given user based on the text of their previous posts and self-description. Additionally, we explore the degree to which incorporating inferred user traits into our model helps with this prediction task."
P19-1339,Women{'}s Syntactic Resilience and Men{'}s Grammatical Luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing,2019,0,2,4,1,8420,aparna garimella,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Several linguistic studies have shown the prevalence of various lexical and grammatical patterns in texts authored by a person of a particular gender, but models for part-of-speech tagging and dependency parsing have still not adapted to account for these differences. To address this, we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles{'} authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women. Further analyses reveal numerous part-of-speech tags and syntactic relations whose prediction performances benefit from the prevalence of a specific gender in the training data. The results underscore the importance of accounting for gendered differences in syntactic tasks, and outline future venues for developing more accurate taggers and parsers. We release our data to the research community."
P19-1455,Towards Multimodal Sarcasm Detection (An {\\_}{O}bviously{\\_} Perfect Paper),2019,41,1,5,1,9524,santiago castro,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Sarcasm is often expressed through several verbal and non-verbal cues, e.g., a change of tone, overemphasis in a word, a drawn-out syllable, or a straight looking face. Most of the recent work in sarcasm detection has been carried out on textual data. In this paper, we argue that incorporating multimodal cues can improve the automatic classification of sarcasm. As a first step towards enabling the development of multimodal approaches for sarcasm detection, we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD), compiled from popular TV shows. MUStARD consists of audiovisual utterances annotated with sarcasm labels. Each utterance is accompanied by its context of historical utterances in the dialogue, which provides additional information on the scenario where the utterance occurs. Our initial results show that the use of multimodal information can reduce the relative error rate of sarcasm detection by up to 12.9{\%} in F-score when compared to the use of individual modalities. The full dataset is publicly available for use at https://github.com/soujanyaporia/MUStARD."
P19-1643,Identifying Visible Actions in Lifestyle Vlogs,2019,0,0,4,0,9523,oana ignat,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"We consider the task of identifying human actions visible in online videos. We focus on the widely spread genre of lifestyle vlogs, which consist of videos of people performing actions while verbally describing them. Our goal is to identify if actions mentioned in the speech description of a video are visually present. We construct a dataset with crowdsourced manual annotations of visible actions, and introduce a multimodal algorithm that leverages information derived from visual and linguistic clues to automatically infer which actions are visible in a video."
N19-1175,Box of Lies: Multimodal Deception Detection in Dialogues,2019,0,1,3,0,24734,felix soldner,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Deception often takes place during everyday conversations, yet conversational dialogues remain largely unexplored by current work on automatic deception detection. In this paper, we address the task of detecting multimodal deceptive cues during conversational dialogues. We introduce a multimodal dataset containing deceptive conversations between participants playing the Box of Lies game from The Tonight Show Starring Jimmy Fallon, in which they try to guess whether an object description provided by their opponent is deceptive or not. We conduct annotations of multimodal communication behaviors, including facial and linguistic behaviors, and derive several learning features based on these annotations. Initial classification experiments show promising results, performing well above both a random and a human baseline, and reaching up to 69{\%} accuracy in distinguishing deceptive and truthful behaviors."
K19-1010,Representing Movie Characters in Dialogues,2019,0,0,4,1,17745,mahmoud azab,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"We introduce a new embedding model to represent movie characters and their interactions in a dialogue by encoding in the same representation the language used by these characters as well as information about the other participants in the dialogue. We evaluate the performance of these new character embeddings on two tasks: (1) character relatedness, using a dataset we introduce consisting of a dense character interaction matrix for 4,378 unique character pairs over 22 hours of dialogue from eighteen movies; and (2) character relation classification, for fine- and coarse-grained relations, as well as sentiment relations. Our experiments show that our model significantly outperforms the traditional Word2Vec continuous bag-of-words and skip-gram models, demonstrating the effectiveness of the character embeddings we introduce. We further show how these embeddings can be used in conjunction with a visual question answering system to improve over previous results."
D19-1122,Towards Extracting Medical Family History from Natural Language Interactions: A New Dataset and Baselines,2019,0,1,5,1,17745,mahmoud azab,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"We introduce a new dataset consisting of natural language interactions annotated with medical family histories, obtained during interactions with a genetic counselor and through crowdsourcing, following a questionnaire created by experts in the domain. We describe the data collection process and the annotations performed by medical professionals, including illness and personal attributes (name, age, gender, family relationships) for the patient and their family members. An initial system that performs argument identification and relation extraction shows promising results {--} average F-score of 0.87 on complex sentences on the targeted relations."
N18-1190,Factors Influencing the Surprising Instability of Word Embeddings,2018,11,3,3,0,29491,laura wendlandt,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Despite the recent popularity of word embedding methods, there is only a small body of work exploring the limitations of these representations. In this paper, we consider one aspect of embedding spaces, namely their stability. We show that even relatively high frequency words (100-200 occurrences) are often unstable. We provide empirical evidence for how various factors contribute to the stability of word embeddings, and we analyze the effects of stability on downstream tasks."
N18-1200,Speaker Naming in Movies,2018,0,2,6,1,17745,mahmoud azab,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"We propose a new model for speaker naming in movies that leverages visual, textual, and acoustic modalities in an unified optimization framework. To evaluate the performance of our model, we introduce a new dataset consisting of six episodes of the Big Bang Theory TV show and eighteen full movies covering different genres. Our experiments show that our multimodal model significantly outperforms several competitive baselines on the average weighted F-score metric. To demonstrate the effectiveness of our framework, we design an end-to-end memory network model that leverages our speaker naming model and achieves state-of-the-art results on the subtitles task of the MovieQA 2017 Challenge."
L18-1492,World Knowledge for {A}bstract {M}eaning {R}epresentation Parsing,2018,0,0,4,1,8415,charles welch,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1591,Analyzing the Quality of Counseling Conversations: the Tell-Tale Signs of High-quality Counseling,2018,0,2,6,1,2882,veronica perezrosas,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D18-1280,{ICON}: Interactive Conversational Memory Network for Multimodal Emotion Detection,2018,0,15,3,1,3705,devamanyu hazarika,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Emotion recognition in conversations is crucial for building empathetic machines. Present works in this domain do not explicitly consider the inter-personal influences that thrive in the emotional dynamics of dialogues. To this end, we propose Interactive COnversational memory Network (ICON), a multimodal emotion detection framework that extracts multimodal features from conversational videos and hierarchically models the self- and inter-speaker emotional influences into global memories. Such memories generate contextual summaries which aid in predicting the emotional orientation of utterance-videos. Our model outperforms state-of-the-art networks on multiple classification and regression tasks in two benchmark datasets."
C18-1156,{CASCADE}: Contextual Sarcasm Detection in Online Discussion Forums,2018,27,10,6,1,3705,devamanyu hazarika,Proceedings of the 27th International Conference on Computational Linguistics,0,"The literature in automated sarcasm detection has mainly focused on lexical-, syntactic- and semantic-level analysis of text. However, a sarcastic sentence can be expressed with contextual presumptions, background and commonsense knowledge. In this paper, we propose a ContextuAl SarCasm DEtector (CASCADE), which adopts a hybrid approach of both content- and context-driven modeling for sarcasm detection in online social media discussions. For the latter, CASCADE aims at extracting contextual information from the discourse of a discussion thread. Also, since the sarcastic nature and form of expression can vary from person to person, CASCADE utilizes user embeddings that encode stylometric and personality features of users. When used along with content-based feature extractors such as convolutional neural networks, we see a significant boost in the classification performance on a large Reddit corpus."
C18-1287,Automatic Detection of Fake News,2018,0,42,4,1,2882,veronica perezrosas,Proceedings of the 27th International Conference on Computational Linguistics,0,"The proliferation of misleading information in everyday access media outlets such as social media feeds, news blogs, and online newspapers have made it challenging to identify trustworthy news sources, thus increasing the need for computational tools able to provide insights into the reliability of online content. In this paper, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we introduce two novel datasets for the task of fake news detection, covering seven different news domains. We describe the collection, annotation, and validation process in detail and present several exploratory analyses on the identification of linguistic differences in fake and legitimate news content. Second, we conduct a set of learning experiments to build accurate fake news detectors, and show that we can achieve accuracies of up to 76{\%}. In addition, we provide comparative analyses of the automatic and manual identification of fake news."
P17-1131,Understanding and Predicting Empathic Behavior in Counseling Therapy,2017,22,9,2,1,2882,veronica perezrosas,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Counselor empathy is associated with better outcomes in psychology and behavioral counseling. In this paper, we explore several aspects pertaining to counseling interaction dynamics and their relation to counselor empathy during motivational interviewing encounters. Particularly, we analyze aspects such as participants{'} engagement, participants{'} verbal and nonverbal accommodation, as well as topics being discussed during the conversation, with the final goal of identifying linguistic and acoustic markers of counselor empathy. We also show how we can use these findings alongside other raw linguistic and acoustic features to build accurate counselor empathy classifiers with accuracies of up to 80{\%}."
I17-1040,Identifying Usage Expression Sentences in Consumer Product Reviews,2017,30,2,3,0.925926,32904,shibamouli lahiri,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"In this paper we introduce the problem of identifying usage expression sentences in a consumer product review. We create a human-annotated gold standard dataset of 565 reviews spanning five distinct product categories. Our dataset consists of more than 3,000 annotated sentences. We further introduce a classification system to label sentences according to whether or not they describe some {``}usage{''}. The system combines lexical, syntactic, and semantic features in a product-agnostic fashion to yield good classification performance. We show the effectiveness of our approach using importance ranking of features, error analysis, and cross-product classification experiments."
I17-1067,Measuring Semantic Relations between Human Activities,2017,14,4,2,1,1646,steven wilson,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"The things people do in their daily lives can provide valuable insights into their personality, values, and interests. Unstructured text data on social media platforms are rich in behavioral content, and automated systems can be deployed to learn about human activity on a broad scale if these systems are able to reason about the content of interest. In order to aid in the evaluation of such systems, we introduce a new phrase-level semantic textual similarity dataset comprised of human activity phrases, providing a testbed for automated systems that analyze relationships between phrasal descriptions of people{'}s actions. Our set of 1,000 pairs of activities is annotated by human judges across four relational dimensions including similarity, relatedness, motivational alignment, and perceived actor congruence. We evaluate a set of strong baselines for the task of generating scores that correlate highly with human ratings, and we introduce several new approaches to the phrase-level similarity task in the domain of human activities."
I17-1089,Identity Deception Detection,2017,15,1,5,1,2882,veronica perezrosas,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"This paper addresses the task of detecting identity deception in language. Using a novel identity deception dataset, consisting of real and portrayed identities from 600 individuals, we show that we can build accurate identity detectors targeting both age and gender, with accuracies of up to 88. We also perform an analysis of the linguistic patterns used in identity deception, which lead to interesting insights into identity portrayers."
E17-2022,A Computational Analysis of the Language of Drug Addiction,2017,34,3,2,0,16980,carlo strapparava,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"We present a computational analysis of the language of drug users when talking about their drug experiences. We introduce a new dataset of over 4,000 descriptions of experiences reported by users of four main drug types, and show that we can predict with an F1-score of up to 88{\%} the drug behind a certain experience. We also perform an analysis of the dominant psycholinguistic processes and dominant emotions associated with each drug type, which sheds light on the characteristics of drug users."
E17-1106,Predicting Counselor Behaviors in Motivational Interviewing Encounters,2017,17,6,2,1,2882,veronica perezrosas,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"As the number of people receiving psycho-therapeutic treatment increases, the automatic evaluation of counseling practice arises as an important challenge in the clinical domain. In this paper, we address the automatic evaluation of counseling performance by analyzing counselors{'} language during their interaction with clients. In particular, we present a model towards the automation of Motivational Interviewing (MI) coding, which is the current gold standard to evaluate MI counseling. First, we build a dataset of hand labeled MI encounters; second, we use text-based methods to extract and analyze linguistic patterns associated with counselor behaviors; and third, we develop an automatic system to predict these behaviors. We introduce a new set of features based on semantic information and syntactic patterns, and show that they lead to accuracy figures of up to 90{\%}, which represent a significant improvement with respect to features used in the past."
D17-1242,Demographic-aware word associations,2017,28,6,3,1,8420,aparna garimella,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Variations of word associations across different groups of people can provide insights into people{'}s psychologies and their world views. To capture these variations, we introduce the task of demographic-aware word associations. We build a new gold standard dataset consisting of word association responses for approximately 300 stimulus words, collected from more than 800 respondents of different gender (male/female) and from different locations (India/United States), and show that there are significant variations in the word associations made by these groups. We also introduce a new demographic-aware word association model based on a neural net skip-gram architecture, and show how computational methods for measuring word associations that specifically account for writer demographics can outperform generic methods that are agnostic to such information."
W16-5619,Disentangling Topic Models: A Cross-cultural Analysis of Personal Values through Words,2016,-1,-1,2,1,1646,steven wilson,Proceedings of the First Workshop on {NLP} and Computational Social Science,0,None
W16-4301,Zooming in on Gender Differences in Social Media,2016,23,3,2,1,8420,aparna garimella,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",0,"Men are from Mars and women are from Venus - or so the genre of relationship literature would have us believe. But there is some truth in this idea, and researchers in fields as diverse as psychology, sociology, and linguistics have explored ways to better understand the differences between genders. In this paper, we take another look at the problem of gender discrimination and attempt to move beyond the typical surface-level text classification approach, by (1) identifying semantic and psycholinguistic word classes that reflect systematic differences between men and women and (2) finding differences between genders in the ways they use the same words. We describe several experiments and report results on a large collection of blogs authored by men and women."
W16-0305,Building a Motivational Interviewing Dataset,2016,25,3,2,1,2882,veronica perezrosas,Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology,0,"This paper contributes a novel psychological dataset consisting of counselorsxe2x80x99 behaviors during Motivational Interviewing encounters. Annotations were conducted using the Motivational Interviewing Integrity Treatment (MITI). We describe relevant aspects associated with the construction of a dataset that relies on behavioral coding such as data acquisition, transcription, expert data annotations, and reliability assessments. The dataset contains a total of 22,719 counselor utterances extracted from 277 motivational interviewing sessions that are annotated with 10 counselor behavioral codes. The reliability analysis showed that annotators achieved excellent agreement at session level, with Intraclass Correlation Coefficient (ICC) scores in the range of 0.75 to 1, and fair to good agreement at utterance level, with Cohenxe2x80x99s Kappa scores ranging from 0.31 to 0.64. Behavioral interventions are a promising approach to address public health issues such as smoking cessation, increasing physical activity, and reducing substance abuse, among others (Resnicow et al., 2002). In particular, Motivational Interviewing (MI), a client centered psychotherapy style, has been receiving increasing attention from the clinical psychology community due to its established efficacy for treating addiction and other behaviors (Moyers et al., 2009; Apodaca et al., 2014; Barnett et al., 2014; Catley et al., 2012). Despite its potential benefits in combating addiction and in providing broader disease prevention and management, implementing MI counseling at larger scale or in other domains is limited by the need for human-based evaluations. Currently, this requires a human either watching or listening to video-tapes and then providing evaluative feedback. Recently, computational approaches have been proposed to aid the MI evaluation process (Atkins et al., 2014; Xiao et al., 2014; Klonek et al., 2015). However, learning resources for this task are not readily available. Having such resources will enable the application of data-driven strategies for the automatic coding of counseling behaviors, thus providing researchers with automatic means for the evaluation of MI. Moreover, this can also be useful to explore how MI works by relating MI behaviors to health outcomes, and to provide counselors with evaluative feedback that helps them improve their MI skills. In this paper, we present the construction and validation of a dataset annotated with counselor verbal behaviours using the Motivational Interviewing Treatment Integrity 4.0 (MITI), which is the current gold standard for MI-based psychology interventions. The dataset is derived from 277 MI sessions containing a total of 22,719 coded utterances. 1 Motivational Interviewing Miller and Rollnick define MI as a collaborative, goal-oriented style of psychotherapy with particular attention to the language of change (Miller and Rollnick, 2013). MI has been widely used as a treatment method in clinical trials on psychotherapy research to address addictive behaviors such as alcohol, tobacco and drug use; promote healthier habits such as nutrition and fitness; and help clients with"
S16-1081,"{S}em{E}val-2016 Task 1: Semantic Textual Similarity, Monolingual and Cross-Lingual Evaluation",2016,29,110,6,0,8824,eneko agirre,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"Comunicacio presentada al 10th International Workshop on Semantic Evaluation (SemEval-2016), celebrat els dies 16 i 17 de juny de 2016 a San Diego, California."
P16-2052,Finding Optimists and Pessimists on {T}witter,2016,11,5,3,0,34424,xianzhi ruan,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Optimism is linked to various personality factors as well as both psychological and physical health, but how does it relate to the way a person tweets? We analyze the online activity of a set of Twitter users in order to determine how well machine learning algorithms can detect a personxe2x80x99s outlook on life by reading their tweets. A sample of tweets from each user is manually annotated in order to establish ground truth labels, and classifiers are trained to distinguish between optimistic and pessimistic users. Our results suggest that the words in peoplexe2x80x99s tweets provide ample evidence to identify them as optimists, pessimists, or somewhere in between. Additionally, several applications of these trained models are explored."
L16-1592,Building a Dataset for Possessions Identification in Text,2016,0,0,3,1,21353,carmen banea,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Just as industrialization matured from mass production to customization and personalization, so has the Web migrated from generic content to public disclosures of one{'}s most intimately held thoughts, opinions and beliefs. This relatively new type of data is able to represent finer and more narrowly defined demographic slices. If until now researchers have primarily focused on leveraging personalized content to identify latent information such as gender, nationality, location, or age of the author, this study seeks to establish a structured way of extracting possessions, or items that people own or are entitled to, as a way to ultimately provide insights into people{'}s behaviors and characteristics. In order to promote more research in this area, we are releasing a set of 798 possessions extracted from blog genre, where possessions are marked at different confidence levels, as well as a detailed set of guidelines to help in future annotation studies."
C16-1065,Identifying Cross-Cultural Differences in Word Usage,2016,16,5,2,1,8420,aparna garimella,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Personal writings have inspired researchers in the fields of linguistics and psychology to study the relationship between language and culture to better understand the psychology of people across different cultures. In this paper, we explore this relation by developing cross-cultural word models to identify words with cultural bias {--} i.e., words that are used in significantly different ways by speakers from different cultures. Focusing specifically on two cultures: United States and Australia, we identify a set of words with significant usage differences, and further investigate these words through feature analysis and topic modeling, shedding light on the attributes of language that contribute to these differences."
C16-1233,Targeted Sentiment to Understand Student Comments,2016,24,4,2,1,8415,charles welch,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We address the task of targeted sentiment as a means of understanding the sentiment that students hold toward courses and instructors, as expressed by students in their comments. We introduce a new dataset consisting of student comments annotated for targeted sentiment and describe a system that can both identify the courses and instructors mentioned in student comments, as well as label the students{'} sentiment toward those entities. Through several comparative evaluations, we show that our system outperforms previous work on a similar task."
S15-2045,"{S}em{E}val-2015 Task 2: Semantic Textual Similarity, {E}nglish, {S}panish and Pilot on Interpretability",2015,15,106,10,0,8824,eneko agirre,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"In semantic textual similarity (STS), systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new datasets in English and Spanish. The annotations for both subtasks leveraged crowdsourcing. The English subtask attracted 29 teams with 74 system runs, and the Spanish subtask engaged 7 teams participating with 16 system runs. In addition, this year we ran a pilot task on interpretable STS, where the systems needed to add an explanatory layer, that is, they had to align the chunks in the sentence pair, explicitly annotating the kind of relation and the score of the chunk pair. The train and test data were manually annotated by an expert, and included headline and image sentence pairs from previous years. 7 teams participated with 29 runs."
N15-3024,Using Word Semantics To Assist {E}nglish as a Second Language Learners,2015,9,2,3,1,17745,mahmoud azab,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,We introduce an interactive interface that aims to help English as a Second Language (ESL) students overcome language related hindrances while reading a text. The interface allows the user to find supplementary information on selected difficult words. The interface is empowered by our lexical substitution engine that provides context-based synonyms for difficult words. We also provide a practical solution for a real-world usage scenario. We demonstrate using the lexical substitution engine xe2x80x90 as a browser extension that can annotate and disambiguate difficult words on any webpage.
D15-1133,Experiments in Open Domain Deception Detection,2015,16,25,2,1,2882,veronica perezrosas,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"The widespread use of deception in online sources has motivated the need for methods to automatically profile and identify deceivers. This work explores deception, gender and age detection in short texts using a machine learning approach. First, we collect a new open domain deception dataset also containing demographic data such as gender and age. Second, we extract feature sets including n-grams, shallow and deep syntactic features, semantic features, and syntactic complexity and readability metrics. Third, we build classifiers that aim to predict deception, gender, and age. Our findings show that while deception detection can be performed in short texts even in the absence of a predetermined domain, gender and age prediction in deceptive texts is a challenging task. We further explore the linguistic differences in deceptive content that relate to deceivers gender and age and find evidence that both age and gender play an important role in peoplexe2x80x99s word choices when fabricating lies."
D15-1281,Verbal and Nonverbal Clues for Real-life Deception Detection,2015,39,25,3,1,2882,veronica perezrosas,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Deception detection has been receiving an increasing amount of attention from the computational linguistics, speech, and multimodal processing communities. One of the major challenges encountered in this task is the availability of data, and most of the research work to date has been conducted on acted or artificially collected data. The generated deception models are thus lacking real-world evidence. In this paper, we explore the use of multimodal real-life data for the task of deception detection. We develop a new deception dataset consisting of videos from reallife scenarios, and build deception tools relying on verbal and nonverbal features. We achieve classification accuracies in the range of 77-82% when using a model that extracts and fuses features from the linguistic and visual modalities. We show that these results outperform the human capability of identifying deceit."
D15-1283,Co-Training for Topic Classification of Scholarly Data,2015,30,6,3,0,3708,cornelia caragea,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"With the exponential growth of scholarly data during the past few years, effective methods for topic classification are greatly needed. Current approaches usually require large amounts of expensive labeled data in order to make accurate predictions. In this paper, we posit that, in addition to a research articlexe2x80x99s textual content, its citation network also contains valuable information. We describe a co-training approach that uses the text and citation information of a research article as two different views to predict the topic of an article. We show that this method improves significantly over the individual classifiers, while also bringing a substantial reduction in the amount of labeled data required for training accurate classifiers."
S14-2010,{S}em{E}val-2014 Task 10: Multilingual Semantic Textual Similarity,2014,25,158,8,0,8824,eneko agirre,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"In Semantic Textual Similarity, systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new data sets for English, as well as the introduction of Spanish, as a new language in which to assess semantic similarity. For the English subtask, we exposed the systems to a diversity of testing scenarios, by preparing additional OntoNotesWordNet sense mappings and news headlines, as well as introducing new genres, including image descriptions, DEFT discussion forums, DEFT newswire, and tweet-newswire headline mappings. For Spanish, since, to our knowledge, this is the first time that official evaluations are conducted, we used well-formed text, by featuring sentences extracted from encyclopedic content and newswire. The annotations for both tasks leveraged crowdsourcing. The Spanish subtask engaged 9 teams participating with 22 system runs, and the English subtask attracted 15 teams with 38 system runs."
S14-2098,{S}im{C}ompass: Using Deep Learning Word Embeddings to Assess Cross-level Similarity,2014,30,21,3,1,21353,carmen banea,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This article presents our teamxe2x80x99s participating system at SemEval-2014 Task 3. Using a meta-learning framework, we experiment with traditional knowledgebased metrics, as well as novel corpusbased measures based on deep learning paradigms, paired with varying degrees of context expansion. The framework enabled us to reach the highest overall performance among all competing systems."
P14-2072,Cross-cultural Deception Detection,2014,16,23,2,1,2882,veronica perezrosas,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In this paper, we address the task of cross-cultural deception detection. Using crowdsourcing, we collect three deception datasets, two in English (one originating from United States and one from India), and one in Spanish obtained from speakers from Mexico. We run comparative experiments to evaluate the accuracies of deception classifiers built for each culture, and also to analyze classification differences within and across cultures. Our results show that we can leverage cross-cultural information, either through translation or equivalent semantic categories, and build deception classifiers with a performance ranging between 60-70%."
loza-etal-2014-building,Building a Dataset for Summarization and Keyword Extraction from Emails,2014,13,14,3,0,39279,vanessa loza,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper introduces a new email dataset, consisting of both single and thread emails, manually annotated with summaries and keywords. A total of 349 emails and threads have been annotated. The dataset is our first step toward developing automatic methods for summarization and keyword extraction from emails. We describe the email corpus, along with the annotation interface, annotator guidelines, and agreement studies."
hokamp-etal-2014-modeling,Modeling Language Proficiency Using Implicit Feedback,2014,12,1,2,1,22646,chris hokamp,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We describe the results of several experiments with interactive interfaces for native and L2 English students, designed to collect implicit feedback from students as they complete a reading activity. In this study, implicit means that all data is obtained without asking the user for feedback. To test the value of implicit feedback for assessing student proficiency, we collect features of user behavior and interaction, which are then used to train classification models. Based upon the feedback collected during these experiments, a studentÂs performance on a quiz and proficiency relative to other students can be accurately predicted, which is a step on the path to our goal of providing automatic feedback and unintrusive evaluation in interactive learning environments."
perez-rosas-etal-2014-multimodal,A Multimodal Dataset for Deception Detection,2014,13,9,2,1,2882,veronica perezrosas,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents the construction of a multimodal dataset for deception detection, including physiological, thermal, and visual responses of human subjects under three deceptive scenarios. We present the experimental protocol, as well as the data acquisition process. To evaluate the usefulness of the dataset for the task of deception detection, we present a statistical analysis of the physiological and thermal modalities associated with the deceptive and truthful conditions. Initial results show that physiological and thermal responses can differentiate between deceptive and truthful states."
E14-1029,Iterative Constrained Clustering for Subjectivity Word Sense Disambiguation,2014,36,3,3,1,25921,cem akkaya,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Subjectivity word sense disambiguation (SWSD) is a supervised and applicationspecific word sense disambiguation task disambiguating between subjective and objective senses of a word. Not surprisingly, SWSD suffers from the knowledge acquisition bottleneck. In this work, we use a xe2x80x9ccluster and labelxe2x80x9d strategy to generate labeled data for SWSD semiautomatically. We define a new algorithm called Iterative Constrained Clustering (ICC) to improve the clustering purity and, as a result, the quality of the generated data. Our experiments show that the SWSD classifiers trained on the ICC generated data by requiring only 59% of the labels can achieve the same performance as the classifiers trained on the full dataset."
W13-1732,Using N-gram and Word Network Features for Native Language Identification,2013,32,2,2,1,32904,shibamouli lahiri,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We report on the performance of two different feature sets in the Native Language Identification Shared Task (Tetreault et al., 2013). Our feature sets were inspired by existing literature on native language identification and word networks. Experiments show that word networks have competitive performance against the baseline feature set, which is a promising result. We also present a discussion of feature analysis based on information gain, and an overview on the performance of different word network features in the Native Language Identification task."
S13-1003,Coarse to Fine Grained Sense Disambiguation in {W}ikipedia,2013,20,12,3,0,41264,hui shen,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"Wikipedia articles are annotated by volunteer contributors with numerous links that connect words and phrases to relevant titles. Links to general senses of a word are used concurrently with links to more specific senses, without being distinguished explicitly. We present an approach to training coarse to fine grained sense disambiguation systems in the presence of such annotation inconsistencies. Experimental results show that accounting for annotation ambiguity in Wikipedia links leads to significant improvements in disambiguation."
S13-1032,{CPN}-{CORE}: A Text Semantic Similarity System Infused with Opinion Knowledge,2013,39,2,8,1,21353,carmen banea,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"This article provides a detailed overview of the CPN text-to-text similarity system that we participated with in the Semantic Textual Similarity task evaluations hosted at *SEM 2013. In addition to more traditional components, such as knowledge-based and corpus-based metrics leveraged in a machine learning framework, we also use opinion analysis features to achieve a stronger semantic representation of textual units. While the evaluation datasets are not designed to test the similarity of opinions, as a component of textual similarity, nonetheless, our system variations ranked number 38, 39 and 45 among the 88 participating systems."
R13-1022,Sense Clustering Using {W}ikipedia,2013,21,15,3,1,33535,bharath dandala,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"In this paper, we propose a novel method for generating a coarse-grained sense inventory from Wikipedia using a machine learning framework. Structural and content-based features are employed to induce clusters of articles representative of a word sense. Additionally, multilingual features are shown to improve the clustering accuracy, especially for languages that are less comprehensive than English. We show the effectiveness of our clustering methodology by testing it against both manually and automatically annotated datasets."
P13-1096,Utterance-Level Multimodal Sentiment Analysis,2013,52,74,2,1,2882,veronica perezrosas,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"During real-life interactions, people are naturally gesturing and modulating their voice to emphasize specific points or to express their emotions. With the recent growth of social websites such as YouTube, Facebook, and Amazon, video reviews are emerging as a new source of multimodal and natural opinions that has been left almost untapped by automatic opinion analysis techniques. This paper presents a method for multimodal sentiment classification, which can identify the sentiment expressed in utterance-level visual datastreams. Using a new multimodal dataset consisting of sentiment annotated utterances extracted from video reviews, we show that multimodal sentiment analysis can be effectively performed, and that the joint use of visual, acoustic, and linguistic modalities can lead to error rate reductions of up to 10.5% as compared to the best performing individual modality."
I13-1057,Multilingual Word Sense Disambiguation Using {W}ikipedia,2013,28,7,2,1,33535,bharath dandala,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Ambiguity is inherent to human language. In particular, word sense ambiguity is prevalent in all natural languages, with a large number of the words in any given language carrying more than one meaning. Word sense disambiguation is the task of automatically assigning the most appropriate meaning to a polysemous word within a given context. Generally the problem of resolving ambiguity in literature has revolved around the famous quote xe2x80x9cyou shall know the meaning of the word by the company it keeps.xe2x80x9d In this thesis, we investigate the role of context for resolving ambiguity through three different approaches. Instead of using a predefined monolingual sense inventory such as WordNet, we use a language-independent framework where the word senses and sense-tagged data are derived automatically from Wikipedia. Using Wikipedia as a source of sense-annotations provides the much needed solution for knowledge acquisition bottleneck. In order to evaluate the viability of Wikipedia based sense-annotations, we cast the task of disambiguating polysemous nouns as a monolingual classification task and experimented on lexical samples from four different languages (viz. English, German, Italian and Spanish). The experiments confirm that the Wikipedia based sense annotations are reliable and can be used to construct accurate monolingual sense classifiers. It is a long belief that exploiting multiple languages helps in building accurate word sense disambiguation systems. Subsequently, we developed two approaches that recast the task of disambiguating polysemous nouns as a multilingual classification task. The first approach for multilingual word sense disambiguation attempts to effectively use a machine translation system to leverage two relevant multilingual aspects of the semantics of text. First, the various senses of a target word may be translated into different words, which constitute unique, yet highly salient signal that effectively expand the target wordxe2x80x99s feature space. Second, the translated context words themselves embed co-occurrence information that a translation engine gathers from very large parallel corpora. The second approach for multlingual word sense disambiguation attempts to reduce the reliance on the machine translation system during training by using the multilingual knowledge available in Wikipedia through its interlingual links. Finally, the experiments on a lexical sample from four different languages confirm that the multilingual systems perform better than the monolingual system and significantly improve the disambiguation accuracy."
W12-3701,Multimodal Sentiment Analysis,2012,0,0,1,1,1124,rada mihalcea,Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis,0,None
W12-0506,Multilingual Natural Language Processing,2012,0,0,1,1,1124,rada mihalcea,Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data,0,"With rapidly growing online resources, such as Wikipedia, Twitter, or Facebook, there is an increasing number of languages that have a Web presence, and correspondingly there is a growing need for effective solutions for multilingual natural language processing. In this talk, I will explore the hypothesis that a multilingual representation can enrich the feature space for natural language processing tasks, and lead to significant improvements over traditional solutions that rely exclusively on a monolingual representation. Specifically, I will describe experiments performed on three different tasks: word sense disambiguation, subjectivity analysis, and text semantic similarity, and show how the use of a multilingual representation can leverage additional information from the languages in the multilingual space, and thus improve over the use of only one language at a time. This is joint work with Samer Hassan and Carmen Banea."
S12-1003,Measuring Semantic Relatedness using Multilingual Representations,2012,46,13,3,1,41275,samer hassan,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper explores the hypothesis that semantic relatedness may be more reliably inferred by using a multilingual space, as compared to the typical monolingual representation. Through evaluations using several state-of-the-art semantic relatedness systems, applied on standard datasets, we show that a multilingual approach is better suited for this task, and leads to improvements of up to 47% with respect to the monolingual baseline."
S12-1004,Towards Building a Multilingual Semantic Network: Identifying Interlingual Links in {W}ikipedia,2012,12,3,2,1,33535,bharath dandala,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"Wikipedia is a Web based, freely available multilingual encyclopedia, constructed in a collaborative effort by thousands of contributors. Wikipedia articles on the same topic in different languages are connected via interlingual (or translational) links. These links serve as an excellent resource for obtaining lexical translations, or building multilingual dictionaries and semantic networks. As these links are manually built, many links are missing or simply wrong. This paper describes a supervised learning method for generating new links and detecting existing incorrect links. Since there is no dataset available to evaluate the resulting interlingual links, we create our own gold standard by sampling translational links from four language pairs using distance heuristics. We manually annotate the sampled translation links and used them to evaluate the output of our method for automatic link detection and correction."
S12-1046,{S}em{E}val-2012 Task 1: {E}nglish Lexical Simplification,2012,14,54,3,0,2509,lucia specia,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We describe the English Lexical Simplification task at SemEval-2012. This is the first time such a shared task has been organized and its goal is to provide a framework for the evaluation of systems for lexical simplification and foster research on context-aware lexical simplification approaches. The task requires that annotators and systems rank a number of alternative substitutes -- all deemed adequate -- for a target word in context, according to how simple these substitutes are. The notion of simplicity is biased towards non-native speakers of English. Out of nine participating systems, the best scoring ones combine context-dependent and context-independent information, with the strongest individual contribution given by the frequency of the substitute regardless of its context."
S12-1094,{UNT}: A Supervised Synergistic Approach to Semantic Text Similarity,2012,31,25,4,1,21353,carmen banea,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper presents the systems that we participated with in the Semantic Text Similarity task at SEMEVAL 2012. Based on prior research in semantic similarity and relatedness, we combine various methods in a machine learning framework. The three variations submitted during the task evaluation period ranked number 5, 9 and 14 among the 89 participating systems. Our evaluations show that corpus-based methods display a more robust behavior on the training data, yet combining a variety of methods allows a learning algorithm to achieve a superior decision than that achievable by any of the individual parts."
P12-4004,Multilingual Subjectivity and Sentiment Analysis,2012,3,8,1,1,1124,rada mihalcea,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,"Subjectivity and sentiment analysis focuses on the automatic identification of private states, such as opinions, emotions, sentiments, evaluations, beliefs, and speculations in natural language. While subjectivity classification labels text as either subjective or objective, sentiment classification adds an additional level of granularity, by further classifying subjective text as either positive, negative or neutral.n n While much of the research work in this area has been applied to English, research on other languages is growing, including Japanese, Chinese, German, Spanish, Romanian. While most of the researchers in the field are familiar with the methods applied on English, few of them have closely looked at the original research carried out in other languages. For example, in languages such as Chinese, researchers have been looking at the ability of characters to carry sentiment information (Ku et al., 2005; Xiang, 2011). In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (Banea et al., 2008). These additional sources of information may not be available across all languages, yet, various articles have pointed out that by investigating a synergistic approach for detecting subjectivity and sentiment in multiple languages at the same time, improvements can be achieved not only in other languages, but in English as well. The development and interest in these methods is also highly motivated by the fact that only 27% of Internet users speak English (www.internetworldstats.com/stats.htm, Oct 11, 2011), and that number diminishes further every year, as more people across the globe gain Internet access.n n The aim of this tutorial is to familiarize the attendees with the subjectivity and sentiment research carried out on languages other than English in order to enable and promote cross-fertilization. Specifically, we will review work along three main directions. First, we will present methods where the resources and tools have been specifically developed for a given target language. In this category, we will also briefly overview the main methods that have been proposed for English, but which can be easily ported to other languages. Second, we will describe cross-lingual approaches, including several methods that have been proposed to leverage on the resources and tools available in English by using cross-lingual projections. Finally, third, we will show how the expression of opinions and polarity pervades language boundaries, and thus methods that holistically explore multiple languages at the same time can be effectively considered."
P12-2051,Word Epoch Disambiguation: Finding How Words Change Over Time,2012,11,50,1,1,1124,rada mihalcea,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"In this paper we introduce the novel task of word epoch disambiguation, defined as the problem of identifying changes in word usage over time. Through experiments run using word usage examples collected from three major periods of time (1800, 1900, 2000), we show that the task is feasible, and significant differences can be observed between occurrences of words in different periods of time."
strapparava-etal-2012-parallel,A Parallel Corpus of Music and Lyrics Annotated with Emotions,2012,11,3,2,0,16980,carlo strapparava,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we introduce a novel parallel corpus of music and lyrics, annotated with emotions at line level. We first describe the corpus, consisting of 100 popular songs, each of them including a music component, provided in the MIDI format, as well as a lyrics component, made available as raw text. We then describe our work on enhancing this corpus with emotion annotations using crowdsourcing. We also present some initial experiments on emotion classification using the music and the lyrics representations of the songs, which lead to encouraging results, thus demonstrating the promise of using joint music-lyric models for song processing."
perez-rosas-etal-2012-learning,Learning Sentiment Lexicons in {S}panish,2012,31,85,3,1,2882,veronica perezrosas,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we present a framework to derive sentiment lexicons in a target language by using manually or automatically annotated data available in an electronic resource rich language, such as English. We show that bridging the language gap using the multilingual sense-level aligned WordNet structure allows us to generate a high accuracy (90{\%}) polarity lexicon comprising 1,347 entries, and a disjoint lower accuracy (74{\%}) one encompassing 2,496 words. By using an LSA-based vectorial expansion for the generated lexicons, we are able to obtain an average F-measure of 66{\%} in the target language. This implies that the lexicons could be used to bootstrap higher-coverage lexicons using in-language resources."
fernandez-ordonez-etal-2012-unsupervised,Unsupervised Word Sense Disambiguation with Multilingual Representations,2012,14,11,2,0,43365,erwin fernandezordonez,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we investigate the role of multilingual features in improving word sense disambiguation. In particular, we explore the use of semantic clues derived from context translation to enrich the intended sense and therefore reduce ambiguity. Our experiments demonstrate up to 26{\%} increase in disambiguation accuracy by utilizing multilingual features as compared to the monolingual baseline."
D12-1054,"Lyrics, Music, and Emotions",2012,35,29,1,1,1124,rada mihalcea,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"In this paper, we explore the classification of emotions in songs, using the music and the lyrics representation of the songs. We introduce a novel corpus of music and lyrics, consisting of 100 songs annotated for emotions. We show that textual and musical features can both be successfully used for emotion recognition in songs. Moreover, through comparative experiments, we show that the joint use of lyrics and music brings significant improvements over each of the individual textual and musical classifiers, with error rate reductions of up to 31%."
C12-2108,Sense and Reference Disambiguation in {W}ikipedia,2012,18,0,3,0,41264,hui shen,Proceedings of {COLING} 2012: Posters,0,"Wikipedia articles are annotated by volunteer contributors with numerous links that connect words and phrases to relevant titles in Wikipedia. In this paper, we identify inconsistencies in the user annotation of links and show that they can have a substantial impact on the performance of word sense disambiguation systems that are trained on Wikipedia links. We describe two major types of link annotations xe2x80x90 sense and reference xe2x80x90 that are frequently used without being explicitly distinguished in Wikipedia, and present an approach to training sense and reference disambiguation systems in the presence of such annotation inconsistencies. Experimental results demonstrate that accounting for annotation ambiguity in Wikipedia links leads to significant improvements in disambiguation accuracy."
W11-3707,Sense-level Subjectivity in a Multilingual Setting,2011,33,1,2,1,21353,carmen banea,Proceedings of the Workshop on Sentiment Analysis where {AI} meets Psychology ({SAAIP} 2011),0,"This paper explores the ability of senses aligned across languages to carry coherent subjectivity information. We start out with a manual annotation study, and then seek to create an automatic framework to determine subjectivity labeling for unseen senses. We identify two methods that are able to incorporate subjectivity information originating from different languages, namely co-training and multilingual vector spaces, and show that for this task the latter method is better suited and obtains superior results."
W11-1513,Topic Modeling on Historical Newspapers,2011,7,33,3,0,44330,tzei yang,"Proceedings of the 5th {ACL}-{HLT} Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",0,"In this paper, we explore the task of automatic text processing applied to collections of historical newspapers, with the aim of assisting historical research. In particular, in this first stage of our project, we experiment with the use of topical models as a means to identify potential issues of interest for historians."
W11-0311,Improving the Impact of Subjectivity Word Sense Disambiguation on Contextual Opinion Analysis,2011,32,21,4,1,25921,cem akkaya,Proceedings of the Fifteenth Conference on Computational Natural Language Learning,0,"Subjectivity word sense disambiguation (SWSD) is automatically determining which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. SWSD has been shown to improve the performance of contextual opinion analysis, but only on a small scale and using manually developed integration rules. In this paper, we scale up the integration of SWSD into contextual opinion analysis and still obtain improvements in performance, by successfully gathering data annotated by non-expert annotators. Further, by improving the method for integrating SWSD into contextual opinion analysis, even greater benefits from SWSD are achieved than in previous work. We thus more firmly demonstrate the potential of SWSD to improve contextual opinion analysis."
W11-0104,Word Sense Disambiguation with Multilingual Features,2011,18,27,2,1,21353,carmen banea,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"This paper explores the role played by a multilingual feature representation for the task of word sense disambiguation. We translate the context of an ambiguous word in multiple languages, and show through experiments on standard datasets that by using a multilingual vector space we can obtain error rate reductions of up to 25%, as compared to a monolingual classifier."
W11-0120,Measuring the semantic relatedness between words and images,2011,22,10,2,1,19992,chee leong,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"Measures of similarity have traditionally focused on computing the semantic relatedness between pairs of words and texts. In this paper, we construct an evaluation framework to quantify cross-modal semantic relationships that exist between arbitrary pairs of words and images. We study the effectiveness of a corpus-based approach to automatically derive the semantic relatedness between words and images, and perform empirical evaluations by measuring its correlation with human annotators."
P11-4018,An Efficient Indexer for Large N-Gram Corpora,2011,15,7,2,1,44580,hakan ceylan,Proceedings of the {ACL}-{HLT} 2011 System Demonstrations,0,"We introduce a new publicly available tool that implements efficient indexing and retrieval of large N-gram datasets, such as the Web1T 5-gram corpus. Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access. With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous. Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5-gram corpus (Yuret, 2008). We demonstrate the effectiveness of our tool and the smoothing algorithms on the English Lexical Substitution task by a simple implementation that gives considerable improvement over a basic language model."
P11-1076,Learning to Grade Short Answer Questions using Semantic Similarity Measures and Dependency Graph Alignments,2011,28,111,3,1,35377,michael mohler,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,In this work we address the task of computerassisted assessment of short student answers. We combine several graph alignment features with lexical semantic similarity measures using machine learning techniques and show that the student answers can be more accurately graded than if the semantic measures were used in isolation. We also present a first attempt to align the dependency graphs of the student and the instructor answers in order to make use of a structural component in the automatic grading of student answers.
I11-1162,Going Beyond Text: A Hybrid Image-Text Approach for Measuring Word Relatedness,2011,18,29,2,1,19992,chee leong,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Traditional approaches to semantic relatedness are often restricted to text-based methods, which typically disregard other multimodal knowledge sources. In this paper, we propose a novel image-based metric to estimate the relatedness of words, and demonstrate the promise of this method through comparative evaluations on three standard datasets. We also show that a hybrid image-text approach can lead to improvements in word relatedness, confirming the applicability of visual cues as a possible orthogonal information source."
W10-0731,{A}mazon {M}echanical {T}urk for Subjectivity Word Sense Disambiguation,2010,14,55,4,1,25921,cem akkaya,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"Amazon Mechanical Turk (MTurk) is a marketplace for so-called human intelligence tasks (HITs), or tasks that are easy for humans but currently difficult for automated processes. Providers upload tasks to MTurk which workers then complete. Natural language annotation is one such human intelligence task. In this paper, we investigate using MTurk to collect annotations for Subjectivity Word Sense Disambiguation (SWSD), a coarse-grained word sense disambiguation task. We investigate whether we can use MTurk to acquire good annotations with respect to gold-standard data, whether we can filter out low-quality workers (spammers), and whether there is a learning effect associated with repeatedly completing the same kind of task. While our results with respect to spammers are inconclusive, we are able to obtain high-quality annotations for the SWSD task. These results suggest a greater role for MTurk with respect to constructing a large scale SWSD system in the future, promising substantial improvement in subjectivity and sentiment analysis."
S10-1002,{S}em{E}val-2010 Task 2: Cross-Lingual Lexical Substitution,2010,15,60,1,1,1124,rada mihalcea,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"In this paper we describe the SemEval-2010 Cross-Lingual Lexical Substitution task, where given an English target word in context, participating systems had to find an alternative substitute word or phrase in Spanish. The task is based on the English Lexical Substitution task run at SemEval-2007. In this paper we provide background and motivation for the task, we describe the data annotation process and the scoring system, and present the results of the participating systems."
N10-1133,Quantifying the Limits and Success of Extractive Summarization Systems Across Domains,2010,19,25,2,1,44580,hakan ceylan,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper analyzes the topic identification stage of single-document automatic text summarization across four different domains, consisting of newswire, literary, scientific and legal documents. We present a study that explores the summary space of each domain via an exhaustive search strategy, and finds the probability density function (pdf) of the ROUGE score distributions for each domain. We then use this pdf to calculate the percentile rank of extractive summarization systems. Our results introduce a new way to judge the success of automatic summarization systems and bring quantified explanations to questions such as why it was so hard for the systems to date to have a statistically significant improvement over the lead baseline in the news domain."
D10-1103,Cross Language Text Classification by Model Translation and Semi-Supervised Learning,2010,27,64,2,1,35822,lei shi,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we introduce a method that automatically builds text classifiers in a new language by training on already labeled data in another language. Our method transfers the classification knowledge across languages by translating the model features and by using an Expectation Maximization (EM) algorithm that naturally takes into account the ambiguity associated with the translation of a word. We further exploit the readily available unlabeled data in the target language via semi-supervised learning, and adapt the translated model to better fit the data distribution of the target language."
C10-2074,Text Mining for Automatic Image Tagging,2010,28,35,2,1,19992,chee leong,Coling 2010: Posters,0,"This paper introduces several extractive approaches for automatic image tagging, relying exclusively on information mined from texts. Through evaluations on two datasets, we show that our methods exceed competitive baselines by a large margin, and compare favorably with the state-of-the-art that uses both textual and image features."
C10-1004,Multilingual Subjectivity: Are More Languages Better?,2010,21,101,2,1,21353,carmen banea,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"While subjectivity related research in other languages has increased, most of the work focuses on single languages. This paper explores the integration of features originating from multiple languages into a machine learning approach to subjectivity analysis, and aims to show that this enriched feature set provides for more effective modeling for the source as well as the target languages. We show not only that we are able to achieve over 75% macro accuracy in all of the six languages we experiment with, but also that by using features drawn from multiple languages we can construct high-precision meta-classifiers with a precision of over 83%."
W09-3009,Explorations in Automatic Image Annotation using Textual Features,2009,7,5,2,1,19992,chee leong,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"In this paper, we report our work on automatic image annotation by combining several textual features drawn from the text surrounding the image. Evaluation of our system is performed on a dataset of images and texts collected from the web. We report our findings through comparative evaluation with two gold standard collections of manual annotations on the same dataset."
W09-2412,{S}em{E}val-2010 Task 2: Cross-Lingual Lexical Substitution,2009,14,23,3,0,42607,ravi sinha,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"In this paper we describe the SemEval-2010 Cross-Lingual Lexical Substitution task, which is based on the English Lexical Substitution task run at SemEval-2007. In the English version of the task, annotators and systems had to find an alternative substitute word or phrase for a target word in context. In this paper we propose a task where the target word and contexts will be in English, but the substitutes will be in Spanish. In this paper we provide background and motivation for the task and describe how the dataset will differ from a machine translation task and previous word sense disambiguation tasks based on parallel data. We describe the annotation process and how we anticipate scoring the system output. We finish with some ideas for participating systems."
W09-1126,Using Encyclopedic Knowledge for Automatic Topic Identification,2009,9,51,2,0,47058,kino coursey,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL}-2009),0,"This paper presents a method for automatic topic identification using an encyclopedic graph derived from Wikipedia. The system is found to exceed the performance of previously proposed machine learning algorithms for topic identification, with an annotation consistency comparable to human annotations."
R09-1024,Learning to Identify Educational Materials,2009,3,7,2,1,41275,samer hassan,Proceedings of the International Conference {RANLP}-2009,0,None
R09-1073,Combining Lexical Resources for Contextual Synonym Expansion,2009,19,13,2,0,42607,ravi sinha,Proceedings of the International Conference {RANLP}-2009,0,"In this paper, we experiment with the task of contextual synonym expansion, and compare the benefits of combining multiple lexical resources using both unsupervised and supervised approaches. Overall, the results obtained through the combination of several resources exceed the current state-of-the-art when selecting the best synonym for a given target word, and place second when selecting the top ten synonyms, thus demonstrating the usefulness of the approach."
P09-2078,The Lie Detector: Explorations in the Automatic Recognition of Deceptive Language,2009,7,168,1,1,1124,rada mihalcea,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"In this paper, we present initial experiments in the recognition of deceptive language. We introduce three data sets of true and lying texts collected for this purpose, and we show that automatic classification is a viable technique to distinguish between truth and falsehood as expressed in language. We also introduce a method for class-based feature analysis, which sheds some light on the features that are characteristic for deceptive text."
N09-2030,Topic Identification Using {W}ikipedia Graph Centrality,2009,5,43,2,0,47058,kino coursey,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"This paper presents a method for automatic topic identification using a graph-centrality algorithm applied to an encyclopedic graph derived from Wikipedia. When tested on a data set with manually assigned topics, the system is found to significantly improve over a simpler baseline that does not make use of the external encyclopedic knowledge."
N09-1002,Integrating Knowledge for Subjectivity Sense Labeling,2009,23,20,3,0,47329,yaw gyamfi,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper introduces an integrative approach to automatic word sense subjectivity annotation. We use features that exploit the hierarchical structure and domain information in lexical resources such as WordNet, as well as other types of features that measure the similarity of glosses and the overlap among sets of semantically related words. Integrated in a machine learning framework, the entire set of features is found to give better results than any individual type of feature."
E09-1065,Text-to-Text Semantic Similarity for Automatic Short Answer Grading,2009,25,148,2,1,35377,michael mohler,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"In this paper, we explore unsupervised techniques for the task of automatic short answer grading. We compare a number of knowledge-based and corpus-based measures of text similarity, evaluate the effect of domain and size on the corpus-based measures, and also introduce a novel technique to improve the performance of the system by integrating automatic feedback from the student answers. Overall, our system significantly and consistently outperforms other unsupervised methods for short answer grading that have been proposed in the past."
D09-1020,Subjectivity Word Sense Disambiguation,2009,27,119,3,1,25921,cem akkaya,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper investigates a new task, subjectivity word sense disambiguation (SWSD), which is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses. We provide empirical evidence that SWSD is more feasible than full word sense disambiguation, and that it can be exploited to improve the performance of contextual subjectivity and sentiment analysis systems."
D09-1124,Cross-lingual Semantic Relatedness Using Encyclopedic Knowledge,2009,28,89,2,1,41275,samer hassan,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we address the task of crosslingual semantic relatedness. We introduce a method that relies on the information extracted from Wikipedia, by exploiting the interlanguage links available between Wikipedia versions in multiple languages. Through experiments performed on several language pairs, we show that the method performs well, with a performance comparable to monolingual measures of relatedness."
P08-1106,Linguistically Motivated Features for Enhanced Back-of-the-Book Indexing,2008,17,21,2,1,47924,andras csomai,Proceedings of ACL-08: HLT,1,This paper discusses linguistically motivated features for enhanced back-of-the-book indexing.
mohler-mihalcea-2008-babylon,Babylon Parallel Text Builder: Gathering Parallel Texts for Low-Density Languages,2008,9,5,2,1,35377,michael mohler,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper describes Babylon, a system that attempts to overcome the shortage of parallel texts in low-density languages by supplementing existing parallel texts with texts gathered automatically from the Web. In addition to the identification of entire Web pages, we also propose a new feature specifically designed to find parallel text chunks within a single document. Experiments carried out on the Quechua-Spanish language pair show that the system is successful in automatically identifying a significant amount of parallel texts on the Web. Evaluations of a machine translation system trained on this corpus indicate that the Web-gathered parallel texts can supplement manually compiled parallel texts and perform significantly better than the manually compiled texts when tested on other Web-gathered data."
banea-etal-2008-bootstrapping,A Bootstrapping Method for Building Subjectivity Lexicons for Languages with Scarce Resources,2008,16,113,2,1,21353,carmen banea,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper introduces a method for creating a subjectivity lexicon for languages with scarce resources. The method is able to build a subjectivity lexicon by using a small seed set of subjective words, an online dictionary, and a small raw corpus, coupled with a bootstrapping process that ranks new candidate words based on a similarity measure. Experiments performed with a rule-based sentence level subjectivity classifier show an 18{\%} absolute improvement in F-measure as compared to previously proposed semi-supervised methods."
J08-1004,Book Reviews: The Text Mining Handbook: Advanced Approaches to Analyzing Unstructured Data by Ronen Feldman and {J}ames Sanger,2008,0,4,1,1,1124,rada mihalcea,Computational Linguistics,0,None
I08-2136,How to Add a New Language on the {NLP} Map: Building Resources and Tools for Languages with Scarce Resources,2008,0,1,1,1,1124,rada mihalcea,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"Those of us whose mother tongue is not English or are curious about applications involving other languages, often find ourselves in the situation where the tools we require are not available. According to recent studies there are about 7200 different languages spoken worldwide xe2x80x93 without including variations or dialects xe2x80x93 out of which very few have automatic language processing tools and machine readable resources. In this tutorial we will show how we can take advantage of lessons learned from frequently studied and used languages in NLP, and of the wealth of information and collaborative efforts mediated by the World Wide Web. We structure the presentation around two major themes: mono-lingual and crosslingual approaches. Within the mono-lingual area, we show how to quickly assemble a corpus for statistical processing, how to obtain a semantic network using on-line resources xe2x80x93 in particular Wikipedia xe2x80x93 and how to obtain automatically annotated corpora for a variety of applications. The cross-lingual half of the tutorial shows how to build upon NLP methods and resources for other languages, and adapt them for a new language. We will review automatic construction of parallel corpora, projecting annotations from one side of the parallel corpus to the other, building language models, and finally we will look at how all these can come together in higherend applications such as machine translation and cross-language information retrieval. Biographies Rada Mihalcea is an Assistant Professor of Computer Science at the University of North Texas. Her research interests are in lexical semantics, multilingual natural language processing, minimally supervised natural language learning, and graph-based algorithms for natural language processing. She serves on the editorial board of the Journal of Computational Linguistics, the Journal of Language Resources and Evaluations, the Journal of Natural Language Engineering, the Journal of Research in Language in Computation, and the recently established Journal of Interesting Negative Results in Natural Language Processing and Machine Learning. Vivi Nastase is a post-doctoral fellow at EML Research gGmbH, Heidelberg, Germany. Her research interests are in lexical semantics, semantic relations, knowledge extraction, multi-document summarization, graph-based algorithms for natural language processing, multilingual natural language processing. She is a co-founder of the Journal of Interesting Negative Results in Natural Language Processing and Machine Learning."
D08-1014,Multilingual Subjectivity Analysis Using Machine Translation,2008,20,182,2,1,21353,carmen banea,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Although research in other languages is increasing, much of the work in subjectivity analysis has been applied to English data, mainly due to the large body of electronic resources and tools that are available for this language. In this paper, we propose and evaluate methods that can be employed to transfer a repository of subjectivity resources across languages. Specifically, we attempt to leverage on the resources available for English and, by employing machine translation, generate resources for subjectivity analysis in other languages. Through comparative evaluations on two different languages (Romanian and Spanish), we show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language."
S07-1013,{S}em{E}val-2007 Task 14: Affective Text,2007,8,402,2,0,16980,carlo strapparava,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"The Affective Text task focuses on the classification of emotions and valence (positive/negative polarity) in news headlines, and is meant as an exploration of the connection between emotions and lexical semantics. In this paper, we describe the data set used in the evaluation and the results obtained by the participating systems."
S07-1090,{UNT}-Yahoo: {S}uper{S}ense{L}earner: Combining {S}ense{L}earner with {S}uper{S}ense and other Coarse Semantic Features,2007,9,7,1,1,1124,rada mihalcea,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,We describe the SuperSenseLearner system that participated in the English all-words disambiguation task. The system relies on automatically-learned semantic models using collocational features coupled with features extracted from the annotations of coarse-grained semantic categories generated by an HMM tagger.
S07-1091,{UNT}: {S}ub{F}inder: Combining Knowledge Sources for Automatic Lexical Substitution,2007,7,31,5,1,41275,samer hassan,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes the University of North Texas SubFinder system. The system is able to provide the most likely set of substitutes for a word in a given context, by combining several techniques and knowledge sources. SubFinder has successfully participated in the best and out of ten (oot) tracks in the SemEval lexical substitution task, consistently ranking in the first or second place."
P07-1123,Learning Multilingual Subjective Language via Cross-Lingual Projections,2007,22,294,1,1,1124,rada mihalcea,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,This paper discusses learning multilingual subjective language via cross-lingual projections.
N07-1025,Using {W}ikipedia for Automatic Word Sense Disambiguation,2007,21,209,1,1,1124,rada mihalcea,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"This paper describes a method for generating sense-tagged data using Wikipedia as a source of sense annotations. Through word sense disambiguation experiments, the authors show that the Wikipedia-based sense annotations are reliable and can be used to construct accurate sense classifiers."
D07-1040,Explorations in Automatic Book Summarization,2007,20,45,1,1,1124,rada mihalcea,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Most of the text summarization research carried out to date has been concerned with the summarization of short documents (e.g., news stories, technical reports), and very little work if any has been done on the summarization of very long documents. In this paper, we try to address this gap and explore the problem of book summarization. We introduce a new data set specifically designed for the evaluation of systems for book summarization, and describe summarization techniques that explicitly account for the length of the documents."
P06-1134,Word Sense and Subjectivity,2006,27,227,2,0,34094,janyce wiebe,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Subjectivity and meaning are both important properties of language. This paper explores their interaction, and brings empirical evidence in support of the hypotheses that (1) subjectivity is a property that can be associated with word senses, and (2) word sense disambiguation can directly benefit from subjectivity annotations."
N06-5003,Graph-based Algorithms for Natural Language Processing and Information Retrieval,2006,0,3,1,1,1124,rada mihalcea,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Tutorial Abstracts",0,"Graph theory is a well studied discipline, and so are the fields of natural language processing and information retrieval. However, most of the times, they are perceived as different disciplines, with different algorithms, different applications, and different potential end-users."
2006.amta-papers.14,Toward Communicating Simple Sentences Using Pictorial Representations,2006,-1,-1,1,1,1124,rada mihalcea,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper evaluates the hypothesis that pictorial representations can be used to effectively convey simple sentences across language barriers. Comparative evaluations show that a considerable amount of understanding can be achieved using visual descriptions of information, with evaluation figures within a comparable range of those obtained with linguistic representations produced by an automatic machine translation system."
W05-1203,Measuring the Semantic Similarity of Texts,2005,20,275,2,0,44288,courtney corley,Proceedings of the {ACL} Workshop on Empirical Modeling of Semantic Equivalence and Entailment,0,"This paper presents a knowledge-based method for measuring the semantic-similarity of texts. While there is a large body of previous work focused on finding the semantic similarity of concepts and words, the application of these word-oriented methods to text similarity has not been yet explored. In this paper, we introduce a method that combines word-to-word similarity metrics into a text-to-text metric, and we show that this method outperforms the traditional text similarity metrics based on lexical matching."
W05-0809,Word Alignment for Languages with Scarce Resources,2005,18,68,2,0,38645,joel martin,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"This paper presents the task definition, resources, participating systems, and comparative results for the shared task on word alignment, which was organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts. The shared task included English-Inuktitut, Romanian-English, and English-Hindi sub-tasks, and drew the participation of ten teams from around the world with a total of 50 systems."
P05-3013,Language Independent Extractive Summarization,2005,8,94,1,1,1124,rada mihalcea,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"We demonstrate TextRank -- a system for unsupervised extractive summarization that relies on the application of iterative graph-based ranking algorithms to graphs encoding the cohesive structure of a text. An important characteristic of the system is that it does not rely on any language-specific knowledge resources or any manually constructed training data, and thus it is highly portable to new languages or domains."
P05-3014,{S}ense{L}earner: Word Sense Disambiguation for All Words in Unrestricted Text,2005,9,61,1,1,1124,rada mihalcea,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"This paper describes SENSELEARNER --- a minimally supervised word sense disambiguation system that attempts to disambiguate all content words in a text using WordNet senses. We evaluate the accuracy of SENSELEARNER on several standard sense-annotated data sets, and show that it compares favorably with the best results reported during the recent SENSEVAL evaluations."
I05-2004,A Language Independent Algorithm for Single and Multiple Document Summarization,2005,10,153,1,1,1124,rada mihalcea,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,This paper discusses a language independent algorithm for single and multiple document summarization.
H05-1052,Unsupervised Large-Vocabulary Word Sense Disambiguation with Graph-based Algorithms for Sequence Data Labeling,2005,16,183,1,1,1124,rada mihalcea,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper introduces a graph-based algorithm for sequence data labeling, using random walks on graphs encoding label dependencies. The algorithm is illustrated and tested in the context of an unsupervised word sense disambiguation problem, and shown to significantly outperform the accuracy achieved through individual label assignment, as measured on standard sense-annotated data sets."
H05-1067,Making Computers Laugh: Investigations in Automatic Humor Recognition,2005,11,80,1,1,1124,rada mihalcea,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"Humor is one of the most interesting and puzzling aspects of human behavior. Despite the attention it has received in fields such as philosophy, linguistics, and psychology, there have been only few attempts to create computational models for humor recognition or generation. In this paper, we bring empirical evidence that computational approaches can be successfully applied to the task of humor recognition. Through experiments performed on very large data sets, we show that automatic classification techniques can be effectively used to distinguish between humorous and non-humorous texts, with significant improvements observed over apriori known baselines."
W04-3252,{T}ext{R}ank: Bringing Order into Text,2004,10,2013,1,1,1124,rada mihalcea,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, the authors introduce TextRank, a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications."
W04-2405,Co-training and Self-training for Word Sense Disambiguation,2004,10,136,1,1,1124,rada mihalcea,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,"This paper investigates the application of co-training and self-training to word sense disambiguation. Optimal and empirical parameter selection methods for co-training and self-training are investigated, with various degrees of error reduction. A new method that combines co-training with majority voting is introduced, with the effect of smoothing the bootstrapping learning curves, and improving the average performance."
W04-2008,An algorithm for open text semantic parsing,2004,6,12,2,1,35822,lei shi,Proceedings of the 3rd workshop on {RO}bust Methods in Analysis of Natural Language Data ({ROMAND} 2004),0,"This paper describes an algorithm for open text shallow semantic parsing. The algorithm relies on a frame dataset (FrameNet) and a semantic network (WordNet), to identify semantic relations between words in open text, as well as shallow semantic features associated with concepts in the text. Parsing semantic structures allows semantic units and constituents to be accessed and processed in a more meaningful way than syntactic parsing, moving the automation of understanding natural language text to a higher level."
W04-0802,The Senseval-3 Multilingual {E}nglish-{H}indi lexical sample task,2004,4,18,2,0.769231,49341,timothy chklovski,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper describes the Englishxe2x80x90Hindi Multilingual lexical sample task in SENSEVALxe2x80x903. Rather than tagging an English word with a sense from an English dictionary, this task seeks to assign the most appropriate Hindi translation to an ambiguous target word. Training data was solicited via the Open Mind Word Expert (OMWE) from Web users who are fluent in English and Hindi."
W04-0807,The Senseval-3 {E}nglish lexical sample task,2004,3,195,1,1,1124,rada mihalcea,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper presents the task definition, resources, participating systems, and comparative results for the English lexical sample task, which was organized as part of the SENSEVAL-3 evaluation exercise. The task drew the participation of 27 teams from around the world, with a total of 47 systems."
W04-0808,An evaluation exercise for {R}omanian Word Sense Disambiguation,2004,2,2,1,1,1124,rada mihalcea,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper presents the task definition, resources, participating systems, and comparative results for a Romanian Word Sense Disambiguation task, which was organized as part of the SENSEVAL-3 evaluation exercise. Five teams with a total of seven systems were drawn to this task."
W04-0838,{S}ense{L}earner: Minimally supervised Word Sense Disambiguation for all words in open text,2004,8,53,1,1,1124,rada mihalcea,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper introduces SenseLearner - a minimally supervised sense tagger that attempts to disambiguate all content words in a text using the sense from WordNet. SenseLearner participated in the SENSEVAL-3 English all words task, and achieved an average accuracy of 64.6%."
P04-3020,"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization",2004,9,312,1,1,1124,rada mihalcea,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"This paper presents an innovative unsupervised method for automatic sentence extraction using graph-based ranking algorithms. We evaluate the method in the context of a text summarization task, and show that the results obtained compare favorably with previously published results on established benchmarks."
N04-3006,Open Text Semantic Parsing Using {F}rame{N}et and {W}ord{N}et,2004,4,16,2,1,35822,lei shi,Demonstration Papers at {HLT}-{NAACL} 2004,0,"This paper describes a rule-based semantic parser that relies on a frame dataset (FrameNet), and a semantic network (WordNet), to identify semantic relations between words in open text, as well as shallow semantic features associated with concepts in the text. Parsing semantic structures allows semantic units and constituents to be accessed and processed in a more meaningful way than syntactic parsing, moving the automation of understanding natural language text to a higher level."
nastase-mihalcea-2004-finding,Finding Semantic Associations on Express Lane,2004,5,0,2,0,51626,vivi nuastase,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,This paper introduces a new codification scheme for efficient computation of measures in semantic networks. The scheme is particularly useful for fast computation of semantic associations between words and implementation of an informational retrieval operator for efficient search in semantic spaces. Other applications may also be possible.
C04-1162,"{P}age{R}ank on Semantic Networks, with Application to Word Sense Disambiguation",2004,15,213,1,1,1124,rada mihalcea,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper presents a new open text word sense disambiguation method that combines the use of logical inferences with PageRank-style algorithms applied on graphs extracted from natural language documents. We evaluate the accuracy of the proposed algorithm on several sense-annotated texts, and show that it consistently outperforms the accuracy of other previously proposed knowledge-based word sense disambiguation methods. We also explore and evaluate methods that combine several open-text word sense disambiguation algorithms."
W03-2408,Open Mind Word Expert: Creating Large Annotated Data Collections with Web Users{'} Help,2003,14,35,1,1,1124,rada mihalcea,Proceedings of 4th International Workshop on Linguistically Interpreted Corpora ({LINC}-03) at {EACL} 2003,0,None
W03-0301,An Evaluation Exercise for Word Alignment,2003,13,165,1,1,1124,rada mihalcea,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"This paper presents the task definition, resources, participating systems, and comparative results for the shared task on word alignment, which was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts. The shared task included Romanian-English and English-French sub-tasks, and drew the participation of seven teams from around the world."
W02-2021,Letter Level Learning for Language Independent Diacritics Restoration,2002,8,31,1,1,1124,rada mihalcea,{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002),0,"This paper presents a method for diacritics restoration based on learning mechanisms that act at letter level. The method requires no additional tagging tools or resources other than raw text, which makes it independent of the language, and particularly appealing for languages for which there are few resources available. The algorithm was evaluated on four different languages, namely Czech, Hungarian, Polish and Romanian, and an average accuracy of over 98% was observed."
W02-0817,Building a Sense Tagged Corpus with Open Mind Word Expert,2002,12,100,2,0.769231,49341,timothy chklovski,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"Open Mind Word Expert is an implemented active learning system for collecting word sense tagging from the general public over the Web. It is available at http://teach-computers.org. We expect the system to yield a large volume of high-quality training data at a much lower cost than the traditional method of hiring lexicographers. We thus propose a Senseval-3 lexical sample activity where the training data is collected via Open Mind Word Expert. If successful, the collection process can be extended to create the definitive corpus of word sense information."
mihalcea-2002-bootstrapping,Bootstrapping Large Sense Tagged Corpora,2002,11,62,1,1,1124,rada mihalcea,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The performance of Word Sense Disambiguation systems largely depends on the availability of sense tagged corpora. Since the semantic annotations are usually done by humans, the size of such corpora is limited to a handful of tagged texts. This paper proposes a generation algorithm that may be used to automatically create large sense tagged corpora. The approach is evaluated through comparative sense disambiguation experiments performed on data provided during the SENSEVAL-2 English all words and English lexical sample tasks."
C02-1039,Instance Based Learning with Automatic Feature Selection Applied to Word Sense Disambiguation,2002,17,46,1,1,1124,rada mihalcea,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,We describe an algorithm for Word Sense Disambiguation (WSD) that relies on a lazy learner improved with automatic feature selection. The algorithm was implemented in a system that achieves excellent performance on the set of data released during the SENSEVAL-2 competition. We present the results obtained and discuss the performance of various features in the context of supervised learning algorithms for WSD.
S01-1031,Pattern Learning and Active Feature Selection for Word Sense Disambiguation,2001,6,23,1,1,1124,rada mihalcea,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"We present here the main ideas of the algorithm employed in the SMUls and SMUaw systems. These systems have participated in the Senseval-2 competition attaining the best performance for both English all words and English lexical sample tasks. The algorithm has two main components (1) pattern learning from available sense tagged corpora (SemCor) and dictionary definitions (WordNet), and (2) instance based learning with active feature selection, when training data is available for a particular word."
P01-1037,The Role of Lexico-Semantic Feedback in Open-Domain Textual Question-Answering,2001,14,72,4,0.357143,13772,sanda harabagiu,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents an open-domain textual Question-Answering system that uses several feedback loops to enhance its performance. These feedback loops combine in a new way statistical results with syntactic, semantic or pragmatic information derived from texts and lexical databases. The paper presents the contribution of each feedback loop to the overall performance of 76% human-assessed precise answers."
W00-1104,Semantic Indexing using {W}ord{N}et Senses,2000,19,128,1,1,1124,rada mihalcea,{ACL}-2000 Workshop on Recent Advances in Natural Language Processing and Information Retrieval,0,"We describe in this paper a boolean Information Retrieval system that adds word semantics to the classic word based indexing. Two of the main tasks of our system, namely the indexing and retrieval components, are using a combined word-based and sense-based approach. The key to our system is a methodology for building semantic representations of open text, at word and collocation level. This new technique, called semantic indexing, shows improved effectiveness over the classic word based indexing techniques."
P00-1071,The Structure and Performance of an Open-Domain Question Answering System,2000,5,152,4,0.517352,16607,dan moldovan,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents the architecture, operation and results obtained with the LASSO Question Answering system developed in the Natural Language Processing Laboratory at SMU. To find answers, the system relies on a combination of syntactic and semantic techniques. The search for the answer is based on a novel form of indexing called paragraph indexing. A score of 55.5% for short answers and 64.5% for long answers was achieved at the TREC-8 competition."
P99-1020,A Method for Word Sense Disambiguation of Unrestricted Text,1999,13,137,1,1,1124,rada mihalcea,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"Selecting the most appropriate sense for an ambiguous word in a sentence is a central problem in Natural Language Processing. In this paper, we present a method that attempts to disambiguate all the nouns, verbs, adverbs and adjectives in a text, using the senses provided in WordNet. The senses are ranked using two sources of information: (1) the Internet for gathering statistics for word-word cooccurrences and (2) WordNet for measuring the semantic density for a pair of words. We report an average accuracy of 80% for the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered."
W98-0703,Word Sense Disambiguation based on Semantic Density,1998,13,33,1,1,1124,rada mihalcea,Usage of {W}ord{N}et in Natural Language Processing Systems,0,None
