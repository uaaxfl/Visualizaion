P17-1195,Semantic Parsing of Pre-university Math Problems,2017,17,9,1,1,32672,takuya matsuzaki,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,We have been developing an end-to-end math problem solving system that accepts natural language input. The current paper focuses on how we analyze the problem sentences to produce logical forms. We chose a hybrid approach combining a shallow syntactic analyzer and a manually-developed lexicalized grammar. A feature of the grammar is that it is extensively typed on the basis of a formal ontology for pre-university math. These types are helpful in semantic disambiguation inside and across sentences. Experimental results show that the hybrid system produces a well-formed logical form with 88{\%} precision and 56{\%} recall.
I17-2063,Coreference Resolution on Math Problem Text in {J}apanese,2017,6,0,2,0,13281,takumi ito,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,This paper describes a coreference resolution system for math problem text. Case frame dictionaries and a math taxonomy are utilized for supplying domain knowledge. The system deals with various anaphoric phenomena beyond well-studied entity coreferences.
I17-1097,"Automated Historical Fact-Checking by Passage Retrieval, Word Statistics, and Virtual Question-Answering",2017,17,4,5,0,32923,mio kobayashi,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"This paper presents a hybrid approach to the verification of statements about historical facts. The test data was collected from the world history examinations in a standardized achievement test for high school students. The data includes various kinds of false statements that were carefully written so as to deceive the students while they can be disproven on the basis of the teaching materials. Our system predicts the truth or falsehood of a statement based on text search, word cooccurrence statistics, factoid-style question answering, and temporal relation recognition. These features contribute to the judgement complementarily and achieved the state-of-the-art accuracy."
L16-1440,Translation Errors and Incomprehensibility: a Case Study using Machine-Translated Second Language Proficiency Tests,2016,0,0,1,1,32672,takuya matsuzaki,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper reports on an experiment where 795 human participants answered to the questions taken from second language proficiency tests that were translated to their native language. The output of three machine translation systems and two different human translations were used as the test material. We classified the translation errors in the questions according to an error taxonomy and analyzed the participants{'} response on the basis of the type and frequency of the translation errors. Through the analysis, we identified several types of errors that deteriorated most the accuracy of the participants{'} answers, their confidence on the answers, and their overall evaluation of the translation quality."
P15-2024,Evaluating Machine Translation Systems with Second Language Proficiency Tests,2015,10,2,1,1,32672,takuya matsuzaki,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"A lightweight, human-in-the-loop evaluation scheme for machine translation (MT) systems is proposed. It extrinsically evaluates MT systems using human subjectsxe2x80x99 scores on second language ability test problems that are machine-translated to the subjectsxe2x80x99 native language. A largescale experiment involving 320 subjects revealed that the context-unawareness of the current MT systems severely damages human performance when solving the test problems, while one of the evaluated MT systems performed as good as a human translation produced in a context-unaware condition. An analysis of the experimental results showed that the extrinsic evaluation captured a different dimension of translation quality than that captured by manual and automatic intrinsic evaluation."
W14-2414,Efficient Logical Inference for Semantic Processing,2014,6,1,3,0,20138,ran tian,Proceedings of the {ACL} 2014 Workshop on Semantic Parsing,0,"Dependency-based Compositional Semantics (DCS) provides a precise and expressive way to model semantics of natural language queries on relational databases, by simple dependency-like trees. Recently abstract denotation is proposed to enable generic logical inference on DCS. In this paper, we discuss some other possibilities to equip DCS with logical inference, and we discuss further on how logical inference can help textual entailment recognition, or other semantic precessing tasks."
P14-1008,Logical Inference on Dependency-based Compositional Semantics,2014,50,25,3,0,20138,ran tian,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics. In this paper, we equip the DCS framework with logical inference, by defining abstract denotations as an abstraction of the computing process of denotations in original DCS. An inference engine is built to achieve inference on abstract denotations. Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation. Experiments on FraCaS and PASCAL RTE datasets show promising results."
W13-4403,Deep Context-Free Grammar for {C}hinese with Broad-Coverage,2013,10,0,4,1,40670,xiangli wang,Proceedings of the Seventh {SIGHAN} Workshop on {C}hinese Language Processing,0,"The accuracy of Chinese parsers trained on Penn Chinese Treebank is evidently lower than that of the English parsers trained on Penn Treebank. It is plausible that the essential reason is the lack of surface syntactic constraints in Chinese. In this paper, we present evidences to show that strict deep syntactic constraints exist in Chinese sentences and such constraints cannot be effectively described with context-free phrase structure rules as in the Penn Chinese Treebank annotation; we show that such constraints may be described precisely by the idea of Sentence Structure Grammar; we introduce how to develop a broad-coverage rule-based grammar for Chinese based on this idea; we evaluated the grammar and the evaluation results show that the coverage of the current grammar is 94.2%."
P13-1103,Integrating Multiple Dependency Corpora for Inducing Wide-coverage {J}apanese {CCG} Resources,2013,0,6,2,0,29831,sumire uematsu,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
I13-1009,"The Complexity of Math Problems {--} Linguistic, or Computational?",2013,18,8,1,1,32672,takuya matsuzaki,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We present a simple, logic-based architecture for solving math problems written in natural language. A problem is firstly translated to a logical form. It is then rewritten into the input language of a solver algorithm and finally the solver finds an answer. Such a clean decomposition of the task however does not come for free. First, despite its formality, math text still exploits the flexibility of natural language to convey its complex logical content succinctly. We propose a mechanism to fill the gap between the simple form and the complex meaning while adhering to the principle of compositionality. Second, since the input to the solver is derived by strictly following the text, it may require far more computation than those derived by a human, and may go beyond the capability of the current solvers. Empirical study on Japanese university entrance examination problems showed positive results indicating the viability of the approach, which opens up a way towards a true end-to-end problem solving system through the synthesis of the advances in linguistics, NLP, and computer math."
P12-3022,{A}kamon: An Open Source Toolkit for Tree/Forest-Based Statistical Machine Translation,2012,34,2,2,0.666667,6319,xianchao wu,Proceedings of the {ACL} 2012 System Demonstrations,0,"We describe Akamon, an open source toolkit for tree and forest-based statistical machine translation (Liu et al., 2006; Mi et al., 2008; Mi and Huang, 2008). Akamon implements all of the algorithms required for tree/forest-to-string decoding using tree-to-string translation rules: multiple-thread forest-based decoding, n-gram language model integration, beam- and cube-pruning, k-best hypotheses extraction, and minimum error rate training. In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al., 2004) and HPSG trees/forests (Wu et al., 2010)."
P12-1110,"Incremental Joint Approach to Word Segmentation, {POS} Tagging, and Dependency Parsing in {C}hinese",2012,18,54,2,1,42725,jun hatori,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We propose the first joint model for word segmentation, POS tagging, and dependency parsing for Chinese. Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models. We also describe our method to align comparable states in the beam, and how we can combine features of different characteristics in our incremental framework. In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing. We also perform comparison experiments with the partially joint models."
E12-1044,Coordination Structure Analysis using Dual Decomposition,2012,13,10,2,0,43593,atsushi hanamoto,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Coordination disambiguation remains a difficult sub-problem in parsing despite the frequency and importance of coordination structures. We propose a method for disambiguating coordination structures. In this method, dual decomposition is used as a framework to take advantage of both HPSG parsing and coordinate structure analysis with alignment-based local features. We evaluate the performance of the proposed method on the Genia corpus and the Wall Street Journal portion of the Penn Treebank. Results show it increases the percentage of sentences in which coordination structures are detected correctly, compared with each of the two algorithms alone."
W11-2907,Analysis of the Difficulties in {C}hinese Deep Parsing,2011,33,9,3,1,44132,kun yu,Proceedings of the 12th International Conference on Parsing Technologies,0,"This paper discusses the difficulties in Chinese deep parsing, by comparing the accuracy of a Chinese HPSG parser to the accuracy of an English HPSG parser and the commonly used Chinese syntactic parsers. Analysis reveals that deep parsing for Chinese is more challenging than for English, due to the shortage of syntactic constraints of Chinese verbs, the widespread pro-drop, and the large distribution of ambiguous constructions. Moreover, the inherent ambiguities caused by verbal co-ordination and relative clauses make semantic analysis of Chinese more difficult than the syntactic analysis of Chinese."
W11-1203,Learning the Optimal Use of Dependency-parsing Information for Finding Translations with Comparable Corpora,2011,15,4,2,0,37700,daniel andrade,Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,0,"Using comparable corpora to find new word translations is a promising approach for extending bilingual dictionaries (semi-) automatically. The basic idea is based on the assumption that similar words have similar contexts across languages. The context of a word is often summarized by using the bag-of-words in the sentence, or by using the words which are in a certain dependency position, e.g. the predecessors and successors. These different context positions are then combined into one context vector and compared across languages. However, previous research makes the (implicit) assumption that these different context positions should be weighted as equally important. Furthermore, only the same context positions are compared with each other, for example the successor position in Spanish is compared with the successor position in English. However, this is not necessarily always appropriate for languages like Japanese and English. To overcome these limitations, we suggest to perform a linear transformation of the context vectors, which is defined by a matrix. We define the optimal transformation matrix by using a Bayesian probabilistic model, and show that it is feasible to find an approximate solution using Markov chain Monte Carlo methods. Our experiments demonstrate that our proposed method constantly improves translation accuracy."
W11-0407,A Collaborative Annotation between Human Annotators and a Statistical Parser,2011,11,0,3,0,44409,shunya iwasawa,Proceedings of the 5th Linguistic Annotation Workshop,0,"We describe a new interactive annotation scheme between a human annotator who carries out simplified annotations on CFG trees, and a statistical parser that converts the human annotations automatically into a richly annotated HPSG treebank. In order to check the proposed scheme's effectiveness, we performed automatic pseudo-annotations that emulate the system's idealized behavior and measured the performance of the parser trained on those annotations. In addition, we implemented a prototype system and conducted manual annotation experiments on a small test set."
P11-1003,Effective Use of Function Words for Rule Generalization in Forest-Based Translation,2011,26,7,2,0.731707,6319,xianchao wu,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"In the present paper, we propose the effective usage of function words to generate generalized translation rules for forest-based translation. Given aligned forest-string pairs, we extract composed tree-to-string translation rules that account for multiple interpretations of both aligned and unaligned target function words. In order to constrain the exhaustive attachments of function words, we limit to bind them to the nearby syntactic chunks yielded by a target dependency parser. Therefore, the proposed approach can not only capture source-tree-to-target-chunk correspondences but can also use forest structures that compactly encode an exponential number of parse trees to properly generate target function words during decoding. Extensive experiments involving large-scale English-to-Japanese translation revealed a significant improvement of 1.8 points in BLEU score, as compared with a strong forest-to-string baseline system."
I11-1084,Exploring Difficulties in Parsing Imperatives and Questions,2011,19,2,2,0,38278,tadayoshi hara,Proceedings of 5th International Joint Conference on Natural Language Processing,0,This paper analyzes the effect of the structural variation of sentences on parsing performance. We examine the performance of both shallow and deep parsers for two sentence constructions: imperatives and questions. We first prepare an annotated corpus for each of these sentence constructions by extracting sentences from a fiction domain that cover various types of imperatives and questions. The target parsers are then adapted to each of the obtained corpora as well as the existing query-focused corpus. Analysis of the experimental results reveals that the current mainstream parsing technologies and adaptation techniques cannot cope with different sentence constructions even with much in-domain data.
I11-1136,Incremental Joint {POS} Tagging and Dependency Parsing in {C}hinese,2011,21,60,2,1,42725,jun hatori,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We address the problem of joint part-of-speech (POS) tagging and dependency parsing in Chinese. In Chinese, some POS tags are often hard to disambiguate without considering longrange syntactic information. Also, the traditional pipeline approach to POS tagging and dependency parsing may suffer from the problem of error propagation. In this paper, we propose the first incremental approach to the task of joint POS tagging and dependency parsing, which is built upon a shift-reduce parsing framework with dynamic programming. Although the incremental approach encounters difficulties with underspecified POS tags of look-ahead words, we overcome this issue by introducing so-called delayed features. Our joint approach achieved substantial improvements over the pipeline and baseline systems in both POS tagging and dependency parsing task, achieving the new state-of-the-art performance on this joint task."
W10-1816,The Deep Re-Annotation in a {C}hinese Scientific Treebank,2010,13,0,4,1,44132,kun yu,Proceedings of the Fourth Linguistic Annotation Workshop,0,"In this paper, we introduce our recent work on re-annotating the deep information, which includes both the grammatical functional tags and the traces, in a Chinese scientific treebank. The issues with regard to re-annotation and its corresponding solutions are discussed. Furthermore, the process of the re-annotation work is described."
P10-1034,Fine-Grained Tree-to-String Translation Rule Extraction,2010,28,12,2,1,6319,xianchao wu,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"Tree-to-string translation rules are widely used in linguistically syntax-based statistical machine translation systems. In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules. A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence. We extract fine-grained rules from aligned HPSG tree/forest-string pairs and use them in our tree-to-string and string-to-tree systems. Extensive experiments on large-scale bidirectional Japanese-English translations testified the effectiveness of our approach."
N10-1090,A Simple Approach for {HPSG} Supertagging Using Dependency Information,2010,16,5,2,1,45809,yaozhong zhang,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"In a supertagging task, sequence labeling models are commonly used. But their limited ability to model long-distance information presents a bottleneck to make further improvements. In this paper, we modeled this long-distance information in dependency formalism and integrated it into the process of HPSG supertagging. The experiments showed that the dependency information is very informative for supertag disambiguation. We also evaluated the improved supertagger in the HPSG parser."
C10-2162,Semi-automatically Developing {C}hinese {HPSG} Grammar from the {P}enn {C}hinese Treebank for Deep Parsing,2010,29,16,4,1,44132,kun yu,Coling 2010: Posters,0,"In this paper, we introduce our recent work on Chinese HPSG grammar development through treebank conversion. By manually defining grammatical constraints and annotation rules, we convert the bracketing trees in the Penn Chinese Treebank (CTB) to be an HPSG treebank. Then, a large-scale lexicon is automatically extracted from the HPSG treebank. Experimental results on the CTB 6.0 show that a HPSG lexicon was successfully extracted with 97.24% accuracy; furthermore, the obtained lexicon achieved 98.51% lexical coverage and 76.51% sentential coverage for unseen text, which are comparable to the state-of-the-art works for English."
C10-1144,Forest-guided Supertagger Training,2010,18,3,2,1,45809,yaozhong zhang,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Supertagging is an important technique for deep syntactic analysis. A supertagger is usually trained independently of the parser using a sequence labeling method. This presents an inconsistent training objective between the supertagger and the parser. In this paper, we propose a forest-guided supertagger training method to alleviate this problem by incorporating global grammar constraints into the supertagging process using a CFG-filter. It also provides an approach to make the supertagger and the parser more tightly integrated. The experiment shows that using the forest-guided trained supertagger, the parser got an absolute 0.68% improvement from baseline in F-score for predicate-argument relation recognition accuracy and achieved a competitive result of 89.31% with a faster parsing speed, compared to a state-of-the-art HPSG parser."
Y09-2048,Design of {C}hinese {HPSG} Framework for Data-Driven Parsing,2009,15,7,4,1,40670,xiangli wang,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 2",0,"Data-driven parsing has been a main method for analyzing natural languages. We aim at exploring a data-driven Chinese parser, by basing it on Head-driven Phrase Structure Grammar (HPSG). Unlike for English, there is still no available Chinese HPSG framework. As the first step of our work, we design a Chinese HPSG framework, which can be used as the basis for a practical parser. In this paper, 1) we present a Chinese syntactic structure system and 2) we design a primary Chinese HPSG framework."
W09-3832,{HPSG} Supertagging: A Sequence Labeling View,2009,12,8,2,1,45809,yaozhong zhang,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"Supertagging is a widely used speed-up technique for deep parsing. In another aspect, supertagging has been exploited in other NLP tasks than parsing for utilizing the rich syntactic information given by the supertags. However, the performance of supertagger is still a bottleneck for such applications. In this paper, we investigated the relationship between supertagging and parsing, not just to speed up the deep parser; We started from a sequence labeling view of HPSG supertagging, examining how well a supertagger can do when separated from parsing. Comparison of two types of supertagging model, point-wise model and sequential model, showed that the former model works competitively well despite its simplicity, which indicates the true dependency among supertag assignments is far more complex than the crude first-order approximation made in the sequential model. We then analyzed the limitation of separated supertagging by using a CFG-filter. The results showed that big gains could be acquired by resorting to a light-weight parser."
N09-1007,A Discriminative Latent Variable {C}hinese Segmenter with Hybrid Word/Character Information,2009,21,39,3,0,3749,xu sun,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Conventional approaches to Chinese word segmentation treat the problem as a character-based tagging task. Recently, semi-Markov models have been applied to the problem, incorporating features based on complete words. In this paper, we propose an alternative, a latent variable model, which uses hybrid information based on both word sequences and character sequences. We argue that the use of latent variables can help capture long range dependencies and improve the recall on segmenting long words, e.g., named-entities. Experimental results show that this is indeed the case. With this improvement, evaluations on the data of the second SIGHAN CWS bakeoff show that our system is competitive with the best ones in the literature."
E09-1069,Deterministic Shift-Reduce Parsing for Unification-Based Grammars by Using Default Unification,2009,30,6,2,1,3213,takashi ninomiya,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"Many parsing techniques including parameter estimation assume the use of a packed parse forest for efficient and accurate parsing. However, they have several inherent problems deriving from the restriction of locality in the packed parse forest. Deterministic parsing is one of solutions that can achieve simple and fast parsing without the mechanisms of the packed parse forest by accurately choosing search paths. We propose (i) deterministic shift-reduce parsing for unification-based grammars, and (ii) best-first shift-reduce parsing with beam thresholding for unification-based grammars. Deterministic parsing cannot simply be applied to unification-based grammar parsing, which often fails because of its hard constraints. Therefore, it is developed by using default unification, which almost always succeeds in unification by overwriting inconsistent constraints in grammars."
2009.iwslt-evaluation.15,The {UOT} system,2009,-1,-1,2,1,6319,xianchao wu,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We present the UOT Machine Translation System that was used in the IWSLT-09 evaluation campaign. This year, we participated in the BTEC track for Chinese-to-English translation. Our system is based on a string-to-tree framework. To integrate deep syntactic information, we propose the use of parse trees and semantic dependencies on English sentences described respectively by Head-driven Phrase Structure Grammar and Predicate-Argument Structures. We report the results of our system on both the development and test sets."
P08-1006,Task-oriented Evaluation of Syntactic Parsers and Their Representations,2008,41,71,4,0.0982409,5928,yusuke miyao,Proceedings of ACL-08: HLT,1,"This paper presents a comparative evaluation of several state-of-the-art English parsers based on different frameworks. Our approach is to measure the impact of each parser when it is used as a component of an information extraction system that performs protein-protein interaction (PPI) identification in biomedical papers. We evaluate eight parsers (based on dependency parsing, phrase structure parsing, or deep parsing) using five different parse representations. We run a PPI system with several combinations of parser and parse representation, and examine their impact on PPI identification accuracy. Our experiments show that the levels of accuracy obtained with these different parsers are similar, but that accuracy improvements vary when the parsers are retrained with domain-specific data."
C08-1069,Comparative Parser Performance Analysis across Grammar Frameworks through Automatic Tree Conversion using Synchronous Grammars,2008,17,15,1,1,32672,takuya matsuzaki,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"This paper presents a methodology for the comparative performance analysis of the parsers developed for different grammar frameworks. For such a comparison, we need a common representation format of the parsing results since the representation of the parsing results depends on the grammar frameworks; hence they are not directly comparable to each other. We first convert the parsing result to a shallow CFG analysis by using an automatic tree converter based on synchronous grammars. The use of such a shallow representation as a common format has the advantage of reduced noise introduced by the conversion in comparison with the noise produced by the conversion to deeper representations. We compared an HPSG parser with several CFG parsers in our experiment and found that meaningful differences among the parsers' performance can still be observed by such a shallow representation."
W07-2208,A log-linear model with an n-gram reference distribution for accurate {HPSG} parsing,2007,32,22,2,1,3213,takashi ninomiya,Proceedings of the Tenth International Conference on Parsing Technologies,0,"This paper describes a log-linear model with an n-gram reference distribution for accurate probabilistic HPSG parsing. In the model, the n-gram reference distribution is simply defined as the product of the probabilities of selecting lexical entries, which are provided by the discriminative method with machine learning features of word and POS n-gram as defined in the CCG/HPSG/CDG supertagging. Recently, supertagging becomes well known to drastically improve the parsing accuracy and speed, but supertagging techniques were heuristically introduced, and hence the probabilistic models for parse trees were not well defined. We introduce the supertagging probabilities as a reference distribution for the log-linear model of the probabilistic HPSG. This is the first model which properly incorporates the supertagging probabilities into parse tree's probabilistic model."
W06-1619,Extremely Lexicalized Models for Accurate and Fast {HPSG} Parsing,2006,30,34,2,1,3213,takashi ninomiya,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"This paper describes an extremely lexicalized probabilistic model for fast and accurate HPSG parsing. In this model, the probabilities of parse trees are defined with only the probabilities of selecting lexical entries. The proposed model is very simple, and experiments revealed that the implemented parser runs around four times faster than the previous model and that the proposed model has a high accuracy comparable to that of the previous model for probabilistic HPSG, which is defined over phrase structures. We also developed a hybrid of our probabilistic model and the conventional phrase-structure-based model. The hybrid model is not only significantly faster but also significantly more accurate by two points of precision and recall compared to the previous model."
P05-1010,Probabilistic {CFG} with Latent Annotations,2005,16,236,1,1,32672,takuya matsuzaki,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"This paper defines a generative probabilistic model of parse trees, which we call PCFG-LA. This model is an extension of PCFG in which non-terminal symbols are augmented with latent variables. Fine-grained CFG rules are automatically induced from a parsed corpus by training a PCFG-LA model using an EM-algorithm. Because exact parsing with a PCFG-LA is NP-hard, several approximations are described and empirically compared. In experiments using the Penn WSJ corpus, our automatically trained model gave a performance of 86.6% (F1, sentences xe2x89xa4 40 words), which is comparable to that of an unlexicalized PCFG parser created using extensive manual feature selection."
W03-0416,An efficient clustering algorithm for class-based language models,2003,11,11,1,1,32672,takuya matsuzaki,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"This paper defines a general form for class-based probabilistic language models and proposes an efficient algorithm for clustering based on this. Our evaluation experiments revealed that our method decreased computation time drastically, while retaining accuracy."
