2021.unimplicit-1.7,A Mention-Based System for Revision Requirements Detection,2021,-1,-1,2,0,669,ahmed ruby,Proceedings of the 1st Workshop on Understanding Implicit and Underspecified Language,0,"Exploring aspects of sentential meaning that are implicit or underspecified in context is important for sentence understanding. In this paper, we propose a novel architecture based on mentions for revision requirements detection. The goal is to improve understandability, addressing some types of revisions, especially for the Replaced Pronoun type. We show that our mention-based system can predict replaced pronouns well on the mention-level. However, our combined sentence-level system does not improve on the sentence-level BERT baseline. We also present additional contrastive systems, and show results for each type of edit."
2021.nodalida-main.34,Exploring the Importance of Source Text in Automatic Post-Editing for Context-Aware Machine Translation,2021,-1,-1,2,0,2689,chaojun wang,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"Accurate translation requires document-level information, which is ignored by sentence-level machine translation. Recent work has demonstrated that document-level consistency can be improved with automatic post-editing (APE) using only target-language (TL) information. We study an extended APE model that additionally integrates source context. A human evaluation of fluency and adequacy in English{--}Russian translation reveals that the model with access to source context significantly outperforms monolingual APE in terms of adequacy, an effect largely ignored by automatic evaluation metrics. Our results show that TL-only modelling increases fluency without improving adequacy, demonstrating the need for conditioning on source text for automatic post-editing. They also highlight blind spots in automatic methods for targeted evaluation and demonstrate the need for human assessment to evaluate document-level translation quality reliably."
2020.wmt-1.58,The {U}niversity of {E}dinburgh-{U}ppsala {U}niversity{'}s Submission to the {WMT} 2020 Chat Translation Task,2020,-1,-1,2,0,8806,nikita moghe,Proceedings of the Fifth Conference on Machine Translation,0,"This paper describes the joint submission of the University of Edinburgh and Uppsala University to the WMT{'}20 chat translation task for both language directions (English-German). We use existing state-of-the-art machine translation models trained on news data and fine-tune them on in-domain and pseudo-in-domain web crawled data. Our baseline systems are transformer-big models that are pre-trained on the WMT{'}19 News Translation task and fine-tuned on pseudo-in-domain web crawled data and in-domain task data. We also experiment with (i) adaptation using speaker and domain tags and (ii) using different types and amounts of preceding context. We observe that contrarily to expectations, exploiting context degrades the results (and on analysis the data is not highly contextual). However using domain tags does improve scores according to the automatic evaluation. Our final primary systems use domain tags and are ensembles of 4 models, with noisy channel reranking of outputs. Our en-de system was ranked second in the shared task while our de-en system outperformed all the other systems."
2020.lrec-1.12,Exploiting Cross-Lingual Hints to Discover Event Pronouns,2020,-1,-1,2,0.734413,4241,sharid loaiciga,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Non-nominal co-reference is much less studied than nominal coreference, partly because of the lack of annotated corpora. We explore the possibility to exploit parallel multilingual corpora as a means of cheap supervision for the classification of three different readings of the English pronoun {`}it{'}: entity, event or pleonastic, from their translation in several languages. We found that the {`}event{'} reading is not very frequent, but can be easily predicted provided that the construction used to translate the {`}it{'} example is a pronoun as well. These cases, nevertheless, are not enough to generalize to other types of non-nominal reference."
2020.iwdp-1.10,Referential Cohesion A Challenge for Machine Translation Evaluation,2020,-1,-1,1,1,670,christian hardmeier,Proceedings of the Second International Workshop of Discourse Processing,0,"Connected texts are characterised by the presence of linguistic elements relating to shared referents throughout the text. These elements together form a structure that lends cohesion to the text. The realisation of those cohesive structures is subject to different constraints and varying preferences in different languages. We regularly observe mismatches of cohesive structures across languages in parallel texts. This can be a result of either a divergence of language-internal constraints or of effects of the translation process. As fully automatic high-quality MT is starting to look achievable, the question arises how cohesive elements should be handled in MT evaluation, since the common assumption of 1:1 correspondence between referring expressions is a poor match for what we find in corpus data. Focusing on the translation of pronouns, I discuss different approaches to evaluating a particular type of cohesive elements in MT output and the trade-offs they make between evaluation cost, validity, specificity and coverage. I suggest that a meaningful evaluation of cohesive structures in translation is difficult to achieve simply by appealing to the intuition of human annotators, but requires a more structured approach that forces us to make up our minds about the standards we expect the translation output to adhere to."
2020.crac-1.15,Coreference Strategies in {E}nglish-{G}erman Translation,2020,-1,-1,3,0.418589,2628,ekaterina lapshinovakoltunski,"Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference",0,"We present a study focusing on variation of coreferential devices in English original TED talks and news texts and their German translations. Using exploratory techniques we contemplate a diverse set of coreference devices as features which we assume indicate language-specific and register-based variation as well as potential translation strategies. Our findings reflect differences on both dimensions with stronger variation along the lines of register than between languages. By exposing interactions between text type and cross-linguistic variation, they can also inform multilingual NLP applications, especially machine translation."
W19-3801,Gendered Ambiguous Pronoun ({GAP}) Shared Task at the Gender Bias in {NLP} Workshop 2019,2019,-1,-1,3,0,9606,kellie webster,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"The 1st ACL workshop on Gender Bias in Natural Language Processing included a shared task on gendered ambiguous pronoun (GAP) resolution. This task was based on the coreference challenge defined in Webster et al. (2018), designed to benchmark the ability of systems to resolve pronouns in real-world contexts in a gender-fair way. 263 teams competed via a Kaggle competition, with the winning system achieving logloss of 0.13667 and near gender parity. We review the approaches of eleven systems with accepted description papers, noting their effective use of BERT (Devlin et al., 2018), both via fine-tuning and for feature extraction, as well as ensembling."
W19-2803,Entity Decisions in Neural Language Modelling: Approaches and Problems,2019,0,0,2,0,12071,jenny kunz,"Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference",0,"We explore different approaches to explicit entity modelling in language models (LM). We independently replicate two existing models in a controlled setup, introduce a simplified variant of one of the models and analyze their performance in direct comparison. Our results suggest that today{'}s models are limited as several stochastic variables make learning difficult. We show that the most challenging point in the systems is the decision if the next token is an entity token. The low precision and recall for this variable will lead to severe cascading errors. Our own simplified approach dispenses with the need for latent variables and improves the performance in the entity yes/no decision. A standard well-tuned baseline RNN-LM with a larger number of hidden units outperforms all entity-enabled LMs in terms of perplexity."
W19-2805,Cross-lingual Incongruences in the Annotation of Coreference,2019,0,1,3,0.526486,2628,ekaterina lapshinovakoltunski,"Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference",0,"In the present paper, we deal with incongruences in English-German multilingual coreference annotation and present automated methods to discover them. More specifically, we automatically detect full coreference chains in parallel texts and analyse discrepancies in their annotations. In doing so, we wish to find out whether the discrepancies rather derive from language typological constraints, from the translation or the actual annotation process. The results of our study contribute to the referential analysis of similarities and differences across languages and support evaluation of cross-lingual coreference annotation. They are also useful for cross-lingual coreference resolution systems and contrastive linguistic studies."
W18-6435,A Pronoun Test Suite Evaluation of the {E}nglish{--}{G}erman {MT} Systems at {WMT} 2018,2018,0,5,2,1,5894,liane guillou,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,"We evaluate the output of 16 English-to-German MT systems with respect to the translation of pronouns in the context of the WMT 2018 competition. We work with a test suite specifically designed to assess system quality in various fine-grained categories known to be problematic. The main evaluation scores come from a semi-automatic process, combining automatic reference matching with extensive manual annotation of uncertain cases. We find that current NMT systems are good at translating pronouns with intra-sentential reference, but the inter-sentential cases remain difficult. NMT systems are also good at the translation of event pronouns, unlike systems from the phrase-based SMT paradigm. No single system performs best at translating all types of anaphoric pronouns, suggesting unexplained random effects influencing the translation of pronouns with NMT."
W18-6305,Discourse-Related Language Contrasts in {E}nglish-{C}roatian Human and Machine Translation,2018,-1,-1,2,0,27748,margita vsovstaric,Proceedings of the Third Conference on Machine Translation: Research Papers,0,"We present an analysis of a number of coreference phenomena in English-Croatian human and machine translations. The aim is to shed light on the differences in the way these structurally different languages make use of discourse information and provide insights for discourse-aware machine translation system development. The phenomena are automatically identified in parallel data using annotation produced by parsers and word alignment tools, enabling us to pinpoint patterns of interest in both languages. We make the analysis more fine-grained by including three corpora pertaining to three different registers. In a second step, we create a test set with the challenging linguistic constructions and use it to evaluate the performance of three MT systems. We show that both SMT and NMT systems struggle with handling these discourse phenomena, even though NMT tends to perform somewhat better than SMT. By providing an overview of patterns frequently occurring in actual language use, as well as by pointing out the weaknesses of current MT systems that commonly mistranslate them, we hope to contribute to the effort of resolving the issue of discourse phenomena in MT applications."
W18-2406,"Forms of Anaphoric Reference to Organisational Named Entities: Hoping to widen appeal, they diversified",2018,0,1,1,1,670,christian hardmeier,Proceedings of the Seventh Named Entities Workshop,0,"Proper names of organisations are a special case of collective nouns. Their meaning can be conceptualised as a collective unit or as a plurality of persons, allowing for different morphological marking of coreferent anaphoric pronouns. This paper explores the variability of references to organisation names with 1) a corpus analysis and 2) two crowd-sourced story continuation experiments. The first shows that the preference for singular vs. plural conceptualisation is dependent on the level of formality of a text. In the second, we observe a strong preference for the plural they otherwise typical of informal speech. Using edited corpus data instead of constructed sentences as stimuli reduces this preference."
W18-0711,Event versus entity co-reference: Effects of context and form of referring expression,2018,-1,-1,4,0.852831,4241,sharid loaiciga,"Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference",0,"Anaphora resolution systems require both an enumeration of possible candidate antecedents and an identification process of the antecedent. This paper focuses on (i) the impact of the form of referring expression on entity-vs-event preferences and (ii) how properties of the passage interact with referential form. Two crowd-sourced story-continuation experiments were conducted, using constructed and naturally-occurring passages, to see how participants interpret \textit{It} and \textit{This} pronouns following a context sentence that makes available event and entity referents. Our participants show a strong, but not categorical, bias to use \textit{This} to refer to events and \textit{It} to refer to entities. However, these preferences vary with passage characteristics such as verb class (a proxy in our constructed examples for the number of explicit and implicit entities) and more subtle author intentions regarding subsequent re-mention (the original event-vs-entity re-mention of our corpus items)."
Q18-1030,Universal Word Segmentation: Implementation and Interpretation,2018,5,4,2,1,28950,yan shao,Transactions of the Association for Computational Linguistics,0,"Word segmentation is a low-level NLP task that is non-trivial for a considerable number of languages. In this paper, we present a sequence tagging framework and apply it to word segmentation for a wide range of languages with different writing systems and typological characteristics. Additionally, we investigate the correlations between various typological factors and word segmentation accuracy. The experimental results indicate that segmentation accuracy is positively related to word boundary markers and negatively to the number of unique non-segmental terms. Based on the analysis, we design a small set of language-specific settings and extensively evaluate the segmentation system on the Universal Dependencies datasets. Our model obtains state-of-the-art accuracies on all the UD languages. It performs substantially better on languages that are non-trivial to segment, such as Chinese, Japanese, Arabic and Hebrew, when compared to previous work."
L18-1065,{P}ar{C}or{F}ull: a Parallel Corpus Annotated with Full Coreference,2018,0,4,2,0.807115,2628,ekaterina lapshinovakoltunski,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"ParCorFull is a parallel corpus annotated with full coreference chains that has been created to address an important problem that machine translation and other multilingual natural language processing (NLP) technologies face -- translation of coreference across languages. Our corpus contains parallel texts for the language pair English-German, two major European languages. Despite being typologically very close, these languages still have systemic differences in the realisation of coreference, and thus pose problems for multilingual coreference resolution and machine translation. Our parallel corpus covers the genres of planned speech (public lectures) and newswire. It is richly annotated for coreference in both languages, including annotation of both nominal coreference and reference to antecedents expressed as clauses, sentences and verb phrases. This resource supports research in the areas of natural language processing, contrastive linguistics and translation studies on the mechanisms involved in coreference translation in order to develop a better understanding of the phenomenon."
D18-1334,Getting Gender Right in Neural Machine Translation,2018,22,18,2,0,5078,eva vanmassenhove,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly (Sapir, 1921; Slobin, 1996). One such difference is related to the way gender is expressed in a language. Saying {``}I am happy{''} in English, does not encode any additional knowledge of the speaker that uttered the sentence. However, many other languages do have grammatical gender systems and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, French, the inherent gender information needs to be retained/recovered. The same sentence would become either {``}Je suis heureux{''}, for a male speaker or {``}Je suis heureuse{''} for a female one. Apart from morphological agreement, demographic factors (gender, age, etc.) also influence our use of language in terms of word choices or syntactic constructions (Tannen, 1991; Pennebaker et al., 2003). We integrate gender information into NMT systems. Our contribution is two-fold: (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs."
D18-1513,Automatic Reference-Based Evaluation of Pronoun Translation Misses the Point,2018,0,6,2,1,5894,liane guillou,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We compare the performance of the APT and AutoPRF metrics for pronoun translation against a manually annotated dataset comprising human judgements as to the correctness of translations of the PROTEST test suite. Although there is some correlation with the human judgements, a range of issues limit the performance of the automated metrics. Instead, we recommend the use of semi-automatic metrics and test suites in place of fully automatic metrics."
W17-4801,Findings of the 2017 {D}isco{MT} Shared Task on Cross-lingual Pronoun Prediction,2017,0,3,4,0.852831,4241,sharid loaiciga,Proceedings of the Third Workshop on Discourse in Machine Translation,0,"We describe the design, the setup, and the evaluation results of the DiscoMT 2017 shared task on cross-lingual pronoun prediction. The task asked participants to predict a target-language pronoun given a source-language pronoun in the context of a sentence. We further provided a lemmatized target-language human-authored translation of the source sentence, and automatic word alignments between the source sentence words and the target-language lemmata. The aim of the task was to predict, for each target-language pronoun placeholder, the word that should replace it from a small, closed set of classes, using any type of information that can be extracted from the entire document. We offered four subtasks, each for a different language pair and translation direction: English-to-French, English-to-German, German-to-English, and Spanish-to-English. Five teams participated in the shared task, making submissions for all language pairs. The evaluation results show that most participating teams outperformed two strong n-gram-based language model-based baseline systems by a sizable margin."
W17-4807,Predicting Pronouns with a Convolutional Network and an N-gram Model,2017,0,1,1,1,670,christian hardmeier,Proceedings of the Third Workshop on Discourse in Machine Translation,0,This paper describes the UU-Hardmeier system submitted to the DiscoMT 2017 shared task on cross-lingual pronoun prediction. The system is an ensemble of convolutional neural networks combined with a source-aware n-gram language model.
W17-4810,Discovery of Discourse-Related Language Contrasts through Alignment Discrepancies in {E}nglish-{G}erman Translation,2017,0,2,2,0.807115,2628,ekaterina lapshinovakoltunski,Proceedings of the Third Workshop on Discourse in Machine Translation,0,"In this paper, we analyse alignment discrepancies for discourse structures in English-German parallel data {--} sentence pairs, in which discourse structures in target or source texts have no alignment in the corresponding parallel sentences. The discourse-related structures are designed in form of linguistic patterns based on the information delivered by automatic part-of-speech and dependency annotation. In addition to alignment errors (existing structures left unaligned), these alignment discrepancies can be caused by language contrasts or through the phenomena of explicitation and implicitation in the translation process. We propose a new approach including new type of resources for corpus-based language contrast analysis and apply it to study and classify the contrasts found in our English-German parallel corpus. As unaligned discourse structures may also result in the loss of discourse information in the MT training data, we hope to deliver information in support of discourse-aware machine translation (MT)."
I17-2015,Recall is the Proper Evaluation Metric for Word Segmentation,2017,0,1,2,1,28950,yan shao,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We extensively analyse the correlations and drawbacks of conventionally employed evaluation metrics for word segmentation. Unlike in standard information retrieval, precision favours under-splitting systems and therefore can be misleading in word segmentation. Overall, based on both theoretical and experimental analysis, we propose that precision should be excluded from the standard evaluation metrics and that the evaluation score obtained by using only recall is sufficient and better correlated with the performance of word segmentation systems."
I17-1018,Character-based Joint Segmentation and {POS} Tagging for {C}hinese using Bidirectional {RNN}-{CRF},2017,23,2,2,1,28950,yan shao,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"We present a character-based model for joint segmentation and POS tagging for Chinese. The bidirectional RNN-CRF architecture for general sequence tagging is adapted and applied with novel vector representations of Chinese characters that capture rich contextual information and lower-than-character level features. The proposed model is extensively evaluated and compared with a state-of-the-art tagger respectively on CTB5, CTB9 and UD Chinese. The experimental results indicate that our model is accurate and robust across datasets in different sizes, genres and annotation schemes. We obtain state-of-the-art performance on CTB5, achieving 94.38 F1-score for joint segmentation and POS tagging."
D17-1137,What is it? Disambiguating the different readings of the pronoun {`}it{'},2017,16,4,3,0.852831,4241,sharid loaiciga,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we address the problem of predicting one of three functions for the English pronoun {`}it{'}: anaphoric, event reference or pleonastic. This disambiguation is valuable in the context of machine translation and coreference resolution. We present experiments using a MAXENT classifier trained on gold-standard data and self-training experiments of an RNN trained on silver-standard data, annotated using the MAXENT classifier. Lastly, we report on an analysis of the strengths of these two models."
W16-3414,Climbing Mont {BLEU}: The Strange World of Reachable High-{BLEU} Translations,2016,14,3,2,0,29069,aaron smith,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,We present a method for finding oracle BLEU translations in phrase-based statistical machine translation using exact document-level scores. Experiments are presented where the BLEU score of a candi ...
W16-3418,A Graphical Pronoun Analysis Tool for the {PROTEST} Pronoun Evaluation Test Suite,2016,11,1,1,1,670,christian hardmeier,Proceedings of the 19th Annual Conference of the {E}uropean Association for Machine Translation,0,"We present a graphical pronoun analysis tool and a set of guidelines for manual evaluation to be used with the PROTEST pronoun test suite for machine translation (MT). The tool provides a means for researchers to evaluate the performance of their MT systems and browse individual pronoun translations. MT systems may be evaluated automatically by comparing the translation of the test suite pronoun tokens in the MT output with those in the reference translation. Those translations that do not match the reference are referred for manual evaluation, which is supported by the graphical pronoun analysis tool and its accompanying annotation guidelines. By encouraging the manual examination and evaluation of individual pronoun tokens, we hope to understand better how well MT systems perform when translating different categories of pronouns, and gain insights as to where MT systems perform poorly and why."
W16-2345,Findings of the 2016 {WMT} Shared Task on Cross-lingual Pronoun Prediction,2016,20,11,2,1,5894,liane guillou,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"We describe the design, the evaluation setup, and the results of the 2016 WMT shared task on cross-lingual pronoun prediction. This is a classification task in which participants are asked to provi ..."
W16-2350,Pronoun Prediction with Latent Anaphora Resolution,2016,6,3,1,1,670,christian hardmeier,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper describes the UU-Hardmeier submissions to the WMT 2016 shared task on cross-lingual pronoun prediction. Our model is a system combination of two different approaches, one based on a neural network with latent anaphora resolution and the other one on ann-gram model with an additional dependency on the source pronoun. The combination of the two models results in an improvement over each individual system, but it appears that the contribution of the neural network is more likely due to its context modelling capacities than to the anaphora resolution subnetwork."
W16-2351,It-disambiguation and source-aware language models for cross-lingual pronoun prediction,2016,23,2,3,0.731219,4241,sharid loaiciga,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"We present our systems for the WMT 2016 shared task on cross-lingual pronoun prediction. The main contribution is a classifier used to determine whether an instance of the ambiguous English pronoun xe2x80x9citxe2x80x9d functions as an anaphoric, pleonastic or event reference pronoun. For the English-to-French task the classifier is incorporated in an extended baseline, which takes the form of a source-aware language model. An implementation of the sourceaware language model is also provided for each of the remaining language pairs."
L16-1100,{PROTEST}: A Test Suite for Evaluating Pronouns in Machine Translation,2016,0,17,2,1,5894,liane guillou,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present PROTEST, a test suite for the evaluation of pronoun translation by MT systems. The test suite comprises 250 hand-selected pronoun tokens and an automatic evaluation method which compares the translations of pronouns in MT output with those in the reference translation. Pronoun translations that do not match the reference are referred for manual evaluation. PROTEST is designed to support analysis of system performance at the level of individual pronoun groups, rather than to provide a single aggregate measure over all pronouns. We wish to encourage detailed analyses to highlight issues in the handling of specific linguistic mechanisms by MT systems, thereby contributing to a better understanding of those problems involved in translating pronouns. We present two use cases for PROTEST: a) for measuring improvement/degradation of an incremental system change, and b) for comparing the performance of a group of systems whose design may be largely unrelated. Following the latter use case, we demonstrate the application of PROTEST to the evaluation of the systems submitted to the DiscoMT 2015 shared task on pronoun translation."
C16-1088,A Neural Model for Part-of-Speech Tagging in Historical Texts,2016,8,4,1,1,670,christian hardmeier,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Historical texts are challenging for natural language processing because they differ linguistically from modern texts and because of their lack of orthographical and grammatical standardisation. We use a character-level neural network to build a part-of-speech (POS) tagger that can process historical data directly without requiring a separate spelling normalisation stage. Its performance in a Swedish verb identification and a German POS tagging task is similar to that of a two-stage model. We analyse the performance of this tagger and a more traditional baseline system, discuss some of the remaining problems for tagging historical data and suggest how the flexibility of our neural tagger could be exploited to address diachronic divergences in morphology and syntax in early modern Swedish with the help of data from closely related languages."
W15-2501,Pronoun-Focused {MT} and Cross-Lingual Pronoun Prediction: Findings of the 2015 {D}isco{MT} Shared Task on Pronoun Translation,2015,48,33,1,1,670,christian hardmeier,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"We describe the design, the evaluation setup, and the results of the DiscoMT 2015 shared task, which included two subtasks, relevant to both the machine translation (MT) and the discourse communities: (i) pronoun-focused translation, a practical MT task, and (ii) cross-lingual pronoun prediction, a classification task that requires no specific MT expertise and is interesting as a machine learning task in its own right. We focused on the Englishxe2x80x90French language pair, for which MT output is generally of high quality, but has visible issues with pronoun translation due to differences in the pronoun systems of the two languages. Six groups participated in the pronoun-focused translation task and eight groups in the cross-lingual pronoun prediction task."
W15-2508,Part-of-Speech Driven Cross-Lingual Pronoun Prediction with Feed-Forward Neural Networks,2015,12,6,2,0,36929,jimmy callin,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"For some language pairs, pronoun translation is a discourse-driven task which requires information that lies beyond its local context. This motivates the task of predicting the correct pronoun give ..."
W15-2510,A Document-Level {SMT} System with Integrated Pronoun Prediction,2015,16,1,1,1,670,christian hardmeier,Proceedings of the Second Workshop on Discourse in Machine Translation,0,This paper describes one of Uppsala Universityxe2x80x99s submissions to the pronoun-focused machine translation (MT) shared task at DiscoMT 2015. The system is based on phrase-based statistical MT implemen ...
W15-2522,On Statistical Machine Translation and Translation Theory,2015,10,3,1,1,670,christian hardmeier,Proceedings of the Second Workshop on Discourse in Machine Translation,0,"The translation process in statistical machine translation (SMT) is shaped by technical constraints and engineering considerations. SMT explicitly models translation as search for a target-language equivalent of the input text. This perspective on translation had wide currency in mid-20th century translation studies, but has since been superseded by approaches arguing for a more complex relation between source and target text. In this paper, we show how traditional assumptions of translational equivalence are embodied in SMT through the concepts of word alignment and domain and discuss some limitations arising from the word-level/corpus-level dichotomy inherent in these concepts."
Q15-1033,Learning Structural Kernels for Natural Language Processing,2015,44,6,3,0,5907,daniel beck,Transactions of the Association for Computational Linguistics,0,"Structural kernels are a flexible learning paradigm that has been widely used in Natural Language Processing. However, the problem of model selection in kernel-based methods is usually overlooked. Previous approaches mostly rely on setting default values for kernel hyperparameters or using grid search, which is slow and coarse-grained. In contrast, Bayesian methods allow efficient model selection by maximizing the evidence on the training data through gradient-based methods. In this paper we show how to perform this in the context of structural kernels by using Gaussian Processes. Experimental results on tree kernels show that this procedure results in better prediction performance compared to hyperparameter optimization via grid search. The framework proposed in this paper can be adapted to other structures besides trees, e.g., strings and graphs, thereby extending the utility of kernel-based methods."
W14-3312,Anaphora Models and Reordering for Phrase-Based {SMT},2014,28,6,1,1,670,christian hardmeier,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"We describe the Uppsala University systems for WMT14. We look at the integration of a model for translating pronominal anaphora and a syntactic dependency projection model for Englishxe2x80x90French. Furthermore, we investigate post-ordering and tunable POS distortion models for Englishxe2x80x90 German."
guillou-etal-2014-parcor,{P}ar{C}or 1.0: A Parallel Pronoun-Coreference Corpus to Support Statistical {MT},2014,27,22,2,1,5894,liane guillou,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present ParCor, a parallel corpus of texts in which pronoun coreference â reduced coreference in which pronouns are used as referring expressions â has been annotated. The corpus is intended to be used both as a resource from which to learn systematic differences in pronoun use between languages and ultimately for developing and testing informed Statistical Machine Translation systems aimed at addressing the problem of pronoun coreference in translation. At present, the corpus consists of a collection of parallel English-German documents from two different text genres: TED Talks (transcribed planned speech), and EU Bookshop publications (written text). All documents in the corpus have been manually annotated with respect to the type and location of each pronoun and, where relevant, its antecedent. We provide details of the texts that we selected, the guidelines and tools used to support annotation and some corpus statistics. The texts in the corpus have already been translated into many languages, and we plan to expand the corpus into these other languages, as well as other genres, in the future."
W13-5634,Statistical Machine Translation with Readability Constraints,2013,26,15,3,0,634,sara stymne,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,"This paper presents experiments with document-level machine translation with readability constraints. We describe the task of producing simplified translations from a given source with the aim to optimize machine translation for specific target users such as language learners. In our approach, we introduce global features that are known to affect readability into a documentlevel SMT decoding framework. We show that the decoder is capable of incorporating those features and that we can influence the readability of the output as measured by common metrics. This study presents the first attempt of jointly performing machine translation and text simplification, which is demonstrated through the case of translating parliamentary texts from English to Swedish."
W13-3308,Feature Weight Optimization for Discourse-Level {SMT},2013,36,8,2,0,634,sara stymne,Proceedings of the Workshop on Discourse in Machine Translation,0,"We present an approach to feature weight optimization for document-level decoding. This is an essential task for enabling future development of discourse-level statistical machine translation, as it allows easy integration of discourse features in the decoding process. We extend the framework of sentence-level feature weight optimization to the document-level. We show experimentally that we can get competitive and relatively stable results when using a standard set of features, and that this framework also allows us to optimize documentlevel features, which can be used to model discourse phenomena."
W13-2229,Tunable Distortion Limits and Corpus Cleaning for {SMT},2013,17,11,2,0,634,sara stymne,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,"We describe the Uppsala University system for WMT13, for English-to-German translation. We use the Docent decoder, a local search decoder that translates at the document level. We add tunable distortion limits, that is, soft constraints on the maximum distortion allowed, to Docent. We also investigate cleaning of the noisy Common Crawl corpus. We show that we can use alignment-based filtering for cleaning with good results. Finally we investigate effects of corpus selection for recasing."
P13-4033,{D}ocent: A Document-Level Decoder for Phrase-Based Statistical Machine Translation,2013,20,30,1,1,670,christian hardmeier,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We describe Docent, an open-source decoder for statistical machine translation that breaks with the usual sentence-bysentence paradigm and translates complete documents as units. By taking translation to the document level, our decoder can handle feature models with arbitrary discourse-wide dependencies and constitutes an essential infrastructure component in the quest for discourse-aware SMT models. 1 Motivation"
D13-1037,Latent Anaphora Resolution for Cross-Lingual Pronoun Prediction,2013,23,19,1,1,670,christian hardmeier,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"This paper addresses the task of predicting the correct French translations of third-person subject pronouns in English discourse, a problem that is relevant as a prerequisite for machine translation and that requires anaphora resolution. We present an approach based on neural networks that models anaphoric links as latent variables and show that its performance is competitive with that of a system with separate anaphora resolution while not requiring any coreference-annotated training data. This demonstrates that the information contained in parallel bitexts can successfully be used to acquire knowledge about pronominal anaphora in an unsupervised way."
W12-3112,Tree Kernels for Machine Translation Quality Estimation,2012,17,33,1,1,670,christian hardmeier,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes Uppsala University's submissions to the Quality Estimation (QE) shared task at WMT 2012. We present a QE system based on Support Vector Machine regression, using a number of explicitly defined features extracted from the Machine Translation input, output and models in combination with tree kernels over constituency and dependency parse trees for the input and output sentences. We confirm earlier results suggesting that tree kernels can be a useful tool for QE system construction especially in the early stages of system design."
D12-1108,Document-Wide Decoding for Phrase-Based Statistical Machine Translation,2012,31,47,1,1,670,christian hardmeier,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"Independence between sentences is an assumption deeply entrenched in the models and algorithms used for statistical machine translation (SMT), particularly in the popular dynamic programming beam search decoding algorithm. This restriction is an obstacle to research on more sophisticated discourse-level models for SMT. We propose a stochastic local search decoding method for phrase-based SMT, which permits free document-wide dependencies in the models. We explore the stability and the search parameters of this method and demonstrate that it can be successfully used to optimise a document-level semantic language model."
W11-2144,The {U}ppsala-{FBK} systems at {WMT} 2011,2011,17,5,1,1,670,christian hardmeier,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper presents our submissions to the shared translation task at WMT 2011. We created two largely independent systems for English-to-French and Haitian Creole-to-English translation to evaluate different features and components from our ongoing research on these language pairs. Key features of our systems include anaphora resolution, hierarchical lexical reordering, data selection for language modelling, linear transduction grammars for word alignment and syntax-based decoding with monolingual dependency information."
2011.eamt-1.32,Improving Machine Translation Quality Prediction with Syntactic Tree Kernels,2011,22,14,1,1,670,christian hardmeier,Proceedings of the 15th Annual conference of the European Association for Machine Translation,0,"We investigate the problem of predicting the quality of a given Machine Translation (MT) output segment as a binary classification task. In a study with four different data sets in two text genres and two language pairs, we show that the performance of a Support Vector Machine (SVM) classifier can be improved by extending the feature set with implicitly defined syntactic features in the form of tree kernels over syntactic parse trees. Moreover, we demonstrate that syntax tree kernels achieve surprisingly high performance levels even without additional features, which makes them suitable as a low-effort initial building block for an MT quality estimation system."
W10-1710,{FBK} at {WMT} 2010: Word Lattices for Morphological Reduction and Chunk-Based Reordering,2010,10,16,1,1,670,christian hardmeier,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"FBK participated in the WMT 2010 Machine Translation shared task with phrase-based Statistical Machine Translation systems based on the Moses decoder for English-German and German-English translation. Our work concentrates on exploiting the available language modelling resources by using linear mixtures of large 6-gram language models and on addressing linguistic differences between English and German with methods based on word lattices. In particular, we use lattices to integrate a morphological analyser for German into our system, and we present some initial work on rule-based word reordering."
2010.jec-1.7,Machine Translation of {TV} Subtitles for Large Scale Production,2010,13,11,3,0,15670,martin volk,Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry,0,"This paper describes our work on building and employing Statistical Machine Translation systems for TV subtitles in Scandinavia. We have built translation systems for Danish, English, Norwegian and Swedish. They are used in daily subtitle production and translate large volumes. As an example we report on our evaluation results for three TV genres. We discuss our lessons learned in the system development process which shed interesting light on the practical use of Machine Translation technology."
2010.iwslt-papers.10,Modelling pronominal anaphora in statistical machine translation,2010,15,73,1,1,670,christian hardmeier,Proceedings of the 7th International Workshop on Spoken Language Translation: Papers,0,"Current Statistical Machine Translation (SMT) systems translate texts sentence by sentence without considering any cross-sentential context. Assuming independence between sentences makes it difficult to take certain translation decisions when the necessary information cannot be determined locally. We argue for the necessity to include crosssentence dependencies in SMT. As a case in point, we study the problem of pronominal anaphora translation by manually evaluating German-English SMT output. We then present a word dependency model for SMT, which can represent links between word pairs in the same or in different sentences. We use this model to integrate the output of a coreference resolution system into English-German SMT with a view to improving the translation of anaphoric pronouns."
W09-4610,Using Linguistic Annotations in Statistical Machine Translation of Film Subtitles,2009,12,8,1,1,670,christian hardmeier,Proceedings of the 17th Nordic Conference of Computational Linguistics ({NODALIDA} 2009),0,"Statistical Machine Translation (SMT) has been successfully employed to support translation of film subtitles. We explore the integration of Constraint Grammar corpus annotations into a Swedishxe2x80x90Danish subtitle SMT system in the framework of factored SMT. While the usefulness of the annotations is limited with large amounts of parallel data, we show that linguistic annotations can increase the gains in translation quality when monolingual data in the target language is added to an SMT system based on a small parallel corpus."
